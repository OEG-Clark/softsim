{"home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.maskrcnn-benchmark.setup.get_extensions": [[17, 57], ["os.path.dirname", "os.path.join", "glob.glob", "glob.glob", "glob.glob", "os.path.abspath", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "extension", "torch.cuda.is_available", "os.getenv"], "function", ["None"], ["def", "get_extensions", "(", ")", ":", "\n", "    ", "this_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "extensions_dir", "=", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"maskrcnn_benchmark\"", ",", "\"csrc\"", ")", "\n", "\n", "main_file", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"*.cpp\"", ")", ")", "\n", "source_cpu", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"cpu\"", ",", "\"*.cpp\"", ")", ")", "\n", "source_cuda", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"cuda\"", ",", "\"*.cu\"", ")", ")", "\n", "\n", "sources", "=", "main_file", "+", "source_cpu", "\n", "extension", "=", "CppExtension", "\n", "\n", "extra_compile_args", "=", "{", "\"cxx\"", ":", "[", "]", "}", "\n", "define_macros", "=", "[", "]", "\n", "\n", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "CUDA_HOME", "is", "not", "None", ")", "or", "os", ".", "getenv", "(", "\"FORCE_CUDA\"", ",", "\"0\"", ")", "==", "\"1\"", ":", "\n", "        ", "extension", "=", "CUDAExtension", "\n", "sources", "+=", "source_cuda", "\n", "define_macros", "+=", "[", "(", "\"WITH_CUDA\"", ",", "None", ")", "]", "\n", "extra_compile_args", "[", "\"nvcc\"", "]", "=", "[", "\n", "\"-DCUDA_HAS_FP16=1\"", ",", "\n", "\"-D__CUDA_NO_HALF_OPERATORS__\"", ",", "\n", "\"-D__CUDA_NO_HALF_CONVERSIONS__\"", ",", "\n", "\"-D__CUDA_NO_HALF2_OPERATORS__\"", ",", "\n", "]", "\n", "\n", "", "sources", "=", "[", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "s", ")", "for", "s", "in", "sources", "]", "\n", "\n", "include_dirs", "=", "[", "extensions_dir", "]", "\n", "\n", "ext_modules", "=", "[", "\n", "extension", "(", "\n", "\"maskrcnn_benchmark._C\"", ",", "\n", "sources", ",", "\n", "include_dirs", "=", "include_dirs", ",", "\n", "define_macros", "=", "define_macros", ",", "\n", "extra_compile_args", "=", "extra_compile_args", ",", "\n", ")", "\n", "]", "\n", "\n", "return", "ext_modules", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.test_net.main": [[21, 94], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "fcos_core.config.cfg.merge_from_file", "fcos_core.config.cfg.merge_from_list", "fcos_core.config.cfg.freeze", "fcos_core.utils.logger.setup_logger", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.modeling.detector.build_detection_model", "fcos_core.modeling.detector.build_detection_model.to", "fcos_core.utils.checkpoint.DetectronCheckpointer", "fcos_core.utils.checkpoint.DetectronCheckpointer.load", "fcos_core.data.make_data_loader", "zip", "int", "torch.cuda.set_device", "torch.distributed.init_process_group", "fcos_core.utils.comm.synchronize", "fcos_core.utils.comm.get_rank", "len", "enumerate", "fcos_core.engine.inference.inference", "fcos_core.utils.comm.synchronize", "fcos_core.utils.collect_env.collect_env_info", "os.path.join", "fcos_core.utils.miscellaneous.mkdir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detector.detectors.build_detection_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_data_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.collect_env_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.mkdir"], ["try", ":", "\n", "    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for mixed precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"PyTorch Object Detection Inference\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"/private/home/fmassa/github/detectron.pytorch_v2/configs/e2e_faster_rcnn_R_50_C4_1x_caffe2.yaml\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ckpt\"", ",", "\n", "help", "=", "\"The path to the checkpoint for test, default is the latest checkpoint.\"", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line\"", ",", "\n", "default", "=", "None", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "num_gpus", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "if", "\"WORLD_SIZE\"", "in", "os", ".", "environ", "else", "1", "\n", "distributed", "=", "num_gpus", ">", "1", "\n", "\n", "if", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "\"nccl\"", ",", "init_method", "=", "\"env://\"", "\n", ")", "\n", "synchronize", "(", ")", "\n", "\n", "", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "\n", "save_dir", "=", "\"\"", "\n", "logger", "=", "setup_logger", "(", "\"maskrcnn_benchmark\"", ",", "save_dir", ",", "get_rank", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Using {} GPUs\"", ".", "format", "(", "num_gpus", ")", ")", "\n", "logger", ".", "info", "(", "cfg", ")", "\n", "\n", "logger", ".", "info", "(", "\"Collecting env info (might take some time)\"", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", "+", "collect_env_info", "(", ")", ")", "\n", "\n", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "model", ".", "to", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "\n", "# Initialize mixed-precision if necessary", "\n", "use_mixed_precision", "=", "cfg", ".", "DTYPE", "==", "'float16'", "\n", "amp_handle", "=", "amp", ".", "init", "(", "enabled", "=", "use_mixed_precision", ",", "verbose", "=", "cfg", ".", "AMP_VERBOSE", ")", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "cfg", ",", "model", ",", "save_dir", "=", "output_dir", ")", "\n", "ckpt", "=", "cfg", ".", "MODEL", ".", "WEIGHT", "if", "args", ".", "ckpt", "is", "None", "else", "args", ".", "ckpt", "\n", "_", "=", "checkpointer", ".", "load", "(", "ckpt", ",", "use_latest", "=", "args", ".", "ckpt", "is", "None", ")", "\n", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "output_folders", "=", "[", "None", "]", "*", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "\n", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "if", "cfg", ".", "OUTPUT_DIR", ":", "\n", "        ", "for", "idx", ",", "dataset_name", "in", "enumerate", "(", "dataset_names", ")", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "mkdir", "(", "output_folder", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.__init__": [[49, 63], ["os.path.join", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "logger", ",", "distributed", ")", ":", "\n", "\n", "        ", "self", ".", "log_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "self", ".", "checkpoint_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "log_dir", ",", "'checkpoint.brainpkl'", ")", "\n", "\n", "self", ".", "memory", "=", "[", "]", "\n", "self", ".", "candidates", "=", "torch", ".", "Tensor", "(", "[", "[", "-", "1", "]", "*", "search_config", ".", "nr_layer", "]", "*", "search_config", ".", "population_num", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "vis_dict", "=", "{", "}", "\n", "self", ".", "keep_top_k", "=", "{", "search_config", ".", "select_num", ":", "[", "]", ",", "50", ":", "[", "]", "}", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "distributed", "=", "distributed", "\n", "self", ".", "results_scale_baseline", "=", "[", "0.204", ",", "0.394", ",", "0.483", "]", "\n", "self", ".", "prob_idx", "=", "[", "0", ",", "2", "]", "+", "[", "(", "5", "+", "3", "*", "i", ")", "for", "i", "in", "range", "(", "2", "*", "5", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.save_checkpoint": [[64, 77], ["search.EvolutionTrainer.logger.info", "os.path.exists", "os.makedirs", "isinstance", "search.EvolutionTrainer.candidates.cpu().long().tolist", "open", "pickle.dump", "search.EvolutionTrainer.candidates.cpu().long", "search.EvolutionTrainer.candidates.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["", "def", "save_checkpoint", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "log_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "log_dir", ")", "\n", "", "info", "=", "{", "}", "\n", "info", "[", "'memory'", "]", "=", "self", ".", "memory", "\n", "info", "[", "'candidates'", "]", "=", "self", ".", "candidates", "if", "isinstance", "(", "self", ".", "candidates", ",", "list", ")", "else", "self", ".", "candidates", ".", "cpu", "(", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "info", "[", "'vis_dict'", "]", "=", "self", ".", "vis_dict", "\n", "info", "[", "'keep_top_k'", "]", "=", "self", ".", "keep_top_k", "\n", "info", "[", "'epoch'", "]", "=", "self", ".", "epoch", "\n", "\n", "with", "open", "(", "self", ".", "checkpoint_name", ",", "'wb'", ")", "as", "fid", ":", "\n", "            ", "pickle", ".", "dump", "(", "info", ",", "fid", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "'save checkpoint to %s'", "%", "self", ".", "checkpoint_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.load_checkpoint": [[78, 92], ["torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "search.EvolutionTrainer.logger.info", "os.path.exists", "open", "pickle.load", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "load_checkpoint", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "checkpoint_name", ")", ":", "\n", "            ", "return", "False", "\n", "", "with", "open", "(", "self", ".", "checkpoint_name", ",", "'rb'", ")", "as", "fid", ":", "\n", "            ", "info", "=", "pickle", ".", "load", "(", "fid", ")", "\n", "\n", "", "self", ".", "memory", "=", "info", "[", "'memory'", "]", "\n", "self", ".", "candidates", "=", "torch", ".", "Tensor", "(", "info", "[", "'candidates'", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "vis_dict", "=", "info", "[", "'vis_dict'", "]", "\n", "self", ".", "keep_top_k", "=", "info", "[", "'keep_top_k'", "]", "\n", "self", ".", "epoch", "=", "info", "[", "'epoch'", "]", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'load checkpoint from %s'", "%", "self", ".", "checkpoint_name", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.update_top_k": [[93, 100], ["search.EvolutionTrainer.logger.info", "t.sort"], "methods", ["None"], ["", "def", "update_top_k", "(", "self", ",", "candidates", ",", "*", ",", "k", ",", "key", ",", "reverse", "=", "False", ")", ":", "\n", "        ", "assert", "k", "in", "self", ".", "keep_top_k", "\n", "self", ".", "logger", ".", "info", "(", "'select ......'", ")", "\n", "t", "=", "self", ".", "keep_top_k", "[", "k", "]", "\n", "t", "+=", "candidates", "\n", "t", ".", "sort", "(", "key", "=", "key", ",", "reverse", "=", "reverse", ")", "\n", "self", ".", "keep_top_k", "[", "k", "]", "=", "t", "[", ":", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.evaluate_single_aug": [[101, 126], ["os.path.join", "maskrcnn_benchmark.utils.miscellaneous.mkdir", "os.path.join", "search.EvolutionTrainer.logger.info", "maskrcnn_benchmark.utils.miscellaneous.save_config", "tools.train_net.train", "tools.train_net.run_test", "str", "search.reduce_loss_scale"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.mkdir", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.save_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.run_test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.reduce_loss_scale"], ["", "def", "evaluate_single_aug", "(", "self", ",", "cand", ",", "local_rank", ")", ":", "\n", "        ", "file_dir", "=", "''", "\n", "for", "i", "in", "cand", ":", "\n", "            ", "file_dir", "+=", "str", "(", "i", ")", "\n", "", "cfg", ".", "OUTPUT_DIR", "=", "os", ".", "path", ".", "join", "(", "self", ".", "log_dir", ",", "file_dir", ")", "\n", "\n", "mkdir", "(", "cfg", ".", "OUTPUT_DIR", ")", "\n", "\n", "output_config_path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "'config.yml'", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Saving config into: {}\"", ".", "format", "(", "output_config_path", ")", ")", "\n", "# save overloaded model config in the output directory", "\n", "save_config", "(", "cfg", ",", "output_config_path", ")", "\n", "\n", "model", ",", "loss_scale_hist", "=", "train", "(", "cfg", ",", "local_rank", ",", "self", ".", "distributed", ",", "search", "=", "self", ".", "logger", ")", "\n", "\n", "results", "=", "run_test", "(", "cfg", ",", "model", ",", "self", ".", "distributed", ")", "\n", "results_scales", "=", "[", "]", "\n", "if", "not", "results", "is", "None", ":", "\n", "            ", "results_bbox", "=", "results", "[", "0", "]", ".", "results", "[", "'bbox'", "]", "\n", "results_scales", "=", "[", "results_bbox", "[", "'APs'", "]", ",", "results_bbox", "[", "'APm'", "]", ",", "results_bbox", "[", "'APl'", "]", "]", "\n", "\n", "", "if", "self", ".", "distributed", ":", "\n", "            ", "loss_scale_hist", "=", "reduce_loss_scale", "(", "loss_scale_hist", ")", "\n", "\n", "", "return", "loss_scale_hist", ",", "results_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.stack_random_cand": [[127, 137], ["search.EvolutionTrainer.get_mutation.random_func", "range"], "methods", ["None"], ["", "def", "stack_random_cand", "(", "self", ",", "random_func", ",", "*", ",", "batchsize", "=", "10", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "cands", "=", "[", "random_func", "(", ")", "for", "_", "in", "range", "(", "batchsize", ")", "]", "\n", "for", "cand", "in", "cands", ":", "\n", "                ", "if", "cand", "not", "in", "self", ".", "vis_dict", ":", "\n", "                    ", "self", ".", "vis_dict", "[", "cand", "]", "=", "{", "}", "\n", "", "info", "=", "self", ".", "vis_dict", "[", "cand", "]", "\n", "\n", "", "for", "cand", "in", "cands", ":", "\n", "                ", "yield", "cand", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.random_can": [[138, 151], ["search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.stack_random_cand", "search.EvolutionTrainer.logger.info", "len", "next", "candidates.append", "search.EvolutionTrainer.logger.info", "tuple", "len", "len", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.stack_random_cand"], ["", "", "", "def", "random_can", "(", "self", ",", "num", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "'random select ........'", ")", "\n", "candidates", "=", "[", "]", "\n", "cand_iter", "=", "self", ".", "stack_random_cand", "(", "\n", "lambda", ":", "tuple", "(", "np", ".", "random", ".", "randint", "(", "i", ")", "for", "i", "in", "search_config", ".", "states", ")", ")", "\n", "while", "len", "(", "candidates", ")", "<", "num", ":", "\n", "            ", "cand", "=", "next", "(", "cand_iter", ")", "\n", "\n", "candidates", ".", "append", "(", "cand", ")", "\n", "self", ".", "logger", ".", "info", "(", "'random {}/{}'", ".", "format", "(", "len", "(", "candidates", ")", ",", "num", ")", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'random_num = {}'", ".", "format", "(", "len", "(", "candidates", ")", ")", ")", "\n", "return", "candidates", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.get_mutation": [[152, 175], ["search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.stack_random_cand", "search.EvolutionTrainer.logger.info", "list", "range", "tuple", "next", "res.append", "search.EvolutionTrainer.logger.info", "choice", "len", "len", "len", "numpy.random.random_sample", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.stack_random_cand", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "get_mutation", "(", "self", ",", "k", ",", "mutation_num", ",", "m_prob", ")", ":", "\n", "        ", "assert", "k", "in", "self", ".", "keep_top_k", "\n", "self", ".", "logger", ".", "info", "(", "'mutation ......'", ")", "\n", "res", "=", "[", "]", "\n", "iter", "=", "0", "\n", "max_iters", "=", "mutation_num", "*", "10", "\n", "\n", "def", "random_func", "(", ")", ":", "\n", "            ", "cand", "=", "list", "(", "choice", "(", "self", ".", "keep_top_k", "[", "k", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "search_config", ".", "states", ")", ")", ":", "\n", "                ", "if", "np", ".", "random", ".", "random_sample", "(", ")", "<", "m_prob", ":", "\n", "                    ", "cand", "[", "i", "]", "=", "np", ".", "random", ".", "randint", "(", "search_config", ".", "states", "[", "i", "]", ")", "\n", "", "", "return", "tuple", "(", "cand", ")", "\n", "\n", "", "cand_iter", "=", "self", ".", "stack_random_cand", "(", "random_func", ")", "\n", "while", "len", "(", "res", ")", "<", "mutation_num", "and", "max_iters", ">", "0", ":", "\n", "            ", "cand", "=", "next", "(", "cand_iter", ")", "\n", "res", ".", "append", "(", "cand", ")", "\n", "self", ".", "logger", ".", "info", "(", "'mutation {}/{}'", ".", "format", "(", "len", "(", "res", ")", ",", "mutation_num", ")", ")", "\n", "max_iters", "-=", "1", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'mutation_num = {}'", ".", "format", "(", "len", "(", "res", ")", ")", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.get_crossover": [[176, 195], ["search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.stack_random_cand", "search.EvolutionTrainer.logger.info", "choice", "choice", "tuple", "next", "res.append", "search.EvolutionTrainer.logger.info", "len", "len", "choice", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.stack_random_cand"], ["", "def", "get_crossover", "(", "self", ",", "k", ",", "crossover_num", ")", ":", "\n", "        ", "assert", "k", "in", "self", ".", "keep_top_k", "\n", "self", ".", "logger", ".", "info", "(", "'crossover ......'", ")", "\n", "res", "=", "[", "]", "\n", "iter", "=", "0", "\n", "max_iters", "=", "10", "*", "crossover_num", "\n", "def", "random_func", "(", ")", ":", "\n", "            ", "p1", "=", "choice", "(", "self", ".", "keep_top_k", "[", "k", "]", ")", "\n", "p2", "=", "choice", "(", "self", ".", "keep_top_k", "[", "k", "]", ")", "\n", "return", "tuple", "(", "choice", "(", "[", "i", ",", "j", "]", ")", "for", "i", ",", "j", "in", "zip", "(", "p1", ",", "p2", ")", ")", "\n", "", "cand_iter", "=", "self", ".", "stack_random_cand", "(", "random_func", ")", "\n", "while", "len", "(", "res", ")", "<", "crossover_num", "and", "max_iters", ">", "0", ":", "\n", "            ", "cand", "=", "next", "(", "cand_iter", ")", "\n", "res", ".", "append", "(", "cand", ")", "\n", "self", ".", "logger", ".", "info", "(", "'crossover {}/{}'", ".", "format", "(", "len", "(", "res", ")", ",", "crossover_num", ")", ")", "\n", "max_iters", "-=", "1", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'crossover_num = {}'", ".", "format", "(", "len", "(", "res", ")", ")", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.train": [[196, 274], ["maskrcnn_benchmark.utils.comm.synchronize", "search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.logger.info", "isinstance", "search.EvolutionTrainer.logger.info", "enumerate", "search.EvolutionTrainer.memory.append", "search.EvolutionTrainer.update_top_k", "search.EvolutionTrainer.update_top_k", "search.EvolutionTrainer.logger.info", "enumerate", "search.EvolutionTrainer.get_mutation", "search.EvolutionTrainer.get_crossover", "search.EvolutionTrainer.random_can", "search.EvolutionTrainer.save_checkpoint", "search.EvolutionTrainer.load_checkpoint", "search.EvolutionTrainer.random_can", "search.EvolutionTrainer.save_checkpoint", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.broadcast", "torch.broadcast", "tuple", "maskrcnn_benchmark.utils.comm.synchronize", "search.EvolutionTrainer.evaluate_single_aug", "loss_scale_hists.append", "results_scales.append", "copy.deepcopy", "copy.deepcopy.sum", "copy.deepcopy.std", "enumerate", "str", "search.EvolutionTrainer.memory[].append", "search.EvolutionTrainer.logger.info", "search.EvolutionTrainer.logger.info", "cand.tolist", "len", "len", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "search.EvolutionTrainer.logger.info", "[].mean", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "str", "str", "str", "numpy.array", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.update_top_k", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.update_top_k", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.get_mutation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.get_crossover", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.random_can", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.save_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.load_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.random_can", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.save_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.EvolutionTrainer.evaluate_single_aug"], ["", "def", "train", "(", "self", ",", "local_rank", ")", ":", "\n", "        ", "if", "local_rank", "==", "0", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'population_num = {} select_num = {} mutation_num = {} '", "\n", "'crossover_num = {} random_num = {} max_epochs = {}'", ".", "format", "(", "\n", "search_config", ".", "population_num", ",", "search_config", ".", "select_num", ",", "search_config", ".", "mutation_num", ",", "\n", "search_config", ".", "crossover_num", ",", "\n", "search_config", ".", "population_num", "-", "search_config", ".", "mutation_num", "-", "search_config", ".", "crossover_num", ",", "\n", "search_config", ".", "max_epochs", ")", ")", "\n", "\n", "if", "not", "self", ".", "load_checkpoint", "(", ")", ":", "\n", "                ", "self", ".", "candidates", "=", "self", ".", "random_can", "(", "search_config", ".", "population_num", ")", "\n", "self", ".", "save_checkpoint", "(", ")", "\n", "\n", "", "", "while", "self", ".", "epoch", "<", "search_config", ".", "max_epochs", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'epoch = {}'", ".", "format", "(", "self", ".", "epoch", ")", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "candidates", ",", "list", ")", ":", "\n", "                ", "self", ".", "candidates", "=", "torch", ".", "Tensor", "(", "self", ".", "candidates", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "", "if", "self", ".", "distributed", ":", "\n", "                ", "dist", ".", "broadcast", "(", "self", ".", "candidates", ",", "0", ")", "\n", "\n", "", "self", ".", "candidates", "=", "[", "tuple", "(", "cand", ".", "tolist", "(", ")", ")", "for", "cand", "in", "self", ".", "candidates", "]", "\n", "\n", "loss_scale_hists", "=", "[", "]", "\n", "results_scales", "=", "[", "]", "\n", "for", "cand", "in", "self", ".", "candidates", ":", "\n", "                ", "synchronize", "(", ")", "\n", "cfg", ".", "AUTOAUG", ".", "LIST", "=", "cand", "\n", "loss_scale_hist", ",", "results_scale", "=", "self", ".", "evaluate_single_aug", "(", "cand", ",", "local_rank", ")", "\n", "loss_scale_hists", ".", "append", "(", "loss_scale_hist", ")", "\n", "results_scales", ".", "append", "(", "results_scale", ")", "\n", "\n", "", "self", ".", "epoch", "+=", "1", "\n", "if", "local_rank", ">", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "logger", ".", "info", "(", "'Evaluation finish'", ")", "\n", "\n", "for", "i", ",", "cand", "in", "enumerate", "(", "self", ".", "candidates", ")", ":", "\n", "                ", "loss_hist", "=", "copy", ".", "deepcopy", "(", "loss_scale_hists", "[", "i", "]", ")", "\n", "loss_hist", "/=", "loss_hist", ".", "sum", "(", ")", "\n", "err", "=", "loss_hist", ".", "std", "(", ")", "\n", "for", "j", ",", "result_s", "in", "enumerate", "(", "self", ".", "results_scale_baseline", ")", ":", "\n", "                    ", "if", "results_scales", "[", "i", "]", "[", "j", "]", "<", "result_s", ":", "\n", "                        ", "self", ".", "logger", ".", "info", "(", "'Punishment for sarcrificing other scales : %s (baseline: %s) in %d th scale of %s.'", "%", "(", "str", "(", "copy", ".", "deepcopy", "(", "results_scales", "[", "i", "]", ")", ")", ",", "str", "(", "self", ".", "results_scale_baseline", ")", ",", "j", ",", "str", "(", "cand", ")", ")", ")", "\n", "err", "*=", "(", "result_s", "/", "results_scales", "[", "i", "]", "[", "j", "]", ")", "\n", "\n", "# A regularization to avoid probabilities decay to zero.", "\n", "", "", "l_prob", "=", "(", "9", "-", "np", ".", "array", "(", "cand", ")", "[", "self", ".", "prob_idx", "]", ".", "mean", "(", ")", ")", "*", "1e-2", "\n", "err", "+=", "l_prob", "\n", "self", ".", "vis_dict", "[", "cand", "]", "[", "'err'", "]", "=", "err", "\n", "self", ".", "vis_dict", "[", "cand", "]", "[", "'loss_hist'", "]", "=", "str", "(", "loss_scale_hists", "[", "i", "]", ")", "\n", "\n", "", "self", ".", "memory", ".", "append", "(", "[", "]", ")", "\n", "for", "cand", "in", "self", ".", "candidates", ":", "\n", "                ", "self", ".", "memory", "[", "-", "1", "]", ".", "append", "(", "cand", ")", "\n", "self", ".", "vis_dict", "[", "cand", "]", "[", "'visited'", "]", "=", "True", "\n", "\n", "", "self", ".", "update_top_k", "(", "self", ".", "candidates", ",", "k", "=", "search_config", ".", "select_num", ",", "key", "=", "lambda", "x", ":", "self", ".", "vis_dict", "[", "x", "]", "[", "'err'", "]", ")", "\n", "self", ".", "update_top_k", "(", "self", ".", "candidates", ",", "k", "=", "50", ",", "key", "=", "lambda", "x", ":", "self", ".", "vis_dict", "[", "x", "]", "[", "'err'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'epoch = {} : top {} result'", ".", "format", "(", "self", ".", "epoch", "-", "1", ",", "len", "(", "self", ".", "keep_top_k", "[", "50", "]", ")", ")", ")", "\n", "for", "i", ",", "cand", "in", "enumerate", "(", "self", ".", "keep_top_k", "[", "50", "]", ")", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'No.{} {} Top-1 err = {} loss hist = {}'", ".", "format", "(", "i", "+", "1", ",", "cand", ",", "self", ".", "vis_dict", "[", "cand", "]", "[", "'err'", "]", ",", "self", ".", "vis_dict", "[", "cand", "]", "[", "'loss_hist'", "]", ")", ")", "\n", "ops", "=", "[", "search_config", ".", "blocks_keys", "[", "i", "]", "for", "i", "in", "cand", "]", "\n", "self", ".", "logger", ".", "info", "(", "ops", ")", "\n", "\n", "", "mutation", "=", "self", ".", "get_mutation", "(", "search_config", ".", "select_num", ",", "search_config", ".", "mutation_num", ",", "search_config", ".", "m_prob", ")", "\n", "crossover", "=", "self", ".", "get_crossover", "(", "search_config", ".", "select_num", ",", "search_config", ".", "crossover_num", ")", "\n", "rand", "=", "self", ".", "random_can", "(", "search_config", ".", "population_num", "-", "len", "(", "mutation", ")", "-", "len", "(", "crossover", ")", ")", "\n", "\n", "self", ".", "candidates", "=", "mutation", "+", "crossover", "+", "rand", "\n", "\n", "self", ".", "save_checkpoint", "(", ")", "\n", "\n", "", "synchronize", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "self", ".", "keep_top_k", "[", "search_config", ".", "select_num", "]", ")", "\n", "self", ".", "logger", ".", "info", "(", "'finish!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.reduce_loss_scale": [[38, 47], ["maskrcnn_benchmark.utils.comm.get_world_size", "torch.no_grad", "torch.no_grad", "torch.reduce", "torch.get_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "def", "reduce_loss_scale", "(", "loss_scale", ")", ":", "\n", "    ", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "loss_scale", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "dist", ".", "reduce", "(", "loss_scale", ",", "dst", "=", "0", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "loss_scale", "/=", "world_size", "\n", "", "", "return", "loss_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.search.main": [[276, 315], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "maskrcnn_benchmark.config.cfg.merge_from_file", "maskrcnn_benchmark.utils.miscellaneous.mkdir", "maskrcnn_benchmark.utils.logger.setup_logger", "maskrcnn_benchmark.utils.logger.setup_logger.info", "time.time", "search.EvolutionTrainer", "search.EvolutionTrainer.train", "maskrcnn_benchmark.utils.logger.setup_logger.info", "int", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "maskrcnn_benchmark.utils.comm.synchronize", "time.time"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.mkdir", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "num_gpus", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "if", "\"WORLD_SIZE\"", "in", "os", ".", "environ", "else", "1", "\n", "distributed", "=", "num_gpus", ">", "1", "\n", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "AUTOAUG", ".", "SEARCH", "=", "True", "\n", "cfg", ".", "MODEL", ".", "WEIGHT", "=", "cfg", ".", "AUTOAUG", ".", "FT_WEIGHT", "\n", "cfg", ".", "SOLVER", ".", "MAX_ITER", "=", "cfg", ".", "AUTOAUG", ".", "FT_ITERS", "\n", "cfg", ".", "SOLVER", ".", "BASE_LR", "=", "cfg", ".", "AUTOAUG", ".", "FT_LR", "\n", "\n", "if", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"nccl\"", ",", "init_method", "=", "\"env://\"", "\n", ")", "\n", "synchronize", "(", ")", "\n", "\n", "", "mkdir", "(", "cfg", ".", "OUTPUT_DIR", ")", "\n", "logger", "=", "setup_logger", "(", "\"aug_search\"", ",", "cfg", ".", "OUTPUT_DIR", ",", "args", ".", "local_rank", ")", "\n", "logger", ".", "info", "(", "search_config", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "trainer", "=", "EvolutionTrainer", "(", "cfg", ",", "logger", ",", "distributed", ")", "\n", "\n", "trainer", ".", "train", "(", "args", ".", "local_rank", ")", "\n", "logger", ".", "info", "(", "'total searching time = {:.2f} hours'", ".", "format", "(", "(", "time", ".", "time", "(", ")", "-", "t", ")", "/", "3600", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.train": [[30, 83], ["fcos_core.modeling.detector.build_detection_model", "torch.device", "torch.nn.parallel.DistributedDataParallel.to", "fcos_core.solver.make_optimizer", "fcos_core.solver.make_lr_scheduler", "fcos_core.utils.checkpoint.DetectronCheckpointer", "fcos_core.utils.checkpoint.DetectronCheckpointer.load", "arguments.update", "fcos_core.data.make_data_loader", "fcos_core.engine.trainer.do_train", "fcos_core.utils.comm.is_pytorch_1_1_0_or_later", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.parallel.DistributedDataParallel", "fcos_core.utils.comm.get_rank", "fcos_core.config.cfg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detector.detectors.build_detection_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.make_optimizer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.make_lr_scheduler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_data_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.do_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_pytorch_1_1_0_or_later", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["try", ":", "\n", "    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for multi-precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n", "    ", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "make_optimizer", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "make_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Initialize mixed-precision training", "\n", "use_mixed_precision", "=", "cfg", ".", "DTYPE", "==", "\"float16\"", "\n", "amp_opt_level", "=", "'O1'", "if", "use_mixed_precision", "else", "'O0'", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "amp_opt_level", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ",", "\n", "# this should be removed if we update BatchNorm stats", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n", "", "arguments", "=", "{", "}", "\n", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "\n", "save_to_disk", "=", "get_rank", "(", ")", "==", "0", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "\n", "cfg", ",", "model", ",", "optimizer", ",", "scheduler", ",", "output_dir", ",", "save_to_disk", "\n", ")", "\n", "extra_checkpoint_data", "=", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHT", ")", "\n", "arguments", ".", "update", "(", "extra_checkpoint_data", ")", "\n", "\n", "if", "search", ":", "\n", "        ", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "", "data_loader", "=", "make_data_loader", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "is_distributed", "=", "distributed", ",", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", ",", "\n", ")", "\n", "\n", "test_period", "=", "cfg", ".", "SOLVER", ".", "TEST_PERIOD", "\n", "if", "test_period", ">", "0", ":", "\n", "        ", "data_loader_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ",", "is_for_period", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_val", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.run_test": [[85, 115], ["torch.cuda.empty_cache", "fcos_core.data.make_data_loader", "zip", "len", "enumerate", "fcos_core.engine.inference.inference", "fcos_core.utils.comm.synchronize", "os.path.join", "fcos_core.utils.miscellaneous.mkdir", "fcos_core.config.cfg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_data_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.mkdir"], ["\n", "loss_hist", "=", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "checkpointer", ",", "\n", "device", ",", "\n", "checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n", "search", ",", "\n", ")", "\n", "\n", "return", "model", ",", "loss_hist", "\n", "\n", "\n", "", "def", "run_test", "(", "cfg", ",", "model", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "# TODO check if it helps", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "output_folders", "=", "[", "None", "]", "*", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "\n", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "if", "cfg", ".", "OUTPUT_DIR", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.main": [[117, 177], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "fcos_core.config.cfg.merge_from_file", "fcos_core.config.cfg.merge_from_list", "fcos_core.config.cfg.freeze", "fcos_core.utils.logger.setup_logger", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "fcos_core.utils.logger.setup_logger.info", "train_net.train", "int", "torch.cuda.set_device", "torch.distributed.init_process_group", "fcos_core.utils.comm.synchronize", "fcos_core.utils.miscellaneous.mkdir", "fcos_core.utils.comm.get_rank", "open", "fcos_core.utils.logger.setup_logger.info", "train_net.run_test", "fcos_core.utils.collect_env.collect_env_info", "cf.read"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.mkdir", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.run_test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.collect_env_info"], ["            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "mkdir", "(", "output_folder", ")", "\n", "output_folders", "[", "idx", "]", "=", "output_folder", "\n", "", "", "data_loaders_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ")", "\n", "for", "output_folder", ",", "dataset_name", ",", "data_loader_val", "in", "zip", "(", "output_folders", ",", "dataset_names", ",", "data_loaders_val", ")", ":", "\n", "        ", "results", "=", "inference", "(", "\n", "model", ",", "\n", "data_loader_val", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "box_only", "=", "False", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", "or", "cfg", ".", "MODEL", ".", "FCOS_ON", "or", "cfg", ".", "MODEL", ".", "RETINANET_ON", "else", "cfg", ".", "MODEL", ".", "RPN_ONLY", ",", "\n", "device", "=", "cfg", ".", "MODEL", ".", "DEVICE", ",", "\n", "expected_results", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS", ",", "\n", "expected_results_sigma_tol", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS_SIGMA_TOL", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", ")", "\n", "synchronize", "(", ")", "\n", "\n", "", "if", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "return", "results", "\n", "\n", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"PyTorch Object Detection Training\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--skip-test\"", ",", "\n", "dest", "=", "\"skip_test\"", ",", "\n", "help", "=", "\"Do not test the final model\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line\"", ",", "\n", "default", "=", "None", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "num_gpus", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "if", "\"WORLD_SIZE\"", "in", "os", ".", "environ", "else", "1", "\n", "args", ".", "distributed", "=", "num_gpus", ">", "1", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "\"nccl\"", ",", "init_method", "=", "\"env://\"", "\n", ")", "\n", "synchronize", "(", ")", "\n", "\n", "", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.get_evaluator": [[56, 100], ["detectron2.evaluation.DatasetEvaluators", "os.path.join", "detectron2.data.MetadataCatalog.get", "evaluator_list.append", "evaluator_list.append", "evaluator_list.append", "detectron2.evaluation.CityscapesInstanceEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "detectron2.evaluation.PascalVOCDetectionEvaluator", "detectron2.evaluation.LVISEvaluator", "len", "NotImplementedError", "len", "detectron2.evaluation.SemSegEvaluator", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.COCOPanopticEvaluator", "torch.cuda.device_count", "detectron2.get_rank", "torch.cuda.device_count", "detectron2.get_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["def", "get_evaluator", "(", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Create evaluator(s) for a given dataset.\n    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n    For your own dataset, you can simply create an evaluator manually in your\n    script and do not have to worry about the hacky if-else logic here.\n    \"\"\"", "\n", "if", "output_folder", "is", "None", ":", "\n", "        ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "", "evaluator_list", "=", "[", "]", "\n", "evaluator_type", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", ".", "evaluator_type", "\n", "if", "evaluator_type", "in", "[", "\"sem_seg\"", ",", "\"coco_panoptic_seg\"", "]", ":", "\n", "        ", "evaluator_list", ".", "append", "(", "\n", "SemSegEvaluator", "(", "\n", "dataset_name", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "output_folder", ",", "\n", ")", "\n", ")", "\n", "", "if", "evaluator_type", "in", "[", "\"coco\"", ",", "\"coco_panoptic_seg\"", "]", ":", "\n", "        ", "evaluator_list", ".", "append", "(", "COCOEvaluator", "(", "dataset_name", ",", "output_dir", "=", "output_folder", ")", ")", "\n", "", "if", "evaluator_type", "==", "\"coco_panoptic_seg\"", ":", "\n", "        ", "evaluator_list", ".", "append", "(", "COCOPanopticEvaluator", "(", "dataset_name", ",", "output_folder", ")", ")", "\n", "", "if", "evaluator_type", "==", "\"cityscapes_instance\"", ":", "\n", "        ", "assert", "(", "\n", "torch", ".", "cuda", ".", "device_count", "(", ")", ">=", "comm", ".", "get_rank", "(", ")", "\n", ")", ",", "\"CityscapesEvaluator currently do not work with multiple machines.\"", "\n", "return", "CityscapesInstanceEvaluator", "(", "dataset_name", ")", "\n", "", "if", "evaluator_type", "==", "\"cityscapes_sem_seg\"", ":", "\n", "        ", "assert", "(", "\n", "torch", ".", "cuda", ".", "device_count", "(", ")", ">=", "comm", ".", "get_rank", "(", ")", "\n", ")", ",", "\"CityscapesEvaluator currently do not work with multiple machines.\"", "\n", "return", "CityscapesSemSegEvaluator", "(", "dataset_name", ")", "\n", "", "if", "evaluator_type", "==", "\"pascal_voc\"", ":", "\n", "        ", "return", "PascalVOCDetectionEvaluator", "(", "dataset_name", ")", "\n", "", "if", "evaluator_type", "==", "\"lvis\"", ":", "\n", "        ", "return", "LVISEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "", "if", "len", "(", "evaluator_list", ")", "==", "0", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"no Evaluator for the dataset {} with the type {}\"", ".", "format", "(", "dataset_name", ",", "evaluator_type", ")", "\n", ")", "\n", "", "if", "len", "(", "evaluator_list", ")", "==", "1", ":", "\n", "        ", "return", "evaluator_list", "[", "0", "]", "\n", "", "return", "DatasetEvaluators", "(", "evaluator_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.do_test": [[102, 117], ["collections.OrderedDict", "detectron2.data.build_detection_test_loader", "plain_train_net.get_evaluator", "detectron2.evaluation.inference_on_dataset", "detectron2.is_main_process", "len", "os.path.join", "logger.info", "detectron2.evaluation.print_csv_format", "list", "collections.OrderedDict.values"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.get_evaluator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.inference_on_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.print_csv_format", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "do_test", "(", "cfg", ",", "model", ")", ":", "\n", "    ", "results", "=", "OrderedDict", "(", ")", "\n", "for", "dataset_name", "in", "cfg", ".", "DATASETS", ".", "TEST", ":", "\n", "        ", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "evaluator", "=", "get_evaluator", "(", "\n", "cfg", ",", "dataset_name", ",", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", ")", "\n", "results_i", "=", "inference_on_dataset", "(", "model", ",", "data_loader", ",", "evaluator", ")", "\n", "results", "[", "dataset_name", "]", "=", "results_i", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Evaluation results for {} in csv format:\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "print_csv_format", "(", "results_i", ")", "\n", "", "", "if", "len", "(", "results", ")", "==", "1", ":", "\n", "        ", "results", "=", "list", "(", "results", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.do_train": [[119, 176], ["model.train", "detectron2.solver.build_optimizer", "detectron2.solver.build_lr_scheduler", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.PeriodicCheckpointer", "detectron2.data.build_detection_train_loader", "logger.info", "detectron2.checkpoint.DetectionCheckpointer.resume_or_load().get", "detectron2.is_main_process", "detectron2.engine.default_writers", "detectron2.utils.events.EventStorage", "zip", "range", "model", "sum", "torch.isfinite().all", "sum", "detectron2.is_main_process", "detectron2.solver.build_optimizer.zero_grad", "sum.backward", "detectron2.solver.build_optimizer.step", "storage.put_scalar", "detectron2.solver.build_lr_scheduler.step", "detectron2.checkpoint.PeriodicCheckpointer.step", "detectron2.checkpoint.DetectionCheckpointer.resume_or_load", "model.values", "v.item", "storage.put_scalars", "plain_train_net.do_test", "detectron2.synchronize", "torch.isfinite", "detectron2.reduce_dict().items", "writer.write", "loss_dict_reduced.values", "detectron2.reduce_dict"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_optimizer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_writers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_func.DeformRoIPoolingFunction.backward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalars", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.reduce_dict"], ["", "def", "do_train", "(", "cfg", ",", "model", ",", "resume", "=", "False", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "optimizer", "=", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "checkpointer", "=", "DetectionCheckpointer", "(", "\n", "model", ",", "cfg", ".", "OUTPUT_DIR", ",", "optimizer", "=", "optimizer", ",", "scheduler", "=", "scheduler", "\n", ")", "\n", "start_iter", "=", "(", "\n", "checkpointer", ".", "resume_or_load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "resume", ")", ".", "get", "(", "\"iteration\"", ",", "-", "1", ")", "+", "1", "\n", ")", "\n", "max_iter", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "\n", "periodic_checkpointer", "=", "PeriodicCheckpointer", "(", "\n", "checkpointer", ",", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", ",", "max_iter", "=", "max_iter", "\n", ")", "\n", "\n", "writers", "=", "default_writers", "(", "cfg", ".", "OUTPUT_DIR", ",", "max_iter", ")", "if", "comm", ".", "is_main_process", "(", ")", "else", "[", "]", "\n", "\n", "# compared to \"train_net.py\", we do not support accurate timing and", "\n", "# precise BN here, because they are not trivial to implement in a small training loop", "\n", "data_loader", "=", "build_detection_train_loader", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "storage", ":", "\n", "        ", "for", "data", ",", "iteration", "in", "zip", "(", "data_loader", ",", "range", "(", "start_iter", ",", "max_iter", ")", ")", ":", "\n", "            ", "storage", ".", "iter", "=", "iteration", "\n", "\n", "loss_dict", "=", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "assert", "torch", ".", "isfinite", "(", "losses", ")", ".", "all", "(", ")", ",", "loss_dict", "\n", "\n", "loss_dict_reduced", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "comm", ".", "reduce_dict", "(", "loss_dict", ")", ".", "items", "(", ")", "}", "\n", "losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "storage", ".", "put_scalars", "(", "total_loss", "=", "losses_reduced", ",", "**", "loss_dict_reduced", ")", "\n", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"lr\"", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "smoothing_hint", "=", "False", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "if", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ">", "0", "\n", "and", "(", "iteration", "+", "1", ")", "%", "cfg", ".", "TEST", ".", "EVAL_PERIOD", "==", "0", "\n", "and", "iteration", "!=", "max_iter", "-", "1", "\n", ")", ":", "\n", "                ", "do_test", "(", "cfg", ",", "model", ")", "\n", "# Compared to \"train_net.py\", the test results are not dumped to EventStorage", "\n", "comm", ".", "synchronize", "(", ")", "\n", "\n", "", "if", "iteration", "-", "start_iter", ">", "5", "and", "(", "\n", "(", "iteration", "+", "1", ")", "%", "20", "==", "0", "or", "iteration", "==", "max_iter", "-", "1", "\n", ")", ":", "\n", "                ", "for", "writer", "in", "writers", ":", "\n", "                    ", "writer", ".", "write", "(", ")", "\n", "", "", "periodic_checkpointer", ".", "step", "(", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.setup": [[178, 190], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["", "", "", "def", "setup", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Create configs and perform basic setups.\n    \"\"\"", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "default_setup", "(", "\n", "cfg", ",", "args", "\n", ")", "# if you don't like any of the default setup, write your own setup code", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.main": [[192, 211], ["plain_train_net.setup", "detectron2.modeling.build_model", "logger.info", "plain_train_net.do_train", "plain_train_net.do_test", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "plain_train_net.do_test", "detectron2.get_world_size", "torch.nn.parallel.DistributedDataParallel", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.get_local_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.do_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_local_rank"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Model:\\n{}\"", ".", "format", "(", "model", ")", ")", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", "\n", ")", "\n", "return", "do_test", "(", "cfg", ",", "model", ")", "\n", "\n", "", "distributed", "=", "comm", ".", "get_world_size", "(", ")", ">", "1", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "\n", "", "do_train", "(", "cfg", ",", "model", ",", "resume", "=", "args", ".", "resume", ")", "\n", "return", "do_test", "(", "cfg", ",", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.setup": [[35, 43], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.utils.logger.setup_logger", "detectron2.utils.comm.get_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "SOLVER", ".", "BASE_LR", "=", "0.001", "# Avoid NaNs. Not useful in this script anyway.", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "setup_logger", "(", "distributed_rank", "=", "comm", ".", "get_rank", "(", ")", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.RAM_msg": [[45, 49], ["psutil.virtual_memory"], "function", ["None"], ["", "def", "RAM_msg", "(", ")", ":", "\n", "    ", "vram", "=", "psutil", ".", "virtual_memory", "(", ")", "\n", "return", "\"RAM Usage: {:.2f}/{:.2f} GB\"", ".", "format", "(", "\n", "(", "vram", ".", "total", "-", "vram", ".", "available", ")", "/", "1024", "**", "3", ",", "vram", ".", "total", "/", "1024", "**", "3", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.benchmark_data": [[52, 87], ["benchmark.setup", "logger.info", "fvcore.common.timer.Timer", "detectron2.data.build_detection_train_loader", "logger.info", "fvcore.common.timer.Timer.reset", "iter", "range", "logger.info", "fvcore.common.timer.Timer", "tqdm.trange", "logger.info", "range", "next", "next", "logger.info", "fvcore.common.timer.Timer", "tqdm.trange", "logger.info", "benchmark.RAM_msg", "fvcore.common.timer.Timer.seconds", "fvcore.common.timer.Timer.seconds", "fvcore.common.timer.Timer.seconds", "next", "benchmark.RAM_msg", "fvcore.common.timer.Timer.seconds"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.RAM_msg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.RAM_msg"], ["", "def", "benchmark_data", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "\n", "logger", ".", "info", "(", "\"After spawning \"", "+", "RAM_msg", "(", ")", ")", "\n", "timer", "=", "Timer", "(", ")", "\n", "dataloader", "=", "build_detection_train_loader", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Initialize loader using {} seconds.\"", ".", "format", "(", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "timer", ".", "reset", "(", ")", "\n", "itr", "=", "iter", "(", "dataloader", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "# warmup", "\n", "        ", "next", "(", "itr", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "startup_time", "=", "timer", ".", "seconds", "(", ")", "\n", "", "", "logger", ".", "info", "(", "\"Startup time: {} seconds\"", ".", "format", "(", "startup_time", ")", ")", "\n", "timer", "=", "Timer", "(", ")", "\n", "max_iter", "=", "1000", "\n", "for", "_", "in", "tqdm", ".", "trange", "(", "max_iter", ")", ":", "\n", "        ", "next", "(", "itr", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"{} iters ({} images) in {} seconds.\"", ".", "format", "(", "\n", "max_iter", ",", "max_iter", "*", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", ",", "timer", ".", "seconds", "(", ")", "\n", ")", "\n", ")", "\n", "\n", "# test for a few more rounds", "\n", "for", "k", "in", "range", "(", "10", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Iteration {k} \"", "+", "RAM_msg", "(", ")", ")", "\n", "timer", "=", "Timer", "(", ")", "\n", "max_iter", "=", "1000", "\n", "for", "_", "in", "tqdm", ".", "trange", "(", "max_iter", ")", ":", "\n", "            ", "next", "(", "itr", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"{} iters ({} images) in {} seconds.\"", ".", "format", "(", "\n", "max_iter", ",", "max_iter", "*", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", ",", "timer", ".", "seconds", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.benchmark_train": [[91, 119], ["benchmark.setup", "detectron2.modeling.build_model", "logger.info", "detectron2.solver.build_optimizer", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer.load", "setup.defrost", "detectron2.data.build_detection_train_loader", "list", "trainer.register_hooks", "trainer.train", "detectron2.utils.comm.get_world_size", "torch.nn.parallel.DistributedDataParallel", "itertools.islice", "detectron2.data.DatasetFromList", "benchmark.benchmark_train.f"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_optimizer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.register_hooks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["", "", "def", "benchmark_train", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Model:\\n{}\"", ".", "format", "(", "model", ")", ")", "\n", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "        ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "", "optimizer", "=", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "checkpointer", "=", "DetectionCheckpointer", "(", "model", ",", "optimizer", "=", "optimizer", ")", "\n", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "2", "\n", "data_loader", "=", "build_detection_train_loader", "(", "cfg", ")", "\n", "dummy_data", "=", "list", "(", "itertools", ".", "islice", "(", "data_loader", ",", "100", ")", ")", "\n", "\n", "def", "f", "(", ")", ":", "\n", "        ", "data", "=", "DatasetFromList", "(", "dummy_data", ",", "copy", "=", "False", ",", "serialize", "=", "False", ")", "\n", "while", "True", ":", "\n", "            ", "yield", "from", "data", "\n", "\n", "", "", "max_iter", "=", "400", "\n", "trainer", "=", "(", "AMPTrainer", "if", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", "else", "SimpleTrainer", ")", "(", "model", ",", "f", "(", ")", ",", "optimizer", ")", "\n", "trainer", ".", "register_hooks", "(", "\n", "[", "hooks", ".", "IterationTimer", "(", ")", ",", "hooks", ".", "PeriodicWriter", "(", "[", "CommonMetricPrinter", "(", "max_iter", ")", "]", ")", "]", "\n", ")", "\n", "trainer", ".", "train", "(", "1", ",", "max_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.benchmark.benchmark_eval": [[121, 150], ["torch.no_grad", "benchmark.setup", "detectron2.modeling.build_model", "detectron2.modeling.build_model.eval", "logger.info", "detectron2.checkpoint.DetectionCheckpointer().load", "setup.defrost", "detectron2.data.build_detection_test_loader", "detectron2.data.DatasetFromList", "range", "fvcore.common.timer.Timer", "logger.info", "list", "detectron2.modeling.build_model.", "tqdm.tqdm", "enumerate", "detectron2.checkpoint.DetectionCheckpointer", "itertools.islice", "benchmark.benchmark_train.f"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "benchmark_eval", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "model", ".", "eval", "(", ")", "\n", "logger", ".", "info", "(", "\"Model:\\n{}\"", ".", "format", "(", "model", ")", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "dummy_data", "=", "DatasetFromList", "(", "list", "(", "itertools", ".", "islice", "(", "data_loader", ",", "100", ")", ")", ",", "copy", "=", "False", ")", "\n", "\n", "def", "f", "(", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "yield", "from", "dummy_data", "\n", "\n", "", "", "for", "k", "in", "range", "(", "5", ")", ":", "# warmup", "\n", "        ", "model", "(", "dummy_data", "[", "k", "]", ")", "\n", "\n", "", "max_iter", "=", "300", "\n", "timer", "=", "Timer", "(", ")", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "max_iter", ")", "as", "pbar", ":", "\n", "        ", "for", "idx", ",", "d", "in", "enumerate", "(", "f", "(", ")", ")", ":", "\n", "            ", "if", "idx", "==", "max_iter", ":", "\n", "                ", "break", "\n", "", "model", "(", "d", ")", "\n", "pbar", ".", "update", "(", ")", "\n", "", "", "logger", ".", "info", "(", "\"{} iters in {} seconds.\"", ".", "format", "(", "max_iter", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.analyze_model.setup": [[25, 34], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "setup_logger", "(", "name", "=", "\"fvcore\"", ")", "\n", "setup_logger", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.analyze_model.do_flop": [[36, 58], ["detectron2.data.build_detection_test_loader", "detectron2.modeling.build_model", "detectron2.checkpoint.DetectionCheckpointer().load", "detectron2.modeling.build_model.eval", "collections.Counter", "zip", "logger.info", "logger.info", "logger.info", "tqdm.trange", "detectron2.utils.analysis.FlopCountAnalysis", "detectron2.utils.analysis.FlopCountAnalysis.by_operator", "total_flops.append", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.utils.analysis.FlopCountAnalysis.unsupported_ops_warnings().uncalled_modules_warnings", "detectron2.utils.analysis.FlopCountAnalysis.total", "fvcore.nn.flop_count_table", "str", "numpy.mean", "numpy.std", "detectron2.utils.analysis.FlopCountAnalysis.unsupported_ops_warnings", "collections.Counter.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "do_flop", "(", "cfg", ")", ":", "\n", "    ", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "counts", "=", "Counter", "(", ")", "\n", "total_flops", "=", "[", "]", "\n", "for", "idx", ",", "data", "in", "zip", "(", "tqdm", ".", "trange", "(", "args", ".", "num_inputs", ")", ",", "data_loader", ")", ":", "# noqa", "\n", "        ", "flops", "=", "FlopCountAnalysis", "(", "model", ",", "data", ")", "\n", "if", "idx", ">", "0", ":", "\n", "            ", "flops", ".", "unsupported_ops_warnings", "(", "False", ")", ".", "uncalled_modules_warnings", "(", "False", ")", "\n", "", "counts", "+=", "flops", ".", "by_operator", "(", ")", "\n", "total_flops", ".", "append", "(", "flops", ".", "total", "(", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Flops table computed from only one input sample:\\n\"", "+", "flop_count_table", "(", "flops", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Average GFlops for each type of operators:\\n\"", "\n", "+", "str", "(", "[", "(", "k", ",", "v", "/", "(", "idx", "+", "1", ")", "/", "1e9", ")", "for", "k", ",", "v", "in", "counts", ".", "items", "(", ")", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total GFlops: {:.1f}\u00b1{:.1f}\"", ".", "format", "(", "np", ".", "mean", "(", "total_flops", ")", "/", "1e9", ",", "np", ".", "std", "(", "total_flops", ")", "/", "1e9", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.analyze_model.do_activation": [[61, 80], ["detectron2.data.build_detection_test_loader", "detectron2.modeling.build_model", "detectron2.checkpoint.DetectionCheckpointer().load", "detectron2.modeling.build_model.eval", "collections.Counter", "zip", "logger.info", "logger.info", "tqdm.trange", "detectron2.utils.analysis.activation_count_operators", "total_activations.append", "detectron2.checkpoint.DetectionCheckpointer", "sum", "str", "numpy.mean", "numpy.std", "detectron2.utils.analysis.activation_count_operators.values", "collections.Counter.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.analysis.activation_count_operators"], ["", "def", "do_activation", "(", "cfg", ")", ":", "\n", "    ", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "counts", "=", "Counter", "(", ")", "\n", "total_activations", "=", "[", "]", "\n", "for", "idx", ",", "data", "in", "zip", "(", "tqdm", ".", "trange", "(", "args", ".", "num_inputs", ")", ",", "data_loader", ")", ":", "# noqa", "\n", "        ", "count", "=", "activation_count_operators", "(", "model", ",", "data", ")", "\n", "counts", "+=", "count", "\n", "total_activations", ".", "append", "(", "sum", "(", "count", ".", "values", "(", ")", ")", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"(Million) Activations for Each Type of Operators:\\n\"", "\n", "+", "str", "(", "[", "(", "k", ",", "v", "/", "idx", ")", "for", "k", ",", "v", "in", "counts", ".", "items", "(", ")", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total (Million) Activations: {}\u00b1{}\"", ".", "format", "(", "\n", "np", ".", "mean", "(", "total_activations", ")", ",", "np", ".", "std", "(", "total_activations", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.analyze_model.do_parameter": [[84, 87], ["detectron2.modeling.build_model", "logger.info", "detectron2.utils.analysis.parameter_count_table"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model"], ["", "def", "do_parameter", "(", "cfg", ")", ":", "\n", "    ", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Parameter Count:\\n\"", "+", "parameter_count_table", "(", "model", ",", "max_depth", "=", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.analyze_model.do_structure": [[89, 92], ["detectron2.modeling.build_model", "logger.info", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model"], ["", "def", "do_structure", "(", "cfg", ")", ":", "\n", "    ", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Model Structure:\\n\"", "+", "str", "(", "model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.visualize_data.setup": [[17, 25], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.config.get_cfg.merge_from_file"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "if", "args", ".", "config_file", ":", "\n", "        ", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.visualize_data.parse_args": [[27, 45], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args"], ["", "def", "parse_args", "(", "in_args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Visualize ground-truth data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--source\"", ",", "\n", "choices", "=", "[", "\"annotation\"", ",", "\"dataloader\"", "]", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"visualize the annotations or the data loader (with pre-processing)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--config-file\"", ",", "metavar", "=", "\"FILE\"", ",", "help", "=", "\"path to config file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output-dir\"", ",", "default", "=", "\"./\"", ",", "help", "=", "\"path to output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--show\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"show output in a window\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line\"", ",", "\n", "default", "=", "None", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", "in_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.visualize_json_results.create_instances": [[19, 39], ["detectron2.structures.Instances", "numpy.asarray", "numpy.asarray().reshape", "detectron2.structures.BoxMode.convert", "numpy.asarray", "detectron2.structures.Boxes", "numpy.asarray", "dataset_id_map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["def", "create_instances", "(", "predictions", ",", "image_size", ")", ":", "\n", "    ", "ret", "=", "Instances", "(", "image_size", ")", "\n", "\n", "score", "=", "np", ".", "asarray", "(", "[", "x", "[", "\"score\"", "]", "for", "x", "in", "predictions", "]", ")", "\n", "chosen", "=", "(", "score", ">", "args", ".", "conf_threshold", ")", ".", "nonzero", "(", ")", "[", "0", "]", "\n", "score", "=", "score", "[", "chosen", "]", "\n", "bbox", "=", "np", ".", "asarray", "(", "[", "predictions", "[", "i", "]", "[", "\"bbox\"", "]", "for", "i", "in", "chosen", "]", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "bbox", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "\n", "labels", "=", "np", ".", "asarray", "(", "[", "dataset_id_map", "(", "predictions", "[", "i", "]", "[", "\"category_id\"", "]", ")", "for", "i", "in", "chosen", "]", ")", "\n", "\n", "ret", ".", "scores", "=", "score", "\n", "ret", ".", "pred_boxes", "=", "Boxes", "(", "bbox", ")", "\n", "ret", ".", "pred_classes", "=", "labels", "\n", "\n", "try", ":", "\n", "        ", "ret", ".", "pred_masks", "=", "[", "predictions", "[", "i", "]", "[", "\"segmentation\"", "]", "for", "i", "in", "chosen", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "pass", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.Trainer.build_evaluator": [[51, 98], ["detectron2.evaluation.DatasetEvaluators", "os.path.join", "detectron2.data.MetadataCatalog.get", "evaluator_list.append", "evaluator_list.append", "evaluator_list.append", "detectron2.evaluation.CityscapesInstanceEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "len", "NotImplementedError", "detectron2.evaluation.SemSegEvaluator", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.COCOPanopticEvaluator", "torch.cuda.device_count", "detectron2.get_rank", "torch.cuda.device_count", "detectron2.get_rank", "detectron2.evaluation.PascalVOCDetectionEvaluator", "len", "detectron2.evaluation.LVISEvaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ",", "\n", "# this should be removed if we update BatchNorm stats", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n", "", "arguments", "=", "{", "}", "\n", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "\n", "save_to_disk", "=", "get_rank", "(", ")", "==", "0", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "\n", "cfg", ",", "model", ",", "optimizer", ",", "scheduler", ",", "output_dir", ",", "save_to_disk", "\n", ")", "\n", "extra_checkpoint_data", "=", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHT", ")", "\n", "arguments", ".", "update", "(", "extra_checkpoint_data", ")", "\n", "\n", "if", "search", ":", "\n", "        ", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "", "data_loader", "=", "make_data_loader", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "is_distributed", "=", "distributed", ",", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", ",", "\n", ")", "\n", "\n", "test_period", "=", "cfg", ".", "SOLVER", ".", "TEST_PERIOD", "\n", "if", "test_period", ">", "0", ":", "\n", "        ", "data_loader_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ",", "is_for_period", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_val", "=", "None", "\n", "\n", "", "checkpoint_period", "=", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", "\n", "loss_hist", "=", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "checkpointer", ",", "\n", "device", ",", "\n", "checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n", "search", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.Trainer.test_with_TTA": [[99, 115], ["logging.getLogger", "logging.getLogger.info", "detectron2.modeling.GeneralizedRCNNWithTTA", "cls.test", "collections.OrderedDict", "cls.build_evaluator", "os.path.join", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_evaluator"], [")", "\n", "\n", "return", "model", ",", "loss_hist", "\n", "\n", "\n", "", "def", "run_test", "(", "cfg", ",", "model", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "# TODO check if it helps", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "output_folders", "=", "[", "None", "]", "*", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "\n", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "if", "cfg", ".", "OUTPUT_DIR", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.train_net.setup": [[117, 131], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup", "int", "[].rstrip", "detectron2.config.get_cfg.MODEL.WEIGHTS.split"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "mkdir", "(", "output_folder", ")", "\n", "output_folders", "[", "idx", "]", "=", "output_folder", "\n", "", "", "data_loaders_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ")", "\n", "for", "output_folder", ",", "dataset_name", ",", "data_loader_val", "in", "zip", "(", "output_folders", ",", "dataset_names", ",", "data_loaders_val", ")", ":", "\n", "        ", "results", "=", "inference", "(", "\n", "model", ",", "\n", "data_loader_val", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "box_only", "=", "False", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", "or", "cfg", ".", "MODEL", ".", "FCOS_ON", "or", "cfg", ".", "MODEL", ".", "RETINANET_ON", "else", "cfg", ".", "MODEL", ".", "RPN_ONLY", ",", "\n", "device", "=", "cfg", ".", "MODEL", ".", "DEVICE", ",", "\n", "expected_results", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS", ",", "\n", "expected_results_sigma_tol", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS_SIGMA_TOL", ",", "\n", "output_folder", "=", "output_folder", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tools.remove_solver_states.main": [[9, 28], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "os.path.splitext", "torch.save", "print"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Remove the solver states stored in a trained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"model\"", ",", "\n", "default", "=", "\"models/FCOS_R_50_FPN_1x.pth\"", ",", "\n", "help", "=", "\"path to the input model file\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "del", "model", "[", "\"optimizer\"", "]", "\n", "del", "model", "[", "\"scheduler\"", "]", "\n", "del", "model", "[", "\"iteration\"", "]", "\n", "\n", "filename_wo_ext", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "args", ".", "model", ")", "\n", "output_file", "=", "filename_wo_ext", "+", "\"_wo_solver_states\"", "+", "ext", "\n", "torch", ".", "save", "(", "model", ",", "output_file", ")", "\n", "print", "(", "\"Done. The model without solver states is saved to {}\"", ".", "format", "(", "output_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.instances2dict_with_polygons.instances2dict_with_polygons": [[19, 71], ["isinstance", "print", "Image.open", "np.array", "np.unique", "os.path.abspath", "print", "Instance", "Instance.toDict", "instances[].append", "print", "sys.stdout.flush", "len", "fcos_core.utils.cv2_util.findContours", "mask.copy", "c.reshape().tolist", "c.reshape"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours"], ["def", "instances2dict_with_polygons", "(", "imageFileList", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "imgCount", "=", "0", "\n", "instanceDict", "=", "{", "}", "\n", "\n", "if", "not", "isinstance", "(", "imageFileList", ",", "list", ")", ":", "\n", "        ", "imageFileList", "=", "[", "imageFileList", "]", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Processing {} images...\"", ".", "format", "(", "len", "(", "imageFileList", ")", ")", ")", "\n", "\n", "", "for", "imageFileName", "in", "imageFileList", ":", "\n", "# Load image", "\n", "        ", "img", "=", "Image", ".", "open", "(", "imageFileName", ")", "\n", "\n", "# Image as numpy array", "\n", "imgNp", "=", "np", ".", "array", "(", "img", ")", "\n", "\n", "# Initialize label categories", "\n", "instances", "=", "{", "}", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "instances", "[", "label", ".", "name", "]", "=", "[", "]", "\n", "\n", "# Loop through all instance ids in instance image", "\n", "", "for", "instanceId", "in", "np", ".", "unique", "(", "imgNp", ")", ":", "\n", "            ", "if", "instanceId", "<", "1000", ":", "\n", "                ", "continue", "\n", "", "instanceObj", "=", "Instance", "(", "imgNp", ",", "instanceId", ")", "\n", "instanceObj_dict", "=", "instanceObj", ".", "toDict", "(", ")", "\n", "\n", "#instances[id2label[instanceObj.labelID].name].append(instanceObj.toDict())", "\n", "if", "id2label", "[", "instanceObj", ".", "labelID", "]", ".", "hasInstances", ":", "\n", "                ", "mask", "=", "(", "imgNp", "==", "instanceId", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "contour", ",", "hier", "=", "cv2_util", ".", "findContours", "(", "\n", "mask", ".", "copy", "(", ")", ",", "cv2", ".", "RETR_EXTERNAL", ",", "cv2", ".", "CHAIN_APPROX_NONE", ")", "\n", "\n", "polygons", "=", "[", "c", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "for", "c", "in", "contour", "]", "\n", "instanceObj_dict", "[", "'contours'", "]", "=", "polygons", "\n", "\n", "", "instances", "[", "id2label", "[", "instanceObj", ".", "labelID", "]", ".", "name", "]", ".", "append", "(", "instanceObj_dict", ")", "\n", "\n", "", "imgKey", "=", "os", ".", "path", ".", "abspath", "(", "imageFileName", ")", "\n", "instanceDict", "[", "imgKey", "]", "=", "instances", "\n", "imgCount", "+=", "1", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"\\rImages Processed: {}\"", ".", "format", "(", "imgCount", ")", ",", "end", "=", "' '", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"\"", ")", "\n", "\n", "", "return", "instanceDict", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.instances2dict_with_polygons.main": [[72, 79], ["instances2dict_with_polygons.instances2dict_with_polygons", "len", "fileList.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.instances2dict_with_polygons.instances2dict_with_polygons"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "fileList", "=", "[", "]", "\n", "if", "(", "len", "(", "argv", ")", ">", "2", ")", ":", "\n", "        ", "for", "arg", "in", "argv", ":", "\n", "            ", "if", "(", "\"png\"", "in", "arg", ")", ":", "\n", "                ", "fileList", ".", "append", "(", "arg", ")", "\n", "", "", "", "instances2dict_with_polygons", "(", "fileList", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args": [[35, 48], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "argparse.ArgumentParser.print_help", "sys.exit"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Convert dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dataset'", ",", "help", "=", "\"cocostuff, cityscapes\"", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--outdir'", ",", "help", "=", "\"output dir for json files\"", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--datadir'", ",", "help", "=", "\"data dir for annotations to be converted\"", ",", "\n", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "1", ":", "\n", "        ", "parser", ".", "print_help", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.poly_to_box": [[50, 59], ["min", "max", "min", "max", "min", "max", "min", "max"], "function", ["None"], ["", "def", "poly_to_box", "(", "poly", ")", ":", "\n", "    ", "\"\"\"Convert a polygon into a tight bounding box.\"\"\"", "\n", "x0", "=", "min", "(", "min", "(", "p", "[", ":", ":", "2", "]", ")", "for", "p", "in", "poly", ")", "\n", "x1", "=", "max", "(", "max", "(", "p", "[", ":", ":", "2", "]", ")", "for", "p", "in", "poly", ")", "\n", "y0", "=", "min", "(", "min", "(", "p", "[", "1", ":", ":", "2", "]", ")", "for", "p", "in", "poly", ")", "\n", "y1", "=", "max", "(", "max", "(", "p", "[", "1", ":", ":", "2", "]", ")", "for", "p", "in", "poly", ")", "\n", "box_from_poly", "=", "[", "x0", ",", "y0", ",", "x1", ",", "y1", "]", "\n", "\n", "return", "box_from_poly", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.xyxy_to_xywh": [[60, 65], ["None"], "function", ["None"], ["", "def", "xyxy_to_xywh", "(", "xyxy_box", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "xyxy_box", "\n", "TO_REMOVE", "=", "1", "\n", "xywh_box", "=", "(", "xmin", ",", "ymin", ",", "xmax", "-", "xmin", "+", "TO_REMOVE", ",", "ymax", "-", "ymin", "+", "TO_REMOVE", ")", "\n", "return", "xywh_box", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.convert_coco_stuff_mat": [[67, 105], ["os.path.join", "print", "open", "enumerate", "open", "outfile.write", "img_name.replace().strip.replace().strip", "os.path.join", "h5py.File", "h5py.File.get", "scipy.misc.imsave", "images.append", "len", "os.path.join", "json.dumps", "len", "h5py.File.get", "enumerate", "os.path.join", "img_name.replace().strip.replace", "categories.append", "chr"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "convert_coco_stuff_mat", "(", "data_dir", ",", "out_dir", ")", ":", "\n", "    ", "\"\"\"Convert to png and save json with path. This currently only contains\n    the segmentation labels for objects+stuff in cocostuff - if we need to\n    combine with other labels from original COCO that will be a TODO.\"\"\"", "\n", "sets", "=", "[", "'train'", ",", "'val'", "]", "\n", "categories", "=", "[", "]", "\n", "json_name", "=", "'coco_stuff_%s.json'", "\n", "ann_dict", "=", "{", "}", "\n", "for", "data_set", "in", "sets", ":", "\n", "        ", "file_list", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'%s.txt'", ")", "\n", "images", "=", "[", "]", "\n", "with", "open", "(", "file_list", "%", "data_set", ")", "as", "f", ":", "\n", "            ", "for", "img_id", ",", "img_name", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "img_name", "=", "img_name", ".", "replace", "(", "'coco'", ",", "'COCO'", ")", ".", "strip", "(", "'\\n'", ")", "\n", "image", "=", "{", "}", "\n", "mat_file", "=", "os", ".", "path", ".", "join", "(", "\n", "data_dir", ",", "'annotations/%s.mat'", "%", "img_name", ")", "\n", "data", "=", "h5py", ".", "File", "(", "mat_file", ",", "'r'", ")", "\n", "labelMap", "=", "data", ".", "get", "(", "'S'", ")", "\n", "if", "len", "(", "categories", ")", "==", "0", ":", "\n", "                    ", "labelNames", "=", "data", ".", "get", "(", "'names'", ")", "\n", "for", "idx", ",", "n", "in", "enumerate", "(", "labelNames", ")", ":", "\n", "                        ", "categories", ".", "append", "(", "\n", "{", "\"id\"", ":", "idx", ",", "\"name\"", ":", "''", ".", "join", "(", "chr", "(", "i", ")", "for", "i", "in", "data", "[", "\n", "n", "[", "0", "]", "]", ")", "}", ")", "\n", "", "ann_dict", "[", "'categories'", "]", "=", "categories", "\n", "", "scipy", ".", "misc", ".", "imsave", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "img_name", "+", "'.png'", ")", ",", "labelMap", ")", "\n", "image", "[", "'width'", "]", "=", "labelMap", ".", "shape", "[", "0", "]", "\n", "image", "[", "'height'", "]", "=", "labelMap", ".", "shape", "[", "1", "]", "\n", "image", "[", "'file_name'", "]", "=", "img_name", "\n", "image", "[", "'seg_file_name'", "]", "=", "img_name", "\n", "image", "[", "'id'", "]", "=", "img_id", "\n", "images", ".", "append", "(", "image", ")", "\n", "", "", "ann_dict", "[", "'images'", "]", "=", "images", "\n", "print", "(", "\"Num images: %s\"", "%", "len", "(", "images", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "json_name", "%", "data_set", ")", ",", "'wb'", ")", "as", "outfile", ":", "\n", "            ", "outfile", ".", "write", "(", "json", ".", "dumps", "(", "ann_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.getLabelID": [[108, 113], ["int"], "function", ["None"], ["", "", "", "def", "getLabelID", "(", "self", ",", "instID", ")", ":", "\n", "    ", "if", "(", "instID", "<", "1000", ")", ":", "\n", "        ", "return", "instID", "\n", "", "else", ":", "\n", "        ", "return", "int", "(", "instID", "/", "1000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.convert_cityscapes_instance_only": [[115, 228], ["zip", "print", "os.path.join", "os.walk", "print", "print", "print", "open", "outfile.write", "filename.endswith", "len", "len", "len", "os.path.join", "json.dumps", "json.load", "images.append", "os.path.join", "print", "open", "cityscapesscripts.instances2dict_with_polygons", "data_set.split", "len", "os.path.join", "convert_cityscapes_to_coco.poly_to_box", "convert_cityscapes_to_coco.xyxy_to_xywh", "annotations.append", "data_set.split", "print", "len", "min", "print", "len", "len", "len", "len", "data_set.split", "data_set.split"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.instances2dict_with_polygons.instances2dict_with_polygons", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.poly_to_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.xyxy_to_xywh"], ["", "", "def", "convert_cityscapes_instance_only", "(", "\n", "data_dir", ",", "out_dir", ")", ":", "\n", "    ", "\"\"\"Convert from cityscapes format to COCO instance seg format - polygons\"\"\"", "\n", "sets", "=", "[", "\n", "'gtFine_val'", ",", "\n", "'gtFine_train'", ",", "\n", "'gtFine_test'", ",", "\n", "\n", "# 'gtCoarse_train',", "\n", "# 'gtCoarse_val',", "\n", "# 'gtCoarse_train_extra'", "\n", "]", "\n", "ann_dirs", "=", "[", "\n", "'gtFine_trainvaltest/gtFine/val'", ",", "\n", "'gtFine_trainvaltest/gtFine/train'", ",", "\n", "'gtFine_trainvaltest/gtFine/test'", ",", "\n", "\n", "# 'gtCoarse/train',", "\n", "# 'gtCoarse/train_extra',", "\n", "# 'gtCoarse/val'", "\n", "]", "\n", "json_name", "=", "'instancesonly_filtered_%s.json'", "\n", "ends_in", "=", "'%s_polygons.json'", "\n", "img_id", "=", "0", "\n", "ann_id", "=", "0", "\n", "cat_id", "=", "1", "\n", "category_dict", "=", "{", "}", "\n", "\n", "category_instancesonly", "=", "[", "\n", "'person'", ",", "\n", "'rider'", ",", "\n", "'car'", ",", "\n", "'truck'", ",", "\n", "'bus'", ",", "\n", "'train'", ",", "\n", "'motorcycle'", ",", "\n", "'bicycle'", ",", "\n", "]", "\n", "\n", "for", "data_set", ",", "ann_dir", "in", "zip", "(", "sets", ",", "ann_dirs", ")", ":", "\n", "        ", "print", "(", "'Starting %s'", "%", "data_set", ")", "\n", "ann_dict", "=", "{", "}", "\n", "images", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "ann_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "ann_dir", ")", "\n", "\n", "for", "root", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "ann_dir", ")", ":", "\n", "            ", "for", "filename", "in", "files", ":", "\n", "                ", "if", "filename", ".", "endswith", "(", "ends_in", "%", "data_set", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ":", "\n", "                    ", "if", "len", "(", "images", ")", "%", "50", "==", "0", ":", "\n", "                        ", "print", "(", "\"Processed %s images, %s annotations\"", "%", "(", "\n", "len", "(", "images", ")", ",", "len", "(", "annotations", ")", ")", ")", "\n", "", "json_ann", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", ")", ")", "\n", "image", "=", "{", "}", "\n", "image", "[", "'id'", "]", "=", "img_id", "\n", "img_id", "+=", "1", "\n", "\n", "image", "[", "'width'", "]", "=", "json_ann", "[", "'imgWidth'", "]", "\n", "image", "[", "'height'", "]", "=", "json_ann", "[", "'imgHeight'", "]", "\n", "image", "[", "'file_name'", "]", "=", "filename", "[", ":", "-", "len", "(", "\n", "ends_in", "%", "data_set", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "]", "+", "'leftImg8bit.png'", "\n", "image", "[", "'seg_file_name'", "]", "=", "filename", "[", ":", "-", "len", "(", "\n", "ends_in", "%", "data_set", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "]", "+", "'%s_instanceIds.png'", "%", "data_set", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "images", ".", "append", "(", "image", ")", "\n", "\n", "fullname", "=", "os", ".", "path", ".", "join", "(", "root", ",", "image", "[", "'seg_file_name'", "]", ")", "\n", "objects", "=", "cs", ".", "instances2dict_with_polygons", "(", "\n", "[", "fullname", "]", ",", "verbose", "=", "False", ")", "[", "fullname", "]", "\n", "\n", "for", "object_cls", "in", "objects", ":", "\n", "                        ", "if", "object_cls", "not", "in", "category_instancesonly", ":", "\n", "                            ", "continue", "# skip non-instance categories", "\n", "\n", "", "for", "obj", "in", "objects", "[", "object_cls", "]", ":", "\n", "                            ", "if", "obj", "[", "'contours'", "]", "==", "[", "]", ":", "\n", "                                ", "print", "(", "'Warning: empty contours.'", ")", "\n", "continue", "# skip non-instance categories", "\n", "\n", "", "len_p", "=", "[", "len", "(", "p", ")", "for", "p", "in", "obj", "[", "'contours'", "]", "]", "\n", "if", "min", "(", "len_p", ")", "<=", "4", ":", "\n", "                                ", "print", "(", "'Warning: invalid contours.'", ")", "\n", "continue", "# skip non-instance categories", "\n", "\n", "", "ann", "=", "{", "}", "\n", "ann", "[", "'id'", "]", "=", "ann_id", "\n", "ann_id", "+=", "1", "\n", "ann", "[", "'image_id'", "]", "=", "image", "[", "'id'", "]", "\n", "ann", "[", "'segmentation'", "]", "=", "obj", "[", "'contours'", "]", "\n", "\n", "if", "object_cls", "not", "in", "category_dict", ":", "\n", "                                ", "category_dict", "[", "object_cls", "]", "=", "cat_id", "\n", "cat_id", "+=", "1", "\n", "", "ann", "[", "'category_id'", "]", "=", "category_dict", "[", "object_cls", "]", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "ann", "[", "'area'", "]", "=", "obj", "[", "'pixelCount'", "]", "\n", "\n", "xyxy_box", "=", "poly_to_box", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "xywh_box", "=", "xyxy_to_xywh", "(", "xyxy_box", ")", "\n", "ann", "[", "'bbox'", "]", "=", "xywh_box", "\n", "\n", "annotations", ".", "append", "(", "ann", ")", "\n", "\n", "", "", "", "", "", "ann_dict", "[", "'images'", "]", "=", "images", "\n", "categories", "=", "[", "{", "\"id\"", ":", "category_dict", "[", "name", "]", ",", "\"name\"", ":", "name", "}", "for", "name", "in", "\n", "category_dict", "]", "\n", "ann_dict", "[", "'categories'", "]", "=", "categories", "\n", "ann_dict", "[", "'annotations'", "]", "=", "annotations", "\n", "print", "(", "\"Num categories: %s\"", "%", "len", "(", "categories", ")", ")", "\n", "print", "(", "\"Num images: %s\"", "%", "len", "(", "images", ")", ")", "\n", "print", "(", "\"Num annotations: %s\"", "%", "len", "(", "annotations", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "json_name", "%", "data_set", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "            ", "outfile", ".", "write", "(", "json", ".", "dumps", "(", "ann_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.cityscapes_eval.do_cityscapes_evaluation": [[22, 104], ["logging.getLogger", "logging.getLogger.info", "copy.deepcopy", "os.path.join", "cityscapesscripts.helpers.csHelpers.ensurePath", "os.path.join", "os.path.join", "os.path.join", "list", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.matchGtsWithPreds", "cityscapesscripts.helpers.csHelpers.writeDict2JSON", "NotImplementedError", "logging.getLogger.info", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.evaluateBoxMatches", "logging.getLogger.info", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.computeAverages", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.prepareJSONDataForResults", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.printResults", "logging.getLogger.info", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.evaluateMaskMatches", "logging.getLogger.info", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.computeAverages", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.prepareJSONDataForResults", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.printResults", "os.path.dirname", "cityscapesscripts.helpers.csHelpers.ensurePath", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.writeDict2JSON", "os.path.dirname", "cityscapesscripts.helpers.csHelpers.ensurePath", "maskrcnn_benchmark.data.datasets.evaluation.cityscapes.eval_instances.writeDict2JSON"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.matchGtsWithPreds", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.evaluateBoxMatches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeAverages", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.prepareJSONDataForResults", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.printResults", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.evaluateMaskMatches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeAverages", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.prepareJSONDataForResults", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.printResults"], ["def", "do_cityscapes_evaluation", "(", "\n", "dataset", ",", "\n", "predictions", ",", "\n", "box_only", ",", "\n", "output_folder", ",", "\n", "iou_types", ",", "\n", "expected_results", ",", "\n", "expected_results_sigma_tol", ",", "\n", ")", ":", "\n", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.inference\"", ")", "\n", "logger", ".", "info", "(", "f\"CityScapes evaluation on [{dataset}]:\"", ")", "\n", "# Set default args for evaluation", "\n", "args", "=", "deepcopy", "(", "eval_instances", ".", "defaultArgs", ")", "\n", "\n", "# Set output folder", "\n", "output_folder", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"evaluationResults\"", ")", "\n", "ensurePath", "(", "output_folder", ")", "\n", "\n", "# Set custom fields", "\n", "args", ".", "exportMatchFile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"matches.json\"", ")", "\n", "args", ".", "exportBoxFile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"boxResult.json\"", ")", "\n", "args", ".", "exportMaskFile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"maskResult.json\"", ")", "\n", "args", ".", "instLabels", "=", "list", "(", "dataset", ".", "CLASSES", ")", "\n", "\n", "logger", ".", "info", "(", "\"Evaluation arguments\"", ")", "\n", "logger", ".", "info", "(", "\"%s\"", "%", "args", ")", "\n", "logger", ".", "info", "(", "\"Matching GT instances with Predictions\"", ")", "\n", "if", "\"bbox\"", "in", "iou_types", "or", "\"segm\"", "in", "iou_types", ":", "\n", "# Match and compute IoU of mask and box in one iteration:", "\n", "        ", "matches", "=", "eval_instances", ".", "matchGtsWithPreds", "(", "dataset", ",", "predictions", ")", "\n", "writeDict2JSON", "(", "matches", ",", "args", ".", "exportMatchFile", ")", "\n", "", "else", ":", "\n", "        ", "NotImplementedError", "(", "f\"IoU type not implemented {iou_types}\"", ")", "\n", "\n", "# printing", "\n", "", "strResults", "=", "\"\"", "\n", "if", "\"bbox\"", "in", "iou_types", ":", "\n", "# evaluate matches", "\n", "        ", "logger", ".", "info", "(", "\"Evaluating BBox matches\"", ")", "\n", "boxApScores", "=", "eval_instances", ".", "evaluateBoxMatches", "(", "matches", ",", "args", ")", "\n", "\n", "# averages", "\n", "logger", ".", "info", "(", "\"Average Box scores\"", ")", "\n", "boxAvgDict", "=", "eval_instances", ".", "computeAverages", "(", "boxApScores", ",", "args", ")", "\n", "\n", "# logging", "\n", "boxResDict", "=", "eval_instances", ".", "prepareJSONDataForResults", "(", "\n", "boxAvgDict", ",", "boxApScores", ",", "args", "\n", ")", "\n", "if", "args", ".", "JSONOutput", ":", "\n", "# create output folder if necessary", "\n", "            ", "path", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "exportBoxFile", ")", "\n", "ensurePath", "(", "path", ")", "\n", "# Write APs to JSON", "\n", "eval_instances", ".", "writeDict2JSON", "(", "boxResDict", ",", "args", ".", "exportBoxFile", ")", "\n", "", "strBoxResults", "=", "eval_instances", ".", "printResults", "(", "boxAvgDict", ",", "args", ")", "\n", "strResults", "+=", "\"\\nBBox\\n\"", "+", "strBoxResults", "\n", "\n", "", "if", "\"segm\"", "in", "iou_types", ":", "\n", "# evaluate matches", "\n", "        ", "logger", ".", "info", "(", "\"Evaluating Mask matches\"", ")", "\n", "maskApScores", "=", "eval_instances", ".", "evaluateMaskMatches", "(", "matches", ",", "args", ")", "\n", "\n", "# averages", "\n", "logger", ".", "info", "(", "\"Average Mask scores\"", ")", "\n", "maskAvgDict", "=", "eval_instances", ".", "computeAverages", "(", "maskApScores", ",", "args", ")", "\n", "\n", "# logging", "\n", "maskResDict", "=", "eval_instances", ".", "prepareJSONDataForResults", "(", "\n", "maskAvgDict", ",", "maskApScores", ",", "args", "\n", ")", "\n", "if", "args", ".", "JSONOutput", ":", "\n", "# create output folder if necessary", "\n", "            ", "path", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "exportMaskFile", ")", "\n", "ensurePath", "(", "path", ")", "\n", "# Write APs to JSON", "\n", "eval_instances", ".", "writeDict2JSON", "(", "maskResDict", ",", "args", ".", "exportMaskFile", ")", "\n", "", "strMaskResults", "=", "eval_instances", ".", "printResults", "(", "maskAvgDict", ",", "args", ")", "\n", "strResults", "+=", "\"\\nMask\\n\"", "+", "strMaskResults", "\n", "\n", "", "logger", ".", "info", "(", "strResults", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.CArgs.__repr__": [[66, 77], ["max", "max", "eval_instances.CArgs.__dict__.items", "len", "len", "max", "str", "eval_instances.CArgs.__dict__.keys", "str", "eval_instances.CArgs.__dict__.values", "max"], "methods", ["None"], ["    ", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        A weird looking pretty print for Evaluation Arguments\n        \"\"\"", "\n", "longest_key", "=", "max", "(", "[", "len", "(", "str", "(", "k", ")", ")", "for", "k", "in", "self", ".", "__dict__", ".", "keys", "(", ")", "]", ")", "\n", "longest_val", "=", "max", "(", "[", "len", "(", "str", "(", "v", ")", ")", "for", "v", "in", "self", ".", "__dict__", ".", "values", "(", ")", "]", ")", "\n", "s", "=", "\"\\n\"", "+", "\"#\"", "*", "max", "(", "79", ",", "(", "longest_key", "+", "longest_val", "+", "3", ")", ")", "+", "\"\\n\"", "\n", "for", "k", ",", "v", "in", "self", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "s", "+=", "\"%{}s : %s\\n\"", ".", "format", "(", "longest_key", ")", "%", "(", "k", ",", "v", ")", "\n", "", "s", "+=", "\"#\"", "*", "max", "(", "79", ",", "(", "longest_key", "+", "longest_val", "+", "3", ")", ")", "+", "\"\\n\"", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.matchGtsWithPreds": [[99, 157], ["tqdm.tqdm", "len", "len", "range", "matches.append", "len", "len", "len", "eval_instances.matchGtWithPred"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.matchGtWithPred"], ["def", "matchGtsWithPreds", "(", "dataset", ",", "predictions", ")", ":", "\n", "    ", "\"\"\"\n    Go through the `dataset` and `predictions` one-by-one, and list all\n    instances with any non-zero intersection.\n\n    This function handles matching when only BBoxes are used, and when\n    instnace segmentation is available it computes the pixel-wise overlap as\n    well\n\n    The implementation is heavily based on the original CityScapes eval script:\n    https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/evalInstanceLevelSemanticLabeling.py\n\n\n    Original match structure looks like:\n    {\"filename1\":\n        \"groundTruth\":gtInstances\n        \"prediction\":predInstances\n    }\n    # Filenames are not necessary, replace them with idx\n\n\n    <gt/pred>Instances=\n    {\n        \"category_name1\":[<gt/pred>Instance1, <gt/pred>Instance2, ...]\n        \"category_name2\":[<gt/pred>Instance3, <gt/pred>Instance4, ...]\n    ...\n    }\n\n    gtInstance=\n    {\n        \"labelID\":int(labelID)\n        \"instID\":int(instID)\n        \"boxArea\":np.count_nonzero(npArray binary mask)\n        \"intersection\": pixel count (ONLY IF the dict is in the inner list of a predInstance[\"matchedGt\"])\n        \"voidIntersection\":REMOVE THIS!!!\n        \"matchedPred\":list(predInstance) which has nonzero intersection\n    }\n\n    predInstance=\n    {\n        \"imgName\":\"path/to/input/img\"\n        \"predID\":<a counter's current state>\n        \"labelID\":int(labelID)\n        \"boxArea\":pixel count (ONLY IF the dict is in the inner list of a predInstance[\"matchedGt\"])\n        \"confidence\":float(confidence)\n        \"intersection\":np.count_nonzero( np.logical_and( gtNp == gtInstance[\"instID\"] , boolPredInst) )\n        \"voidIntersection\":REMOVE THIS!!!\n        \"matchedGt\":list(gtInstance) which has nonzero intersection\n    }\n    \"\"\"", "\n", "\n", "assert", "len", "(", "dataset", ")", "==", "len", "(", "predictions", ")", ",", "f\"{len(dataset)} != {len(predictions)}\"", "\n", "\n", "matches", "=", "[", "]", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "predictions", ")", ")", ",", "desc", "=", "\"Matching Preds with GT\"", ")", ":", "\n", "        ", "matches", ".", "append", "(", "matchGtWithPred", "(", "dataset", ",", "predictions", ",", "idx", ")", ")", "\n", "\n", "", "return", "matches", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.isOverlapping": [[159, 164], ["None"], "function", ["None"], ["", "def", "isOverlapping", "(", "box1", ",", "box2", ")", ":", "\n", "    ", "x1min", ",", "y1min", ",", "x1max", ",", "y1max", "=", "box1", "\n", "x2min", ",", "y2min", ",", "x2max", ",", "y2max", "=", "box2", "\n", "ret", "=", "x1min", "<", "x2max", "and", "x2min", "<", "x1max", "and", "y1min", "<", "y2max", "and", "y2min", "<", "y1max", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.getUnionBox": [[166, 177], ["map", "map", "min", "min", "max", "max"], "function", ["None"], ["", "def", "getUnionBox", "(", "box1", ",", "box2", ")", ":", "\n", "    ", "x1min", ",", "y1min", ",", "x1max", ",", "y1max", "=", "map", "(", "int", ",", "box1", ")", "\n", "x2min", ",", "y2min", ",", "x2max", ",", "y2max", "=", "map", "(", "int", ",", "box2", ")", "\n", "\n", "xmin", "=", "min", "(", "x1min", ",", "x2min", ")", "\n", "ymin", "=", "min", "(", "y1min", ",", "y2min", ")", "\n", "xmax", "=", "max", "(", "x1max", ",", "x2max", ")", "\n", "ymax", "=", "max", "(", "y1max", ",", "y2max", ")", "\n", "\n", "unionBox", "=", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "return", "unionBox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.getIntersectionBox": [[179, 190], ["map", "map", "max", "max", "min", "min"], "function", ["None"], ["", "def", "getIntersectionBox", "(", "box1", ",", "box2", ")", ":", "\n", "    ", "x1min", ",", "y1min", ",", "x1max", ",", "y1max", "=", "map", "(", "int", ",", "box1", ")", "\n", "x2min", ",", "y2min", ",", "x2max", ",", "y2max", "=", "map", "(", "int", ",", "box2", ")", "\n", "\n", "xmin", "=", "max", "(", "x1min", ",", "x2min", ")", "\n", "ymin", "=", "max", "(", "y1min", ",", "y2min", ")", "\n", "xmax", "=", "min", "(", "x1max", ",", "x2max", ")", "\n", "ymax", "=", "min", "(", "y1max", ",", "y2max", ")", "\n", "\n", "intersectionBox", "=", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "return", "intersectionBox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeBoxIntersection": [[192, 199], ["eval_instances.getIntersectionBox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.getIntersectionBox"], ["", "def", "computeBoxIntersection", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\"\n    Compute intersection between GT instance and prediction.\n    \"\"\"", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "getIntersectionBox", "(", "gt", "[", "\"box\"", "]", ",", "pred", "[", "\"box\"", "]", ")", "\n", "intersection", "=", "(", "xmax", "-", "xmin", ")", "*", "(", "ymax", "-", "ymin", ")", "\n", "return", "intersection", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeMaskIntersection": [[201, 221], ["eval_instances.getUnionBox", "torch.sum().item", "len", "len", "torch.sum", "torch.mul"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.getUnionBox"], ["", "def", "computeMaskIntersection", "(", "gt", ",", "gtMask", ",", "pred", ",", "predMask", ")", ":", "\n", "    ", "\"\"\"\n    Compute intersection between GT instance and prediction.\n    Increase efficiency by computing elementwise product between masks\n    only inside the tight bounding box of the union of the prediction and\n    target masks.\n    \"\"\"", "\n", "if", "gtMask", "is", "None", "or", "predMask", "is", "None", ":", "\n", "        ", "return", "0", "\n", "\n", "", "assert", "gtMask", ".", "shape", "==", "predMask", ".", "shape", "\n", "assert", "len", "(", "gtMask", ".", "shape", ")", "==", "len", "(", "predMask", ".", "shape", ")", "==", "2", "\n", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "getUnionBox", "(", "gt", "[", "\"box\"", "]", ",", "pred", "[", "\"box\"", "]", ")", "\n", "gtMask_crop", "=", "gtMask", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "\n", "predMask_crop", "=", "predMask", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "\n", "\n", "# elementwise AND", "\n", "intersection", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "gtMask_crop", ",", "predMask_crop", ")", ")", ".", "item", "(", ")", "\n", "return", "intersection", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.matchGtWithPred": [[223, 272], ["eval_instances.prepareGtImage", "eval_instances.preparePredImage", "zip", "zip", "groupedGtInstances[].append", "groupedPredInstances[].append", "eval_instances.computeBoxIntersection", "eval_instances.computeMaskIntersection", "eval_instances.isOverlapping", "gt.copy", "pred.copy", "gt.copy.pop", "pred.copy.pop", "gt[].append", "pred[].append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.prepareGtImage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.preparePredImage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeBoxIntersection", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeMaskIntersection", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.isOverlapping"], ["", "def", "matchGtWithPred", "(", "dataset", ",", "predictions", ",", "idx", ")", ":", "\n", "# Collect instances from gt and pred separately per image", "\n", "# TODO: not parallel! parallelize this process safely", "\n", "    ", "perImgGtInstances", ",", "gtMasks", "=", "prepareGtImage", "(", "dataset", ",", "idx", ")", "\n", "perImgPredInstances", ",", "predMasks", "=", "preparePredImage", "(", "dataset", ",", "predictions", ",", "idx", ")", "\n", "\n", "# If no masks are provided, the segmentation score will be 0", "\n", "for", "gt", ",", "gtMask", "in", "zip", "(", "perImgGtInstances", ",", "gtMasks", ")", ":", "\n", "        ", "for", "pred", ",", "predMask", "in", "zip", "(", "perImgPredInstances", ",", "predMasks", ")", ":", "\n", "            ", "if", "not", "isOverlapping", "(", "gt", "[", "\"box\"", "]", ",", "pred", "[", "\"box\"", "]", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "boxIntersection", "=", "computeBoxIntersection", "(", "gt", ",", "pred", ")", "\n", "maskIntersection", "=", "computeMaskIntersection", "(", "gt", ",", "gtMask", ",", "pred", ",", "predMask", ")", "\n", "\n", "if", "boxIntersection", ">", "0", ":", "\n", "# Copy metadata only, and register the matched pairs", "\n", "# this step is redundant but informative", "\n", "# intersection score would be enough", "\n", "                ", "gtCopy", "=", "gt", ".", "copy", "(", ")", "\n", "predCopy", "=", "pred", ".", "copy", "(", ")", "\n", "\n", "# remove linking field (an empty list) to avoid confusion", "\n", "gtCopy", ".", "pop", "(", "\"matchedPred\"", ")", "\n", "predCopy", ".", "pop", "(", "\"matchedGt\"", ")", "\n", "\n", "gtCopy", "[", "\"boxIntersection\"", "]", "=", "boxIntersection", "\n", "gtCopy", "[", "\"maskIntersection\"", "]", "=", "maskIntersection", "\n", "predCopy", "[", "\"boxIntersection\"", "]", "=", "boxIntersection", "\n", "predCopy", "[", "\"maskIntersection\"", "]", "=", "maskIntersection", "\n", "\n", "gt", "[", "\"matchedPred\"", "]", ".", "append", "(", "predCopy", ")", "\n", "pred", "[", "\"matchedGt\"", "]", ".", "append", "(", "gtCopy", ")", "\n", "\n", "# Group by classes", "\n", "", "", "", "groupedGtInstances", "=", "{", "labelName", ":", "[", "]", "for", "labelName", "in", "dataset", ".", "CLASSES", "}", "\n", "groupedPredInstances", "=", "{", "labelName", ":", "[", "]", "for", "labelName", "in", "dataset", ".", "CLASSES", "}", "\n", "\n", "for", "gt", "in", "perImgGtInstances", ":", "\n", "        ", "gtLabelName", "=", "dataset", ".", "id_to_name", "[", "gt", "[", "\"labelID\"", "]", "]", "\n", "groupedGtInstances", "[", "gtLabelName", "]", ".", "append", "(", "gt", ")", "\n", "\n", "", "for", "pred", "in", "perImgPredInstances", ":", "\n", "        ", "predLabelName", "=", "dataset", ".", "id_to_name", "[", "pred", "[", "\"labelID\"", "]", "]", "\n", "groupedPredInstances", "[", "predLabelName", "]", ".", "append", "(", "pred", ")", "\n", "\n", "", "match", "=", "{", "\"groundTruth\"", ":", "groupedGtInstances", ",", "\"prediction\"", ":", "groupedPredInstances", "}", "\n", "\n", "return", "match", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.prepareGtImage": [[274, 325], ["dataset.get_img_info", "perImageGts.resize.convert", "perImageGts.resize.bbox.long", "bbs.tolist.tolist", "perImageGts.resize.get_field().tolist", "range", "len", "len", "perImageGts.resize.resize", "perImageGts.resize.fields", "perImageGts.resize.get_field().get_mask_tensor", "zip", "len", "perImageInstances.append", "perImageGts.resize.get_field", "len", "pixelCounts.append", "perImageGts.resize.get_field", "instanceMask[].sum().item", "instanceMask[].sum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.get_mask_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "prepareGtImage", "(", "dataset", ",", "idx", ")", ":", "\n", "    ", "_", ",", "perImageGts", ",", "_", "=", "dataset", "[", "idx", "]", "\n", "perImageInstances", "=", "[", "]", "\n", "maskTensor", "=", "[", "None", "]", "*", "len", "(", "perImageGts", ")", "\n", "if", "len", "(", "perImageGts", ")", "==", "0", ":", "\n", "        ", "return", "perImageInstances", ",", "maskTensor", "\n", "\n", "# Resize to original image size", "\n", "", "imgInfo", "=", "dataset", ".", "get_img_info", "(", "idx", ")", "\n", "origSize", "=", "imgInfo", "[", "\"width\"", "]", ",", "imgInfo", "[", "\"height\"", "]", "\n", "if", "perImageGts", ".", "size", "!=", "origSize", ":", "\n", "        ", "perImageGts", "=", "perImageGts", ".", "resize", "(", "size", "=", "origSize", ")", "\n", "\n", "# Compute box areas", "\n", "", "perImageGts", "=", "perImageGts", ".", "convert", "(", "\"xyxy\"", ")", "\n", "bbs", "=", "perImageGts", ".", "bbox", ".", "long", "(", ")", "\n", "xmins", ",", "ymins", ",", "xmaxs", ",", "ymaxs", "=", "bbs", "[", ":", ",", "0", "]", ",", "bbs", "[", ":", ",", "1", "]", ",", "bbs", "[", ":", ",", "2", "]", ",", "bbs", "[", ":", ",", "3", "]", "\n", "boxAreas", "=", "(", "(", "xmaxs", "-", "xmins", ")", "*", "(", "ymaxs", "-", "ymins", ")", ")", ".", "tolist", "(", ")", "\n", "bbs", "=", "bbs", ".", "tolist", "(", ")", "\n", "\n", "# object label for each prediction", "\n", "labels", "=", "perImageGts", ".", "get_field", "(", "\"labels\"", ")", ".", "tolist", "(", ")", "\n", "if", "\"masks\"", "in", "perImageGts", ".", "fields", "(", ")", ":", "\n", "# Get the binary mask for each instance in a contiguous array", "\n", "        ", "maskTensor", "=", "perImageGts", ".", "get_field", "(", "\"masks\"", ")", ".", "get_mask_tensor", "(", ")", "\n", "\n", "# In case of single mask then add a new axis", "\n", "if", "len", "(", "maskTensor", ".", "shape", ")", "==", "2", ":", "\n", "            ", "maskTensor", "=", "maskTensor", "[", "None", "]", "\n", "\n", "# unique_values = set(torch.unique(maskTensor).tolist())", "\n", "# assert len(unique_values) == 2, \"Not binary mask: %s\" % unique_values", "\n", "# pixelCounts = maskTensor.clamp_(0, 1).sum(dim=[1, 2])", "\n", "", "pixelCounts", "=", "[", "]", "\n", "for", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ",", "instanceMask", "in", "zip", "(", "bbs", ",", "maskTensor", ")", ":", "\n", "            ", "pixelCounts", ".", "append", "(", "instanceMask", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "", "for", "instID", "in", "range", "(", "len", "(", "perImageGts", ")", ")", ":", "\n", "        ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "bbs", "[", "instID", "]", "\n", "pixelCount", "=", "pixelCounts", "[", "instID", "]", "if", "maskTensor", "[", "0", "]", "is", "not", "None", "else", "0", "\n", "gtInstance", "=", "{", "\n", "\"labelID\"", ":", "labels", "[", "instID", "]", ",", "\n", "\"instID\"", ":", "instID", ",", "\n", "\"boxArea\"", ":", "boxAreas", "[", "instID", "]", ",", "\n", "\"pixelCount\"", ":", "pixelCount", ",", "\n", "\"box\"", ":", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ",", "\n", "\"matchedPred\"", ":", "[", "]", ",", "\n", "}", "\n", "perImageInstances", ".", "append", "(", "gtInstance", ")", "\n", "\n", "", "return", "perImageInstances", ",", "maskTensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.preparePredImage": [[327, 416], ["dataset.get_img_info", "perImagePredictions.resize.convert", "perImagePredictions.resize.bbox.long", "bbs.tolist.tolist", "perImagePredictions.resize.get_field().tolist", "perImagePredictions.resize.get_field().tolist", "range", "len", "len", "perImagePredictions.resize.resize", "perImagePredictions.resize.fields", "perImagePredictions.resize.get_field", "maskTensor.float.float", "zip", "len", "perImageInstances.append", "perImagePredictions.resize.get_field", "perImagePredictions.resize.get_field", "len", "len", "maskrcnn_benchmark.modeling.roi_heads.mask_head.inference.Masker().forward_single_image", "pixelCounts.append", "len", "len", "instanceMask[].sum().item", "maskrcnn_benchmark.modeling.roi_heads.mask_head.inference.Masker", "instanceMask[].sum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.Masker.forward_single_image"], ["", "def", "preparePredImage", "(", "dataset", ",", "predictions", ",", "idx", ")", ":", "\n", "    ", "perImagePredictions", "=", "predictions", "[", "idx", "]", "\n", "\n", "# A list will hold statistics and meta-data about the image", "\n", "perImageInstances", "=", "[", "]", "\n", "\n", "# maskTensor represents binary masks of all predicted instance segmentations", "\n", "# if present", "\n", "maskTensor", "=", "[", "None", "]", "*", "len", "(", "perImagePredictions", ")", "\n", "\n", "# No predictions for this image", "\n", "if", "len", "(", "perImagePredictions", ")", "==", "0", ":", "\n", "        ", "return", "perImageInstances", ",", "maskTensor", "\n", "\n", "# Resize to original image size", "\n", "", "imgInfo", "=", "dataset", ".", "get_img_info", "(", "idx", ")", "\n", "origSize", "=", "imgInfo", "[", "\"width\"", "]", ",", "imgInfo", "[", "\"height\"", "]", "\n", "if", "perImagePredictions", ".", "size", "!=", "origSize", ":", "\n", "        ", "perImagePredictions", "=", "perImagePredictions", ".", "resize", "(", "size", "=", "origSize", ")", "\n", "\n", "# Bounding boxes and areas", "\n", "", "perImagePredictions", "=", "perImagePredictions", ".", "convert", "(", "\"xyxy\"", ")", "\n", "bbs", "=", "perImagePredictions", ".", "bbox", ".", "long", "(", ")", "\n", "xmins", ",", "ymins", ",", "xmaxs", ",", "ymaxs", "=", "bbs", "[", ":", ",", "0", "]", ",", "bbs", "[", ":", ",", "1", "]", ",", "bbs", "[", ":", ",", "2", "]", ",", "bbs", "[", ":", ",", "3", "]", "\n", "boxAreas", "=", "(", "(", "xmaxs", "-", "xmins", ")", "*", "(", "ymaxs", "-", "ymins", ")", ")", ".", "tolist", "(", ")", "\n", "bbs", "=", "bbs", ".", "tolist", "(", ")", "\n", "\n", "# object label and \"Objectness\" score for each prediction", "\n", "labels", "=", "perImagePredictions", ".", "get_field", "(", "\"labels\"", ")", ".", "tolist", "(", ")", "\n", "scores", "=", "perImagePredictions", ".", "get_field", "(", "\"scores\"", ")", ".", "tolist", "(", ")", "\n", "\n", "# Get the mask for each instance in a contiguous array", "\n", "if", "\"mask\"", "in", "perImagePredictions", ".", "fields", "(", ")", ":", "\n", "        ", "maskTensor", "=", "perImagePredictions", ".", "get_field", "(", "\"mask\"", ")", "\n", "\n", "# sanity checks", "\n", "assert", "len", "(", "perImagePredictions", ")", "==", "len", "(", "maskTensor", ")", ",", "(", "\n", "\"number of masks (%d) do not match the number of boxes (%d)\"", "\n", "%", "(", "len", "(", "perImagePredictions", ")", ",", "len", "(", "maskTensor", ")", ")", "\n", ")", "\n", "\n", "maskTensor", "=", "maskTensor", ".", "float", "(", ")", "\n", "# We assume that the maskTensors are coming right out of the maskRCNN", "\n", "# having values between [0, 1] inclusive", "\n", "#", "\n", "# assert maskTensor.min() >= 0.0 and maskTensor.max() <= 1.0, [", "\n", "#     maskTensor.max(),", "\n", "#     maskTensor.min(),", "\n", "# ]", "\n", "\n", "# Project masks to the boxes", "\n", "# TODO: Issue #527 - bad Masker interface", "\n", "#", "\n", "# The predicted masks are in the shape of i.e. [N, 1, 28, 28] where N is", "\n", "# the number of instances predicted, and they represent the interior", "\n", "# of the bounding boxes.", "\n", "#", "\n", "# Masker projects these predictions on an empty canvas with the full", "\n", "# size of the input image using the predicted bounding boxes", "\n", "maskTensor", "=", "Masker", "(", "threshold", "=", "0.5", ")", ".", "forward_single_image", "(", "\n", "maskTensor", ",", "perImagePredictions", "\n", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "\n", "pixelCounts", "=", "[", "]", "\n", "for", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ",", "instanceMask", "in", "zip", "(", "bbs", ",", "maskTensor", ")", ":", "\n", "            ", "pixelCounts", ".", "append", "(", "instanceMask", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "", "for", "predID", "in", "range", "(", "len", "(", "perImagePredictions", ")", ")", ":", "\n", "        ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "bbs", "[", "predID", "]", "\n", "# if we have instance segmentation prediction then we update pixelCount", "\n", "pixelCount", "=", "0", "\n", "if", "maskTensor", "[", "0", "]", "is", "not", "None", ":", "\n", "            ", "pixelCount", "=", "pixelCounts", "[", "predID", "]", "\n", "if", "pixelCount", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "", "predInstance", "=", "{", "\n", "\"imgName\"", ":", "idx", ",", "\n", "\"predID\"", ":", "predID", ",", "\n", "\"labelID\"", ":", "labels", "[", "predID", "]", ",", "\n", "\"boxArea\"", ":", "boxAreas", "[", "predID", "]", ",", "\n", "\"pixelCount\"", ":", "pixelCount", ",", "\n", "\"confidence\"", ":", "scores", "[", "predID", "]", ",", "\n", "\"box\"", ":", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ",", "\n", "\"matchedGt\"", ":", "[", "]", ",", "\n", "}", "\n", "perImageInstances", ".", "append", "(", "predInstance", ")", "\n", "\n", "", "return", "perImageInstances", ",", "maskTensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.evaluateBoxMatches": [[418, 617], ["numpy.zeros", "enumerate", "enumerate", "len", "len", "len", "enumerate", "numpy.empty", "numpy.empty", "numpy.ones", "numpy.zeros", "enumerate", "numpy.append", "numpy.append", "numpy.argsort", "numpy.cumsum", "numpy.unique", "len", "numpy.zeros", "numpy.zeros", "numpy.append", "enumerate", "numpy.copy", "numpy.append", "numpy.append", "numpy.convolve", "numpy.dot", "len", "numpy.ones", "len", "len", "float", "len", "float", "float", "float", "float", "float", "numpy.append", "numpy.append", "max", "min", "numpy.append", "numpy.append", "numpy.append", "float"], "function", ["None"], ["", "def", "evaluateBoxMatches", "(", "matches", ",", "args", ")", ":", "\n", "# In the end, we need two vectors for each class and for each overlap", "\n", "# The first vector (y_true) is binary and is 1, where the ground truth says true,", "\n", "# and is 0 otherwise.", "\n", "# The second vector (y_score) is float [0...1] and represents the confidence of", "\n", "# the prediction.", "\n", "#", "\n", "# We represent the following cases as:", "\n", "#                                       | y_true |   y_score", "\n", "#   gt instance with matched prediction |    1   | confidence", "\n", "#   gt instance w/o  matched prediction |    1   |     0.0", "\n", "#          false positive prediction    |    0   | confidence", "\n", "#", "\n", "# The current implementation makes only sense for an overlap threshold >= 0.5,", "\n", "# since only then, a single prediction can either be ignored or matched, but", "\n", "# never both. Further, it can never match to two gt instances.", "\n", "# For matching, we vary the overlap and do the following steps:", "\n", "#   1.) remove all predictions that satisfy the overlap criterion with an ignore region (either void or *group)", "\n", "#   2.) remove matches that do not satisfy the overlap", "\n", "#   3.) mark non-matched predictions as false positive", "\n", "\n", "# AP", "\n", "    ", "overlaps", "=", "args", ".", "overlaps", "\n", "# region size", "\n", "minRegionSizes", "=", "args", ".", "minRegionSizes", "\n", "\n", "# only keep the first, if distances are not available", "\n", "# if not args.distanceAvailable:", "\n", "#     minRegionSizes = [ minRegionSizes[0] ]", "\n", "#     distThs        = [ distThs       [0] ]", "\n", "#     distConfs      = [ distConfs     [0] ]", "\n", "\n", "# Here we hold the results", "\n", "# First dimension is class, second overlap", "\n", "ap", "=", "np", ".", "zeros", "(", "(", "len", "(", "minRegionSizes", ")", ",", "len", "(", "args", ".", "instLabels", ")", ",", "len", "(", "overlaps", ")", ")", ",", "np", ".", "float", ")", "\n", "\n", "for", "dI", ",", "minRegionSize", "in", "enumerate", "(", "minRegionSizes", ")", ":", "\n", "        ", "for", "(", "oI", ",", "overlapTh", ")", "in", "enumerate", "(", "overlaps", ")", ":", "\n", "            ", "for", "(", "lI", ",", "labelName", ")", "in", "enumerate", "(", "args", ".", "instLabels", ")", ":", "\n", "                ", "y_true", "=", "np", ".", "empty", "(", "0", ")", "\n", "y_score", "=", "np", ".", "empty", "(", "0", ")", "\n", "# count hard false negatives", "\n", "hardFns", "=", "0", "\n", "# found at least one gt and predicted instance?", "\n", "haveGt", "=", "False", "\n", "havePred", "=", "False", "\n", "\n", "for", "img", "in", "matches", ":", "\n", "                    ", "predInstances", "=", "img", "[", "\"prediction\"", "]", "[", "labelName", "]", "\n", "gtInstances", "=", "img", "[", "\"groundTruth\"", "]", "[", "labelName", "]", "\n", "# filter groups in ground truth", "\n", "gtInstances", "=", "[", "\n", "gt", "for", "gt", "in", "gtInstances", "if", "gt", "[", "\"boxArea\"", "]", ">=", "minRegionSize", "\n", "]", "\n", "\n", "if", "gtInstances", ":", "\n", "                        ", "haveGt", "=", "True", "\n", "", "if", "predInstances", ":", "\n", "                        ", "havePred", "=", "True", "\n", "\n", "", "curTrue", "=", "np", ".", "ones", "(", "len", "(", "gtInstances", ")", ")", "\n", "curScore", "=", "np", ".", "ones", "(", "len", "(", "gtInstances", ")", ")", "*", "(", "-", "float", "(", "\"inf\"", ")", ")", "\n", "curMatch", "=", "np", ".", "zeros", "(", "len", "(", "gtInstances", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# collect matches", "\n", "for", "(", "gtI", ",", "gt", ")", "in", "enumerate", "(", "gtInstances", ")", ":", "\n", "                        ", "foundMatch", "=", "False", "\n", "for", "pred", "in", "gt", "[", "\"matchedPred\"", "]", ":", "\n", "                            ", "overlap", "=", "float", "(", "pred", "[", "\"boxIntersection\"", "]", ")", "/", "(", "\n", "gt", "[", "\"boxArea\"", "]", "\n", "+", "pred", "[", "\"boxArea\"", "]", "\n", "-", "pred", "[", "\"boxIntersection\"", "]", "\n", ")", "\n", "if", "overlap", ">", "overlapTh", ":", "\n", "# the score", "\n", "                                ", "confidence", "=", "pred", "[", "\"confidence\"", "]", "\n", "\n", "# if we already hat a prediction for this groundtruth", "\n", "# the prediction with the lower score is automatically a false positive", "\n", "if", "curMatch", "[", "gtI", "]", ":", "\n", "                                    ", "maxScore", "=", "max", "(", "curScore", "[", "gtI", "]", ",", "confidence", ")", "\n", "minScore", "=", "min", "(", "curScore", "[", "gtI", "]", ",", "confidence", ")", "\n", "curScore", "[", "gtI", "]", "=", "maxScore", "\n", "# append false positive", "\n", "curTrue", "=", "np", ".", "append", "(", "curTrue", ",", "0", ")", "\n", "curScore", "=", "np", ".", "append", "(", "curScore", ",", "minScore", ")", "\n", "curMatch", "=", "np", ".", "append", "(", "curMatch", ",", "True", ")", "\n", "# otherwise set score", "\n", "", "else", ":", "\n", "                                    ", "foundMatch", "=", "True", "\n", "curMatch", "[", "gtI", "]", "=", "True", "\n", "curScore", "[", "gtI", "]", "=", "confidence", "\n", "\n", "", "", "", "if", "not", "foundMatch", ":", "\n", "                            ", "hardFns", "+=", "1", "\n", "\n", "# remove non-matched ground truth instances", "\n", "", "", "curTrue", "=", "curTrue", "[", "curMatch", "==", "True", "]", "\n", "curScore", "=", "curScore", "[", "curMatch", "==", "True", "]", "\n", "\n", "# collect non-matched predictions as false positive", "\n", "for", "pred", "in", "predInstances", ":", "\n", "                        ", "foundGt", "=", "False", "\n", "for", "gt", "in", "pred", "[", "\"matchedGt\"", "]", ":", "\n", "                            ", "overlap", "=", "float", "(", "gt", "[", "\"boxIntersection\"", "]", ")", "/", "(", "\n", "gt", "[", "\"boxArea\"", "]", "+", "pred", "[", "\"boxArea\"", "]", "-", "gt", "[", "\"boxIntersection\"", "]", "\n", ")", "\n", "if", "overlap", ">", "overlapTh", ":", "\n", "                                ", "foundGt", "=", "True", "\n", "break", "\n", "", "", "if", "not", "foundGt", ":", "\n", "# collect number of void and *group pixels", "\n", "                            ", "nbIgnorePixels", "=", "0", "\n", "for", "gt", "in", "pred", "[", "\"matchedGt\"", "]", ":", "\n", "# small ground truth instances", "\n", "                                ", "if", "gt", "[", "\"boxArea\"", "]", "<", "minRegionSize", ":", "\n", "                                    ", "nbIgnorePixels", "+=", "gt", "[", "\"boxIntersection\"", "]", "\n", "", "", "if", "pred", "[", "\"boxArea\"", "]", ">", "0", ":", "\n", "                                ", "proportionIgnore", "=", "(", "\n", "float", "(", "nbIgnorePixels", ")", "/", "pred", "[", "\"boxArea\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "                                ", "proportionIgnore", "=", "0", "\n", "# if not ignored", "\n", "# append false positive", "\n", "", "if", "proportionIgnore", "<=", "overlapTh", ":", "\n", "                                ", "curTrue", "=", "np", ".", "append", "(", "curTrue", ",", "0", ")", "\n", "confidence", "=", "pred", "[", "\"confidence\"", "]", "\n", "curScore", "=", "np", ".", "append", "(", "curScore", ",", "confidence", ")", "\n", "\n", "# append to overall results", "\n", "", "", "", "y_true", "=", "np", ".", "append", "(", "y_true", ",", "curTrue", ")", "\n", "y_score", "=", "np", ".", "append", "(", "y_score", ",", "curScore", ")", "\n", "\n", "# compute the average precision", "\n", "", "if", "haveGt", "and", "havePred", ":", "\n", "# compute precision recall curve first", "\n", "\n", "# sorting and cumsum", "\n", "                    ", "scoreArgSort", "=", "np", ".", "argsort", "(", "y_score", ")", "\n", "yScoreSorted", "=", "y_score", "[", "scoreArgSort", "]", "\n", "yTrueSorted", "=", "y_true", "[", "scoreArgSort", "]", "\n", "yTrueSortedCumsum", "=", "np", ".", "cumsum", "(", "yTrueSorted", ")", "\n", "\n", "# unique thresholds", "\n", "(", "thresholds", ",", "uniqueIndices", ")", "=", "np", ".", "unique", "(", "\n", "yScoreSorted", ",", "return_index", "=", "True", "\n", ")", "\n", "\n", "# since we need to add an artificial point to the precision-recall curve", "\n", "# increase its length by 1", "\n", "nbPrecRecall", "=", "len", "(", "uniqueIndices", ")", "+", "1", "\n", "\n", "# prepare precision recall", "\n", "nbExamples", "=", "len", "(", "yScoreSorted", ")", "\n", "nbTrueExamples", "=", "yTrueSortedCumsum", "[", "-", "1", "]", "\n", "precision", "=", "np", ".", "zeros", "(", "nbPrecRecall", ")", "\n", "recall", "=", "np", ".", "zeros", "(", "nbPrecRecall", ")", "\n", "\n", "# deal with the first point", "\n", "# only thing we need to do, is to append a zero to the cumsum at the end.", "\n", "# an index of -1 uses that zero then", "\n", "yTrueSortedCumsum", "=", "np", ".", "append", "(", "yTrueSortedCumsum", ",", "0", ")", "\n", "\n", "# deal with remaining", "\n", "for", "idxRes", ",", "idxScores", "in", "enumerate", "(", "uniqueIndices", ")", ":", "\n", "                        ", "cumSum", "=", "yTrueSortedCumsum", "[", "idxScores", "-", "1", "]", "\n", "tp", "=", "nbTrueExamples", "-", "cumSum", "\n", "fp", "=", "nbExamples", "-", "idxScores", "-", "tp", "\n", "fn", "=", "cumSum", "+", "hardFns", "\n", "p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "\n", "r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "\n", "precision", "[", "idxRes", "]", "=", "p", "\n", "recall", "[", "idxRes", "]", "=", "r", "\n", "\n", "# first point in curve is artificial", "\n", "", "precision", "[", "-", "1", "]", "=", "1.0", "\n", "recall", "[", "-", "1", "]", "=", "0.0", "\n", "\n", "# compute average of precision-recall curve", "\n", "# integration is performed via zero order, or equivalently step-wise integration", "\n", "# first compute the widths of each step:", "\n", "# use a convolution with appropriate kernel, manually deal with the boundaries first", "\n", "recallForConv", "=", "np", ".", "copy", "(", "recall", ")", "\n", "recallForConv", "=", "np", ".", "append", "(", "recallForConv", "[", "0", "]", ",", "recallForConv", ")", "\n", "recallForConv", "=", "np", ".", "append", "(", "recallForConv", ",", "0.0", ")", "\n", "\n", "stepWidths", "=", "np", ".", "convolve", "(", "recallForConv", ",", "[", "-", "0.5", ",", "0", ",", "0.5", "]", ",", "\"valid\"", ")", "\n", "\n", "# integrate is now simply a dot product", "\n", "apCurrent", "=", "np", ".", "dot", "(", "precision", ",", "stepWidths", ")", "\n", "\n", "", "elif", "haveGt", ":", "\n", "                    ", "apCurrent", "=", "0.0", "\n", "", "else", ":", "\n", "                    ", "apCurrent", "=", "float", "(", "\"nan\"", ")", "\n", "", "ap", "[", "dI", ",", "lI", ",", "oI", "]", "=", "apCurrent", "\n", "\n", "", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.evaluateMaskMatches": [[619, 821], ["numpy.zeros", "enumerate", "enumerate", "len", "len", "len", "enumerate", "numpy.empty", "numpy.empty", "numpy.ones", "numpy.zeros", "enumerate", "numpy.append", "numpy.append", "numpy.argsort", "numpy.cumsum", "numpy.unique", "len", "numpy.zeros", "numpy.zeros", "numpy.append", "enumerate", "numpy.copy", "numpy.append", "numpy.append", "numpy.convolve", "numpy.dot", "len", "numpy.ones", "len", "len", "float", "len", "float", "float", "float", "float", "float", "numpy.append", "numpy.append", "max", "min", "numpy.append", "numpy.append", "numpy.append", "float"], "function", ["None"], ["", "def", "evaluateMaskMatches", "(", "matches", ",", "args", ")", ":", "\n", "# In the end, we need two vectors for each class and for each overlap", "\n", "# The first vector (y_true) is binary and is 1, where the ground truth says true,", "\n", "# and is 0 otherwise.", "\n", "# The second vector (y_score) is float [0...1] and represents the confidence of", "\n", "# the prediction.", "\n", "#", "\n", "# We represent the following cases as:", "\n", "#                                       | y_true |   y_score", "\n", "#   gt instance with matched prediction |    1   | confidence", "\n", "#   gt instance w/o  matched prediction |    1   |     0.0", "\n", "#          false positive prediction    |    0   | confidence", "\n", "#", "\n", "# The current implementation makes only sense for an overlap threshold >= 0.5,", "\n", "# since only then, a single prediction can either be ignored or matched, but", "\n", "# never both. Further, it can never match to two gt instances.", "\n", "# For matching, we vary the overlap and do the following steps:", "\n", "#   1.) remove all predictions that satisfy the overlap criterion with an ignore region (either void or *group)", "\n", "#   2.) remove matches that do not satisfy the overlap", "\n", "#   3.) mark non-matched predictions as false positive", "\n", "\n", "# AP", "\n", "    ", "overlaps", "=", "args", ".", "overlaps", "\n", "# region size", "\n", "minRegionSizes", "=", "args", ".", "minRegionSizes", "\n", "\n", "# only keep the first, if distances are not available", "\n", "# if not args.distanceAvailable:", "\n", "#     minRegionSizes = [ minRegionSizes[0] ]", "\n", "#     distThs        = [ distThs       [0] ]", "\n", "#     distConfs      = [ distConfs     [0] ]", "\n", "\n", "# Here we hold the results", "\n", "# First dimension is class, second overlap", "\n", "ap", "=", "np", ".", "zeros", "(", "(", "len", "(", "minRegionSizes", ")", ",", "len", "(", "args", ".", "instLabels", ")", ",", "len", "(", "overlaps", ")", ")", ",", "np", ".", "float", ")", "\n", "\n", "for", "dI", ",", "minRegionSize", "in", "enumerate", "(", "minRegionSizes", ")", ":", "\n", "        ", "for", "(", "oI", ",", "overlapTh", ")", "in", "enumerate", "(", "overlaps", ")", ":", "\n", "            ", "for", "(", "lI", ",", "labelName", ")", "in", "enumerate", "(", "args", ".", "instLabels", ")", ":", "\n", "                ", "y_true", "=", "np", ".", "empty", "(", "0", ")", "\n", "y_score", "=", "np", ".", "empty", "(", "0", ")", "\n", "# count hard false negatives", "\n", "hardFns", "=", "0", "\n", "# found at least one gt and predicted instance?", "\n", "haveGt", "=", "False", "\n", "havePred", "=", "False", "\n", "\n", "for", "img", "in", "matches", ":", "\n", "                    ", "predInstances", "=", "img", "[", "\"prediction\"", "]", "[", "labelName", "]", "\n", "gtInstances", "=", "img", "[", "\"groundTruth\"", "]", "[", "labelName", "]", "\n", "# filter groups in ground truth", "\n", "gtInstances", "=", "[", "\n", "gt", "for", "gt", "in", "gtInstances", "if", "gt", "[", "\"pixelCount\"", "]", ">=", "minRegionSize", "\n", "]", "\n", "\n", "if", "gtInstances", ":", "\n", "                        ", "haveGt", "=", "True", "\n", "", "if", "predInstances", ":", "\n", "                        ", "havePred", "=", "True", "\n", "\n", "", "curTrue", "=", "np", ".", "ones", "(", "len", "(", "gtInstances", ")", ")", "\n", "curScore", "=", "np", ".", "ones", "(", "len", "(", "gtInstances", ")", ")", "*", "(", "-", "float", "(", "\"inf\"", ")", ")", "\n", "curMatch", "=", "np", ".", "zeros", "(", "len", "(", "gtInstances", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# collect matches", "\n", "for", "(", "gtI", ",", "gt", ")", "in", "enumerate", "(", "gtInstances", ")", ":", "\n", "                        ", "foundMatch", "=", "False", "\n", "for", "pred", "in", "gt", "[", "\"matchedPred\"", "]", ":", "\n", "                            ", "overlap", "=", "float", "(", "pred", "[", "\"maskIntersection\"", "]", ")", "/", "(", "\n", "gt", "[", "\"pixelCount\"", "]", "\n", "+", "pred", "[", "\"pixelCount\"", "]", "\n", "-", "pred", "[", "\"maskIntersection\"", "]", "\n", ")", "\n", "if", "overlap", ">", "overlapTh", ":", "\n", "# the score", "\n", "                                ", "confidence", "=", "pred", "[", "\"confidence\"", "]", "\n", "\n", "# if we already hat a prediction for this groundtruth", "\n", "# the prediction with the lower score is automatically a false positive", "\n", "if", "curMatch", "[", "gtI", "]", ":", "\n", "                                    ", "maxScore", "=", "max", "(", "curScore", "[", "gtI", "]", ",", "confidence", ")", "\n", "minScore", "=", "min", "(", "curScore", "[", "gtI", "]", ",", "confidence", ")", "\n", "curScore", "[", "gtI", "]", "=", "maxScore", "\n", "# append false positive", "\n", "curTrue", "=", "np", ".", "append", "(", "curTrue", ",", "0", ")", "\n", "curScore", "=", "np", ".", "append", "(", "curScore", ",", "minScore", ")", "\n", "curMatch", "=", "np", ".", "append", "(", "curMatch", ",", "True", ")", "\n", "# otherwise set score", "\n", "", "else", ":", "\n", "                                    ", "foundMatch", "=", "True", "\n", "curMatch", "[", "gtI", "]", "=", "True", "\n", "curScore", "[", "gtI", "]", "=", "confidence", "\n", "\n", "", "", "", "if", "not", "foundMatch", ":", "\n", "                            ", "hardFns", "+=", "1", "\n", "\n", "# remove non-matched ground truth instances", "\n", "", "", "curTrue", "=", "curTrue", "[", "curMatch", "==", "True", "]", "\n", "curScore", "=", "curScore", "[", "curMatch", "==", "True", "]", "\n", "\n", "# collect non-matched predictions as false positive", "\n", "for", "pred", "in", "predInstances", ":", "\n", "                        ", "foundGt", "=", "False", "\n", "for", "gt", "in", "pred", "[", "\"matchedGt\"", "]", ":", "\n", "                            ", "overlap", "=", "float", "(", "gt", "[", "\"maskIntersection\"", "]", ")", "/", "(", "\n", "gt", "[", "\"pixelCount\"", "]", "\n", "+", "pred", "[", "\"pixelCount\"", "]", "\n", "-", "gt", "[", "\"maskIntersection\"", "]", "\n", ")", "\n", "if", "overlap", ">", "overlapTh", ":", "\n", "                                ", "foundGt", "=", "True", "\n", "break", "\n", "", "", "if", "not", "foundGt", ":", "\n", "# collect number of void and *group pixels", "\n", "                            ", "nbIgnorePixels", "=", "0", "\n", "for", "gt", "in", "pred", "[", "\"matchedGt\"", "]", ":", "\n", "# small ground truth instances", "\n", "                                ", "if", "gt", "[", "\"pixelCount\"", "]", "<", "minRegionSize", ":", "\n", "                                    ", "nbIgnorePixels", "+=", "gt", "[", "\"maskIntersection\"", "]", "\n", "\n", "", "", "if", "pred", "[", "\"pixelCount\"", "]", "<=", "0", ":", "\n", "                                ", "proportionIgnore", "=", "0", "\n", "", "else", ":", "\n", "                                ", "proportionIgnore", "=", "(", "\n", "float", "(", "nbIgnorePixels", ")", "/", "pred", "[", "\"pixelCount\"", "]", "\n", ")", "\n", "# if not ignored", "\n", "# append false positive", "\n", "", "if", "proportionIgnore", "<=", "overlapTh", ":", "\n", "                                ", "curTrue", "=", "np", ".", "append", "(", "curTrue", ",", "0", ")", "\n", "confidence", "=", "pred", "[", "\"confidence\"", "]", "\n", "curScore", "=", "np", ".", "append", "(", "curScore", ",", "confidence", ")", "\n", "\n", "# append to overall results", "\n", "", "", "", "y_true", "=", "np", ".", "append", "(", "y_true", ",", "curTrue", ")", "\n", "y_score", "=", "np", ".", "append", "(", "y_score", ",", "curScore", ")", "\n", "\n", "# compute the average precision", "\n", "", "if", "haveGt", "and", "havePred", ":", "\n", "# compute precision recall curve first", "\n", "\n", "# sorting and cumsum", "\n", "                    ", "scoreArgSort", "=", "np", ".", "argsort", "(", "y_score", ")", "\n", "yScoreSorted", "=", "y_score", "[", "scoreArgSort", "]", "\n", "yTrueSorted", "=", "y_true", "[", "scoreArgSort", "]", "\n", "yTrueSortedCumsum", "=", "np", ".", "cumsum", "(", "yTrueSorted", ")", "\n", "\n", "# unique thresholds", "\n", "(", "thresholds", ",", "uniqueIndices", ")", "=", "np", ".", "unique", "(", "\n", "yScoreSorted", ",", "return_index", "=", "True", "\n", ")", "\n", "\n", "# since we need to add an artificial point to the precision-recall curve", "\n", "# increase its length by 1", "\n", "nbPrecRecall", "=", "len", "(", "uniqueIndices", ")", "+", "1", "\n", "\n", "# prepare precision recall", "\n", "nbExamples", "=", "len", "(", "yScoreSorted", ")", "\n", "nbTrueExamples", "=", "yTrueSortedCumsum", "[", "-", "1", "]", "\n", "precision", "=", "np", ".", "zeros", "(", "nbPrecRecall", ")", "\n", "recall", "=", "np", ".", "zeros", "(", "nbPrecRecall", ")", "\n", "\n", "# deal with the first point", "\n", "# only thing we need to do, is to append a zero to the cumsum at the end.", "\n", "# an index of -1 uses that zero then", "\n", "yTrueSortedCumsum", "=", "np", ".", "append", "(", "yTrueSortedCumsum", ",", "0", ")", "\n", "\n", "# deal with remaining", "\n", "for", "idxRes", ",", "idxScores", "in", "enumerate", "(", "uniqueIndices", ")", ":", "\n", "                        ", "cumSum", "=", "yTrueSortedCumsum", "[", "idxScores", "-", "1", "]", "\n", "tp", "=", "nbTrueExamples", "-", "cumSum", "\n", "fp", "=", "nbExamples", "-", "idxScores", "-", "tp", "\n", "fn", "=", "cumSum", "+", "hardFns", "\n", "p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "\n", "r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "\n", "precision", "[", "idxRes", "]", "=", "p", "\n", "recall", "[", "idxRes", "]", "=", "r", "\n", "\n", "# first point in curve is artificial", "\n", "", "precision", "[", "-", "1", "]", "=", "1.0", "\n", "recall", "[", "-", "1", "]", "=", "0.0", "\n", "\n", "# compute average of precision-recall curve", "\n", "# integration is performed via zero order, or equivalently step-wise integration", "\n", "# first compute the widths of each step:", "\n", "# use a convolution with appropriate kernel, manually deal with the boundaries first", "\n", "recallForConv", "=", "np", ".", "copy", "(", "recall", ")", "\n", "recallForConv", "=", "np", ".", "append", "(", "recallForConv", "[", "0", "]", ",", "recallForConv", ")", "\n", "recallForConv", "=", "np", ".", "append", "(", "recallForConv", ",", "0.0", ")", "\n", "\n", "stepWidths", "=", "np", ".", "convolve", "(", "recallForConv", ",", "[", "-", "0.5", ",", "0", ",", "0.5", "]", ",", "\"valid\"", ")", "\n", "\n", "# integrate is now simply a dot product", "\n", "apCurrent", "=", "np", ".", "dot", "(", "precision", ",", "stepWidths", ")", "\n", "\n", "", "elif", "haveGt", ":", "\n", "                    ", "apCurrent", "=", "0.0", "\n", "", "else", ":", "\n", "                    ", "apCurrent", "=", "float", "(", "\"nan\"", ")", "\n", "", "ap", "[", "dI", ",", "lI", ",", "oI", "]", "=", "apCurrent", "\n", "\n", "", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.computeAverages": [[823, 845], ["numpy.argmin", "numpy.where", "numpy.where", "numpy.nanmean", "numpy.nanmean", "numpy.nanmean", "enumerate", "numpy.isclose", "numpy.isclose", "numpy.average", "numpy.average", "numpy.average"], "function", ["None"], ["", "def", "computeAverages", "(", "aps", ",", "args", ")", ":", "\n", "# max distance index", "\n", "# dInf  = np.argmax( args.distanceThs )", "\n", "# d50m  = np.where( np.isclose( args.distanceThs ,  50. ) )", "\n", "# d100m = np.where( np.isclose( args.distanceThs , 100. ) )", "\n", "    ", "dInf", "=", "np", ".", "argmin", "(", "args", ".", "minRegionSizes", ")", "\n", "o50", "=", "np", ".", "where", "(", "np", ".", "isclose", "(", "args", ".", "overlaps", ",", "0.5", ")", ")", "\n", "o75", "=", "np", ".", "where", "(", "np", ".", "isclose", "(", "args", ".", "overlaps", ",", "0.75", ")", ")", "\n", "\n", "avgDict", "=", "{", "}", "\n", "avgDict", "[", "\"allAp\"", "]", "=", "np", ".", "nanmean", "(", "aps", "[", "dInf", ",", ":", ",", ":", "]", ")", "\n", "avgDict", "[", "\"allAp50%\"", "]", "=", "np", ".", "nanmean", "(", "aps", "[", "dInf", ",", ":", ",", "o50", "]", ")", "\n", "avgDict", "[", "\"allAp75%\"", "]", "=", "np", ".", "nanmean", "(", "aps", "[", "dInf", ",", ":", ",", "o75", "]", ")", "\n", "\n", "avgDict", "[", "\"classes\"", "]", "=", "{", "}", "\n", "for", "(", "lI", ",", "labelName", ")", "in", "enumerate", "(", "args", ".", "instLabels", ")", ":", "\n", "        ", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "=", "{", "}", "\n", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "[", "\"ap\"", "]", "=", "np", ".", "average", "(", "aps", "[", "dInf", ",", "lI", ",", ":", "]", ")", "\n", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "[", "\"ap50%\"", "]", "=", "np", ".", "average", "(", "aps", "[", "dInf", ",", "lI", ",", "o50", "]", ")", "\n", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "[", "\"ap75%\"", "]", "=", "np", ".", "average", "(", "aps", "[", "dInf", ",", "lI", ",", "o75", "]", ")", "\n", "\n", "", "return", "avgDict", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.printResults": [[847, 898], ["io.StringIO", "contextlib.redirect_stdout", "print", "print", "enumerate", "print", "print", "io.StringIO.getvalue", "print", "print", "print", "print", "cityscapesscripts.helpers.csHelpers.getColorEntry", "cityscapesscripts.helpers.csHelpers.getColorEntry", "cityscapesscripts.helpers.csHelpers.getColorEntry", "cityscapesscripts.helpers.csHelpers.getColorEntry", "cityscapesscripts.helpers.csHelpers.getColorEntry", "cityscapesscripts.helpers.csHelpers.getColorEntry"], "function", ["None"], ["", "def", "printResults", "(", "avgDict", ",", "args", ")", ":", "\n", "    ", "strbuffer", "=", "io", ".", "StringIO", "(", ")", "\n", "# redirect all the print functions to a string buffer", "\n", "with", "redirect_stdout", "(", "strbuffer", ")", ":", "\n", "\n", "        ", "sep", "=", "\",\"", "if", "args", ".", "csv", "else", "\"\"", "\n", "col1", "=", "\":\"", "if", "not", "args", ".", "csv", "else", "\"\"", "\n", "noCol", "=", "colors", ".", "ENDC", "if", "args", ".", "colorized", "else", "\"\"", "\n", "bold", "=", "colors", ".", "BOLD", "if", "args", ".", "colorized", "else", "\"\"", "\n", "lineLen", "=", "65", "\n", "\n", "print", "(", "\"\"", ")", "\n", "if", "not", "args", ".", "csv", ":", "\n", "            ", "print", "(", "\"#\"", "*", "lineLen", ")", "\n", "", "line", "=", "bold", "\n", "line", "+=", "\"{:<15}\"", ".", "format", "(", "\"what\"", ")", "+", "sep", "+", "col1", "\n", "line", "+=", "\"{:>15}\"", ".", "format", "(", "\"AP\"", ")", "+", "sep", "\n", "line", "+=", "\"{:>15}\"", ".", "format", "(", "\"AP_50%\"", ")", "+", "sep", "\n", "line", "+=", "\"{:>15}\"", ".", "format", "(", "\"AP_75%\"", ")", "+", "sep", "\n", "line", "+=", "noCol", "\n", "print", "(", "line", ")", "\n", "if", "not", "args", ".", "csv", ":", "\n", "            ", "print", "(", "\"#\"", "*", "lineLen", ")", "\n", "\n", "", "for", "(", "lI", ",", "labelName", ")", "in", "enumerate", "(", "args", ".", "instLabels", ")", ":", "\n", "            ", "apAvg", "=", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "[", "\"ap\"", "]", "\n", "ap50o", "=", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "[", "\"ap50%\"", "]", "\n", "ap75o", "=", "avgDict", "[", "\"classes\"", "]", "[", "labelName", "]", "[", "\"ap75%\"", "]", "\n", "\n", "line", "=", "\"{:<15}\"", ".", "format", "(", "labelName", ")", "+", "sep", "+", "col1", "\n", "line", "+=", "getColorEntry", "(", "apAvg", ",", "args", ")", "+", "sep", "+", "\"{:>15.3f}\"", ".", "format", "(", "apAvg", ")", "+", "sep", "\n", "line", "+=", "getColorEntry", "(", "ap50o", ",", "args", ")", "+", "sep", "+", "\"{:>15.3f}\"", ".", "format", "(", "ap50o", ")", "+", "sep", "\n", "line", "+=", "getColorEntry", "(", "ap75o", ",", "args", ")", "+", "sep", "+", "\"{:>15.3f}\"", ".", "format", "(", "ap75o", ")", "+", "sep", "\n", "line", "+=", "noCol", "\n", "print", "(", "line", ")", "\n", "\n", "", "allApAvg", "=", "avgDict", "[", "\"allAp\"", "]", "\n", "allAp50o", "=", "avgDict", "[", "\"allAp50%\"", "]", "\n", "allAp75o", "=", "avgDict", "[", "\"allAp75%\"", "]", "\n", "\n", "if", "not", "args", ".", "csv", ":", "\n", "            ", "print", "(", "\"-\"", "*", "lineLen", ")", "\n", "", "line", "=", "\"{:<15}\"", ".", "format", "(", "\"average\"", ")", "+", "sep", "+", "col1", "\n", "line", "+=", "getColorEntry", "(", "allApAvg", ",", "args", ")", "+", "sep", "+", "\"{:>15.3f}\"", ".", "format", "(", "allApAvg", ")", "+", "sep", "\n", "line", "+=", "getColorEntry", "(", "allAp50o", ",", "args", ")", "+", "sep", "+", "\"{:>15.3f}\"", ".", "format", "(", "allAp50o", ")", "+", "sep", "\n", "line", "+=", "getColorEntry", "(", "allAp75o", ",", "args", ")", "+", "sep", "+", "\"{:>15.3f}\"", ".", "format", "(", "allAp75o", ")", "+", "sep", "\n", "line", "+=", "noCol", "\n", "print", "(", "line", ")", "\n", "print", "(", "\"\"", ")", "\n", "\n", "return", "strbuffer", ".", "getvalue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.eval_instances.prepareJSONDataForResults": [[900, 909], ["args.overlaps.tolist", "args.minRegionSizes.tolist", "aps.tolist"], "function", ["None"], ["", "", "def", "prepareJSONDataForResults", "(", "avgDict", ",", "aps", ",", "args", ")", ":", "\n", "    ", "JSONData", "=", "{", "}", "\n", "JSONData", "[", "\"averages\"", "]", "=", "avgDict", "\n", "JSONData", "[", "\"overlaps\"", "]", "=", "args", ".", "overlaps", ".", "tolist", "(", ")", "\n", "JSONData", "[", "\"minRegionSizes\"", "]", "=", "args", ".", "minRegionSizes", ".", "tolist", "(", ")", "\n", "JSONData", "[", "\"instLabels\"", "]", "=", "args", ".", "instLabels", "\n", "JSONData", "[", "\"resultApMatrix\"", "]", "=", "aps", ".", "tolist", "(", ")", "\n", "\n", "return", "JSONData", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.__init__.abs_cityscapes_evaluation": [[4, 21], ["cityscapes_eval.do_cityscapes_evaluation"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.cityscapes_eval.do_cityscapes_evaluation"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.align_and_update_state_dicts": [[10, 57], ["sorted", "sorted", "torch.as_tensor().view", "torch.as_tensor().view.max", "logging.getLogger", "enumerate", "list", "list", "len", "len", "max", "max", "idxs.tolist", "logging.getLogger.info", "model_state_dict.keys", "loaded_state_dict.keys", "i.endswith", "len", "torch.as_tensor", "log_str_template.format", "len", "len", "tuple"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["def", "align_and_update_state_dicts", "(", "model_state_dict", ",", "loaded_state_dict", ")", ":", "\n", "    ", "\"\"\"\n    Strategy: suppose that the models that we will create will have prefixes appended\n    to each of its keys, for example due to an extra level of nesting that the original\n    pre-trained weights from ImageNet won't contain. For example, model.state_dict()\n    might return backbone[0].body.res2.conv1.weight, while the pre-trained model contains\n    res2.conv1.weight. We thus want to match both parameters together.\n    For that, we look for each model weight, look among all loaded keys if there is one\n    that is a suffix of the current weight name, and use it if that's the case.\n    If multiple matches exist, take the one with longest size\n    of the corresponding name. For example, for the same model as before, the pretrained\n    weight file can contain both res2.conv1.weight, as well as conv1.weight. In this case,\n    we want to match backbone[0].body.conv1.weight to conv1.weight, and\n    backbone[0].body.res2.conv1.weight to res2.conv1.weight.\n    \"\"\"", "\n", "current_keys", "=", "sorted", "(", "list", "(", "model_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "loaded_keys", "=", "sorted", "(", "list", "(", "loaded_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "# get a matrix of string matches, where each (i, j) entry correspond to the size of the", "\n", "# loaded_key string, if it matches", "\n", "match_matrix", "=", "[", "\n", "len", "(", "j", ")", "if", "i", ".", "endswith", "(", "j", ")", "else", "0", "for", "i", "in", "current_keys", "for", "j", "in", "loaded_keys", "\n", "]", "\n", "match_matrix", "=", "torch", ".", "as_tensor", "(", "match_matrix", ")", ".", "view", "(", "\n", "len", "(", "current_keys", ")", ",", "len", "(", "loaded_keys", ")", "\n", ")", "\n", "max_match_size", ",", "idxs", "=", "match_matrix", ".", "max", "(", "1", ")", "\n", "# remove indices that correspond to no-match", "\n", "idxs", "[", "max_match_size", "==", "0", "]", "=", "-", "1", "\n", "\n", "# used for logging", "\n", "max_size", "=", "max", "(", "[", "len", "(", "key", ")", "for", "key", "in", "current_keys", "]", ")", "if", "current_keys", "else", "1", "\n", "max_size_loaded", "=", "max", "(", "[", "len", "(", "key", ")", "for", "key", "in", "loaded_keys", "]", ")", "if", "loaded_keys", "else", "1", "\n", "log_str_template", "=", "\"{: <{}} loaded from {: <{}} of shape {}\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "for", "idx_new", ",", "idx_old", "in", "enumerate", "(", "idxs", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "if", "idx_old", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "key", "=", "current_keys", "[", "idx_new", "]", "\n", "key_old", "=", "loaded_keys", "[", "idx_old", "]", "\n", "model_state_dict", "[", "key", "]", "=", "loaded_state_dict", "[", "key_old", "]", "\n", "logger", ".", "info", "(", "\n", "log_str_template", ".", "format", "(", "\n", "key", ",", "\n", "max_size", ",", "\n", "key_old", ",", "\n", "max_size_loaded", ",", "\n", "tuple", "(", "loaded_state_dict", "[", "key_old", "]", ".", "shape", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.strip_prefix_if_present": [[61, 69], ["sorted", "collections.OrderedDict", "state_dict.items", "state_dict.keys", "all", "key.startswith", "key.replace"], "function", ["None"], ["", "", "def", "strip_prefix_if_present", "(", "state_dict", ",", "prefix", ")", ":", "\n", "    ", "keys", "=", "sorted", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "if", "not", "all", "(", "key", ".", "startswith", "(", "prefix", ")", "for", "key", "in", "keys", ")", ":", "\n", "        ", "return", "state_dict", "\n", "", "stripped_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "stripped_state_dict", "[", "key", ".", "replace", "(", "prefix", ",", "\"\"", ")", "]", "=", "value", "\n", "", "return", "stripped_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.load_state_dict": [[71, 81], ["model.state_dict", "model_serialization.strip_prefix_if_present", "model_serialization.align_and_update_state_dicts", "model.load_state_dict"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.state_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.strip_prefix_if_present", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.align_and_update_state_dicts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.load_state_dict"], ["", "def", "load_state_dict", "(", "model", ",", "loaded_state_dict", ")", ":", "\n", "    ", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "# if the state_dict comes from a model that was wrapped in a", "\n", "# DataParallel or DistributedDataParallel during serialization,", "\n", "# remove the \"module\" prefix before performing the matching", "\n", "loaded_state_dict", "=", "strip_prefix_if_present", "(", "loaded_state_dict", ",", "prefix", "=", "\"module.\"", ")", "\n", "align_and_update_state_dicts", "(", "model_state_dict", ",", "loaded_state_dict", ")", "\n", "\n", "# use strict loading", "\n", "model", ".", "load_state_dict", "(", "model_state_dict", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.mkdir": [[6, 12], ["os.makedirs"], "function", ["None"], ["from", ".", "comm", "import", "is_main_process", "\n", "\n", "\n", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.save_labels": [[17, 34], ["comm.is_main_process", "logging.getLogger", "hasattr", "os.path.join", "logging.getLogger.info", "ids_to_labels.update", "logging.getLogger.warning", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["", "", "", "def", "save_labels", "(", "dataset_list", ",", "output_dir", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "ids_to_labels", "=", "{", "}", "\n", "for", "dataset", "in", "dataset_list", ":", "\n", "            ", "if", "hasattr", "(", "dataset", ",", "'categories'", ")", ":", "\n", "                ", "ids_to_labels", ".", "update", "(", "dataset", ".", "categories", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Dataset [{}] has no categories attribute, labels.json file won't be created\"", ".", "format", "(", "\n", "dataset", ".", "__class__", ".", "__name__", ")", ")", "\n", "\n", "", "", "if", "ids_to_labels", ":", "\n", "            ", "labels_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'labels.json'", ")", "\n", "logger", ".", "info", "(", "\"Saving labels mapping into {}\"", ".", "format", "(", "labels_file", ")", ")", "\n", "with", "open", "(", "labels_file", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "ids_to_labels", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.miscellaneous.save_config": [[36, 40], ["comm.is_main_process", "open", "f.write", "cfg.dump"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["", "", "", "", "def", "save_config", "(", "cfg", ",", "path", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "cfg", ".", "dump", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size": [[13, 19], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank": [[21, 27], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process": [[29, 31], ["comm.get_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize": [[33, 46], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["", "def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather": [[48, 89], ["comm.get_world_size", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.IntTensor().to", "torch.IntTensor().to", "torch.all_gather", "max", "torch.all_gather", "zip", "torch.IntTensor().to", "torch.IntTensor().to", "int", "tensor_list.append", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.cat", "torch.cat", "data_list.append", "torch.ByteTensor", "torch.ByteTensor", "torch.IntTensor", "torch.IntTensor", "range", "size.item", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.cat.cpu().numpy().tobytes", "pickle.loads", "torch.IntTensor", "torch.IntTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.cat.numel", "torch.ByteTensor", "torch.ByteTensor", "torch.cat.cpu().numpy", "torch.cat.cpu"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "all_gather", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "# serialized to a Tensor", "\n", "", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "# obtain Tensor size of each rank", "\n", "local_size", "=", "torch", ".", "LongTensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "size_list", "=", "[", "torch", ".", "LongTensor", "(", "[", "0", "]", ")", ".", "to", "(", "\"cuda\"", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "tensor_list", "=", "[", "]", "\n", "for", "_", "in", "size_list", ":", "\n", "        ", "tensor_list", ".", "append", "(", "torch", ".", "ByteTensor", "(", "size", "=", "(", "max_size", ",", ")", ")", ".", "to", "(", "\"cuda\"", ")", ")", "\n", "", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "ByteTensor", "(", "size", "=", "(", "max_size", "-", "local_size", ",", ")", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.reduce_dict": [[91, 118], ["comm.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.reduce", "input_dict.keys", "names.append", "torch.stack.append", "torch.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that process with rank\n    0 has the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "reduce", "(", "values", ",", "dst", "=", "0", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "average", ":", "\n", "# only main process gets accumulated, so only divide by", "\n", "# world_size in this case", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.__init__": [[9, 11], ["timer.Timer.reset"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.average_time": [[12, 15], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "average_time", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total_time", "/", "self", ".", "calls", "if", "self", ".", "calls", ">", "0", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.tic": [[16, 20], ["time.time"], "methods", ["None"], ["", "def", "tic", "(", "self", ")", ":", "\n", "# using time.time instead of time.clock because time time.clock", "\n", "# does not normalize for multithreading", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.toc": [[21, 27], ["timer.Timer.add", "time.time"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], ["", "def", "toc", "(", "self", ",", "average", "=", "True", ")", ":", "\n", "        ", "self", ".", "add", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", "\n", "if", "average", ":", "\n", "            ", "return", "self", ".", "average_time", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "diff", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add": [[28, 32], ["None"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "time_diff", ")", ":", "\n", "        ", "self", ".", "diff", "=", "time_diff", "\n", "self", ".", "total_time", "+=", "self", ".", "diff", "\n", "self", ".", "calls", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.reset": [[33, 38], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "total_time", "=", "0.0", "\n", "self", ".", "calls", "=", "0", "\n", "self", ".", "start_time", "=", "0.0", "\n", "self", ".", "diff", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.avg_time_str": [[39, 42], ["str", "datetime.timedelta"], "methods", ["None"], ["", "def", "avg_time_str", "(", "self", ")", ":", "\n", "        ", "time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "self", ".", "average_time", ")", ")", "\n", "return", "time_str", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.get_time_str": [[44, 47], ["str", "datetime.timedelta"], "function", ["None"], ["", "", "def", "get_time_str", "(", "time_diff", ")", ":", "\n", "    ", "time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "time_diff", ")", ")", "\n", "return", "time_str", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger": [[7, 26], ["logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "os.path.join"], "function", ["None"], ["def", "setup_logger", "(", "name", ",", "save_dir", ",", "distributed_rank", ",", "filename", "=", "\"log.txt\"", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "# don't log results for the non-master process", "\n", "if", "distributed_rank", ">", "0", ":", "\n", "        ", "return", "logger", "\n", "", "ch", "=", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "\"%(asctime)s %(name)s %(levelname)s: %(message)s\"", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "if", "save_dir", ":", "\n", "        ", "fh", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "filename", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry.Registry.__init__": [[31, 33], ["dict.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Registry", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry.Registry.register": [[34, 46], ["registry._register_generic", "registry._register_generic"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry._register_generic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry._register_generic"], ["", "def", "register", "(", "self", ",", "module_name", ",", "module", "=", "None", ")", ":", "\n", "# used as function call", "\n", "        ", "if", "module", "is", "not", "None", ":", "\n", "            ", "_register_generic", "(", "self", ",", "module_name", ",", "module", ")", "\n", "return", "\n", "\n", "# used as decorator", "\n", "", "def", "register_fn", "(", "fn", ")", ":", "\n", "            ", "_register_generic", "(", "self", ",", "module_name", ",", "fn", ")", "\n", "return", "fn", "\n", "\n", "", "return", "register_fn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry._register_generic": [[4, 7], ["None"], "function", ["None"], ["def", "_register_generic", "(", "module_dict", ",", "module_name", ",", "module", ")", ":", "\n", "    ", "assert", "module_name", "not", "in", "module_dict", "\n", "module_dict", "[", "module_name", "]", "=", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours": [[8, 25], ["cv2.__version__.startswith", "cv2.findContours", "cv2.__version__.startswith", "cv2.findContours", "AssertionError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours"], ["def", "findContours", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Wraps cv2.findContours to maintain compatiblity between versions\n    3 and 4\n\n    Returns:\n        contours, hierarchy\n    \"\"\"", "\n", "if", "cv2", ".", "__version__", ".", "startswith", "(", "'4'", ")", ":", "\n", "        ", "contours", ",", "hierarchy", "=", "cv2", ".", "findContours", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "cv2", ".", "__version__", ".", "startswith", "(", "'3'", ")", ":", "\n", "        ", "_", ",", "contours", ",", "hierarchy", "=", "cv2", ".", "findContours", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "AssertionError", "(", "\n", "'cv2 must be either version 3 or 4 to call this method'", ")", "\n", "\n", "", "return", "contours", ",", "hierarchy", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_zoo.cache_url": [[20, 65], ["urlparse", "os.path.join", "fcos_core.utils.comm.synchronize", "os.path.expanduser", "os.getenv", "os.path.exists", "os.makedirs", "os.path.basename", "urlparse.path.replace", "fcos_core.utils.comm.is_main_process", "sys.stderr.write", "HASH_REGEX.search", "_download_url_to_file", "os.getenv", "os.path.join", "os.path.exists", "hash_prefix.group.group", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["def", "cache_url", "(", "url", ",", "model_dir", "=", "None", ",", "progress", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Loads the Torch serialized object at the given URL.\n    If the object is already present in `model_dir`, it's deserialized and\n    returned. The filename part of the URL should follow the naming convention\n    ``filename-<sha256>.ext`` where ``<sha256>`` is the first eight or more\n    digits of the SHA256 hash of the contents of the file. The hash is used to\n    ensure unique names and to verify the contents of the file.\n    The default value of `model_dir` is ``$TORCH_HOME/models`` where\n    ``$TORCH_HOME`` defaults to ``~/.torch``. The default directory can be\n    overridden with the ``$TORCH_MODEL_ZOO`` environment variable.\n    Args:\n        url (string): URL of the object to download\n        model_dir (string, optional): directory in which to save the object\n        progress (bool, optional): whether or not to display a progress bar to stderr\n    Example:\n        >>> cached_file = maskrcnn_benchmark.utils.model_zoo.cache_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n    \"\"\"", "\n", "if", "model_dir", "is", "None", ":", "\n", "        ", "torch_home", "=", "os", ".", "path", ".", "expanduser", "(", "os", ".", "getenv", "(", "\"TORCH_HOME\"", ",", "\"~/.torch\"", ")", ")", "\n", "model_dir", "=", "os", ".", "getenv", "(", "\"TORCH_MODEL_ZOO\"", ",", "os", ".", "path", ".", "join", "(", "torch_home", ",", "\"models\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dir", ")", "\n", "", "parts", "=", "urlparse", "(", "url", ")", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "parts", ".", "path", ")", "\n", "if", "filename", "==", "\"model_final.pkl\"", ":", "\n", "# workaround as pre-trained Caffe2 models from Detectron have all the same filename", "\n", "# so make the full path the filename by replacing / with _", "\n", "        ", "filename", "=", "parts", ".", "path", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "\n", "", "cached_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cached_file", ")", "and", "is_main_process", "(", ")", ":", "\n", "        ", "sys", ".", "stderr", ".", "write", "(", "'Downloading: \"{}\" to {}\\n'", ".", "format", "(", "url", ",", "cached_file", ")", ")", "\n", "hash_prefix", "=", "HASH_REGEX", ".", "search", "(", "filename", ")", "\n", "if", "hash_prefix", "is", "not", "None", ":", "\n", "            ", "hash_prefix", "=", "hash_prefix", ".", "group", "(", "1", ")", "\n", "# workaround: Caffe2 models don't have a hash, but follow the R-50 convention,", "\n", "# which matches the hash PyTorch uses. So we skip the hash matching", "\n", "# if the hash_prefix is less than 6 characters", "\n", "if", "len", "(", "hash_prefix", ")", "<", "6", ":", "\n", "                ", "hash_prefix", "=", "None", "\n", "", "", "_download_url_to_file", "(", "url", ",", "cached_file", ",", "hash_prefix", ",", "progress", "=", "progress", ")", "\n", "", "synchronize", "(", ")", "\n", "return", "cached_file", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.__init__": [[13, 18], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "self", ".", "series", "=", "[", "]", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.update": [[19, 24], ["metric_logger.SmoothedValue.deque.append", "metric_logger.SmoothedValue.series.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "self", ".", "series", ".", "append", "(", "value", ")", "\n", "self", ".", "count", "+=", "1", "\n", "self", ".", "total", "+=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median": [[25, 29], ["torch.tensor", "torch.tensor.median().item", "list", "torch.tensor.median"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median"], ["", "@", "property", "\n", "def", "median", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "median", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.avg": [[30, 34], ["torch.tensor", "torch.tensor.mean().item", "list", "torch.tensor.mean"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.global_avg": [[35, 38], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.MetricLogger.__init__": [[41, 44], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "        ", "self", ".", "meters", "=", "defaultdict", "(", "SmoothedValue", ")", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.MetricLogger.update": [[45, 51], ["kwargs.items", "isinstance", "isinstance", "metric_logger.MetricLogger.meters[].update", "v.item.item.item"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "v", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.MetricLogger.__getattr__": [[52, 59], ["AttributeError", "type"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "in", "self", ".", "meters", ":", "\n", "            ", "return", "self", ".", "meters", "[", "attr", "]", "\n", "", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "attr", "]", "\n", "", "raise", "AttributeError", "(", "\"'{}' object has no attribute '{}'\"", ".", "format", "(", "\n", "type", "(", "self", ")", ".", "__name__", ",", "attr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.MetricLogger.__str__": [[60, 67], ["metric_logger.MetricLogger.meters.items", "metric_logger.MetricLogger.delimiter.join", "loss_str.append"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "loss_str", ".", "append", "(", "\n", "\"{}: {:.4f} ({:.4f})\"", ".", "format", "(", "name", ",", "meter", ".", "median", ",", "meter", ".", "global_avg", ")", "\n", ")", "\n", "", "return", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_basic_resnet_weights": [[12, 63], ["k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace"], "function", ["None"], ["def", "_rename_basic_resnet_weights", "(", "layer_keys", ")", ":", "\n", "    ", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_\"", ",", "\".\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".w\"", ",", "\".weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".bn\"", ",", "\"_bn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".b\"", ",", "\".bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_bn.s\"", ",", "\"_bn.scale\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".biasranch\"", ",", "\".branch\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"bbox.pred\"", ",", "\"bbox_pred\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"cls.score\"", ",", "\"cls_score\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res.conv1_\"", ",", "\"conv1_\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# RPN / Faster RCNN", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".biasbox\"", ",", "\".bbox\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv.rpn\"", ",", "\"rpn.conv\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.bbox.pred\"", ",", "\"rpn.bbox_pred\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.cls.logits\"", ",", "\"rpn.cls_logits\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Affine-Channel -> BatchNorm enaming", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_bn.scale\"", ",", "\"_bn.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Make torchvision-compatible", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv1_bn.\"", ",", "\"bn1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res2.\"", ",", "\"layer1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res3.\"", ",", "\"layer2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res4.\"", ",", "\"layer3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res5.\"", ",", "\"layer4.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2a.\"", ",", "\".conv1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2a_bn.\"", ",", "\".bn1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2b.\"", ",", "\".conv2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2b_bn.\"", ",", "\".bn2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2c.\"", ",", "\".conv3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2c_bn.\"", ",", "\".bn3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch1.\"", ",", "\".downsample.0.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch1_bn.\"", ",", "\".downsample.1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# GroupNorm", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv1.gn.s\"", ",", "\"bn1.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv1.gn.bias\"", ",", "\"bn1.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv2.gn.s\"", ",", "\"bn2.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv2.gn.bias\"", ",", "\"bn2.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv3.gn.s\"", ",", "\"bn3.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv3.gn.bias\"", ",", "\"bn3.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"downsample.0.gn.s\"", ",", "\"downsample.1.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"downsample.0.gn.bias\"", ",", "\"downsample.1.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "return", "layer_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_fpn_weights": [[64, 82], ["enumerate", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace"], "function", ["None"], ["", "def", "_rename_fpn_weights", "(", "layer_keys", ",", "stage_names", ")", ":", "\n", "    ", "for", "mapped_idx", ",", "stage_name", "in", "enumerate", "(", "stage_names", ",", "1", ")", ":", "\n", "        ", "suffix", "=", "\"\"", "\n", "if", "mapped_idx", "<", "4", ":", "\n", "            ", "suffix", "=", "\".lateral\"", "\n", "", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"fpn.inner.layer{}.sum{}\"", ".", "format", "(", "stage_name", ",", "suffix", ")", ",", "\"fpn_inner{}\"", ".", "format", "(", "mapped_idx", ")", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"fpn.layer{}.sum\"", ".", "format", "(", "stage_name", ")", ",", "\"fpn_layer{}\"", ".", "format", "(", "mapped_idx", ")", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "\n", "", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.conv.fpn2\"", ",", "\"rpn.conv\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.bbox_pred.fpn2\"", ",", "\"rpn.bbox_pred\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"rpn.cls_logits.fpn2\"", ",", "\"rpn.cls_logits\"", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "\n", "return", "layer_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_weights_for_resnet": [[84, 133], ["sorted", "sorted", "c2_model_loading._rename_basic_resnet_weights", "c2_model_loading._rename_fpn_weights", "logging.getLogger", "logging.getLogger.info", "max", "collections.OrderedDict", "weights.keys", "weights.keys", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "torch.from_numpy", "logging.getLogger.info", "zip", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_basic_resnet_weights", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_fpn_weights"], ["", "def", "_rename_weights_for_resnet", "(", "weights", ",", "stage_names", ")", ":", "\n", "    ", "original_keys", "=", "sorted", "(", "weights", ".", "keys", "(", ")", ")", "\n", "layer_keys", "=", "sorted", "(", "weights", ".", "keys", "(", ")", ")", "\n", "\n", "# for X-101, rename output to fc1000 to avoid conflicts afterwards", "\n", "layer_keys", "=", "[", "k", "if", "k", "!=", "\"pred_b\"", "else", "\"fc1000_b\"", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", "if", "k", "!=", "\"pred_w\"", "else", "\"fc1000_w\"", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# performs basic renaming: _ -> . , etc", "\n", "layer_keys", "=", "_rename_basic_resnet_weights", "(", "layer_keys", ")", "\n", "\n", "# FPN", "\n", "layer_keys", "=", "_rename_fpn_weights", "(", "layer_keys", ",", "stage_names", ")", "\n", "\n", "# Mask R-CNN", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"mask.fcn.logits\"", ",", "\"mask_fcn_logits\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".[mask].fcn\"", ",", "\"mask_fcn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv5.mask\"", ",", "\"conv5_mask\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Keypoint R-CNN", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"kps.score.lowres\"", ",", "\"kps_score_lowres\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"kps.score\"", ",", "\"kps_score\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv.fcn\"", ",", "\"conv_fcn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Rename for our RPN structure", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.\"", ",", "\"rpn.head.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "key_map", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "original_keys", ",", "layer_keys", ")", "}", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Remapping C2 weights\"", ")", "\n", "max_c2_key_size", "=", "max", "(", "[", "len", "(", "k", ")", "for", "k", "in", "original_keys", "if", "\"_momentum\"", "not", "in", "k", "]", ")", "\n", "\n", "new_weights", "=", "OrderedDict", "(", ")", "\n", "for", "k", "in", "original_keys", ":", "\n", "        ", "v", "=", "weights", "[", "k", "]", "\n", "if", "\"_momentum\"", "in", "k", ":", "\n", "            ", "continue", "\n", "", "if", "'weight_order'", "in", "k", ":", "\n", "            ", "continue", "\n", "# if 'fc1000' in k:", "\n", "#     continue", "\n", "", "w", "=", "torch", ".", "from_numpy", "(", "v", ")", "\n", "# if \"bn\" in k:", "\n", "#     w = w.view(1, -1, 1, 1)", "\n", "logger", ".", "info", "(", "\"C2 name: {: <{}} mapped name: {}\"", ".", "format", "(", "k", ",", "max_c2_key_size", ",", "key_map", "[", "k", "]", ")", ")", "\n", "new_weights", "[", "key_map", "[", "k", "]", "]", "=", "w", "\n", "\n", "", "return", "new_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._load_c2_pickled_weights": [[135, 146], ["open", "pickle.load", "pickle.load"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "_load_c2_pickled_weights", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "if", "torch", ".", "_six", ".", "PY3", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "if", "\"blobs\"", "in", "data", ":", "\n", "        ", "weights", "=", "data", "[", "\"blobs\"", "]", "\n", "", "else", ":", "\n", "        ", "weights", "=", "data", "\n", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_conv_weights_for_deformable_conv_layers": [[148, 173], ["logging.getLogger", "logging.getLogger.info", "sorted", "enumerate", "state_dict.keys", "re.match", "old_key.replace", "logging.getLogger.info", "old_key.find"], "function", ["None"], ["", "def", "_rename_conv_weights_for_deformable_conv_layers", "(", "state_dict", ",", "cfg", ")", ":", "\n", "    ", "import", "re", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Remapping conv weights for deformable conv weights\"", ")", "\n", "layer_keys", "=", "sorted", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "for", "ix", ",", "stage_with_dcn", "in", "enumerate", "(", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STAGE_WITH_DCN", ",", "1", ")", ":", "\n", "        ", "if", "not", "stage_with_dcn", ":", "\n", "            ", "continue", "\n", "", "for", "old_key", "in", "layer_keys", ":", "\n", "            ", "pattern", "=", "\".*layer{}.*conv2.*\"", ".", "format", "(", "ix", ")", "\n", "r", "=", "re", ".", "match", "(", "pattern", ",", "old_key", ")", "\n", "if", "r", "is", "None", ":", "\n", "                ", "continue", "\n", "", "for", "param", "in", "[", "\"weight\"", ",", "\"bias\"", "]", ":", "\n", "                ", "if", "old_key", ".", "find", "(", "param", ")", "is", "-", "1", ":", "\n", "                    ", "continue", "\n", "", "new_key", "=", "old_key", ".", "replace", "(", "\n", "\"conv2.{}\"", ".", "format", "(", "param", ")", ",", "\"conv2.conv.{}\"", ".", "format", "(", "param", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"pattern: {}, old_key: {}, new_key: {}\"", ".", "format", "(", "\n", "pattern", ",", "old_key", ",", "new_key", "\n", ")", ")", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", "[", "old_key", "]", "\n", "del", "state_dict", "[", "old_key", "]", "\n", "", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading.load_resnet_c2_format": [[184, 205], ["C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "C2_FORMAT_LOADER.register", "c2_model_loading._load_c2_pickled_weights", "conv_body.replace().replace().replace", "arch.replace.replace", "c2_model_loading._rename_weights_for_resnet", "c2_model_loading._rename_conv_weights_for_deformable_conv_layers", "dict", "conv_body.replace().replace", "conv_body.replace"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._load_c2_pickled_weights", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_weights_for_resnet", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading._rename_conv_weights_for_deformable_conv_layers"], ["@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-C4\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-C5\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-C4\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-C5\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-FPN\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-FPN-RETINANET\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-FPN\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-FPN-RETINANET\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-152-FPN\"", ")", "\n", "def", "load_resnet_c2_format", "(", "cfg", ",", "f", ")", ":", "\n", "    ", "state_dict", "=", "_load_c2_pickled_weights", "(", "f", ")", "\n", "conv_body", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "\n", "arch", "=", "conv_body", ".", "replace", "(", "\"-C4\"", ",", "\"\"", ")", ".", "replace", "(", "\"-C5\"", ",", "\"\"", ")", ".", "replace", "(", "\"-FPN\"", ",", "\"\"", ")", "\n", "arch", "=", "arch", ".", "replace", "(", "\"-RETINANET\"", ",", "\"\"", ")", "\n", "stages", "=", "_C2_STAGE_NAMES", "[", "arch", "]", "\n", "state_dict", "=", "_rename_weights_for_resnet", "(", "state_dict", ",", "stages", ")", "\n", "# ***********************************", "\n", "# for deformable convolutional layer", "\n", "state_dict", "=", "_rename_conv_weights_for_deformable_conv_layers", "(", "state_dict", ",", "cfg", ")", "\n", "# ***********************************", "\n", "return", "dict", "(", "model", "=", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading.load_c2_format": [[207, 209], ["None"], "function", ["None"], ["", "def", "load_c2_format", "(", "cfg", ",", "f", ")", ":", "\n", "    ", "return", "C2_FORMAT_LOADER", "[", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "]", "(", "cfg", ",", "f", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.get_pil_version": [[7, 9], ["None"], "function", ["None"], ["def", "get_pil_version", "(", ")", ":", "\n", "    ", "return", "\"\\n        Pillow ({})\"", ".", "format", "(", "PIL", ".", "__version__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.collect_env_info": [[11, 15], ["torch.utils.collect_env.get_pretty_env_info", "collect_env.get_pil_version"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.get_pil_version"], ["", "def", "collect_env_info", "(", ")", ":", "\n", "    ", "env_str", "=", "get_pretty_env_info", "(", ")", "\n", "env_str", "+=", "get_pil_version", "(", ")", "\n", "return", "env_str", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.__init__": [[14, 31], ["logging.getLogger"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "save_dir", "=", "\"\"", ",", "\n", "save_to_disk", "=", "None", ",", "\n", "logger", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "save_dir", "=", "save_dir", "\n", "self", ".", "save_to_disk", "=", "save_to_disk", "\n", "if", "logger", "is", "None", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.save": [[32, 51], ["checkpoint.Checkpointer.model.state_dict", "data.update", "os.path.join", "checkpoint.Checkpointer.logger.info", "torch.save", "checkpoint.Checkpointer.tag_last_checkpoint", "checkpoint.Checkpointer.optimizer.state_dict", "checkpoint.Checkpointer.scheduler.state_dict"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.state_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.tag_last_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.state_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.state_dict"], ["", "def", "save", "(", "self", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "save_dir", ":", "\n", "            ", "return", "\n", "\n", "", "if", "not", "self", ".", "save_to_disk", ":", "\n", "            ", "return", "\n", "\n", "", "data", "=", "{", "}", "\n", "data", "[", "\"model\"", "]", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "optimizer", "is", "not", "None", ":", "\n", "            ", "data", "[", "\"optimizer\"", "]", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "", "if", "self", ".", "scheduler", "is", "not", "None", ":", "\n", "            ", "data", "[", "\"scheduler\"", "]", "=", "self", ".", "scheduler", ".", "state_dict", "(", ")", "\n", "", "data", ".", "update", "(", "kwargs", ")", "\n", "\n", "save_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "\"{}.pth\"", ".", "format", "(", "name", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Saving checkpoint to {}\"", ".", "format", "(", "save_file", ")", ")", "\n", "torch", ".", "save", "(", "data", ",", "save_file", ")", "\n", "self", ".", "tag_last_checkpoint", "(", "save_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.load": [[52, 72], ["checkpoint.Checkpointer.Checkpointer.has_checkpoint", "checkpoint.Checkpointer.Checkpointer.logger.info", "checkpoint.Checkpointer.Checkpointer._load_file", "checkpoint.Checkpointer.Checkpointer._load_model", "checkpoint.Checkpointer.Checkpointer.get_checkpoint_file", "checkpoint.Checkpointer.Checkpointer.logger.info", "checkpoint.Checkpointer.Checkpointer.logger.info", "checkpoint.Checkpointer.Checkpointer.optimizer.load_state_dict", "checkpoint.Checkpointer.Checkpointer.logger.info", "checkpoint.Checkpointer.Checkpointer.scheduler.load_state_dict", "checkpoint.Checkpointer.Checkpointer.pop", "checkpoint.Checkpointer.Checkpointer.pop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.has_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.get_checkpoint_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.load_state_dict"], ["", "def", "load", "(", "self", ",", "f", "=", "None", ",", "use_latest", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "has_checkpoint", "(", ")", "and", "use_latest", ":", "\n", "# override argument with existing checkpoint", "\n", "            ", "f", "=", "self", ".", "get_checkpoint_file", "(", ")", "\n", "", "if", "not", "f", ":", "\n", "# no checkpoint could be found", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"No checkpoint found. Initializing model from scratch\"", ")", "\n", "return", "{", "}", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Loading checkpoint from {}\"", ".", "format", "(", "f", ")", ")", "\n", "checkpoint", "=", "self", ".", "_load_file", "(", "f", ")", "\n", "self", ".", "_load_model", "(", "checkpoint", ")", "\n", "if", "\"optimizer\"", "in", "checkpoint", "and", "self", ".", "optimizer", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading optimizer from {}\"", ".", "format", "(", "f", ")", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", ".", "pop", "(", "\"optimizer\"", ")", ")", "\n", "", "if", "\"scheduler\"", "in", "checkpoint", "and", "self", ".", "scheduler", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading scheduler from {}\"", ".", "format", "(", "f", ")", ")", "\n", "self", ".", "scheduler", ".", "load_state_dict", "(", "checkpoint", ".", "pop", "(", "\"scheduler\"", ")", ")", "\n", "\n", "# return any further checkpoint data", "\n", "", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.has_checkpoint": [[73, 76], ["os.path.join", "os.path.exists"], "methods", ["None"], ["", "def", "has_checkpoint", "(", "self", ")", ":", "\n", "        ", "save_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "\"last_checkpoint\"", ")", "\n", "return", "os", ".", "path", ".", "exists", "(", "save_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.get_checkpoint_file": [[77, 88], ["os.path.join", "open", "f.read", "last_saved.strip.strip.strip"], "methods", ["None"], ["", "def", "get_checkpoint_file", "(", "self", ")", ":", "\n", "        ", "save_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "\"last_checkpoint\"", ")", "\n", "try", ":", "\n", "            ", "with", "open", "(", "save_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "last_saved", "=", "f", ".", "read", "(", ")", "\n", "last_saved", "=", "last_saved", ".", "strip", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# if file doesn't exist, maybe because it has just been", "\n", "# deleted by a separate process", "\n", "            ", "last_saved", "=", "\"\"", "\n", "", "return", "last_saved", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.tag_last_checkpoint": [[89, 93], ["os.path.join", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["", "def", "tag_last_checkpoint", "(", "self", ",", "last_filename", ")", ":", "\n", "        ", "save_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "\"last_checkpoint\"", ")", "\n", "with", "open", "(", "save_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "last_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer._load_file": [[94, 96], ["torch.load", "torch.device"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["", "", "def", "_load_file", "(", "self", ",", "f", ")", ":", "\n", "        ", "return", "torch", ".", "load", "(", "f", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer._load_model": [[97, 99], ["fcos_core.utils.model_serialization.load_state_dict", "checkpoint.pop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.load_state_dict"], ["", "def", "_load_model", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "load_state_dict", "(", "self", ".", "model", ",", "checkpoint", ".", "pop", "(", "\"model\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.DetectronCheckpointer.__init__": [[102, 116], ["checkpoint.Checkpointer.__init__", "cfg.clone"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ",", "\n", "model", ",", "\n", "optimizer", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "save_dir", "=", "\"\"", ",", "\n", "save_to_disk", "=", "None", ",", "\n", "logger", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DetectronCheckpointer", ",", "self", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "scheduler", ",", "save_dir", ",", "save_to_disk", ",", "logger", "\n", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.DetectronCheckpointer._load_file": [[117, 140], ["f.startswith", "f.startswith", "f.endswith", "checkpoint.Checkpointer._load_file", "fcos_core.utils.imports.import_file", "fcos_core.utils.imports.import_file.ModelCatalog.get", "checkpoint.DetectronCheckpointer.logger.info", "fcos_core.utils.model_zoo.cache_url", "checkpoint.DetectronCheckpointer.logger.info", "fcos_core.utils.c2_model_loading.load_c2_format", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_zoo.cache_url", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.c2_model_loading.load_c2_format"], ["", "def", "_load_file", "(", "self", ",", "f", ")", ":", "\n", "# catalog lookup", "\n", "        ", "if", "f", ".", "startswith", "(", "\"catalog://\"", ")", ":", "\n", "            ", "paths_catalog", "=", "import_file", "(", "\n", "\"maskrcnn_benchmark.config.paths_catalog\"", ",", "self", ".", "cfg", ".", "PATHS_CATALOG", ",", "True", "\n", ")", "\n", "catalog_f", "=", "paths_catalog", ".", "ModelCatalog", ".", "get", "(", "f", "[", "len", "(", "\"catalog://\"", ")", ":", "]", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"{} points to {}\"", ".", "format", "(", "f", ",", "catalog_f", ")", ")", "\n", "f", "=", "catalog_f", "\n", "# download url files", "\n", "", "if", "f", ".", "startswith", "(", "\"http\"", ")", ":", "\n", "# if the file is a url path, download it and cache it", "\n", "            ", "cached_f", "=", "cache_url", "(", "f", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"url {} cached in {}\"", ".", "format", "(", "f", ",", "cached_f", ")", ")", "\n", "f", "=", "cached_f", "\n", "# convert Caffe2 checkpoint from pkl", "\n", "", "if", "f", ".", "endswith", "(", "\".pkl\"", ")", ":", "\n", "            ", "return", "load_c2_format", "(", "self", ".", "cfg", ",", "f", ")", "\n", "# load native detectron.pytorch checkpoint", "\n", "", "loaded", "=", "super", "(", "DetectronCheckpointer", ",", "self", ")", ".", "_load_file", "(", "f", ")", "\n", "if", "\"model\"", "not", "in", "loaded", ":", "\n", "            ", "loaded", "=", "dict", "(", "model", "=", "loaded", ")", "\n", "", "return", "loaded", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.setup_environment": [[7, 18], ["os.environ.get", "env.setup_custom_environment"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.setup_custom_environment"], ["def", "setup_environment", "(", ")", ":", "\n", "    ", "\"\"\"Perform environment setup work. The default setup is a no-op, but this\n    function allows the user to specify a Python source file that performs\n    custom setup work that may be necessary to their computing environment.\n    \"\"\"", "\n", "custom_module_path", "=", "os", ".", "environ", ".", "get", "(", "\"TORCH_DETECTRON_ENV_MODULE\"", ")", "\n", "if", "custom_module_path", ":", "\n", "        ", "setup_custom_environment", "(", "custom_module_path", ")", "\n", "", "else", ":", "\n", "# The default setup is a no-op", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.setup_custom_environment": [[20, 34], ["fcos_core.utils.imports.import_file", "fcos_core.utils.imports.import_file.setup_environment", "hasattr", "callable"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.setup_environment"], ["", "", "def", "setup_custom_environment", "(", "custom_module_path", ")", ":", "\n", "    ", "\"\"\"Load custom environment setup from a Python source file and run the setup\n    function.\n    \"\"\"", "\n", "module", "=", "import_file", "(", "\"maskrcnn_benchmark.utils.env.custom_module\"", ",", "custom_module_path", ")", "\n", "assert", "hasattr", "(", "module", ",", "\"setup_environment\"", ")", "and", "callable", "(", "\n", "module", ".", "setup_environment", "\n", ")", ",", "(", "\n", "\"Custom environment module defined in {} does not have the \"", "\n", "\"required callable attribute 'setup_environment'.\"", "\n", ")", ".", "format", "(", "\n", "custom_module_path", "\n", ")", "\n", "module", ".", "setup_environment", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.serialize.PicklableWrapper.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "self", ".", "_obj", "=", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.serialize.PicklableWrapper.__reduce__": [[18, 21], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__reduce__", "(", "self", ")", ":", "\n", "        ", "s", "=", "cloudpickle", ".", "dumps", "(", "self", ".", "_obj", ")", "\n", "return", "cloudpickle", ".", "loads", ",", "(", "s", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.serialize.PicklableWrapper.__call__": [[22, 24], ["serialize.PicklableWrapper._obj"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_obj", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.serialize.PicklableWrapper.__getattr__": [[25, 30], ["getattr", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "# Ensure that the wrapped object can be used seamlessly as the previous object.", "\n", "        ", "if", "attr", "not", "in", "[", "\"_obj\"", "]", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "_obj", ",", "attr", ")", "\n", "", "return", "getattr", "(", "self", ",", "attr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.colormap.colormap": [[95, 109], ["None"], "function", ["None"], ["def", "colormap", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a float32 array of Nx3 colors, in range [0, 255] or [0, 1]\n    \"\"\"", "\n", "assert", "maximum", "in", "[", "255", ",", "1", "]", ",", "maximum", "\n", "c", "=", "_COLORS", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "c", "=", "c", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.colormap.random_color": [[111, 125], ["numpy.random.randint", "len"], "function", ["None"], ["", "def", "random_color", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a vector of 3 numbers\n    \"\"\"", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "_COLORS", ")", ")", "\n", "ret", "=", "_COLORS", "[", "idx", "]", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "ret", "=", "ret", "[", ":", ":", "-", "1", "]", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventWriter.write": [[43, 45], ["None"], "methods", ["None"], ["def", "write", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventWriter.close": [[46, 48], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.JSONWriter.__init__": [[94, 104], ["detectron2.utils.file_io.PathManager.open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "json_file", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            json_file (str): path to the json file. New data will be appended if the file exists.\n            window_size (int): the window size of median smoothing for the scalars whose\n                `smoothing_hint` are True.\n        \"\"\"", "\n", "self", ".", "_file_handle", "=", "PathManager", ".", "open", "(", "json_file", ",", "\"a\"", ")", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_last_write", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.JSONWriter.write": [[105, 126], ["events.get_event_storage", "collections.defaultdict", "get_event_storage.latest_with_smoothing_hint().items", "len", "collections.defaultdict.items", "events.JSONWriter._file_handle.flush", "sorted", "max", "events.JSONWriter._file_handle.write", "os.fsync", "get_event_storage.latest_with_smoothing_hint", "collections.defaultdict.keys", "events.JSONWriter._file_handle.fileno", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.latest_with_smoothing_hint"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "to_save", "=", "defaultdict", "(", "dict", ")", "\n", "\n", "for", "k", ",", "(", "v", ",", "iter", ")", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "# keep scalars that have not been written", "\n", "            ", "if", "iter", "<=", "self", ".", "_last_write", ":", "\n", "                ", "continue", "\n", "", "to_save", "[", "iter", "]", "[", "k", "]", "=", "v", "\n", "", "if", "len", "(", "to_save", ")", ":", "\n", "            ", "all_iters", "=", "sorted", "(", "to_save", ".", "keys", "(", ")", ")", "\n", "self", ".", "_last_write", "=", "max", "(", "all_iters", ")", "\n", "\n", "", "for", "itr", ",", "scalars_per_iter", "in", "to_save", ".", "items", "(", ")", ":", "\n", "            ", "scalars_per_iter", "[", "\"iteration\"", "]", "=", "itr", "\n", "self", ".", "_file_handle", ".", "write", "(", "json", ".", "dumps", "(", "scalars_per_iter", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", ")", "\n", "", "self", ".", "_file_handle", ".", "flush", "(", ")", "\n", "try", ":", "\n", "            ", "os", ".", "fsync", "(", "self", ".", "_file_handle", ".", "fileno", "(", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.JSONWriter.close": [[127, 129], ["events.JSONWriter._file_handle.close"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "_file_handle", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.__init__": [[136, 149], ["SummaryWriter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "log_dir", ":", "str", ",", "window_size", ":", "int", "=", "20", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            log_dir (str): the directory to save the output events\n            window_size (int): the scalars will be median-smoothed by this window size\n\n            kwargs: other arguments passed to `torch.utils.tensorboard.SummaryWriter(...)`\n        \"\"\"", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "from", "torch", ".", "utils", ".", "tensorboard", "import", "SummaryWriter", "\n", "\n", "self", ".", "_writer", "=", "SummaryWriter", "(", "log_dir", ",", "**", "kwargs", ")", "\n", "self", ".", "_last_write", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.write": [[150, 175], ["events.get_event_storage", "get_event_storage.latest_with_smoothing_hint().items", "len", "get_event_storage.clear_images", "len", "get_event_storage.clear_histograms", "get_event_storage.latest_with_smoothing_hint", "events.TensorboardXWriter._writer.add_scalar", "max", "events.TensorboardXWriter._writer.add_image", "events.TensorboardXWriter._writer.add_histogram_raw"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.clear_images", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.clear_histograms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.latest_with_smoothing_hint"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "new_last_write", "=", "self", ".", "_last_write", "\n", "for", "k", ",", "(", "v", ",", "iter", ")", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "iter", ">", "self", ".", "_last_write", ":", "\n", "                ", "self", ".", "_writer", ".", "add_scalar", "(", "k", ",", "v", ",", "iter", ")", "\n", "new_last_write", "=", "max", "(", "new_last_write", ",", "iter", ")", "\n", "", "", "self", ".", "_last_write", "=", "new_last_write", "\n", "\n", "# storage.put_{image,histogram} is only meant to be used by", "\n", "# tensorboard writer. So we access its internal fields directly from here.", "\n", "if", "len", "(", "storage", ".", "_vis_data", ")", ">=", "1", ":", "\n", "            ", "for", "img_name", ",", "img", ",", "step_num", "in", "storage", ".", "_vis_data", ":", "\n", "                ", "self", ".", "_writer", ".", "add_image", "(", "img_name", ",", "img", ",", "step_num", ")", "\n", "# Storage stores all image data and rely on this writer to clear them.", "\n", "# As a result it assumes only one writer will use its image data.", "\n", "# An alternative design is to let storage store limited recent", "\n", "# data (e.g. only the most recent image) that all writers can access.", "\n", "# In that case a writer may not see all image data if its period is long.", "\n", "", "storage", ".", "clear_images", "(", ")", "\n", "\n", "", "if", "len", "(", "storage", ".", "_histograms", ")", ">=", "1", ":", "\n", "            ", "for", "params", "in", "storage", ".", "_histograms", ":", "\n", "                ", "self", ".", "_writer", ".", "add_histogram_raw", "(", "**", "params", ")", "\n", "", "storage", ".", "clear_histograms", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close": [[176, 179], ["hasattr", "events.TensorboardXWriter._writer.close"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"_writer\"", ")", ":", "# doesn't exist when the code fails at import", "\n", "            ", "self", ".", "_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.CommonMetricPrinter.__init__": [[191, 202], ["logging.getLogger"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_iter", ":", "Optional", "[", "int", "]", "=", "None", ",", "window_size", ":", "int", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            max_iter: the maximum number of iterations to train.\n                Used to compute ETA. If not given, ETA will not be printed.\n            window_size (int): the losses will be median-smoothed by this window size\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_last_write", "=", "None", "# (step, time) of last call to write(). Used to compute ETA", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.CommonMetricPrinter._get_eta": [[203, 222], ["storage.put_scalar", "str", "storage.history().median", "datetime.timedelta", "str", "time.perf_counter", "storage.history", "int", "datetime.timedelta", "time.perf_counter", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.history"], ["", "def", "_get_eta", "(", "self", ",", "storage", ")", "->", "Optional", "[", "str", "]", ":", "\n", "        ", "if", "self", ".", "_max_iter", "is", "None", ":", "\n", "            ", "return", "\"\"", "\n", "", "iteration", "=", "storage", ".", "iter", "\n", "try", ":", "\n", "            ", "eta_seconds", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "median", "(", "1000", ")", "*", "(", "self", ".", "_max_iter", "-", "iteration", "-", "1", ")", "\n", "storage", ".", "put_scalar", "(", "\"eta_seconds\"", ",", "eta_seconds", ",", "smoothing_hint", "=", "False", ")", "\n", "return", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "# estimate eta on our own - more noisy", "\n", "            ", "eta_string", "=", "None", "\n", "if", "self", ".", "_last_write", "is", "not", "None", ":", "\n", "                ", "estimate_iter_time", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_last_write", "[", "1", "]", ")", "/", "(", "\n", "iteration", "-", "self", ".", "_last_write", "[", "0", "]", "\n", ")", "\n", "eta_seconds", "=", "estimate_iter_time", "*", "(", "self", ".", "_max_iter", "-", "iteration", "-", "1", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "self", ".", "_last_write", "=", "(", "iteration", ",", "time", ".", "perf_counter", "(", ")", ")", "\n", "return", "eta_string", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.CommonMetricPrinter.write": [[223, 270], ["events.get_event_storage", "events.CommonMetricPrinter._get_eta", "torch.cuda.is_available", "events.CommonMetricPrinter.logger.info", "get_event_storage.history().avg", "get_event_storage.history().global_avg", "get_event_storage.history().latest", "get_event_storage.history", "get_event_storage.history", "torch.cuda.max_memory_allocated", "get_event_storage.history", "v.median", "get_event_storage.histories().items", "get_event_storage.histories"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.CommonMetricPrinter._get_eta", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.avg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.global_avg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.latest", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.histories"], ["", "", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "iteration", "=", "storage", ".", "iter", "\n", "if", "iteration", "==", "self", ".", "_max_iter", ":", "\n", "# This hook only reports training progress (loss, ETA, etc) but not other data,", "\n", "# therefore do not write anything after training succeeds, even if this method", "\n", "# is called.", "\n", "            ", "return", "\n", "\n", "", "try", ":", "\n", "            ", "data_time", "=", "storage", ".", "history", "(", "\"data_time\"", ")", ".", "avg", "(", "20", ")", "\n", "", "except", "KeyError", ":", "\n", "# they may not exist in the first few iterations (due to warmup)", "\n", "# or when SimpleTrainer is not used", "\n", "            ", "data_time", "=", "None", "\n", "", "try", ":", "\n", "            ", "iter_time", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "global_avg", "(", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "iter_time", "=", "None", "\n", "", "try", ":", "\n", "            ", "lr", "=", "\"{:.5g}\"", ".", "format", "(", "storage", ".", "history", "(", "\"lr\"", ")", ".", "latest", "(", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "lr", "=", "\"N/A\"", "\n", "\n", "", "eta_string", "=", "self", ".", "_get_eta", "(", "storage", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "max_mem_mb", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", "\n", "", "else", ":", "\n", "            ", "max_mem_mb", "=", "None", "\n", "\n", "# NOTE: max_mem is parsed by grep in \"dev/parse_results.sh\"", "\n", "", "self", ".", "logger", ".", "info", "(", "\n", "\" {eta}iter: {iter}  {losses}  {time}{data_time}lr: {lr}  {memory}\"", ".", "format", "(", "\n", "eta", "=", "f\"eta: {eta_string}  \"", "if", "eta_string", "else", "\"\"", ",", "\n", "iter", "=", "iteration", ",", "\n", "losses", "=", "\"  \"", ".", "join", "(", "\n", "[", "\n", "\"{}: {:.4g}\"", ".", "format", "(", "k", ",", "v", ".", "median", "(", "self", ".", "_window_size", ")", ")", "\n", "for", "k", ",", "v", "in", "storage", ".", "histories", "(", ")", ".", "items", "(", ")", "\n", "if", "\"loss\"", "in", "k", "\n", "]", "\n", ")", ",", "\n", "time", "=", "\"time: {:.4f}  \"", ".", "format", "(", "iter_time", ")", "if", "iter_time", "is", "not", "None", "else", "\"\"", ",", "\n", "data_time", "=", "\"data_time: {:.4f}  \"", ".", "format", "(", "data_time", ")", "if", "data_time", "is", "not", "None", "else", "\"\"", ",", "\n", "lr", "=", "lr", ",", "\n", "memory", "=", "\"max_mem: {:.0f}M\"", ".", "format", "(", "max_mem_mb", ")", "if", "max_mem_mb", "is", "not", "None", "else", "\"\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.__init__": [[281, 293], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "start_iter", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter (int): the iteration number to start with\n        \"\"\"", "\n", "self", ".", "_history", "=", "defaultdict", "(", "HistoryBuffer", ")", "\n", "self", ".", "_smoothing_hints", "=", "{", "}", "\n", "self", ".", "_latest_scalars", "=", "{", "}", "\n", "self", ".", "_iter", "=", "start_iter", "\n", "self", ".", "_current_prefix", "=", "\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "self", ".", "_histograms", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_image": [[294, 308], ["events.EventStorage._vis_data.append"], "methods", ["None"], ["", "def", "put_image", "(", "self", ",", "img_name", ",", "img_tensor", ")", ":", "\n", "        ", "\"\"\"\n        Add an `img_tensor` associated with `img_name`, to be shown on\n        tensorboard.\n\n        Args:\n            img_name (str): The name of the image to put into tensorboard.\n            img_tensor (torch.Tensor or numpy.array): An `uint8` or `float`\n                Tensor of shape `[channel, height, width]` where `channel` is\n                3. The image format should be RGB. The elements in img_tensor\n                can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                The `img_tensor` will be visualized in tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", ".", "append", "(", "(", "img_name", ",", "img_tensor", ",", "self", ".", "_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar": [[309, 335], ["float", "history.update", "events.EventStorage._smoothing_hints.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "put_scalar", "(", "self", ",", "name", ",", "value", ",", "smoothing_hint", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Add a scalar `value` to the `HistoryBuffer` associated with `name`.\n\n        Args:\n            smoothing_hint (bool): a 'hint' on whether this scalar is noisy and should be\n                smoothed when logged. The hint will be accessible through\n                :meth:`EventStorage.smoothing_hints`.  A writer may ignore the hint\n                and apply custom smoothing rule.\n\n                It defaults to True because most scalars we save need to be smoothed to\n                provide any useful signal.\n        \"\"\"", "\n", "name", "=", "self", ".", "_current_prefix", "+", "name", "\n", "history", "=", "self", ".", "_history", "[", "name", "]", "\n", "value", "=", "float", "(", "value", ")", "\n", "history", ".", "update", "(", "value", ",", "self", ".", "_iter", ")", "\n", "self", ".", "_latest_scalars", "[", "name", "]", "=", "(", "value", ",", "self", ".", "_iter", ")", "\n", "\n", "existing_hint", "=", "self", ".", "_smoothing_hints", ".", "get", "(", "name", ")", "\n", "if", "existing_hint", "is", "not", "None", ":", "\n", "            ", "assert", "(", "\n", "existing_hint", "==", "smoothing_hint", "\n", ")", ",", "\"Scalar {} was put with a different smoothing_hint!\"", ".", "format", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_smoothing_hints", "[", "name", "]", "=", "smoothing_hint", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalars": [[336, 346], ["kwargs.items", "events.EventStorage.put_scalar"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar"], ["", "", "def", "put_scalars", "(", "self", ",", "*", ",", "smoothing_hint", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Put multiple scalars from keyword arguments.\n\n        Examples:\n\n            storage.put_scalars(loss=my_loss, accuracy=my_accuracy, smoothing_hint=True)\n        \"\"\"", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "put_scalar", "(", "k", ",", "v", ",", "smoothing_hint", "=", "smoothing_hint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_histogram": [[347, 376], ["torch.histc", "torch.linspace", "dict", "events.EventStorage._histograms.append", "hist_tensor.min().item", "hist_tensor.max().item", "len", "float", "float", "hist_edges[].tolist", "torch.histc.tolist", "hist_tensor.min", "hist_tensor.max", "hist_tensor.sum", "torch.sum"], "methods", ["None"], ["", "", "def", "put_histogram", "(", "self", ",", "hist_name", ",", "hist_tensor", ",", "bins", "=", "1000", ")", ":", "\n", "        ", "\"\"\"\n        Create a histogram from a tensor.\n\n        Args:\n            hist_name (str): The name of the histogram to put into tensorboard.\n            hist_tensor (torch.Tensor): A Tensor of arbitrary shape to be converted\n                into a histogram.\n            bins (int): Number of histogram bins.\n        \"\"\"", "\n", "ht_min", ",", "ht_max", "=", "hist_tensor", ".", "min", "(", ")", ".", "item", "(", ")", ",", "hist_tensor", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Create a histogram with PyTorch", "\n", "hist_counts", "=", "torch", ".", "histc", "(", "hist_tensor", ",", "bins", "=", "bins", ")", "\n", "hist_edges", "=", "torch", ".", "linspace", "(", "start", "=", "ht_min", ",", "end", "=", "ht_max", ",", "steps", "=", "bins", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Parameter for the add_histogram_raw function of SummaryWriter", "\n", "hist_params", "=", "dict", "(", "\n", "tag", "=", "hist_name", ",", "\n", "min", "=", "ht_min", ",", "\n", "max", "=", "ht_max", ",", "\n", "num", "=", "len", "(", "hist_tensor", ")", ",", "\n", "sum", "=", "float", "(", "hist_tensor", ".", "sum", "(", ")", ")", ",", "\n", "sum_squares", "=", "float", "(", "torch", ".", "sum", "(", "hist_tensor", "**", "2", ")", ")", ",", "\n", "bucket_limits", "=", "hist_edges", "[", "1", ":", "]", ".", "tolist", "(", ")", ",", "\n", "bucket_counts", "=", "hist_counts", ".", "tolist", "(", ")", ",", "\n", "global_step", "=", "self", ".", "_iter", ",", "\n", ")", "\n", "self", ".", "_histograms", ".", "append", "(", "hist_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.history": [[377, 386], ["events.EventStorage._history.get", "KeyError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "history", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            HistoryBuffer: the scalar history for name\n        \"\"\"", "\n", "ret", "=", "self", ".", "_history", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "ret", "is", "None", ":", "\n", "            ", "raise", "KeyError", "(", "\"No history metric available for {}!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.histories": [[387, 393], ["None"], "methods", ["None"], ["", "def", "histories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> HistoryBuffer]: the HistoryBuffer for all scalars\n        \"\"\"", "\n", "return", "self", ".", "_history", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.latest": [[394, 401], ["None"], "methods", ["None"], ["", "def", "latest", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[str -> (float, int)]: mapping from the name of each scalar to the most\n                recent value and the iteration number its added.\n        \"\"\"", "\n", "return", "self", ".", "_latest_scalars", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.latest_with_smoothing_hint": [[402, 418], ["events.EventStorage._latest_scalars.items", "events.EventStorage._history[].median"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median"], ["", "def", "latest_with_smoothing_hint", "(", "self", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Similar to :meth:`latest`, but the returned values\n        are either the un-smoothed original latest value,\n        or a median of the given window_size,\n        depend on whether the smoothing_hint is True.\n\n        This provides a default behavior that other writers can use.\n        \"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "(", "v", ",", "itr", ")", "in", "self", ".", "_latest_scalars", ".", "items", "(", ")", ":", "\n", "            ", "result", "[", "k", "]", "=", "(", "\n", "self", ".", "_history", "[", "k", "]", ".", "median", "(", "window_size", ")", "if", "self", ".", "_smoothing_hints", "[", "k", "]", "else", "v", ",", "\n", "itr", ",", "\n", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.smoothing_hints": [[419, 426], ["None"], "methods", ["None"], ["", "def", "smoothing_hints", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> bool]: the user-provided hint on whether the scalar\n                is noisy and needs smoothing.\n        \"\"\"", "\n", "return", "self", ".", "_smoothing_hints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step": [[427, 435], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        User should either: (1) Call this function to increment storage.iter when needed. Or\n        (2) Set `storage.iter` to the correct iteration number before each iteration.\n\n        The storage will then be able to associate the new data with an iteration number.\n        \"\"\"", "\n", "self", ".", "_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter": [[445, 448], ["int"], "methods", ["None"], ["", "@", "iter", ".", "setter", "\n", "def", "iter", "(", "self", ",", "val", ")", ":", "\n", "        ", "self", ".", "_iter", "=", "int", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iteration": [[449, 453], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iteration", "(", "self", ")", ":", "\n", "# for backward compatibility", "\n", "        ", "return", "self", ".", "_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.__enter__": [[454, 457], ["_CURRENT_STORAGE_STACK.append"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "_CURRENT_STORAGE_STACK", ".", "append", "(", "self", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.__exit__": [[458, 461], ["_CURRENT_STORAGE_STACK.pop"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "assert", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "==", "self", "\n", "_CURRENT_STORAGE_STACK", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.name_scope": [[462, 473], ["name.rstrip"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "name_scope", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Yields:\n            A context within which all the events added to this storage\n            will be prefixed by the name scope.\n        \"\"\"", "\n", "old_prefix", "=", "self", ".", "_current_prefix", "\n", "self", ".", "_current_prefix", "=", "name", ".", "rstrip", "(", "\"/\"", ")", "+", "\"/\"", "\n", "yield", "\n", "self", ".", "_current_prefix", "=", "old_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.clear_images": [[474, 480], ["None"], "methods", ["None"], ["", "def", "clear_images", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Delete all the stored images for visualization. This should be called\n        after images are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.clear_histograms": [[481, 487], ["None"], "methods", ["None"], ["", "def", "clear_histograms", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Delete all the stored histograms for visualization.\n        This should be called after histograms are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_histograms", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage": [[26, 36], ["len"], "function", ["None"], ["def", "get_event_storage", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The :class:`EventStorage` object that's currently being used.\n        Throws an error if no :class:`EventStorage` is currently enabled.\n    \"\"\"", "\n", "assert", "len", "(", "\n", "_CURRENT_STORAGE_STACK", "\n", ")", ",", "\"get_event_storage() has to be called inside a 'with EventStorage(...)' context!\"", "\n", "return", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_local_rank": [[37, 48], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "\n", "", "def", "all_gather", "(", "data", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_local_size": [[50, 61], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "# serialized to a Tensor", "\n", "", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm._get_global_gloo_group": [[82, 92], ["functools.lru_cache", "torch.get_backend", "torch.new_group"], "function", ["None"], ["\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n", "\n", "", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm._serialize_to_tensor": [[94, 110], ["torch.get_backend", "torch.device", "torch.device", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "len", "logging.getLogger", "logging.getLogger.warning", "torch.ByteTensor", "torch.ByteTensor", "comm.get_rank", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm._pad_to_largest_tensor": [[112, 137], ["torch.get_world_size", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.zeros", "torch.zeros", "int", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat.numel", "range", "size.item"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "average", ":", "\n", "# only main process gets accumulated, so only divide by", "\n", "# world_size in this case", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather": [[177, 218], ["torch.get_rank", "comm._serialize_to_tensor", "comm._pad_to_largest_tensor", "comm.get_world_size", "comm._get_global_gloo_group", "torch.get_world_size", "max", "torch.gather", "zip", "torch.gather", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm._serialize_to_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm._pad_to_largest_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm._get_global_gloo_group", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.shared_random_seed": [[220, 232], ["numpy.random.randint", "comm.all_gather"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.__init__": [[67, 94], ["isinstance", "isinstance", "isinstance", "ValueError", "isinstance", "pycocotools.frPyObjects.astype", "pycocotools.frPyObjects", "pycocotools.decode", "numpy.asarray().reshape", "type", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["def", "__init__", "(", "self", ",", "mask_or_polygons", ",", "height", ",", "width", ")", ":", "\n", "        ", "self", ".", "_mask", "=", "self", ".", "_polygons", "=", "self", ".", "_has_holes", "=", "None", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "width", "=", "width", "\n", "\n", "m", "=", "mask_or_polygons", "\n", "if", "isinstance", "(", "m", ",", "dict", ")", ":", "\n", "# RLEs", "\n", "            ", "assert", "\"counts\"", "in", "m", "and", "\"size\"", "in", "m", "\n", "if", "isinstance", "(", "m", "[", "\"counts\"", "]", ",", "list", ")", ":", "# uncompressed RLEs", "\n", "                ", "h", ",", "w", "=", "m", "[", "\"size\"", "]", "\n", "assert", "h", "==", "height", "and", "w", "==", "width", "\n", "m", "=", "mask_util", ".", "frPyObjects", "(", "m", ",", "h", ",", "w", ")", "\n", "", "self", ".", "_mask", "=", "mask_util", ".", "decode", "(", "m", ")", "[", ":", ",", ":", "]", "\n", "return", "\n", "\n", "", "if", "isinstance", "(", "m", ",", "list", ")", ":", "# list[ndarray]", "\n", "            ", "self", ".", "_polygons", "=", "[", "np", ".", "asarray", "(", "x", ")", ".", "reshape", "(", "-", "1", ")", "for", "x", "in", "m", "]", "\n", "return", "\n", "\n", "", "if", "isinstance", "(", "m", ",", "np", ".", "ndarray", ")", ":", "# assumed to be a binary mask", "\n", "            ", "assert", "m", ".", "shape", "[", "1", "]", "!=", "2", ",", "m", ".", "shape", "\n", "assert", "m", ".", "shape", "==", "(", "height", ",", "width", ")", ",", "m", ".", "shape", "\n", "self", ".", "_mask", "=", "m", ".", "astype", "(", "\"uint8\"", ")", "\n", "return", "\n", "\n", "", "raise", "ValueError", "(", "\"GenericMask cannot handle object {} of type '{}'\"", ".", "format", "(", "m", ",", "type", "(", "m", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.mask": [[95, 100], ["visualizer.GenericMask.polygons_to_mask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.polygons_to_mask"], ["", "@", "property", "\n", "def", "mask", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_mask", "is", "None", ":", "\n", "            ", "self", ".", "_mask", "=", "self", ".", "polygons_to_mask", "(", "self", ".", "_polygons", ")", "\n", "", "return", "self", ".", "_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.polygons": [[101, 106], ["visualizer.GenericMask.mask_to_polygons"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.mask_to_polygons"], ["", "@", "property", "\n", "def", "polygons", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_polygons", "is", "None", ":", "\n", "            ", "self", ".", "_polygons", ",", "self", ".", "_has_holes", "=", "self", ".", "mask_to_polygons", "(", "self", ".", "_mask", ")", "\n", "", "return", "self", ".", "_polygons", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.has_holes": [[107, 115], ["visualizer.GenericMask.mask_to_polygons"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.mask_to_polygons"], ["", "@", "property", "\n", "def", "has_holes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_has_holes", "is", "None", ":", "\n", "            ", "if", "self", ".", "_mask", "is", "not", "None", ":", "\n", "                ", "self", ".", "_polygons", ",", "self", ".", "_has_holes", "=", "self", ".", "mask_to_polygons", "(", "self", ".", "_mask", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_has_holes", "=", "False", "# if original format is polygon, does not have holes", "\n", "", "", "return", "self", ".", "_has_holes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.mask_to_polygons": [[116, 134], ["numpy.ascontiguousarray", "cv2.findContours", "numpy.ascontiguousarray.astype", "x.flatten", "len", "hierarchy.reshape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "def", "mask_to_polygons", "(", "self", ",", "mask", ")", ":", "\n", "# cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level", "\n", "# hierarchy. External contours (boundary) of the object are placed in hierarchy-1.", "\n", "# Internal contours (holes) are placed in hierarchy-2.", "\n", "# cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.", "\n", "        ", "mask", "=", "np", ".", "ascontiguousarray", "(", "mask", ")", "# some versions of cv2 does not support incontiguous arr", "\n", "res", "=", "cv2", ".", "findContours", "(", "mask", ".", "astype", "(", "\"uint8\"", ")", ",", "cv2", ".", "RETR_CCOMP", ",", "cv2", ".", "CHAIN_APPROX_NONE", ")", "\n", "hierarchy", "=", "res", "[", "-", "1", "]", "\n", "if", "hierarchy", "is", "None", ":", "# empty mask", "\n", "            ", "return", "[", "]", ",", "False", "\n", "", "has_holes", "=", "(", "hierarchy", ".", "reshape", "(", "-", "1", ",", "4", ")", "[", ":", ",", "3", "]", ">=", "0", ")", ".", "sum", "(", ")", ">", "0", "\n", "res", "=", "res", "[", "-", "2", "]", "\n", "res", "=", "[", "x", ".", "flatten", "(", ")", "for", "x", "in", "res", "]", "\n", "# These coordinates from OpenCV are integers in range [0, W-1 or H-1].", "\n", "# We add 0.5 to turn them into real-value coordinate space. A better solution", "\n", "# would be to first +0.5 and then dilate the returned polygon by 0.5.", "\n", "res", "=", "[", "x", "+", "0.5", "for", "x", "in", "res", "if", "len", "(", "x", ")", ">=", "6", "]", "\n", "return", "res", ",", "has_holes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.polygons_to_mask": [[135, 139], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.decode"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["", "def", "polygons_to_mask", "(", "self", ",", "polygons", ")", ":", "\n", "        ", "rle", "=", "mask_util", ".", "frPyObjects", "(", "polygons", ",", "self", ".", "height", ",", "self", ".", "width", ")", "\n", "rle", "=", "mask_util", ".", "merge", "(", "rle", ")", "\n", "return", "mask_util", ".", "decode", "(", "rle", ")", "[", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.area": [[140, 142], ["visualizer.GenericMask.mask.sum"], "methods", ["None"], ["", "def", "area", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mask", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.bbox": [[143, 150], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.toBbox"], "methods", ["None"], ["", "def", "bbox", "(", "self", ")", ":", "\n", "        ", "p", "=", "mask_util", ".", "frPyObjects", "(", "self", ".", "polygons", ",", "self", ".", "height", ",", "self", ".", "width", ")", "\n", "p", "=", "mask_util", ".", "merge", "(", "p", ")", "\n", "bbox", "=", "mask_util", ".", "toBbox", "(", "p", ")", "\n", "bbox", "[", "2", "]", "+=", "bbox", "[", "0", "]", "\n", "bbox", "[", "3", "]", "+=", "bbox", "[", "1", "]", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.__init__": [[157, 192], ["torch.unique", "areas.numpy.numpy.numpy", "numpy.argsort", "visualizer._PanopticPrediction._seg_ids.tolist", "zip", "numpy.unique", "panoptic_seg.numpy", "segments_info.append", "float", "metadata.thing_dataset_id_to_contiguous_id.values", "int", "int", "bool"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "panoptic_seg", ",", "segments_info", ",", "metadata", "=", "None", ")", ":", "\n", "        ", "if", "segments_info", "is", "None", ":", "\n", "            ", "assert", "metadata", "is", "not", "None", "\n", "# If \"segments_info\" is None, we assume \"panoptic_img\" is a", "\n", "# H*W int32 image storing the panoptic_id in the format of", "\n", "# category_id * label_divisor + instance_id. We reserve -1 for", "\n", "# VOID label.", "\n", "label_divisor", "=", "metadata", ".", "label_divisor", "\n", "segments_info", "=", "[", "]", "\n", "for", "panoptic_label", "in", "np", ".", "unique", "(", "panoptic_seg", ".", "numpy", "(", ")", ")", ":", "\n", "                ", "if", "panoptic_label", "==", "-", "1", ":", "\n", "# VOID region.", "\n", "                    ", "continue", "\n", "", "pred_class", "=", "panoptic_label", "//", "label_divisor", "\n", "isthing", "=", "pred_class", "in", "metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "int", "(", "panoptic_label", ")", ",", "\n", "\"category_id\"", ":", "int", "(", "pred_class", ")", ",", "\n", "\"isthing\"", ":", "bool", "(", "isthing", ")", ",", "\n", "}", "\n", ")", "\n", "", "", "del", "metadata", "\n", "\n", "self", ".", "_seg", "=", "panoptic_seg", "\n", "\n", "self", ".", "_sinfo", "=", "{", "s", "[", "\"id\"", "]", ":", "s", "for", "s", "in", "segments_info", "}", "# seg id -> seg info", "\n", "segment_ids", ",", "areas", "=", "torch", ".", "unique", "(", "panoptic_seg", ",", "sorted", "=", "True", ",", "return_counts", "=", "True", ")", "\n", "areas", "=", "areas", ".", "numpy", "(", ")", "\n", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", "\n", "self", ".", "_seg_ids", ",", "self", ".", "_seg_areas", "=", "segment_ids", "[", "sorted_idxs", "]", ",", "areas", "[", "sorted_idxs", "]", "\n", "self", ".", "_seg_ids", "=", "self", ".", "_seg_ids", ".", "tolist", "(", ")", "\n", "for", "sid", ",", "area", "in", "zip", "(", "self", ".", "_seg_ids", ",", "self", ".", "_seg_areas", ")", ":", "\n", "            ", "if", "sid", "in", "self", ".", "_sinfo", ":", "\n", "                ", "self", ".", "_sinfo", "[", "sid", "]", "[", "\"area\"", "]", "=", "float", "(", "area", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.non_empty_mask": [[193, 208], ["len", "numpy.zeros", "len", "empty_ids.append"], "methods", ["None"], ["", "", "", "def", "non_empty_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            (H, W) array, a mask for all pixels that have a prediction\n        \"\"\"", "\n", "empty_ids", "=", "[", "]", "\n", "for", "id", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "if", "id", "not", "in", "self", ".", "_sinfo", ":", "\n", "                ", "empty_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "empty_ids", ")", "==", "0", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "self", ".", "_seg", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "", "assert", "(", "\n", "len", "(", "empty_ids", ")", "==", "1", "\n", ")", ",", "\">1 ids corresponds to no labels. This is currently not supported\"", "\n", "return", "(", "self", ".", "_seg", "!=", "empty_ids", "[", "0", "]", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.semantic_masks": [[209, 216], ["visualizer._PanopticPrediction._sinfo.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "semantic_masks", "(", "self", ")", ":", "\n", "        ", "for", "sid", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "sinfo", "=", "self", ".", "_sinfo", ".", "get", "(", "sid", ")", "\n", "if", "sinfo", "is", "None", "or", "sinfo", "[", "\"isthing\"", "]", ":", "\n", "# Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions.", "\n", "                ", "continue", "\n", "", "yield", "(", "self", ".", "_seg", "==", "sid", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", ",", "sinfo", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.instance_masks": [[217, 225], ["visualizer._PanopticPrediction._sinfo.get", "mask.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "instance_masks", "(", "self", ")", ":", "\n", "        ", "for", "sid", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "sinfo", "=", "self", ".", "_sinfo", ".", "get", "(", "sid", ")", "\n", "if", "sinfo", "is", "None", "or", "not", "sinfo", "[", "\"isthing\"", "]", ":", "\n", "                ", "continue", "\n", "", "mask", "=", "(", "self", ".", "_seg", "==", "sid", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "if", "mask", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "yield", "mask", ",", "sinfo", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.__init__": [[255, 265], ["visualizer.VisImage._setup_figure"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage._setup_figure"], ["    ", "def", "__init__", "(", "self", ",", "img", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (ndarray): an RGB image of shape (H, W, 3).\n            scale (float): scale the input image\n        \"\"\"", "\n", "self", ".", "img", "=", "img", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "width", ",", "self", ".", "height", "=", "img", ".", "shape", "[", "1", "]", ",", "img", ".", "shape", "[", "0", "]", "\n", "self", ".", "_setup_figure", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage._setup_figure": [[266, 292], ["matplotlib.Figure", "matplotlib.Figure", "matplotlib.Figure", "matplotlib.Figure.get_dpi", "matplotlib.Figure.set_size_inches", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.Figure.add_axes", "mplfigure.Figure.add_axes.axis", "mplfigure.Figure.add_axes.imshow"], "methods", ["None"], ["", "def", "_setup_figure", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            Same as in :meth:`__init__()`.\n\n        Returns:\n            fig (matplotlib.pyplot.figure): top level container for all the image plot elements.\n            ax (matplotlib.pyplot.Axes): contains figure elements and sets the coordinate system.\n        \"\"\"", "\n", "fig", "=", "mplfigure", ".", "Figure", "(", "frameon", "=", "False", ")", "\n", "self", ".", "dpi", "=", "fig", ".", "get_dpi", "(", ")", "\n", "# add a small 1e-2 to avoid precision lost due to matplotlib's truncation", "\n", "# (https://github.com/matplotlib/matplotlib/issues/15363)", "\n", "fig", ".", "set_size_inches", "(", "\n", "(", "self", ".", "width", "*", "self", ".", "scale", "+", "1e-2", ")", "/", "self", ".", "dpi", ",", "\n", "(", "self", ".", "height", "*", "self", ".", "scale", "+", "1e-2", ")", "/", "self", ".", "dpi", ",", "\n", ")", "\n", "self", ".", "canvas", "=", "FigureCanvasAgg", "(", "fig", ")", "\n", "# self.canvas = mpl.backends.backend_cairo.FigureCanvasCairo(fig)", "\n", "ax", "=", "fig", ".", "add_axes", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "ax", ".", "axis", "(", "\"off\"", ")", "\n", "# Need to imshow this first so that other patches can be drawn on top", "\n", "ax", ".", "imshow", "(", "img", ",", "extent", "=", "(", "0", ",", "self", ".", "width", ",", "self", ".", "height", ",", "0", ")", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "\n", "self", ".", "fig", "=", "fig", "\n", "self", ".", "ax", "=", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save": [[293, 300], ["visualizer.VisImage.fig.savefig"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            filepath (str): a string that contains the absolute path, including the file name, where\n                the visualized image will be saved.\n        \"\"\"", "\n", "self", ".", "fig", ".", "savefig", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.get_image": [[301, 320], ["canvas.print_to_buffer", "numpy.frombuffer", "numpy.frombuffer.reshape", "numpy.split", "rgb.astype"], "methods", ["None"], ["", "def", "get_image", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            ndarray:\n                the visualized image of shape (H, W, 3) (RGB) in uint8 type.\n                The shape is scaled w.r.t the input image using the given `scale` argument.\n        \"\"\"", "\n", "canvas", "=", "self", ".", "canvas", "\n", "s", ",", "(", "width", ",", "height", ")", "=", "canvas", ".", "print_to_buffer", "(", ")", "\n", "# buf = io.BytesIO()  # works for cairo backend", "\n", "# canvas.print_rgba(buf)", "\n", "# width, height = self.width, self.height", "\n", "# s = buf.getvalue()", "\n", "\n", "buffer", "=", "np", ".", "frombuffer", "(", "s", ",", "dtype", "=", "\"uint8\"", ")", "\n", "\n", "img_rgba", "=", "buffer", ".", "reshape", "(", "height", ",", "width", ",", "4", ")", "\n", "rgb", ",", "alpha", "=", "np", ".", "split", "(", "img_rgba", ",", "[", "3", "]", ",", "axis", "=", "2", ")", "\n", "return", "rgb", ".", "astype", "(", "\"uint8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.__init__": [[348, 372], ["numpy.asarray().clip().astype", "visualizer.VisImage", "torch.device", "max", "detectron2.data.MetadataCatalog.get", "numpy.asarray().clip", "numpy.sqrt", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["def", "__init__", "(", "self", ",", "img_rgb", ",", "metadata", "=", "None", ",", "scale", "=", "1.0", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_rgb: a numpy array of shape (H, W, C), where H and W correspond to\n                the height and width of the image respectively. C is the number of\n                color channels. The image is required to be in RGB format since that\n                is a requirement of the Matplotlib library. The image is also expected\n                to be in the range [0, 255].\n            metadata (Metadata): image metadata.\n            instance_mode (ColorMode): defines one of the pre-defined style for drawing\n                instances on an image.\n        \"\"\"", "\n", "self", ".", "img", "=", "np", ".", "asarray", "(", "img_rgb", ")", ".", "clip", "(", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "if", "metadata", "is", "None", ":", "\n", "            ", "metadata", "=", "MetadataCatalog", ".", "get", "(", "\"__nonexist__\"", ")", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "output", "=", "VisImage", "(", "self", ".", "img", ",", "scale", "=", "scale", ")", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# too small texts are useless, therefore clamp to 9", "\n", "self", ".", "_default_font_size", "=", "max", "(", "\n", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "//", "90", ",", "10", "//", "scale", "\n", ")", "\n", "self", ".", "_instance_mode", "=", "instance_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_instance_predictions": [[373, 423], ["visualizer._create_text_labels", "predictions.has", "visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.has", "predictions.has", "predictions.pred_classes.tolist", "visualizer.Visualizer.metadata.get", "predictions.has", "numpy.asarray", "visualizer.Visualizer.metadata.get", "visualizer.Visualizer._create_grayscale_image", "visualizer.GenericMask", "visualizer.Visualizer._jitter", "predictions.has", "predictions.pred_masks.any"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._jitter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["", "def", "draw_instance_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "boxes", "=", "predictions", ".", "pred_boxes", "if", "predictions", ".", "has", "(", "\"pred_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "scores", "if", "predictions", ".", "has", "(", "\"scores\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", ".", "tolist", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "labels", "=", "_create_text_labels", "(", "classes", ",", "scores", ",", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", ")", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "np", ".", "asarray", "(", "predictions", ".", "pred_masks", ")", "\n", "masks", "=", "[", "GenericMask", "(", "x", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "for", "x", "in", "masks", "]", "\n", "", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "            ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "classes", "\n", "]", "\n", "alpha", "=", "0.8", "\n", "", "else", ":", "\n", "            ", "colors", "=", "None", "\n", "alpha", "=", "0.5", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "\n", "(", "predictions", ".", "pred_masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", "\n", "else", "None", "\n", ")", "\n", "alpha", "=", "0.3", "\n", "\n", "", "self", ".", "overlay_instances", "(", "\n", "masks", "=", "masks", ",", "\n", "boxes", "=", "boxes", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_sem_seg": [[424, 459], ["isinstance", "numpy.unique", "numpy.argsort().tolist", "filter", "sem_seg.numpy.numpy.numpy", "visualizer.Visualizer.draw_binary_mask", "numpy.argsort", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_binary_mask"], ["", "def", "draw_sem_seg", "(", "self", ",", "sem_seg", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.8", ")", ":", "\n", "        ", "\"\"\"\n        Draw semantic segmentation predictions/labels.\n\n        Args:\n            sem_seg (Tensor or ndarray): the segmentation of shape (H, W).\n                Each value is the integer label of the pixel.\n            area_threshold (int): segments with less than `area_threshold` are not drawn.\n            alpha (float): the larger it is, the more opaque the segmentations are.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "if", "isinstance", "(", "sem_seg", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sem_seg", "=", "sem_seg", ".", "numpy", "(", ")", "\n", "", "labels", ",", "areas", "=", "np", ".", "unique", "(", "sem_seg", ",", "return_counts", "=", "True", ")", "\n", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "labels", "[", "sorted_idxs", "]", "\n", "for", "label", "in", "filter", "(", "lambda", "l", ":", "l", "<", "len", "(", "self", ".", "metadata", ".", "stuff_classes", ")", ",", "labels", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "label", "]", "]", "\n", "", "except", "(", "AttributeError", ",", "IndexError", ")", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "binary_mask", "=", "(", "sem_seg", "==", "label", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "label", "]", "\n", "self", ".", "draw_binary_mask", "(", "\n", "binary_mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "edge_color", "=", "_OFF_WHITE", ",", "\n", "text", "=", "text", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_panoptic_seg": [[460, 523], ["visualizer._PanopticPrediction", "visualizer._PanopticPrediction.semantic_masks", "list", "list", "visualizer._create_text_labels", "visualizer.Visualizer.overlay_instances", "visualizer.Visualizer._create_grayscale_image", "visualizer.Visualizer.draw_binary_mask", "visualizer._PanopticPrediction.instance_masks", "len", "zip", "visualizer._PanopticPrediction.non_empty_mask", "x.get", "visualizer.Visualizer._jitter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.semantic_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_binary_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.instance_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.non_empty_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._jitter"], ["", "def", "draw_panoptic_seg", "(", "self", ",", "panoptic_seg", ",", "segments_info", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.7", ")", ":", "\n", "        ", "\"\"\"\n        Draw panoptic prediction annotations or results.\n\n        Args:\n            panoptic_seg (Tensor): of shape (height, width) where the values are ids for each\n                segment.\n            segments_info (list[dict] or None): Describe each segment in `panoptic_seg`.\n                If it is a ``list[dict]``, each dict contains keys \"id\", \"category_id\".\n                If None, category id of each pixel is computed by\n                ``pixel // metadata.label_divisor``.\n            area_threshold (int): stuff segments with less than `area_threshold` are not drawn.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "pred", "=", "_PanopticPrediction", "(", "panoptic_seg", ",", "segments_info", ",", "self", ".", "metadata", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "pred", ".", "non_empty_mask", "(", ")", ")", "\n", "\n", "# draw mask for all semantic segments first i.e. \"stuff\"", "\n", "", "for", "mask", ",", "sinfo", "in", "pred", ".", "semantic_masks", "(", ")", ":", "\n", "            ", "category_idx", "=", "sinfo", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "category_idx", "]", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "category_idx", "]", "\n", "self", ".", "draw_binary_mask", "(", "\n", "mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "edge_color", "=", "_OFF_WHITE", ",", "\n", "text", "=", "text", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "\n", "# draw mask for all instances second", "\n", "", "all_instances", "=", "list", "(", "pred", ".", "instance_masks", "(", ")", ")", "\n", "if", "len", "(", "all_instances", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "", "masks", ",", "sinfo", "=", "list", "(", "zip", "(", "*", "all_instances", ")", ")", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "sinfo", "]", "\n", "\n", "try", ":", "\n", "            ", "scores", "=", "[", "x", "[", "\"score\"", "]", "for", "x", "in", "sinfo", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "scores", "=", "None", "\n", "", "labels", "=", "_create_text_labels", "(", "\n", "category_ids", ",", "scores", ",", "self", ".", "metadata", ".", "thing_classes", ",", "[", "x", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "for", "x", "in", "sinfo", "]", "\n", ")", "\n", "\n", "try", ":", "\n", "            ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "category_ids", "\n", "]", "\n", "", "except", "AttributeError", ":", "\n", "            ", "colors", "=", "None", "\n", "", "self", ".", "overlay_instances", "(", "masks", "=", "masks", ",", "labels", "=", "labels", ",", "assigned_colors", "=", "colors", ",", "alpha", "=", "alpha", ")", "\n", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_dataset_dict": [[526, 594], ["dic.get", "dic.get", "dic.get", "visualizer.Visualizer.metadata.get", "visualizer._create_text_labels", "visualizer.Visualizer.overlay_instances", "visualizer.Visualizer.draw_sem_seg", "torch.Tensor", "visualizer.Visualizer.draw_panoptic_seg", "numpy.array().reshape", "visualizer.Visualizer.metadata.get", "detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "numpy.asarray", "detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "numpy.asarray", "rgb2id", "len", "detectron2.structures.BoxMode.convert", "visualizer.Visualizer._jitter", "numpy.array", "len", "x.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer.draw_sem_seg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_panoptic_seg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._jitter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "draw_dataset_dict", "(", "self", ",", "dic", ")", ":", "\n", "        ", "\"\"\"\n        Draw annotations/segmentaions in Detectron2 Dataset format.\n\n        Args:\n            dic (dict): annotation/segmentation data of one image, in Detectron2 Dataset format.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "annos", "=", "dic", ".", "get", "(", "\"annotations\"", ",", "None", ")", "\n", "if", "annos", ":", "\n", "            ", "if", "\"segmentation\"", "in", "annos", "[", "0", "]", ":", "\n", "                ", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "", "else", ":", "\n", "                ", "masks", "=", "None", "\n", "", "if", "\"keypoints\"", "in", "annos", "[", "0", "]", ":", "\n", "                ", "keypts", "=", "[", "x", "[", "\"keypoints\"", "]", "for", "x", "in", "annos", "]", "\n", "keypts", "=", "np", ".", "array", "(", "keypts", ")", ".", "reshape", "(", "len", "(", "annos", ")", ",", "-", "1", ",", "3", ")", "\n", "", "else", ":", "\n", "                ", "keypts", "=", "None", "\n", "\n", "", "boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "x", "[", "\"bbox\"", "]", ",", "x", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "if", "len", "(", "x", "[", "\"bbox\"", "]", ")", "==", "4", "\n", "else", "x", "[", "\"bbox\"", "]", "\n", "for", "x", "in", "annos", "\n", "]", "\n", "\n", "colors", "=", "None", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "                ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "\n", "for", "c", "in", "category_ids", "\n", "]", "\n", "", "names", "=", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", "\n", "labels", "=", "_create_text_labels", "(", "\n", "category_ids", ",", "\n", "scores", "=", "None", ",", "\n", "class_names", "=", "names", ",", "\n", "is_crowd", "=", "[", "x", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "for", "x", "in", "annos", "]", ",", "\n", ")", "\n", "self", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "boxes", "=", "boxes", ",", "masks", "=", "masks", ",", "keypoints", "=", "keypts", ",", "assigned_colors", "=", "colors", "\n", ")", "\n", "\n", "", "sem_seg", "=", "dic", ".", "get", "(", "\"sem_seg\"", ",", "None", ")", "\n", "if", "sem_seg", "is", "None", "and", "\"sem_seg_file_name\"", "in", "dic", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "dic", "[", "\"sem_seg_file_name\"", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "sem_seg", "=", "Image", ".", "open", "(", "f", ")", "\n", "sem_seg", "=", "np", ".", "asarray", "(", "sem_seg", ",", "dtype", "=", "\"uint8\"", ")", "\n", "", "", "if", "sem_seg", "is", "not", "None", ":", "\n", "            ", "self", ".", "draw_sem_seg", "(", "sem_seg", ",", "area_threshold", "=", "0", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "pan_seg", "=", "dic", ".", "get", "(", "\"pan_seg\"", ",", "None", ")", "\n", "if", "pan_seg", "is", "None", "and", "\"pan_seg_file_name\"", "in", "dic", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "dic", "[", "\"pan_seg_file_name\"", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "pan_seg", "=", "Image", ".", "open", "(", "f", ")", "\n", "pan_seg", "=", "np", ".", "asarray", "(", "pan_seg", ")", "\n", "from", "panopticapi", ".", "utils", "import", "rgb2id", "\n", "\n", "pan_seg", "=", "rgb2id", "(", "pan_seg", ")", "\n", "", "", "if", "pan_seg", "is", "not", "None", ":", "\n", "            ", "segments_info", "=", "dic", "[", "\"segments_info\"", "]", "\n", "pan_seg", "=", "torch", ".", "Tensor", "(", "pan_seg", ")", "\n", "self", ".", "draw_panoptic_seg", "(", "pan_seg", ",", "segments_info", ",", "area_threshold", "=", "0", ",", "alpha", "=", "0.5", ")", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances": [[595, 737], ["range", "visualizer.Visualizer._convert_boxes", "len", "visualizer.Visualizer._convert_masks", "visualizer.Visualizer._convert_keypoints", "visualizer.Visualizer.overlay_rotated_instances", "numpy.prod", "numpy.argsort().tolist", "len", "len", "len", "colormap.random_color", "numpy.asarray", "visualizer.Visualizer.draw_box", "visualizer.Visualizer._change_color_brightness", "visualizer.Visualizer.draw_text", "visualizer.Visualizer.draw_and_connect_keypoints", "len", "len", "range", "numpy.argsort", "visualizer.Visualizer.draw_polygon", "numpy.sqrt", "x.area", "segment.reshape", "masks[].bbox", "numpy.clip", "len", "numpy.median", "masks[].mask.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._convert_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._convert_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._convert_keypoints", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_rotated_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.colormap.random_color", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_and_connect_keypoints", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_polygon", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median"], ["", "def", "overlay_instances", "(", "\n", "self", ",", "\n", "*", ",", "\n", "boxes", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "masks", "=", "None", ",", "\n", "keypoints", "=", "None", ",", "\n", "assigned_colors", "=", "None", ",", "\n", "alpha", "=", "0.5", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (Boxes, RotatedBoxes or ndarray): either a :class:`Boxes`,\n                or an Nx4 numpy array of XYXY_ABS format for the N objects in a single image,\n                or a :class:`RotatedBoxes`,\n                or an Nx5 numpy array of (x_center, y_center, width, height, angle_degrees) format\n                for the N objects in a single image,\n            labels (list[str]): the text to be displayed for each instance.\n            masks (masks-like object): Supported types are:\n\n                * :class:`detectron2.structures.PolygonMasks`,\n                  :class:`detectron2.structures.BitMasks`.\n                * list[list[ndarray]]: contains the segmentation masks for all objects in one image.\n                  The first level of the list corresponds to individual instances. The second\n                  level to all the polygon that compose the instance, and the third level\n                  to the polygon coordinates. The third level should have the format of\n                  [x0, y0, x1, y1, ..., xn, yn] (n >= 3).\n                * list[ndarray]: each ndarray is a binary mask of shape (H, W).\n                * list[dict]: each dict is a COCO-style RLE.\n            keypoints (Keypoint or array like): an array-like object of shape (N, K, 3),\n                where the N is the number of instances and K is the number of keypoints.\n                The last dimension corresponds to (x, y, visibility or score).\n            assigned_colors (list[matplotlib.colors]): a list of colors, where each color\n                corresponds to each mask or box in the image. Refer to 'matplotlib.colors'\n                for full list of formats that the colors are accepted in.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "num_instances", "=", "None", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "self", ".", "_convert_boxes", "(", "boxes", ")", "\n", "num_instances", "=", "len", "(", "boxes", ")", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "            ", "masks", "=", "self", ".", "_convert_masks", "(", "masks", ")", "\n", "if", "num_instances", ":", "\n", "                ", "assert", "len", "(", "masks", ")", "==", "num_instances", "\n", "", "else", ":", "\n", "                ", "num_instances", "=", "len", "(", "masks", ")", "\n", "", "", "if", "keypoints", "is", "not", "None", ":", "\n", "            ", "if", "num_instances", ":", "\n", "                ", "assert", "len", "(", "keypoints", ")", "==", "num_instances", "\n", "", "else", ":", "\n", "                ", "num_instances", "=", "len", "(", "keypoints", ")", "\n", "", "keypoints", "=", "self", ".", "_convert_keypoints", "(", "keypoints", ")", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "labels", ")", "==", "num_instances", "\n", "", "if", "assigned_colors", "is", "None", ":", "\n", "            ", "assigned_colors", "=", "[", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "for", "_", "in", "range", "(", "num_instances", ")", "]", "\n", "", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "", "if", "boxes", "is", "not", "None", "and", "boxes", ".", "shape", "[", "1", "]", "==", "5", ":", "\n", "            ", "return", "self", ".", "overlay_rotated_instances", "(", "\n", "boxes", "=", "boxes", ",", "labels", "=", "labels", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", "\n", "\n", "# Display in largest to smallest order to reduce occlusion.", "\n", "", "areas", "=", "None", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "areas", "=", "np", ".", "prod", "(", "boxes", "[", ":", ",", "2", ":", "]", "-", "boxes", "[", ":", ",", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "masks", "is", "not", "None", ":", "\n", "            ", "areas", "=", "np", ".", "asarray", "(", "[", "x", ".", "area", "(", ")", "for", "x", "in", "masks", "]", ")", "\n", "\n", "", "if", "areas", "is", "not", "None", ":", "\n", "            ", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "# Re-order overlapped instances in descending order.", "\n", "boxes", "=", "boxes", "[", "sorted_idxs", "]", "if", "boxes", "is", "not", "None", "else", "None", "\n", "labels", "=", "[", "labels", "[", "k", "]", "for", "k", "in", "sorted_idxs", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", "masks", "=", "[", "masks", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "if", "masks", "is", "not", "None", "else", "None", "\n", "assigned_colors", "=", "[", "assigned_colors", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "\n", "keypoints", "=", "keypoints", "[", "sorted_idxs", "]", "if", "keypoints", "is", "not", "None", "else", "None", "\n", "\n", "", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "color", "=", "assigned_colors", "[", "i", "]", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "                ", "self", ".", "draw_box", "(", "boxes", "[", "i", "]", ",", "edge_color", "=", "color", ")", "\n", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "                ", "for", "segment", "in", "masks", "[", "i", "]", ".", "polygons", ":", "\n", "                    ", "self", ".", "draw_polygon", "(", "segment", ".", "reshape", "(", "-", "1", ",", "2", ")", ",", "color", ",", "alpha", "=", "alpha", ")", "\n", "\n", "", "", "if", "labels", "is", "not", "None", ":", "\n", "# first get a box", "\n", "                ", "if", "boxes", "is", "not", "None", ":", "\n", "                    ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "boxes", "[", "i", "]", "\n", "text_pos", "=", "(", "x0", ",", "y0", ")", "# if drawing boxes, put text on the box corner.", "\n", "horiz_align", "=", "\"left\"", "\n", "", "elif", "masks", "is", "not", "None", ":", "\n", "# skip small mask without polygon", "\n", "                    ", "if", "len", "(", "masks", "[", "i", "]", ".", "polygons", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "masks", "[", "i", "]", ".", "bbox", "(", ")", "\n", "\n", "# draw text in the center (defined by median) when box is not drawn", "\n", "# median is less sensitive to outliers.", "\n", "text_pos", "=", "np", ".", "median", "(", "masks", "[", "i", "]", ".", "mask", ".", "nonzero", "(", ")", ",", "axis", "=", "1", ")", "[", ":", ":", "-", "1", "]", "\n", "horiz_align", "=", "\"center\"", "\n", "", "else", ":", "\n", "                    ", "continue", "# drawing the box confidence for keypoints isn't very useful.", "\n", "# for small objects, draw text at the side to avoid occlusion", "\n", "", "instance_area", "=", "(", "y1", "-", "y0", ")", "*", "(", "x1", "-", "x0", ")", "\n", "if", "(", "\n", "instance_area", "<", "_SMALL_OBJECT_AREA_THRESH", "*", "self", ".", "output", ".", "scale", "\n", "or", "y1", "-", "y0", "<", "40", "*", "self", ".", "output", ".", "scale", "\n", ")", ":", "\n", "                    ", "if", "y1", ">=", "self", ".", "output", ".", "height", "-", "5", ":", "\n", "                        ", "text_pos", "=", "(", "x1", ",", "y0", ")", "\n", "", "else", ":", "\n", "                        ", "text_pos", "=", "(", "x0", ",", "y1", ")", "\n", "\n", "", "", "height_ratio", "=", "(", "y1", "-", "y0", ")", "/", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "\n", "lighter_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "0.7", ")", "\n", "font_size", "=", "(", "\n", "np", ".", "clip", "(", "(", "height_ratio", "-", "0.02", ")", "/", "0.08", "+", "1", ",", "1.2", ",", "2", ")", "\n", "*", "0.5", "\n", "*", "self", ".", "_default_font_size", "\n", ")", "\n", "self", ".", "draw_text", "(", "\n", "labels", "[", "i", "]", ",", "\n", "text_pos", ",", "\n", "color", "=", "lighter_color", ",", "\n", "horizontal_alignment", "=", "horiz_align", ",", "\n", "font_size", "=", "font_size", ",", "\n", ")", "\n", "\n", "# draw keypoints", "\n", "", "", "if", "keypoints", "is", "not", "None", ":", "\n", "            ", "for", "keypoints_per_instance", "in", "keypoints", ":", "\n", "                ", "self", ".", "draw_and_connect_keypoints", "(", "keypoints_per_instance", ")", "\n", "\n", "", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_rotated_instances": [[738, 775], ["len", "numpy.argsort().tolist", "range", "visualizer.Visualizer.draw_rotated_box_with_label", "colormap.random_color", "numpy.argsort", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_rotated_box_with_label", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.colormap.random_color"], ["", "def", "overlay_rotated_instances", "(", "self", ",", "boxes", "=", "None", ",", "labels", "=", "None", ",", "assigned_colors", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (ndarray): an Nx5 numpy array of\n                (x_center, y_center, width, height, angle_degrees) format\n                for the N objects in a single image.\n            labels (list[str]): the text to be displayed for each instance.\n            assigned_colors (list[matplotlib.colors]): a list of colors, where each color\n                corresponds to each mask or box in the image. Refer to 'matplotlib.colors'\n                for full list of formats that the colors are accepted in.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "num_instances", "=", "len", "(", "boxes", ")", "\n", "\n", "if", "assigned_colors", "is", "None", ":", "\n", "            ", "assigned_colors", "=", "[", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "for", "_", "in", "range", "(", "num_instances", ")", "]", "\n", "", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "\n", "# Display in largest to smallest order to reduce occlusion.", "\n", "", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "areas", "=", "boxes", "[", ":", ",", "2", "]", "*", "boxes", "[", ":", ",", "3", "]", "\n", "\n", "", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "# Re-order overlapped instances in descending order.", "\n", "boxes", "=", "boxes", "[", "sorted_idxs", "]", "\n", "labels", "=", "[", "labels", "[", "k", "]", "for", "k", "in", "sorted_idxs", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", "colors", "=", "[", "assigned_colors", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "self", ".", "draw_rotated_box_with_label", "(", "\n", "boxes", "[", "i", "]", ",", "edge_color", "=", "colors", "[", "i", "]", ",", "label", "=", "labels", "[", "i", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_and_connect_keypoints": [[776, 833], ["visualizer.Visualizer.metadata.get", "enumerate", "visualizer.Visualizer.metadata.get", "visible.get", "visualizer.Visualizer.draw_circle", "visualizer.Visualizer.draw_line", "visualizer.Visualizer.draw_line", "tuple", "visualizer.Visualizer.draw_line"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_circle", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_line"], ["", "def", "draw_and_connect_keypoints", "(", "self", ",", "keypoints", ")", ":", "\n", "        ", "\"\"\"\n        Draws keypoints of an instance and follows the rules for keypoint connections\n        to draw lines between appropriate keypoints. This follows color heuristics for\n        line color.\n\n        Args:\n            keypoints (Tensor): a tensor of shape (K, 3), where K is the number of keypoints\n                and the last dimension corresponds to (x, y, probability).\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "visible", "=", "{", "}", "\n", "keypoint_names", "=", "self", ".", "metadata", ".", "get", "(", "\"keypoint_names\"", ")", "\n", "for", "idx", ",", "keypoint", "in", "enumerate", "(", "keypoints", ")", ":", "\n", "# draw keypoint", "\n", "            ", "x", ",", "y", ",", "prob", "=", "keypoint", "\n", "if", "prob", ">", "_KEYPOINT_THRESHOLD", ":", "\n", "                ", "self", ".", "draw_circle", "(", "(", "x", ",", "y", ")", ",", "color", "=", "_RED", ")", "\n", "if", "keypoint_names", ":", "\n", "                    ", "keypoint_name", "=", "keypoint_names", "[", "idx", "]", "\n", "visible", "[", "keypoint_name", "]", "=", "(", "x", ",", "y", ")", "\n", "\n", "", "", "", "if", "self", ".", "metadata", ".", "get", "(", "\"keypoint_connection_rules\"", ")", ":", "\n", "            ", "for", "kp0", ",", "kp1", ",", "color", "in", "self", ".", "metadata", ".", "keypoint_connection_rules", ":", "\n", "                ", "if", "kp0", "in", "visible", "and", "kp1", "in", "visible", ":", "\n", "                    ", "x0", ",", "y0", "=", "visible", "[", "kp0", "]", "\n", "x1", ",", "y1", "=", "visible", "[", "kp1", "]", "\n", "color", "=", "tuple", "(", "x", "/", "255.0", "for", "x", "in", "color", ")", "\n", "self", ".", "draw_line", "(", "[", "x0", ",", "x1", "]", ",", "[", "y0", ",", "y1", "]", ",", "color", "=", "color", ")", "\n", "\n", "# draw lines from nose to mid-shoulder and mid-shoulder to mid-hip", "\n", "# Note that this strategy is specific to person keypoints.", "\n", "# For other keypoints, it should just do nothing", "\n", "", "", "", "try", ":", "\n", "            ", "ls_x", ",", "ls_y", "=", "visible", "[", "\"left_shoulder\"", "]", "\n", "rs_x", ",", "rs_y", "=", "visible", "[", "\"right_shoulder\"", "]", "\n", "mid_shoulder_x", ",", "mid_shoulder_y", "=", "(", "ls_x", "+", "rs_x", ")", "/", "2", ",", "(", "ls_y", "+", "rs_y", ")", "/", "2", "\n", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "# draw line from nose to mid-shoulder", "\n", "            ", "nose_x", ",", "nose_y", "=", "visible", ".", "get", "(", "\"nose\"", ",", "(", "None", ",", "None", ")", ")", "\n", "if", "nose_x", "is", "not", "None", ":", "\n", "                ", "self", ".", "draw_line", "(", "[", "nose_x", ",", "mid_shoulder_x", "]", ",", "[", "nose_y", ",", "mid_shoulder_y", "]", ",", "color", "=", "_RED", ")", "\n", "\n", "", "try", ":", "\n", "# draw line from mid-shoulder to mid-hip", "\n", "                ", "lh_x", ",", "lh_y", "=", "visible", "[", "\"left_hip\"", "]", "\n", "rh_x", ",", "rh_y", "=", "visible", "[", "\"right_hip\"", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "mid_hip_x", ",", "mid_hip_y", "=", "(", "lh_x", "+", "rh_x", ")", "/", "2", ",", "(", "lh_y", "+", "rh_y", ")", "/", "2", "\n", "self", ".", "draw_line", "(", "[", "mid_hip_x", ",", "mid_shoulder_x", "]", ",", "[", "mid_hip_y", ",", "mid_shoulder_y", "]", ",", "color", "=", "_RED", ")", "\n", "", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_text": [[838, 884], ["numpy.maximum", "max", "visualizer.Visualizer.output.ax.text", "list", "numpy.max", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["def", "draw_text", "(", "\n", "self", ",", "\n", "text", ",", "\n", "position", ",", "\n", "*", ",", "\n", "font_size", "=", "None", ",", "\n", "color", "=", "\"g\"", ",", "\n", "horizontal_alignment", "=", "\"center\"", ",", "\n", "rotation", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text (str): class label\n            position (tuple): a tuple of the x and y coordinates to place text on image.\n            font_size (int, optional): font of the text. If not provided, a font size\n                proportional to the image width is calculated and used.\n            color: color of the text. Refer to `matplotlib.colors` for full list\n                of formats that are accepted.\n            horizontal_alignment (str): see `matplotlib.text.Text`\n            rotation: rotation angle in degrees CCW\n\n        Returns:\n            output (VisImage): image object with text drawn.\n        \"\"\"", "\n", "if", "not", "font_size", ":", "\n", "            ", "font_size", "=", "self", ".", "_default_font_size", "\n", "\n", "# since the text background is dark, we don't want the text to be dark", "\n", "", "color", "=", "np", ".", "maximum", "(", "list", "(", "mplc", ".", "to_rgb", "(", "color", ")", ")", ",", "0.2", ")", "\n", "color", "[", "np", ".", "argmax", "(", "color", ")", "]", "=", "max", "(", "0.8", ",", "np", ".", "max", "(", "color", ")", ")", "\n", "\n", "x", ",", "y", "=", "position", "\n", "self", ".", "output", ".", "ax", ".", "text", "(", "\n", "x", ",", "\n", "y", ",", "\n", "text", ",", "\n", "size", "=", "font_size", "*", "self", ".", "output", ".", "scale", ",", "\n", "family", "=", "\"sans-serif\"", ",", "\n", "bbox", "=", "{", "\"facecolor\"", ":", "\"black\"", ",", "\"alpha\"", ":", "0.8", ",", "\"pad\"", ":", "0.7", ",", "\"edgecolor\"", ":", "\"none\"", "}", ",", "\n", "verticalalignment", "=", "\"top\"", ",", "\n", "horizontalalignment", "=", "horizontal_alignment", ",", "\n", "color", "=", "color", ",", "\n", "zorder", "=", "10", ",", "\n", "rotation", "=", "rotation", ",", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_box": [[885, 918], ["max", "visualizer.Visualizer.output.ax.add_patch", "matplotlib.patches.Rectangle", "matplotlib.patches.Rectangle", "matplotlib.patches.Rectangle"], "methods", ["None"], ["", "def", "draw_box", "(", "self", ",", "box_coord", ",", "alpha", "=", "0.5", ",", "edge_color", "=", "\"g\"", ",", "line_style", "=", "\"-\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_coord (tuple): a tuple containing x0, y0, x1, y1 coordinates, where x0 and y0\n                are the coordinates of the image's top left corner. x1 and y1 are the\n                coordinates of the image's bottom right corner.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            edge_color: color of the outline of the box. Refer to `matplotlib.colors`\n                for full list of formats that are accepted.\n            line_style (string): the string to use to create the outline of the boxes.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "box_coord", "\n", "width", "=", "x1", "-", "x0", "\n", "height", "=", "y1", "-", "y0", "\n", "\n", "linewidth", "=", "max", "(", "self", ".", "_default_font_size", "/", "4", ",", "1", ")", "\n", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "\n", "mpl", ".", "patches", ".", "Rectangle", "(", "\n", "(", "x0", ",", "y0", ")", ",", "\n", "width", ",", "\n", "height", ",", "\n", "fill", "=", "False", ",", "\n", "edgecolor", "=", "edge_color", ",", "\n", "linewidth", "=", "linewidth", "*", "self", ".", "output", ".", "scale", ",", "\n", "alpha", "=", "alpha", ",", "\n", "linestyle", "=", "line_style", ",", "\n", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_rotated_box_with_label": [[919, 973], ["math.cos", "math.sin", "range", "visualizer.Visualizer.draw_line", "visualizer.Visualizer._change_color_brightness", "visualizer.Visualizer.draw_text", "numpy.sqrt", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "draw_rotated_box_with_label", "(", "\n", "self", ",", "rotated_box", ",", "alpha", "=", "0.5", ",", "edge_color", "=", "\"g\"", ",", "line_style", "=", "\"-\"", ",", "label", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Draw a rotated box with label on its top-left corner.\n\n        Args:\n            rotated_box (tuple): a tuple containing (cnt_x, cnt_y, w, h, angle),\n                where cnt_x and cnt_y are the center coordinates of the box.\n                w and h are the width and height of the box. angle represents how\n                many degrees the box is rotated CCW with regard to the 0-degree box.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            edge_color: color of the outline of the box. Refer to `matplotlib.colors`\n                for full list of formats that are accepted.\n            line_style (string): the string to use to create the outline of the boxes.\n            label (string): label for rotated box. It will not be rendered when set to None.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "cnt_x", ",", "cnt_y", ",", "w", ",", "h", ",", "angle", "=", "rotated_box", "\n", "area", "=", "w", "*", "h", "\n", "# use thinner lines when the box is small", "\n", "linewidth", "=", "self", ".", "_default_font_size", "/", "(", "\n", "6", "if", "area", "<", "_SMALL_OBJECT_AREA_THRESH", "*", "self", ".", "output", ".", "scale", "else", "3", "\n", ")", "\n", "\n", "theta", "=", "angle", "*", "math", ".", "pi", "/", "180.0", "\n", "c", "=", "math", ".", "cos", "(", "theta", ")", "\n", "s", "=", "math", ".", "sin", "(", "theta", ")", "\n", "rect", "=", "[", "(", "-", "w", "/", "2", ",", "h", "/", "2", ")", ",", "(", "-", "w", "/", "2", ",", "-", "h", "/", "2", ")", ",", "(", "w", "/", "2", ",", "-", "h", "/", "2", ")", ",", "(", "w", "/", "2", ",", "h", "/", "2", ")", "]", "\n", "# x: left->right ; y: top->down", "\n", "rotated_rect", "=", "[", "(", "s", "*", "yy", "+", "c", "*", "xx", "+", "cnt_x", ",", "c", "*", "yy", "-", "s", "*", "xx", "+", "cnt_y", ")", "for", "(", "xx", ",", "yy", ")", "in", "rect", "]", "\n", "for", "k", "in", "range", "(", "4", ")", ":", "\n", "            ", "j", "=", "(", "k", "+", "1", ")", "%", "4", "\n", "self", ".", "draw_line", "(", "\n", "[", "rotated_rect", "[", "k", "]", "[", "0", "]", ",", "rotated_rect", "[", "j", "]", "[", "0", "]", "]", ",", "\n", "[", "rotated_rect", "[", "k", "]", "[", "1", "]", ",", "rotated_rect", "[", "j", "]", "[", "1", "]", "]", ",", "\n", "color", "=", "edge_color", ",", "\n", "linestyle", "=", "\"--\"", "if", "k", "==", "1", "else", "line_style", ",", "\n", "linewidth", "=", "linewidth", ",", "\n", ")", "\n", "\n", "", "if", "label", "is", "not", "None", ":", "\n", "            ", "text_pos", "=", "rotated_rect", "[", "1", "]", "# topleft corner", "\n", "\n", "height_ratio", "=", "h", "/", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "\n", "label_color", "=", "self", ".", "_change_color_brightness", "(", "edge_color", ",", "brightness_factor", "=", "0.7", ")", "\n", "font_size", "=", "(", "\n", "np", ".", "clip", "(", "(", "height_ratio", "-", "0.02", ")", "/", "0.08", "+", "1", ",", "1.2", ",", "2", ")", "*", "0.5", "*", "self", ".", "_default_font_size", "\n", ")", "\n", "self", ".", "draw_text", "(", "label", ",", "text_pos", ",", "color", "=", "label_color", ",", "font_size", "=", "font_size", ",", "rotation", "=", "angle", ")", "\n", "\n", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_circle": [[974, 991], ["visualizer.Visualizer.output.ax.add_patch", "matplotlib.patches.Circle", "matplotlib.patches.Circle", "matplotlib.patches.Circle"], "methods", ["None"], ["", "def", "draw_circle", "(", "self", ",", "circle_coord", ",", "color", ",", "radius", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            circle_coord (list(int) or tuple(int)): contains the x and y coordinates\n                of the center of the circle.\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            radius (int): radius of the circle.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "x", ",", "y", "=", "circle_coord", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "\n", "mpl", ".", "patches", ".", "Circle", "(", "circle_coord", ",", "radius", "=", "radius", ",", "fill", "=", "True", ",", "color", "=", "color", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_line": [[992, 1022], ["max", "visualizer.Visualizer.output.ax.add_line", "matplotlib.lines.Line2D", "matplotlib.lines.Line2D", "matplotlib.lines.Line2D"], "methods", ["None"], ["", "def", "draw_line", "(", "self", ",", "x_data", ",", "y_data", ",", "color", ",", "linestyle", "=", "\"-\"", ",", "linewidth", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x_data (list[int]): a list containing x values of all the points being drawn.\n                Length of list should match the length of y_data.\n            y_data (list[int]): a list containing y values of all the points being drawn.\n                Length of list should match the length of x_data.\n            color: color of the line. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            linestyle: style of the line. Refer to `matplotlib.lines.Line2D`\n                for a full list of formats that are accepted.\n            linewidth (float or None): width of the line. When it's None,\n                a default value will be computed and used.\n\n        Returns:\n            output (VisImage): image object with line drawn.\n        \"\"\"", "\n", "if", "linewidth", "is", "None", ":", "\n", "            ", "linewidth", "=", "self", ".", "_default_font_size", "/", "3", "\n", "", "linewidth", "=", "max", "(", "linewidth", ",", "1", ")", "\n", "self", ".", "output", ".", "ax", ".", "add_line", "(", "\n", "mpl", ".", "lines", ".", "Line2D", "(", "\n", "x_data", ",", "\n", "y_data", ",", "\n", "linewidth", "=", "linewidth", "*", "self", ".", "output", ".", "scale", ",", "\n", "color", "=", "color", ",", "\n", "linestyle", "=", "linestyle", ",", "\n", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_binary_mask": [[1023, 1083], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "binary_mask.astype.astype.astype", "visualizer.GenericMask", "colormap.random_color", "numpy.zeros", "visualizer.Visualizer.output.ax.imshow", "visualizer.Visualizer._change_color_brightness", "cv2.connectedComponentsWithStats", "range", "pycocotools.area", "segment.reshape.reshape.reshape", "visualizer.Visualizer.draw_polygon", "numpy.argmax", "pycocotools.frPyObjects", "visualizer.Visualizer.draw_text", "numpy.median"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.colormap.random_color", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_polygon", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.median"], ["", "def", "draw_binary_mask", "(", "\n", "self", ",", "binary_mask", ",", "color", "=", "None", ",", "*", ",", "edge_color", "=", "None", ",", "text", "=", "None", ",", "alpha", "=", "0.5", ",", "area_threshold", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            binary_mask (ndarray): numpy array of shape (H, W), where H is the image height and\n                W is the image width. Each value in the array is either a 0 or 1 value of uint8\n                type.\n            color: color of the mask. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted. If None, will pick a random color.\n            edge_color: color of the polygon edges. Refer to `matplotlib.colors` for a\n                full list of formats that are accepted.\n            text (str): if None, will be drawn in the object's center of mass.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            area_threshold (float): a connected component small than this will not be shown.\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"", "\n", "if", "color", "is", "None", ":", "\n", "            ", "color", "=", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "\n", "has_valid_segment", "=", "False", "\n", "binary_mask", "=", "binary_mask", ".", "astype", "(", "\"uint8\"", ")", "# opencv needs uint8", "\n", "mask", "=", "GenericMask", "(", "binary_mask", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "\n", "shape2d", "=", "(", "binary_mask", ".", "shape", "[", "0", "]", ",", "binary_mask", ".", "shape", "[", "1", "]", ")", "\n", "\n", "if", "not", "mask", ".", "has_holes", ":", "\n", "# draw polygons for regular masks", "\n", "            ", "for", "segment", "in", "mask", ".", "polygons", ":", "\n", "                ", "area", "=", "mask_util", ".", "area", "(", "mask_util", ".", "frPyObjects", "(", "[", "segment", "]", ",", "shape2d", "[", "0", "]", ",", "shape2d", "[", "1", "]", ")", ")", "\n", "if", "area", "<", "(", "area_threshold", "or", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "has_valid_segment", "=", "True", "\n", "segment", "=", "segment", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "self", ".", "draw_polygon", "(", "segment", ",", "color", "=", "color", ",", "edge_color", "=", "edge_color", ",", "alpha", "=", "alpha", ")", "\n", "", "", "else", ":", "\n", "# TODO: Use Path/PathPatch to draw vector graphics:", "\n", "# https://stackoverflow.com/questions/8919719/how-to-plot-a-complex-polygon", "\n", "            ", "rgba", "=", "np", ".", "zeros", "(", "shape2d", "+", "(", "4", ",", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "rgba", "[", ":", ",", ":", ",", ":", "3", "]", "=", "color", "\n", "rgba", "[", ":", ",", ":", ",", "3", "]", "=", "(", "mask", ".", "mask", "==", "1", ")", ".", "astype", "(", "\"float32\"", ")", "*", "alpha", "\n", "has_valid_segment", "=", "True", "\n", "self", ".", "output", ".", "ax", ".", "imshow", "(", "rgba", ",", "extent", "=", "(", "0", ",", "self", ".", "output", ".", "width", ",", "self", ".", "output", ".", "height", ",", "0", ")", ")", "\n", "\n", "", "if", "text", "is", "not", "None", "and", "has_valid_segment", ":", "\n", "# TODO sometimes drawn on wrong objects. the heuristics here can improve.", "\n", "            ", "lighter_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "0.7", ")", "\n", "_num_cc", ",", "cc_labels", ",", "stats", ",", "centroids", "=", "cv2", ".", "connectedComponentsWithStats", "(", "binary_mask", ",", "8", ")", "\n", "largest_component_id", "=", "np", ".", "argmax", "(", "stats", "[", "1", ":", ",", "-", "1", "]", ")", "+", "1", "\n", "\n", "# draw text on the largest component, as well as other very large components.", "\n", "for", "cid", "in", "range", "(", "1", ",", "_num_cc", ")", ":", "\n", "                ", "if", "cid", "==", "largest_component_id", "or", "stats", "[", "cid", ",", "-", "1", "]", ">", "_LARGE_MASK_AREA_THRESH", ":", "\n", "# median is more stable than centroid", "\n", "# center = centroids[largest_component_id]", "\n", "                    ", "center", "=", "np", ".", "median", "(", "(", "cc_labels", "==", "cid", ")", ".", "nonzero", "(", ")", ",", "axis", "=", "1", ")", "[", ":", ":", "-", "1", "]", "\n", "self", ".", "draw_text", "(", "text", ",", "center", ",", "color", "=", "lighter_color", ")", "\n", "", "", "", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_polygon": [[1084, 1115], ["matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "visualizer.Visualizer.output.ax.add_patch", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "visualizer.Visualizer._change_color_brightness", "max", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._change_color_brightness"], ["", "def", "draw_polygon", "(", "self", ",", "segment", ",", "color", ",", "edge_color", "=", "None", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            segment: numpy array of shape Nx2, containing all the points in the polygon.\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            edge_color: color of the polygon edges. Refer to `matplotlib.colors` for a\n                full list of formats that are accepted. If not provided, a darker shade\n                of the polygon color will be used instead.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n\n        Returns:\n            output (VisImage): image object with polygon drawn.\n        \"\"\"", "\n", "if", "edge_color", "is", "None", ":", "\n", "# make edge color darker than the polygon color", "\n", "            ", "if", "alpha", ">", "0.8", ":", "\n", "                ", "edge_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "-", "0.7", ")", "\n", "", "else", ":", "\n", "                ", "edge_color", "=", "color", "\n", "", "", "edge_color", "=", "mplc", ".", "to_rgb", "(", "edge_color", ")", "+", "(", "1", ",", ")", "\n", "\n", "polygon", "=", "mpl", ".", "patches", ".", "Polygon", "(", "\n", "segment", ",", "\n", "fill", "=", "True", ",", "\n", "facecolor", "=", "mplc", ".", "to_rgb", "(", "color", ")", "+", "(", "alpha", ",", ")", ",", "\n", "edgecolor", "=", "edge_color", ",", "\n", "linewidth", "=", "max", "(", "self", ".", "_default_font_size", "//", "15", "*", "self", ".", "output", ".", "scale", ",", "1", ")", ",", "\n", ")", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "polygon", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._jitter": [[1120, 1138], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "numpy.random.rand", "numpy.clip", "tuple", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["def", "_jitter", "(", "self", ",", "color", ")", ":", "\n", "        ", "\"\"\"\n        Randomly modifies given color to produce a slightly different color than the color given.\n\n        Args:\n            color (tuple[double]): a tuple of 3 elements, containing the RGB values of the color\n                picked. The values in the list are in the [0.0, 1.0] range.\n\n        Returns:\n            jittered_color (tuple[double]): a tuple of 3 elements, containing the RGB values of the\n                color after being jittered. The values in the list are in the [0.0, 1.0] range.\n        \"\"\"", "\n", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "vec", "=", "np", ".", "random", ".", "rand", "(", "3", ")", "\n", "# better to do it in another color space", "\n", "vec", "=", "vec", "/", "np", ".", "linalg", ".", "norm", "(", "vec", ")", "*", "0.5", "\n", "res", "=", "np", ".", "clip", "(", "vec", "+", "color", ",", "0", ",", "1", ")", "\n", "return", "tuple", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._create_grayscale_image": [[1139, 1149], ["visualizer.Visualizer.img.astype().mean", "numpy.stack", "visualizer.Visualizer.img.astype"], "methods", ["None"], ["", "def", "_create_grayscale_image", "(", "self", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create a grayscale version of the original image.\n        The colors in masked area, if given, will be kept.\n        \"\"\"", "\n", "img_bw", "=", "self", ".", "img", ".", "astype", "(", "\"f4\"", ")", ".", "mean", "(", "axis", "=", "2", ")", "\n", "img_bw", "=", "np", ".", "stack", "(", "[", "img_bw", "]", "*", "3", ",", "axis", "=", "2", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "img_bw", "[", "mask", "]", "=", "self", ".", "img", "[", "mask", "]", "\n", "", "return", "img_bw", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._change_color_brightness": [[1150, 1174], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "colorsys.rgb_to_hls", "colorsys.hls_to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb"], "methods", ["None"], ["", "def", "_change_color_brightness", "(", "self", ",", "color", ",", "brightness_factor", ")", ":", "\n", "        ", "\"\"\"\n        Depending on the brightness_factor, gives a lighter or darker color i.e. a color with\n        less or more saturation than the original color.\n\n        Args:\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            brightness_factor (float): a value in [-1.0, 1.0] range. A lightness factor of\n                0 will correspond to no change, a factor in [-1.0, 0) range will result in\n                a darker color and a factor in (0, 1.0] range will result in a lighter color.\n\n        Returns:\n            modified_color (tuple[double]): a tuple containing the RGB values of the\n                modified color. Each value in the tuple is in the [0.0, 1.0] range.\n        \"\"\"", "\n", "assert", "brightness_factor", ">=", "-", "1.0", "and", "brightness_factor", "<=", "1.0", "\n", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "polygon_color", "=", "colorsys", ".", "rgb_to_hls", "(", "*", "mplc", ".", "to_rgb", "(", "color", ")", ")", "\n", "modified_lightness", "=", "polygon_color", "[", "1", "]", "+", "(", "brightness_factor", "*", "polygon_color", "[", "1", "]", ")", "\n", "modified_lightness", "=", "0.0", "if", "modified_lightness", "<", "0.0", "else", "modified_lightness", "\n", "modified_lightness", "=", "1.0", "if", "modified_lightness", ">", "1.0", "else", "modified_lightness", "\n", "modified_color", "=", "colorsys", ".", "hls_to_rgb", "(", "polygon_color", "[", "0", "]", ",", "modified_lightness", ",", "polygon_color", "[", "2", "]", ")", "\n", "return", "modified_color", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._convert_boxes": [[1175, 1183], ["isinstance", "isinstance", "boxes.tensor.numpy", "numpy.asarray"], "methods", ["None"], ["", "def", "_convert_boxes", "(", "self", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Convert different format of boxes to an NxB array, where B = 4 or 5 is the box dimension.\n        \"\"\"", "\n", "if", "isinstance", "(", "boxes", ",", "Boxes", ")", "or", "isinstance", "(", "boxes", ",", "RotatedBoxes", ")", ":", "\n", "            ", "return", "boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "asarray", "(", "boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._convert_masks": [[1184, 1206], ["isinstance", "isinstance", "isinstance", "m.numpy.numpy.tensor.numpy", "m.numpy.numpy.numpy", "isinstance", "ret.append", "ret.append", "visualizer.GenericMask"], "methods", ["None"], ["", "", "def", "_convert_masks", "(", "self", ",", "masks_or_polygons", ")", ":", "\n", "        ", "\"\"\"\n        Convert different format of masks or polygons to a tuple of masks and polygons.\n\n        Returns:\n            list[GenericMask]:\n        \"\"\"", "\n", "\n", "m", "=", "masks_or_polygons", "\n", "if", "isinstance", "(", "m", ",", "PolygonMasks", ")", ":", "\n", "            ", "m", "=", "m", ".", "polygons", "\n", "", "if", "isinstance", "(", "m", ",", "BitMasks", ")", ":", "\n", "            ", "m", "=", "m", ".", "tensor", ".", "numpy", "(", ")", "\n", "", "if", "isinstance", "(", "m", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "m", "=", "m", ".", "numpy", "(", ")", "\n", "", "ret", "=", "[", "]", "\n", "for", "x", "in", "m", ":", "\n", "            ", "if", "isinstance", "(", "x", ",", "GenericMask", ")", ":", "\n", "                ", "ret", ".", "append", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "ret", ".", "append", "(", "GenericMask", "(", "x", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._convert_keypoints": [[1207, 1212], ["isinstance", "numpy.asarray"], "methods", ["None"], ["", "def", "_convert_keypoints", "(", "self", ",", "keypoints", ")", ":", "\n", "        ", "if", "isinstance", "(", "keypoints", ",", "Keypoints", ")", ":", "\n", "            ", "keypoints", "=", "keypoints", ".", "tensor", "\n", "", "keypoints", "=", "np", ".", "asarray", "(", "keypoints", ")", "\n", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.get_output": [[1213, 1220], ["None"], "methods", ["None"], ["", "def", "get_output", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            output (VisImage): the image output containing the visualizations added\n            to the image.\n        \"\"\"", "\n", "return", "self", ".", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._create_text_labels": [[227, 252], ["len", "str", "zip", "zip"], "function", ["None"], ["", "", "", "", "def", "_create_text_labels", "(", "classes", ",", "scores", ",", "class_names", ",", "is_crowd", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        classes (list[int] or None):\n        scores (list[float] or None):\n        class_names (list[str] or None):\n        is_crowd (list[bool] or None):\n\n    Returns:\n        list[str] or None\n    \"\"\"", "\n", "labels", "=", "None", "\n", "if", "classes", "is", "not", "None", ":", "\n", "        ", "if", "class_names", "is", "not", "None", "and", "len", "(", "class_names", ")", ">", "0", ":", "\n", "            ", "labels", "=", "[", "class_names", "[", "i", "]", "for", "i", "in", "classes", "]", "\n", "", "else", ":", "\n", "            ", "labels", "=", "[", "str", "(", "i", ")", "for", "i", "in", "classes", "]", "\n", "", "", "if", "scores", "is", "not", "None", ":", "\n", "        ", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "\"{:.0f}%\"", ".", "format", "(", "s", "*", "100", ")", "for", "s", "in", "scores", "]", "\n", "", "else", ":", "\n", "            ", "labels", "=", "[", "\"{} {:.0f}%\"", ".", "format", "(", "l", ",", "s", "*", "100", ")", "for", "l", ",", "s", "in", "zip", "(", "labels", ",", "scores", ")", "]", "\n", "", "", "if", "labels", "is", "not", "None", "and", "is_crowd", "is", "not", "None", ":", "\n", "        ", "labels", "=", "[", "l", "+", "(", "\"|crowd\"", "if", "crowd", "else", "\"\"", ")", "for", "l", ",", "crowd", "in", "zip", "(", "labels", ",", "is_crowd", ")", "]", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer._DetectedInstance.__init__": [[31, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "label", ",", "bbox", ",", "mask_rle", ",", "color", ",", "ttl", ")", ":", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "bbox", "=", "bbox", "\n", "self", ".", "mask_rle", "=", "mask_rle", "\n", "self", ".", "color", "=", "color", "\n", "self", ".", "ttl", "=", "ttl", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer.__init__": [[40, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "metadata", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            metadata (MetadataCatalog): image metadata.\n        \"\"\"", "\n", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "_old_instances", "=", "[", "]", "\n", "assert", "instance_mode", "in", "[", "\n", "ColorMode", ".", "IMAGE", ",", "\n", "ColorMode", ".", "IMAGE_BW", ",", "\n", "]", ",", "\"Other mode not supported yet.\"", "\n", "self", ".", "_instance_mode", "=", "instance_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer.draw_instance_predictions": [[53, 111], ["detectron2.utils.visualizer.Visualizer", "len", "predictions.has", "video_visualizer.VideoVisualizer._assign_colors", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.pred_boxes.tensor.numpy", "predictions.has", "predictions.has", "predictions.pred_classes.numpy", "predictions.has", "video_visualizer._DetectedInstance", "video_visualizer.VideoVisualizer.metadata.get", "detectron2.utils.visualizer.Visualizer._create_grayscale_image", "range", "masks.any"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer._assign_colors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._create_grayscale_image"], ["", "def", "draw_instance_predictions", "(", "self", ",", "frame", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            frame (ndarray): an RGB image of shape (H, W, C), in the range [0, 255].\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "num_instances", "=", "len", "(", "predictions", ")", "\n", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "frame_visualizer", ".", "output", "\n", "\n", "", "boxes", "=", "predictions", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "scores", "if", "predictions", ".", "has", "(", "\"scores\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", ".", "numpy", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "predictions", ".", "pred_masks", "\n", "# mask IOU is not yet enabled", "\n", "# masks_rles = mask_util.encode(np.asarray(masks.permute(1, 2, 0), order=\"F\"))", "\n", "# assert len(masks_rles) == num_instances", "\n", "", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "", "detected", "=", "[", "\n", "_DetectedInstance", "(", "classes", "[", "i", "]", ",", "boxes", "[", "i", "]", ",", "mask_rle", "=", "None", ",", "color", "=", "None", ",", "ttl", "=", "8", ")", "\n", "for", "i", "in", "range", "(", "num_instances", ")", "\n", "]", "\n", "colors", "=", "self", ".", "_assign_colors", "(", "detected", ")", "\n", "\n", "labels", "=", "_create_text_labels", "(", "classes", ",", "scores", ",", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "# any() returns uint8 tensor", "\n", "            ", "frame_visualizer", ".", "output", ".", "img", "=", "frame_visualizer", ".", "_create_grayscale_image", "(", "\n", "(", "masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "if", "masks", "is", "not", "None", "else", "None", "\n", ")", "\n", "alpha", "=", "0.3", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "0.5", "\n", "\n", "", "frame_visualizer", ".", "overlay_instances", "(", "\n", "boxes", "=", "None", "if", "masks", "is", "not", "None", "else", "boxes", ",", "# boxes are a bit distracting", "\n", "masks", "=", "masks", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer.draw_sem_seg": [[112, 123], ["detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.draw_sem_seg"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer.draw_sem_seg"], ["", "def", "draw_sem_seg", "(", "self", ",", "frame", ",", "sem_seg", ",", "area_threshold", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sem_seg (ndarray or Tensor): semantic segmentation of shape (H, W),\n                each value is the integer label.\n            area_threshold (Optional[int]): only draw segmentations larger than the threshold\n        \"\"\"", "\n", "# don't need to do anything special", "\n", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "frame_visualizer", ".", "draw_sem_seg", "(", "sem_seg", ",", "area_threshold", "=", "None", ")", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions": [[124, 179], ["detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._PanopticPrediction", "detectron2.utils.visualizer._PanopticPrediction.semantic_masks", "list", "list", "len", "pycocotools.encode", "video_visualizer.VideoVisualizer._assign_colors", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer._create_grayscale_image", "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "detectron2.utils.visualizer._PanopticPrediction.instance_masks", "len", "zip", "numpy.asarray", "len", "video_visualizer._DetectedInstance", "detectron2.utils.visualizer._PanopticPrediction.non_empty_mask", "numpy.asarray().transpose", "range", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.semantic_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer._assign_colors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.draw_binary_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.instance_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer._PanopticPrediction.non_empty_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "draw_panoptic_seg_predictions", "(", "\n", "self", ",", "frame", ",", "panoptic_seg", ",", "segments_info", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.5", "\n", ")", ":", "\n", "        ", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "pred", "=", "_PanopticPrediction", "(", "panoptic_seg", ",", "segments_info", ",", "self", ".", "metadata", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "frame_visualizer", ".", "output", ".", "img", "=", "frame_visualizer", ".", "_create_grayscale_image", "(", "\n", "pred", ".", "non_empty_mask", "(", ")", "\n", ")", "\n", "\n", "# draw mask for all semantic segments first i.e. \"stuff\"", "\n", "", "for", "mask", ",", "sinfo", "in", "pred", ".", "semantic_masks", "(", ")", ":", "\n", "            ", "category_idx", "=", "sinfo", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "category_idx", "]", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "frame_visualizer", ".", "draw_binary_mask", "(", "\n", "mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "category_idx", "]", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "\n", "", "all_instances", "=", "list", "(", "pred", ".", "instance_masks", "(", ")", ")", "\n", "if", "len", "(", "all_instances", ")", "==", "0", ":", "\n", "            ", "return", "frame_visualizer", ".", "output", "\n", "# draw mask for all instances second", "\n", "", "masks", ",", "sinfo", "=", "list", "(", "zip", "(", "*", "all_instances", ")", ")", "\n", "num_instances", "=", "len", "(", "masks", ")", "\n", "masks_rles", "=", "mask_util", ".", "encode", "(", "\n", "np", ".", "asarray", "(", "np", ".", "asarray", "(", "masks", ")", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "order", "=", "\"F\"", ")", "\n", ")", "\n", "assert", "len", "(", "masks_rles", ")", "==", "num_instances", "\n", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "sinfo", "]", "\n", "detected", "=", "[", "\n", "_DetectedInstance", "(", "category_ids", "[", "i", "]", ",", "bbox", "=", "None", ",", "mask_rle", "=", "masks_rles", "[", "i", "]", ",", "color", "=", "None", ",", "ttl", "=", "8", ")", "\n", "for", "i", "in", "range", "(", "num_instances", ")", "\n", "]", "\n", "colors", "=", "self", ".", "_assign_colors", "(", "detected", ")", "\n", "labels", "=", "[", "self", ".", "metadata", ".", "thing_classes", "[", "k", "]", "for", "k", "in", "category_ids", "]", "\n", "\n", "frame_visualizer", ".", "overlay_instances", "(", "\n", "boxes", "=", "None", ",", "\n", "masks", "=", "masks", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "None", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.video_visualizer.VideoVisualizer._assign_colors": [[180, 236], ["numpy.zeros", "enumerate", "numpy.asarray().argmax", "numpy.asarray().max", "enumerate", "pycocotools.iou", "pycocotools.iou", "len", "numpy.zeros", "enumerate", "len", "numpy.asarray", "numpy.asarray", "extra_instances.append", "colormap.random_color", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.colormap.random_color"], ["", "def", "_assign_colors", "(", "self", ",", "instances", ")", ":", "\n", "        ", "\"\"\"\n        Naive tracking heuristics to assign same color to the same instance,\n        will update the internal state of tracked instances.\n\n        Returns:\n            list[tuple[float]]: list of colors.\n        \"\"\"", "\n", "\n", "# Compute iou with either boxes or masks:", "\n", "is_crowd", "=", "np", ".", "zeros", "(", "(", "len", "(", "instances", ")", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "if", "instances", "[", "0", "]", ".", "bbox", "is", "None", ":", "\n", "            ", "assert", "instances", "[", "0", "]", ".", "mask_rle", "is", "not", "None", "\n", "# use mask iou only when box iou is None", "\n", "# because box seems good enough", "\n", "rles_old", "=", "[", "x", ".", "mask_rle", "for", "x", "in", "self", ".", "_old_instances", "]", "\n", "rles_new", "=", "[", "x", ".", "mask_rle", "for", "x", "in", "instances", "]", "\n", "ious", "=", "mask_util", ".", "iou", "(", "rles_old", ",", "rles_new", ",", "is_crowd", ")", "\n", "threshold", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "boxes_old", "=", "[", "x", ".", "bbox", "for", "x", "in", "self", ".", "_old_instances", "]", "\n", "boxes_new", "=", "[", "x", ".", "bbox", "for", "x", "in", "instances", "]", "\n", "ious", "=", "mask_util", ".", "iou", "(", "boxes_old", ",", "boxes_new", ",", "is_crowd", ")", "\n", "threshold", "=", "0.6", "\n", "", "if", "len", "(", "ious", ")", "==", "0", ":", "\n", "            ", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "_old_instances", ")", ",", "len", "(", "instances", ")", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "# Only allow matching instances of the same label:", "\n", "", "for", "old_idx", ",", "old", "in", "enumerate", "(", "self", ".", "_old_instances", ")", ":", "\n", "            ", "for", "new_idx", ",", "new", "in", "enumerate", "(", "instances", ")", ":", "\n", "                ", "if", "old", ".", "label", "!=", "new", ".", "label", ":", "\n", "                    ", "ious", "[", "old_idx", ",", "new_idx", "]", "=", "0", "\n", "\n", "", "", "", "matched_new_per_old", "=", "np", ".", "asarray", "(", "ious", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "max_iou_per_old", "=", "np", ".", "asarray", "(", "ious", ")", ".", "max", "(", "axis", "=", "1", ")", "\n", "\n", "# Try to find match for each old instance:", "\n", "extra_instances", "=", "[", "]", "\n", "for", "idx", ",", "inst", "in", "enumerate", "(", "self", ".", "_old_instances", ")", ":", "\n", "            ", "if", "max_iou_per_old", "[", "idx", "]", ">", "threshold", ":", "\n", "                ", "newidx", "=", "matched_new_per_old", "[", "idx", "]", "\n", "if", "instances", "[", "newidx", "]", ".", "color", "is", "None", ":", "\n", "                    ", "instances", "[", "newidx", "]", ".", "color", "=", "inst", ".", "color", "\n", "continue", "\n", "# If an old instance does not match any new instances,", "\n", "# keep it for the next frame in case it is just missed by the detector", "\n", "", "", "inst", ".", "ttl", "-=", "1", "\n", "if", "inst", ".", "ttl", ">", "0", ":", "\n", "                ", "extra_instances", ".", "append", "(", "inst", ")", "\n", "\n", "# Assign random color to newly-detected instances:", "\n", "", "", "for", "inst", "in", "instances", ":", "\n", "            ", "if", "inst", ".", "color", "is", "None", ":", "\n", "                ", "inst", ".", "color", "=", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "", "", "self", ".", "_old_instances", "=", "instances", "[", ":", "]", "+", "extra_instances", "\n", "return", "[", "d", ".", "color", "for", "d", "in", "instances", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.analysis.FlopCountAnalysis.__init__": [[57, 66], ["detectron2.export.TracingAdapter", "super().__init__", "analysis.FlopCountAnalysis.set_op_handle"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model (nn.Module):\n            inputs (Any): inputs of the given model. Does not have to be tuple of tensors.\n        \"\"\"", "\n", "wrapper", "=", "TracingAdapter", "(", "model", ",", "inputs", ",", "allow_non_tensor", "=", "True", ")", "\n", "super", "(", ")", ".", "__init__", "(", "wrapper", ",", "wrapper", ".", "flattened_inputs", ")", "\n", "self", ".", "set_op_handle", "(", "**", "{", "k", ":", "None", "for", "k", "in", "_IGNORED_OPS", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.analysis.flop_count_operators": [[68, 98], ["model.eval", "FlopCountAnalysis().by_operator", "model.train", "analysis.FlopCountAnalysis", "FlopCountAnalysis().by_operator.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train"], ["", "", "def", "flop_count_operators", "(", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Implement operator-level flops counting using jit.\n    This is a wrapper of :func:`fvcore.nn.flop_count` and adds supports for standard\n    detection models in detectron2.\n    Please use :class:`FlopCountAnalysis` for more advanced functionalities.\n\n    Note:\n        The function runs the input through the model to compute flops.\n        The flops of a detection model is often input-dependent, for example,\n        the flops of box & mask head depends on the number of proposals &\n        the number of detected objects.\n        Therefore, the flops counting using a single input may not accurately\n        reflect the computation cost of a model. It's recommended to average\n        across a number of inputs.\n\n    Args:\n        model: a detectron2 model that takes `list[dict]` as input.\n        inputs (list[dict]): inputs to model, in detectron2's standard format.\n            Only \"image\" key will be used.\n        supported_ops (dict[str, Handle]): see documentation of :func:`fvcore.nn.flop_count`\n\n    Returns:\n        Counter: Gflop count per operator\n    \"\"\"", "\n", "old_train", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "ret", "=", "FlopCountAnalysis", "(", "model", ",", "inputs", ")", ".", "by_operator", "(", ")", "\n", "model", ".", "train", "(", "old_train", ")", "\n", "return", "{", "k", ":", "v", "/", "1e9", "for", "k", ",", "v", "in", "ret", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.analysis.activation_count_operators": [[100, 123], ["analysis._wrapper_count_operators"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.analysis._wrapper_count_operators"], ["", "def", "activation_count_operators", "(", "\n", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ",", "**", "kwargs", "\n", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Implement operator-level activations counting using jit.\n    This is a wrapper of fvcore.nn.activation_count, that supports standard detection models\n    in detectron2.\n\n    Note:\n        The function runs the input through the model to compute activations.\n        The activations of a detection model is often input-dependent, for example,\n        the activations of box & mask head depends on the number of proposals &\n        the number of detected objects.\n\n    Args:\n        model: a detectron2 model that takes `list[dict]` as input.\n        inputs (list[dict]): inputs to model, in detectron2's standard format.\n            Only \"image\" key will be used.\n\n    Returns:\n        Counter: activation count per operator\n    \"\"\"", "\n", "return", "_wrapper_count_operators", "(", "model", "=", "model", ",", "inputs", "=", "inputs", ",", "mode", "=", "ACTIVATIONS_MODE", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.analysis._wrapper_count_operators": [[125, 153], ["supported_ops.update", "isinstance", "detectron2.export.TracingAdapter", "detectron2.export.TracingAdapter.eval", "isinstance", "model.train", "kwargs.pop", "len", "fvcore.nn.flop_count", "fvcore.nn.activation_count", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train"], ["", "def", "_wrapper_count_operators", "(", "\n", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ",", "mode", ":", "str", ",", "**", "kwargs", "\n", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "# ignore some ops", "\n", "    ", "supported_ops", "=", "{", "k", ":", "lambda", "*", "args", ",", "**", "kwargs", ":", "{", "}", "for", "k", "in", "_IGNORED_OPS", "}", "\n", "supported_ops", ".", "update", "(", "kwargs", ".", "pop", "(", "\"supported_ops\"", ",", "{", "}", ")", ")", "\n", "kwargs", "[", "\"supported_ops\"", "]", "=", "supported_ops", "\n", "\n", "assert", "len", "(", "inputs", ")", "==", "1", ",", "\"Please use batch size=1\"", "\n", "tensor_input", "=", "inputs", "[", "0", "]", "[", "\"image\"", "]", "\n", "inputs", "=", "[", "{", "\"image\"", ":", "tensor_input", "}", "]", "# remove other keys, in case there are any", "\n", "\n", "old_train", "=", "model", ".", "training", "\n", "if", "isinstance", "(", "model", ",", "(", "nn", ".", "parallel", ".", "distributed", ".", "DistributedDataParallel", ",", "nn", ".", "DataParallel", ")", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "wrapper", "=", "TracingAdapter", "(", "model", ",", "inputs", ")", "\n", "wrapper", ".", "eval", "(", ")", "\n", "if", "mode", "==", "FLOPS_MODE", ":", "\n", "        ", "ret", "=", "flop_count", "(", "wrapper", ",", "(", "tensor_input", ",", ")", ",", "**", "kwargs", ")", "\n", "", "elif", "mode", "==", "ACTIVATIONS_MODE", ":", "\n", "        ", "ret", "=", "activation_count", "(", "wrapper", ",", "(", "tensor_input", ",", ")", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Count for mode {} is not supported yet.\"", ".", "format", "(", "mode", ")", ")", "\n", "# compatible with change in fvcore", "\n", "", "if", "isinstance", "(", "ret", ",", "tuple", ")", ":", "\n", "        ", "ret", "=", "ret", "[", "0", "]", "\n", "", "model", ".", "train", "(", "old_train", ")", "\n", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._ColorfulFormatter.__init__": [[19, 25], ["kwargs.pop", "len", "logging.Formatter.__init__", "kwargs.pop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["if", "save_dir", ":", "\n", "        ", "fh", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "filename", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "", "return", "logger", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._ColorfulFormatter.formatMessage": [[26, 36], ["record.name.replace", "super().formatMessage", "termcolor.colored", "termcolor.colored"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._ColorfulFormatter.formatMessage"], ["", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._cached_log_stream": [[104, 110], ["functools.lru_cache", "detectron2.utils.file_io.PathManager.open", "atexit.register"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._find_caller": [[119, 134], ["sys._getframe", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_first_n": [[140, 173], ["isinstance", "logger._find_caller", "len", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._find_caller"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_every_n": [[175, 189], ["logger._find_caller", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._find_caller"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_every_n_seconds": [[191, 207], ["logger._find_caller", "_LOG_TIMER.get", "time.time", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._find_caller", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.create_small_table": [[209, 230], ["tuple", "tabulate.tabulate", "zip", "small_dict.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._log_api_usage": [[232, 238], ["torch._C._log_api_usage_once"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry._convert_target_to_string": [[15, 20], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry.locate": [[22, 43], ["pydoc.locate", "get_method", "ImportError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry.locate"], ["\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Registry", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "register", "(", "self", ",", "module_name", ",", "module", "=", "None", ")", ":", "\n", "# used as function call", "\n", "        ", "if", "module", "is", "not", "None", ":", "\n", "            ", "_register_generic", "(", "self", ",", "module_name", ",", "module", ")", "\n", "return", "\n", "\n", "# used as decorator", "\n", "", "def", "register_fn", "(", "fn", ")", ":", "\n", "            ", "_register_generic", "(", "self", ",", "module_name", ",", "fn", ")", "\n", "return", "fn", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.collect_torch_env": [[17, 27], ["torch.__config__.show", "get_pretty_env_info"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.get_env_module": [[29, 32], ["os.environ.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.detect_compute_compatibility": [[34, 53], ["os.path.join", "os.path.isfile", "subprocess.check_output", "output.decode().strip().split.decode().strip().split", "sorted", "sorted.append", "set", "output.decode().strip().split.decode().strip", "re.findall", "output.decode().strip().split.decode"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.get_model_no_weights": [[19, 27], ["detectron2.model_zoo.get_config", "detectron2.modeling.build_model", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model"], ["def", "get_model_no_weights", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Like model_zoo.get, but do not load any weights (even pretrained)\n    \"\"\"", "\n", "cfg", "=", "model_zoo", ".", "get_config", "(", "config_path", ")", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cpu\"", "\n", "", "return", "build_model", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.random_boxes": [[29, 41], ["boxes.clamp_", "torch.rand"], "function", ["None"], ["", "def", "random_boxes", "(", "num_boxes", ",", "max_coord", "=", "100", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "\"\"\"\n    Create a random Nx4 boxes tensor, with coordinates < max_coord.\n    \"\"\"", "\n", "boxes", "=", "torch", ".", "rand", "(", "num_boxes", ",", "4", ",", "device", "=", "device", ")", "*", "(", "max_coord", "*", "0.5", ")", "\n", "boxes", ".", "clamp_", "(", "min", "=", "1.0", ")", "# tiny boxes cause numerical instability in box regression", "\n", "# Note: the implementation of this function in torchvision is:", "\n", "# boxes[:, 2:] += torch.rand(N, 2) * 100", "\n", "# but it does not guarantee non-negative widths/heights constraints:", "\n", "# boxes[:, 2] >= boxes[:, 0] and boxes[:, 3] >= boxes[:, 1]:", "\n", "boxes", "[", ":", ",", "2", ":", "]", "+=", "boxes", "[", ":", ",", ":", "2", "]", "\n", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.get_sample_coco_image": [[43, 63], ["detectron2.data.detection_utils.read_image", "torch.from_numpy", "detectron2.utils.file_io.PathManager.exists", "FileNotFoundError", "numpy.ascontiguousarray", "detectron2.data.DatasetCatalog.get", "torch.from_numpy.transpose"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "get_sample_coco_image", "(", "tensor", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        tensor (bool): if True, returns 3xHxW tensor.\n            else, returns a HxWx3 numpy array.\n\n    Returns:\n        an image, in BGR color.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "file_name", "=", "DatasetCatalog", ".", "get", "(", "\"coco_2017_val_100\"", ")", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "if", "not", "PathManager", ".", "exists", "(", "file_name", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# for public CI to run", "\n", "        ", "file_name", "=", "\"http://images.cocodataset.org/train2017/000000000009.jpg\"", "\n", "", "ret", "=", "read_image", "(", "file_name", ",", "format", "=", "\"BGR\"", ")", "\n", "if", "tensor", ":", "\n", "        ", "ret", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "ret", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.convert_scripted_instances": [[65, 75], ["detectron2.structures.Instances", "getattr", "detectron2.structures.Instances.set"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "def", "convert_scripted_instances", "(", "instances", ")", ":", "\n", "    ", "\"\"\"\n    Convert a scripted Instances object to a regular :class:`Instances` object\n    \"\"\"", "\n", "ret", "=", "Instances", "(", "instances", ".", "image_size", ")", "\n", "for", "name", "in", "instances", ".", "_field_names", ":", "\n", "        ", "val", "=", "getattr", "(", "instances", ",", "\"_\"", "+", "name", ",", "None", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "            ", "ret", ".", "set", "(", "name", ",", "val", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.assert_instances_allclose": [[77, 122], ["sorted", "sorted", "isinstance", "testing.convert_scripted_instances", "isinstance", "testing.convert_scripted_instances", "torch.equal", "convert_scripted_instances.get_fields().keys", "convert_scripted_instances.get_fields().keys", "isinstance", "msg.rstrip", "torch.tensor", "torch.tensor", "convert_scripted_instances.get", "convert_scripted_instances.get", "torch.allclose", "isinstance", "convert_scripted_instances.get_fields", "convert_scripted_instances.get_fields", "ValueError", "torch.abs().max().cpu().item", "torch.allclose", "torch.equal", "torch.abs().max().cpu", "type", "torch.abs().max", "torch.abs"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.convert_scripted_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.convert_scripted_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields"], ["", "def", "assert_instances_allclose", "(", "input", ",", "other", ",", "*", ",", "rtol", "=", "1e-5", ",", "msg", "=", "\"\"", ",", "size_as_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input, other (Instances):\n        size_as_tensor: compare image_size of the Instances as tensors (instead of tuples).\n             Useful for comparing outputs of tracing.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input", ",", "Instances", ")", ":", "\n", "        ", "input", "=", "convert_scripted_instances", "(", "input", ")", "\n", "", "if", "not", "isinstance", "(", "other", ",", "Instances", ")", ":", "\n", "        ", "other", "=", "convert_scripted_instances", "(", "other", ")", "\n", "\n", "", "if", "not", "msg", ":", "\n", "        ", "msg", "=", "\"Two Instances are different! \"", "\n", "", "else", ":", "\n", "        ", "msg", "=", "msg", ".", "rstrip", "(", ")", "+", "\" \"", "\n", "\n", "", "size_error_msg", "=", "msg", "+", "f\"image_size is {input.image_size} vs. {other.image_size}!\"", "\n", "if", "size_as_tensor", ":", "\n", "        ", "assert", "torch", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "input", ".", "image_size", ")", ",", "torch", ".", "tensor", "(", "other", ".", "image_size", ")", "\n", ")", ",", "size_error_msg", "\n", "", "else", ":", "\n", "        ", "assert", "input", ".", "image_size", "==", "other", ".", "image_size", ",", "size_error_msg", "\n", "", "fields", "=", "sorted", "(", "input", ".", "get_fields", "(", ")", ".", "keys", "(", ")", ")", "\n", "fields_other", "=", "sorted", "(", "other", ".", "get_fields", "(", ")", ".", "keys", "(", ")", ")", "\n", "assert", "fields", "==", "fields_other", ",", "msg", "+", "f\"Fields are {fields} vs {fields_other}!\"", "\n", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "val1", ",", "val2", "=", "input", ".", "get", "(", "f", ")", ",", "other", ".", "get", "(", "f", ")", "\n", "if", "isinstance", "(", "val1", ",", "Boxes", ")", ":", "\n", "# boxes in the range of O(100) and can have a larger tolerance", "\n", "            ", "assert", "torch", ".", "allclose", "(", "val1", ".", "tensor", ",", "val2", ".", "tensor", ",", "atol", "=", "100", "*", "rtol", ")", ",", "(", "\n", "msg", "+", "f\"Field {f} differs too much!\"", "\n", ")", "\n", "", "elif", "isinstance", "(", "val1", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "if", "val1", ".", "dtype", ".", "is_floating_point", ":", "\n", "                ", "mag", "=", "torch", ".", "abs", "(", "val1", ")", ".", "max", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "assert", "torch", ".", "allclose", "(", "val1", ",", "val2", ",", "atol", "=", "mag", "*", "rtol", ")", ",", "(", "\n", "msg", "+", "f\"Field {f} differs too much!\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "assert", "torch", ".", "equal", "(", "val1", ",", "val2", ")", ",", "msg", "+", "f\"Field {f} is different!\"", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Don't know how to compare type {type(val1)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.testing.reload_script_model": [[124, 133], ["io.BytesIO", "torch.jit.save", "io.BytesIO.seek", "torch.jit.load"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "", "", "def", "reload_script_model", "(", "module", ")", ":", "\n", "    ", "\"\"\"\n    Save a jit module and load it back.\n    Similar to the `getExportImportCopy` function in torch/testing/\n    \"\"\"", "\n", "buffer", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "jit", ".", "save", "(", "module", ",", "buffer", ")", "\n", "buffer", ".", "seek", "(", "0", ")", "\n", "return", "torch", ".", "jit", ".", "load", "(", "buffer", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.file_io.Detectron2Handler._get_supported_prefixes": [[24, 26], ["None"], "methods", ["None"], ["def", "_get_supported_prefixes", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "PREFIX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.file_io.Detectron2Handler._get_local_path": [[27, 30], ["iopath.common.file_io.PathManager.get_local_path", "len"], "methods", ["None"], ["", "def", "_get_local_path", "(", "self", ",", "path", ",", "**", "kwargs", ")", ":", "\n", "        ", "name", "=", "path", "[", "len", "(", "self", ".", "PREFIX", ")", ":", "]", "\n", "return", "PathManager", ".", "get_local_path", "(", "self", ".", "S3_DETECTRON2_PREFIX", "+", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.file_io.Detectron2Handler._open": [[31, 33], ["iopath.common.file_io.PathManager.open", "file_io.Detectron2Handler._get_local_path"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalogHandler._get_local_path"], ["", "def", "_open", "(", "self", ",", "path", ",", "mode", "=", "\"r\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "self", ".", "_get_local_path", "(", "path", ")", ",", "mode", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.seed_all_rng": [[27, 46], ["numpy.random.seed", "torch.manual_seed", "random.seed", "str", "logging.getLogger", "logging.getLogger.info", "int.from_bytes", "os.getpid", "int", "os.urandom", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], [")", ",", "(", "\n", "\"Custom environment module defined in {} does not have the \"", "\n", "\"required callable attribute 'setup_environment'.\"", "\n", ")", ".", "format", "(", "\n", "custom_module_path", "\n", ")", "\n", "module", ".", "setup_environment", "(", ")", "\n", "\n", "\n", "# Force environment setup when this module is imported", "\n", "", "setup_environment", "(", ")", "\n", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env._import_file": [[49, 56], ["importlib.util.spec_from_file_location", "importlib.util.spec_from_file_location", "importlib.util.module_from_spec", "importlib.util.module_from_spec", "importlib.util.spec_from_file_location.loader.exec_module"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env._configure_libraries": [[58, 91], ["int", "os.environ.get", "tuple", "env._configure_libraries.get_version"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detectron2.setup.get_version"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.fixup_module_metadata": [[135, 171], ["set", "set.add", "getattr", "namespace.keys", "id", "id", "isinstance", "objname.startswith", "env.fixup_module_metadata.fix_one"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory._ignore_torch_cuda_oom": [[11, 24], ["str"], "function", ["None"], ["@", "contextmanager", "\n", "def", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "    ", "\"\"\"\n    A context which ignores CUDA OOM exception from pytorch.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "# NOTE: the string may change?", "\n", "        ", "if", "\"CUDA out of memory. \"", "in", "str", "(", "e", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory.retry_if_cuda_oom": [[26, 85], ["functools.wraps", "torch.cuda.empty_cache", "logging.getLogger", "logging.getLogger.info", "func", "x.to", "memory._ignore_torch_cuda_oom", "func", "memory._ignore_torch_cuda_oom", "func", "memory.retry_if_cuda_oom.maybe_to_cpu"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory._ignore_torch_cuda_oom", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory._ignore_torch_cuda_oom"], ["", "", "", "def", "retry_if_cuda_oom", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Makes a function retry itself after encountering\n    pytorch's CUDA OOM error.\n    It will first retry after calling `torch.cuda.empty_cache()`.\n\n    If that still fails, it will then retry by trying to convert inputs to CPUs.\n    In this case, it expects the function to dispatch to CPU implementation.\n    The return values may become CPU tensors as well and it's user's\n    responsibility to convert it back to CUDA tensor if needed.\n\n    Args:\n        func: a stateless callable that takes tensor-like objects as arguments\n\n    Returns:\n        a callable which retries `func` if OOM is encountered.\n\n    Examples:\n    ::\n        output = retry_if_cuda_oom(some_torch_function)(input1, input2)\n        # output may be on CPU even if inputs are on GPU\n\n    Note:\n        1. When converting inputs to CPU, it will only look at each argument and check\n           if it has `.device` and `.to` for conversion. Nested structures of tensors\n           are not supported.\n\n        2. Since the function might be called more than once, it has to be\n           stateless.\n    \"\"\"", "\n", "\n", "def", "maybe_to_cpu", "(", "x", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "like_gpu_tensor", "=", "x", ".", "device", ".", "type", "==", "\"cuda\"", "and", "hasattr", "(", "x", ",", "\"to\"", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "like_gpu_tensor", "=", "False", "\n", "", "if", "like_gpu_tensor", ":", "\n", "            ", "return", "x", ".", "to", "(", "device", "=", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "@", "wraps", "(", "func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Clear cache and retry", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "with", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Try on CPU. This slows down the code significantly, therefore print a notice.", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Attempting to copy inputs of {} to CPU due to CUDA OOM\"", ".", "format", "(", "str", "(", "func", ")", ")", ")", "\n", "new_args", "=", "(", "maybe_to_cpu", "(", "x", ")", "for", "x", "in", "args", ")", "\n", "new_kwargs", "=", "{", "k", ":", "maybe_to_cpu", "(", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "}", "\n", "return", "func", "(", "*", "new_args", ",", "**", "new_kwargs", ")", "\n", "\n", "", "return", "wrapped", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.EntrySelector.from_string": [[10, 15], ["dbhelper.FieldEntrySelector", "dbhelper.AllEntrySelector"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "from_string", "(", "spec", ":", "str", ")", "->", "\"EntrySelector\"", ":", "\n", "        ", "if", "spec", "==", "\"*\"", ":", "\n", "            ", "return", "AllEntrySelector", "(", ")", "\n", "", "return", "FieldEntrySelector", "(", "spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.AllEntrySelector.__call__": [[24, 26], ["None"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "entry", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector.__init__": [[85, 87], ["dbhelper.FieldEntrySelector._parse_specifier_into_predicates"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_specifier_into_predicates"], ["", "", "def", "__init__", "(", "self", ",", "spec", ":", "str", ")", ":", "\n", "        ", "self", ".", "_predicates", "=", "self", ".", "_parse_specifier_into_predicates", "(", "spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector.__call__": [[88, 93], ["predicate"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "entry", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "for", "predicate", "in", "self", ".", "_predicates", ":", "\n", "            ", "if", "not", "predicate", "(", "entry", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_specifier_into_predicates": [[94, 118], ["spec.split", "subspec.find", "dbhelper.FieldEntrySelector._parse_field_name_type", "dbhelper.FieldEntrySelector._is_range_spec", "predicates.append", "dbhelper.FieldEntrySelector._get_range_spec", "FieldEntrySelector._FieldEntryRangePredicate", "FieldEntrySelector._FieldEntryValuePredicate", "dbhelper.FieldEntrySelector._parse_error", "dbhelper.FieldEntrySelector._parse_error"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_field_name_type", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._is_range_spec", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._get_range_spec", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_error", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_error"], ["", "def", "_parse_specifier_into_predicates", "(", "self", ",", "spec", ":", "str", ")", ":", "\n", "        ", "predicates", "=", "[", "]", "\n", "specs", "=", "spec", ".", "split", "(", "self", ".", "_SPEC_DELIM", ")", "\n", "for", "subspec", "in", "specs", ":", "\n", "            ", "eq_idx", "=", "subspec", ".", "find", "(", "self", ".", "_EQUAL", ")", "\n", "if", "eq_idx", ">", "0", ":", "\n", "                ", "field_name_with_type", "=", "subspec", "[", ":", "eq_idx", "]", "\n", "field_name", ",", "field_type", "=", "self", ".", "_parse_field_name_type", "(", "field_name_with_type", ")", "\n", "field_value_or_range", "=", "subspec", "[", "eq_idx", "+", "1", ":", "]", "\n", "if", "self", ".", "_is_range_spec", "(", "field_value_or_range", ")", ":", "\n", "                    ", "vmin", ",", "vmax", "=", "self", ".", "_get_range_spec", "(", "field_value_or_range", ")", "\n", "predicate", "=", "FieldEntrySelector", ".", "_FieldEntryRangePredicate", "(", "\n", "field_name", ",", "field_type", ",", "vmin", ",", "vmax", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "predicate", "=", "FieldEntrySelector", ".", "_FieldEntryValuePredicate", "(", "\n", "field_name", ",", "field_type", ",", "field_value_or_range", "\n", ")", "\n", "", "predicates", ".", "append", "(", "predicate", ")", "\n", "", "elif", "eq_idx", "==", "0", ":", "\n", "                ", "self", ".", "_parse_error", "(", "f'\"{subspec}\", field name is empty!'", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_parse_error", "(", "f'\"{subspec}\", should have format '", "\"<field>=<value_or_range>!\"", ")", "\n", "", "", "return", "predicates", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_field_name_type": [[119, 130], ["field_name_with_type.find", "dbhelper.FieldEntrySelector._parse_error"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_error"], ["", "def", "_parse_field_name_type", "(", "self", ",", "field_name_with_type", ":", "str", ")", "->", "Tuple", "[", "str", ",", "Optional", "[", "str", "]", "]", ":", "\n", "        ", "type_delim_idx", "=", "field_name_with_type", ".", "find", "(", "self", ".", "_TYPE_DELIM", ")", "\n", "if", "type_delim_idx", ">", "0", ":", "\n", "            ", "field_name", "=", "field_name_with_type", "[", ":", "type_delim_idx", "]", "\n", "field_type", "=", "field_name_with_type", "[", "type_delim_idx", "+", "1", ":", "]", "\n", "", "elif", "type_delim_idx", "==", "0", ":", "\n", "            ", "self", ".", "_parse_error", "(", "f'\"{field_name_with_type}\", field name is empty!'", ")", "\n", "", "else", ":", "\n", "            ", "field_name", "=", "field_name_with_type", "\n", "field_type", "=", "None", "\n", "", "return", "field_name", ",", "field_type", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._is_range_spec": [[131, 134], ["field_value_or_range.find"], "methods", ["None"], ["", "def", "_is_range_spec", "(", "self", ",", "field_value_or_range", ")", ":", "\n", "        ", "delim_idx", "=", "field_value_or_range", ".", "find", "(", "self", ".", "_RANGE_DELIM", ")", "\n", "return", "delim_idx", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._get_range_spec": [[135, 143], ["dbhelper.FieldEntrySelector._is_range_spec", "field_value_or_range.find", "dbhelper.FieldEntrySelector._parse_error"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._is_range_spec", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_error"], ["", "def", "_get_range_spec", "(", "self", ",", "field_value_or_range", ")", ":", "\n", "        ", "if", "self", ".", "_is_range_spec", "(", "field_value_or_range", ")", ":", "\n", "            ", "delim_idx", "=", "field_value_or_range", ".", "find", "(", "self", ".", "_RANGE_DELIM", ")", "\n", "vmin", "=", "field_value_or_range", "[", ":", "delim_idx", "]", "\n", "vmax", "=", "field_value_or_range", "[", "delim_idx", "+", "1", ":", "]", "\n", "return", "vmin", ",", "vmax", "\n", "", "else", ":", "\n", "            ", "self", ".", "_parse_error", "(", "'\"field_value_or_range\", range of values expected!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.FieldEntrySelector._parse_error": [[144, 146], ["ValueError"], "methods", ["None"], ["", "", "def", "_parse_error", "(", "self", ",", "msg", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{self._ERROR_PREFIX}: {msg}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.verbosity_to_level": [[5, 14], ["None"], "function", ["None"], ["\n", "\n", "def", "setup_logger", "(", "name", ",", "save_dir", ",", "distributed_rank", ",", "filename", "=", "\"log.txt\"", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "# don't log results for the non-master process", "\n", "if", "distributed_rank", ">", "0", ":", "\n", "        ", "return", "logger", "\n", "", "ch", "=", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.transform.load_for_dataset": [[8, 12], ["detectron2.utils.file_io.PathManager.get_local_path", "densepose.DensePoseTransformData.load", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "import", "numpy", "as", "np", "\n", "import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fvcore", ".", "transforms", ".", "transform", "import", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.transform.load_from_cfg": [[14, 16], ["transform.load_for_dataset"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.transform.load_for_dataset"], ["HFlipTransform", ",", "\n", "NoOpTransform", ",", "\n", "Transform", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_pytorch_1_1_0_or_later": [[120, 122], ["int", "torch.__version__.split", "torch.__version__.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_coder.BoxCoder.__init__": [[13, 21], ["math.log"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "weights", ",", "bbox_xform_clip", "=", "math", ".", "log", "(", "1000.", "/", "16", ")", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            weights (4-element tuple)\n            bbox_xform_clip (float)\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "bbox_xform_clip", "=", "bbox_xform_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_coder.BoxCoder.encode": [[22, 51], ["torch.stack", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "reference_boxes", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Encode a set of proposals with respect to some\n        reference boxes\n\n        Arguments:\n            reference_boxes (Tensor): reference boxes\n            proposals (Tensor): boxes to be encoded\n        \"\"\"", "\n", "\n", "TO_REMOVE", "=", "1", "# TODO remove", "\n", "ex_widths", "=", "proposals", "[", ":", ",", "2", "]", "-", "proposals", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "ex_heights", "=", "proposals", "[", ":", ",", "3", "]", "-", "proposals", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "ex_ctr_x", "=", "proposals", "[", ":", ",", "0", "]", "+", "0.5", "*", "ex_widths", "\n", "ex_ctr_y", "=", "proposals", "[", ":", ",", "1", "]", "+", "0.5", "*", "ex_heights", "\n", "\n", "gt_widths", "=", "reference_boxes", "[", ":", ",", "2", "]", "-", "reference_boxes", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "gt_heights", "=", "reference_boxes", "[", ":", ",", "3", "]", "-", "reference_boxes", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "gt_ctr_x", "=", "reference_boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "gt_widths", "\n", "gt_ctr_y", "=", "reference_boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "gt_heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "weights", "\n", "targets_dx", "=", "wx", "*", "(", "gt_ctr_x", "-", "ex_ctr_x", ")", "/", "ex_widths", "\n", "targets_dy", "=", "wy", "*", "(", "gt_ctr_y", "-", "ex_ctr_y", ")", "/", "ex_heights", "\n", "targets_dw", "=", "ww", "*", "torch", ".", "log", "(", "gt_widths", "/", "ex_widths", ")", "\n", "targets_dh", "=", "wh", "*", "torch", ".", "log", "(", "gt_heights", "/", "ex_heights", ")", "\n", "\n", "targets", "=", "torch", ".", "stack", "(", "(", "targets_dx", ",", "targets_dy", ",", "targets_dw", ",", "targets_dh", ")", ",", "dim", "=", "1", ")", "\n", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_coder.BoxCoder.decode": [[52, 96], ["boxes.to.to.to", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "decode", "(", "self", ",", "rel_codes", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        From a set of original boxes and encoded relative box offsets,\n        get the decoded boxes.\n\n        Arguments:\n            rel_codes (Tensor): encoded boxes\n            boxes (Tensor): reference boxes.\n        \"\"\"", "\n", "\n", "boxes", "=", "boxes", ".", "to", "(", "rel_codes", ".", "dtype", ")", "\n", "\n", "TO_REMOVE", "=", "1", "# TODO remove", "\n", "widths", "=", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "heights", "=", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "ctr_x", "=", "boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "widths", "\n", "ctr_y", "=", "boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "weights", "\n", "dx", "=", "rel_codes", "[", ":", ",", "0", ":", ":", "4", "]", "/", "wx", "\n", "dy", "=", "rel_codes", "[", ":", ",", "1", ":", ":", "4", "]", "/", "wy", "\n", "dw", "=", "rel_codes", "[", ":", ",", "2", ":", ":", "4", "]", "/", "ww", "\n", "dh", "=", "rel_codes", "[", ":", ",", "3", ":", ":", "4", "]", "/", "wh", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "self", ".", "bbox_xform_clip", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "self", ".", "bbox_xform_clip", ")", "\n", "\n", "pred_ctr_x", "=", "dx", "*", "widths", "[", ":", ",", "None", "]", "+", "ctr_x", "[", ":", ",", "None", "]", "\n", "pred_ctr_y", "=", "dy", "*", "heights", "[", ":", ",", "None", "]", "+", "ctr_y", "[", ":", ",", "None", "]", "\n", "pred_w", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "[", ":", ",", "None", "]", "\n", "pred_h", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "[", ":", ",", "None", "]", "\n", "\n", "pred_boxes", "=", "torch", ".", "zeros_like", "(", "rel_codes", ")", "\n", "# x1", "\n", "pred_boxes", "[", ":", ",", "0", ":", ":", "4", "]", "=", "pred_ctr_x", "-", "0.5", "*", "pred_w", "\n", "# y1", "\n", "pred_boxes", "[", ":", ",", "1", ":", ":", "4", "]", "=", "pred_ctr_y", "-", "0.5", "*", "pred_h", "\n", "# x2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)", "\n", "pred_boxes", "[", ":", ",", "2", ":", ":", "4", "]", "=", "pred_ctr_x", "+", "0.5", "*", "pred_w", "-", "1", "\n", "# y2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)", "\n", "pred_boxes", "[", ":", ",", "3", ":", ":", "4", "]", "=", "pred_ctr_y", "+", "0.5", "*", "pred_h", "-", "1", "\n", "\n", "return", "pred_boxes", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.balanced_positive_negative_sampler.BalancedPositiveNegativeSampler.__init__": [[10, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size_per_image", ",", "positive_fraction", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            batch_size_per_image (int): number of elements to be selected per image\n            positive_fraction (float): percentage of positive elements per batch\n        \"\"\"", "\n", "self", ".", "batch_size_per_image", "=", "batch_size_per_image", "\n", "self", ".", "positive_fraction", "=", "positive_fraction", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.balanced_positive_negative_sampler.BalancedPositiveNegativeSampler.__call__": [[19, 69], ["torch.nonzero().squeeze", "torch.nonzero().squeeze", "int", "min", "min", "torch.zeros_like", "torch.zeros_like", "pos_idx.append", "neg_idx.append", "torch.nonzero().squeeze.numel", "torch.nonzero().squeeze.numel", "torch.randperm", "torch.randperm", "torch.nonzero", "torch.nonzero", "torch.nonzero().squeeze.numel", "torch.nonzero().squeeze.numel"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "matched_idxs", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            matched idxs: list of tensors containing -1, 0 or positive values.\n                Each tensor corresponds to a specific image.\n                -1 values are ignored, 0 are considered as negatives and > 0 as\n                positives.\n\n        Returns:\n            pos_idx (list[tensor])\n            neg_idx (list[tensor])\n\n        Returns two lists of binary masks for each image.\n        The first list contains the positive elements that were selected,\n        and the second list the negative example.\n        \"\"\"", "\n", "pos_idx", "=", "[", "]", "\n", "neg_idx", "=", "[", "]", "\n", "for", "matched_idxs_per_image", "in", "matched_idxs", ":", "\n", "            ", "positive", "=", "torch", ".", "nonzero", "(", "matched_idxs_per_image", ">=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "negative", "=", "torch", ".", "nonzero", "(", "matched_idxs_per_image", "==", "0", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "num_pos", "=", "int", "(", "self", ".", "batch_size_per_image", "*", "self", ".", "positive_fraction", ")", "\n", "# protect against not enough positive examples", "\n", "num_pos", "=", "min", "(", "positive", ".", "numel", "(", ")", ",", "num_pos", ")", "\n", "num_neg", "=", "self", ".", "batch_size_per_image", "-", "num_pos", "\n", "# protect against not enough negative examples", "\n", "num_neg", "=", "min", "(", "negative", ".", "numel", "(", ")", ",", "num_neg", ")", "\n", "\n", "# randomly select positive and negative examples", "\n", "perm1", "=", "torch", ".", "randperm", "(", "positive", ".", "numel", "(", ")", ",", "device", "=", "positive", ".", "device", ")", "[", ":", "num_pos", "]", "\n", "perm2", "=", "torch", ".", "randperm", "(", "negative", ".", "numel", "(", ")", ",", "device", "=", "negative", ".", "device", ")", "[", ":", "num_neg", "]", "\n", "\n", "pos_idx_per_image", "=", "positive", "[", "perm1", "]", "\n", "neg_idx_per_image", "=", "negative", "[", "perm2", "]", "\n", "\n", "# create binary mask from indices", "\n", "pos_idx_per_image_mask", "=", "torch", ".", "zeros_like", "(", "\n", "matched_idxs_per_image", ",", "dtype", "=", "torch", ".", "bool", "\n", ")", "\n", "neg_idx_per_image_mask", "=", "torch", ".", "zeros_like", "(", "\n", "matched_idxs_per_image", ",", "dtype", "=", "torch", ".", "bool", "\n", ")", "\n", "pos_idx_per_image_mask", "[", "pos_idx_per_image", "]", "=", "1", "\n", "neg_idx_per_image_mask", "[", "neg_idx_per_image", "]", "=", "1", "\n", "\n", "pos_idx", ".", "append", "(", "pos_idx_per_image_mask", ")", "\n", "neg_idx", ".", "append", "(", "neg_idx_per_image_mask", ")", "\n", "\n", "", "return", "pos_idx", ",", "neg_idx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.matcher.Matcher.__init__": [[23, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "high_threshold", ",", "low_threshold", ",", "allow_low_quality_matches", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            high_threshold (float): quality values greater than or equal to\n                this value are candidate matches.\n            low_threshold (float): a lower quality threshold used to stratify\n                matches into three levels:\n                1) matches >= high_threshold\n                2) BETWEEN_THRESHOLDS matches in [low_threshold, high_threshold)\n                3) BELOW_LOW_THRESHOLD matches in [0, low_threshold)\n            allow_low_quality_matches (bool): if True, produce additional matches\n                for predictions that have only low-quality match candidates. See\n                set_low_quality_matches_ for more details.\n        \"\"\"", "\n", "assert", "low_threshold", "<=", "high_threshold", "\n", "self", ".", "high_threshold", "=", "high_threshold", "\n", "self", ".", "low_threshold", "=", "low_threshold", "\n", "self", ".", "allow_low_quality_matches", "=", "allow_low_quality_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.matcher.Matcher.__call__": [[42, 82], ["match_quality_matrix.max", "match_quality_matrix.numel", "matches.clone", "matcher.Matcher.set_low_quality_matches_", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.matcher.Matcher.set_low_quality_matches_"], ["", "def", "__call__", "(", "self", ",", "match_quality_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            match_quality_matrix (Tensor[float]): an MxN tensor, containing the\n            pairwise quality between M ground-truth elements and N predicted elements.\n\n        Returns:\n            matches (Tensor[int64]): an N tensor where N[i] is a matched gt in\n            [0, M - 1] or a negative value indicating that prediction i could not\n            be matched.\n        \"\"\"", "\n", "if", "match_quality_matrix", ".", "numel", "(", ")", "==", "0", ":", "\n", "# empty targets or proposals not supported during training", "\n", "            ", "if", "match_quality_matrix", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"No ground-truth boxes available for one of the images \"", "\n", "\"during training\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"No proposal boxes available for one of the images \"", "\n", "\"during training\"", ")", "\n", "\n", "# match_quality_matrix is M (gt) x N (predicted)", "\n", "# Max over gt elements (dim 0) to find best gt candidate for each prediction", "\n", "", "", "matched_vals", ",", "matches", "=", "match_quality_matrix", ".", "max", "(", "dim", "=", "0", ")", "\n", "if", "self", ".", "allow_low_quality_matches", ":", "\n", "            ", "all_matches", "=", "matches", ".", "clone", "(", ")", "\n", "\n", "# Assign candidate matches with low quality to negative (unassigned) values", "\n", "", "below_low_threshold", "=", "matched_vals", "<", "self", ".", "low_threshold", "\n", "between_thresholds", "=", "(", "matched_vals", ">=", "self", ".", "low_threshold", ")", "&", "(", "\n", "matched_vals", "<", "self", ".", "high_threshold", "\n", ")", "\n", "matches", "[", "below_low_threshold", "]", "=", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "matches", "[", "between_thresholds", "]", "=", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "\n", "if", "self", ".", "allow_low_quality_matches", ":", "\n", "            ", "self", ".", "set_low_quality_matches_", "(", "matches", ",", "all_matches", ",", "match_quality_matrix", ")", "\n", "\n", "", "return", "matches", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.matcher.Matcher.set_low_quality_matches_": [[83, 113], ["match_quality_matrix.max", "torch.nonzero"], "methods", ["None"], ["", "def", "set_low_quality_matches_", "(", "self", ",", "matches", ",", "all_matches", ",", "match_quality_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Produce additional matches for predictions that have only low-quality matches.\n        Specifically, for each ground-truth find the set of predictions that have\n        maximum overlap with it (including ties); for each prediction in that set, if\n        it is unmatched, then match it to the ground-truth with which it has the highest\n        quality value.\n        \"\"\"", "\n", "# For each gt, find the prediction with which it has highest quality", "\n", "highest_quality_foreach_gt", ",", "_", "=", "match_quality_matrix", ".", "max", "(", "dim", "=", "1", ")", "\n", "# Find highest quality match available, even if it is low, including ties", "\n", "gt_pred_pairs_of_highest_quality", "=", "torch", ".", "nonzero", "(", "\n", "match_quality_matrix", "==", "highest_quality_foreach_gt", "[", ":", ",", "None", "]", "\n", ")", "\n", "# Example gt_pred_pairs_of_highest_quality:", "\n", "#   tensor([[    0, 39796],", "\n", "#           [    1, 32055],", "\n", "#           [    1, 32070],", "\n", "#           [    2, 39190],", "\n", "#           [    2, 40255],", "\n", "#           [    3, 40390],", "\n", "#           [    3, 41455],", "\n", "#           [    4, 45470],", "\n", "#           [    5, 45325],", "\n", "#           [    5, 46390]])", "\n", "# Each row is a (gt index, prediction index)", "\n", "# Note how gt items 1, 2, 3, and 5 each have two ties", "\n", "\n", "pred_inds_to_update", "=", "gt_pred_pairs_of_highest_quality", "[", ":", ",", "1", "]", "\n", "matches", "[", "pred_inds_to_update", "]", "=", "all_matches", "[", "pred_inds_to_update", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.LevelMapper.__init__": [[16, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "k_min", ",", "k_max", ",", "canonical_scale", "=", "224", ",", "canonical_level", "=", "4", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            k_min (int)\n            k_max (int)\n            canonical_scale (int)\n            canonical_level (int)\n            eps (float)\n        \"\"\"", "\n", "self", ".", "k_min", "=", "k_min", "\n", "self", ".", "k_max", "=", "k_max", "\n", "self", ".", "s0", "=", "canonical_scale", "\n", "self", ".", "lvl0", "=", "canonical_level", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.LevelMapper.__call__": [[31, 43], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "utils.cat", "torch.clamp.to", "torch.clamp.to", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "boxlist.area"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area"], ["", "def", "__call__", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            boxlists (list[BoxList])\n        \"\"\"", "\n", "# Compute level ids", "\n", "s", "=", "torch", ".", "sqrt", "(", "cat", "(", "[", "boxlist", ".", "area", "(", ")", "for", "boxlist", "in", "boxlists", "]", ")", ")", "\n", "\n", "# Eqn.(1) in FPN paper", "\n", "target_lvls", "=", "torch", ".", "floor", "(", "self", ".", "lvl0", "+", "torch", ".", "log2", "(", "s", "/", "self", ".", "s0", "+", "self", ".", "eps", ")", ")", "\n", "target_lvls", "=", "torch", ".", "clamp", "(", "target_lvls", ",", "min", "=", "self", ".", "k_min", ",", "max", "=", "self", ".", "k_max", ")", "\n", "return", "target_lvls", ".", "to", "(", "torch", ".", "int64", ")", "-", "self", ".", "k_min", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.Pooler.__init__": [[55, 77], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "poolers.LevelMapper", "poolers.append", "torch.log2().item", "torch.log2().item", "torch.log2().item", "torch.log2().item", "torch.log2().item", "torch.log2().item", "torch.log2().item", "torch.log2().item", "fcos_core.layers.ROIAlign", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "scales", ",", "sampling_ratio", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            output_size (list[tuple[int]] or list[int]): output size for the pooled region\n            scales (list[float]): scales for each Pooler\n            sampling_ratio (int): sampling ratio for ROIAlign\n        \"\"\"", "\n", "super", "(", "Pooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "poolers", "=", "[", "]", "\n", "for", "scale", "in", "scales", ":", "\n", "            ", "poolers", ".", "append", "(", "\n", "ROIAlign", "(", "\n", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", "\n", ")", "\n", ")", "\n", "", "self", ".", "poolers", "=", "nn", ".", "ModuleList", "(", "poolers", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "# get the levels in the feature map by leveraging the fact that the network always", "\n", "# downsamples by a factor of 2 at each level.", "\n", "lvl_min", "=", "-", "torch", ".", "log2", "(", "torch", ".", "tensor", "(", "scales", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", ".", "item", "(", ")", "\n", "lvl_max", "=", "-", "torch", ".", "log2", "(", "torch", ".", "tensor", "(", "scales", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "map_levels", "=", "LevelMapper", "(", "lvl_min", ",", "lvl_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.Pooler.convert_to_roi_format": [[78, 90], ["utils.cat", "utils.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full", "torch.full", "torch.full", "torch.full", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "convert_to_roi_format", "(", "self", ",", "boxes", ")", ":", "\n", "        ", "concat_boxes", "=", "cat", "(", "[", "b", ".", "bbox", "for", "b", "in", "boxes", "]", ",", "dim", "=", "0", ")", "\n", "device", ",", "dtype", "=", "concat_boxes", ".", "device", ",", "concat_boxes", ".", "dtype", "\n", "ids", "=", "cat", "(", "\n", "[", "\n", "torch", ".", "full", "(", "(", "len", "(", "b", ")", ",", "1", ")", ",", "i", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "boxes", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "rois", "=", "torch", ".", "cat", "(", "[", "ids", ",", "concat_boxes", "]", ",", "dim", "=", "1", ")", "\n", "return", "rois", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.Pooler.forward": [[91, 122], ["len", "poolers.Pooler.convert_to_roi_format", "poolers.Pooler.map_levels", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "zip", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "pooler", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.Pooler.convert_to_roi_format"], ["", "def", "forward", "(", "self", ",", "x", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            x (list[Tensor]): feature maps for each level\n            boxes (list[BoxList]): boxes to be used to perform the pooling operation.\n        Returns:\n            result (Tensor)\n        \"\"\"", "\n", "num_levels", "=", "len", "(", "self", ".", "poolers", ")", "\n", "rois", "=", "self", ".", "convert_to_roi_format", "(", "boxes", ")", "\n", "if", "num_levels", "==", "1", ":", "\n", "            ", "return", "self", ".", "poolers", "[", "0", "]", "(", "x", "[", "0", "]", ",", "rois", ")", "\n", "\n", "", "levels", "=", "self", ".", "map_levels", "(", "boxes", ")", "\n", "\n", "num_rois", "=", "len", "(", "rois", ")", "\n", "num_channels", "=", "x", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "output_size", "=", "self", ".", "output_size", "[", "0", "]", "\n", "\n", "dtype", ",", "device", "=", "x", "[", "0", "]", ".", "dtype", ",", "x", "[", "0", "]", ".", "device", "\n", "result", "=", "torch", ".", "zeros", "(", "\n", "(", "num_rois", ",", "num_channels", ",", "output_size", ",", "output_size", ")", ",", "\n", "dtype", "=", "dtype", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "for", "level", ",", "(", "per_level_feature", ",", "pooler", ")", "in", "enumerate", "(", "zip", "(", "x", ",", "self", ".", "poolers", ")", ")", ":", "\n", "            ", "idx_in_level", "=", "torch", ".", "nonzero", "(", "levels", "==", "level", ")", ".", "squeeze", "(", "1", ")", "\n", "rois_per_level", "=", "rois", "[", "idx_in_level", "]", "\n", "result", "[", "idx_in_level", "]", "=", "pooler", "(", "per_level_feature", ",", "rois_per_level", ")", ".", "to", "(", "dtype", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.make_pooler": [[124, 134], ["poolers.Pooler"], "function", ["None"], ["", "", "def", "make_pooler", "(", "cfg", ",", "head_name", ")", ":", "\n", "    ", "resolution", "=", "cfg", ".", "MODEL", "[", "head_name", "]", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "cfg", ".", "MODEL", "[", "head_name", "]", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", "[", "head_name", "]", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "return", "pooler", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.cat": [[9, 17], ["isinstance", "torch.cat", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["def", "cat", "(", "tensors", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.get_group_gn": [[14, 29], ["None"], "function", ["None"], ["def", "get_group_gn", "(", "dim", ",", "dim_per_gp", ",", "num_groups", ")", ":", "\n", "    ", "\"\"\"get number of groups used by GroupNorm, based on number of channels.\"\"\"", "\n", "assert", "dim_per_gp", "==", "-", "1", "or", "num_groups", "==", "-", "1", ",", "\"GroupNorm: can only specify G or C/G.\"", "\n", "\n", "if", "dim_per_gp", ">", "0", ":", "\n", "        ", "assert", "dim", "%", "dim_per_gp", "==", "0", ",", "\"dim: {}, dim_per_gp: {}\"", ".", "format", "(", "dim", ",", "dim_per_gp", ")", "\n", "group_gn", "=", "dim", "//", "dim_per_gp", "\n", "", "else", ":", "\n", "        ", "assert", "dim", "%", "num_groups", "==", "0", ",", "\"dim: {}, num_groups: {}\"", ".", "format", "(", "dim", ",", "num_groups", ")", "\n", "group_gn", "=", "num_groups", "\n", "\n", "", "return", "group_gn", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.group_norm": [[31, 41], ["torch.nn.GroupNorm", "make_layers.get_group_gn"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.get_group_gn"], ["", "def", "group_norm", "(", "out_channels", ",", "affine", "=", "True", ",", "divisor", "=", "1", ")", ":", "\n", "    ", "out_channels", "=", "out_channels", "//", "divisor", "\n", "dim_per_gp", "=", "cfg", ".", "MODEL", ".", "GROUP_NORM", ".", "DIM_PER_GP", "//", "divisor", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "GROUP_NORM", ".", "NUM_GROUPS", "//", "divisor", "\n", "eps", "=", "cfg", ".", "MODEL", ".", "GROUP_NORM", ".", "EPSILON", "# default: 1e-5", "\n", "return", "torch", ".", "nn", ".", "GroupNorm", "(", "\n", "get_group_gn", "(", "out_channels", ",", "dim_per_gp", ",", "num_groups", ")", ",", "\n", "out_channels", ",", "\n", "eps", ",", "\n", "affine", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.make_conv3x3": [[44, 78], ["fcos_core.layers.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "module.append", "module.append", "len", "torch.nn.Sequential", "make_layers.group_norm", "torch.nn.ReLU"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.group_norm"], ["", "def", "make_conv3x3", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "dilation", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "use_gn", "=", "False", ",", "\n", "use_relu", "=", "False", ",", "\n", "kaiming_init", "=", "True", "\n", ")", ":", "\n", "    ", "conv", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", "if", "use_gn", "else", "True", "\n", ")", "\n", "if", "kaiming_init", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_normal_", "(", "\n", "conv", ".", "weight", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "conv", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "", "if", "not", "use_gn", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "conv", ".", "bias", ",", "0", ")", "\n", "", "module", "=", "[", "conv", ",", "]", "\n", "if", "use_gn", ":", "\n", "        ", "module", ".", "append", "(", "group_norm", "(", "out_channels", ")", ")", "\n", "", "if", "use_relu", ":", "\n", "        ", "module", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "if", "len", "(", "module", ")", ">", "1", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "*", "module", ")", "\n", "", "return", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.make_fc": [[80, 93], ["torch.nn.Linear", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "torch.nn.Linear", "torch.nn.init.kaiming_uniform_", "torch.nn.Sequential", "make_layers.group_norm"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.group_norm"], ["", "def", "make_fc", "(", "dim_in", ",", "hidden_dim", ",", "use_gn", "=", "False", ")", ":", "\n", "    ", "'''\n        Caffe2 implementation uses XavierFill, which in fact\n        corresponds to kaiming_uniform_ in PyTorch\n    '''", "\n", "if", "use_gn", ":", "\n", "        ", "fc", "=", "nn", ".", "Linear", "(", "dim_in", ",", "hidden_dim", ",", "bias", "=", "False", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "fc", ".", "weight", ",", "a", "=", "1", ")", "\n", "return", "nn", ".", "Sequential", "(", "fc", ",", "group_norm", "(", "hidden_dim", ")", ")", "\n", "", "fc", "=", "nn", ".", "Linear", "(", "dim_in", ",", "hidden_dim", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "fc", ".", "weight", ",", "a", "=", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "fc", ".", "bias", ",", "0", ")", "\n", "return", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.conv_with_kaiming_uniform": [[95, 123], ["fcos_core.layers.Conv2d", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "module.append", "module.append", "len", "torch.nn.Sequential", "make_layers.group_norm", "torch.nn.ReLU"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.group_norm"], ["", "def", "conv_with_kaiming_uniform", "(", "use_gn", "=", "False", ",", "use_relu", "=", "False", ")", ":", "\n", "    ", "def", "make_conv", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "dilation", "=", "1", "\n", ")", ":", "\n", "        ", "conv", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", "*", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", "if", "use_gn", "else", "True", "\n", ")", "\n", "# Caffe2 implementation uses XavierFill, which in fact", "\n", "# corresponds to kaiming_uniform_ in PyTorch", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "conv", ".", "weight", ",", "a", "=", "1", ")", "\n", "if", "not", "use_gn", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "conv", ".", "bias", ",", "0", ")", "\n", "", "module", "=", "[", "conv", ",", "]", "\n", "if", "use_gn", ":", "\n", "            ", "module", ".", "append", "(", "group_norm", "(", "out_channels", ")", ")", "\n", "", "if", "use_relu", ":", "\n", "            ", "module", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "if", "len", "(", "module", ")", ">", "1", ":", "\n", "            ", "return", "nn", ".", "Sequential", "(", "*", "module", ")", "\n", "", "return", "conv", "\n", "\n", "", "return", "make_conv", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess": [[11, 76], ["isinstance", "detectron2.structures.Instances", "detectron2.structures.Instances.has", "output_boxes.scale", "output_boxes.clip", "detectron2.structures.Instances.has", "detectron2.structures.Instances.has", "output_width.float", "output_height.float", "torch.stack", "detectron2.structures.Instances.has", "detectron2.structures.Instances.get_fields", "output_boxes.nonempty", "detectron2.utils.memory.retry_if_cuda_oom"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.scale", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory.retry_if_cuda_oom"], ["def", "detector_postprocess", "(", "\n", "results", ":", "Instances", ",", "output_height", ":", "int", ",", "output_width", ":", "int", ",", "mask_threshold", ":", "float", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Resize the output instances.\n    The input images are often resized when entering an object detector.\n    As a result, we often need the outputs of the detector in a different\n    resolution from its inputs.\n\n    This function will resize the raw outputs of an R-CNN detector\n    to produce outputs according to the desired output resolution.\n\n    Args:\n        results (Instances): the raw outputs from the detector.\n            `results.image_size` contains the input image resolution the detector sees.\n            This object might be modified in-place.\n        output_height, output_width: the desired output resolution.\n\n    Returns:\n        Instances: the resized output from the model, based on the output resolution\n    \"\"\"", "\n", "# Change to 'if is_tracing' after PT1.7", "\n", "if", "isinstance", "(", "output_height", ",", "torch", ".", "Tensor", ")", ":", "\n", "# Converts integer tensors to float temporaries to ensure true", "\n", "# division is performed when computing scale_x and scale_y.", "\n", "        ", "output_width_tmp", "=", "output_width", ".", "float", "(", ")", "\n", "output_height_tmp", "=", "output_height", ".", "float", "(", ")", "\n", "new_size", "=", "torch", ".", "stack", "(", "[", "output_height", ",", "output_width", "]", ")", "\n", "", "else", ":", "\n", "        ", "new_size", "=", "(", "output_height", ",", "output_width", ")", "\n", "output_width_tmp", "=", "output_width", "\n", "output_height_tmp", "=", "output_height", "\n", "\n", "", "scale_x", ",", "scale_y", "=", "(", "\n", "output_width_tmp", "/", "results", ".", "image_size", "[", "1", "]", ",", "\n", "output_height_tmp", "/", "results", ".", "image_size", "[", "0", "]", ",", "\n", ")", "\n", "results", "=", "Instances", "(", "new_size", ",", "**", "results", ".", "get_fields", "(", ")", ")", "\n", "\n", "if", "results", ".", "has", "(", "\"pred_boxes\"", ")", ":", "\n", "        ", "output_boxes", "=", "results", ".", "pred_boxes", "\n", "", "elif", "results", ".", "has", "(", "\"proposal_boxes\"", ")", ":", "\n", "        ", "output_boxes", "=", "results", ".", "proposal_boxes", "\n", "", "else", ":", "\n", "        ", "output_boxes", "=", "None", "\n", "", "assert", "output_boxes", "is", "not", "None", ",", "\"Predictions must contain boxes!\"", "\n", "\n", "output_boxes", ".", "scale", "(", "scale_x", ",", "scale_y", ")", "\n", "output_boxes", ".", "clip", "(", "results", ".", "image_size", ")", "\n", "\n", "results", "=", "results", "[", "output_boxes", ".", "nonempty", "(", ")", "]", "\n", "\n", "if", "results", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "        ", "results", ".", "pred_masks", "=", "retry_if_cuda_oom", "(", "paste_masks_in_image", ")", "(", "\n", "results", ".", "pred_masks", "[", ":", ",", "0", ",", ":", ",", ":", "]", ",", "# N, 1, M, M", "\n", "results", ".", "pred_boxes", ",", "\n", "results", ".", "image_size", ",", "\n", "threshold", "=", "mask_threshold", ",", "\n", ")", "\n", "\n", "", "if", "results", ".", "has", "(", "\"pred_keypoints\"", ")", ":", "\n", "        ", "results", ".", "pred_keypoints", "[", ":", ",", ":", ",", "0", "]", "*=", "scale_x", "\n", "results", ".", "pred_keypoints", "[", ":", ",", ":", ",", "1", "]", "*=", "scale_y", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess": [[78, 102], ["result[].expand", "torch.nn.functional.interpolate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "sem_seg_postprocess", "(", "result", ",", "img_size", ",", "output_height", ",", "output_width", ")", ":", "\n", "    ", "\"\"\"\n    Return semantic segmentation predictions in the original resolution.\n\n    The input images are often resized when entering semantic segmentor. Moreover, in same\n    cases, they also padded inside segmentor to be divisible by maximum network stride.\n    As a result, we often need the predictions of the segmentor in a different\n    resolution from its inputs.\n\n    Args:\n        result (Tensor): semantic segmentation prediction logits. A tensor of shape (C, H, W),\n            where C is the number of classes, and H, W are the height and width of the prediction.\n        img_size (tuple): image size that segmentor is taking as input.\n        output_height, output_width: the desired output resolution.\n\n    Returns:\n        semantic segmentation prediction (Tensor): A tensor of the shape\n            (C, output_height, output_width) that contains per-pixel soft predictions.\n    \"\"\"", "\n", "result", "=", "result", "[", ":", ",", ":", "img_size", "[", "0", "]", ",", ":", "img_size", "[", "1", "]", "]", ".", "expand", "(", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "result", "=", "F", ".", "interpolate", "(", "\n", "result", ",", "size", "=", "(", "output_height", ",", "output_width", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "[", "0", "]", "\n", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.BufferList.__init__": [[26, 30], ["torch.nn.Module.__init__", "enumerate", "anchor_generator.BufferList.register_buffer", "str"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_buffers", ")", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.BufferList.__len__": [[31, 33], ["len"], "methods", ["None"], ["        ", "return", "iter", "(", "self", ".", "_buffers", ".", "values", "(", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.BufferList.__iter__": [[34, 36], ["iter", "anchor_generator.BufferList._buffers.values"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "", "class", "AnchorGenerator", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator.__init__": [[92, 121], ["torch.nn.Module.__init__", "len", "anchor_generator._broadcast_params", "anchor_generator._broadcast_params", "anchor_generator.DefaultAnchorGenerator._calculate_anchors"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator._calculate_anchors"], ["(", "shifts", ".", "view", "(", "-", "1", ",", "1", ",", "4", ")", "+", "base_anchors", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "", "return", "anchors", "\n", "\n", "", "def", "add_visibility_to", "(", "self", ",", "boxlist", ")", ":", "\n", "        ", "image_width", ",", "image_height", "=", "boxlist", ".", "size", "\n", "anchors", "=", "boxlist", ".", "bbox", "\n", "if", "self", ".", "straddle_thresh", ">=", "0", ":", "\n", "            ", "inds_inside", "=", "(", "\n", "(", "anchors", "[", "...", ",", "0", "]", ">=", "-", "self", ".", "straddle_thresh", ")", "\n", "&", "(", "anchors", "[", "...", ",", "1", "]", ">=", "-", "self", ".", "straddle_thresh", ")", "\n", "&", "(", "anchors", "[", "...", ",", "2", "]", "<", "image_width", "+", "self", ".", "straddle_thresh", ")", "\n", "&", "(", "anchors", "[", "...", ",", "3", "]", "<", "image_height", "+", "self", ".", "straddle_thresh", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "anchors", ".", "device", "\n", "inds_inside", "=", "torch", ".", "ones", "(", "anchors", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "", "boxlist", ".", "add_field", "(", "\"visibility\"", ",", "inds_inside", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "image_list", ",", "feature_maps", ")", ":", "\n", "        ", "grid_sizes", "=", "[", "feature_map", ".", "shape", "[", "-", "2", ":", "]", "for", "feature_map", "in", "feature_maps", "]", "\n", "anchors_over_all_feature_maps", "=", "self", ".", "grid_anchors", "(", "grid_sizes", ")", "\n", "anchors", "=", "[", "]", "\n", "for", "i", ",", "(", "image_height", ",", "image_width", ")", "in", "enumerate", "(", "image_list", ".", "image_sizes", ")", ":", "\n", "            ", "anchors_in_image", "=", "[", "]", "\n", "for", "anchors_per_feature_map", "in", "anchors_over_all_feature_maps", ":", "\n", "                ", "boxlist", "=", "BoxList", "(", "\n", "anchors_per_feature_map", ",", "(", "image_width", ",", "image_height", ")", ",", "mode", "=", "\"xyxy\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator.from_config": [[122, 129], ["None"], "methods", ["None"], ["self", ".", "add_visibility_to", "(", "boxlist", ")", "\n", "anchors_in_image", ".", "append", "(", "boxlist", ")", "\n", "", "anchors", ".", "append", "(", "anchors_in_image", ")", "\n", "", "return", "anchors", "\n", "\n", "\n", "", "", "def", "make_anchor_generator", "(", "config", ")", ":", "\n", "    ", "anchor_sizes", "=", "config", ".", "MODEL", ".", "RPN", ".", "ANCHOR_SIZES", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator._calculate_anchors": [[131, 136], ["anchor_generator.BufferList", "anchor_generator.DefaultAnchorGenerator.generate_cell_anchors().float", "zip", "anchor_generator.DefaultAnchorGenerator.generate_cell_anchors"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.generate_cell_anchors"], ["anchor_stride", "=", "config", ".", "MODEL", ".", "RPN", ".", "ANCHOR_STRIDE", "\n", "straddle_thresh", "=", "config", ".", "MODEL", ".", "RPN", ".", "STRADDLE_THRESH", "\n", "\n", "if", "config", ".", "MODEL", ".", "RPN", ".", "USE_FPN", ":", "\n", "        ", "assert", "len", "(", "anchor_stride", ")", "==", "len", "(", "\n", "anchor_sizes", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator.num_cell_anchors": [[137, 144], ["None"], "methods", ["None"], [")", ",", "\"FPN should have len(ANCHOR_STRIDE) == len(ANCHOR_SIZES)\"", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "anchor_stride", ")", "==", "1", ",", "\"Non-FPN should have a single ANCHOR_STRIDE\"", "\n", "", "anchor_generator", "=", "AnchorGenerator", "(", "\n", "anchor_sizes", ",", "aspect_ratios", ",", "anchor_stride", ",", "straddle_thresh", "\n", ")", "\n", "return", "anchor_generator", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator.num_anchors": [[145, 159], ["len"], "methods", ["None"], ["\n", "", "def", "make_anchor_generator_retinanet", "(", "config", ")", ":", "\n", "    ", "anchor_sizes", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_SIZES", "\n", "aspect_ratios", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "ASPECT_RATIOS", "\n", "anchor_strides", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_STRIDES", "\n", "straddle_thresh", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "STRADDLE_THRESH", "\n", "octave", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "OCTAVE", "\n", "scales_per_octave", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "SCALES_PER_OCTAVE", "\n", "\n", "assert", "len", "(", "anchor_strides", ")", "==", "len", "(", "anchor_sizes", ")", ",", "\"Only support FPN now\"", "\n", "new_anchor_sizes", "=", "[", "]", "\n", "for", "size", "in", "anchor_sizes", ":", "\n", "        ", "per_layer_anchor_sizes", "=", "[", "]", "\n", "for", "scale_per_octave", "in", "range", "(", "scales_per_octave", ")", ":", "\n", "            ", "octave_scale", "=", "octave", "**", "(", "scale_per_octave", "/", "float", "(", "scales_per_octave", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator._grid_anchors": [[160, 175], ["zip", "anchor_generator._create_grid_offsets", "torch.stack", "anchors.append", "anchor_generator.DefaultAnchorGenerator.cell_anchors.named_buffers", "torch.stack.view", "base_anchors.view"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._create_grid_offsets"], ["per_layer_anchor_sizes", ".", "append", "(", "octave_scale", "*", "size", ")", "\n", "", "new_anchor_sizes", ".", "append", "(", "tuple", "(", "per_layer_anchor_sizes", ")", ")", "\n", "\n", "", "anchor_generator", "=", "AnchorGenerator", "(", "\n", "tuple", "(", "new_anchor_sizes", ")", ",", "aspect_ratios", ",", "anchor_strides", ",", "straddle_thresh", "\n", ")", "\n", "return", "anchor_generator", "\n", "\n", "\n", "", "def", "make_anchor_generator_atss", "(", "config", ")", ":", "\n", "    ", "anchor_sizes", "=", "config", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_SIZES", "\n", "aspect_ratios", "=", "config", ".", "MODEL", ".", "ATSS", ".", "ASPECT_RATIOS", "\n", "anchor_strides", "=", "config", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_STRIDES", "\n", "straddle_thresh", "=", "config", ".", "MODEL", ".", "ATSS", ".", "STRADDLE_THRESH", "\n", "octave", "=", "config", ".", "MODEL", ".", "ATSS", ".", "OCTAVE", "\n", "scales_per_octave", "=", "config", ".", "MODEL", ".", "ATSS", ".", "SCALES_PER_OCTAVE", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator.generate_cell_anchors": [[176, 212], ["torch.tensor", "math.sqrt", "anchors.append"], "methods", ["None"], ["\n", "assert", "len", "(", "anchor_strides", ")", "==", "len", "(", "anchor_sizes", ")", ",", "\"Only support FPN now\"", "\n", "new_anchor_sizes", "=", "[", "]", "\n", "for", "size", "in", "anchor_sizes", ":", "\n", "        ", "per_layer_anchor_sizes", "=", "[", "]", "\n", "for", "scale_per_octave", "in", "range", "(", "scales_per_octave", ")", ":", "\n", "            ", "octave_scale", "=", "octave", "**", "(", "scale_per_octave", "/", "float", "(", "scales_per_octave", ")", ")", "\n", "per_layer_anchor_sizes", ".", "append", "(", "octave_scale", "*", "size", ")", "\n", "", "new_anchor_sizes", ".", "append", "(", "tuple", "(", "per_layer_anchor_sizes", ")", ")", "\n", "\n", "", "anchor_generator", "=", "AnchorGenerator", "(", "\n", "tuple", "(", "new_anchor_sizes", ")", ",", "aspect_ratios", ",", "anchor_strides", ",", "straddle_thresh", "\n", ")", "\n", "return", "anchor_generator", "\n", "\n", "# Copyright (c) 2017-present, Facebook, Inc.", "\n", "#", "\n", "# Licensed under the Apache License, Version 2.0 (the \"License\");", "\n", "# you may not use this file except in compliance with the License.", "\n", "# You may obtain a copy of the License at", "\n", "#", "\n", "#     http://www.apache.org/licenses/LICENSE-2.0", "\n", "#", "\n", "# Unless required by applicable law or agreed to in writing, software", "\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,", "\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n", "# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "##############################################################################", "\n", "#", "\n", "# Based on:", "\n", "# --------------------------------------------------------", "\n", "# Faster R-CNN", "\n", "# Copyright (c) 2015 Microsoft", "\n", "# Licensed under The MIT License [see LICENSE for details]", "\n", "# Written by Ross Girshick and Sean Bell", "\n", "# --------------------------------------------------------", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.DefaultAnchorGenerator.forward": [[213, 227], ["anchor_generator.DefaultAnchorGenerator._grid_anchors", "detectron2.structures.Boxes"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator._grid_anchors"], ["\n", "\n", "# Verify that we compute the same anchors as Shaoqing's matlab implementation:", "\n", "#", "\n", "#    >> load output/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat", "\n", "#    >> anchors", "\n", "#", "\n", "#    anchors =", "\n", "#", "\n", "#       -83   -39   100    56", "\n", "#      -175   -87   192   104", "\n", "#      -359  -183   376   200", "\n", "#       -55   -55    72    72", "\n", "#      -119  -119   136   136", "\n", "#      -247  -247   264   264", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.__init__": [[241, 273], ["torch.nn.Module.__init__", "len", "anchor_generator._broadcast_params", "anchor_generator._broadcast_params", "anchor_generator._broadcast_params", "anchor_generator.RotatedAnchorGenerator._calculate_anchors"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._broadcast_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator._calculate_anchors"], ["\n", "\n", "", "def", "generate_anchors", "(", "\n", "stride", "=", "16", ",", "sizes", "=", "(", "32", ",", "64", ",", "128", ",", "256", ",", "512", ")", ",", "aspect_ratios", "=", "(", "0.5", ",", "1", ",", "2", ")", "\n", ")", ":", "\n", "    ", "\"\"\"Generates a matrix of anchor boxes in (x1, y1, x2, y2) format. Anchors\n    are centered on stride / 2, have (approximate) sqrt areas of the specified\n    sizes, and aspect ratios as given.\n    \"\"\"", "\n", "return", "_generate_anchors", "(", "\n", "stride", ",", "\n", "np", ".", "array", "(", "sizes", ",", "dtype", "=", "np", ".", "float", ")", "/", "stride", ",", "\n", "np", ".", "array", "(", "aspect_ratios", ",", "dtype", "=", "np", ".", "float", ")", ",", "\n", ")", "\n", "\n", "\n", "", "def", "_generate_anchors", "(", "base_size", ",", "scales", ",", "aspect_ratios", ")", ":", "\n", "    ", "\"\"\"Generate anchor (reference) windows by enumerating aspect ratios X\n    scales wrt a reference (0, 0, base_size - 1, base_size - 1) window.\n    \"\"\"", "\n", "anchor", "=", "np", ".", "array", "(", "[", "1", ",", "1", ",", "base_size", ",", "base_size", "]", ",", "dtype", "=", "np", ".", "float", ")", "-", "1", "\n", "anchors", "=", "_ratio_enum", "(", "anchor", ",", "aspect_ratios", ")", "\n", "anchors", "=", "np", ".", "vstack", "(", "\n", "[", "_scale_enum", "(", "anchors", "[", "i", ",", ":", "]", ",", "scales", ")", "for", "i", "in", "range", "(", "anchors", ".", "shape", "[", "0", "]", ")", "]", "\n", ")", "\n", "return", "torch", ".", "from_numpy", "(", "anchors", ")", "\n", "\n", "\n", "", "def", "_whctrs", "(", "anchor", ")", ":", "\n", "    ", "\"\"\"Return width, height, x center, and y center for an anchor (window).\"\"\"", "\n", "w", "=", "anchor", "[", "2", "]", "-", "anchor", "[", "0", "]", "+", "1", "\n", "h", "=", "anchor", "[", "3", "]", "-", "anchor", "[", "1", "]", "+", "1", "\n", "x_ctr", "=", "anchor", "[", "0", "]", "+", "0.5", "*", "(", "w", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.from_config": [[274, 282], ["None"], "methods", ["None"], ["y_ctr", "=", "anchor", "[", "1", "]", "+", "0.5", "*", "(", "h", "-", "1", ")", "\n", "return", "w", ",", "h", ",", "x_ctr", ",", "y_ctr", "\n", "\n", "\n", "", "def", "_mkanchors", "(", "ws", ",", "hs", ",", "x_ctr", ",", "y_ctr", ")", ":", "\n", "    ", "\"\"\"Given a vector of widths (ws) and heights (hs) around a center\n    (x_ctr, y_ctr), output a set of anchors (windows).\n    \"\"\"", "\n", "ws", "=", "ws", "[", ":", ",", "np", ".", "newaxis", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator._calculate_anchors": [[284, 290], ["anchor_generator.BufferList", "anchor_generator.RotatedAnchorGenerator.generate_cell_anchors().float", "zip", "anchor_generator.RotatedAnchorGenerator.generate_cell_anchors"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.generate_cell_anchors"], ["anchors", "=", "np", ".", "hstack", "(", "\n", "(", "\n", "x_ctr", "-", "0.5", "*", "(", "ws", "-", "1", ")", ",", "\n", "y_ctr", "-", "0.5", "*", "(", "hs", "-", "1", ")", ",", "\n", "x_ctr", "+", "0.5", "*", "(", "ws", "-", "1", ")", ",", "\n", "y_ctr", "+", "0.5", "*", "(", "hs", "-", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.num_cell_anchors": [[291, 297], ["None"], "methods", ["None"], [")", "\n", "return", "anchors", "\n", "\n", "\n", "", "def", "_ratio_enum", "(", "anchor", ",", "ratios", ")", ":", "\n", "    ", "\"\"\"Enumerate a set of anchors for each aspect ratio wrt an anchor.\"\"\"", "\n", "w", ",", "h", ",", "x_ctr", ",", "y_ctr", "=", "_whctrs", "(", "anchor", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.num_anchors": [[298, 312], ["len"], "methods", ["None"], ["size", "=", "w", "*", "h", "\n", "size_ratios", "=", "size", "/", "ratios", "\n", "ws", "=", "np", ".", "round", "(", "np", ".", "sqrt", "(", "size_ratios", ")", ")", "\n", "hs", "=", "np", ".", "round", "(", "ws", "*", "ratios", ")", "\n", "anchors", "=", "_mkanchors", "(", "ws", ",", "hs", ",", "x_ctr", ",", "y_ctr", ")", "\n", "return", "anchors", "\n", "\n", "\n", "", "def", "_scale_enum", "(", "anchor", ",", "scales", ")", ":", "\n", "    ", "\"\"\"Enumerate a set of anchors for each scale wrt an anchor.\"\"\"", "\n", "w", ",", "h", ",", "x_ctr", ",", "y_ctr", "=", "_whctrs", "(", "anchor", ")", "\n", "ws", "=", "w", "*", "scales", "\n", "hs", "=", "h", "*", "scales", "\n", "anchors", "=", "_mkanchors", "(", "ws", ",", "hs", ",", "x_ctr", ",", "y_ctr", ")", "\n", "return", "anchors", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator._grid_anchors": [[313, 323], ["zip", "anchor_generator._create_grid_offsets", "torch.zeros_like", "torch.stack", "anchors.append", "torch.stack.view", "base_anchors.view"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._create_grid_offsets"], ["", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.generate_cell_anchors": [[324, 359], ["torch.tensor", "math.sqrt", "anchors.extend"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator.forward": [[360, 374], ["anchor_generator.RotatedAnchorGenerator._grid_anchors", "detectron2.structures.RotatedBoxes"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.RotatedAnchorGenerator._grid_anchors"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._create_grid_offsets": [[38, 51], ["torch.arange", "torch.arange", "torch.meshgrid", "shift_x.reshape.reshape", "shift_y.reshape.reshape"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "sizes", "=", "(", "128", ",", "256", ",", "512", ")", ",", "\n", "aspect_ratios", "=", "(", "0.5", ",", "1.0", ",", "2.0", ")", ",", "\n", "anchor_strides", "=", "(", "8", ",", "16", ",", "32", ")", ",", "\n", "straddle_thresh", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "AnchorGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "len", "(", "anchor_strides", ")", "==", "1", ":", "\n", "            ", "anchor_stride", "=", "anchor_strides", "[", "0", "]", "\n", "cell_anchors", "=", "[", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator._broadcast_params": [[53, 78], ["isinstance", "len", "isinstance", "len", "len", "list", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["]", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "anchor_strides", ")", "!=", "len", "(", "sizes", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"FPN should have #anchor_strides == #sizes\"", ")", "\n", "\n", "", "cell_anchors", "=", "[", "\n", "generate_anchors", "(", "\n", "anchor_stride", ",", "\n", "size", "if", "isinstance", "(", "size", ",", "(", "tuple", ",", "list", ")", ")", "else", "(", "size", ",", ")", ",", "\n", "aspect_ratios", "\n", ")", ".", "float", "(", ")", "\n", "for", "anchor_stride", ",", "size", "in", "zip", "(", "anchor_strides", ",", "sizes", ")", "\n", "]", "\n", "", "self", ".", "strides", "=", "anchor_strides", "\n", "self", ".", "cell_anchors", "=", "BufferList", "(", "cell_anchors", ")", "\n", "self", ".", "straddle_thresh", "=", "straddle_thresh", "\n", "\n", "", "def", "num_anchors_per_location", "(", "self", ")", ":", "\n", "        ", "return", "[", "len", "(", "cell_anchors", ")", "for", "cell_anchors", "in", "self", ".", "cell_anchors", "]", "\n", "\n", "", "def", "grid_anchors", "(", "self", ",", "grid_sizes", ")", ":", "\n", "        ", "anchors", "=", "[", "]", "\n", "for", "size", ",", "stride", ",", "base_anchors", "in", "zip", "(", "\n", "grid_sizes", ",", "self", ".", "strides", ",", "self", ".", "cell_anchors", "\n", ")", ":", "\n", "            ", "grid_height", ",", "grid_width", "=", "size", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.build_anchor_generator": [[376, 382], ["ANCHOR_GENERATOR_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper.MMDetBackbone.__init__": [[44, 104], ["backbone.Backbone.__init__", "isinstance", "isinstance", "logger.info", "mmdet_wrapper.MMDetBackbone.backbone.init_weights", "mmdet_wrapper.MMDetBackbone.backbone.train", "build_backbone", "build_neck", "logger.info", "isinstance", "mmdet_wrapper.MMDetBackbone.neck.train", "mmdet_wrapper._to_container", "mmdet_wrapper._to_container", "mmdet_wrapper.MMDetBackbone.neck.init_weights", "m.init_weights", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.HRFPN.init_weights", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._to_container", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._to_container", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.HRFPN.init_weights", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.HRFPN.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "backbone", ":", "Union", "[", "nn", ".", "Module", ",", "Mapping", "]", ",", "\n", "neck", ":", "Union", "[", "nn", ".", "Module", ",", "Mapping", ",", "None", "]", "=", "None", ",", "\n", "*", ",", "\n", "pretrained_backbone", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "output_shapes", ":", "List", "[", "ShapeSpec", "]", ",", "\n", "output_names", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: either a backbone module or a mmdet config dict that defines a\n                backbone. The backbone takes a 4D image tensor and returns a\n                sequence of tensors.\n            neck: either a backbone module or a mmdet config dict that defines a\n                neck. The neck takes outputs of backbone and returns a\n                sequence of tensors. If None, no neck is used.\n            pretrained_backbone: defines the backbone weights that can be loaded by\n                mmdet, such as \"torchvision://resnet50\".\n            output_shapes: shape for every output of the backbone (or neck, if given).\n                stride and channels are often needed.\n            output_names: names for every output of the backbone (or neck, if given).\n                By default, will use \"out0\", \"out1\", ...\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "backbone", ",", "Mapping", ")", ":", "\n", "            ", "from", "mmdet", ".", "models", "import", "build_backbone", "\n", "\n", "backbone", "=", "build_backbone", "(", "_to_container", "(", "backbone", ")", ")", "\n", "", "self", ".", "backbone", "=", "backbone", "\n", "\n", "if", "isinstance", "(", "neck", ",", "Mapping", ")", ":", "\n", "            ", "from", "mmdet", ".", "models", "import", "build_neck", "\n", "\n", "neck", "=", "build_neck", "(", "_to_container", "(", "neck", ")", ")", "\n", "", "self", ".", "neck", "=", "neck", "\n", "\n", "# It's confusing that backbone weights are given as a separate argument,", "\n", "# but \"neck\" weights, if any, are part of neck itself. This is the interface", "\n", "# of mmdet so we follow it. Reference:", "\n", "# https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/detectors/two_stage.py", "\n", "logger", ".", "info", "(", "f\"Initializing mmdet backbone weights: {pretrained_backbone} ...\"", ")", "\n", "self", ".", "backbone", ".", "init_weights", "(", "pretrained_backbone", ")", "\n", "# train() in mmdet modules is non-trivial, and has to be explicitly", "\n", "# called. Reference:", "\n", "# https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/backbones/resnet.py", "\n", "self", ".", "backbone", ".", "train", "(", ")", "\n", "if", "self", ".", "neck", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"Initializing mmdet neck weights ...\"", ")", "\n", "if", "isinstance", "(", "self", ".", "neck", ",", "nn", ".", "Sequential", ")", ":", "\n", "                ", "for", "m", "in", "self", ".", "neck", ":", "\n", "                    ", "m", ".", "init_weights", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "neck", ".", "init_weights", "(", ")", "\n", "", "self", ".", "neck", ".", "train", "(", ")", "\n", "\n", "", "self", ".", "_output_shapes", "=", "output_shapes", "\n", "if", "not", "output_names", ":", "\n", "            ", "output_names", "=", "[", "f\"out{i}\"", "for", "i", "in", "range", "(", "len", "(", "output_shapes", ")", ")", "]", "\n", "", "self", ".", "_output_names", "=", "output_names", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper.MMDetBackbone.forward": [[105, 118], ["mmdet_wrapper.MMDetBackbone.backbone", "isinstance", "mmdet_wrapper.MMDetBackbone.neck", "len", "len", "ValueError", "zip", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "Dict", "[", "str", ",", "Tensor", "]", ":", "\n", "        ", "outs", "=", "self", ".", "backbone", "(", "x", ")", "\n", "if", "self", ".", "neck", "is", "not", "None", ":", "\n", "            ", "outs", "=", "self", ".", "neck", "(", "outs", ")", "\n", "", "assert", "isinstance", "(", "\n", "outs", ",", "(", "list", ",", "tuple", ")", "\n", ")", ",", "\"mmdet backbone should return a list/tuple of tensors!\"", "\n", "if", "len", "(", "outs", ")", "!=", "len", "(", "self", ".", "_output_shapes", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Length of output_shapes does not match outputs from the mmdet backbone: \"", "\n", "f\"{len(outs)} != {len(self._output_shapes)}\"", "\n", ")", "\n", "", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "_output_names", ",", "outs", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper.MMDetBackbone.output_shape": [[119, 121], ["zip"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", "->", "Dict", "[", "str", ",", "ShapeSpec", "]", ":", "\n", "        ", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "_output_names", ",", "self", ".", "_output_shapes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper.MMDetDetector.__init__": [[130, 160], ["torch.nn.Module.__init__", "isinstance", "mmdet_wrapper.MMDetDetector.register_buffer", "mmdet_wrapper.MMDetDetector.register_buffer", "build_detector", "torch.Tensor().view", "torch.Tensor().view", "mmdet_wrapper._to_container", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._to_container"], ["def", "__init__", "(", "\n", "self", ",", "\n", "detector", ":", "Union", "[", "nn", ".", "Module", ",", "Mapping", "]", ",", "\n", "*", ",", "\n", "# Default is 32 regardless of model:", "\n", "# https://github.com/open-mmlab/mmdetection/tree/master/configs/_base_/datasets", "\n", "size_divisibility", "=", "32", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            detector: a mmdet detector, or a mmdet config dict that defines a detector.\n            size_divisibility: pad input images to multiple of this number\n            pixel_mean: per-channel mean to normalize input image\n            pixel_std: per-channel stddev to normalize input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "detector", ",", "Mapping", ")", ":", "\n", "            ", "from", "mmdet", ".", "models", "import", "build_detector", "\n", "\n", "detector", "=", "build_detector", "(", "_to_container", "(", "detector", ")", ")", "\n", "", "self", ".", "detector", "=", "detector", "\n", "self", ".", "size_divisibility", "=", "size_divisibility", "\n", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "assert", "(", "\n", "self", ".", "pixel_mean", ".", "shape", "==", "self", ".", "pixel_std", ".", "shape", "\n", ")", ",", "f\"{self.pixel_mean} and {self.pixel_std} have different shapes!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper.MMDetDetector.forward": [[161, 219], ["x[].to", "detectron2.structures.ImageList.from_tensors", "len", "ValueError", "list", "metas.append", "gt_instances[].has", "mmdet_wrapper.MMDetDetector.detector.forward_train", "mmdet_wrapper._parse_losses", "mmdet_wrapper.MMDetDetector.detector.simple_test", "numpy.sqrt", "output_shapes.append", "output_shapes.append", "x[].to", "isinstance", "mmdet_wrapper.MMDetDetector.forward.convert_mask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._parse_losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", ":", "\n", "        ", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "size_divisibility", "=", "self", ".", "size_divisibility", ")", ".", "tensor", "\n", "metas", "=", "[", "]", "\n", "rescale", "=", "{", "\"height\"", "in", "x", "for", "x", "in", "batched_inputs", "}", "\n", "if", "len", "(", "rescale", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Some inputs have original height/width, but some don't!\"", ")", "\n", "", "rescale", "=", "list", "(", "rescale", ")", "[", "0", "]", "\n", "output_shapes", "=", "[", "]", "\n", "for", "input", "in", "batched_inputs", ":", "\n", "            ", "meta", "=", "{", "}", "\n", "c", ",", "h", ",", "w", "=", "input", "[", "\"image\"", "]", ".", "shape", "\n", "meta", "[", "\"img_shape\"", "]", "=", "meta", "[", "\"ori_shape\"", "]", "=", "(", "h", ",", "w", ",", "c", ")", "\n", "if", "rescale", ":", "\n", "                ", "scale_factor", "=", "np", ".", "sqrt", "(", "h", "*", "w", "/", "(", "input", "[", "\"height\"", "]", "*", "input", "[", "\"width\"", "]", ")", ")", "\n", "ori_shape", "=", "(", "input", "[", "\"height\"", "]", ",", "input", "[", "\"width\"", "]", ")", "\n", "output_shapes", ".", "append", "(", "ori_shape", ")", "\n", "meta", "[", "\"ori_shape\"", "]", "=", "ori_shape", "+", "(", "c", ",", ")", "\n", "", "else", ":", "\n", "                ", "scale_factor", "=", "1.0", "\n", "output_shapes", ".", "append", "(", "(", "h", ",", "w", ")", ")", "\n", "", "meta", "[", "\"scale_factor\"", "]", "=", "scale_factor", "\n", "meta", "[", "\"flip\"", "]", "=", "False", "\n", "padh", ",", "padw", "=", "images", ".", "shape", "[", "-", "2", ":", "]", "\n", "meta", "[", "\"pad_shape\"", "]", "=", "(", "padh", ",", "padw", ",", "c", ")", "\n", "metas", ".", "append", "(", "meta", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "if", "gt_instances", "[", "0", "]", ".", "has", "(", "\"gt_masks\"", ")", ":", "\n", "                ", "from", "mmdet", ".", "core", "import", "PolygonMasks", "as", "mm_PolygonMasks", ",", "BitmapMasks", "as", "mm_BitMasks", "\n", "\n", "def", "convert_mask", "(", "m", ",", "shape", ")", ":", "\n", "# mmdet mask format", "\n", "                    ", "if", "isinstance", "(", "m", ",", "BitMasks", ")", ":", "\n", "                        ", "return", "mm_BitMasks", "(", "m", ".", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "return", "mm_PolygonMasks", "(", "m", ".", "polygons", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "\n", "", "", "gt_masks", "=", "[", "convert_mask", "(", "x", ".", "gt_masks", ",", "x", ".", "image_size", ")", "for", "x", "in", "gt_instances", "]", "\n", "", "else", ":", "\n", "                ", "gt_masks", "=", "None", "\n", "", "losses_and_metrics", "=", "self", ".", "detector", ".", "forward_train", "(", "\n", "images", ",", "\n", "metas", ",", "\n", "[", "x", ".", "gt_boxes", ".", "tensor", "for", "x", "in", "gt_instances", "]", ",", "\n", "[", "x", ".", "gt_classes", "for", "x", "in", "gt_instances", "]", ",", "\n", "gt_masks", "=", "gt_masks", ",", "\n", ")", "\n", "return", "_parse_losses", "(", "losses_and_metrics", ")", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "detector", ".", "simple_test", "(", "images", ",", "metas", ",", "rescale", "=", "rescale", ")", "\n", "results", "=", "[", "\n", "{", "\"instances\"", ":", "_convert_mmdet_result", "(", "r", ",", "shape", ")", "}", "\n", "for", "r", ",", "shape", "in", "zip", "(", "results", ",", "output_shapes", ")", "\n", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper.MMDetDetector.device": [[220, 223], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._to_container": [[22, 32], ["isinstance", "ConfigDict", "omegaconf.OmegaConf.to_container"], "function", ["None"], ["def", "_to_container", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    mmdet will assert the type of dict/list.\n    So convert omegaconf objects to dict/list.\n    \"\"\"", "\n", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "cfg", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "", "from", "mmcv", ".", "utils", "import", "ConfigDict", "\n", "\n", "return", "ConfigDict", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._convert_mmdet_result": [[227, 252], ["isinstance", "torch.from_numpy", "torch.cat", "detectron2.structures.Instances", "detectron2.structures.Boxes", "isinstance", "numpy.vstack", "torch.full", "list", "torch.stack", "enumerate", "len", "itertools.chain", "isinstance", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "", "def", "_convert_mmdet_result", "(", "result", ",", "shape", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "Instances", ":", "\n", "    ", "if", "isinstance", "(", "result", ",", "tuple", ")", ":", "\n", "        ", "bbox_result", ",", "segm_result", "=", "result", "\n", "if", "isinstance", "(", "segm_result", ",", "tuple", ")", ":", "\n", "            ", "segm_result", "=", "segm_result", "[", "0", "]", "\n", "", "", "else", ":", "\n", "        ", "bbox_result", ",", "segm_result", "=", "result", ",", "None", "\n", "\n", "", "bboxes", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "bbox_result", ")", ")", "# Nx5", "\n", "bboxes", ",", "scores", "=", "bboxes", "[", ":", ",", ":", "4", "]", ",", "bboxes", "[", ":", ",", "-", "1", "]", "\n", "labels", "=", "[", "\n", "torch", ".", "full", "(", "(", "bbox", ".", "shape", "[", "0", "]", ",", ")", ",", "i", ",", "dtype", "=", "torch", ".", "int32", ")", "for", "i", ",", "bbox", "in", "enumerate", "(", "bbox_result", ")", "\n", "]", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ")", "\n", "inst", "=", "Instances", "(", "shape", ")", "\n", "inst", ".", "pred_boxes", "=", "Boxes", "(", "bboxes", ")", "\n", "inst", ".", "scores", "=", "scores", "\n", "inst", ".", "pred_classes", "=", "labels", "\n", "\n", "if", "segm_result", "is", "not", "None", "and", "len", "(", "labels", ")", ">", "0", ":", "\n", "        ", "segm_result", "=", "list", "(", "itertools", ".", "chain", "(", "*", "segm_result", ")", ")", "\n", "segm_result", "=", "[", "torch", ".", "from_numpy", "(", "x", ")", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", "else", "x", "for", "x", "in", "segm_result", "]", "\n", "segm_result", "=", "torch", ".", "stack", "(", "segm_result", ",", "dim", "=", "0", ")", "\n", "inst", ".", "pred_masks", "=", "segm_result", "\n", "", "return", "inst", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.mmdet_wrapper._parse_losses": [[255, 271], ["collections.OrderedDict", "losses.items", "isinstance", "loss_value.mean", "isinstance", "detectron2.utils.events.get_event_storage", "collections.OrderedDict.pop().cpu().item", "detectron2.utils.events.get_event_storage.put_scalar", "sum", "TypeError", "collections.OrderedDict.pop().cpu", "_loss.mean", "collections.OrderedDict.pop"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar"], ["", "def", "_parse_losses", "(", "losses", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "Tensor", "]", ":", "\n", "    ", "log_vars", "=", "OrderedDict", "(", ")", "\n", "for", "loss_name", ",", "loss_value", "in", "losses", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "loss_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "mean", "(", ")", "\n", "", "elif", "isinstance", "(", "loss_value", ",", "list", ")", ":", "\n", "            ", "log_vars", "[", "loss_name", "]", "=", "sum", "(", "_loss", ".", "mean", "(", ")", "for", "_loss", "in", "loss_value", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f\"{loss_name} is not a tensor or list of tensors\"", ")", "\n", "\n", "", "if", "\"loss\"", "not", "in", "loss_name", ":", "\n", "# put metrics to storage; don't return them", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "value", "=", "log_vars", ".", "pop", "(", "loss_name", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "storage", ".", "put_scalar", "(", "loss_name", ",", "value", ")", "\n", "", "", "return", "log_vars", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DatasetMapperTTA.__init__": [[38, 49], ["None"], "methods", ["None"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "min_sizes", ":", "List", "[", "int", "]", ",", "max_size", ":", "int", ",", "flip", ":", "bool", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            min_sizes: list of short-edge size to resize the image to\n            max_size: maximum height or width of resized images\n            flip: whether to apply flipping augmentation\n        \"\"\"", "\n", "self", ".", "min_sizes", "=", "min_sizes", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "flip", "=", "flip", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DatasetMapperTTA.from_config": [[50, 56], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "return", "{", "\n", "\"min_sizes\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "MIN_SIZES", ",", "\n", "\"max_size\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "MAX_SIZE", ",", "\n", "\"flip\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "FLIP", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DatasetMapperTTA.__call__": [[58, 99], ["dataset_dict[].permute().numpy", "detectron2.data.transforms.ResizeTransform", "fvcore.transforms.NoOpTransform", "detectron2.data.transforms.ResizeShortestEdge", "aug_candidates.append", "detectron2.data.transforms.apply_augmentations", "torch.from_numpy", "copy.deepcopy", "ret.append", "dataset_dict[].permute", "detectron2.data.transforms.RandomFlip", "aug_candidates.append", "numpy.copy", "numpy.ascontiguousarray", "new_image.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.apply_augmentations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dict: a dict in standard model input format. See tutorials for details.\n\n        Returns:\n            list[dict]:\n                a list of dicts, which contain augmented version of the input image.\n                The total number of dicts is ``len(min_sizes) * (2 if flip else 1)``.\n                Each dict has field \"transforms\" which is a TransformList,\n                containing the transforms that are used to generate this image.\n        \"\"\"", "\n", "numpy_image", "=", "dataset_dict", "[", "\"image\"", "]", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "numpy", "(", ")", "\n", "shape", "=", "numpy_image", ".", "shape", "\n", "orig_shape", "=", "(", "dataset_dict", "[", "\"height\"", "]", ",", "dataset_dict", "[", "\"width\"", "]", ")", "\n", "if", "shape", "[", ":", "2", "]", "!=", "orig_shape", ":", "\n", "# It transforms the \"original\" image in the dataset to the input image", "\n", "            ", "pre_tfm", "=", "ResizeTransform", "(", "orig_shape", "[", "0", "]", ",", "orig_shape", "[", "1", "]", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "pre_tfm", "=", "NoOpTransform", "(", ")", "\n", "\n", "# Create all combinations of augmentations to use", "\n", "", "aug_candidates", "=", "[", "]", "# each element is a list[Augmentation]", "\n", "for", "min_size", "in", "self", ".", "min_sizes", ":", "\n", "            ", "resize", "=", "ResizeShortestEdge", "(", "min_size", ",", "self", ".", "max_size", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", "]", ")", "# resize only", "\n", "if", "self", ".", "flip", ":", "\n", "                ", "flip", "=", "RandomFlip", "(", "prob", "=", "1.0", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", ",", "flip", "]", ")", "# resize + flip", "\n", "\n", "# Apply all the augmentations", "\n", "", "", "ret", "=", "[", "]", "\n", "for", "aug", "in", "aug_candidates", ":", "\n", "            ", "new_image", ",", "tfms", "=", "apply_augmentations", "(", "aug", ",", "np", ".", "copy", "(", "numpy_image", ")", ")", "\n", "torch_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "new_image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "\n", "dic", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "\n", "dic", "[", "\"transforms\"", "]", "=", "pre_tfm", "+", "tfms", "\n", "dic", "[", "\"image\"", "]", "=", "torch_image", "\n", "ret", ".", "append", "(", "dic", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA.__init__": [[107, 135], ["torch.nn.Module.__init__", "isinstance", "isinstance", "cfg.clone", "type", "test_time_augmentation.DatasetMapperTTA"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["def", "__init__", "(", "self", ",", "cfg", ",", "model", ",", "tta_mapper", "=", "None", ",", "batch_size", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            model (GeneralizedRCNN): a GeneralizedRCNN to apply TTA on.\n            tta_mapper (callable): takes a dataset dict and returns a list of\n                augmented versions of the dataset dict. Defaults to\n                `DatasetMapperTTA(cfg)`.\n            batch_size (int): batch the augmented images into this batch size for inference.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "model", ",", "DistributedDataParallel", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "", "assert", "isinstance", "(", "\n", "model", ",", "GeneralizedRCNN", "\n", ")", ",", "\"TTA is only supported on GeneralizedRCNN. Got a model of type {}\"", ".", "format", "(", "type", "(", "model", ")", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "assert", "not", "self", ".", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\"TTA for keypoint is not supported yet\"", "\n", "assert", "(", "\n", "not", "self", ".", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", ")", ",", "\"TTA for pre-computed proposals is not supported yet\"", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "if", "tta_mapper", "is", "None", ":", "\n", "            ", "tta_mapper", "=", "DatasetMapperTTA", "(", "cfg", ")", "\n", "", "self", ".", "tta_mapper", "=", "tta_mapper", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads": [[136, 161], ["len", "old.keys", "old.keys", "getattr", "old.keys", "setattr", "setattr"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "_turn_off_roi_heads", "(", "self", ",", "attrs", ")", ":", "\n", "        ", "\"\"\"\n        Open a context where some heads in `model.roi_heads` are temporarily turned off.\n        Args:\n            attr (list[str]): the attribute in `model.roi_heads` which can be used\n                to turn off a specific head, e.g., \"mask_on\", \"keypoint_on\".\n        \"\"\"", "\n", "roi_heads", "=", "self", ".", "model", ".", "roi_heads", "\n", "old", "=", "{", "}", "\n", "for", "attr", "in", "attrs", ":", "\n", "            ", "try", ":", "\n", "                ", "old", "[", "attr", "]", "=", "getattr", "(", "roi_heads", ",", "attr", ")", "\n", "", "except", "AttributeError", ":", "\n", "# The head may not be implemented in certain ROIHeads", "\n", "                ", "pass", "\n", "\n", "", "", "if", "len", "(", "old", ".", "keys", "(", ")", ")", "==", "0", ":", "\n", "            ", "yield", "\n", "", "else", ":", "\n", "            ", "for", "attr", "in", "old", ".", "keys", "(", ")", ":", "\n", "                ", "setattr", "(", "roi_heads", ",", "attr", ",", "False", ")", "\n", "", "yield", "\n", "for", "attr", "in", "old", ".", "keys", "(", ")", ":", "\n", "                ", "setattr", "(", "roi_heads", ",", "attr", ",", "old", "[", "attr", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference": [[162, 187], ["zip", "itertools.count", "inputs.append", "instances.append", "len", "outputs.extend", "len", "test_time_augmentation.GeneralizedRCNNWithTTA.model.inference", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference"], ["", "", "", "def", "_batch_inference", "(", "self", ",", "batched_inputs", ",", "detected_instances", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Execute inference on a list of inputs,\n        using batch size = self.batch_size, instead of the length of the list.\n\n        Inputs & outputs have the same format as :meth:`GeneralizedRCNN.inference`\n        \"\"\"", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "detected_instances", "=", "[", "None", "]", "*", "len", "(", "batched_inputs", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "input", ",", "instance", "in", "zip", "(", "count", "(", ")", ",", "batched_inputs", ",", "detected_instances", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "input", ")", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "if", "len", "(", "inputs", ")", "==", "self", ".", "batch_size", "or", "idx", "==", "len", "(", "batched_inputs", ")", "-", "1", ":", "\n", "                ", "outputs", ".", "extend", "(", "\n", "self", ".", "model", ".", "inference", "(", "\n", "inputs", ",", "\n", "instances", "if", "instances", "[", "0", "]", "is", "not", "None", "else", "None", ",", "\n", "do_postprocess", "=", "False", ",", "\n", ")", "\n", ")", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA.__call__": [[188, 205], ["copy.copy", "test_time_augmentation.GeneralizedRCNNWithTTA._inference_one_image", "detectron2.data.detection_utils.read_image", "torch.from_numpy", "test_time_augmentation.GeneralizedRCNNWithTTA.__call__._maybe_read_image"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._inference_one_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image"], ["", "def", "__call__", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Same input/output format as :meth:`GeneralizedRCNN.forward`\n        \"\"\"", "\n", "\n", "def", "_maybe_read_image", "(", "dataset_dict", ")", ":", "\n", "            ", "ret", "=", "copy", ".", "copy", "(", "dataset_dict", ")", "\n", "if", "\"image\"", "not", "in", "ret", ":", "\n", "                ", "image", "=", "read_image", "(", "ret", ".", "pop", "(", "\"file_name\"", ")", ",", "self", ".", "model", ".", "input_format", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "# CHW", "\n", "ret", "[", "\"image\"", "]", "=", "image", "\n", "", "if", "\"height\"", "not", "in", "ret", "and", "\"width\"", "not", "in", "ret", ":", "\n", "                ", "ret", "[", "\"height\"", "]", "=", "image", ".", "shape", "[", "1", "]", "\n", "ret", "[", "\"width\"", "]", "=", "image", ".", "shape", "[", "2", "]", "\n", "", "return", "ret", "\n", "\n", "", "return", "[", "self", ".", "_inference_one_image", "(", "_maybe_read_image", "(", "x", ")", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._inference_one_image": [[206, 238], ["test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs", "test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections", "test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads", "test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_boxes", "test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes", "test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks", "postprocessing.detector_postprocess"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._get_augmented_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess"], ["", "def", "_inference_one_image", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (dict): one dataset dict with \"image\" field being a CHW tensor\n\n        Returns:\n            dict: one output dict\n        \"\"\"", "\n", "orig_shape", "=", "(", "input", "[", "\"height\"", "]", ",", "input", "[", "\"width\"", "]", ")", "\n", "augmented_inputs", ",", "tfms", "=", "self", ".", "_get_augmented_inputs", "(", "input", ")", "\n", "# Detect boxes from all augmented versions", "\n", "with", "self", ".", "_turn_off_roi_heads", "(", "[", "\"mask_on\"", ",", "\"keypoint_on\"", "]", ")", ":", "\n", "# temporarily disable roi heads", "\n", "            ", "all_boxes", ",", "all_scores", ",", "all_classes", "=", "self", ".", "_get_augmented_boxes", "(", "augmented_inputs", ",", "tfms", ")", "\n", "# merge all detected boxes to obtain final predictions for boxes", "\n", "", "merged_instances", "=", "self", ".", "_merge_detections", "(", "all_boxes", ",", "all_scores", ",", "all_classes", ",", "orig_shape", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "# Use the detected boxes to obtain masks", "\n", "            ", "augmented_instances", "=", "self", ".", "_rescale_detected_boxes", "(", "\n", "augmented_inputs", ",", "merged_instances", ",", "tfms", "\n", ")", "\n", "# run forward on the detected boxes", "\n", "outputs", "=", "self", ".", "_batch_inference", "(", "augmented_inputs", ",", "augmented_instances", ")", "\n", "# Delete now useless variables to avoid being out of memory", "\n", "del", "augmented_inputs", ",", "augmented_instances", "\n", "# average the predictions", "\n", "merged_instances", ".", "pred_masks", "=", "self", ".", "_reduce_pred_masks", "(", "outputs", ",", "tfms", ")", "\n", "merged_instances", "=", "detector_postprocess", "(", "merged_instances", ",", "*", "orig_shape", ")", "\n", "return", "{", "\"instances\"", ":", "merged_instances", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\"instances\"", ":", "merged_instances", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs": [[239, 243], ["test_time_augmentation.GeneralizedRCNNWithTTA.tta_mapper", "x.pop"], "methods", ["None"], ["", "", "def", "_get_augmented_inputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "augmented_inputs", "=", "self", ".", "tta_mapper", "(", "input", ")", "\n", "tfms", "=", "[", "x", ".", "pop", "(", "\"transforms\"", ")", "for", "x", "in", "augmented_inputs", "]", "\n", "return", "augmented_inputs", ",", "tfms", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_boxes": [[244, 261], ["test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "zip", "torch.cat", "tfm.inverse().apply_box", "torch.cat.append", "all_scores.extend", "all_classes.extend", "pred_boxes.cpu().numpy", "torch.from_numpy().to", "tfm.inverse", "pred_boxes.cpu", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.inverse"], ["", "def", "_get_augmented_boxes", "(", "self", ",", "augmented_inputs", ",", "tfms", ")", ":", "\n", "# 1: forward with all augmented images", "\n", "        ", "outputs", "=", "self", ".", "_batch_inference", "(", "augmented_inputs", ")", "\n", "# 2: union the results", "\n", "all_boxes", "=", "[", "]", "\n", "all_scores", "=", "[", "]", "\n", "all_classes", "=", "[", "]", "\n", "for", "output", ",", "tfm", "in", "zip", "(", "outputs", ",", "tfms", ")", ":", "\n", "# Need to inverse the transforms on boxes, to obtain results on original image", "\n", "            ", "pred_boxes", "=", "output", ".", "pred_boxes", ".", "tensor", "\n", "original_pred_boxes", "=", "tfm", ".", "inverse", "(", ")", ".", "apply_box", "(", "pred_boxes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "all_boxes", ".", "append", "(", "torch", ".", "from_numpy", "(", "original_pred_boxes", ")", ".", "to", "(", "pred_boxes", ".", "device", ")", ")", "\n", "\n", "all_scores", ".", "extend", "(", "output", ".", "scores", ")", "\n", "all_classes", ".", "extend", "(", "output", ".", "pred_classes", ")", "\n", "", "all_boxes", "=", "torch", ".", "cat", "(", "all_boxes", ",", "dim", "=", "0", ")", "\n", "return", "all_boxes", ",", "all_scores", ",", "all_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections": [[262, 281], ["len", "torch.zeros", "zip", "roi_heads.fast_rcnn.fast_rcnn_inference_single_image", "itertools.count"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.fast_rcnn_inference_single_image"], ["", "def", "_merge_detections", "(", "self", ",", "all_boxes", ",", "all_scores", ",", "all_classes", ",", "shape_hw", ")", ":", "\n", "# select from the union of all results", "\n", "        ", "num_boxes", "=", "len", "(", "all_boxes", ")", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", "\n", "# +1 because fast_rcnn_inference expects background scores as well", "\n", "all_scores_2d", "=", "torch", ".", "zeros", "(", "num_boxes", ",", "num_classes", "+", "1", ",", "device", "=", "all_boxes", ".", "device", ")", "\n", "for", "idx", ",", "cls", ",", "score", "in", "zip", "(", "count", "(", ")", ",", "all_classes", ",", "all_scores", ")", ":", "\n", "            ", "all_scores_2d", "[", "idx", ",", "cls", "]", "=", "score", "\n", "\n", "", "merged_instances", ",", "_", "=", "fast_rcnn_inference_single_image", "(", "\n", "all_boxes", ",", "\n", "all_scores_2d", ",", "\n", "shape_hw", ",", "\n", "1e-8", ",", "\n", "self", ".", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NMS_THRESH_TEST", ",", "\n", "self", ".", "cfg", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", ",", "\n", ")", "\n", "\n", "return", "merged_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes": [[282, 297], ["zip", "merged_instances.pred_boxes.tensor.cpu().numpy", "torch.from_numpy", "detectron2.structures.Instances", "augmented_instances.append", "tfm.apply_box", "merged_instances.pred_boxes.tensor.cpu", "detectron2.structures.Boxes"], "methods", ["None"], ["", "def", "_rescale_detected_boxes", "(", "self", ",", "augmented_inputs", ",", "merged_instances", ",", "tfms", ")", ":", "\n", "        ", "augmented_instances", "=", "[", "]", "\n", "for", "input", ",", "tfm", "in", "zip", "(", "augmented_inputs", ",", "tfms", ")", ":", "\n", "# Transform the target box to the augmented image's coordinate space", "\n", "            ", "pred_boxes", "=", "merged_instances", ".", "pred_boxes", ".", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_boxes", "=", "torch", ".", "from_numpy", "(", "tfm", ".", "apply_box", "(", "pred_boxes", ")", ")", "\n", "\n", "aug_instances", "=", "Instances", "(", "\n", "image_size", "=", "input", "[", "\"image\"", "]", ".", "shape", "[", "1", ":", "3", "]", ",", "\n", "pred_boxes", "=", "Boxes", "(", "pred_boxes", ")", ",", "\n", "pred_classes", "=", "merged_instances", ".", "pred_classes", ",", "\n", "scores", "=", "merged_instances", ".", "scores", ",", "\n", ")", "\n", "augmented_instances", ".", "append", "(", "aug_instances", ")", "\n", "", "return", "augmented_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks": [[298, 308], ["zip", "torch.stack", "torch.mean", "any", "output.pred_masks.flip", "isinstance"], "methods", ["None"], ["", "def", "_reduce_pred_masks", "(", "self", ",", "outputs", ",", "tfms", ")", ":", "\n", "# Should apply inverse transforms on masks.", "\n", "# We assume only resize & flip are used. pred_masks is a scale-invariant", "\n", "# representation, so we handle flip specially", "\n", "        ", "for", "output", ",", "tfm", "in", "zip", "(", "outputs", ",", "tfms", ")", ":", "\n", "            ", "if", "any", "(", "isinstance", "(", "t", ",", "HFlipTransform", ")", "for", "t", "in", "tfm", ".", "transforms", ")", ":", "\n", "                ", "output", ".", "pred_masks", "=", "output", ".", "pred_masks", ".", "flip", "(", "dims", "=", "[", "3", "]", ")", "\n", "", "", "all_pred_masks", "=", "torch", ".", "stack", "(", "[", "o", ".", "pred_masks", "for", "o", "in", "outputs", "]", ",", "dim", "=", "0", ")", "\n", "avg_pred_masks", "=", "torch", ".", "mean", "(", "all_pred_masks", ",", "dim", "=", "0", ")", "\n", "return", "avg_pred_masks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.ROIPooler.__init__": [[104, 189], ["torch.nn.Module.__init__", "isinstance", "int", "int", "len", "isinstance", "isinstance", "torch.nn.ModuleList", "math.log2", "math.log2", "math.isclose", "math.isclose", "len", "torch.nn.ModuleList", "int", "int", "detectron2.layers.ROIAlign", "torch.nn.ModuleList", "detectron2.layers.ROIAlign", "torch.nn.ModuleList", "ValueError", "torchvision.ops.RoIPool", "detectron2.layers.ROIAlignRotated"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["", "levels", "=", "self", ".", "map_levels", "(", "boxes", ")", "\n", "\n", "num_rois", "=", "len", "(", "rois", ")", "\n", "num_channels", "=", "x", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "output_size", "=", "self", ".", "output_size", "[", "0", "]", "\n", "\n", "dtype", ",", "device", "=", "x", "[", "0", "]", ".", "dtype", ",", "x", "[", "0", "]", ".", "device", "\n", "result", "=", "torch", ".", "zeros", "(", "\n", "(", "num_rois", ",", "num_channels", ",", "output_size", ",", "output_size", ")", ",", "\n", "dtype", "=", "dtype", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "for", "level", ",", "(", "per_level_feature", ",", "pooler", ")", "in", "enumerate", "(", "zip", "(", "x", ",", "self", ".", "poolers", ")", ")", ":", "\n", "            ", "idx_in_level", "=", "torch", ".", "nonzero", "(", "levels", "==", "level", ")", ".", "squeeze", "(", "1", ")", "\n", "rois_per_level", "=", "rois", "[", "idx_in_level", "]", "\n", "result", "[", "idx_in_level", "]", "=", "pooler", "(", "per_level_feature", ",", "rois_per_level", ")", ".", "to", "(", "dtype", ")", "\n", "\n", "", "return", "result", "\n", "\n", "\n", "", "", "def", "make_pooler", "(", "cfg", ",", "head_name", ")", ":", "\n", "    ", "resolution", "=", "cfg", ".", "MODEL", "[", "head_name", "]", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "cfg", ".", "MODEL", "[", "head_name", "]", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", "[", "head_name", "]", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "return", "pooler", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.ROIPooler.forward": [[190, 251], ["len", "poolers.convert_boxes_to_pooler_format", "poolers.assign_boxes_to_levels", "convert_boxes_to_pooler_format.size", "torch.zeros", "enumerate", "isinstance", "isinstance", "len", "len", "len", "x[].size", "x[].size", "len", "len", "torch.zeros", "torch.zeros.index_put_", "detectron2.layers.nonzero_tuple", "pooler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.convert_boxes_to_pooler_format", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.assign_boxes_to_levels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.assign_boxes_to_levels": [[22, 59], ["torch.sqrt", "torch.floor", "torch.clamp", "detectron2.layers.cat", "torch.clamp.to", "torch.log2", "boxes.area"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area"], ["\n", "self", ".", "k_min", "=", "k_min", "\n", "self", ".", "k_max", "=", "k_max", "\n", "self", ".", "s0", "=", "canonical_scale", "\n", "self", ".", "lvl0", "=", "canonical_level", "\n", "self", ".", "eps", "=", "eps", "\n", "\n", "", "def", "__call__", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            boxlists (list[BoxList])\n        \"\"\"", "\n", "# Compute level ids", "\n", "s", "=", "torch", ".", "sqrt", "(", "cat", "(", "[", "boxlist", ".", "area", "(", ")", "for", "boxlist", "in", "boxlists", "]", ")", ")", "\n", "\n", "# Eqn.(1) in FPN paper", "\n", "target_lvls", "=", "torch", ".", "floor", "(", "self", ".", "lvl0", "+", "torch", ".", "log2", "(", "s", "/", "self", ".", "s0", "+", "self", ".", "eps", ")", ")", "\n", "target_lvls", "=", "torch", ".", "clamp", "(", "target_lvls", ",", "min", "=", "self", ".", "k_min", ",", "max", "=", "self", ".", "k_max", ")", "\n", "return", "target_lvls", ".", "to", "(", "torch", ".", "int64", ")", "-", "self", ".", "k_min", "\n", "\n", "\n", "", "", "class", "Pooler", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Pooler for Detection with or without FPN.\n    It currently hard-code ROIAlign in the implementation,\n    but that can be made more generic later on.\n    Also, the requirement of passing the scales is not strictly necessary, as they\n    can be inferred from the size of the feature map / size of original image,\n    which is available thanks to the BoxList.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "output_size", ",", "scales", ",", "sampling_ratio", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers._fmt_box_list": [[61, 66], ["torch.full_like", "detectron2.layers.cat"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["\n", "super", "(", "Pooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "poolers", "=", "[", "]", "\n", "for", "scale", "in", "scales", ":", "\n", "            ", "poolers", ".", "append", "(", "\n", "ROIAlign", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.convert_boxes_to_pooler_format": [[68, 96], ["detectron2.layers.cat", "poolers._fmt_box_list", "enumerate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers._fmt_box_list"], [")", "\n", ")", "\n", "", "self", ".", "poolers", "=", "nn", ".", "ModuleList", "(", "poolers", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "# get the levels in the feature map by leveraging the fact that the network always", "\n", "# downsamples by a factor of 2 at each level.", "\n", "lvl_min", "=", "-", "torch", ".", "log2", "(", "torch", ".", "tensor", "(", "scales", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", ".", "item", "(", ")", "\n", "lvl_max", "=", "-", "torch", ".", "log2", "(", "torch", ".", "tensor", "(", "scales", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "map_levels", "=", "LevelMapper", "(", "lvl_min", ",", "lvl_max", ")", "\n", "\n", "", "def", "convert_to_roi_format", "(", "self", ",", "boxes", ")", ":", "\n", "        ", "concat_boxes", "=", "cat", "(", "[", "b", ".", "bbox", "for", "b", "in", "boxes", "]", ",", "dim", "=", "0", ")", "\n", "device", ",", "dtype", "=", "concat_boxes", ".", "device", ",", "concat_boxes", ".", "dtype", "\n", "ids", "=", "cat", "(", "\n", "[", "\n", "torch", ".", "full", "(", "(", "len", "(", "b", ")", ",", "1", ")", ",", "i", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "boxes", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "rois", "=", "torch", ".", "cat", "(", "[", "ids", ",", "concat_boxes", "]", ",", "dim", "=", "1", ")", "\n", "return", "rois", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "boxes", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransform.__init__": [[27, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "weights", ":", "Tuple", "[", "float", ",", "float", ",", "float", ",", "float", "]", ",", "scale_clamp", ":", "float", "=", "_DEFAULT_SCALE_CLAMP", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            weights (4-element tuple): Scaling factors that are applied to the\n                (dx, dy, dw, dh) deltas. In Fast R-CNN, these were originally set\n                such that the deltas have unit variance; now they are treated as\n                hyperparameters of the system.\n            scale_clamp (float): When predicting deltas, the predicted box scaling\n                factors (dw and dh) are clamped such that they are <= scale_clamp.\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "scale_clamp", "=", "scale_clamp", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransform.get_deltas": [[42, 76], ["isinstance", "type", "isinstance", "type", "torch.stack", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "get_deltas", "(", "self", ",", "src_boxes", ",", "target_boxes", ")", ":", "\n", "        ", "\"\"\"\n        Get box regression transformation deltas (dx, dy, dw, dh) that can be used\n        to transform the `src_boxes` into the `target_boxes`. That is, the relation\n        ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless\n        any delta is too large and is clamped).\n\n        Args:\n            src_boxes (Tensor): source boxes, e.g., object proposals\n            target_boxes (Tensor): target of the transformation, e.g., ground-truth\n                boxes.\n        \"\"\"", "\n", "assert", "isinstance", "(", "src_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "src_boxes", ")", "\n", "assert", "isinstance", "(", "target_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "target_boxes", ")", "\n", "\n", "src_widths", "=", "src_boxes", "[", ":", ",", "2", "]", "-", "src_boxes", "[", ":", ",", "0", "]", "\n", "src_heights", "=", "src_boxes", "[", ":", ",", "3", "]", "-", "src_boxes", "[", ":", ",", "1", "]", "\n", "src_ctr_x", "=", "src_boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "src_widths", "\n", "src_ctr_y", "=", "src_boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "src_heights", "\n", "\n", "target_widths", "=", "target_boxes", "[", ":", ",", "2", "]", "-", "target_boxes", "[", ":", ",", "0", "]", "\n", "target_heights", "=", "target_boxes", "[", ":", ",", "3", "]", "-", "target_boxes", "[", ":", ",", "1", "]", "\n", "target_ctr_x", "=", "target_boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "target_widths", "\n", "target_ctr_y", "=", "target_boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "target_heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "weights", "\n", "dx", "=", "wx", "*", "(", "target_ctr_x", "-", "src_ctr_x", ")", "/", "src_widths", "\n", "dy", "=", "wy", "*", "(", "target_ctr_y", "-", "src_ctr_y", ")", "/", "src_heights", "\n", "dw", "=", "ww", "*", "torch", ".", "log", "(", "target_widths", "/", "src_widths", ")", "\n", "dh", "=", "wh", "*", "torch", ".", "log", "(", "target_heights", "/", "src_heights", ")", "\n", "\n", "deltas", "=", "torch", ".", "stack", "(", "(", "dx", ",", "dy", ",", "dw", ",", "dh", ")", ",", "dim", "=", "1", ")", "\n", "assert", "(", "src_widths", ">", "0", ")", ".", "all", "(", ")", ".", "item", "(", ")", ",", "\"Input boxes to Box2BoxTransform are not valid!\"", "\n", "return", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransform.apply_deltas": [[77, 116], ["deltas.float.float.float", "boxes.to.to.to", "torch.clamp", "torch.clamp", "torch.stack", "torch.stack.reshape", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "apply_deltas", "(", "self", ",", "deltas", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"", "\n", "deltas", "=", "deltas", ".", "float", "(", ")", "# ensure fp32 for decoding precision", "\n", "boxes", "=", "boxes", ".", "to", "(", "deltas", ".", "dtype", ")", "\n", "\n", "widths", "=", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", "\n", "heights", "=", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", "\n", "ctr_x", "=", "boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "widths", "\n", "ctr_y", "=", "boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "heights", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "self", ".", "weights", "\n", "dx", "=", "deltas", "[", ":", ",", "0", ":", ":", "4", "]", "/", "wx", "\n", "dy", "=", "deltas", "[", ":", ",", "1", ":", ":", "4", "]", "/", "wy", "\n", "dw", "=", "deltas", "[", ":", ",", "2", ":", ":", "4", "]", "/", "ww", "\n", "dh", "=", "deltas", "[", ":", ",", "3", ":", ":", "4", "]", "/", "wh", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "\n", "pred_ctr_x", "=", "dx", "*", "widths", "[", ":", ",", "None", "]", "+", "ctr_x", "[", ":", ",", "None", "]", "\n", "pred_ctr_y", "=", "dy", "*", "heights", "[", ":", ",", "None", "]", "+", "ctr_y", "[", ":", ",", "None", "]", "\n", "pred_w", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "[", ":", ",", "None", "]", "\n", "pred_h", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "[", ":", ",", "None", "]", "\n", "\n", "x1", "=", "pred_ctr_x", "-", "0.5", "*", "pred_w", "\n", "y1", "=", "pred_ctr_y", "-", "0.5", "*", "pred_h", "\n", "x2", "=", "pred_ctr_x", "+", "0.5", "*", "pred_w", "\n", "y2", "=", "pred_ctr_y", "+", "0.5", "*", "pred_h", "\n", "pred_boxes", "=", "torch", ".", "stack", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "pred_boxes", ".", "reshape", "(", "deltas", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.__init__": [[128, 143], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "weights", ":", "Tuple", "[", "float", ",", "float", ",", "float", ",", "float", ",", "float", "]", ",", "\n", "scale_clamp", ":", "float", "=", "_DEFAULT_SCALE_CLAMP", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            weights (5-element tuple): Scaling factors that are applied to the\n                (dx, dy, dw, dh, da) deltas. These are treated as\n                hyperparameters of the system.\n            scale_clamp (float): When predicting deltas, the predicted box scaling\n                factors (dw and dh) are clamped such that they are <= scale_clamp.\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "scale_clamp", "=", "scale_clamp", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.get_deltas": [[144, 181], ["isinstance", "type", "isinstance", "type", "torch.unbind", "torch.unbind", "torch.stack", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "get_deltas", "(", "self", ",", "src_boxes", ",", "target_boxes", ")", ":", "\n", "        ", "\"\"\"\n        Get box regression transformation deltas (dx, dy, dw, dh, da) that can be used\n        to transform the `src_boxes` into the `target_boxes`. That is, the relation\n        ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless\n        any delta is too large and is clamped).\n\n        Args:\n            src_boxes (Tensor): Nx5 source boxes, e.g., object proposals\n            target_boxes (Tensor): Nx5 target of the transformation, e.g., ground-truth\n                boxes.\n        \"\"\"", "\n", "assert", "isinstance", "(", "src_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "src_boxes", ")", "\n", "assert", "isinstance", "(", "target_boxes", ",", "torch", ".", "Tensor", ")", ",", "type", "(", "target_boxes", ")", "\n", "\n", "src_ctr_x", ",", "src_ctr_y", ",", "src_widths", ",", "src_heights", ",", "src_angles", "=", "torch", ".", "unbind", "(", "src_boxes", ",", "dim", "=", "1", ")", "\n", "\n", "target_ctr_x", ",", "target_ctr_y", ",", "target_widths", ",", "target_heights", ",", "target_angles", "=", "torch", ".", "unbind", "(", "\n", "target_boxes", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", ",", "wa", "=", "self", ".", "weights", "\n", "dx", "=", "wx", "*", "(", "target_ctr_x", "-", "src_ctr_x", ")", "/", "src_widths", "\n", "dy", "=", "wy", "*", "(", "target_ctr_y", "-", "src_ctr_y", ")", "/", "src_heights", "\n", "dw", "=", "ww", "*", "torch", ".", "log", "(", "target_widths", "/", "src_widths", ")", "\n", "dh", "=", "wh", "*", "torch", ".", "log", "(", "target_heights", "/", "src_heights", ")", "\n", "# Angles of deltas are in radians while angles of boxes are in degrees.", "\n", "# the conversion to radians serve as a way to normalize the values", "\n", "da", "=", "target_angles", "-", "src_angles", "\n", "da", "=", "(", "da", "+", "180.0", ")", "%", "360.0", "-", "180.0", "# make it in [-180, 180)", "\n", "da", "*=", "wa", "*", "math", ".", "pi", "/", "180.0", "\n", "\n", "deltas", "=", "torch", ".", "stack", "(", "(", "dx", ",", "dy", ",", "dw", ",", "dh", ",", "da", ")", ",", "dim", "=", "1", ")", "\n", "assert", "(", "\n", "(", "src_widths", ">", "0", ")", ".", "all", "(", ")", ".", "item", "(", ")", "\n", ")", ",", "\"Input boxes to Box2BoxTransformRotated are not valid!\"", "\n", "return", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas": [[182, 227], ["boxes.to().unsqueeze.to().unsqueeze.to().unsqueeze", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.exp", "torch.exp", "boxes.to().unsqueeze.to().unsqueeze.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "apply_deltas", "(", "self", ",", "deltas", ",", "boxes", ")", ":", "\n", "        ", "\"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh, da) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*5).\n                deltas[i] represents box transformation for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 5)\n        \"\"\"", "\n", "assert", "deltas", ".", "shape", "[", "1", "]", "%", "5", "==", "0", "and", "boxes", ".", "shape", "[", "1", "]", "==", "5", "\n", "\n", "boxes", "=", "boxes", ".", "to", "(", "deltas", ".", "dtype", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "ctr_x", "=", "boxes", "[", ":", ",", "0", "]", "\n", "ctr_y", "=", "boxes", "[", ":", ",", "1", "]", "\n", "widths", "=", "boxes", "[", ":", ",", "2", "]", "\n", "heights", "=", "boxes", "[", ":", ",", "3", "]", "\n", "angles", "=", "boxes", "[", ":", ",", "4", "]", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", ",", "wa", "=", "self", ".", "weights", "\n", "\n", "dx", "=", "deltas", "[", ":", ",", "0", ":", ":", "5", "]", "/", "wx", "\n", "dy", "=", "deltas", "[", ":", ",", "1", ":", ":", "5", "]", "/", "wy", "\n", "dw", "=", "deltas", "[", ":", ",", "2", ":", ":", "5", "]", "/", "ww", "\n", "dh", "=", "deltas", "[", ":", ",", "3", ":", ":", "5", "]", "/", "wh", "\n", "da", "=", "deltas", "[", ":", ",", "4", ":", ":", "5", "]", "/", "wa", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "self", ".", "scale_clamp", ")", "\n", "\n", "pred_boxes", "=", "torch", ".", "zeros_like", "(", "deltas", ")", "\n", "pred_boxes", "[", ":", ",", "0", ":", ":", "5", "]", "=", "dx", "*", "widths", "+", "ctr_x", "# x_ctr", "\n", "pred_boxes", "[", ":", ",", "1", ":", ":", "5", "]", "=", "dy", "*", "heights", "+", "ctr_y", "# y_ctr", "\n", "pred_boxes", "[", ":", ",", "2", ":", ":", "5", "]", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "# width", "\n", "pred_boxes", "[", ":", ",", "3", ":", ":", "5", "]", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "# height", "\n", "\n", "# Following original RRPN implementation,", "\n", "# angles of deltas are in radians while angles of boxes are in degrees.", "\n", "pred_angle", "=", "da", "*", "180.0", "/", "math", ".", "pi", "+", "angles", "\n", "pred_angle", "=", "(", "pred_angle", "+", "180.0", ")", "%", "360.0", "-", "180.0", "# make it in [-180, 180)", "\n", "\n", "pred_boxes", "[", ":", ",", "4", ":", ":", "5", "]", "=", "pred_angle", "\n", "\n", "return", "pred_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression._dense_box_regression_loss": [[229, 271], ["type().cat", "torch.stack", "fvcore.nn.smooth_l1_loss", "box2box_transform.get_deltas", "fvcore.nn.giou_loss", "ValueError", "type", "detectron2.layers.cat", "box2box_transform.apply_deltas", "detectron2.layers.cat", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "", "def", "_dense_box_regression_loss", "(", "\n", "anchors", ":", "List", "[", "Boxes", "]", ",", "\n", "box2box_transform", ":", "Box2BoxTransform", ",", "\n", "pred_anchor_deltas", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "gt_boxes", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "fg_mask", ":", "torch", ".", "Tensor", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Compute loss for dense multi-level box regression.\n    Loss is accumulated over ``fg_mask``.\n\n    Args:\n        anchors: #lvl anchor boxes, each is (HixWixA, 4)\n        pred_anchor_deltas: #lvl predictions, each is (N, HixWixA, 4)\n        gt_boxes: N ground truth boxes, each has shape (R, 4) (R = sum(Hi * Wi * A))\n        fg_mask: the foreground boolean mask of shape (N, R) to compute loss on\n        box_reg_loss_type (str): Loss type to use. Supported losses: \"smooth_l1\", \"giou\".\n        smooth_l1_beta (float): beta parameter for the smooth L1 regression loss. Default to\n            use L1 loss. Only used when `box_reg_loss_type` is \"smooth_l1\"\n    \"\"\"", "\n", "anchors", "=", "type", "(", "anchors", "[", "0", "]", ")", ".", "cat", "(", "anchors", ")", ".", "tensor", "# (R, 4)", "\n", "if", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "        ", "gt_anchor_deltas", "=", "[", "box2box_transform", ".", "get_deltas", "(", "anchors", ",", "k", ")", "for", "k", "in", "gt_boxes", "]", "\n", "gt_anchor_deltas", "=", "torch", ".", "stack", "(", "gt_anchor_deltas", ")", "# (N, R, 4)", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "cat", "(", "pred_anchor_deltas", ",", "dim", "=", "1", ")", "[", "fg_mask", "]", ",", "\n", "gt_anchor_deltas", "[", "fg_mask", "]", ",", "\n", "beta", "=", "smooth_l1_beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "elif", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "        ", "pred_boxes", "=", "[", "\n", "box2box_transform", ".", "apply_deltas", "(", "k", ",", "anchors", ")", "for", "k", "in", "cat", "(", "pred_anchor_deltas", ",", "dim", "=", "1", ")", "\n", "]", "\n", "loss_box_reg", "=", "giou_loss", "(", "\n", "torch", ".", "stack", "(", "pred_boxes", ")", "[", "fg_mask", "]", ",", "torch", ".", "stack", "(", "gt_boxes", ")", "[", "fg_mask", "]", ",", "reduction", "=", "\"sum\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Invalid dense box regression loss type '{box_reg_loss_type}'\"", ")", "\n", "", "return", "loss_box_reg", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.sampling.subsample_labels": [[9, 55], ["int", "min", "min", "detectron2.layers.nonzero_tuple", "detectron2.layers.nonzero_tuple", "positive.numel", "negative.numel", "torch.randperm", "torch.randperm", "positive.numel", "negative.numel"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple"], ["def", "subsample_labels", "(", "\n", "labels", ":", "torch", ".", "Tensor", ",", "num_samples", ":", "int", ",", "positive_fraction", ":", "float", ",", "bg_label", ":", "int", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Return `num_samples` (or fewer, if not enough found)\n    random samples from `labels` which is a mixture of positives & negatives.\n    It will try to return as many positives as possible without\n    exceeding `positive_fraction * num_samples`, and then try to\n    fill the remaining slots with negatives.\n\n    Args:\n        labels (Tensor): (N, ) label vector with values:\n            * -1: ignore\n            * bg_label: background (\"negative\") class\n            * otherwise: one or more foreground (\"positive\") classes\n        num_samples (int): The total number of labels with value >= 0 to return.\n            Values that are not sampled will be filled with -1 (ignore).\n        positive_fraction (float): The number of subsampled labels with values > 0\n            is `min(num_positives, int(positive_fraction * num_samples))`. The number\n            of negatives sampled is `min(num_negatives, num_samples - num_positives_sampled)`.\n            In order words, if there are not enough positives, the sample is filled with\n            negatives. If there are also not enough negatives, then as many elements are\n            sampled as is possible.\n        bg_label (int): label index of background (\"negative\") class.\n\n    Returns:\n        pos_idx, neg_idx (Tensor):\n            1D vector of indices. The total length of both is `num_samples` or fewer.\n    \"\"\"", "\n", "positive", "=", "nonzero_tuple", "(", "(", "labels", "!=", "-", "1", ")", "&", "(", "labels", "!=", "bg_label", ")", ")", "[", "0", "]", "\n", "negative", "=", "nonzero_tuple", "(", "labels", "==", "bg_label", ")", "[", "0", "]", "\n", "\n", "num_pos", "=", "int", "(", "num_samples", "*", "positive_fraction", ")", "\n", "# protect against not enough positive examples", "\n", "num_pos", "=", "min", "(", "positive", ".", "numel", "(", ")", ",", "num_pos", ")", "\n", "num_neg", "=", "num_samples", "-", "num_pos", "\n", "# protect against not enough negative examples", "\n", "num_neg", "=", "min", "(", "negative", ".", "numel", "(", ")", ",", "num_neg", ")", "\n", "\n", "# randomly select positive and negative examples", "\n", "perm1", "=", "torch", ".", "randperm", "(", "positive", ".", "numel", "(", ")", ",", "device", "=", "positive", ".", "device", ")", "[", ":", "num_pos", "]", "\n", "perm2", "=", "torch", ".", "randperm", "(", "negative", ".", "numel", "(", ")", ",", "device", "=", "negative", ".", "device", ")", "[", ":", "num_neg", "]", "\n", "\n", "pos_idx", "=", "positive", "[", "perm1", "]", "\n", "neg_idx", "=", "negative", "[", "perm2", "]", "\n", "return", "pos_idx", ",", "neg_idx", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.densepose_checkpoint.DensePoseCheckpointer.__init__": [[27, 29], ["detectron2.checkpoint.DetectionCheckpointer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "save_dir", "=", "\"\"", ",", "*", ",", "save_to_disk", "=", "None", ",", "**", "checkpointables", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "save_dir", ",", "save_to_disk", "=", "save_to_disk", ",", "**", "checkpointables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.densepose_checkpoint.DensePoseCheckpointer._load_file": [[30, 36], ["super()._load_file", "densepose_checkpoint._rename_HRNet_weights"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.densepose_checkpoint._rename_HRNet_weights"], ["", "def", "_load_file", "(", "self", ",", "filename", ":", "str", ")", "->", "object", ":", "\n", "        ", "\"\"\"\n        Adding hrnet support\n        \"\"\"", "\n", "weights", "=", "super", "(", ")", ".", "_load_file", "(", "filename", ")", "\n", "return", "_rename_HRNet_weights", "(", "weights", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.densepose_checkpoint._rename_HRNet_weights": [[7, 20], ["collections.OrderedDict", "weights[].keys", "len", "len", "weights[].keys", "weights[].keys", "k.startswith", "str"], "function", ["None"], ["def", "_rename_HRNet_weights", "(", "weights", ")", ":", "\n", "# We detect and  rename HRNet weights for DensePose. 1956 and 1716 are values that are", "\n", "# common to all HRNet pretrained weights, and should be enough to accurately identify them", "\n", "    ", "if", "(", "\n", "len", "(", "weights", "[", "\"model\"", "]", ".", "keys", "(", ")", ")", "==", "1956", "\n", "and", "len", "(", "[", "k", "for", "k", "in", "weights", "[", "\"model\"", "]", ".", "keys", "(", ")", "if", "k", ".", "startswith", "(", "\"stage\"", ")", "]", ")", "==", "1716", "\n", ")", ":", "\n", "        ", "hrnet_weights", "=", "OrderedDict", "(", ")", "\n", "for", "k", "in", "weights", "[", "\"model\"", "]", ".", "keys", "(", ")", ":", "\n", "            ", "hrnet_weights", "[", "\"backbone.bottom_up.\"", "+", "str", "(", "k", ")", "]", "=", "weights", "[", "\"model\"", "]", "[", "k", "]", "\n", "", "return", "{", "\"model\"", ":", "hrnet_weights", "}", "\n", "", "else", ":", "\n", "        ", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_predictor": [[12, 26], ["DENSEPOSE_PREDICTOR_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["from", ".", "import", "samplers", "\n", "\n", "from", ".", "collate_batch", "import", "BatchCollator", ",", "BBoxAugCollator", "\n", "from", ".", "transforms", "import", "build_transforms", "\n", "\n", "\n", "def", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "dataset_catalog", ",", "is_train", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_data_filter": [[28, 42], ["filter.DensePoseDataFilter"], "function", ["None"], ["if", "not", "isinstance", "(", "dataset_list", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"dataset_list should be a list of strings, got {}\"", ".", "format", "(", "dataset_list", ")", "\n", ")", "\n", "", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "dataset_list", ":", "\n", "        ", "data", "=", "dataset_catalog", ".", "get", "(", "dataset_name", ")", "\n", "factory", "=", "getattr", "(", "D", ",", "data", "[", "\"factory\"", "]", ")", "\n", "args", "=", "data", "[", "\"args\"", "]", "\n", "# for COCODataset, we want to remove images without annotations", "\n", "# during training", "\n", "if", "data", "[", "\"factory\"", "]", "==", "\"COCODataset\"", ":", "\n", "            ", "args", "[", "\"remove_images_without_annotations\"", "]", "=", "is_train", "\n", "", "if", "data", "[", "\"factory\"", "]", "==", "\"PascalVOCDataset\"", ":", "\n", "            ", "args", "[", "\"use_difficult\"", "]", "=", "not", "is_train", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_head": [[44, 58], ["ROI_DENSEPOSE_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["# make dataset from factory", "\n", "dataset", "=", "factory", "(", "**", "args", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "# for testing, return a list of datasets", "\n", "", "if", "not", "is_train", ":", "\n", "        ", "return", "datasets", "\n", "\n", "# for training, concatenate all datasets into a single one", "\n", "", "dataset", "=", "datasets", "[", "0", "]", "\n", "if", "len", "(", "datasets", ")", ">", "1", ":", "\n", "        ", "dataset", "=", "D", ".", "ConcatDataset", "(", "datasets", ")", "\n", "\n", "", "return", "[", "dataset", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_losses": [[60, 73], ["DENSEPOSE_LOSS_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n", "\n", "", "def", "_quantize", "(", "x", ",", "bins", ")", ":", "\n", "    ", "bins", "=", "copy", ".", "copy", "(", "bins", ")", "\n", "bins", "=", "sorted", "(", "bins", ")", "\n", "quantized", "=", "list", "(", "map", "(", "lambda", "y", ":", "bisect", ".", "bisect_right", "(", "bins", ",", "y", ")", ",", "x", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_embedder": [[75, 88], ["cse.embedder.Embedder"], "function", ["None"], ["\n", "\n", "", "def", "_compute_aspect_ratios", "(", "dataset", ")", ":", "\n", "    ", "aspect_ratios", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "img_info", "=", "dataset", ".", "get_img_info", "(", "i", ")", "\n", "aspect_ratio", "=", "float", "(", "img_info", "[", "\"height\"", "]", ")", "/", "float", "(", "img_info", "[", "\"width\"", "]", ")", "\n", "aspect_ratios", ".", "append", "(", "aspect_ratio", ")", "\n", "", "return", "aspect_ratios", "\n", "\n", "\n", "", "def", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_batch", ",", "num_iters", "=", "None", ",", "start_iter", "=", "0", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.inference.densepose_inference": [[9, 44], ["len", "type", "dataclasses.fields", "type.", "getattr", "isinstance"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields"], ["\n", "from", ".", ".", "utils", "import", "cat", "\n", "from", ".", "utils", "import", "permute_and_flatten", "\n", "\n", "class", "RPNPostProcessor", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Performs post-processing on the outputs of the RPN boxes, before feeding the\n    proposals to the heads\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.BasicBlock.__init__": [[32, 41], ["torch.Module.__init__", "hrnet.conv3x3", "torch.BatchNorm2d", "torch.ReLU", "hrnet.conv3x3", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.conv3x3", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.BasicBlock.forward": [[42, 59], ["hrnet.BasicBlock.conv1", "hrnet.BasicBlock.bn1", "hrnet.BasicBlock.relu", "hrnet.BasicBlock.conv2", "hrnet.BasicBlock.bn2", "hrnet.BasicBlock.relu", "hrnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.Bottleneck.__init__": [[64, 75], ["torch.Module.__init__", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.Bottleneck.forward": [[76, 97], ["hrnet.Bottleneck.conv1", "hrnet.Bottleneck.bn1", "hrnet.Bottleneck.relu", "hrnet.Bottleneck.conv2", "hrnet.Bottleneck.bn2", "hrnet.Bottleneck.relu", "hrnet.Bottleneck.conv3", "hrnet.Bottleneck.bn3", "hrnet.Bottleneck.relu", "hrnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule.__init__": [[112, 132], ["torch.Module.__init__", "hrnet.HighResolutionModule._check_branches", "hrnet.HighResolutionModule._make_branches", "hrnet.HighResolutionModule._make_fuse_layers", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._check_branches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._make_branches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._make_fuse_layers"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_branches", ",", "\n", "blocks", ",", "\n", "num_blocks", ",", "\n", "num_inchannels", ",", "\n", "num_channels", ",", "\n", "multi_scale_output", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", "HighResolutionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_check_branches", "(", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_inchannels", ",", "num_channels", ")", "\n", "\n", "self", ".", "num_inchannels", "=", "num_inchannels", "\n", "self", ".", "num_branches", "=", "num_branches", "\n", "\n", "self", ".", "multi_scale_output", "=", "multi_scale_output", "\n", "\n", "self", ".", "branches", "=", "self", ".", "_make_branches", "(", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_channels", ")", "\n", "self", ".", "fuse_layers", "=", "self", ".", "_make_fuse_layers", "(", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._check_branches": [[133, 152], ["len", "logger.error", "ValueError", "len", "logger.error", "ValueError", "len", "logger.error", "ValueError", "len", "len", "len"], "methods", ["None"], ["", "def", "_check_branches", "(", "self", ",", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_inchannels", ",", "num_channels", ")", ":", "\n", "        ", "if", "num_branches", "!=", "len", "(", "num_blocks", ")", ":", "\n", "            ", "error_msg", "=", "\"NUM_BRANCHES({}) <> NUM_BLOCKS({})\"", ".", "format", "(", "num_branches", ",", "len", "(", "num_blocks", ")", ")", "\n", "logger", ".", "error", "(", "error_msg", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "if", "num_branches", "!=", "len", "(", "num_channels", ")", ":", "\n", "            ", "error_msg", "=", "\"NUM_BRANCHES({}) <> NUM_CHANNELS({})\"", ".", "format", "(", "\n", "num_branches", ",", "len", "(", "num_channels", ")", "\n", ")", "\n", "logger", ".", "error", "(", "error_msg", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "if", "num_branches", "!=", "len", "(", "num_inchannels", ")", ":", "\n", "            ", "error_msg", "=", "\"NUM_BRANCHES({}) <> NUM_INCHANNELS({})\"", ".", "format", "(", "\n", "num_branches", ",", "len", "(", "num_inchannels", ")", "\n", ")", "\n", "logger", ".", "error", "(", "error_msg", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._make_one_branch": [[153, 179], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "def", "_make_one_branch", "(", "self", ",", "branch_index", ",", "block", ",", "num_blocks", ",", "num_channels", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "(", "\n", "stride", "!=", "1", "\n", "or", "self", ".", "num_inchannels", "[", "branch_index", "]", "!=", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", "\n", ")", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "self", ".", "num_inchannels", "[", "branch_index", "]", ",", "\n", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", ",", "momentum", "=", "BN_MOMENTUM", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "\n", "block", "(", "self", ".", "num_inchannels", "[", "branch_index", "]", ",", "num_channels", "[", "branch_index", "]", ",", "stride", ",", "downsample", ")", "\n", ")", "\n", "self", ".", "num_inchannels", "[", "branch_index", "]", "=", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "num_blocks", "[", "branch_index", "]", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "num_inchannels", "[", "branch_index", "]", ",", "num_channels", "[", "branch_index", "]", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._make_branches": [[180, 187], ["range", "torch.ModuleList", "branches.append", "hrnet.HighResolutionModule._make_one_branch"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._make_one_branch"], ["", "def", "_make_branches", "(", "self", ",", "num_branches", ",", "block", ",", "num_blocks", ",", "num_channels", ")", ":", "\n", "        ", "branches", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_branches", ")", ":", "\n", "            ", "branches", ".", "append", "(", "self", ".", "_make_one_branch", "(", "i", ",", "block", ",", "num_blocks", ",", "num_channels", ")", ")", "\n", "\n", "", "return", "nn", ".", "ModuleList", "(", "branches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule._make_fuse_layers": [[188, 246], ["range", "torch.ModuleList", "range", "fuse_layers.append", "torch.ModuleList", "fuse_layer.append", "torch.Sequential", "fuse_layer.append", "range", "fuse_layer.append", "torch.Conv2d", "torch.BatchNorm2d", "torch.Upsample", "torch.Sequential", "conv3x3s.append", "conv3x3s.append", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "methods", ["None"], ["", "def", "_make_fuse_layers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_branches", "==", "1", ":", "\n", "            ", "return", "None", "\n", "\n", "", "num_branches", "=", "self", ".", "num_branches", "\n", "num_inchannels", "=", "self", ".", "num_inchannels", "\n", "fuse_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_branches", "if", "self", ".", "multi_scale_output", "else", "1", ")", ":", "\n", "            ", "fuse_layer", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "num_branches", ")", ":", "\n", "                ", "if", "j", ">", "i", ":", "\n", "                    ", "fuse_layer", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_inchannels", "[", "j", "]", ",", "num_inchannels", "[", "i", "]", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_inchannels", "[", "i", "]", ")", ",", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", "**", "(", "j", "-", "i", ")", ",", "mode", "=", "\"nearest\"", ")", ",", "\n", ")", "\n", ")", "\n", "", "elif", "j", "==", "i", ":", "\n", "                    ", "fuse_layer", ".", "append", "(", "None", ")", "\n", "", "else", ":", "\n", "                    ", "conv3x3s", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "i", "-", "j", ")", ":", "\n", "                        ", "if", "k", "==", "i", "-", "j", "-", "1", ":", "\n", "                            ", "num_outchannels_conv3x3", "=", "num_inchannels", "[", "i", "]", "\n", "conv3x3s", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "num_inchannels", "[", "j", "]", ",", "\n", "num_outchannels_conv3x3", ",", "\n", "3", ",", "\n", "2", ",", "\n", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_outchannels_conv3x3", ")", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                            ", "num_outchannels_conv3x3", "=", "num_inchannels", "[", "j", "]", "\n", "conv3x3s", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "num_inchannels", "[", "j", "]", ",", "\n", "num_outchannels_conv3x3", ",", "\n", "3", ",", "\n", "2", ",", "\n", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_outchannels_conv3x3", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", ")", "\n", ")", "\n", "", "", "fuse_layer", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "conv3x3s", ")", ")", "\n", "", "", "fuse_layers", ".", "append", "(", "nn", ".", "ModuleList", "(", "fuse_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "ModuleList", "(", "fuse_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule.get_num_inchannels": [[247, 249], ["None"], "methods", ["None"], ["", "def", "get_num_inchannels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_inchannels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule.forward": [[250, 270], ["range", "range", "len", "range", "x_fuse.append", "hrnet.HighResolutionModule.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "num_branches", "==", "1", ":", "\n", "            ", "return", "[", "self", ".", "branches", "[", "0", "]", "(", "x", "[", "0", "]", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_branches", ")", ":", "\n", "            ", "x", "[", "i", "]", "=", "self", ".", "branches", "[", "i", "]", "(", "x", "[", "i", "]", ")", "\n", "\n", "", "x_fuse", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "fuse_layers", ")", ")", ":", "\n", "            ", "y", "=", "x", "[", "0", "]", "if", "i", "==", "0", "else", "self", ".", "fuse_layers", "[", "i", "]", "[", "0", "]", "(", "x", "[", "0", "]", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "self", ".", "num_branches", ")", ":", "\n", "                ", "if", "i", "==", "j", ":", "\n", "                    ", "y", "=", "y", "+", "x", "[", "j", "]", "\n", "", "else", ":", "\n", "                    ", "z", "=", "self", ".", "fuse_layers", "[", "i", "]", "[", "j", "]", "(", "x", "[", "j", "]", ")", "[", ":", ",", ":", ",", ":", "y", ".", "shape", "[", "2", "]", ",", ":", "y", ".", "shape", "[", "3", "]", "]", "\n", "y", "=", "y", "+", "z", "\n", "", "", "x_fuse", ".", "append", "(", "self", ".", "relu", "(", "y", ")", ")", "\n", "\n", "", "return", "x_fuse", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet.__init__": [[282, 327], ["detectron2.modeling.backbone.backbone.Backbone.__init__", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "hrnet.PoseHigherResolutionNet._make_layer", "hrnet.PoseHigherResolutionNet._make_transition_layer", "hrnet.PoseHigherResolutionNet._make_stage", "hrnet.PoseHigherResolutionNet._make_transition_layer", "hrnet.PoseHigherResolutionNet._make_stage", "hrnet.PoseHigherResolutionNet._make_transition_layer", "hrnet.PoseHigherResolutionNet._make_stage", "range", "hrnet.PoseHigherResolutionNet._out_features.append", "hrnet.PoseHigherResolutionNet._out_feature_channels.update", "hrnet.PoseHigherResolutionNet._out_feature_strides.update", "range", "range", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_layer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_transition_layer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet._make_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_transition_layer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet._make_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_transition_layer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet._make_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "cfg", ".", "MODEL", ".", "HRNET", ".", "STEM_INPLANES", "\n", "super", "(", "PoseHigherResolutionNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# stem net", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "BN_MOMENTUM", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "Bottleneck", ",", "64", ",", "4", ")", "\n", "\n", "self", ".", "stage2_cfg", "=", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE2", "\n", "num_channels", "=", "self", ".", "stage2_cfg", ".", "NUM_CHANNELS", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage2_cfg", ".", "BLOCK", "]", "\n", "num_channels", "=", "[", "num_channels", "[", "i", "]", "*", "block", ".", "expansion", "for", "i", "in", "range", "(", "len", "(", "num_channels", ")", ")", "]", "\n", "self", ".", "transition1", "=", "self", ".", "_make_transition_layer", "(", "[", "256", "]", ",", "num_channels", ")", "\n", "self", ".", "stage2", ",", "pre_stage_channels", "=", "self", ".", "_make_stage", "(", "self", ".", "stage2_cfg", ",", "num_channels", ")", "\n", "\n", "self", ".", "stage3_cfg", "=", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE3", "\n", "num_channels", "=", "self", ".", "stage3_cfg", ".", "NUM_CHANNELS", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage3_cfg", ".", "BLOCK", "]", "\n", "num_channels", "=", "[", "num_channels", "[", "i", "]", "*", "block", ".", "expansion", "for", "i", "in", "range", "(", "len", "(", "num_channels", ")", ")", "]", "\n", "self", ".", "transition2", "=", "self", ".", "_make_transition_layer", "(", "pre_stage_channels", ",", "num_channels", ")", "\n", "self", ".", "stage3", ",", "pre_stage_channels", "=", "self", ".", "_make_stage", "(", "self", ".", "stage3_cfg", ",", "num_channels", ")", "\n", "\n", "self", ".", "stage4_cfg", "=", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE4", "\n", "num_channels", "=", "self", ".", "stage4_cfg", ".", "NUM_CHANNELS", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage4_cfg", ".", "BLOCK", "]", "\n", "num_channels", "=", "[", "num_channels", "[", "i", "]", "*", "block", ".", "expansion", "for", "i", "in", "range", "(", "len", "(", "num_channels", ")", ")", "]", "\n", "self", ".", "transition3", "=", "self", ".", "_make_transition_layer", "(", "pre_stage_channels", ",", "num_channels", ")", "\n", "self", ".", "stage4", ",", "pre_stage_channels", "=", "self", ".", "_make_stage", "(", "\n", "self", ".", "stage4_cfg", ",", "num_channels", ",", "multi_scale_output", "=", "True", "\n", ")", "\n", "\n", "self", ".", "_out_features", "=", "[", "]", "\n", "self", ".", "_out_feature_channels", "=", "{", "}", "\n", "self", ".", "_out_feature_strides", "=", "{", "}", "\n", "\n", "for", "i", "in", "range", "(", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE4", ".", "NUM_BRANCHES", ")", ":", "\n", "            ", "self", ".", "_out_features", ".", "append", "(", "\"p%d\"", "%", "(", "i", "+", "1", ")", ")", "\n", "self", ".", "_out_feature_channels", ".", "update", "(", "\n", "{", "self", ".", "_out_features", "[", "-", "1", "]", ":", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE4", ".", "NUM_CHANNELS", "[", "i", "]", "}", "\n", ")", "\n", "self", ".", "_out_feature_strides", ".", "update", "(", "{", "self", ".", "_out_features", "[", "-", "1", "]", ":", "1", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._get_deconv_cfg": [[328, 340], ["None"], "methods", ["None"], ["", "", "def", "_get_deconv_cfg", "(", "self", ",", "deconv_kernel", ")", ":", "\n", "        ", "if", "deconv_kernel", "==", "4", ":", "\n", "            ", "padding", "=", "1", "\n", "output_padding", "=", "0", "\n", "", "elif", "deconv_kernel", "==", "3", ":", "\n", "            ", "padding", "=", "1", "\n", "output_padding", "=", "1", "\n", "", "elif", "deconv_kernel", "==", "2", ":", "\n", "            ", "padding", "=", "0", "\n", "output_padding", "=", "0", "\n", "\n", "", "return", "deconv_kernel", ",", "padding", ",", "output_padding", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_transition_layer": [[341, 382], ["len", "len", "range", "torch.ModuleList", "range", "transition_layers.append", "transition_layers.append", "transition_layers.append", "conv3x3s.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "methods", ["None"], ["", "def", "_make_transition_layer", "(", "self", ",", "num_channels_pre_layer", ",", "num_channels_cur_layer", ")", ":", "\n", "        ", "num_branches_cur", "=", "len", "(", "num_channels_cur_layer", ")", "\n", "num_branches_pre", "=", "len", "(", "num_channels_pre_layer", ")", "\n", "\n", "transition_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_branches_cur", ")", ":", "\n", "            ", "if", "i", "<", "num_branches_pre", ":", "\n", "                ", "if", "num_channels_cur_layer", "[", "i", "]", "!=", "num_channels_pre_layer", "[", "i", "]", ":", "\n", "                    ", "transition_layers", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "num_channels_pre_layer", "[", "i", "]", ",", "\n", "num_channels_cur_layer", "[", "i", "]", ",", "\n", "3", ",", "\n", "1", ",", "\n", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_channels_cur_layer", "[", "i", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "transition_layers", ".", "append", "(", "None", ")", "\n", "", "", "else", ":", "\n", "                ", "conv3x3s", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", "+", "1", "-", "num_branches_pre", ")", ":", "\n", "                    ", "inchannels", "=", "num_channels_pre_layer", "[", "-", "1", "]", "\n", "outchannels", "=", "(", "\n", "num_channels_cur_layer", "[", "i", "]", "if", "j", "==", "i", "-", "num_branches_pre", "else", "inchannels", "\n", ")", "\n", "conv3x3s", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "inchannels", ",", "outchannels", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "outchannels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", ")", "\n", "", "transition_layers", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "conv3x3s", ")", ")", "\n", "\n", "", "", "return", "nn", ".", "ModuleList", "(", "transition_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_layer": [[383, 404], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "self", ".", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ",", "momentum", "=", "BN_MOMENTUM", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet._make_stage": [[405, 433], ["range", "modules.append", "modules[].get_num_inchannels", "torch.Sequential", "hrnet.HighResolutionModule"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.HighResolutionModule.get_num_inchannels"], ["", "def", "_make_stage", "(", "self", ",", "layer_config", ",", "num_inchannels", ",", "multi_scale_output", "=", "True", ")", ":", "\n", "        ", "num_modules", "=", "layer_config", "[", "\"NUM_MODULES\"", "]", "\n", "num_branches", "=", "layer_config", "[", "\"NUM_BRANCHES\"", "]", "\n", "num_blocks", "=", "layer_config", "[", "\"NUM_BLOCKS\"", "]", "\n", "num_channels", "=", "layer_config", "[", "\"NUM_CHANNELS\"", "]", "\n", "block", "=", "blocks_dict", "[", "layer_config", "[", "\"BLOCK\"", "]", "]", "\n", "\n", "modules", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_modules", ")", ":", "\n", "# multi_scale_output is only used last module", "\n", "            ", "if", "not", "multi_scale_output", "and", "i", "==", "num_modules", "-", "1", ":", "\n", "                ", "reset_multi_scale_output", "=", "False", "\n", "", "else", ":", "\n", "                ", "reset_multi_scale_output", "=", "True", "\n", "\n", "", "modules", ".", "append", "(", "\n", "HighResolutionModule", "(", "\n", "num_branches", ",", "\n", "block", ",", "\n", "num_blocks", ",", "\n", "num_inchannels", ",", "\n", "num_channels", ",", "\n", "reset_multi_scale_output", ",", "\n", ")", "\n", ")", "\n", "num_inchannels", "=", "modules", "[", "-", "1", "]", ".", "get_num_inchannels", "(", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "modules", ")", ",", "num_inchannels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.PoseHigherResolutionNet.forward": [[434, 469], ["hrnet.PoseHigherResolutionNet.conv1", "hrnet.PoseHigherResolutionNet.bn1", "hrnet.PoseHigherResolutionNet.relu", "hrnet.PoseHigherResolutionNet.conv2", "hrnet.PoseHigherResolutionNet.bn2", "hrnet.PoseHigherResolutionNet.relu", "hrnet.PoseHigherResolutionNet.layer1", "range", "hrnet.PoseHigherResolutionNet.stage2", "range", "hrnet.PoseHigherResolutionNet.stage3", "range", "hrnet.PoseHigherResolutionNet.stage4", "dict", "len", "len", "zip", "x_list.append", "x_list.append", "x_list.append", "x_list.append", "x_list.append", "x_list.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "\n", "x_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "stage2_cfg", ".", "NUM_BRANCHES", ")", ":", "\n", "            ", "if", "self", ".", "transition1", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "x_list", ".", "append", "(", "self", ".", "transition1", "[", "i", "]", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "                ", "x_list", ".", "append", "(", "x", ")", "\n", "", "", "y_list", "=", "self", ".", "stage2", "(", "x_list", ")", "\n", "\n", "x_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "stage3_cfg", ".", "NUM_BRANCHES", ")", ":", "\n", "            ", "if", "self", ".", "transition2", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "x_list", ".", "append", "(", "self", ".", "transition2", "[", "i", "]", "(", "y_list", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "x_list", ".", "append", "(", "y_list", "[", "i", "]", ")", "\n", "", "", "y_list", "=", "self", ".", "stage3", "(", "x_list", ")", "\n", "\n", "x_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "stage4_cfg", ".", "NUM_BRANCHES", ")", ":", "\n", "            ", "if", "self", ".", "transition3", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "x_list", ".", "append", "(", "self", ".", "transition3", "[", "i", "]", "(", "y_list", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "x_list", ".", "append", "(", "y_list", "[", "i", "]", ")", "\n", "", "", "y_list", "=", "self", ".", "stage4", "(", "x_list", ")", "\n", "\n", "assert", "len", "(", "self", ".", "_out_features", ")", "==", "len", "(", "y_list", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "_out_features", ",", "y_list", ")", ")", "# final_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.conv3x3": [[24, 27], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.build_pose_hrnet_backbone": [[471, 475], ["detectron2.modeling.backbone.BACKBONE_REGISTRY.register", "hrnet.PoseHigherResolutionNet"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_pose_hrnet_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "model", "=", "PoseHigherResolutionNet", "(", "cfg", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseDatasetMapperTTA.__init__": [[16, 19], ["detectron2.modeling.test_time_augmentation.DatasetMapperTTA.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["ResizeShortestEdge", ",", "\n", "ResizeTransform", ",", "\n", "apply_augmentations", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseDatasetMapperTTA.__call__": [[20, 36], ["super().__call__", "dataset_dict[].permute().numpy", "detectron2.data.transforms.RandomRotation", "detectron2.data.transforms.apply_transform_gens", "torch.from_numpy", "copy.deepcopy", "fvcore.transforms.TransformList", "super().__call__.append", "dataset_dict[].permute", "numpy.copy", "numpy.ascontiguousarray", "new_numpy_image.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoreThresholdedExtractor.__call__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["from", "detectron2", ".", "structures", "import", "Boxes", ",", "Instances", "\n", "\n", "from", ".", "meta_arch", "import", "GeneralizedRCNN", "\n", "from", ".", "postprocessing", "import", "detector_postprocess", "\n", "from", ".", "roi_heads", ".", "fast_rcnn", "import", "fast_rcnn_inference_single_image", "\n", "\n", "__all__", "=", "[", "\"DatasetMapperTTA\"", ",", "\"GeneralizedRCNNWithTTA\"", "]", "\n", "\n", "\n", "class", "DatasetMapperTTA", ":", "\n", "    ", "\"\"\"\n    Implement test-time augmentation for detection data.\n    It is a callable which takes a dataset dict from a detection dataset,\n    and returns a list of dataset dicts where the images\n    are augmented from the input image by the transformations defined in the config.\n    This is used for test-time augmentation.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA.__init__": [[39, 53], ["transform_data.to", "detectron2.modeling.test_time_augmentation.GeneralizedRCNNWithTTA.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "min_sizes", ":", "List", "[", "int", "]", ",", "max_size", ":", "int", ",", "flip", ":", "bool", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            min_sizes: list of short-edge size to resize the image to\n            max_size: maximum height or width of resized images\n            flip: whether to apply flipping augmentation\n        \"\"\"", "\n", "self", ".", "min_sizes", "=", "min_sizes", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "flip", "=", "flip", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "return", "{", "\n", "\"min_sizes\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "MIN_SIZES", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._inference_one_image": [[55, 92], ["input[].to", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._get_augmented_inputs", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._merge_detections", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._turn_off_roi_heads", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._get_augmented_boxes", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._rescale_detected_boxes", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._batch_inference", "detectron2.modeling.postprocessing.detector_postprocess", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._reduce_pred_masks", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._reduce_pred_densepose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._get_augmented_inputs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._merge_detections", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._turn_off_roi_heads", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._get_augmented_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._rescale_detected_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._reduce_pred_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._reduce_pred_densepose"], ["\"flip\"", ":", "cfg", ".", "TEST", ".", "AUG", ".", "FLIP", ",", "\n", "}", "\n", "\n", "", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dict: a dict in standard model input format. See tutorials for details.\n\n        Returns:\n            list[dict]:\n                a list of dicts, which contain augmented version of the input image.\n                The total number of dicts is ``len(min_sizes) * (2 if flip else 1)``.\n                Each dict has field \"transforms\" which is a TransformList,\n                containing the transforms that are used to generate this image.\n        \"\"\"", "\n", "numpy_image", "=", "dataset_dict", "[", "\"image\"", "]", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "numpy", "(", ")", "\n", "shape", "=", "numpy_image", ".", "shape", "\n", "orig_shape", "=", "(", "dataset_dict", "[", "\"height\"", "]", ",", "dataset_dict", "[", "\"width\"", "]", ")", "\n", "if", "shape", "[", ":", "2", "]", "!=", "orig_shape", ":", "\n", "# It transforms the \"original\" image in the dataset to the input image", "\n", "            ", "pre_tfm", "=", "ResizeTransform", "(", "orig_shape", "[", "0", "]", ",", "orig_shape", "[", "1", "]", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "pre_tfm", "=", "NoOpTransform", "(", ")", "\n", "\n", "# Create all combinations of augmentations to use", "\n", "", "aug_candidates", "=", "[", "]", "# each element is a list[Augmentation]", "\n", "for", "min_size", "in", "self", ".", "min_sizes", ":", "\n", "            ", "resize", "=", "ResizeShortestEdge", "(", "min_size", ",", "self", ".", "max_size", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", "]", ")", "# resize only", "\n", "if", "self", ".", "flip", ":", "\n", "                ", "flip", "=", "RandomFlip", "(", "prob", "=", "1.0", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", ",", "flip", "]", ")", "# resize + flip", "\n", "\n", "# Apply all the augmentations", "\n", "", "", "ret", "=", "[", "]", "\n", "for", "aug", "in", "aug_candidates", ":", "\n", "            ", "new_image", ",", "tfms", "=", "apply_augmentations", "(", "aug", ",", "np", ".", "copy", "(", "numpy_image", ")", ")", "\n", "torch_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "new_image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._get_augmented_boxes": [[93, 113], ["test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._batch_inference", "zip", "torch.cat", "any", "tfm.inverse().apply_box", "torch.cat.append", "all_scores.extend", "all_classes.extend", "pred_boxes.cpu().numpy", "torch.from_numpy().to", "isinstance", "tfm.inverse", "pred_boxes.cpu", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.GeneralizedRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.inverse"], ["\n", "dic", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "\n", "dic", "[", "\"transforms\"", "]", "=", "pre_tfm", "+", "tfms", "\n", "dic", "[", "\"image\"", "]", "=", "torch_image", "\n", "ret", ".", "append", "(", "dic", ")", "\n", "", "return", "ret", "\n", "\n", "\n", "", "", "class", "GeneralizedRCNNWithTTA", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    A GeneralizedRCNN with test-time augmentation enabled.\n    Its :meth:`__call__` method has the same interface as :meth:`GeneralizedRCNN.forward`.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ",", "model", ",", "tta_mapper", "=", "None", ",", "batch_size", "=", "3", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._reduce_pred_densepose": [[114, 134], ["enumerate", "zip", "any", "test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._incremental_avg_dp", "converters.HFlipConverter.convert", "setattr", "isinstance", "test_time_augmentation._inverse_rotation", "getattr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._incremental_avg_dp", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation._inverse_rotation"], ["\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "model", ",", "DistributedDataParallel", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "", "assert", "isinstance", "(", "\n", "model", ",", "GeneralizedRCNN", "\n", ")", ",", "\"TTA is only supported on GeneralizedRCNN. Got a model of type {}\"", ".", "format", "(", "type", "(", "model", ")", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "assert", "not", "self", ".", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\"TTA for keypoint is not supported yet\"", "\n", "assert", "(", "\n", "not", "self", ".", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", ")", ",", "\"TTA for pre-computed proposals is not supported yet\"", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "if", "tta_mapper", "is", "None", ":", "\n", "            ", "tta_mapper", "=", "DatasetMapperTTA", "(", "cfg", ")", "\n", "", "self", ".", "tta_mapper", "=", "tta_mapper", "\n", "self", ".", "batch_size", "=", "batch_size", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.DensePoseGeneralizedRCNNWithTTA._incremental_avg_dp": [[136, 143], ["setattr", "setattr", "getattr", "getattr"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "_turn_off_roi_heads", "(", "self", ",", "attrs", ")", ":", "\n", "        ", "\"\"\"\n        Open a context where some heads in `model.roi_heads` are temporarily turned off.\n        Args:\n            attr (list[str]): the attribute in `model.roi_heads` which can be used\n                to turn off a specific head, e.g., \"mask_on\", \"keypoint_on\".\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation._inverse_rotation": [[145, 183], ["boxes.int().cpu().numpy.int().cpu().numpy", "rotate_box_inverse().astype", "torch.tensor().to().float", "numpy.maximum", "range", "len", "densepose_attrs[].clone", "torch.nn.functional.interpolate", "torch.nn.functional.pad", "torch.nn.functional.affine_grid", "torch.nn.functional.grid_sample", "len", "isinstance", "boxes.int().cpu().numpy.int().cpu", "test_time_augmentation.rotate_box_inverse", "torch.tensor().to", "min", "tuple", "min", "torch.nn.functional.interpolate", "wh_boxes[].tolist", "numpy.repeat", "boxes.int().cpu().numpy.int", "torch.tensor", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.rotate_box_inverse", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["old", "=", "{", "}", "\n", "for", "attr", "in", "attrs", ":", "\n", "            ", "try", ":", "\n", "                ", "old", "[", "attr", "]", "=", "getattr", "(", "roi_heads", ",", "attr", ")", "\n", "", "except", "AttributeError", ":", "\n", "# The head may not be implemented in certain ROIHeads", "\n", "                ", "pass", "\n", "\n", "", "", "if", "len", "(", "old", ".", "keys", "(", ")", ")", "==", "0", ":", "\n", "            ", "yield", "\n", "", "else", ":", "\n", "            ", "for", "attr", "in", "old", ".", "keys", "(", ")", ":", "\n", "                ", "setattr", "(", "roi_heads", ",", "attr", ",", "False", ")", "\n", "", "yield", "\n", "for", "attr", "in", "old", ".", "keys", "(", ")", ":", "\n", "                ", "setattr", "(", "roi_heads", ",", "attr", ",", "old", "[", "attr", "]", ")", "\n", "\n", "", "", "", "def", "_batch_inference", "(", "self", ",", "batched_inputs", ",", "detected_instances", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Execute inference on a list of inputs,\n        using batch size = self.batch_size, instead of the length of the list.\n\n        Inputs & outputs have the same format as :meth:`GeneralizedRCNN.inference`\n        \"\"\"", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "detected_instances", "=", "[", "None", "]", "*", "len", "(", "batched_inputs", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "input", ",", "instance", "in", "zip", "(", "count", "(", ")", ",", "batched_inputs", ",", "detected_instances", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "input", ")", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "if", "len", "(", "inputs", ")", "==", "self", ".", "batch_size", "or", "idx", "==", "len", "(", "batched_inputs", ")", "-", "1", ":", "\n", "                ", "outputs", ".", "extend", "(", "\n", "self", ".", "model", ".", "inference", "(", "\n", "inputs", ",", "\n", "instances", "if", "instances", "[", "0", "]", "is", "not", "None", "else", "None", ",", "\n", "do_postprocess", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.test_time_augmentation.rotate_box_inverse": [[185, 208], ["rot_tfm.inverse().apply_box", "rot_tfm.inverse"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.inverse"], ["inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "", "", "return", "outputs", "\n", "\n", "", "def", "__call__", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Same input/output format as :meth:`GeneralizedRCNN.forward`\n        \"\"\"", "\n", "\n", "def", "_maybe_read_image", "(", "dataset_dict", ")", ":", "\n", "            ", "ret", "=", "copy", ".", "copy", "(", "dataset_dict", ")", "\n", "if", "\"image\"", "not", "in", "ret", ":", "\n", "                ", "image", "=", "read_image", "(", "ret", ".", "pop", "(", "\"file_name\"", ")", ",", "self", ".", "model", ".", "input_format", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "# CHW", "\n", "ret", "[", "\"image\"", "]", "=", "image", "\n", "", "if", "\"height\"", "not", "in", "ret", "and", "\"width\"", "not", "in", "ret", ":", "\n", "                ", "ret", "[", "\"height\"", "]", "=", "image", ".", "shape", "[", "1", "]", "\n", "ret", "[", "\"width\"", "]", "=", "image", ".", "shape", "[", "2", "]", "\n", "", "return", "ret", "\n", "\n", "", "return", "[", "self", ".", "_inference_one_image", "(", "_maybe_read_image", "(", "x", ")", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "def", "_inference_one_image", "(", "self", ",", "input", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.HRFPN.__init__": [[48, 127], ["detectron2.modeling.backbone.backbone.Backbone.__init__", "isinstance", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "len", "hrfpn.HRFPN.interp_conv.append", "hrfpn.HRFPN.reduction_pooling_conv.append", "hrfpn.HRFPN._out_features.append", "hrfpn.HRFPN._out_feature_channels.update", "hrfpn.HRFPN._out_feature_strides.update", "hrfpn.HRFPN.fpn_conv.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["def", "__init__", "(", "\n", "self", ",", "\n", "bottom_up", ",", "\n", "in_features", ",", "\n", "n_out_features", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "pooling", "=", "\"AVG\"", ",", "\n", "share_conv", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "HRFPN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "in_channels", ",", "list", ")", "\n", "self", ".", "bottom_up", "=", "bottom_up", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "n_out_features", "=", "n_out_features", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_ins", "=", "len", "(", "in_channels", ")", "\n", "self", ".", "share_conv", "=", "share_conv", "\n", "\n", "if", "self", ".", "share_conv", ":", "\n", "            ", "self", ".", "fpn_conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "out_channels", ",", "out_channels", "=", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fpn_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_out_features", ")", ":", "\n", "                ", "self", ".", "fpn_conv", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "out_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "\n", "# Custom change: Replaces a simple bilinear interpolation", "\n", "", "", "self", ".", "interp_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "in_features", ")", ")", ":", "\n", "            ", "self", ".", "interp_conv", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "\n", "in_channels", "=", "in_channels", "[", "i", "]", ",", "\n", "out_channels", "=", "in_channels", "[", "i", "]", ",", "\n", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", "**", "i", ",", "\n", "padding", "=", "0", ",", "\n", "output_padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "in_channels", "[", "i", "]", ",", "momentum", "=", "0.1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# Custom change: Replaces a couple (reduction conv + pooling) by one conv", "\n", "", "self", ".", "reduction_pooling_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_out_features", ")", ":", "\n", "            ", "self", ".", "reduction_pooling_conv", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "sum", "(", "in_channels", ")", ",", "out_channels", ",", "kernel_size", "=", "2", "**", "i", ",", "stride", "=", "2", "**", "i", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "momentum", "=", "0.1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "if", "pooling", "==", "\"MAX\"", ":", "\n", "            ", "self", ".", "pooling", "=", "F", ".", "max_pool2d", "\n", "", "else", ":", "\n", "            ", "self", ".", "pooling", "=", "F", ".", "avg_pool2d", "\n", "\n", "", "self", ".", "_out_features", "=", "[", "]", "\n", "self", ".", "_out_feature_channels", "=", "{", "}", "\n", "self", ".", "_out_feature_strides", "=", "{", "}", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_out_features", ")", ":", "\n", "            ", "self", ".", "_out_features", ".", "append", "(", "\"p%d\"", "%", "(", "i", "+", "1", ")", ")", "\n", "self", ".", "_out_feature_channels", ".", "update", "(", "{", "self", ".", "_out_features", "[", "-", "1", "]", ":", "self", ".", "out_channels", "}", ")", "\n", "self", ".", "_out_feature_strides", ".", "update", "(", "{", "self", ".", "_out_features", "[", "-", "1", "]", ":", "2", "**", "(", "i", "+", "2", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.HRFPN.init_weights": [[129, 134], ["hrfpn.HRFPN.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "a", "=", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.HRFPN.forward": [[135, 162], ["hrfpn.HRFPN.bottom_up", "range", "min", "min", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "range", "dict", "len", "len", "len", "outs.append", "outs.append", "len", "len", "len", "len", "zip", "outputs.append", "outputs.append", "hrfpn.HRFPN.fpn_conv"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "bottom_up_features", "=", "self", ".", "bottom_up", "(", "inputs", ")", "\n", "assert", "len", "(", "bottom_up_features", ")", "==", "len", "(", "self", ".", "in_features", ")", "\n", "inputs", "=", "[", "bottom_up_features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "\n", "outs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "            ", "outs", ".", "append", "(", "self", ".", "interp_conv", "[", "i", "]", "(", "inputs", "[", "i", "]", ")", ")", "\n", "", "shape_2", "=", "min", "(", "o", ".", "shape", "[", "2", "]", "for", "o", "in", "outs", ")", "\n", "shape_3", "=", "min", "(", "o", ".", "shape", "[", "3", "]", "for", "o", "in", "outs", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "o", "[", ":", ",", ":", ",", ":", "shape_2", ",", ":", "shape_3", "]", "for", "o", "in", "outs", "]", ",", "dim", "=", "1", ")", "\n", "outs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_out_features", ")", ":", "\n", "            ", "outs", ".", "append", "(", "self", ".", "reduction_pooling_conv", "[", "i", "]", "(", "out", ")", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "outs", ")", ")", ":", "# Make shapes consistent", "\n", "            ", "outs", "[", "-", "1", "-", "i", "]", "=", "outs", "[", "-", "1", "-", "i", "]", "[", "\n", ":", ",", ":", ",", ":", "outs", "[", "-", "1", "]", ".", "shape", "[", "2", "]", "*", "2", "**", "i", ",", ":", "outs", "[", "-", "1", "]", ".", "shape", "[", "3", "]", "*", "2", "**", "i", "\n", "]", "\n", "", "outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "outs", ")", ")", ":", "\n", "            ", "if", "self", ".", "share_conv", ":", "\n", "                ", "outputs", ".", "append", "(", "self", ".", "fpn_conv", "(", "outs", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "self", ".", "fpn_conv", "[", "i", "]", "(", "outs", "[", "i", "]", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "self", ".", "_out_features", ")", "==", "len", "(", "outputs", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "_out_features", ",", "outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrfpn.build_hrfpn_backbone": [[164, 183], ["detectron2.modeling.backbone.BACKBONE_REGISTRY.register", "len", "hrnet.build_pose_hrnet_backbone", "hrfpn.HRFPN", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.hrnet.build_pose_hrnet_backbone"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_hrfpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "\n", "    ", "in_channels", "=", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE4", ".", "NUM_CHANNELS", "\n", "in_features", "=", "[", "\"p%d\"", "%", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "cfg", ".", "MODEL", ".", "HRNET", ".", "STAGE4", ".", "NUM_BRANCHES", ")", "]", "\n", "n_out_features", "=", "len", "(", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", ")", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "HRNET", ".", "HRFPN", ".", "OUT_CHANNELS", "\n", "hrnet", "=", "build_pose_hrnet_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "hrfpn", "=", "HRFPN", "(", "\n", "hrnet", ",", "\n", "in_features", ",", "\n", "n_out_features", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "pooling", "=", "\"AVG\"", ",", "\n", "share_conv", "=", "False", ",", "\n", ")", "\n", "\n", "return", "hrfpn", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.initialize_module_params": [[6, 12], ["module.named_parameters", "torch.nn.init.constant_", "torch.nn.init.kaiming_normal_"], "function", ["None"], ["import", "torch", "\n", "\n", "\n", "def", "cat", "(", "tensors", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.confidence.DensePoseConfidenceModelConfig.from_cfg": [[61, 72], ["confidence.DensePoseConfidenceModelConfig", "confidence.DensePoseUVConfidenceConfig", "confidence.DensePoseSegmConfidenceConfig", "confidence.DensePoseUVConfidenceType"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "from_cfg", "(", "cfg", ":", "CfgNode", ")", "->", "\"DensePoseConfidenceModelConfig\"", ":", "\n", "        ", "return", "DensePoseConfidenceModelConfig", "(", "\n", "uv_confidence", "=", "DensePoseUVConfidenceConfig", "(", "\n", "enabled", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UV_CONFIDENCE", ".", "ENABLED", ",", "\n", "epsilon", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UV_CONFIDENCE", ".", "EPSILON", ",", "\n", "type", "=", "DensePoseUVConfidenceType", "(", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UV_CONFIDENCE", ".", "TYPE", ")", ",", "\n", ")", ",", "\n", "segm_confidence", "=", "DensePoseSegmConfidenceConfig", "(", "\n", "enabled", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "SEGM_CONFIDENCE", ".", "ENABLED", ",", "\n", "epsilon", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "SEGM_CONFIDENCE", ".", "EPSILON", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.filter.DensePoseDataFilter.__init__": [[12, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "self", ".", "iou_threshold", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "FG_IOU_THRESHOLD", "\n", "self", ".", "keep_masks", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "COARSE_SEGM_TRAINED_BY_MASKS", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.filter.DensePoseDataFilter.__call__": [[16, 95], ["torch.no_grad", "enumerate", "detectron2.structures.boxes.matched_boxlist_iou", "len", "proposals_filtered.append", "len", "hasattr", "len", "len", "len", "len", "len", "proposals_per_image.has", "len", "hasattr", "enumerate", "proposals_per_image.has", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.matched_boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["", "@", "torch", ".", "no_grad", "(", ")", "# pyre-ignore[56]", "\n", "def", "__call__", "(", "self", ",", "features", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "proposals_with_targets", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Filters proposals with targets to keep only the ones relevant for\n        DensePose training\n\n        Args:\n            features (list[Tensor]): input data as a list of features,\n                each feature is a tensor. Axis 0 represents the number of\n                images `N` in the input data; axes 1-3 are channels,\n                height, and width, which may vary between features\n                (e.g., if a feature pyramid is used).\n            proposals_with_targets (list[Instances]): length `N` list of\n                `Instances`. The i-th `Instances` contains instances\n                (proposals, GT) for the i-th input image,\n        Returns:\n            list[Tensor]: filtered features\n            list[Instances]: filtered proposals\n        \"\"\"", "\n", "proposals_filtered", "=", "[", "]", "\n", "# TODO: the commented out code was supposed to correctly deal with situations", "\n", "# where no valid DensePose GT is available for certain images. The corresponding", "\n", "# image features were sliced and proposals were filtered. This led to performance", "\n", "# deterioration, both in terms of runtime and in terms of evaluation results.", "\n", "#", "\n", "# feature_mask = torch.ones(", "\n", "#    len(proposals_with_targets),", "\n", "#    dtype=torch.bool,", "\n", "#    device=features[0].device if len(features) > 0 else torch.device(\"cpu\"),", "\n", "# )", "\n", "for", "i", ",", "proposals_per_image", "in", "enumerate", "(", "proposals_with_targets", ")", ":", "\n", "            ", "if", "not", "proposals_per_image", ".", "has", "(", "\"gt_densepose\"", ")", "and", "(", "\n", "not", "proposals_per_image", ".", "has", "(", "\"gt_masks\"", ")", "or", "not", "self", ".", "keep_masks", "\n", ")", ":", "\n", "# feature_mask[i] = 0", "\n", "                ", "continue", "\n", "", "gt_boxes", "=", "proposals_per_image", ".", "gt_boxes", "\n", "est_boxes", "=", "proposals_per_image", ".", "proposal_boxes", "\n", "# apply match threshold for densepose head", "\n", "iou", "=", "matched_boxlist_iou", "(", "gt_boxes", ",", "est_boxes", ")", "\n", "iou_select", "=", "iou", ">", "self", ".", "iou_threshold", "\n", "proposals_per_image", "=", "proposals_per_image", "[", "iou_select", "]", "# pyre-ignore[6]", "\n", "\n", "N_gt_boxes", "=", "len", "(", "proposals_per_image", ".", "gt_boxes", ")", "\n", "assert", "N_gt_boxes", "==", "len", "(", "proposals_per_image", ".", "proposal_boxes", ")", ",", "(", "\n", "f\"The number of GT boxes {N_gt_boxes} is different from the \"", "\n", "f\"number of proposal boxes {len(proposals_per_image.proposal_boxes)}\"", "\n", ")", "\n", "# filter out any target without suitable annotation", "\n", "if", "self", ".", "keep_masks", ":", "\n", "                ", "gt_masks", "=", "(", "\n", "proposals_per_image", ".", "gt_masks", "\n", "if", "hasattr", "(", "proposals_per_image", ",", "\"gt_masks\"", ")", "\n", "else", "[", "None", "]", "*", "N_gt_boxes", "\n", ")", "\n", "", "else", ":", "\n", "                ", "gt_masks", "=", "[", "None", "]", "*", "N_gt_boxes", "\n", "", "gt_densepose", "=", "(", "\n", "proposals_per_image", ".", "gt_densepose", "\n", "if", "hasattr", "(", "proposals_per_image", ",", "\"gt_densepose\"", ")", "\n", "else", "[", "None", "]", "*", "N_gt_boxes", "\n", ")", "\n", "assert", "len", "(", "gt_masks", ")", "==", "N_gt_boxes", "\n", "assert", "len", "(", "gt_densepose", ")", "==", "N_gt_boxes", "\n", "selected_indices", "=", "[", "\n", "i", "\n", "for", "i", ",", "(", "dp_target", ",", "mask_target", ")", "in", "enumerate", "(", "zip", "(", "gt_densepose", ",", "gt_masks", ")", ")", "\n", "if", "(", "dp_target", "is", "not", "None", ")", "or", "(", "mask_target", "is", "not", "None", ")", "\n", "]", "\n", "# if not len(selected_indices):", "\n", "#     feature_mask[i] = 0", "\n", "#     continue", "\n", "if", "len", "(", "selected_indices", ")", "!=", "N_gt_boxes", ":", "\n", "                ", "proposals_per_image", "=", "proposals_per_image", "[", "selected_indices", "]", "# pyre-ignore[6]", "\n", "", "assert", "len", "(", "proposals_per_image", ".", "gt_boxes", ")", "==", "len", "(", "proposals_per_image", ".", "proposal_boxes", ")", "\n", "proposals_filtered", ".", "append", "(", "proposals_per_image", ")", "\n", "# features_filtered = [feature[feature_mask] for feature in features]", "\n", "# return features_filtered, proposals_filtered", "\n", "", "return", "features", ",", "proposals_filtered", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNHeadConvRegressor.__init__": [[21, 37], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ",", "num_anchors", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            cfg              : config\n            in_channels (int): number of channels of the input feature\n            num_anchors (int): number of anchors to be predicted\n        \"\"\"", "\n", "super", "(", "RPNHeadConvRegressor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "num_anchors", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", "\n", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "cls_logits", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNHeadConvRegressor.forward": [[38, 44], ["isinstance", "rpn.RPNHeadConvRegressor.cls_logits", "rpn.RPNHeadConvRegressor.bbox_pred"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", "\n", "logits", "=", "[", "self", ".", "cls_logits", "(", "y", ")", "for", "y", "in", "x", "]", "\n", "bbox_reg", "=", "[", "self", ".", "bbox_pred", "(", "y", ")", "for", "y", "in", "x", "]", "\n", "\n", "return", "logits", ",", "bbox_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNHeadFeatureSingleConv.__init__": [[51, 67], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            cfg              : config\n            in_channels (int): number of channels of the input feature\n        \"\"\"", "\n", "super", "(", "RPNHeadFeatureSingleConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "", "self", ".", "out_channels", "=", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNHeadFeatureSingleConv.forward": [[68, 73], ["isinstance", "torch.relu", "torch.relu", "rpn.RPNHeadFeatureSingleConv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", "\n", "x", "=", "[", "F", ".", "relu", "(", "self", ".", "conv", "(", "z", ")", ")", "for", "z", "in", "x", "]", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNHead.__init__": [[81, 100], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ",", "num_anchors", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            cfg              : config\n            in_channels (int): number of channels of the input feature\n            num_anchors (int): number of anchors to be predicted\n        \"\"\"", "\n", "super", "(", "RPNHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "num_anchors", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", "\n", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv", ",", "self", ".", "cls_logits", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNHead.forward": [[101, 109], ["torch.relu", "torch.relu", "logits.append", "bbox_reg.append", "rpn.RPNHead.conv", "rpn.RPNHead.cls_logits", "rpn.RPNHead.bbox_pred"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "for", "feature", "in", "x", ":", "\n", "            ", "t", "=", "F", ".", "relu", "(", "self", ".", "conv", "(", "feature", ")", ")", "\n", "logits", ".", "append", "(", "self", ".", "cls_logits", "(", "t", ")", ")", "\n", "bbox_reg", ".", "append", "(", "self", ".", "bbox_pred", "(", "t", ")", ")", "\n", "", "return", "logits", ",", "bbox_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNModule.__init__": [[117, 141], ["super().__init__", "cfg.clone", "anchor_generator.make_anchor_generator.make_anchor_generator", "rpn_head", "fcos_core.modeling.box_coder.BoxCoder", "inference.make_rpn_postprocessor", "inference.make_rpn_postprocessor", "loss.make_rpn_loss_evaluator", "anchor_generator.make_anchor_generator.make_anchor_generator.num_anchors_per_location"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.make_anchor_generator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.make_rpn_postprocessor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.make_rpn_postprocessor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.make_rpn_loss_evaluator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.num_anchors_per_location"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "RPNModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "\n", "anchor_generator", "=", "make_anchor_generator", "(", "cfg", ")", "\n", "\n", "rpn_head", "=", "registry", ".", "RPN_HEADS", "[", "cfg", ".", "MODEL", ".", "RPN", ".", "RPN_HEAD", "]", "\n", "head", "=", "rpn_head", "(", "\n", "cfg", ",", "in_channels", ",", "anchor_generator", ".", "num_anchors_per_location", "(", ")", "[", "0", "]", "\n", ")", "\n", "\n", "rpn_box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "\n", "box_selector_train", "=", "make_rpn_postprocessor", "(", "cfg", ",", "rpn_box_coder", ",", "is_train", "=", "True", ")", "\n", "box_selector_test", "=", "make_rpn_postprocessor", "(", "cfg", ",", "rpn_box_coder", ",", "is_train", "=", "False", ")", "\n", "\n", "loss_evaluator", "=", "make_rpn_loss_evaluator", "(", "cfg", ",", "rpn_box_coder", ")", "\n", "\n", "self", ".", "anchor_generator", "=", "anchor_generator", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "box_selector_train", "=", "box_selector_train", "\n", "self", ".", "box_selector_test", "=", "box_selector_test", "\n", "self", ".", "loss_evaluator", "=", "loss_evaluator", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNModule.forward": [[142, 164], ["rpn.RPNModule.head", "rpn.RPNModule.anchor_generator", "rpn.RPNModule._forward_train", "rpn.RPNModule._forward_test"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_test"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (ImageList): images for which we want to compute the predictions\n            features (list[Tensor]): features computed from the images that are\n                used for computing the predictions. Each tensor in the list\n                correspond to different feature levels\n            targets (list[BoxList): ground-truth boxes present in the image (optional)\n\n        Returns:\n            boxes (list[BoxList]): the predicted boxes from the RPN, one BoxList per\n                image.\n            losses (dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"", "\n", "objectness", ",", "rpn_box_regression", "=", "self", ".", "head", "(", "features", ")", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "images", ",", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_train", "(", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_test", "(", "anchors", ",", "objectness", ",", "rpn_box_regression", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNModule._forward_train": [[165, 187], ["rpn.RPNModule.loss_evaluator", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "rpn.RPNModule.box_selector_train"], "methods", ["None"], ["", "", "def", "_forward_train", "(", "self", ",", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "MODEL", ".", "RPN_ONLY", ":", "\n", "# When training an RPN-only model, the loss is determined by the", "\n", "# predicted objectness and rpn_box_regression values and there is", "\n", "# no need to transform the anchors into predicted boxes; this is an", "\n", "# optimization that avoids the unnecessary transformation.", "\n", "            ", "boxes", "=", "anchors", "\n", "", "else", ":", "\n", "# For end-to-end models, anchors must be transformed into boxes and", "\n", "# sampled into a training batch.", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "boxes", "=", "self", ".", "box_selector_train", "(", "\n", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", "\n", ")", "\n", "", "", "loss_objectness", ",", "loss_rpn_box_reg", "=", "self", ".", "loss_evaluator", "(", "\n", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", "\n", ")", "\n", "losses", "=", "{", "\n", "\"loss_objectness\"", ":", "loss_objectness", ",", "\n", "\"loss_rpn_box_reg\"", ":", "loss_rpn_box_reg", ",", "\n", "}", "\n", "return", "boxes", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.RPNModule._forward_test": [[188, 200], ["rpn.RPNModule.box_selector_test", "box.get_field().sort", "zip", "box.get_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "_forward_test", "(", "self", ",", "anchors", ",", "objectness", ",", "rpn_box_regression", ")", ":", "\n", "        ", "boxes", "=", "self", ".", "box_selector_test", "(", "anchors", ",", "objectness", ",", "rpn_box_regression", ")", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "RPN_ONLY", ":", "\n", "# For end-to-end models, the RPN proposals are an intermediate state", "\n", "# and don't bother to sort them in decreasing score order. For RPN-only", "\n", "# models, the proposals are the final output and we return them in", "\n", "# high-to-low confidence order.", "\n", "            ", "inds", "=", "[", "\n", "box", ".", "get_field", "(", "\"objectness\"", ")", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "for", "box", "in", "boxes", "\n", "]", "\n", "boxes", "=", "[", "box", "[", "ind", "]", "for", "box", ",", "ind", "in", "zip", "(", "boxes", ",", "inds", ")", "]", "\n", "", "return", "boxes", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.build_rpn": [[202, 214], ["rpn.RPNModule", "fcos_core.modeling.rpn.atss.atss.build_atss", "fcos_core.modeling.rpn.fcos.fcos.build_fcos", "fcos_core.modeling.rpn.retinanet.retinanet.build_retinanet"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.build_atss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.build_fcos", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.build_retinanet"], ["", "", "def", "build_rpn", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "\"\"\"\n    This gives the gist of it. Not super important because it doesn't change as much\n    \"\"\"", "\n", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", ":", "\n", "        ", "return", "build_atss", "(", "cfg", ",", "in_channels", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "FCOS_ON", ":", "\n", "        ", "return", "build_fcos", "(", "cfg", ",", "in_channels", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "RETINANET_ON", ":", "\n", "        ", "return", "build_retinanet", "(", "cfg", ",", "in_channels", ")", "\n", "\n", "", "return", "RPNModule", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.__init__": [[16, 20], ["torch.nn.Module.__init__", "anchor_generator.BufferList.extend"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["def", "__init__", "(", "self", ",", "buffers", "=", "None", ")", ":", "\n", "        ", "super", "(", "BufferList", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "buffers", "is", "not", "None", ":", "\n", "            ", "self", ".", "extend", "(", "buffers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend": [[21, 26], ["len", "enumerate", "anchor_generator.BufferList.register_buffer", "str"], "methods", ["None"], ["", "", "def", "extend", "(", "self", ",", "buffers", ")", ":", "\n", "        ", "offset", "=", "len", "(", "self", ")", "\n", "for", "i", ",", "buffer", "in", "enumerate", "(", "buffers", ")", ":", "\n", "            ", "self", ".", "register_buffer", "(", "str", "(", "offset", "+", "i", ")", ",", "buffer", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.__len__": [[27, 29], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_buffers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.__iter__": [[30, 32], ["iter", "anchor_generator.BufferList._buffers.values"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "_buffers", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.__init__": [[40, 71], ["torch.nn.Module.__init__", "anchor_generator.BufferList", "len", "generate_anchors().float", "len", "len", "RuntimeError", "generate_anchors().float", "zip", "anchor_generator.generate_anchors", "anchor_generator.generate_anchors", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.generate_anchors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.generate_anchors"], ["def", "__init__", "(", "\n", "self", ",", "\n", "sizes", "=", "(", "128", ",", "256", ",", "512", ")", ",", "\n", "aspect_ratios", "=", "(", "0.5", ",", "1.0", ",", "2.0", ")", ",", "\n", "anchor_strides", "=", "(", "8", ",", "16", ",", "32", ")", ",", "\n", "straddle_thresh", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "AnchorGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "len", "(", "anchor_strides", ")", "==", "1", ":", "\n", "            ", "anchor_stride", "=", "anchor_strides", "[", "0", "]", "\n", "cell_anchors", "=", "[", "\n", "generate_anchors", "(", "anchor_stride", ",", "sizes", ",", "aspect_ratios", ")", ".", "float", "(", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "anchor_strides", ")", "!=", "len", "(", "sizes", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"FPN should have #anchor_strides == #sizes\"", ")", "\n", "\n", "", "cell_anchors", "=", "[", "\n", "generate_anchors", "(", "\n", "anchor_stride", ",", "\n", "size", "if", "isinstance", "(", "size", ",", "(", "tuple", ",", "list", ")", ")", "else", "(", "size", ",", ")", ",", "\n", "aspect_ratios", "\n", ")", ".", "float", "(", ")", "\n", "for", "anchor_stride", ",", "size", "in", "zip", "(", "anchor_strides", ",", "sizes", ")", "\n", "]", "\n", "", "self", ".", "strides", "=", "anchor_strides", "\n", "self", ".", "cell_anchors", "=", "BufferList", "(", "cell_anchors", ")", "\n", "self", ".", "straddle_thresh", "=", "straddle_thresh", "\n", "\n", "", "def", "num_anchors_per_location", "(", "self", ")", ":", "\n", "        ", "return", "[", "len", "(", "cell_anchors", ")", "for", "cell_anchors", "in", "self", ".", "cell_anchors", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.num_anchors_per_location": [[72, 74], ["len"], "methods", ["None"], ["\n", "", "def", "grid_anchors", "(", "self", ",", "grid_sizes", ")", ":", "\n", "        ", "anchors", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.grid_anchors": [[75, 98], ["zip", "torch.arange", "torch.arange", "torch.meshgrid", "shift_x.reshape.reshape.reshape", "shift_y.reshape.reshape.reshape", "torch.stack", "anchors.append", "torch.stack.view", "base_anchors.view"], "methods", ["None"], ["for", "size", ",", "stride", ",", "base_anchors", "in", "zip", "(", "\n", "grid_sizes", ",", "self", ".", "strides", ",", "self", ".", "cell_anchors", "\n", ")", ":", "\n", "            ", "grid_height", ",", "grid_width", "=", "size", "\n", "device", "=", "base_anchors", ".", "device", "\n", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "grid_width", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "grid_height", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "shifts", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ",", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "\n", "\n", "anchors", ".", "append", "(", "\n", "(", "shifts", ".", "view", "(", "-", "1", ",", "1", ",", "4", ")", "+", "base_anchors", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "", "return", "anchors", "\n", "\n", "", "def", "add_visibility_to", "(", "self", ",", "boxlist", ")", ":", "\n", "        ", "image_width", ",", "image_height", "=", "boxlist", ".", "size", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.add_visibility_to": [[99, 113], ["boxlist.add_field", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["anchors", "=", "boxlist", ".", "bbox", "\n", "if", "self", ".", "straddle_thresh", ">=", "0", ":", "\n", "            ", "inds_inside", "=", "(", "\n", "(", "anchors", "[", "...", ",", "0", "]", ">=", "-", "self", ".", "straddle_thresh", ")", "\n", "&", "(", "anchors", "[", "...", ",", "1", "]", ">=", "-", "self", ".", "straddle_thresh", ")", "\n", "&", "(", "anchors", "[", "...", ",", "2", "]", "<", "image_width", "+", "self", ".", "straddle_thresh", ")", "\n", "&", "(", "anchors", "[", "...", ",", "3", "]", "<", "image_height", "+", "self", ".", "straddle_thresh", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "anchors", ".", "device", "\n", "inds_inside", "=", "torch", ".", "ones", "(", "anchors", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "", "boxlist", ".", "add_field", "(", "\"visibility\"", ",", "inds_inside", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "image_list", ",", "feature_maps", ")", ":", "\n", "        ", "grid_sizes", "=", "[", "feature_map", ".", "shape", "[", "-", "2", ":", "]", "for", "feature_map", "in", "feature_maps", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.forward": [[114, 128], ["anchor_generator.AnchorGenerator.grid_anchors", "enumerate", "anchors.append", "fcos_core.structures.bounding_box.BoxList", "anchor_generator.AnchorGenerator.add_visibility_to", "anchors_in_image.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.grid_anchors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.AnchorGenerator.add_visibility_to"], ["anchors_over_all_feature_maps", "=", "self", ".", "grid_anchors", "(", "grid_sizes", ")", "\n", "anchors", "=", "[", "]", "\n", "for", "i", ",", "(", "image_height", ",", "image_width", ")", "in", "enumerate", "(", "image_list", ".", "image_sizes", ")", ":", "\n", "            ", "anchors_in_image", "=", "[", "]", "\n", "for", "anchors_per_feature_map", "in", "anchors_over_all_feature_maps", ":", "\n", "                ", "boxlist", "=", "BoxList", "(", "\n", "anchors_per_feature_map", ",", "(", "image_width", ",", "image_height", ")", ",", "mode", "=", "\"xyxy\"", "\n", ")", "\n", "self", ".", "add_visibility_to", "(", "boxlist", ")", "\n", "anchors_in_image", ".", "append", "(", "boxlist", ")", "\n", "", "anchors", ".", "append", "(", "anchors_in_image", ")", "\n", "", "return", "anchors", "\n", "\n", "\n", "", "", "def", "make_anchor_generator", "(", "config", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.make_anchor_generator": [[130, 147], ["anchor_generator.AnchorGenerator", "len", "len", "len"], "function", ["None"], ["aspect_ratios", "=", "config", ".", "MODEL", ".", "RPN", ".", "ASPECT_RATIOS", "\n", "anchor_stride", "=", "config", ".", "MODEL", ".", "RPN", ".", "ANCHOR_STRIDE", "\n", "straddle_thresh", "=", "config", ".", "MODEL", ".", "RPN", ".", "STRADDLE_THRESH", "\n", "\n", "if", "config", ".", "MODEL", ".", "RPN", ".", "USE_FPN", ":", "\n", "        ", "assert", "len", "(", "anchor_stride", ")", "==", "len", "(", "\n", "anchor_sizes", "\n", ")", ",", "\"FPN should have len(ANCHOR_STRIDE) == len(ANCHOR_SIZES)\"", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "anchor_stride", ")", "==", "1", ",", "\"Non-FPN should have a single ANCHOR_STRIDE\"", "\n", "", "anchor_generator", "=", "AnchorGenerator", "(", "\n", "anchor_sizes", ",", "aspect_ratios", ",", "anchor_stride", ",", "straddle_thresh", "\n", ")", "\n", "return", "anchor_generator", "\n", "\n", "\n", "", "def", "make_anchor_generator_retinanet", "(", "config", ")", ":", "\n", "    ", "anchor_sizes", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_SIZES", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.make_anchor_generator_retinanet": [[149, 170], ["anchor_generator.AnchorGenerator", "len", "len", "range", "new_anchor_sizes.append", "tuple", "per_layer_anchor_sizes.append", "tuple", "float"], "function", ["None"], ["anchor_strides", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_STRIDES", "\n", "straddle_thresh", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "STRADDLE_THRESH", "\n", "octave", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "OCTAVE", "\n", "scales_per_octave", "=", "config", ".", "MODEL", ".", "RETINANET", ".", "SCALES_PER_OCTAVE", "\n", "\n", "assert", "len", "(", "anchor_strides", ")", "==", "len", "(", "anchor_sizes", ")", ",", "\"Only support FPN now\"", "\n", "new_anchor_sizes", "=", "[", "]", "\n", "for", "size", "in", "anchor_sizes", ":", "\n", "        ", "per_layer_anchor_sizes", "=", "[", "]", "\n", "for", "scale_per_octave", "in", "range", "(", "scales_per_octave", ")", ":", "\n", "            ", "octave_scale", "=", "octave", "**", "(", "scale_per_octave", "/", "float", "(", "scales_per_octave", ")", ")", "\n", "per_layer_anchor_sizes", ".", "append", "(", "octave_scale", "*", "size", ")", "\n", "", "new_anchor_sizes", ".", "append", "(", "tuple", "(", "per_layer_anchor_sizes", ")", ")", "\n", "\n", "", "anchor_generator", "=", "AnchorGenerator", "(", "\n", "tuple", "(", "new_anchor_sizes", ")", ",", "aspect_ratios", ",", "anchor_strides", ",", "straddle_thresh", "\n", ")", "\n", "return", "anchor_generator", "\n", "\n", "\n", "", "def", "make_anchor_generator_atss", "(", "config", ")", ":", "\n", "    ", "anchor_sizes", "=", "config", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_SIZES", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.make_anchor_generator_atss": [[172, 193], ["anchor_generator.AnchorGenerator", "len", "len", "range", "new_anchor_sizes.append", "tuple", "per_layer_anchor_sizes.append", "tuple", "float"], "function", ["None"], ["anchor_strides", "=", "config", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_STRIDES", "\n", "straddle_thresh", "=", "config", ".", "MODEL", ".", "ATSS", ".", "STRADDLE_THRESH", "\n", "octave", "=", "config", ".", "MODEL", ".", "ATSS", ".", "OCTAVE", "\n", "scales_per_octave", "=", "config", ".", "MODEL", ".", "ATSS", ".", "SCALES_PER_OCTAVE", "\n", "\n", "assert", "len", "(", "anchor_strides", ")", "==", "len", "(", "anchor_sizes", ")", ",", "\"Only support FPN now\"", "\n", "new_anchor_sizes", "=", "[", "]", "\n", "for", "size", "in", "anchor_sizes", ":", "\n", "        ", "per_layer_anchor_sizes", "=", "[", "]", "\n", "for", "scale_per_octave", "in", "range", "(", "scales_per_octave", ")", ":", "\n", "            ", "octave_scale", "=", "octave", "**", "(", "scale_per_octave", "/", "float", "(", "scales_per_octave", ")", ")", "\n", "per_layer_anchor_sizes", ".", "append", "(", "octave_scale", "*", "size", ")", "\n", "", "new_anchor_sizes", ".", "append", "(", "tuple", "(", "per_layer_anchor_sizes", ")", ")", "\n", "\n", "", "anchor_generator", "=", "AnchorGenerator", "(", "\n", "tuple", "(", "new_anchor_sizes", ")", ",", "aspect_ratios", ",", "anchor_strides", ",", "straddle_thresh", "\n", ")", "\n", "return", "anchor_generator", "\n", "\n", "# Copyright (c) 2017-present, Facebook, Inc.", "\n", "#", "\n", "# Licensed under the Apache License, Version 2.0 (the \"License\");", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.generate_anchors": [[246, 258], ["anchor_generator._generate_anchors", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._generate_anchors"], ["    ", "\"\"\"Generates a matrix of anchor boxes in (x1, y1, x2, y2) format. Anchors\n    are centered on stride / 2, have (approximate) sqrt areas of the specified\n    sizes, and aspect ratios as given.\n    \"\"\"", "\n", "return", "_generate_anchors", "(", "\n", "stride", ",", "\n", "np", ".", "array", "(", "sizes", ",", "dtype", "=", "np", ".", "float", ")", "/", "stride", ",", "\n", "np", ".", "array", "(", "aspect_ratios", ",", "dtype", "=", "np", ".", "float", ")", ",", "\n", ")", "\n", "\n", "\n", "", "def", "_generate_anchors", "(", "base_size", ",", "scales", ",", "aspect_ratios", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._generate_anchors": [[261, 272], ["anchor_generator._ratio_enum", "numpy.vstack", "torch.from_numpy", "numpy.array", "anchor_generator._scale_enum", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._ratio_enum", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._scale_enum"], ["anchor", "=", "np", ".", "array", "(", "[", "1", ",", "1", ",", "base_size", ",", "base_size", "]", ",", "dtype", "=", "np", ".", "float", ")", "-", "1", "\n", "anchors", "=", "_ratio_enum", "(", "anchor", ",", "aspect_ratios", ")", "\n", "anchors", "=", "np", ".", "vstack", "(", "\n", "[", "_scale_enum", "(", "anchors", "[", "i", ",", ":", "]", ",", "scales", ")", "for", "i", "in", "range", "(", "anchors", ".", "shape", "[", "0", "]", ")", "]", "\n", ")", "\n", "return", "torch", ".", "from_numpy", "(", "anchors", ")", "\n", "\n", "\n", "", "def", "_whctrs", "(", "anchor", ")", ":", "\n", "    ", "\"\"\"Return width, height, x center, and y center for an anchor (window).\"\"\"", "\n", "w", "=", "anchor", "[", "2", "]", "-", "anchor", "[", "0", "]", "+", "1", "\n", "h", "=", "anchor", "[", "3", "]", "-", "anchor", "[", "1", "]", "+", "1", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._whctrs": [[274, 281], ["None"], "function", ["None"], ["y_ctr", "=", "anchor", "[", "1", "]", "+", "0.5", "*", "(", "h", "-", "1", ")", "\n", "return", "w", ",", "h", ",", "x_ctr", ",", "y_ctr", "\n", "\n", "\n", "", "def", "_mkanchors", "(", "ws", ",", "hs", ",", "x_ctr", ",", "y_ctr", ")", ":", "\n", "    ", "\"\"\"Given a vector of widths (ws) and heights (hs) around a center\n    (x_ctr, y_ctr), output a set of anchors (windows).\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._mkanchors": [[283, 298], ["numpy.hstack"], "function", ["None"], ["hs", "=", "hs", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "anchors", "=", "np", ".", "hstack", "(", "\n", "(", "\n", "x_ctr", "-", "0.5", "*", "(", "ws", "-", "1", ")", ",", "\n", "y_ctr", "-", "0.5", "*", "(", "hs", "-", "1", ")", ",", "\n", "x_ctr", "+", "0.5", "*", "(", "ws", "-", "1", ")", ",", "\n", "y_ctr", "+", "0.5", "*", "(", "hs", "-", "1", ")", ",", "\n", ")", "\n", ")", "\n", "return", "anchors", "\n", "\n", "\n", "", "def", "_ratio_enum", "(", "anchor", ",", "ratios", ")", ":", "\n", "    ", "\"\"\"Enumerate a set of anchors for each aspect ratio wrt an anchor.\"\"\"", "\n", "w", ",", "h", ",", "x_ctr", ",", "y_ctr", "=", "_whctrs", "(", "anchor", ")", "\n", "size", "=", "w", "*", "h", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._ratio_enum": [[300, 309], ["anchor_generator._whctrs", "numpy.round", "numpy.round", "anchor_generator._mkanchors", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._whctrs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._mkanchors"], ["ws", "=", "np", ".", "round", "(", "np", ".", "sqrt", "(", "size_ratios", ")", ")", "\n", "hs", "=", "np", ".", "round", "(", "ws", "*", "ratios", ")", "\n", "anchors", "=", "_mkanchors", "(", "ws", ",", "hs", ",", "x_ctr", ",", "y_ctr", ")", "\n", "return", "anchors", "\n", "\n", "\n", "", "def", "_scale_enum", "(", "anchor", ",", "scales", ")", ":", "\n", "    ", "\"\"\"Enumerate a set of anchors for each scale wrt an anchor.\"\"\"", "\n", "w", ",", "h", ",", "x_ctr", ",", "y_ctr", "=", "_whctrs", "(", "anchor", ")", "\n", "ws", "=", "w", "*", "scales", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._scale_enum": [[311, 318], ["anchor_generator._whctrs", "anchor_generator._mkanchors"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._whctrs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator._mkanchors"], ["anchors", "=", "_mkanchors", "(", "ws", ",", "hs", ",", "x_ctr", ",", "y_ctr", ")", "\n", "return", "anchors", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.RPNPostProcessor.__init__": [[19, 50], ["super().__init__", "fcos_core.modeling.box_coder.BoxCoder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n", "            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.RPNPostProcessor.add_gt_proposals": [[51, 73], ["target.copy_with_fields", "gt_box.add_field", "fcos_core.structures.boxlist_ops.cat_boxlist", "torch.ones", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist"], ["self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n", "for", "gt_box", "in", "gt_boxes", ":", "\n", "            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.RPNPostProcessor.forward_for_single_feature_map": [[74, 122], ["utils.permute_and_flatten().view", "objectness.sigmoid.sigmoid.sigmoid", "utils.permute_and_flatten", "min", "objectness.sigmoid.sigmoid.topk", "torch.cat", "inference.RPNPostProcessor.box_coder.decode", "proposals.view.view.view", "zip", "torch.arange", "torch.cat.reshape", "utils.permute_and_flatten.view", "torch.cat.view", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.boxlist_ops.boxlist_nms.add_field", "fcos_core.structures.boxlist_ops.boxlist_nms.clip_to_image", "fcos_core.structures.boxlist_ops.remove_small_boxes", "fcos_core.structures.boxlist_ops.boxlist_nms", "result.append", "utils.permute_and_flatten"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.remove_small_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.boxlist_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten"], ["return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n", "\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", "[", ":", ",", "None", "]", "\n", "box_regression", "=", "box_regression", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "image_shapes", "=", "[", "box", ".", "size", "for", "box", "in", "anchors", "]", "\n", "concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n", "result", ".", "append", "(", "boxlist", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.RPNPostProcessor.forward": [[123, 151], ["len", "list", "zip", "list", "zip", "sampled_boxes.append", "zip", "fcos_core.structures.boxlist_ops.cat_boxlist", "inference.RPNPostProcessor.select_over_all_levels", "inference.RPNPostProcessor.add_gt_proposals", "inference.RPNPostProcessor.forward_for_single_feature_map"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.select_over_all_levels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.RetinaNetPostProcessor.add_gt_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.forward_for_single_feature_map"], ["", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[list[BoxList]]\n            objectness: list[tensor]\n            box_regression: list[tensor]\n\n        Returns:\n            boxlists (list[BoxList]): the post-processed anchors, after\n                applying box decoding and NMS\n        \"\"\"", "\n", "sampled_boxes", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "objectness", ")", "\n", "anchors", "=", "list", "(", "zip", "(", "*", "anchors", ")", ")", "\n", "for", "a", ",", "o", ",", "b", "in", "zip", "(", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "            ", "sampled_boxes", ".", "append", "(", "self", ".", "forward_for_single_feature_map", "(", "a", ",", "o", ",", "b", ")", ")", "\n", "\n", "", "boxlists", "=", "list", "(", "zip", "(", "*", "sampled_boxes", ")", ")", "\n", "boxlists", "=", "[", "cat_boxlist", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "\n", "if", "num_levels", ">", "1", ":", "\n", "            ", "boxlists", "=", "self", ".", "select_over_all_levels", "(", "boxlists", ")", "\n", "\n", "# append ground-truth bboxes to proposals", "\n", "", "if", "self", ".", "training", "and", "targets", "is", "not", "None", ":", "\n", "            ", "boxlists", "=", "self", ".", "add_gt_proposals", "(", "boxlists", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.RPNPostProcessor.select_over_all_levels": [[152, 180], ["len", "torch.cat", "min", "torch.topk", "torch.zeros_like", "inds_mask.split.split.split", "range", "range", "len", "len", "boxlists[].get_field", "min", "torch.topk", "boxlist.get_field", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "return", "boxlists", "\n", "\n", "", "def", "select_over_all_levels", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "num_images", "=", "len", "(", "boxlists", ")", "\n", "# different behavior during training and during testing:", "\n", "# during training, post_nms_top_n is over *all* the proposals combined, while", "\n", "# during testing, it is over the proposals for each image", "\n", "# NOTE: it should be per image, and not per batch. However, to be consistent ", "\n", "# with Detectron, the default is per batch (see Issue #672)", "\n", "if", "self", ".", "training", "and", "self", ".", "fpn_post_nms_per_batch", ":", "\n", "            ", "objectness", "=", "torch", ".", "cat", "(", "\n", "[", "boxlist", ".", "get_field", "(", "\"objectness\"", ")", "for", "boxlist", "in", "boxlists", "]", ",", "dim", "=", "0", "\n", ")", "\n", "box_sizes", "=", "[", "len", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n", "_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", ")", "\n", "inds_mask", "=", "torch", ".", "zeros_like", "(", "objectness", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "inds_mask", "[", "inds_sorted", "]", "=", "1", "\n", "inds_mask", "=", "inds_mask", ".", "split", "(", "box_sizes", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_mask", "[", "i", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "objectness", "=", "boxlists", "[", "i", "]", ".", "get_field", "(", "\"objectness\"", ")", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n", "_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "\n", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", "\n", ")", "\n", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_sorted", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.inference.make_rpn_postprocessor": [[182, 203], ["inference.RPNPostProcessor"], "function", ["None"], ["\n", "\n", "", "", "def", "make_rpn_postprocessor", "(", "config", ",", "rpn_box_coder", ",", "is_train", ")", ":", "\n", "    ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TRAIN", "\n", "if", "not", "is_train", ":", "\n", "        ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TEST", "\n", "\n", "", "pre_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TRAIN", "\n", "post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TRAIN", "\n", "if", "not", "is_train", ":", "\n", "        ", "pre_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TEST", "\n", "post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TEST", "\n", "", "fpn_post_nms_per_batch", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_PER_BATCH", "\n", "nms_thresh", "=", "config", ".", "MODEL", ".", "RPN", ".", "NMS_THRESH", "\n", "min_size", "=", "config", ".", "MODEL", ".", "RPN", ".", "MIN_SIZE", "\n", "box_selector", "=", "RPNPostProcessor", "(", "\n", "pre_nms_top_n", "=", "pre_nms_top_n", ",", "\n", "post_nms_top_n", "=", "post_nms_top_n", ",", "\n", "nms_thresh", "=", "nms_thresh", ",", "\n", "min_size", "=", "min_size", ",", "\n", "box_coder", "=", "rpn_box_coder", ",", "\n", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.RPNLossComputation.__init__": [[26, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n", "generate_labels_func", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n", "self", ".", "copied_fields", "=", "[", "]", "\n", "self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.RPNLossComputation.match_targets_to_anchors": [[42, 55], ["fcos_core.structures.boxlist_ops.boxlist_iou", "loss.RPNLossComputation.proposal_matcher", "target.copy_with_fields.copy_with_fields.copy_with_fields", "matched_targets.add_field", "loss.RPNLossComputation.clamp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n", "        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n", "matched_targets", ".", "add_field", "(", "\"matched_idxs\"", ",", "matched_idxs", ")", "\n", "return", "matched_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.RPNLossComputation.prepare_targets": [[56, 90], ["zip", "loss.RPNLossComputation.match_targets_to_anchors", "loss.RPNLossComputation.get_field", "loss.RPNLossComputation.generate_labels_func", "labels_per_image.to.to.to", "loss.RPNLossComputation.box_coder.encode", "labels.append", "regression_targets.append", "anchors_per_image.get_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.RPNLossComputation.match_targets_to_anchors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n", "# compute regression targets", "\n", "", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "labels_per_image", ")", "\n", "regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.RPNLossComputation.__call__": [[92, 132], ["loss.RPNLossComputation.prepare_targets", "loss.RPNLossComputation.fg_bg_sampler", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.cat", "utils.concat_box_prediction_layers", "objectness.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.nn.functional.binary_cross_entropy_with_logits", "fcos_core.structures.boxlist_ops.cat_boxlist", "fcos_core.layers.smooth_l1_loss", "torch.cat.numel", "torch.nonzero", "torch.nonzero", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.concat_box_prediction_layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors (list[list[BoxList]])\n            objectness (list[Tensor])\n            box_regression (list[Tensor])\n            targets (list[BoxList])\n\n        Returns:\n            objectness_loss (Tensor)\n            box_loss (Tensor)\n        \"\"\"", "\n", "anchors", "=", "[", "cat_boxlist", "(", "anchors_per_image", ")", "for", "anchors_per_image", "in", "anchors", "]", "\n", "labels", ",", "regression_targets", "=", "self", ".", "prepare_targets", "(", "anchors", ",", "targets", ")", "\n", "sampled_pos_inds", ",", "sampled_neg_inds", "=", "self", ".", "fg_bg_sampler", "(", "labels", ")", "\n", "sampled_pos_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_pos_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sampled_neg_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_neg_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "sampled_inds", "=", "torch", ".", "cat", "(", "[", "sampled_pos_inds", ",", "sampled_neg_inds", "]", ",", "dim", "=", "0", ")", "\n", "\n", "objectness", ",", "box_regression", "=", "concat_box_prediction_layers", "(", "objectness", ",", "box_regression", ")", "\n", "\n", "objectness", "=", "objectness", ".", "squeeze", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "regression_targets", "=", "torch", ".", "cat", "(", "regression_targets", ",", "dim", "=", "0", ")", "\n", "\n", "box_loss", "=", "smooth_l1_loss", "(", "\n", "box_regression", "[", "sampled_pos_inds", "]", ",", "\n", "regression_targets", "[", "sampled_pos_inds", "]", ",", "\n", "beta", "=", "1.0", "/", "9", ",", "\n", "size_average", "=", "False", ",", "\n", ")", "/", "(", "sampled_inds", ".", "numel", "(", ")", ")", "\n", "\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.generate_rpn_labels": [[134, 138], ["matched_targets.get_field"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], [")", "\n", "\n", "return", "objectness_loss", ",", "box_loss", "\n", "\n", "# This function should be overwritten in RetinaNet", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.loss.make_rpn_loss_evaluator": [[140, 158], ["fcos_core.modeling.matcher.Matcher", "balanced_positive_negative_sampler.BalancedPositiveNegativeSampler", "loss.RPNLossComputation"], "function", ["None"], ["    ", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "matched_idxs", ">=", "0", "\n", "return", "labels_per_image", "\n", "\n", "\n", "", "def", "make_rpn_loss_evaluator", "(", "cfg", ",", "box_coder", ")", ":", "\n", "    ", "matcher", "=", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "FG_IOU_THRESHOLD", ",", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BG_IOU_THRESHOLD", ",", "\n", "allow_low_quality_matches", "=", "True", ",", "\n", ")", "\n", "\n", "fg_bg_sampler", "=", "BalancedPositiveNegativeSampler", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "\n", ")", "\n", "\n", "loss_evaluator", "=", "RPNLossComputation", "(", "\n", "matcher", ",", "\n", "fg_bg_sampler", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten": [[10, 15], ["layer.reshape.view", "layer.reshape.permute", "layer.reshape.reshape"], "function", ["None"], ["    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.concat_box_prediction_layers": [[17, 46], ["zip", "utils.cat().reshape", "utils.cat().reshape", "utils.permute_and_flatten", "box_cls_flattened.append", "utils.permute_and_flatten", "box_regression_flattened.append", "utils.cat", "utils.cat"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.RetinaNetHead.__init__": [[18, 78], ["super().__init__", "range", "retinanet.RetinaNetHead.add_module", "retinanet.RetinaNetHead.add_module", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "len", "cls_tower.append", "cls_tower.append", "bbox_tower.append", "bbox_tower.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "modules.modules", "math.log", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "isinstance", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            in_channels (int): number of channels of the input feature\n            num_anchors (int): number of anchors to be predicted\n        \"\"\"", "\n", "super", "(", "RetinaNetHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# TODO: Implement the sigmoid version first.", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", "-", "1", "\n", "num_anchors", "=", "len", "(", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ASPECT_RATIOS", ")", "*", "cfg", ".", "MODEL", ".", "RETINANET", ".", "SCALES_PER_OCTAVE", "\n", "\n", "cls_tower", "=", "[", "]", "\n", "bbox_tower", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CONVS", ")", ":", "\n", "            ", "cls_tower", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", ")", "\n", "cls_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "bbox_tower", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", ")", "\n", "bbox_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "'cls_tower'", ",", "nn", ".", "Sequential", "(", "*", "cls_tower", ")", ")", "\n", "self", ".", "add_module", "(", "'bbox_tower'", ",", "nn", ".", "Sequential", "(", "*", "bbox_tower", ")", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "\n", "# Initialization", "\n", "for", "modules", "in", "[", "self", ".", "cls_tower", ",", "self", ".", "bbox_tower", ",", "self", ".", "cls_logits", ",", "\n", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "\n", "# retinanet_bias_init", "\n", "", "", "", "prior_prob", "=", "cfg", ".", "MODEL", ".", "RETINANET", ".", "PRIOR_PROB", "\n", "bias_value", "=", "-", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_logits", ".", "bias", ",", "bias_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.RetinaNetHead.forward": [[79, 86], ["logits.append", "bbox_reg.append", "retinanet.RetinaNetHead.cls_logits", "retinanet.RetinaNetHead.bbox_pred", "retinanet.RetinaNetHead.cls_tower", "retinanet.RetinaNetHead.bbox_tower"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "for", "feature", "in", "x", ":", "\n", "            ", "logits", ".", "append", "(", "self", ".", "cls_logits", "(", "self", ".", "cls_tower", "(", "feature", ")", ")", ")", "\n", "bbox_reg", ".", "append", "(", "self", ".", "bbox_pred", "(", "self", ".", "bbox_tower", "(", "feature", ")", ")", ")", "\n", "", "return", "logits", ",", "bbox_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.RetinaNetModule.__init__": [[94, 111], ["super().__init__", "cfg.clone", "anchor_generator.make_anchor_generator_retinanet.make_anchor_generator_retinanet", "retinanet.RetinaNetHead", "fcos_core.modeling.box_coder.BoxCoder", "inference.make_retinanet_postprocessor", "loss.make_retinanet_loss_evaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.make_anchor_generator_retinanet", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.make_retinanet_postprocessor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.loss.make_retinanet_loss_evaluator"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "RetinaNetModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "\n", "anchor_generator", "=", "make_anchor_generator_retinanet", "(", "cfg", ")", "\n", "head", "=", "RetinaNetHead", "(", "cfg", ",", "in_channels", ")", "\n", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "10.", ",", "10.", ",", "5.", ",", "5.", ")", ")", "\n", "\n", "box_selector_test", "=", "make_retinanet_postprocessor", "(", "cfg", ",", "box_coder", ",", "is_train", "=", "False", ")", "\n", "\n", "loss_evaluator", "=", "make_retinanet_loss_evaluator", "(", "cfg", ",", "box_coder", ")", "\n", "\n", "self", ".", "anchor_generator", "=", "anchor_generator", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "box_selector_test", "=", "box_selector_test", "\n", "self", ".", "loss_evaluator", "=", "loss_evaluator", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.RetinaNetModule.forward": [[112, 134], ["retinanet.RetinaNetModule.head", "retinanet.RetinaNetModule.anchor_generator", "retinanet.RetinaNetModule._forward_train", "retinanet.RetinaNetModule._forward_test"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_test"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "targets", "=", "None", ",", "search", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (ImageList): images for which we want to compute the predictions\n            features (list[Tensor]): features computed from the images that are\n                used for computing the predictions. Each tensor in the list\n                correspond to different feature levels\n            targets (list[BoxList): ground-truth boxes present in the image (optional)\n\n        Returns:\n            boxes (list[BoxList]): the predicted boxes from the RPN, one BoxList per\n                image.\n            losses (dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"", "\n", "box_cls", ",", "box_regression", "=", "self", ".", "head", "(", "features", ")", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "images", ",", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_train", "(", "anchors", ",", "box_cls", ",", "box_regression", ",", "targets", ",", "search", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_test", "(", "anchors", ",", "box_cls", ",", "box_regression", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.RetinaNetModule._forward_train": [[135, 145], ["retinanet.RetinaNetModule.loss_evaluator"], "methods", ["None"], ["", "", "def", "_forward_train", "(", "self", ",", "anchors", ",", "box_cls", ",", "box_regression", ",", "targets", ",", "search", "=", "False", ")", ":", "\n", "\n", "        ", "loss_box_cls", ",", "loss_box_reg", ",", "loss_scale", "=", "self", ".", "loss_evaluator", "(", "\n", "anchors", ",", "box_cls", ",", "box_regression", ",", "targets", ",", "search", "\n", ")", "\n", "losses", "=", "{", "\n", "\"loss_retina_cls\"", ":", "loss_box_cls", ",", "\n", "\"loss_retina_reg\"", ":", "loss_box_reg", ",", "\n", "}", "\n", "if", "search", ":", "\n", "            ", "return", "anchors", ",", "losses", ",", "loss_scale", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.RetinaNetModule._forward_test": [[146, 149], ["retinanet.RetinaNetModule.box_selector_test"], "methods", ["None"], ["", "else", ":", "\n", "            ", "return", "anchors", ",", "losses", "\n", "\n", "", "", "def", "_forward_test", "(", "self", ",", "anchors", ",", "box_cls", ",", "box_regression", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.retinanet.build_retinanet": [[151, 153], ["retinanet.RetinaNetModule"], "function", ["None"], ["return", "boxes", ",", "{", "}", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.RetinaNetPostProcessor.__init__": [[19, 52], ["inference.RPNPostProcessor.__init__", "fcos_core.modeling.box_coder.BoxCoder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n", "            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.RetinaNetPostProcessor.add_gt_proposals": [[53, 58], ["None"], "methods", ["None"], ["", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.RetinaNetPostProcessor.forward_for_single_feature_map": [[59, 126], ["utils.permute_and_flatten", "box_cls.sigmoid.sigmoid.sigmoid", "utils.permute_and_flatten", "box_regression.reshape.reshape.reshape", "candidate_inds.view().sum", "pre_nms_top_n.clamp.clamp.clamp", "zip", "box_regression.reshape.reshape.size", "box_cls.sigmoid.sigmoid.size", "per_box_cls.topk", "inference.RetinaNetPostProcessor.box_coder.decode", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.boxlist_ops.remove_small_boxes.add_field", "fcos_core.structures.boxlist_ops.remove_small_boxes.add_field", "fcos_core.structures.boxlist_ops.remove_small_boxes.clip_to_image", "fcos_core.structures.boxlist_ops.remove_small_boxes", "results.append", "candidate_inds.view", "per_candidate_inds.nonzero", "per_box_regression[].view", "per_anchors.bbox[].view"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.remove_small_boxes"], ["# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n", "for", "gt_box", "in", "gt_boxes", ":", "\n", "            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n", "\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", "[", ":", ",", "None", "]", "\n", "box_regression", "=", "box_regression", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "image_shapes", "=", "[", "box", ".", "size", "for", "box", "in", "anchors", "]", "\n", "concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n", "result", ".", "append", "(", "boxlist", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.RetinaNetPostProcessor.select_over_all_levels": [[131, 175], ["len", "range", "boxlists[].get_field", "boxlists[].get_field", "range", "fcos_core.structures.boxlist_ops.cat_boxlist", "len", "results.append", "boxes[].view", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.boxlist_ops.boxlist_nms.add_field", "fcos_core.structures.boxlist_ops.boxlist_nms", "len", "fcos_core.structures.boxlist_ops.boxlist_nms.add_field", "fcos_core.structures.boxlist_ops.cat_boxlist.append", "fcos_core.structures.boxlist_ops.cat_boxlist.get_field", "torch.kthvalue", "torch.nonzero().squeeze", "torch.full", "fcos_core.structures.boxlist_ops.cat_boxlist.get_field.cpu", "image_thresh.item", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.boxlist_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["\n", "sampled_boxes", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "objectness", ")", "\n", "anchors", "=", "list", "(", "zip", "(", "*", "anchors", ")", ")", "\n", "for", "a", ",", "o", ",", "b", "in", "zip", "(", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "            ", "sampled_boxes", ".", "append", "(", "self", ".", "forward_for_single_feature_map", "(", "a", ",", "o", ",", "b", ")", ")", "\n", "\n", "", "boxlists", "=", "list", "(", "zip", "(", "*", "sampled_boxes", ")", ")", "\n", "boxlists", "=", "[", "cat_boxlist", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "\n", "if", "num_levels", ">", "1", ":", "\n", "            ", "boxlists", "=", "self", ".", "select_over_all_levels", "(", "boxlists", ")", "\n", "\n", "# append ground-truth bboxes to proposals", "\n", "", "if", "self", ".", "training", "and", "targets", "is", "not", "None", ":", "\n", "            ", "boxlists", "=", "self", ".", "add_gt_proposals", "(", "boxlists", ",", "targets", ")", "\n", "\n", "", "return", "boxlists", "\n", "\n", "", "def", "select_over_all_levels", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "num_images", "=", "len", "(", "boxlists", ")", "\n", "# different behavior during training and during testing:", "\n", "# during training, post_nms_top_n is over *all* the proposals combined, while", "\n", "# during testing, it is over the proposals for each image", "\n", "# NOTE: it should be per image, and not per batch. However, to be consistent ", "\n", "# with Detectron, the default is per batch (see Issue #672)", "\n", "if", "self", ".", "training", "and", "self", ".", "fpn_post_nms_per_batch", ":", "\n", "            ", "objectness", "=", "torch", ".", "cat", "(", "\n", "[", "boxlist", ".", "get_field", "(", "\"objectness\"", ")", "for", "boxlist", "in", "boxlists", "]", ",", "dim", "=", "0", "\n", ")", "\n", "box_sizes", "=", "[", "len", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n", "_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", ")", "\n", "inds_mask", "=", "torch", ".", "zeros_like", "(", "objectness", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "inds_mask", "[", "inds_sorted", "]", "=", "1", "\n", "inds_mask", "=", "inds_mask", ".", "split", "(", "box_sizes", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_mask", "[", "i", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "objectness", "=", "boxlists", "[", "i", "]", ".", "get_field", "(", "\"objectness\"", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.inference.make_retinanet_postprocessor": [[177, 195], ["inference.RetinaNetPostProcessor"], "function", ["None"], ["_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "\n", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", "\n", ")", "\n", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_sorted", "]", "\n", "", "", "return", "boxlists", "\n", "\n", "\n", "", "", "def", "make_rpn_postprocessor", "(", "config", ",", "rpn_box_coder", ",", "is_train", ")", ":", "\n", "    ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TRAIN", "\n", "if", "not", "is_train", ":", "\n", "        ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TEST", "\n", "\n", "", "pre_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TRAIN", "\n", "post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TRAIN", "\n", "if", "not", "is_train", ":", "\n", "        ", "pre_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TEST", "\n", "post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TEST", "\n", "", "fpn_post_nms_per_batch", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_PER_BATCH", "\n", "nms_thresh", "=", "config", ".", "MODEL", ".", "RPN", ".", "NMS_THRESH", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.loss.RetinaNetLossComputation.__init__": [[24, 42], ["None"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n", "generate_labels_func", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n", "self", ".", "copied_fields", "=", "[", "]", "\n", "self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n", "", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.loss.RetinaNetLossComputation._count_loss_scale": [[43, 52], ["torch.cat", "cls_loss_vec.sum", "box_loss_vec.sum", "loss_vec.detach", "gt_areas.detach"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.loss.RetinaNetLossComputation.__call__": [[43, 81], ["loss.RetinaNetLossComputation.prepare_targets", "len", "utils.concat_box_prediction_layers", "torch.cat", "torch.cat", "torch.nonzero().squeeze", "labels.int.int.int", "fcos_core.structures.boxlist_ops.cat_boxlist", "fcos_core.layers.smooth_l1_loss", "max", "loss.RetinaNetLossComputation.box_cls_loss_func", "torch.nonzero", "torch.nonzero().squeeze.numel", "torch.nonzero().squeeze.numel"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.concat_box_prediction_layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss"], ["        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n", "matched_targets", ".", "add_field", "(", "\"matched_idxs\"", ",", "matched_idxs", ")", "\n", "return", "matched_targets", "\n", "\n", "", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.loss.generate_retinanet_labels": [[83, 86], ["matched_targets.get_field"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.retinanet.loss.make_retinanet_loss_evaluator": [[88, 108], ["fcos_core.modeling.matcher.Matcher", "fcos_core.layers.SigmoidFocalLoss", "loss.RetinaNetLossComputation"], "function", ["None"], ["regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n", "", "", "if", "require_boxes_info", ":", "\n", "            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors (list[list[BoxList]])\n            objectness (list[Tensor])\n            box_regression (list[Tensor])\n            targets (list[BoxList])\n\n        Returns:\n            objectness_loss (Tensor)\n            box_loss (Tensor)\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.__init__": [[16, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode": [[19, 53], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "gt_boxes", ",", "anchors", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "==", "'POINT'", ":", "\n", "            ", "TO_REMOVE", "=", "1", "# TODO remove", "\n", "anchors_w", "=", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "anchors_h", "=", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "anchors_cx", "=", "(", "anchors", "[", ":", ",", "2", "]", "+", "anchors", "[", ":", ",", "0", "]", ")", "/", "2", "\n", "anchors_cy", "=", "(", "anchors", "[", ":", ",", "3", "]", "+", "anchors", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "\n", "w", "=", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_SIZES", "[", "0", "]", "/", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_STRIDES", "[", "0", "]", "\n", "l", "=", "w", "*", "(", "anchors_cx", "-", "gt_boxes", "[", ":", ",", "0", "]", ")", "/", "anchors_w", "\n", "t", "=", "w", "*", "(", "anchors_cy", "-", "gt_boxes", "[", ":", ",", "1", "]", ")", "/", "anchors_h", "\n", "r", "=", "w", "*", "(", "gt_boxes", "[", ":", ",", "2", "]", "-", "anchors_cx", ")", "/", "anchors_w", "\n", "b", "=", "w", "*", "(", "gt_boxes", "[", ":", ",", "3", "]", "-", "anchors_cy", ")", "/", "anchors_h", "\n", "targets", "=", "torch", ".", "stack", "(", "[", "l", ",", "t", ",", "r", ",", "b", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "==", "'BOX'", ":", "\n", "            ", "TO_REMOVE", "=", "1", "# TODO remove", "\n", "ex_widths", "=", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "ex_heights", "=", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "ex_ctr_x", "=", "(", "anchors", "[", ":", ",", "2", "]", "+", "anchors", "[", ":", ",", "0", "]", ")", "/", "2", "\n", "ex_ctr_y", "=", "(", "anchors", "[", ":", ",", "3", "]", "+", "anchors", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "\n", "gt_widths", "=", "gt_boxes", "[", ":", ",", "2", "]", "-", "gt_boxes", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "gt_heights", "=", "gt_boxes", "[", ":", ",", "3", "]", "-", "gt_boxes", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "gt_ctr_x", "=", "(", "gt_boxes", "[", ":", ",", "2", "]", "+", "gt_boxes", "[", ":", ",", "0", "]", ")", "/", "2", "\n", "gt_ctr_y", "=", "(", "gt_boxes", "[", ":", ",", "3", "]", "+", "gt_boxes", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "(", "10.", ",", "10.", ",", "5.", ",", "5.", ")", "\n", "targets_dx", "=", "wx", "*", "(", "gt_ctr_x", "-", "ex_ctr_x", ")", "/", "ex_widths", "\n", "targets_dy", "=", "wy", "*", "(", "gt_ctr_y", "-", "ex_ctr_y", ")", "/", "ex_heights", "\n", "targets_dw", "=", "ww", "*", "torch", ".", "log", "(", "gt_widths", "/", "ex_widths", ")", "\n", "targets_dh", "=", "wh", "*", "torch", ".", "log", "(", "gt_heights", "/", "ex_heights", ")", "\n", "targets", "=", "torch", ".", "stack", "(", "(", "targets_dx", ",", "targets_dy", ",", "targets_dw", ",", "targets_dh", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode": [[54, 98], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "anchors.to.to.to", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "math.log", "math.log"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "decode", "(", "self", ",", "preds", ",", "anchors", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "==", "'POINT'", ":", "\n", "            ", "TO_REMOVE", "=", "1", "# TODO remove", "\n", "anchors_w", "=", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "anchors_h", "=", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "anchors_cx", "=", "(", "anchors", "[", ":", ",", "2", "]", "+", "anchors", "[", ":", ",", "0", "]", ")", "/", "2", "\n", "anchors_cy", "=", "(", "anchors", "[", ":", ",", "3", "]", "+", "anchors", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "\n", "w", "=", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_SIZES", "[", "0", "]", "/", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_STRIDES", "[", "0", "]", "\n", "x1", "=", "anchors_cx", "-", "preds", "[", ":", ",", "0", "]", "/", "w", "*", "anchors_w", "\n", "y1", "=", "anchors_cy", "-", "preds", "[", ":", ",", "1", "]", "/", "w", "*", "anchors_h", "\n", "x2", "=", "anchors_cx", "+", "preds", "[", ":", ",", "2", "]", "/", "w", "*", "anchors_w", "\n", "y2", "=", "anchors_cy", "+", "preds", "[", ":", ",", "3", "]", "/", "w", "*", "anchors_h", "\n", "pred_boxes", "=", "torch", ".", "stack", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "==", "'BOX'", ":", "\n", "            ", "anchors", "=", "anchors", ".", "to", "(", "preds", ".", "dtype", ")", "\n", "\n", "TO_REMOVE", "=", "1", "# TODO remove", "\n", "widths", "=", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "+", "TO_REMOVE", "\n", "heights", "=", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "+", "TO_REMOVE", "\n", "ctr_x", "=", "(", "anchors", "[", ":", ",", "2", "]", "+", "anchors", "[", ":", ",", "0", "]", ")", "/", "2", "\n", "ctr_y", "=", "(", "anchors", "[", ":", ",", "3", "]", "+", "anchors", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "\n", "wx", ",", "wy", ",", "ww", ",", "wh", "=", "(", "10.", ",", "10.", ",", "5.", ",", "5.", ")", "\n", "dx", "=", "preds", "[", ":", ",", "0", ":", ":", "4", "]", "/", "wx", "\n", "dy", "=", "preds", "[", ":", ",", "1", ":", ":", "4", "]", "/", "wy", "\n", "dw", "=", "preds", "[", ":", ",", "2", ":", ":", "4", "]", "/", "ww", "\n", "dh", "=", "preds", "[", ":", ",", "3", ":", ":", "4", "]", "/", "wh", "\n", "\n", "# Prevent sending too large values into torch.exp()", "\n", "dw", "=", "torch", ".", "clamp", "(", "dw", ",", "max", "=", "math", ".", "log", "(", "1000.", "/", "16", ")", ")", "\n", "dh", "=", "torch", ".", "clamp", "(", "dh", ",", "max", "=", "math", ".", "log", "(", "1000.", "/", "16", ")", ")", "\n", "\n", "pred_ctr_x", "=", "dx", "*", "widths", "[", ":", ",", "None", "]", "+", "ctr_x", "[", ":", ",", "None", "]", "\n", "pred_ctr_y", "=", "dy", "*", "heights", "[", ":", ",", "None", "]", "+", "ctr_y", "[", ":", ",", "None", "]", "\n", "pred_w", "=", "torch", ".", "exp", "(", "dw", ")", "*", "widths", "[", ":", ",", "None", "]", "\n", "pred_h", "=", "torch", ".", "exp", "(", "dh", ")", "*", "heights", "[", ":", ",", "None", "]", "\n", "\n", "pred_boxes", "=", "torch", ".", "zeros_like", "(", "preds", ")", "\n", "pred_boxes", "[", ":", ",", "0", ":", ":", "4", "]", "=", "pred_ctr_x", "-", "0.5", "*", "(", "pred_w", "-", "1", ")", "\n", "pred_boxes", "[", ":", ",", "1", ":", ":", "4", "]", "=", "pred_ctr_y", "-", "0.5", "*", "(", "pred_h", "-", "1", ")", "\n", "pred_boxes", "[", ":", ",", "2", ":", ":", "4", "]", "=", "pred_ctr_x", "+", "0.5", "*", "(", "pred_w", "-", "1", ")", "\n", "pred_boxes", "[", ":", ",", "3", ":", ":", "4", "]", "=", "pred_ctr_y", "+", "0.5", "*", "(", "pred_h", "-", "1", ")", "\n", "", "return", "pred_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.ATSSHead.__init__": [[101, 174], ["super().__init__", "range", "atss.ATSSHead.add_module", "atss.ATSSHead.add_module", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.ModuleList", "torch.nn.ModuleList", "len", "cls_tower.append", "cls_tower.append", "cls_tower.append", "bbox_tower.append", "bbox_tower.append", "bbox_tower.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "modules.modules", "math.log", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "conv_func", "torch.nn.GroupNorm", "torch.nn.GroupNorm", "torch.nn.ReLU", "torch.nn.ReLU", "conv_func", "torch.nn.GroupNorm", "torch.nn.GroupNorm", "torch.nn.ReLU", "torch.nn.ReLU", "isinstance", "fcos_core.layers.Scale", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ATSSHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "ATSS", ".", "NUM_CLASSES", "-", "1", "\n", "num_anchors", "=", "len", "(", "cfg", ".", "MODEL", ".", "ATSS", ".", "ASPECT_RATIOS", ")", "*", "cfg", ".", "MODEL", ".", "ATSS", ".", "SCALES_PER_OCTAVE", "\n", "\n", "cls_tower", "=", "[", "]", "\n", "bbox_tower", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "MODEL", ".", "ATSS", ".", "NUM_CONVS", ")", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "USE_DCN_IN_TOWER", "and", "i", "==", "cfg", ".", "MODEL", ".", "ATSS", ".", "NUM_CONVS", "-", "1", ":", "\n", "                ", "conv_func", "=", "DFConv2d", "\n", "", "else", ":", "\n", "                ", "conv_func", "=", "nn", ".", "Conv2d", "\n", "\n", "", "cls_tower", ".", "append", "(", "\n", "conv_func", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "True", "\n", ")", "\n", ")", "\n", "cls_tower", ".", "append", "(", "nn", ".", "GroupNorm", "(", "32", ",", "in_channels", ")", ")", "\n", "cls_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "bbox_tower", ".", "append", "(", "\n", "conv_func", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "True", "\n", ")", "\n", ")", "\n", "bbox_tower", ".", "append", "(", "nn", ".", "GroupNorm", "(", "32", ",", "in_channels", ")", ")", "\n", "bbox_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "'cls_tower'", ",", "nn", ".", "Sequential", "(", "*", "cls_tower", ")", ")", "\n", "self", ".", "add_module", "(", "'bbox_tower'", ",", "nn", ".", "Sequential", "(", "*", "bbox_tower", ")", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "self", ".", "centerness", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "1", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "\n", "# initialization", "\n", "for", "modules", "in", "[", "self", ".", "cls_tower", ",", "self", ".", "bbox_tower", ",", "\n", "self", ".", "cls_logits", ",", "self", ".", "bbox_pred", ",", "\n", "self", ".", "centerness", "]", ":", "\n", "            ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "# initialize the bias for focal loss", "\n", "", "", "", "prior_prob", "=", "cfg", ".", "MODEL", ".", "ATSS", ".", "PRIOR_PROB", "\n", "bias_value", "=", "-", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_logits", ".", "bias", ",", "bias_value", ")", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "==", "'POINT'", ":", "\n", "            ", "assert", "num_anchors", "==", "1", ",", "\"regressing from a point only support num_anchors == 1\"", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bbox_pred", ".", "bias", ",", "4", ")", "\n", "\n", "", "self", ".", "scales", "=", "nn", ".", "ModuleList", "(", "[", "Scale", "(", "init_value", "=", "1.0", ")", "for", "_", "in", "range", "(", "5", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.ATSSHead.forward": [[175, 192], ["enumerate", "atss.ATSSHead.cls_tower", "atss.ATSSHead.bbox_tower", "logits.append", "bbox_reg.append", "centerness.append", "atss.ATSSHead.cls_logits", "atss.ATSSHead.bbox_pred", "torch.relu", "torch.relu", "atss.ATSSHead.centerness"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "centerness", "=", "[", "]", "\n", "for", "l", ",", "feature", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "cls_tower", "=", "self", ".", "cls_tower", "(", "feature", ")", "\n", "box_tower", "=", "self", ".", "bbox_tower", "(", "feature", ")", "\n", "\n", "logits", ".", "append", "(", "self", ".", "cls_logits", "(", "cls_tower", ")", ")", "\n", "\n", "bbox_pred", "=", "self", ".", "scales", "[", "l", "]", "(", "self", ".", "bbox_pred", "(", "box_tower", ")", ")", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "==", "'POINT'", ":", "\n", "                ", "bbox_pred", "=", "F", ".", "relu", "(", "bbox_pred", ")", "\n", "", "bbox_reg", ".", "append", "(", "bbox_pred", ")", "\n", "\n", "centerness", ".", "append", "(", "self", ".", "centerness", "(", "box_tower", ")", ")", "\n", "", "return", "logits", ",", "bbox_reg", ",", "centerness", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.ATSSModule.__init__": [[196, 204], ["super().__init__", "atss.ATSSHead", "atss.BoxCoder", "loss.make_atss_loss_evaluator", "inference.make_atss_postprocessor", "anchor_generator.make_anchor_generator_atss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.make_atss_loss_evaluator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.inference.make_atss_postprocessor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.make_anchor_generator_atss"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ATSSModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "head", "=", "ATSSHead", "(", "cfg", ",", "in_channels", ")", "\n", "box_coder", "=", "BoxCoder", "(", "cfg", ")", "\n", "self", ".", "loss_evaluator", "=", "make_atss_loss_evaluator", "(", "cfg", ",", "box_coder", ")", "\n", "self", ".", "box_selector_test", "=", "make_atss_postprocessor", "(", "cfg", ",", "box_coder", ")", "\n", "self", ".", "anchor_generator", "=", "make_anchor_generator_atss", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.ATSSModule.forward": [[205, 213], ["atss.ATSSModule.head", "atss.ATSSModule.anchor_generator", "atss.ATSSModule._forward_train", "atss.ATSSModule._forward_test"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_test"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        ", "box_cls", ",", "box_regression", ",", "centerness", "=", "self", ".", "head", "(", "features", ")", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "images", ",", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_train", "(", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", ",", "anchors", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_test", "(", "box_cls", ",", "box_regression", ",", "centerness", ",", "anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.ATSSModule._forward_train": [[214, 224], ["atss.ATSSModule.loss_evaluator"], "methods", ["None"], ["", "", "def", "_forward_train", "(", "self", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", ",", "anchors", ")", ":", "\n", "        ", "loss_box_cls", ",", "loss_box_reg", ",", "loss_centerness", "=", "self", ".", "loss_evaluator", "(", "\n", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", ",", "anchors", "\n", ")", "\n", "losses", "=", "{", "\n", "\"loss_cls\"", ":", "loss_box_cls", ",", "\n", "\"loss_reg\"", ":", "loss_box_reg", ",", "\n", "\"loss_centerness\"", ":", "loss_centerness", "\n", "}", "\n", "return", "None", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.ATSSModule._forward_test": [[225, 228], ["atss.ATSSModule.box_selector_test"], "methods", ["None"], ["", "def", "_forward_test", "(", "self", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "anchors", ")", ":", "\n", "        ", "boxes", "=", "self", ".", "box_selector_test", "(", "box_cls", ",", "box_regression", ",", "centerness", ",", "anchors", ")", "\n", "return", "boxes", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.build_atss": [[230, 232], ["atss.ATSSModule"], "function", ["None"], ["", "", "def", "build_atss", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "ATSSModule", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.inference.ATSSPostProcessor.__init__": [[10, 32], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["from", ".", ".", "utils", "import", "cat", "\n", "from", ".", "utils", "import", "permute_and_flatten", "\n", "\n", "class", "RPNPostProcessor", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Performs post-processing on the outputs of the RPN boxes, before feeding the\n    proposals to the heads\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.inference.ATSSPostProcessor.forward_for_single_feature_map": [[33, 81], ["utils.permute_and_flatten", "box_cls.sigmoid.sigmoid.sigmoid", "utils.permute_and_flatten", "box_regression.reshape.reshape.reshape", "candidate_inds.view().sum", "pre_nms_top_n.clamp.clamp.clamp", "utils.permute_and_flatten", "centerness.reshape().sigmoid.reshape().sigmoid.reshape().sigmoid", "zip", "box_regression.reshape.reshape.size", "box_cls.sigmoid.sigmoid.size", "per_box_cls.topk", "inference.ATSSPostProcessor.box_coder.decode", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.boxlist_ops.remove_small_boxes.add_field", "fcos_core.structures.boxlist_ops.remove_small_boxes.add_field", "fcos_core.structures.boxlist_ops.remove_small_boxes.clip_to_image", "fcos_core.structures.boxlist_ops.remove_small_boxes", "results.append", "candidate_inds.view", "centerness.reshape().sigmoid.reshape().sigmoid.reshape", "per_candidate_inds.nonzero", "per_box_regression[].view", "per_anchors.bbox[].view", "torch.sqrt"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.permute_and_flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.remove_small_boxes"], ["\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n", "            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n", "for", "gt_box", "in", "gt_boxes", ":", "\n", "            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.inference.ATSSPostProcessor.forward": [[82, 96], ["list", "enumerate", "list", "zip", "zip", "sampled_boxes.append", "zip", "fcos_core.structures.boxlist_ops.cat_boxlist", "inference.ATSSPostProcessor.select_over_all_levels", "inference.ATSSPostProcessor.forward_for_single_feature_map"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.select_over_all_levels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.forward_for_single_feature_map"], ["\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n", "\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.inference.ATSSPostProcessor.select_over_all_levels": [[101, 121], ["len", "range", "fcos_core.structures.boxlist_ops.boxlist_ml_nms", "len", "results.append", "fcos_core.structures.boxlist_ops.boxlist_ml_nms.get_field", "torch.kthvalue", "torch.nonzero().squeeze", "fcos_core.structures.boxlist_ops.boxlist_ml_nms.get_field.cpu", "image_thresh.item", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_ml_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.inference.make_atss_postprocessor": [[123, 138], ["inference.ATSSPostProcessor"], "function", ["None"], ["", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[list[BoxList]]\n            objectness: list[tensor]\n            box_regression: list[tensor]\n\n        Returns:\n            boxlists (list[BoxList]): the post-processed anchors, after\n                applying box decoding and NMS\n        \"\"\"", "\n", "sampled_boxes", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "objectness", ")", "\n", "anchors", "=", "list", "(", "zip", "(", "*", "anchors", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.ATSSLossComputation.__init__": [[29, 35], ["fcos_core.layers.SigmoidFocalLoss", "torch.nn.BCEWithLogitsLoss", "fcos_core.modeling.matcher.Matcher"], "methods", ["None"], ["\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.ATSSLossComputation.GIoULoss": [[36, 78], ["loss.ATSSLossComputation.box_coder.decode", "torch.max", "torch.max", "loss.ATSSLossComputation.box_coder.decode", "torch.max", "torch.max", "torch.min", "torch.min", "torch.zeros().to", "torch.min", "torch.min", "torch.max", "torch.max", "pred.view", "anchor.view", "target.view", "anchor.view", "losses.sum", "torch.zeros", "weight.sum", "losses.numel", "pred_x1.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n", "self", ".", "copied_fields", "=", "[", "]", "\n", "self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n", "", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n", "        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n", "matched_targets", ".", "add_field", "(", "\"matched_idxs\"", ",", "matched_idxs", ")", "\n", "return", "matched_targets", "\n", "\n", "", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.ATSSLossComputation.prepare_targets": [[79, 257], ["range", "len", "targets_per_im.copy_with_fields.copy_with_fields.get_field", "fcos_core.structures.boxlist_ops.cat_boxlist", "loss.ATSSLossComputation.box_coder.encode", "cls_labels.append", "reg_targets.append", "targets_per_im.copy_with_fields.copy_with_fields.area", "enumerate", "torch.cat", "torch.cat", "torch.stack", "area_per_im[].repeat", "area_per_im[].repeat.min", "torch.stack", "torch.cat.append", "torch.stack.new_tensor", "torch.cat.append", "torch.stack.max", "len", "fcos_core.structures.boxlist_ops.boxlist_iou", "torch.stack", "torch.stack", "enumerate", "torch.cat", "candidate_ious.mean", "candidate_ious.std", "range", "anchors_cx_per_im.view().expand().contiguous().view", "anchors_cy_per_im.view().expand().contiguous().view", "candidate_idxs.view.view.view", "torch.full_like().t().contiguous().view", "ious_inf.view().t.view().t.view().t", "ious_inf.view().t.view().t.max", "object_sizes_of_interest_per_level[].expand", "torch.stack.min", "len", "len", "min", "distances_per_level.topk", "candidate_idxs.view.view.append", "e_anchors_cx[].view", "e_anchors_cy[].view", "e_anchors_cx[].view", "e_anchors_cy[].view", "candidate_idxs.view.view.view", "fcos_core.structures.boxlist_ops.boxlist_iou.t().contiguous().view", "torch.stack", "torch.stack", "fcos_core.structures.boxlist_ops.boxlist_iou", "range", "fcos_core.structures.boxlist_ops.boxlist_iou.max", "len", "anchors_cx_per_im.view().expand().contiguous", "anchors_cy_per_im.view().expand().contiguous", "torch.stack().min", "torch.full_like().t().contiguous", "is_pos.view", "ious_inf.view().t.view().t.view", "fcos_core.structures.boxlist_ops.boxlist_iou", "loss.ATSSLossComputation.matcher", "targets_per_im.copy_with_fields.copy_with_fields.copy_with_fields", "matched_targets.get_field", "cls_labels_per_im.to.to.to", "torch.nonzero().squeeze", "torch.arange", "fcos_core.structures.boxlist_ops.boxlist_iou.t().contiguous", "distances.max", "anchors_cx_per_im.view().expand", "anchors_cy_per_im.view().expand", "torch.stack", "torch.full_like().t", "torch.stack().min", "loss.ATSSLossComputation.clamp", "torch.nonzero", "torch.stack().min", "fcos_core.structures.boxlist_ops.boxlist_iou.t", "anchors_cx_per_im.view", "anchors_cy_per_im.view", "torch.full_like", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n", "# compute regression targets", "\n", "", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "labels_per_image", ")", "\n", "regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n", "", "", "if", "require_boxes_info", ":", "\n", "            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors (list[list[BoxList]])\n            objectness (list[Tensor])\n            box_regression (list[Tensor])\n            targets (list[BoxList])\n\n        Returns:\n            objectness_loss (Tensor)\n            box_loss (Tensor)\n        \"\"\"", "\n", "anchors", "=", "[", "cat_boxlist", "(", "anchors_per_image", ")", "for", "anchors_per_image", "in", "anchors", "]", "\n", "labels", ",", "regression_targets", "=", "self", ".", "prepare_targets", "(", "anchors", ",", "targets", ")", "\n", "sampled_pos_inds", ",", "sampled_neg_inds", "=", "self", ".", "fg_bg_sampler", "(", "labels", ")", "\n", "sampled_pos_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_pos_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sampled_neg_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_neg_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "sampled_inds", "=", "torch", ".", "cat", "(", "[", "sampled_pos_inds", ",", "sampled_neg_inds", "]", ",", "dim", "=", "0", ")", "\n", "\n", "objectness", ",", "box_regression", "=", "concat_box_prediction_layers", "(", "objectness", ",", "box_regression", ")", "\n", "\n", "objectness", "=", "objectness", ".", "squeeze", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "regression_targets", "=", "torch", ".", "cat", "(", "regression_targets", ",", "dim", "=", "0", ")", "\n", "\n", "box_loss", "=", "smooth_l1_loss", "(", "\n", "box_regression", "[", "sampled_pos_inds", "]", ",", "\n", "regression_targets", "[", "sampled_pos_inds", "]", ",", "\n", "beta", "=", "1.0", "/", "9", ",", "\n", "size_average", "=", "False", ",", "\n", ")", "/", "(", "sampled_inds", ".", "numel", "(", ")", ")", "\n", "\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "objectness", "[", "sampled_inds", "]", ",", "labels", "[", "sampled_inds", "]", "\n", ")", "\n", "\n", "return", "objectness_loss", ",", "box_loss", "\n", "\n", "# This function should be overwritten in RetinaNet", "\n", "", "", "def", "generate_rpn_labels", "(", "matched_targets", ")", ":", "\n", "    ", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "matched_idxs", ">=", "0", "\n", "return", "labels_per_image", "\n", "\n", "\n", "", "def", "make_rpn_loss_evaluator", "(", "cfg", ",", "box_coder", ")", ":", "\n", "    ", "matcher", "=", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "FG_IOU_THRESHOLD", ",", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BG_IOU_THRESHOLD", ",", "\n", "allow_low_quality_matches", "=", "True", ",", "\n", ")", "\n", "\n", "fg_bg_sampler", "=", "BalancedPositiveNegativeSampler", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "\n", ")", "\n", "\n", "loss_evaluator", "=", "RPNLossComputation", "(", "\n", "matcher", ",", "\n", "fg_bg_sampler", ",", "\n", "box_coder", ",", "\n", "generate_rpn_labels", "\n", ")", "\n", "return", "loss_evaluator", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.ATSSLossComputation.compute_centerness_targets": [[258, 272], ["loss.ATSSLossComputation.box_coder.decode", "torch.stack", "torch.stack", "torch.sqrt", "torch.isnan().any", "torch.isnan", "torch.stack.min", "torch.stack.max", "torch.stack.min", "torch.stack.max"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.ATSSLossComputation.__call__": [[273, 309], ["loss.ATSSLossComputation.prepare_targets", "len", "utils.concat_box_prediction_layers", "torch.cat().reshape", "torch.cat", "torch.cat", "torch.cat", "torch.nonzero().squeeze", "loss.get_num_gpus", "reduce_sum().item", "max", "loss.ATSSLossComputation.compute_centerness_targets", "ct.permute().reshape", "loss.ATSSLossComputation.cls_loss_func", "reduce_sum().item", "float", "torch.nonzero().squeeze.numel", "box_regression_flatten.sum", "torch.cat().reshape.sum", "torch.cat", "torch.nonzero", "loss.reduce_sum", "float", "torch.cat.int", "loss.ATSSLossComputation.GIoULoss", "loss.ATSSLossComputation.centerness_loss_func", "ct.permute", "fcos_core.structures.boxlist_ops.cat_boxlist", "torch.nonzero().squeeze.new_tensor", "loss.reduce_sum", "loss.ATSSLossComputation.sum", "torch.nonzero().squeeze.numel"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.utils.concat_box_prediction_layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.get_num_gpus", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.compute_centerness_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.reduce_sum", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.ATSSLossComputation.GIoULoss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.reduce_sum"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.get_num_gpus": [[14, 16], ["int"], "function", ["None"], ["\n", "from", "maskrcnn_benchmark", ".", "layers", "import", "smooth_l1_loss", "\n", "from", "maskrcnn_benchmark", ".", "modeling", ".", "matcher", "import", "Matcher", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.reduce_sum": [[18, 25], ["tensor.clone.clone", "dist.all_reduce", "loss.get_num_gpus"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.get_num_gpus"], ["from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "cat_boxlist", "\n", "\n", "\n", "class", "RPNLossComputation", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    This class computes the RPN loss.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.loss.make_atss_loss_evaluator": [[311, 314], ["loss.ATSSLossComputation"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.__init__": [[19, 47], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n", "            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.forward_for_single_feature_map": [[48, 114], ["box_cls.reshape().sigmoid.reshape().sigmoid.view().permute", "box_cls.reshape().sigmoid.reshape().sigmoid.reshape().sigmoid", "box_regression.reshape.reshape.view().permute", "box_regression.reshape.reshape.reshape", "centerness.reshape().sigmoid.reshape().sigmoid.view().permute", "centerness.reshape().sigmoid.reshape().sigmoid.reshape().sigmoid", "candidate_inds.view().sum", "pre_nms_top_n.clamp.clamp.clamp", "range", "per_candidate_inds.nonzero", "torch.stack", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.boxlist_ops.remove_small_boxes.add_field", "fcos_core.structures.boxlist_ops.remove_small_boxes.add_field", "fcos_core.structures.boxlist_ops.remove_small_boxes.clip_to_image", "fcos_core.structures.boxlist_ops.remove_small_boxes", "results.append", "box_cls.reshape().sigmoid.reshape().sigmoid.view", "box_cls.reshape().sigmoid.reshape().sigmoid.reshape", "box_regression.reshape.reshape.view", "centerness.reshape().sigmoid.reshape().sigmoid.view", "centerness.reshape().sigmoid.reshape().sigmoid.reshape", "candidate_inds.view", "per_candidate_inds.sum().item", "per_pre_nms_top_n.item", "per_box_cls.topk", "torch.sqrt", "int", "int", "per_candidate_inds.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.remove_small_boxes"], ["if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n", "for", "gt_box", "in", "gt_boxes", ":", "\n", "            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n", "\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", "[", ":", ",", "None", "]", "\n", "box_regression", "=", "box_regression", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "image_shapes", "=", "[", "box", ".", "size", "for", "box", "in", "anchors", "]", "\n", "concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.forward": [[115, 140], ["enumerate", "list", "zip", "sampled_boxes.append", "zip", "fcos_core.structures.boxlist_ops.cat_boxlist", "inference.FCOSPostProcessor.select_over_all_levels", "inference.FCOSPostProcessor.forward_for_single_feature_map"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.select_over_all_levels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.forward_for_single_feature_map"], ["boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n", "result", ".", "append", "(", "boxlist", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[list[BoxList]]\n            objectness: list[tensor]\n            box_regression: list[tensor]\n\n        Returns:\n            boxlists (list[BoxList]): the post-processed anchors, after\n                applying box decoding and NMS\n        \"\"\"", "\n", "sampled_boxes", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "objectness", ")", "\n", "anchors", "=", "list", "(", "zip", "(", "*", "anchors", ")", ")", "\n", "for", "a", ",", "o", ",", "b", "in", "zip", "(", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "            ", "sampled_boxes", ".", "append", "(", "self", ".", "forward_for_single_feature_map", "(", "a", ",", "o", ",", "b", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.FCOSPostProcessor.select_over_all_levels": [[145, 165], ["len", "range", "fcos_core.structures.boxlist_ops.boxlist_ml_nms", "len", "results.append", "fcos_core.structures.boxlist_ops.boxlist_ml_nms.get_field", "torch.kthvalue", "torch.nonzero().squeeze", "fcos_core.structures.boxlist_ops.boxlist_ml_nms.get_field.cpu", "image_thresh.item", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_ml_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["if", "num_levels", ">", "1", ":", "\n", "            ", "boxlists", "=", "self", ".", "select_over_all_levels", "(", "boxlists", ")", "\n", "\n", "# append ground-truth bboxes to proposals", "\n", "", "if", "self", ".", "training", "and", "targets", "is", "not", "None", ":", "\n", "            ", "boxlists", "=", "self", ".", "add_gt_proposals", "(", "boxlists", ",", "targets", ")", "\n", "\n", "", "return", "boxlists", "\n", "\n", "", "def", "select_over_all_levels", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "num_images", "=", "len", "(", "boxlists", ")", "\n", "# different behavior during training and during testing:", "\n", "# during training, post_nms_top_n is over *all* the proposals combined, while", "\n", "# during testing, it is over the proposals for each image", "\n", "# NOTE: it should be per image, and not per batch. However, to be consistent ", "\n", "# with Detectron, the default is per batch (see Issue #672)", "\n", "if", "self", ".", "training", "and", "self", ".", "fpn_post_nms_per_batch", ":", "\n", "            ", "objectness", "=", "torch", ".", "cat", "(", "\n", "[", "boxlist", ".", "get_field", "(", "\"objectness\"", ")", "for", "boxlist", "in", "boxlists", "]", ",", "dim", "=", "0", "\n", ")", "\n", "box_sizes", "=", "[", "len", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.make_fcos_postprocessor": [[167, 185], ["inference.FCOSPostProcessor"], "function", ["None"], ["_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", ")", "\n", "inds_mask", "=", "torch", ".", "zeros_like", "(", "objectness", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "inds_mask", "[", "inds_sorted", "]", "=", "1", "\n", "inds_mask", "=", "inds_mask", ".", "split", "(", "box_sizes", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_mask", "[", "i", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "objectness", "=", "boxlists", "[", "i", "]", ".", "get_field", "(", "\"objectness\"", ")", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n", "_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "\n", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", "\n", ")", "\n", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_sorted", "]", "\n", "", "", "return", "boxlists", "\n", "\n", "\n", "", "", "def", "make_rpn_postprocessor", "(", "config", ",", "rpn_box_coder", ",", "is_train", ")", ":", "\n", "    ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TRAIN", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSHead.__init__": [[14, 91], ["super().__init__", "range", "fcos.FCOSHead.add_module", "fcos.FCOSHead.add_module", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.ModuleList", "torch.nn.ModuleList", "cls_tower.append", "cls_tower.append", "cls_tower.append", "bbox_tower.append", "bbox_tower.append", "bbox_tower.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "modules.modules", "math.log", "conv_func", "torch.nn.GroupNorm", "torch.nn.GroupNorm", "torch.nn.ReLU", "torch.nn.ReLU", "conv_func", "torch.nn.GroupNorm", "torch.nn.GroupNorm", "torch.nn.ReLU", "torch.nn.ReLU", "isinstance", "fcos_core.layers.Scale", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            in_channels (int): number of channels of the input feature\n        \"\"\"", "\n", "super", "(", "FCOSHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# TODO: Implement the sigmoid version first.", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "NUM_CLASSES", "-", "1", "\n", "self", ".", "fpn_strides", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "FPN_STRIDES", "\n", "self", ".", "norm_reg_targets", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "NORM_REG_TARGETS", "\n", "self", ".", "centerness_on_reg", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "CENTERNESS_ON_REG", "\n", "self", ".", "use_dcn_in_tower", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "USE_DCN_IN_TOWER", "\n", "\n", "cls_tower", "=", "[", "]", "\n", "bbox_tower", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "MODEL", ".", "FCOS", ".", "NUM_CONVS", ")", ":", "\n", "            ", "if", "self", ".", "use_dcn_in_tower", "and", "i", "==", "cfg", ".", "MODEL", ".", "FCOS", ".", "NUM_CONVS", "-", "1", ":", "\n", "                ", "conv_func", "=", "DFConv2d", "\n", "", "else", ":", "\n", "                ", "conv_func", "=", "nn", ".", "Conv2d", "\n", "\n", "", "cls_tower", ".", "append", "(", "\n", "conv_func", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "True", "\n", ")", "\n", ")", "\n", "cls_tower", ".", "append", "(", "nn", ".", "GroupNorm", "(", "32", ",", "in_channels", ")", ")", "\n", "cls_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "bbox_tower", ".", "append", "(", "\n", "conv_func", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "True", "\n", ")", "\n", ")", "\n", "bbox_tower", ".", "append", "(", "nn", ".", "GroupNorm", "(", "32", ",", "in_channels", ")", ")", "\n", "bbox_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "'cls_tower'", ",", "nn", ".", "Sequential", "(", "*", "cls_tower", ")", ")", "\n", "self", ".", "add_module", "(", "'bbox_tower'", ",", "nn", ".", "Sequential", "(", "*", "bbox_tower", ")", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "self", ".", "centerness", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "1", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "\n", "# initialization", "\n", "for", "modules", "in", "[", "self", ".", "cls_tower", ",", "self", ".", "bbox_tower", ",", "\n", "self", ".", "cls_logits", ",", "self", ".", "bbox_pred", ",", "\n", "self", ".", "centerness", "]", ":", "\n", "            ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "# initialize the bias for focal loss", "\n", "", "", "", "prior_prob", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "PRIOR_PROB", "\n", "bias_value", "=", "-", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_logits", ".", "bias", ",", "bias_value", ")", "\n", "\n", "self", ".", "scales", "=", "nn", ".", "ModuleList", "(", "[", "Scale", "(", "init_value", "=", "1.0", ")", "for", "_", "in", "range", "(", "5", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSHead.forward": [[92, 116], ["enumerate", "fcos.FCOSHead.cls_tower", "fcos.FCOSHead.bbox_tower", "logits.append", "fcos.FCOSHead.cls_logits", "centerness.append", "centerness.append", "fcos.FCOSHead.bbox_pred", "torch.relu", "torch.relu", "bbox_reg.append", "fcos.FCOSHead.centerness", "fcos.FCOSHead.centerness", "bbox_reg.append", "bbox_reg.append", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "centerness", "=", "[", "]", "\n", "for", "l", ",", "feature", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "cls_tower", "=", "self", ".", "cls_tower", "(", "feature", ")", "\n", "box_tower", "=", "self", ".", "bbox_tower", "(", "feature", ")", "\n", "\n", "logits", ".", "append", "(", "self", ".", "cls_logits", "(", "cls_tower", ")", ")", "\n", "if", "self", ".", "centerness_on_reg", ":", "\n", "                ", "centerness", ".", "append", "(", "self", ".", "centerness", "(", "box_tower", ")", ")", "\n", "", "else", ":", "\n", "                ", "centerness", ".", "append", "(", "self", ".", "centerness", "(", "cls_tower", ")", ")", "\n", "\n", "", "bbox_pred", "=", "self", ".", "scales", "[", "l", "]", "(", "self", ".", "bbox_pred", "(", "box_tower", ")", ")", "\n", "if", "self", ".", "norm_reg_targets", ":", "\n", "                ", "bbox_pred", "=", "F", ".", "relu", "(", "bbox_pred", ")", "\n", "if", "self", ".", "training", ":", "\n", "                    ", "bbox_reg", ".", "append", "(", "bbox_pred", ")", "\n", "", "else", ":", "\n", "                    ", "bbox_reg", ".", "append", "(", "bbox_pred", "*", "self", ".", "fpn_strides", "[", "l", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "bbox_reg", ".", "append", "(", "torch", ".", "exp", "(", "bbox_pred", ")", ")", "\n", "", "", "return", "logits", ",", "bbox_reg", ",", "centerness", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule.__init__": [[124, 136], ["super().__init__", "fcos.FCOSHead", "inference.make_fcos_postprocessor", "loss.make_fcos_loss_evaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.inference.make_fcos_postprocessor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.make_fcos_loss_evaluator"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FCOSModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "head", "=", "FCOSHead", "(", "cfg", ",", "in_channels", ")", "\n", "\n", "box_selector_test", "=", "make_fcos_postprocessor", "(", "cfg", ")", "\n", "\n", "loss_evaluator", "=", "make_fcos_loss_evaluator", "(", "cfg", ")", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "box_selector_test", "=", "box_selector_test", "\n", "self", ".", "loss_evaluator", "=", "loss_evaluator", "\n", "self", ".", "fpn_strides", "=", "cfg", ".", "MODEL", ".", "FCOS", ".", "FPN_STRIDES", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule.forward": [[137, 165], ["fcos.FCOSModule.head", "fcos.FCOSModule.compute_locations", "fcos.FCOSModule._forward_train", "fcos.FCOSModule._forward_test"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule.compute_locations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_test"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (ImageList): images for which we want to compute the predictions\n            features (list[Tensor]): features computed from the images that are\n                used for computing the predictions. Each tensor in the list\n                correspond to different feature levels\n            targets (list[BoxList): ground-truth boxes present in the image (optional)\n\n        Returns:\n            boxes (list[BoxList]): the predicted boxes from the RPN, one BoxList per\n                image.\n            losses (dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"", "\n", "box_cls", ",", "box_regression", ",", "centerness", "=", "self", ".", "head", "(", "features", ")", "\n", "locations", "=", "self", ".", "compute_locations", "(", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_train", "(", "\n", "locations", ",", "box_cls", ",", "\n", "box_regression", ",", "\n", "centerness", ",", "targets", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_test", "(", "\n", "locations", ",", "box_cls", ",", "box_regression", ",", "\n", "centerness", ",", "images", ".", "image_sizes", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_train": [[167, 177], ["fcos.FCOSModule.loss_evaluator"], "methods", ["None"], ["", "", "def", "_forward_train", "(", "self", ",", "locations", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", ")", ":", "\n", "        ", "loss_box_cls", ",", "loss_box_reg", ",", "loss_centerness", "=", "self", ".", "loss_evaluator", "(", "\n", "locations", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", "\n", ")", "\n", "losses", "=", "{", "\n", "\"loss_cls\"", ":", "loss_box_cls", ",", "\n", "\"loss_reg\"", ":", "loss_box_reg", ",", "\n", "\"loss_centerness\"", ":", "loss_centerness", "\n", "}", "\n", "return", "None", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule._forward_test": [[178, 184], ["fcos.FCOSModule.box_selector_test"], "methods", ["None"], ["", "def", "_forward_test", "(", "self", ",", "locations", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "image_sizes", ")", ":", "\n", "        ", "boxes", "=", "self", ".", "box_selector_test", "(", "\n", "locations", ",", "box_cls", ",", "box_regression", ",", "\n", "centerness", ",", "image_sizes", "\n", ")", "\n", "return", "boxes", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule.compute_locations": [[185, 195], ["enumerate", "fcos.FCOSModule.compute_locations_per_level", "locations.append", "feature.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule.compute_locations_per_level"], ["", "def", "compute_locations", "(", "self", ",", "features", ")", ":", "\n", "        ", "locations", "=", "[", "]", "\n", "for", "level", ",", "feature", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "h", ",", "w", "=", "feature", ".", "size", "(", ")", "[", "-", "2", ":", "]", "\n", "locations_per_level", "=", "self", ".", "compute_locations_per_level", "(", "\n", "h", ",", "w", ",", "self", ".", "fpn_strides", "[", "level", "]", ",", "\n", "feature", ".", "device", "\n", ")", "\n", "locations", ".", "append", "(", "locations_per_level", ")", "\n", "", "return", "locations", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOSModule.compute_locations_per_level": [[196, 210], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "shift_x.reshape.reshape.reshape", "shift_y.reshape.reshape.reshape", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "compute_locations_per_level", "(", "self", ",", "h", ",", "w", ",", "stride", ",", "device", ")", ":", "\n", "        ", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "w", "*", "stride", ",", "step", "=", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "h", "*", "stride", ",", "step", "=", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "locations", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "+", "stride", "//", "2", "\n", "return", "locations", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.build_fcos": [[211, 213], ["fcos.FCOSModule"], "function", ["None"], ["", "", "def", "build_fcos", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "FCOSModule", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.__init__": [[40, 54], ["fcos_core.layers.SigmoidFocalLoss", "fcos_core.layers.IOULoss", "torch.nn.BCEWithLogitsLoss"], "methods", ["None"], ["self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n", "", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n", "        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n", "matched_targets", ".", "add_field", "(", "\"matched_idxs\"", ",", "matched_idxs", ")", "\n", "return", "matched_targets", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.get_sample_region": [[55, 101], ["len", "gt[].expand", "gt[].expand.new_zeros", "enumerate", "torch.stack", "center_x[].sum", "gt_xs.new_zeros", "torch.where", "torch.where", "torch.where", "torch.where", "torch.stack.min"], "methods", ["None"], ["\n", "", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n", "# compute regression targets", "\n", "", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "labels_per_image", ")", "\n", "regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n", "", "", "if", "require_boxes_info", ":", "\n", "            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.prepare_targets": [[102, 147], ["enumerate", "torch.cat", "torch.cat", "loss.FCOSLossComputation.compute_targets_for_locations", "range", "range", "points_per_level.new_tensor", "torch.cat.append", "len", "len", "torch.split", "torch.split", "len", "labels_level_first.append", "torch.cat", "reg_targets_level_first.append", "object_sizes_of_interest_per_level[].expand", "torch.cat", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.compute_targets_for_locations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["\n", "anchors", "=", "[", "cat_boxlist", "(", "anchors_per_image", ")", "for", "anchors_per_image", "in", "anchors", "]", "\n", "labels", ",", "regression_targets", "=", "self", ".", "prepare_targets", "(", "anchors", ",", "targets", ")", "\n", "sampled_pos_inds", ",", "sampled_neg_inds", "=", "self", ".", "fg_bg_sampler", "(", "labels", ")", "\n", "sampled_pos_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_pos_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sampled_neg_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_neg_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "sampled_inds", "=", "torch", ".", "cat", "(", "[", "sampled_pos_inds", ",", "sampled_neg_inds", "]", ",", "dim", "=", "0", ")", "\n", "\n", "objectness", ",", "box_regression", "=", "concat_box_prediction_layers", "(", "objectness", ",", "box_regression", ")", "\n", "\n", "objectness", "=", "objectness", ".", "squeeze", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "regression_targets", "=", "torch", ".", "cat", "(", "regression_targets", ",", "dim", "=", "0", ")", "\n", "\n", "box_loss", "=", "smooth_l1_loss", "(", "\n", "box_regression", "[", "sampled_pos_inds", "]", ",", "\n", "regression_targets", "[", "sampled_pos_inds", "]", ",", "\n", "beta", "=", "1.0", "/", "9", ",", "\n", "size_average", "=", "False", ",", "\n", ")", "/", "(", "sampled_inds", ".", "numel", "(", ")", ")", "\n", "\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "objectness", "[", "sampled_inds", "]", ",", "labels", "[", "sampled_inds", "]", "\n", ")", "\n", "\n", "return", "objectness_loss", ",", "box_loss", "\n", "\n", "# This function should be overwritten in RetinaNet", "\n", "", "", "def", "generate_rpn_labels", "(", "matched_targets", ")", ":", "\n", "    ", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "matched_idxs", ">=", "0", "\n", "return", "labels_per_image", "\n", "\n", "\n", "", "def", "make_rpn_loss_evaluator", "(", "cfg", ",", "box_coder", ")", ":", "\n", "    ", "matcher", "=", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "FG_IOU_THRESHOLD", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.compute_targets_for_locations": [[148, 200], ["range", "len", "targets_per_im.get_field", "targets_per_im.area", "torch.stack", "area[].repeat", "area[].repeat.min", "labels.append", "reg_targets.append", "loss.FCOSLossComputation.get_sample_region", "torch.stack.max", "len", "torch.stack.min", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.get_sample_region"], ["cfg", ".", "MODEL", ".", "RPN", ".", "BG_IOU_THRESHOLD", ",", "\n", "allow_low_quality_matches", "=", "True", ",", "\n", ")", "\n", "\n", "fg_bg_sampler", "=", "BalancedPositiveNegativeSampler", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "\n", ")", "\n", "\n", "loss_evaluator", "=", "RPNLossComputation", "(", "\n", "matcher", ",", "\n", "fg_bg_sampler", ",", "\n", "box_coder", ",", "\n", "generate_rpn_labels", "\n", ")", "\n", "return", "loss_evaluator", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.compute_centerness_targets": [[201, 207], ["torch.sqrt", "left_right.min", "left_right.max", "top_bottom.min", "top_bottom.max"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.__call__": [[208, 283], ["box_cls[].size", "box_cls[].size", "loss.FCOSLossComputation.prepare_targets", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nonzero().squeeze", "loss.get_num_gpus", "reduce_sum().item", "max", "len", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "loss.FCOSLossComputation.cls_loss_func", "torch.nonzero().squeeze.numel", "loss.FCOSLossComputation.compute_centerness_targets", "torch.cat.sum", "loss.reduce_sum", "torch.cat.sum", "box_cls[].permute().reshape", "box_regression[].permute().reshape", "labels[].reshape", "reg_targets[].reshape", "centerness[].reshape", "torch.nonzero", "loss.reduce_sum", "float", "torch.cat.int", "reduce_sum().item", "float", "loss.FCOSLossComputation.box_reg_loss_func", "loss.FCOSLossComputation.centerness_loss_func", "torch.cat.new_tensor", "torch.nonzero().squeeze.new_tensor", "box_cls[].permute", "box_regression[].permute", "loss.reduce_sum", "torch.nonzero().squeeze.numel", "loss.FCOSLossComputation.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.get_num_gpus", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.FCOSLossComputation.compute_centerness_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.reduce_sum", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.reduce_sum", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.reduce_sum"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.get_num_gpus": [[22, 24], ["int"], "function", ["None"], ["    ", "\"\"\"\n    This class computes the RPN loss.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.reduce_sum": [[26, 33], ["tensor.clone.clone", "dist.all_reduce", "loss.get_num_gpus"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.get_num_gpus"], ["def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n", "generate_labels_func", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.loss.make_fcos_loss_evaluator": [[285, 288], ["loss.FCOSLossComputation"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.__init__": [[164, 198], ["os.path.dirname", "os.path.join", "fcos_core.config.cfg.clone", "fcos_core.config.cfg.clone.merge_from_file", "fcos_core.config.cfg.clone.freeze", "fcos_core.modeling.detector.build_detection_model", "fcos.FCOS.model.eval", "torch.device", "fcos.FCOS.model.to", "fcos_core.utils.checkpoint.DetectronCheckpointer", "fcos_core.utils.checkpoint.DetectronCheckpointer.load", "torch.tensor", "fcos.FCOS.build_transform", "torch.device", "os.path.abspath", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detector.detectors.build_detection_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["centerness", ",", "images", ".", "image_sizes", "\n", ")", "\n", "\n", "", "", "def", "_forward_train", "(", "self", ",", "locations", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", ")", ":", "\n", "        ", "loss_box_cls", ",", "loss_box_reg", ",", "loss_centerness", "=", "self", ".", "loss_evaluator", "(", "\n", "locations", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "targets", "\n", ")", "\n", "losses", "=", "{", "\n", "\"loss_cls\"", ":", "loss_box_cls", ",", "\n", "\"loss_reg\"", ":", "loss_box_reg", ",", "\n", "\"loss_centerness\"", ":", "loss_centerness", "\n", "}", "\n", "return", "None", ",", "losses", "\n", "\n", "", "def", "_forward_test", "(", "self", ",", "locations", ",", "box_cls", ",", "box_regression", ",", "centerness", ",", "image_sizes", ")", ":", "\n", "        ", "boxes", "=", "self", ".", "box_selector_test", "(", "\n", "locations", ",", "box_cls", ",", "box_regression", ",", "\n", "centerness", ",", "image_sizes", "\n", ")", "\n", "return", "boxes", ",", "{", "}", "\n", "\n", "", "def", "compute_locations", "(", "self", ",", "features", ")", ":", "\n", "        ", "locations", "=", "[", "]", "\n", "for", "level", ",", "feature", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "h", ",", "w", "=", "feature", ".", "size", "(", ")", "[", "-", "2", ":", "]", "\n", "locations_per_level", "=", "self", ".", "compute_locations_per_level", "(", "\n", "h", ",", "w", ",", "self", ".", "fpn_strides", "[", "level", "]", ",", "\n", "feature", ".", "device", "\n", ")", "\n", "locations", ".", "append", "(", "locations_per_level", ")", "\n", "", "return", "locations", "\n", "\n", "", "def", "compute_locations_per_level", "(", "self", ",", "h", ",", "w", ",", "stride", ",", "device", ")", ":", "\n", "        ", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "w", "*", "stride", ",", "step", "=", "stride", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.detect": [[199, 222], ["fcos.FCOS.transforms", "fcos_core.structures.image_list.to_image_list", "image_list.to.to.to", "fcos.FCOS.select_top_predictions", "fcos.FCOS._bbox_list_to_py_bbox_list", "torch.no_grad", "fcos.FCOS.model", "o.to", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.select_top_predictions", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS._bbox_list_to_py_bbox_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "h", "*", "stride", ",", "step", "=", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "locations", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "+", "stride", "//", "2", "\n", "return", "locations", "\n", "\n", "", "", "def", "build_fcos", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "FCOSModule", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS._bbox_list_to_py_bbox_list": [[223, 241], ["range", "len", "int", "float", "results.append", "float", "predictions.get_field", "predictions.get_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS._py_bbox_list_to_bbox_list": [[242, 261], ["fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.bounding_box.BoxList.add_field", "fcos_core.structures.bounding_box.BoxList.add_field", "bboxes.append", "labels.append", "scores.append", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.select_top_predictions": [[262, 288], ["predictions.get_field", "predictions.get_field", "isinstance", "torch.nonzero().squeeze", "predictions.get_field", "predictions.get_field.sort", "predictions.get_field.new_tensor", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.build_transform": [[289, 317], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToTensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.show_bboxes": [[318, 331], ["im.copy.copy.copy", "fcos.FCOS._py_bbox_list_to_bbox_list", "fcos.FCOS.overlay_boxes", "fcos.FCOS.overlay_class_names", "cv2.imshow", "cv2.waitKey"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS._py_bbox_list_to_bbox_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.overlay_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.overlay_class_names"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.overlay_boxes": [[332, 354], ["predictions.get_field", "fcos.FCOS.compute_colors_for_labels().tolist", "zip", "box.to.to.to", "cv2.rectangle", "fcos.FCOS.compute_colors_for_labels", "box[].tolist", "box[].tolist", "tuple", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.compute_colors_for_labels"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.overlay_class_names": [[355, 379], ["predictions.get_field().tolist", "predictions.get_field().tolist", "zip", "template.format", "cv2.putText", "predictions.get_field", "predictions.get_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.compute_colors_for_labels": [[380, 387], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.fcos.fcos.FCOS.list_available_models": [[388, 391], ["_MODEL_NAMES_TO_INFO_.items", "print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.CombinedROIHeads.__init__": [[15, 22], ["super().__init__", "cfg.clone"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["def", "__init__", "(", "self", ",", "cfg", ",", "heads", ")", ":", "\n", "        ", "super", "(", "CombinedROIHeads", ",", "self", ")", ".", "__init__", "(", "heads", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", "and", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "self", ".", "mask", ".", "feature_extractor", "=", "self", ".", "box", ".", "feature_extractor", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "and", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "self", ".", "keypoint", ".", "feature_extractor", "=", "self", ".", "box", ".", "feature_extractor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.CombinedROIHeads.forward": [[23, 56], ["roi_heads.CombinedROIHeads.box", "losses.update", "roi_heads.CombinedROIHeads.mask", "losses.update", "roi_heads.CombinedROIHeads.keypoint", "losses.update"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.GenericMask.mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "losses", "=", "{", "}", "\n", "# TODO rename x to roi_box_features, if it doesn't increase memory consumption", "\n", "x", ",", "detections", ",", "loss_box", "=", "self", ".", "box", "(", "features", ",", "proposals", ",", "targets", ")", "\n", "losses", ".", "update", "(", "loss_box", ")", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "            ", "mask_features", "=", "features", "\n", "# optimization: during training, if we share the feature extractor between", "\n", "# the box and the mask heads, then we can reuse the features already computed", "\n", "if", "(", "\n", "self", ".", "training", "\n", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", "\n", ")", ":", "\n", "                ", "mask_features", "=", "x", "\n", "# During training, self.box() will return the unaltered proposals as \"detections\"", "\n", "# this makes the API consistent during training and testing", "\n", "", "x", ",", "detections", ",", "loss_mask", "=", "self", ".", "mask", "(", "mask_features", ",", "detections", ",", "targets", ")", "\n", "losses", ".", "update", "(", "loss_mask", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "keypoint_features", "=", "features", "\n", "# optimization: during training, if we share the feature extractor between", "\n", "# the box and the mask heads, then we can reuse the features already computed", "\n", "if", "(", "\n", "self", ".", "training", "\n", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", "\n", ")", ":", "\n", "                ", "keypoint_features", "=", "x", "\n", "# During training, self.box() will return the unaltered proposals as \"detections\"", "\n", "# this makes the API consistent during training and testing", "\n", "", "x", ",", "detections", ",", "loss_keypoint", "=", "self", ".", "keypoint", "(", "keypoint_features", ",", "detections", ",", "targets", ")", "\n", "losses", ".", "update", "(", "loss_keypoint", ")", "\n", "", "return", "x", ",", "detections", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.build_roi_heads": [[58, 77], ["CombinedROIHeads.append", "CombinedROIHeads.append", "CombinedROIHeads.append", "roi_heads.CombinedROIHeads", "box_head.box_head.build_roi_box_head", "mask_head.mask_head.build_roi_mask_head", "keypoint_head.keypoint_head.build_roi_keypoint_head"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.box_head.build_roi_box_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.mask_head.build_roi_mask_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.keypoint_head.build_roi_keypoint_head"], ["", "", "def", "build_roi_heads", "(", "cfg", ",", "in_channels", ")", ":", "\n", "# individually create the heads, that will be combined together", "\n", "# afterwards", "\n", "    ", "roi_heads", "=", "[", "]", "\n", "if", "cfg", ".", "MODEL", ".", "RETINANET_ON", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "if", "not", "cfg", ".", "MODEL", ".", "RPN_ONLY", ":", "\n", "        ", "roi_heads", ".", "append", "(", "(", "\"box\"", ",", "build_roi_box_head", "(", "cfg", ",", "in_channels", ")", ")", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "roi_heads", ".", "append", "(", "(", "\"mask\"", ",", "build_roi_mask_head", "(", "cfg", ",", "in_channels", ")", ")", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "roi_heads", ".", "append", "(", "(", "\"keypoint\"", ",", "build_roi_keypoint_head", "(", "cfg", ",", "in_channels", ")", ")", ")", "\n", "\n", "# combine individual heads in a single module", "\n", "", "if", "roi_heads", ":", "\n", "        ", "roi_heads", "=", "CombinedROIHeads", "(", "cfg", ",", "roi_heads", ")", "\n", "\n", "", "return", "roi_heads", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.BaseMaskRCNNHead.__init__": [[160, 172], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.BaseMaskRCNNHead.from_config": [[173, 176], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.BaseMaskRCNNHead.forward": [[177, 197], ["mask_head.BaseMaskRCNNHead.layers", "mask_head.mask_rcnn_inference", "mask_head.mask_rcnn_loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_loss"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.BaseMaskRCNNHead.layers": [[198, 203], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.MaskRCNNConvUpsampleHead.__init__": [[215, 264], ["super().__init__", "enumerate", "detectron2.layers.ConvTranspose2d", "mask_head.MaskRCNNConvUpsampleHead.add_module", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "len", "detectron2.layers.Conv2d", "mask_head.MaskRCNNConvUpsampleHead.add_module", "mask_head.MaskRCNNConvUpsampleHead.conv_norm_relus.append", "torch.nn.ReLU", "fvcore.c2_msra_fill", "torch.nn.init.constant_", "detectron2.layers.get_norm", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.MaskRCNNConvUpsampleHead.from_config": [[265, 280], ["super().from_config", "super().from_config.update"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.MaskRCNNConvUpsampleHead.layers": [[281, 285], ["layer"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_loss": [[31, 112], ["pred_mask_logits.size", "pred_mask_logits.size", "detectron2.layers.cat", "gt_masks.to.to", "gt_masks_bool.sum().item", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "torch.nn.functional.binary_cross_entropy_with_logits", "pred_mask_logits.size", "pred_mask_logits.size", "pred_mask_logits.size", "instances_per_image.gt_masks.crop_and_resize().to", "gt_masks.to.append", "len", "torch.arange", "detectron2.layers.cat", "max", "max", "pred_mask_logits.sigmoid", "torch.cat", "enumerate", "len", "instances_per_image.gt_classes.to", "detectron2.layers.cat.append", "pred_mask_logits.sum", "mask_incorrect.sum().item", "max", "gt_masks_bool.sum", "torch.stack", "detectron2.utils.events.get_event_storage.put_image", "instances_per_image.gt_masks.crop_and_resize", "mask_incorrect.numel", "gt_masks_bool.numel", "mask_incorrect.sum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.crop_and_resize"], ["positive_boxes", ".", "append", "(", "boxes_per_image", "[", "inds", "]", ")", "\n", "positive_inds", ".", "append", "(", "inds_mask", ")", "\n", "", "return", "positive_boxes", ",", "positive_inds", "\n", "\n", "\n", "", "class", "ROIMaskHead", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ROIMaskHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "self", ".", "feature_extractor", "=", "make_roi_mask_feature_extractor", "(", "cfg", ",", "in_channels", ")", "\n", "self", ".", "predictor", "=", "make_roi_mask_predictor", "(", "\n", "cfg", ",", "self", ".", "feature_extractor", ".", "out_channels", ")", "\n", "self", ".", "post_processor", "=", "make_roi_mask_post_processor", "(", "cfg", ")", "\n", "self", ".", "loss_evaluator", "=", "make_roi_mask_loss_evaluator", "(", "cfg", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            features (list[Tensor]): feature-maps from possibly several levels\n            proposals (list[BoxList]): proposal boxes\n            targets (list[BoxList], optional): the ground-truth targets.\n\n        Returns:\n            x (Tensor): the result of the feature extractor\n            proposals (list[BoxList]): during training, the original proposals\n                are returned. During testing, the predicted boxlists are returned\n                with the `mask` field set\n            losses (dict[Tensor]): During training, returns the losses for the\n                head. During testing, returns an empty dict.\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# during training, only focus on positive boxes", "\n", "            ", "all_proposals", "=", "proposals", "\n", "proposals", ",", "positive_inds", "=", "keep_only_positive_boxes", "(", "proposals", ")", "\n", "", "if", "self", ".", "training", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "x", "=", "features", "\n", "x", "=", "x", "[", "torch", ".", "cat", "(", "positive_inds", ",", "dim", "=", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n", "", "mask_logits", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "mask_logits", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_mask", "=", "self", ".", "loss_evaluator", "(", "proposals", ",", "mask_logits", ",", "targets", ")", "\n", "\n", "return", "x", ",", "all_proposals", ",", "dict", "(", "loss_mask", "=", "loss_mask", ")", "\n", "\n", "\n", "", "", "def", "build_roi_mask_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "ROIMaskHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_inference": [[114, 153], ["[].sigmoid.split", "zip", "pred_mask_logits.size", "pred_mask_logits.sigmoid", "detectron2.layers.cat", "torch.arange", "[].sigmoid", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.build_mask_head": [[287, 293], ["ROI_MASK_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.__init__": [[180, 245], ["len", "len", "type", "type.cat", "proposals[].has", "detectron2.structures.Boxes", "len", "detectron2.layers.cat", "type.cat", "torch.zeros", "p.has"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["def", "__init__", "(", "\n", "self", ",", "\n", "box2box_transform", ",", "\n", "pred_class_logits", ",", "\n", "pred_proposal_deltas", ",", "\n", "proposals", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box2box_transform (Box2BoxTransform/Box2BoxTransformRotated):\n                box2box transform instance for proposal-to-detection transformations.\n            pred_class_logits (Tensor): A tensor of shape (R, K + 1) storing the predicted class\n                logits for all R predicted object instances.\n                Each row corresponds to a predicted object instance.\n            pred_proposal_deltas (Tensor): A tensor of shape (R, K * B) or (R, B) for\n                class-specific or class-agnostic regression. It stores the predicted deltas that\n                transform proposals into final box detections.\n                B is the box dimension (4 or 5).\n                When B is 4, each row is [dx, dy, dw, dh (, ....)].\n                When B is 5, each row is [dx, dy, dw, dh, da (, ....)].\n            proposals (list[Instances]): A list of N Instances, where Instances i stores the\n                proposals for image i, in the field \"proposal_boxes\".\n                When training, each Instances must have ground-truth labels\n                stored in the field \"gt_classes\" and \"gt_boxes\".\n                The total number of all instances must be equal to R.\n            smooth_l1_beta (float): The transition point between L1 and L2 loss in\n                the smooth L1 loss function. When set to 0, the loss becomes L1. When\n                set to +inf, the loss becomes constant 0.\n            box_reg_loss_type (str): Box regression loss type. One of: \"smooth_l1\", \"giou\"\n        \"\"\"", "\n", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "num_preds_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "self", ".", "pred_class_logits", "=", "pred_class_logits", "\n", "self", ".", "pred_proposal_deltas", "=", "pred_proposal_deltas", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "\n", "self", ".", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "\n", "if", "len", "(", "proposals", ")", ":", "\n", "            ", "box_type", "=", "type", "(", "proposals", "[", "0", "]", ".", "proposal_boxes", ")", "\n", "# cat(..., dim=0) concatenates over all images in the batch", "\n", "self", ".", "proposals", "=", "box_type", ".", "cat", "(", "[", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "]", ")", "\n", "assert", "(", "\n", "not", "self", ".", "proposals", ".", "tensor", ".", "requires_grad", "\n", ")", ",", "\"Proposals should not require gradients!\"", "\n", "\n", "# \"gt_classes\" exists if and only if training. But other gt fields may", "\n", "# not necessarily exist in training for images that have no groundtruth.", "\n", "if", "proposals", "[", "0", "]", ".", "has", "(", "\"gt_classes\"", ")", ":", "\n", "                ", "self", ".", "gt_classes", "=", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# If \"gt_boxes\" does not exist, the proposals must be all negative and", "\n", "# should not be included in regression loss computation.", "\n", "# Here we just use proposal_boxes as an arbitrary placeholder because its", "\n", "# value won't be used in self.box_reg_loss().", "\n", "gt_boxes", "=", "[", "\n", "p", ".", "gt_boxes", "if", "p", ".", "has", "(", "\"gt_boxes\"", ")", "else", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "\n", "]", "\n", "self", ".", "gt_boxes", "=", "box_type", ".", "cat", "(", "gt_boxes", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "proposals", "=", "Boxes", "(", "torch", ".", "zeros", "(", "0", ",", "4", ",", "device", "=", "self", ".", "pred_proposal_deltas", ".", "device", ")", ")", "\n", "", "self", ".", "_no_instances", "=", "len", "(", "self", ".", "proposals", ")", "==", "0", "# no instances found", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss": [[246, 252], ["fast_rcnn._log_classification_stats", "detectron2.layers.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn._log_classification_stats", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy"], ["", "def", "softmax_cross_entropy_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "_log_classification_stats", "(", "self", ".", "pred_class_logits", ",", "self", ".", "gt_classes", ")", "\n", "return", "cross_entropy", "(", "self", ".", "pred_class_logits", ",", "self", ".", "gt_classes", ",", "reduction", "=", "\"mean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.box_reg_loss": [[253, 308], ["fast_rcnn.FastRCNNOutputs.proposals.tensor.size", "fast_rcnn.FastRCNNOutputs.pred_proposal_deltas.size", "detectron2.layers.nonzero_tuple", "torch.arange", "fast_rcnn.FastRCNNOutputs.box2box_transform.get_deltas", "fvcore.nn.smooth_l1_loss", "fast_rcnn.FastRCNNOutputs.gt_classes.numel", "fast_rcnn.FastRCNNOutputs.pred_proposal_deltas.sum", "torch.arange", "fast_rcnn.FastRCNNOutputs.box2box_transform.apply_deltas", "fvcore.nn.giou_loss", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas"], ["", "def", "box_reg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "if", "self", ".", "_no_instances", ":", "\n", "            ", "return", "0.0", "*", "self", ".", "pred_proposal_deltas", ".", "sum", "(", ")", "\n", "\n", "", "box_dim", "=", "self", ".", "proposals", ".", "tensor", ".", "size", "(", "1", ")", "# 4 or 5", "\n", "cls_agnostic_bbox_reg", "=", "self", ".", "pred_proposal_deltas", ".", "size", "(", "1", ")", "==", "box_dim", "\n", "device", "=", "self", ".", "pred_proposal_deltas", ".", "device", "\n", "\n", "bg_class_ind", "=", "self", ".", "pred_class_logits", ".", "shape", "[", "1", "]", "-", "1", "\n", "# Box delta loss is only computed between the prediction for the gt class k", "\n", "# (if 0 <= k < bg_class_ind) and the target; there is no loss defined on predictions", "\n", "# for non-gt classes and background.", "\n", "# Empty fg_inds should produce a valid loss of zero because reduction=sum.", "\n", "fg_inds", "=", "nonzero_tuple", "(", "(", "self", ".", "gt_classes", ">=", "0", ")", "&", "(", "self", ".", "gt_classes", "<", "bg_class_ind", ")", ")", "[", "0", "]", "\n", "\n", "if", "cls_agnostic_bbox_reg", ":", "\n", "# pred_proposal_deltas only corresponds to foreground class for agnostic", "\n", "            ", "gt_class_cols", "=", "torch", ".", "arange", "(", "box_dim", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "# pred_proposal_deltas for class k are located in columns [b * k : b * k + b],", "\n", "# where b is the dimension of box representation (4 or 5)", "\n", "# Note that compared to Detectron1,", "\n", "# we do not perform bounding box regression for background classes.", "\n", "            ", "gt_class_cols", "=", "box_dim", "*", "self", ".", "gt_classes", "[", "fg_inds", ",", "None", "]", "+", "torch", ".", "arange", "(", "\n", "box_dim", ",", "device", "=", "device", "\n", ")", "\n", "\n", "", "if", "self", ".", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "            ", "gt_proposal_deltas", "=", "self", ".", "box2box_transform", ".", "get_deltas", "(", "\n", "self", ".", "proposals", ".", "tensor", ",", "self", ".", "gt_boxes", ".", "tensor", "\n", ")", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "self", ".", "pred_proposal_deltas", "[", "fg_inds", "[", ":", ",", "None", "]", ",", "gt_class_cols", "]", ",", "\n", "gt_proposal_deltas", "[", "fg_inds", "]", ",", "\n", "self", ".", "smooth_l1_beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "elif", "self", ".", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "            ", "fg_pred_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "self", ".", "pred_proposal_deltas", "[", "fg_inds", "[", ":", ",", "None", "]", ",", "gt_class_cols", "]", ",", "\n", "self", ".", "proposals", ".", "tensor", "[", "fg_inds", "]", ",", "\n", ")", "\n", "loss_box_reg", "=", "giou_loss", "(", "\n", "fg_pred_boxes", ",", "\n", "self", ".", "gt_boxes", ".", "tensor", "[", "fg_inds", "]", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid bbox reg loss type '{self.box_reg_loss_type}'\"", ")", "\n", "\n", "", "loss_box_reg", "=", "loss_box_reg", "/", "self", ".", "gt_classes", ".", "numel", "(", ")", "\n", "return", "loss_box_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.losses": [[309, 314], ["fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss", "fast_rcnn.FastRCNNOutputs.box_reg_loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.box_reg_loss"], ["", "def", "losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "return", "{", "\"loss_cls\"", ":", "self", ".", "softmax_cross_entropy_loss", "(", ")", ",", "\"loss_box_reg\"", ":", "self", ".", "box_reg_loss", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.predict_boxes": [[315, 321], ["fast_rcnn.FastRCNNOutputs.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputs.split"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas"], ["", "def", "predict_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "pred", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "self", ".", "pred_proposal_deltas", ",", "self", ".", "proposals", ".", "tensor", ")", "\n", "return", "pred", ".", "split", "(", "self", ".", "num_preds_per_image", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputs.predict_probs": [[322, 328], ["torch.nn.functional.softmax", "torch.nn.functional.softmax.split"], "methods", ["None"], ["", "def", "predict_probs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "probs", "=", "F", ".", "softmax", "(", "self", ".", "pred_class_logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "probs", ".", "split", "(", "self", ".", "num_preds_per_image", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.__init__": [[338, 397], ["torch.nn.Module.__init__", "isinstance", "torch.nn.Linear", "len", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.normal_", "isinstance", "detectron2.layers.ShapeSpec", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "ShapeSpec", ",", "\n", "*", ",", "\n", "box2box_transform", ",", "\n", "num_classes", ":", "int", ",", "\n", "test_score_thresh", ":", "float", "=", "0.0", ",", "\n", "test_nms_thresh", ":", "float", "=", "0.5", ",", "\n", "test_topk_per_image", ":", "int", "=", "100", ",", "\n", "cls_agnostic_bbox_reg", ":", "bool", "=", "False", ",", "\n", "smooth_l1_beta", ":", "float", "=", "0.0", ",", "\n", "box_reg_loss_type", ":", "str", "=", "\"smooth_l1\"", ",", "\n", "loss_weight", ":", "Union", "[", "float", ",", "Dict", "[", "str", ",", "float", "]", "]", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature to this module\n            box2box_transform (Box2BoxTransform or Box2BoxTransformRotated):\n            num_classes (int): number of foreground classes\n            test_score_thresh (float): threshold to filter predictions results.\n            test_nms_thresh (float): NMS threshold for prediction results.\n            test_topk_per_image (int): number of top predictions to produce per image.\n            cls_agnostic_bbox_reg (bool): whether to use class agnostic for bbox regression\n            smooth_l1_beta (float): transition point from L1 to L2 loss. Only used if\n                `box_reg_loss_type` is \"smooth_l1\"\n            box_reg_loss_type (str): Box regression loss type. One of: \"smooth_l1\", \"giou\"\n            loss_weight (float|dict): weights to use for losses. Can be single float for weighting\n                all losses, or a dict of individual weightings. Valid dict keys are:\n                    * \"loss_cls\": applied to classification loss\n                    * \"loss_box_reg\": applied to box regression loss\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "input_shape", ",", "int", ")", ":", "# some backward compatibility", "\n", "            ", "input_shape", "=", "ShapeSpec", "(", "channels", "=", "input_shape", ")", "\n", "", "self", ".", "num_classes", "=", "num_classes", "\n", "input_size", "=", "input_shape", ".", "channels", "*", "(", "input_shape", ".", "width", "or", "1", ")", "*", "(", "input_shape", ".", "height", "or", "1", ")", "\n", "# prediction layer for num_classes foreground classes and one background class (hence + 1)", "\n", "self", ".", "cls_score", "=", "nn", ".", "Linear", "(", "input_size", ",", "num_classes", "+", "1", ")", "\n", "num_bbox_reg_classes", "=", "1", "if", "cls_agnostic_bbox_reg", "else", "num_classes", "\n", "box_dim", "=", "len", "(", "box2box_transform", ".", "weights", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Linear", "(", "input_size", ",", "num_bbox_reg_classes", "*", "box_dim", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "cls_score", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "bbox_pred", ".", "weight", ",", "std", "=", "0.001", ")", "\n", "for", "l", "in", "[", "self", ".", "cls_score", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "self", ".", "test_score_thresh", "=", "test_score_thresh", "\n", "self", ".", "test_nms_thresh", "=", "test_nms_thresh", "\n", "self", ".", "test_topk_per_image", "=", "test_topk_per_image", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "if", "isinstance", "(", "loss_weight", ",", "float", ")", ":", "\n", "            ", "loss_weight", "=", "{", "\"loss_cls\"", ":", "loss_weight", ",", "\"loss_box_reg\"", ":", "loss_weight", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.from_config": [[398, 412], ["detectron2.modeling.box_regression.Box2BoxTransform"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "return", "{", "\n", "\"input_shape\"", ":", "input_shape", ",", "\n", "\"box2box_transform\"", ":", "Box2BoxTransform", "(", "weights", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_WEIGHTS", ")", ",", "\n", "# fmt: off", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", ",", "\n", "\"cls_agnostic_bbox_reg\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CLS_AGNOSTIC_BBOX_REG", ",", "\n", "\"smooth_l1_beta\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "SMOOTH_L1_BETA", ",", "\n", "\"test_score_thresh\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "SCORE_THRESH_TEST", ",", "\n", "\"test_nms_thresh\"", ":", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NMS_THRESH_TEST", ",", "\n", "\"test_topk_per_image\"", ":", "cfg", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", ",", "\n", "\"box_reg_loss_type\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_LOSS_TYPE", ",", "\n", "\"loss_weight\"", ":", "{", "\"loss_box_reg\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_LOSS_WEIGHT", "}", ",", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.forward": [[415, 433], ["fast_rcnn.FastRCNNOutputLayers.cls_score", "fast_rcnn.FastRCNNOutputLayers.bbox_pred", "torch.flatten.dim", "torch.flatten"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: per-region features of shape (N, ...) for N bounding boxes to predict.\n\n        Returns:\n            (Tensor, Tensor):\n            First tensor: shape (N,K+1), scores for each of the N box. Each row contains the\n            scores for K object categories and 1 background class.\n\n            Second tensor: bounding box regression deltas for each box. Shape is shape (N,Kx4),\n            or (N,4) for class-agnostic regression.\n        \"\"\"", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "\n", "", "scores", "=", "self", ".", "cls_score", "(", "x", ")", "\n", "proposal_deltas", "=", "self", ".", "bbox_pred", "(", "x", ")", "\n", "return", "scores", ",", "proposal_deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses": [[434, 475], ["fast_rcnn._log_classification_stats", "len", "len", "detectron2.layers.cat", "torch.empty", "detectron2.layers.cat", "detectron2.layers.cat", "torch.empty", "detectron2.layers.cross_entropy", "fast_rcnn.FastRCNNOutputLayers.box_reg_loss", "fast_rcnn.FastRCNNOutputLayers.loss_weight.get", "losses.items", "p.has"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn._log_classification_stats", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.box_reg_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["", "def", "losses", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were used\n                to compute predictions. The fields ``proposal_boxes``, ``gt_boxes``,\n                ``gt_classes`` are expected.\n\n        Returns:\n            Dict[str, Tensor]: dict of losses\n        \"\"\"", "\n", "scores", ",", "proposal_deltas", "=", "predictions", "\n", "\n", "# parse classification outputs", "\n", "gt_classes", "=", "(", "\n", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "if", "len", "(", "proposals", ")", "else", "torch", ".", "empty", "(", "0", ")", "\n", ")", "\n", "_log_classification_stats", "(", "scores", ",", "gt_classes", ")", "\n", "\n", "# parse box regression outputs", "\n", "if", "len", "(", "proposals", ")", ":", "\n", "            ", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "proposal_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "# Nx4", "\n", "assert", "not", "proposal_boxes", ".", "requires_grad", ",", "\"Proposals should not require gradients!\"", "\n", "# If \"gt_boxes\" does not exist, the proposals must be all negative and", "\n", "# should not be included in regression loss computation.", "\n", "# Here we just use proposal_boxes as an arbitrary placeholder because its", "\n", "# value won't be used in self.box_reg_loss().", "\n", "gt_boxes", "=", "cat", "(", "\n", "[", "(", "p", ".", "gt_boxes", "if", "p", ".", "has", "(", "\"gt_boxes\"", ")", "else", "p", ".", "proposal_boxes", ")", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "proposal_boxes", "=", "gt_boxes", "=", "torch", ".", "empty", "(", "(", "0", ",", "4", ")", ",", "device", "=", "proposal_deltas", ".", "device", ")", "\n", "\n", "", "losses", "=", "{", "\n", "\"loss_cls\"", ":", "cross_entropy", "(", "scores", ",", "gt_classes", ",", "reduction", "=", "\"mean\"", ")", ",", "\n", "\"loss_box_reg\"", ":", "self", ".", "box_reg_loss", "(", "\n", "proposal_boxes", ",", "gt_boxes", ",", "proposal_deltas", ",", "gt_classes", "\n", ")", ",", "\n", "}", "\n", "return", "{", "k", ":", "v", "*", "self", ".", "loss_weight", ".", "get", "(", "k", ",", "1.0", ")", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.box_reg_loss": [[476, 520], ["detectron2.layers.nonzero_tuple", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.get_deltas", "fvcore.nn.smooth_l1_loss", "max", "pred_deltas.view", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.apply_deltas", "fvcore.nn.giou_loss", "ValueError", "gt_classes.numel"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas"], ["", "def", "box_reg_loss", "(", "self", ",", "proposal_boxes", ",", "gt_boxes", ",", "pred_deltas", ",", "gt_classes", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            All boxes are tensors with the same shape Rx(4 or 5).\n            gt_classes is a long tensor of shape R, the gt class label of each proposal.\n            R shall be the number of proposals.\n        \"\"\"", "\n", "box_dim", "=", "proposal_boxes", ".", "shape", "[", "1", "]", "# 4 or 5", "\n", "# Regression loss is only computed for foreground proposals (those matched to a GT)", "\n", "fg_inds", "=", "nonzero_tuple", "(", "(", "gt_classes", ">=", "0", ")", "&", "(", "gt_classes", "<", "self", ".", "num_classes", ")", ")", "[", "0", "]", "\n", "if", "pred_deltas", ".", "shape", "[", "1", "]", "==", "box_dim", ":", "# cls-agnostic regression", "\n", "            ", "fg_pred_deltas", "=", "pred_deltas", "[", "fg_inds", "]", "\n", "", "else", ":", "\n", "            ", "fg_pred_deltas", "=", "pred_deltas", ".", "view", "(", "-", "1", ",", "self", ".", "num_classes", ",", "box_dim", ")", "[", "\n", "fg_inds", ",", "gt_classes", "[", "fg_inds", "]", "\n", "]", "\n", "\n", "", "if", "self", ".", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "            ", "gt_pred_deltas", "=", "self", ".", "box2box_transform", ".", "get_deltas", "(", "\n", "proposal_boxes", "[", "fg_inds", "]", ",", "\n", "gt_boxes", "[", "fg_inds", "]", ",", "\n", ")", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "fg_pred_deltas", ",", "gt_pred_deltas", ",", "self", ".", "smooth_l1_beta", ",", "reduction", "=", "\"sum\"", "\n", ")", "\n", "", "elif", "self", ".", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "            ", "fg_pred_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "fg_pred_deltas", ",", "proposal_boxes", "[", "fg_inds", "]", "\n", ")", "\n", "loss_box_reg", "=", "giou_loss", "(", "fg_pred_boxes", ",", "gt_boxes", "[", "fg_inds", "]", ",", "reduction", "=", "\"sum\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid bbox reg loss type '{self.box_reg_loss_type}'\"", ")", "\n", "# The reg loss is normalized using the total number of regions (R), not the number", "\n", "# of foreground regions even though the box regression loss is only defined on", "\n", "# foreground regions. Why? Because doing so gives equal training influence to", "\n", "# each foreground example. To see how, consider two different minibatches:", "\n", "#  (1) Contains a single foreground region", "\n", "#  (2) Contains 100 foreground regions", "\n", "# If we normalize by the number of foreground regions, the single example in", "\n", "# minibatch (1) will be given 100 times as much influence as each foreground", "\n", "# example in minibatch (2). Normalizing by the total number of regions, R,", "\n", "# means that the single example in minibatch (1) and each of the 100 examples", "\n", "# in minibatch (2) are given equal influence.", "\n", "", "return", "loss_box_reg", "/", "max", "(", "gt_classes", ".", "numel", "(", ")", ",", "1.0", ")", "# return 0 if empty", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.inference": [[521, 542], ["fast_rcnn.FastRCNNOutputLayers.predict_boxes", "fast_rcnn.FastRCNNOutputLayers.predict_probs", "fast_rcnn.fast_rcnn_inference"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.fast_rcnn_inference"], ["", "def", "inference", "(", "self", ",", "predictions", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions. The ``proposal_boxes`` field is expected.\n\n        Returns:\n            list[Instances]: same as `fast_rcnn_inference`.\n            list[Tensor]: same as `fast_rcnn_inference`.\n        \"\"\"", "\n", "boxes", "=", "self", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "scores", "=", "self", ".", "predict_probs", "(", "predictions", ",", "proposals", ")", "\n", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "return", "fast_rcnn_inference", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "self", ".", "test_score_thresh", ",", "\n", "self", ".", "test_nms_thresh", ",", "\n", "self", ".", "test_topk_per_image", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes_for_gt_classes": [[544, 578], ["detectron2.layers.cat", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputLayers.split", "len", "torch.cat", "gt_classes.clamp_.clamp_.clamp_", "len", "fast_rcnn.FastRCNNOutputLayers.view", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "predict_boxes_for_gt_classes", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were used\n                to compute predictions. The fields ``proposal_boxes``, ``gt_classes`` are expected.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted boxes for GT classes in case of\n                class-specific box head. Element i of the list has shape (Ri, B), where Ri is\n                the number of proposals for image i and B is the box dimension (4 or 5)\n        \"\"\"", "\n", "if", "not", "len", "(", "proposals", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "scores", ",", "proposal_deltas", "=", "predictions", "\n", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "proposal_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "N", ",", "B", "=", "proposal_boxes", ".", "shape", "\n", "predict_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "proposal_deltas", ",", "proposal_boxes", "\n", ")", "# Nx(KxB)", "\n", "\n", "K", "=", "predict_boxes", ".", "shape", "[", "1", "]", "//", "B", "\n", "if", "K", ">", "1", ":", "\n", "            ", "gt_classes", "=", "torch", ".", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "# Some proposals are ignored or have a background class. Their gt_classes", "\n", "# cannot be used as index.", "\n", "gt_classes", "=", "gt_classes", ".", "clamp_", "(", "0", ",", "K", "-", "1", ")", "\n", "\n", "predict_boxes", "=", "predict_boxes", ".", "view", "(", "N", ",", "K", ",", "B", ")", "[", "\n", "torch", ".", "arange", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "predict_boxes", ".", "device", ")", ",", "gt_classes", "\n", "]", "\n", "", "num_prop_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "return", "predict_boxes", ".", "split", "(", "num_prop_per_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes": [[579, 604], ["detectron2.layers.cat", "fast_rcnn.FastRCNNOutputLayers.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputLayers.split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas"], ["", "def", "predict_boxes", "(", "\n", "self", ",", "predictions", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions. The ``proposal_boxes`` field is expected.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted class-specific or class-agnostic boxes\n                for each image. Element i has shape (Ri, K * B) or (Ri, B), where Ri is\n                the number of proposals for image i and B is the box dimension (4 or 5)\n        \"\"\"", "\n", "if", "not", "len", "(", "proposals", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "_", ",", "proposal_deltas", "=", "predictions", "\n", "num_prop_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "proposal_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "predict_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "proposal_deltas", ",", "\n", "proposal_boxes", ",", "\n", ")", "# Nx(KxB)", "\n", "return", "predict_boxes", ".", "split", "(", "num_prop_per_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs": [[605, 623], ["torch.nn.functional.softmax", "torch.nn.functional.softmax.split", "len"], "methods", ["None"], ["", "def", "predict_probs", "(", "\n", "self", ",", "predictions", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "proposals", ":", "List", "[", "Instances", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted class probabilities for each image.\n                Element i has shape (Ri, K + 1), where Ri is the number of proposals for image i.\n        \"\"\"", "\n", "scores", ",", "_", "=", "predictions", "\n", "num_inst_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "probs", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "return", "probs", ".", "split", "(", "num_inst_per_image", ",", "dim", "=", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.fast_rcnn_inference": [[46, 86], ["fast_rcnn.fast_rcnn_inference_single_image", "zip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.fast_rcnn_inference_single_image"], ["def", "fast_rcnn_inference", "(", "\n", "boxes", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "scores", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "image_shapes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "score_thresh", ":", "float", ",", "\n", "nms_thresh", ":", "float", ",", "\n", "topk_per_image", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Call `fast_rcnn_inference_single_image` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 4) if doing\n            class-specific regression, or (Ri, 4) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputLayers.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputLayers.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"", "\n", "result_per_image", "=", "[", "\n", "fast_rcnn_inference_single_image", "(", "\n", "boxes_per_image", ",", "scores_per_image", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", "\n", "for", "scores_per_image", ",", "boxes_per_image", ",", "image_shape", "in", "zip", "(", "scores", ",", "boxes", ",", "image_shapes", ")", "\n", "]", "\n", "return", "[", "x", "[", "0", "]", "for", "x", "in", "result_per_image", "]", ",", "[", "x", "[", "1", "]", "for", "x", "in", "result_per_image", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn._log_classification_stats": [[88, 116], ["gt_classes.numel", "pred_logits.argmax", "fg_inds.nonzero().numel", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "fg_inds.nonzero"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar"], ["", "def", "_log_classification_stats", "(", "pred_logits", ",", "gt_classes", ",", "prefix", "=", "\"fast_rcnn\"", ")", ":", "\n", "    ", "\"\"\"\n    Log the classification metrics to EventStorage.\n\n    Args:\n        pred_logits: Rx(K+1) logits. The last column is for background class.\n        gt_classes: R labels\n    \"\"\"", "\n", "num_instances", "=", "gt_classes", ".", "numel", "(", ")", "\n", "if", "num_instances", "==", "0", ":", "\n", "        ", "return", "\n", "", "pred_classes", "=", "pred_logits", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "bg_class_ind", "=", "pred_logits", ".", "shape", "[", "1", "]", "-", "1", "\n", "\n", "fg_inds", "=", "(", "gt_classes", ">=", "0", ")", "&", "(", "gt_classes", "<", "bg_class_ind", ")", "\n", "num_fg", "=", "fg_inds", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "fg_gt_classes", "=", "gt_classes", "[", "fg_inds", "]", "\n", "fg_pred_classes", "=", "pred_classes", "[", "fg_inds", "]", "\n", "\n", "num_false_negative", "=", "(", "fg_pred_classes", "==", "bg_class_ind", ")", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "num_accurate", "=", "(", "pred_classes", "==", "gt_classes", ")", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "fg_num_accurate", "=", "(", "fg_pred_classes", "==", "fg_gt_classes", ")", ".", "nonzero", "(", ")", ".", "numel", "(", ")", "\n", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "f\"{prefix}/cls_accuracy\"", ",", "num_accurate", "/", "num_instances", ")", "\n", "if", "num_fg", ">", "0", ":", "\n", "        ", "storage", ".", "put_scalar", "(", "f\"{prefix}/fg_cls_accuracy\"", ",", "fg_num_accurate", "/", "num_fg", ")", "\n", "storage", ".", "put_scalar", "(", "f\"{prefix}/false_negative\"", ",", "num_false_negative", "/", "num_fg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.fast_rcnn_inference_single_image": [[118, 172], ["detectron2.structures.Boxes", "boxes.tensor.view.clip", "boxes.tensor.view.tensor.view", "filter_mask.nonzero", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.isfinite().all", "torch.isfinite().all", "valid_mask.all", "boxes.tensor.view.reshape", "torch.isfinite", "torch.isfinite"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms"], ["", "", "def", "fast_rcnn_inference_single_image", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shape", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "score_thresh", ":", "float", ",", "\n", "nms_thresh", ":", "float", ",", "\n", "topk_per_image", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Single-image inference. Return bounding-box detection results by thresholding\n    on scores and applying non-maximum suppression (NMS).\n\n    Args:\n        Same as `fast_rcnn_inference`, but with boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference`, but for only one image.\n    \"\"\"", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "        ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "\n", "", "scores", "=", "scores", "[", ":", ",", ":", "-", "1", "]", "\n", "num_bbox_reg_classes", "=", "boxes", ".", "shape", "[", "1", "]", "//", "4", "\n", "# Convert to Boxes to use the `clip` function ...", "\n", "boxes", "=", "Boxes", "(", "boxes", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "boxes", "=", "boxes", ".", "tensor", ".", "view", "(", "-", "1", ",", "num_bbox_reg_classes", ",", "4", ")", "# R x C x 4", "\n", "\n", "# 1. Filter results based on detection scores. It can make NMS more efficient", "\n", "#    by filtering out low-confidence detections.", "\n", "filter_mask", "=", "scores", ">", "score_thresh", "# R x K", "\n", "# R' x 2. First column contains indices of the R predictions;", "\n", "# Second column contains indices of classes.", "\n", "filter_inds", "=", "filter_mask", ".", "nonzero", "(", ")", "\n", "if", "num_bbox_reg_classes", "==", "1", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_inds", "[", ":", ",", "0", "]", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_mask", "]", "\n", "", "scores", "=", "scores", "[", "filter_mask", "]", "\n", "\n", "# 2. Apply NMS for each class independently.", "\n", "keep", "=", "batched_nms", "(", "boxes", ",", "scores", ",", "filter_inds", "[", ":", ",", "1", "]", ",", "nms_thresh", ")", "\n", "if", "topk_per_image", ">=", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "", "boxes", ",", "scores", ",", "filter_inds", "=", "boxes", "[", "keep", "]", ",", "scores", "[", "keep", "]", ",", "filter_inds", "[", "keep", "]", "\n", "\n", "result", "=", "Instances", "(", "image_shape", ")", "\n", "result", ".", "pred_boxes", "=", "Boxes", "(", "boxes", ")", "\n", "result", ".", "scores", "=", "scores", "\n", "result", ".", "pred_classes", "=", "filter_inds", "[", ":", ",", "1", "]", "\n", "return", "result", ",", "filter_inds", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.RotatedFastRCNNOutputLayers.from_config": [[139, 146], ["super().from_config", "box_regression.Box2BoxTransformRotated"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config"], ["@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "args", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "args", "[", "\"box2box_transform\"", "]", "=", "Box2BoxTransformRotated", "(", "\n", "weights", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "BBOX_REG_WEIGHTS", "\n", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.RotatedFastRCNNOutputLayers.inference": [[147, 164], ["rotated_fast_rcnn.RotatedFastRCNNOutputLayers.predict_boxes", "rotated_fast_rcnn.RotatedFastRCNNOutputLayers.predict_probs", "rotated_fast_rcnn.fast_rcnn_inference_rotated"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_rotated"], ["", "def", "inference", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[Instances]: same as `fast_rcnn_inference_rotated`.\n            list[Tensor]: same as `fast_rcnn_inference_rotated`.\n        \"\"\"", "\n", "boxes", "=", "self", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "scores", "=", "self", ".", "predict_probs", "(", "predictions", ",", "proposals", ")", "\n", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "\n", "return", "fast_rcnn_inference_rotated", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "self", ".", "test_score_thresh", ",", "\n", "self", ".", "test_nms_thresh", ",", "\n", "self", ".", "test_topk_per_image", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.RROIHeads.__init__": [[174, 184], ["roi_heads.StandardROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "assert", "(", "\n", "not", "self", ".", "mask_on", "and", "not", "self", ".", "keypoint_on", "\n", ")", ",", "\"Mask/Keypoints not supported in Rotated ROIHeads.\"", "\n", "assert", "not", "self", ".", "train_on_pred_boxes", ",", "\"train_on_pred_boxes not implemented for RROIHeads!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.RROIHeads._init_box_head": [[185, 214], ["tuple", "poolers.ROIPooler", "box_head.build_box_head.build_box_head", "rotated_fast_rcnn.RotatedFastRCNNOutputLayers", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.build_box_head"], ["", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "# fmt: on", "\n", "assert", "pooler_type", "in", "[", "\"ROIAlignRotated\"", "]", ",", "pooler_type", "\n", "# assume all channel counts are equal", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "box_head", "=", "build_box_head", "(", "\n", "cfg", ",", "ShapeSpec", "(", "channels", "=", "in_channels", ",", "height", "=", "pooler_resolution", ",", "width", "=", "pooler_resolution", ")", "\n", ")", "\n", "# This line is the only difference v.s. StandardROIHeads", "\n", "box_predictor", "=", "RotatedFastRCNNOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_head\"", ":", "box_head", ",", "\n", "\"box_predictor\"", ":", "box_predictor", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.RROIHeads.label_and_sample_proposals": [[216, 272], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "proposal_generator.proposal_utils.add_ground_truth_to_proposals", "detectron2.structures.pairwise_iou_rotated", "rotated_fast_rcnn.RROIHeads.proposal_matcher", "rotated_fast_rcnn.RROIHeads._sample_proposals", "num_bg_samples.append", "num_fg_samples.append", "proposals_with_gt.append", "numpy.mean", "numpy.mean", "len", "gt_classes.numel"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.add_ground_truth_to_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.rotated_boxes.pairwise_iou_rotated", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads._sample_proposals"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Prepare some proposals to be used to train the RROI heads.\n        It performs box matching between `proposals` and `targets`, and assigns\n        training labels to the proposals.\n        It returns `self.batch_size_per_image` random samples from proposals and groundtruth boxes,\n        with a fraction of positives that is no larger than `self.positive_sample_fraction.\n\n        Args:\n            See :meth:`StandardROIHeads.forward`\n\n        Returns:\n            list[Instances]: length `N` list of `Instances`s containing the proposals\n                sampled for training. Each `Instances` has the following fields:\n                - proposal_boxes: the rotated proposal boxes\n                - gt_boxes: the ground-truth rotated boxes that the proposal is assigned to\n                  (this is only meaningful if the proposal has a label > 0; if label = 0\n                   then the ground-truth box is random)\n                - gt_classes: the ground-truth classification lable for each proposal\n        \"\"\"", "\n", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "targets", "]", "\n", "if", "self", ".", "proposal_append_gt", ":", "\n", "            ", "proposals", "=", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", "\n", "\n", "", "proposals_with_gt", "=", "[", "]", "\n", "\n", "num_fg_samples", "=", "[", "]", "\n", "num_bg_samples", "=", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "has_gt", "=", "len", "(", "targets_per_image", ")", ">", "0", "\n", "match_quality_matrix", "=", "pairwise_iou_rotated", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "matched_idxs", ",", "matched_labels", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "sampled_idxs", ",", "gt_classes", "=", "self", ".", "_sample_proposals", "(", "\n", "matched_idxs", ",", "matched_labels", ",", "targets_per_image", ".", "gt_classes", "\n", ")", "\n", "\n", "proposals_per_image", "=", "proposals_per_image", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "\n", "if", "has_gt", ":", "\n", "                ", "sampled_targets", "=", "matched_idxs", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_boxes", "=", "targets_per_image", ".", "gt_boxes", "[", "sampled_targets", "]", "\n", "\n", "", "num_bg_samples", ".", "append", "(", "(", "gt_classes", "==", "self", ".", "num_classes", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_fg_samples", ".", "append", "(", "gt_classes", ".", "numel", "(", ")", "-", "num_bg_samples", "[", "-", "1", "]", ")", "\n", "proposals_with_gt", ".", "append", "(", "proposals_per_image", ")", "\n", "\n", "# Log the number of fg/bg samples that are selected for training ROI heads", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\"roi_head/num_fg_samples\"", ",", "np", ".", "mean", "(", "num_fg_samples", ")", ")", "\n", "storage", ".", "put_scalar", "(", "\"roi_head/num_bg_samples\"", ",", "np", ".", "mean", "(", "num_bg_samples", ")", ")", "\n", "\n", "return", "proposals_with_gt", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_rotated": [[46, 81], ["rotated_fast_rcnn.fast_rcnn_inference_single_image_rotated", "zip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_single_image_rotated"], ["def", "fast_rcnn_inference_rotated", "(", "\n", "boxes", ",", "scores", ",", "image_shapes", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Call `fast_rcnn_inference_single_image_rotated` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 5) if doing\n            class-specific regression, or (Ri, 5) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputs.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputs.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"", "\n", "result_per_image", "=", "[", "\n", "fast_rcnn_inference_single_image_rotated", "(", "\n", "boxes_per_image", ",", "scores_per_image", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", "\n", "for", "scores_per_image", ",", "boxes_per_image", ",", "image_shape", "in", "zip", "(", "scores", ",", "boxes", ",", "image_shapes", ")", "\n", "]", "\n", "return", "[", "x", "[", "0", "]", "for", "x", "in", "result_per_image", "]", ",", "[", "x", "[", "1", "]", "for", "x", "in", "result_per_image", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.rotated_fast_rcnn.fast_rcnn_inference_single_image_rotated": [[83, 132], ["detectron2.structures.RotatedBoxes", "boxes.tensor.view.clip", "boxes.tensor.view.tensor.view", "filter_mask.nonzero", "detectron2.layers.batched_nms_rotated", "detectron2.structures.Instances", "detectron2.structures.RotatedBoxes", "torch.isfinite().all", "torch.isfinite().all", "valid_mask.all", "boxes.tensor.view.reshape", "torch.isfinite", "torch.isfinite"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms_rotated"], ["", "def", "fast_rcnn_inference_single_image_rotated", "(", "\n", "boxes", ",", "scores", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Single-image inference. Return rotated bounding-box detection results by thresholding\n    on scores and applying rotated non-maximum suppression (Rotated NMS).\n\n    Args:\n        Same as `fast_rcnn_inference_rotated`, but with rotated boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference_rotated`, but for only one image.\n    \"\"\"", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "        ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "\n", "", "B", "=", "5", "# box dimension", "\n", "scores", "=", "scores", "[", ":", ",", ":", "-", "1", "]", "\n", "num_bbox_reg_classes", "=", "boxes", ".", "shape", "[", "1", "]", "//", "B", "\n", "# Convert to Boxes to use the `clip` function ...", "\n", "boxes", "=", "RotatedBoxes", "(", "boxes", ".", "reshape", "(", "-", "1", ",", "B", ")", ")", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "boxes", "=", "boxes", ".", "tensor", ".", "view", "(", "-", "1", ",", "num_bbox_reg_classes", ",", "B", ")", "# R x C x B", "\n", "# Filter results based on detection scores", "\n", "filter_mask", "=", "scores", ">", "score_thresh", "# R x K", "\n", "# R' x 2. First column contains indices of the R predictions;", "\n", "# Second column contains indices of classes.", "\n", "filter_inds", "=", "filter_mask", ".", "nonzero", "(", ")", "\n", "if", "num_bbox_reg_classes", "==", "1", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_inds", "[", ":", ",", "0", "]", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_mask", "]", "\n", "", "scores", "=", "scores", "[", "filter_mask", "]", "\n", "\n", "# Apply per-class Rotated NMS", "\n", "keep", "=", "batched_nms_rotated", "(", "boxes", ",", "scores", ",", "filter_inds", "[", ":", ",", "1", "]", ",", "nms_thresh", ")", "\n", "if", "topk_per_image", ">=", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "", "boxes", ",", "scores", ",", "filter_inds", "=", "boxes", "[", "keep", "]", ",", "scores", "[", "keep", "]", ",", "filter_inds", "[", "keep", "]", "\n", "\n", "result", "=", "Instances", "(", "image_shape", ")", "\n", "result", ".", "pred_boxes", "=", "RotatedBoxes", "(", "boxes", ")", "\n", "result", ".", "scores", "=", "scores", "\n", "result", ".", "pred_classes", "=", "filter_inds", "[", ":", ",", "1", "]", "\n", "\n", "return", "result", ",", "filter_inds", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.__init__": [[138, 165], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.from_config": [[166, 178], ["matcher.Matcher"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads._sample_proposals": [[181, 218], ["sampling.subsample_labels", "torch.cat", "gt_classes.numel", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.sampling.subsample_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals": [[219, 304], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "proposal_generator.proposal_utils.add_ground_truth_to_proposals", "detectron2.structures.pairwise_iou", "roi_heads.ROIHeads.proposal_matcher", "roi_heads.ROIHeads._sample_proposals", "num_bg_samples.append", "num_fg_samples.append", "proposals_with_gt.append", "numpy.mean", "numpy.mean", "len", "targets_per_image.get_fields().items", "gt_classes.numel", "targets_per_image.get_fields", "trg_name.startswith", "proposals_per_image.set", "proposals_per_image.has"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.add_ground_truth_to_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads._sample_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.forward": [[305, 340], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads.__init__": [[351, 386], ["roi_heads.ROIHeads.__init__", "isinstance", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads.from_config": [[387, 428], ["roi_heads.ROIHeads.from_config", "poolers.ROIPooler", "cls._build_res5_block", "fast_rcnn.FastRCNNOutputLayers", "len", "inspect.ismethod", "logger.warning", "classmethod", "detectron2.layers.ShapeSpec", "mask_head.build_mask_head", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads._build_res5_block", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.build_mask_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads._build_res5_block": [[429, 455], ["backbone.resnet.ResNet.make_stage", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads._shared_roi_transform": [[456, 459], ["roi_heads.Res5ROIHeads.pooler", "roi_heads.Res5ROIHeads.res5"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads.forward": [[460, 496], ["roi_heads.Res5ROIHeads._shared_roi_transform", "roi_heads.Res5ROIHeads.box_predictor", "roi_heads.Res5ROIHeads.label_and_sample_proposals", "roi_heads.Res5ROIHeads.mean", "roi_heads.Res5ROIHeads.box_predictor.losses", "roi_heads.Res5ROIHeads.box_predictor.inference", "roi_heads.Res5ROIHeads.forward_with_given_boxes", "roi_heads.select_foreground_proposals", "roi_heads.Res5ROIHeads.update", "roi_heads.Res5ROIHeads.mask_head", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads._shared_roi_transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_foreground_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads.forward_with_given_boxes": [[497, 520], ["instances[].has", "instances[].has", "roi_heads.Res5ROIHeads._shared_roi_transform", "roi_heads.Res5ROIHeads.mask_head"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.Res5ROIHeads._shared_roi_transform"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads.__init__": [[535, 592], ["roi_heads.ROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads.from_config": [[593, 609], ["roi_heads.ROIHeads.from_config", "inspect.ismethod", "inspect.ismethod", "inspect.ismethod", "super().from_config.update", "super().from_config.update", "super().from_config.update", "cls._init_box_head", "cls._init_mask_head", "cls._init_keypoint_head"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._init_box_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.roi_heads.PointRendROIHeads._init_mask_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._init_keypoint_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._init_box_head": [[610, 645], ["tuple", "poolers.ROIPooler", "box_head.build_box_head.build_box_head", "fast_rcnn.FastRCNNOutputLayers", "len", "detectron2.layers.ShapeSpec", "set"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.build_box_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._init_mask_head": [[647, 680], ["tuple", "mask_head.build_mask_head", "poolers.ROIPooler", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.build_mask_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._init_keypoint_head": [[681, 714], ["tuple", "keypoint_head.build_keypoint_head", "poolers.ROIPooler", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.build_keypoint_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads.forward": [[715, 745], ["roi_heads.StandardROIHeads.label_and_sample_proposals", "roi_heads.StandardROIHeads._forward_box", "roi_heads.StandardROIHeads.update", "roi_heads.StandardROIHeads.update", "roi_heads.StandardROIHeads._forward_box", "roi_heads.StandardROIHeads.forward_with_given_boxes", "roi_heads.StandardROIHeads._forward_mask", "roi_heads.StandardROIHeads._forward_keypoint"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_keypoint"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads.forward_with_given_boxes": [[746, 772], ["roi_heads.StandardROIHeads._forward_mask", "roi_heads.StandardROIHeads._forward_keypoint", "instances[].has", "instances[].has"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_keypoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_box": [[773, 810], ["roi_heads.StandardROIHeads.box_pooler", "roi_heads.StandardROIHeads.box_head", "roi_heads.StandardROIHeads.box_predictor", "roi_heads.StandardROIHeads.box_predictor.losses", "roi_heads.StandardROIHeads.box_predictor.inference", "torch.no_grad", "roi_heads.StandardROIHeads.box_predictor.predict_boxes_for_gt_classes", "zip", "detectron2.structures.Boxes"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes_for_gt_classes"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_mask": [[811, 840], ["roi_heads.StandardROIHeads.mask_head", "roi_heads.select_foreground_proposals", "roi_heads.StandardROIHeads.mask_pooler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_foreground_proposals"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_keypoint": [[841, 871], ["roi_heads.StandardROIHeads.keypoint_head", "roi_heads.select_foreground_proposals", "roi_heads.select_proposals_with_visible_keypoints", "roi_heads.StandardROIHeads.keypoint_pooler", "dict"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_foreground_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_proposals_with_visible_keypoints"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_foreground_proposals": [[46, 76], ["isinstance", "isinstance", "proposals[].has", "fg_selection_mask.nonzero().squeeze", "fg_proposals.append", "fg_selection_masks.append", "fg_selection_mask.nonzero"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["if", "(", "\n", "self", ".", "training", "\n", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", "\n", ")", ":", "\n", "                ", "keypoint_features", "=", "x", "\n", "# During training, self.box() will return the unaltered proposals as \"detections\"", "\n", "# this makes the API consistent during training and testing", "\n", "", "x", ",", "detections", ",", "loss_keypoint", "=", "self", ".", "keypoint", "(", "keypoint_features", ",", "detections", ",", "targets", ")", "\n", "losses", ".", "update", "(", "loss_keypoint", ")", "\n", "", "return", "x", ",", "detections", ",", "losses", "\n", "\n", "\n", "", "", "def", "build_roi_heads", "(", "cfg", ",", "in_channels", ")", ":", "\n", "# individually create the heads, that will be combined together", "\n", "# afterwards", "\n", "    ", "roi_heads", "=", "[", "]", "\n", "if", "cfg", ".", "MODEL", ".", "RETINANET_ON", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "if", "not", "cfg", ".", "MODEL", ".", "RPN_ONLY", ":", "\n", "        ", "roi_heads", ".", "append", "(", "(", "\"box\"", ",", "build_roi_box_head", "(", "cfg", ",", "in_channels", ")", ")", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "roi_heads", ".", "append", "(", "(", "\"mask\"", ",", "build_roi_mask_head", "(", "cfg", ",", "in_channels", ")", ")", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "roi_heads", ".", "append", "(", "(", "\"keypoint\"", ",", "build_roi_keypoint_head", "(", "cfg", ",", "in_channels", ")", ")", ")", "\n", "\n", "# combine individual heads in a single module", "\n", "", "if", "roi_heads", ":", "\n", "        ", "roi_heads", "=", "CombinedROIHeads", "(", "cfg", ",", "roi_heads", ")", "\n", "\n", "", "return", "roi_heads", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_proposals_with_visible_keypoints": [[78, 121], ["detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "proposals_per_image.proposal_boxes.tensor.unsqueeze", "all_num_fg.append", "ret.append", "numpy.mean", "len", "ret.append", "detectron2.layers.nonzero_tuple", "selection_idxs.numel"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.BaseKeypointRCNNHead.__init__": [[141, 159], ["torch.nn.Module.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.BaseKeypointRCNNHead.from_config": [[160, 178], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.BaseKeypointRCNNHead.forward": [[179, 206], ["keypoint_head.BaseKeypointRCNNHead.layers", "len", "keypoint_head.keypoint_rcnn_inference", "keypoint_head.keypoint_rcnn_loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.keypoint_rcnn_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.keypoint_rcnn_loss"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.BaseKeypointRCNNHead.layers": [[207, 212], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.__init__": [[225, 260], ["super().__init__", "enumerate", "detectron2.layers.ConvTranspose2d", "keypoint_head.KRCNNConvDeconvUpsampleHead.named_parameters", "detectron2.layers.Conv2d", "keypoint_head.KRCNNConvDeconvUpsampleHead.add_module", "keypoint_head.KRCNNConvDeconvUpsampleHead.add_module", "torch.nn.ReLU", "torch.nn.init.constant_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.from_config": [[261, 267], ["super().from_config"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.KRCNNConvDeconvUpsampleHead.layers": [[268, 273], ["detectron2.layers.interpolate", "layer"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.build_keypoint_head": [[32, 38], ["ROI_KEYPOINT_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "if", "self", ".", "training", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "proposals", "=", "self", ".", "loss_evaluator", ".", "subsample", "(", "proposals", ",", "targets", ")", "\n", "\n", "", "", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.keypoint_rcnn_loss": [[40, 97], ["len", "pred_keypoint_logits.view.view", "torch.nn.functional.cross_entropy", "keypoints.to_heatmap", "heatmaps.append", "torch.nonzero().squeeze.append", "detectron2.layers.cat", "detectron2.layers.cat().to", "torch.nonzero().squeeze", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "torch.nonzero().squeeze.numel", "len", "heatmaps_per_image.view", "valid_per_image.view", "len", "torch.nonzero().squeeze.numel", "pred_keypoint_logits.view.sum", "detectron2.layers.cat", "torch.nonzero"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.to_heatmap", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "kp_logits", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_kp", "=", "self", ".", "loss_evaluator", "(", "proposals", ",", "kp_logits", ")", "\n", "\n", "return", "x", ",", "proposals", ",", "dict", "(", "loss_kp", "=", "loss_kp", ")", "\n", "\n", "\n", "", "", "def", "build_roi_keypoint_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "ROIKeypointHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.keypoint_rcnn_inference": [[99, 133], ["detectron2.layers.cat", "pred_keypoint_logits.detach.detach", "detectron2.structures.heatmaps_to_keypoints", "keypoint_results[].split", "pred_keypoint_logits.detach.split", "zip", "detectron2.layers.cat.detach", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.heatmaps_to_keypoints"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.FastRCNNConvFCHead.__init__": [[32, 80], ["torch.nn.Sequential.__init__", "enumerate", "enumerate", "detectron2.layers.Conv2d", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.conv_norm_relus.append", "torch.nn.Linear", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.fcs.append", "fvcore.c2_msra_fill", "fvcore.c2_xavier_fill", "len", "len", "box_head.FastRCNNConvFCHead.add_module", "int", "torch.nn.ReLU", "detectron2.layers.get_norm", "torch.nn.ReLU", "torch.nn.Flatten", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["\n", "\n", "if", "self", ".", "training", ":", "\n", "# Faster R-CNN subsamples during training the proposals with a fixed", "\n", "# positive / negative ratio", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "proposals", "=", "self", ".", "loss_evaluator", ".", "subsample", "(", "proposals", ",", "targets", ")", "\n", "\n", "# extract features that will be fed to the final classifier. The", "\n", "# feature_extractor generally corresponds to the pooler + heads", "\n", "", "", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n", "# final classifier that converts the features into predictions", "\n", "class_logits", ",", "box_regression", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "(", "class_logits", ",", "box_regression", ")", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_classifier", ",", "loss_box_reg", "=", "self", ".", "loss_evaluator", "(", "\n", "[", "class_logits", "]", ",", "[", "box_regression", "]", "\n", ")", "\n", "return", "(", "\n", "x", ",", "\n", "proposals", ",", "\n", "dict", "(", "loss_classifier", "=", "loss_classifier", ",", "loss_box_reg", "=", "loss_box_reg", ")", ",", "\n", ")", "\n", "\n", "\n", "", "", "def", "build_roi_box_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "\"\"\"\n    Constructs a new box head.\n    By default, uses ROIBoxHead, but if it turns out not to be enough, just register a new class\n    and make it a parameter in the config\n    \"\"\"", "\n", "return", "ROIBoxHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.FastRCNNConvFCHead.from_config": [[81, 92], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.FastRCNNConvFCHead.forward": [[94, 98], ["layer"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.FastRCNNConvFCHead.output_shape": [[99, 111], ["isinstance", "detectron2.layers.ShapeSpec", "detectron2.layers.ShapeSpec"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.build_box_head": [[113, 119], ["ROI_BOX_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn._ScaleGradient.forward": [[21, 25], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "scale", ")", ":", "\n", "        ", "ctx", ".", "scale", "=", "scale", "\n", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn._ScaleGradient.backward": [[26, 29], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "grad_output", "*", "ctx", ".", "scale", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads.__init__": [[37, 79], ["len", "torch.nn.ModuleList", "torch.nn.ModuleList", "roi_heads.StandardROIHeads.__init__", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "box_in_features", ":", "List", "[", "str", "]", ",", "\n", "box_pooler", ":", "ROIPooler", ",", "\n", "box_heads", ":", "List", "[", "nn", ".", "Module", "]", ",", "\n", "box_predictors", ":", "List", "[", "nn", ".", "Module", "]", ",", "\n", "proposal_matchers", ":", "List", "[", "Matcher", "]", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            box_pooler (ROIPooler): pooler that extracts region features from given boxes\n            box_heads (list[nn.Module]): box head for each cascade stage\n            box_predictors (list[nn.Module]): box predictor for each cascade stage\n            proposal_matchers (list[Matcher]): matcher with different IoU thresholds to\n                match boxes with ground truth for each stage. The first matcher matches\n                RPN proposals with ground truth, the other matchers use boxes predicted\n                by the previous stage as proposals and match them with ground truth.\n        \"\"\"", "\n", "assert", "\"proposal_matcher\"", "not", "in", "kwargs", ",", "(", "\n", "\"CascadeROIHeads takes 'proposal_matchers=' for each stage instead \"", "\n", "\"of one 'proposal_matcher='.\"", "\n", ")", "\n", "# The first matcher matches RPN proposals with ground truth, done in the base class", "\n", "kwargs", "[", "\"proposal_matcher\"", "]", "=", "proposal_matchers", "[", "0", "]", "\n", "num_stages", "=", "self", ".", "num_cascade_stages", "=", "len", "(", "box_heads", ")", "\n", "box_heads", "=", "nn", ".", "ModuleList", "(", "box_heads", ")", "\n", "box_predictors", "=", "nn", ".", "ModuleList", "(", "box_predictors", ")", "\n", "assert", "len", "(", "box_predictors", ")", "==", "num_stages", ",", "f\"{len(box_predictors)} != {num_stages}!\"", "\n", "assert", "len", "(", "proposal_matchers", ")", "==", "num_stages", ",", "f\"{len(proposal_matchers)} != {num_stages}!\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "box_in_features", "=", "box_in_features", ",", "\n", "box_pooler", "=", "box_pooler", ",", "\n", "box_head", "=", "box_heads", ",", "\n", "box_predictor", "=", "box_predictors", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "self", ".", "proposal_matchers", "=", "proposal_matchers", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads.from_config": [[80, 85], ["super().from_config", "super().from_config.pop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "ret", ".", "pop", "(", "\"proposal_matcher\"", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._init_box_head": [[86, 135], ["tuple", "poolers.ROIPooler", "detectron2.layers.ShapeSpec", "zip", "len", "len", "len", "box_head.build_box_head.build_box_head", "box_heads.append", "box_predictors.append", "proposal_matchers.append", "set", "fast_rcnn.FastRCNNOutputLayers", "matcher.Matcher", "box_regression.Box2BoxTransform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.box_head.build_box_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "cascade_bbox_reg_weights", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", ".", "BBOX_REG_WEIGHTS", "\n", "cascade_ious", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_CASCADE_HEAD", ".", "IOUS", "\n", "assert", "len", "(", "cascade_bbox_reg_weights", ")", "==", "len", "(", "cascade_ious", ")", "\n", "assert", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CLS_AGNOSTIC_BBOX_REG", ",", "\"CascadeROIHeads only support class-agnostic regression now!\"", "\n", "assert", "cascade_ious", "[", "0", "]", "==", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IOU_THRESHOLDS", "[", "0", "]", "\n", "# fmt: on", "\n", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "pooled_shape", "=", "ShapeSpec", "(", "\n", "channels", "=", "in_channels", ",", "width", "=", "pooler_resolution", ",", "height", "=", "pooler_resolution", "\n", ")", "\n", "\n", "box_heads", ",", "box_predictors", ",", "proposal_matchers", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "match_iou", ",", "bbox_reg_weights", "in", "zip", "(", "cascade_ious", ",", "cascade_bbox_reg_weights", ")", ":", "\n", "            ", "box_head", "=", "build_box_head", "(", "cfg", ",", "pooled_shape", ")", "\n", "box_heads", ".", "append", "(", "box_head", ")", "\n", "box_predictors", ".", "append", "(", "\n", "FastRCNNOutputLayers", "(", "\n", "cfg", ",", "\n", "box_head", ".", "output_shape", ",", "\n", "box2box_transform", "=", "Box2BoxTransform", "(", "weights", "=", "bbox_reg_weights", ")", ",", "\n", ")", "\n", ")", "\n", "proposal_matchers", ".", "append", "(", "Matcher", "(", "[", "match_iou", "]", ",", "[", "0", ",", "1", "]", ",", "allow_low_quality_matches", "=", "False", ")", ")", "\n", "", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_heads\"", ":", "box_heads", ",", "\n", "\"box_predictors\"", ":", "box_predictors", ",", "\n", "\"proposal_matchers\"", ":", "proposal_matchers", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads.forward": [[137, 152], ["cascade_rcnn.CascadeROIHeads.label_and_sample_proposals", "cascade_rcnn.CascadeROIHeads._forward_box", "cascade_rcnn.CascadeROIHeads.update", "cascade_rcnn.CascadeROIHeads.update", "cascade_rcnn.CascadeROIHeads._forward_box", "cascade_rcnn.CascadeROIHeads.forward_with_given_boxes", "cascade_rcnn.CascadeROIHeads._forward_mask", "cascade_rcnn.CascadeROIHeads._forward_keypoint"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.ROIHeads.label_and_sample_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.StandardROIHeads._forward_keypoint"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "del", "images", "\n", "if", "self", ".", "training", ":", "\n", "            ", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "proposals", ",", "targets", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "# Need targets to box head", "\n", "            ", "losses", "=", "self", ".", "_forward_box", "(", "features", ",", "proposals", ",", "targets", ")", "\n", "losses", ".", "update", "(", "self", ".", "_forward_mask", "(", "features", ",", "proposals", ")", ")", "\n", "losses", ".", "update", "(", "self", ".", "_forward_keypoint", "(", "features", ",", "proposals", ")", ")", "\n", "return", "proposals", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", "=", "self", ".", "_forward_box", "(", "features", ",", "proposals", ")", "\n", "pred_instances", "=", "self", ".", "forward_with_given_boxes", "(", "features", ",", "pred_instances", ")", "\n", "return", "pred_instances", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._forward_box": [[153, 207], ["range", "cascade_rcnn.CascadeROIHeads._run_stage", "cascade_rcnn.CascadeROIHeads.box_predictor[].predict_boxes", "head_outputs.append", "detectron2.utils.events.get_event_storage", "enumerate", "predictor.predict_boxes", "fast_rcnn.fast_rcnn_inference", "cascade_rcnn.CascadeROIHeads._create_proposals_from_boxes", "losses.update", "h[].predict_probs", "cascade_rcnn.CascadeROIHeads._match_and_label_boxes", "detectron2.utils.events.get_event_storage.name_scope", "predictor.losses", "sum", "zip", "list", "predictor.losses.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._run_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.fast_rcnn_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._create_proposals_from_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.fast_rcnn.FastRCNNOutputLayers.predict_probs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._match_and_label_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.name_scope", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "", "def", "_forward_box", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features, targets: the same as in\n                Same as in :meth:`ROIHeads.forward`.\n            proposals (list[Instances]): the per-image object proposals with\n                their matching ground truth.\n                Each has fields \"proposal_boxes\", and \"objectness_logits\",\n                \"gt_classes\", \"gt_boxes\".\n        \"\"\"", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "box_in_features", "]", "\n", "head_outputs", "=", "[", "]", "# (predictor, predictions, proposals)", "\n", "prev_pred_boxes", "=", "None", "\n", "image_sizes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "num_cascade_stages", ")", ":", "\n", "            ", "if", "k", ">", "0", ":", "\n", "# The output boxes of the previous stage are used to create the input", "\n", "# proposals of the next stage.", "\n", "                ", "proposals", "=", "self", ".", "_create_proposals_from_boxes", "(", "prev_pred_boxes", ",", "image_sizes", ")", "\n", "if", "self", ".", "training", ":", "\n", "                    ", "proposals", "=", "self", ".", "_match_and_label_boxes", "(", "proposals", ",", "k", ",", "targets", ")", "\n", "", "", "predictions", "=", "self", ".", "_run_stage", "(", "features", ",", "proposals", ",", "k", ")", "\n", "prev_pred_boxes", "=", "self", ".", "box_predictor", "[", "k", "]", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "head_outputs", ".", "append", "(", "(", "self", ".", "box_predictor", "[", "k", "]", ",", "predictions", ",", "proposals", ")", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "losses", "=", "{", "}", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "for", "stage", ",", "(", "predictor", ",", "predictions", ",", "proposals", ")", "in", "enumerate", "(", "head_outputs", ")", ":", "\n", "                ", "with", "storage", ".", "name_scope", "(", "\"stage{}\"", ".", "format", "(", "stage", ")", ")", ":", "\n", "                    ", "stage_losses", "=", "predictor", ".", "losses", "(", "predictions", ",", "proposals", ")", "\n", "", "losses", ".", "update", "(", "{", "k", "+", "\"_stage{}\"", ".", "format", "(", "stage", ")", ":", "v", "for", "k", ",", "v", "in", "stage_losses", ".", "items", "(", ")", "}", ")", "\n", "", "return", "losses", "\n", "", "else", ":", "\n", "# Each is a list[Tensor] of length #image. Each tensor is Ri x (K+1)", "\n", "            ", "scores_per_stage", "=", "[", "h", "[", "0", "]", ".", "predict_probs", "(", "h", "[", "1", "]", ",", "h", "[", "2", "]", ")", "for", "h", "in", "head_outputs", "]", "\n", "\n", "# Average the scores across heads", "\n", "scores", "=", "[", "\n", "sum", "(", "list", "(", "scores_per_image", ")", ")", "*", "(", "1.0", "/", "self", ".", "num_cascade_stages", ")", "\n", "for", "scores_per_image", "in", "zip", "(", "*", "scores_per_stage", ")", "\n", "]", "\n", "# Use the boxes of the last head", "\n", "predictor", ",", "predictions", ",", "proposals", "=", "head_outputs", "[", "-", "1", "]", "\n", "boxes", "=", "predictor", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "pred_instances", ",", "_", "=", "fast_rcnn_inference", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_sizes", ",", "\n", "predictor", ".", "test_score_thresh", ",", "\n", "predictor", ".", "test_nms_thresh", ",", "\n", "predictor", ".", "test_topk_per_image", ",", "\n", ")", "\n", "return", "pred_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._match_and_label_boxes": [[208, 257], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.structures.pairwise_iou", "num_fg_samples.append", "num_bg_samples.append", "len", "detectron2.structures.Boxes", "sum", "len", "sum", "len", "torch.zeros_like", "targets_per_image.gt_boxes.tensor.new_zeros", "proposal_labels.numel", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_iou"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_match_and_label_boxes", "(", "self", ",", "proposals", ",", "stage", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Match proposals with groundtruth using the matcher at the given stage.\n        Label the proposals as foreground or background based on the match.\n\n        Args:\n            proposals (list[Instances]): One Instances for each image, with\n                the field \"proposal_boxes\".\n            stage (int): the current stage\n            targets (list[Instances]): the ground truth instances\n\n        Returns:\n            list[Instances]: the same proposals, but with fields \"gt_classes\" and \"gt_boxes\"\n        \"\"\"", "\n", "num_fg_samples", ",", "num_bg_samples", "=", "[", "]", ",", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "match_quality_matrix", "=", "pairwise_iou", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "# proposal_labels are 0 or 1", "\n", "matched_idxs", ",", "proposal_labels", "=", "self", ".", "proposal_matchers", "[", "stage", "]", "(", "match_quality_matrix", ")", "\n", "if", "len", "(", "targets_per_image", ")", ">", "0", ":", "\n", "                ", "gt_classes", "=", "targets_per_image", ".", "gt_classes", "[", "matched_idxs", "]", "\n", "# Label unmatched proposals (0 label from matcher) as background (label=num_classes)", "\n", "gt_classes", "[", "proposal_labels", "==", "0", "]", "=", "self", ".", "num_classes", "\n", "gt_boxes", "=", "targets_per_image", ".", "gt_boxes", "[", "matched_idxs", "]", "\n", "", "else", ":", "\n", "                ", "gt_classes", "=", "torch", ".", "zeros_like", "(", "matched_idxs", ")", "+", "self", ".", "num_classes", "\n", "gt_boxes", "=", "Boxes", "(", "\n", "targets_per_image", ".", "gt_boxes", ".", "tensor", ".", "new_zeros", "(", "(", "len", "(", "proposals_per_image", ")", ",", "4", ")", ")", "\n", ")", "\n", "", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "proposals_per_image", ".", "gt_boxes", "=", "gt_boxes", "\n", "\n", "num_fg_samples", ".", "append", "(", "(", "proposal_labels", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_bg_samples", ".", "append", "(", "proposal_labels", ".", "numel", "(", ")", "-", "num_fg_samples", "[", "-", "1", "]", ")", "\n", "\n", "# Log the number of fg/bg samples in each stage", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"stage{}/roi_head/num_fg_samples\"", ".", "format", "(", "stage", ")", ",", "\n", "sum", "(", "num_fg_samples", ")", "/", "len", "(", "num_fg_samples", ")", ",", "\n", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"stage{}/roi_head/num_bg_samples\"", ".", "format", "(", "stage", ")", ",", "\n", "sum", "(", "num_bg_samples", ")", "/", "len", "(", "num_bg_samples", ")", ",", "\n", ")", "\n", "return", "proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._run_stage": [[258, 276], ["cascade_rcnn.CascadeROIHeads.box_pooler", "_ScaleGradient.apply"], "methods", ["None"], ["", "def", "_run_stage", "(", "self", ",", "features", ",", "proposals", ",", "stage", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            features (list[Tensor]): #lvl input features to ROIHeads\n            proposals (list[Instances]): #image Instances, with the field \"proposal_boxes\"\n            stage (int): the current stage\n\n        Returns:\n            Same output as `FastRCNNOutputLayers.forward()`.\n        \"\"\"", "\n", "box_features", "=", "self", ".", "box_pooler", "(", "features", ",", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", ")", "\n", "# The original implementation averages the losses among heads,", "\n", "# but scale up the parameter gradients of the heads.", "\n", "# This is equivalent to adding the losses among heads,", "\n", "# but scale down the gradients on features.", "\n", "box_features", "=", "_ScaleGradient", ".", "apply", "(", "box_features", ",", "1.0", "/", "self", ".", "num_cascade_stages", ")", "\n", "box_features", "=", "self", ".", "box_head", "[", "stage", "]", "(", "box_features", ")", "\n", "return", "self", ".", "box_predictor", "[", "stage", "]", "(", "box_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.cascade_rcnn.CascadeROIHeads._create_proposals_from_boxes": [[277, 299], ["zip", "detectron2.structures.Boxes", "boxes_per_image.clip", "detectron2.structures.Instances", "proposals.append", "b.detach", "boxes_per_image.nonempty"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty"], ["", "def", "_create_proposals_from_boxes", "(", "self", ",", "boxes", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (list[Tensor]): per-image predicted boxes, each of shape Ri x 4\n            image_sizes (list[tuple]): list of image shapes in (h, w)\n\n        Returns:\n            list[Instances]: per-image proposals with the given boxes.\n        \"\"\"", "\n", "# Just like RPN, the proposals should not have gradients", "\n", "boxes", "=", "[", "Boxes", "(", "b", ".", "detach", "(", ")", ")", "for", "b", "in", "boxes", "]", "\n", "proposals", "=", "[", "]", "\n", "for", "boxes_per_image", ",", "image_size", "in", "zip", "(", "boxes", ",", "image_sizes", ")", ":", "\n", "            ", "boxes_per_image", ".", "clip", "(", "image_size", ")", "\n", "if", "self", ".", "training", ":", "\n", "# do not filter empty boxes at inference time,", "\n", "# because the scores from each stage need to be aligned and added later", "\n", "                ", "boxes_per_image", "=", "boxes_per_image", "[", "boxes_per_image", ".", "nonempty", "(", ")", "]", "\n", "", "prop", "=", "Instances", "(", "image_size", ")", "\n", "prop", ".", "proposal_boxes", "=", "boxes_per_image", "\n", "proposals", ".", "append", "(", "prop", ")", "\n", "", "return", "proposals", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.v1convx.DensePoseV1ConvXHead.__init__": [[20, 43], ["torch.nn.Module.__init__", "range", "utils.initialize_module_params", "detectron2.layers.Conv2d", "v1convx.DensePoseV1ConvXHead._get_layer_name", "v1convx.DensePoseV1ConvXHead.add_module"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.initialize_module_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead._get_layer_name"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize DensePose fully convolutional head\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): number of input channels\n        \"\"\"", "\n", "super", "(", "DensePoseV1ConvXHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# fmt: off", "\n", "hidden_dim", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CONV_HEAD_DIM", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CONV_HEAD_KERNEL", "\n", "self", ".", "n_stacked_convs", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_STACKED_CONVS", "\n", "# fmt: on", "\n", "pad_size", "=", "kernel_size", "//", "2", "\n", "n_channels", "=", "input_channels", "\n", "for", "i", "in", "range", "(", "self", ".", "n_stacked_convs", ")", ":", "\n", "            ", "layer", "=", "Conv2d", "(", "n_channels", ",", "hidden_dim", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "pad_size", ")", "\n", "layer_name", "=", "self", ".", "_get_layer_name", "(", "i", ")", "\n", "self", ".", "add_module", "(", "layer_name", ",", "layer", ")", "# pyre-ignore[16]", "\n", "n_channels", "=", "hidden_dim", "\n", "", "self", ".", "n_out_channels", "=", "n_channels", "\n", "initialize_module_params", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.v1convx.DensePoseV1ConvXHead.forward": [[44, 61], ["range", "v1convx.DensePoseV1ConvXHead._get_layer_name", "torch.nn.functional.relu", "getattr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead._get_layer_name"], ["", "def", "forward", "(", "self", ",", "features", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Apply DensePose fully convolutional head to the input features\n\n        Args:\n            features (tensor): input features\n        Result:\n            A tensor of DensePose head outputs\n        \"\"\"", "\n", "x", "=", "features", "\n", "output", "=", "x", "\n", "for", "i", "in", "range", "(", "self", ".", "n_stacked_convs", ")", ":", "\n", "            ", "layer_name", "=", "self", ".", "_get_layer_name", "(", "i", ")", "\n", "x", "=", "getattr", "(", "self", ",", "layer_name", ")", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "output", "=", "x", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.v1convx.DensePoseV1ConvXHead._get_layer_name": [[62, 65], ["None"], "methods", ["None"], ["", "def", "_get_layer_name", "(", "self", ",", "i", ":", "int", ")", ":", "\n", "        ", "layer_name", "=", "\"body_conv_fcn{}\"", ".", "format", "(", "i", "+", "1", ")", "\n", "return", "layer_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead.__init__": [[22, 58], ["torch.nn.Module.__init__", "deeplab.ASPP", "deeplab.DensePoseDeepLabHead.add_module", "range", "deeplab.NONLocalBlock2D", "deeplab.DensePoseDeepLabHead.add_module", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "deeplab.DensePoseDeepLabHead._get_layer_name", "deeplab.DensePoseDeepLabHead.add_module", "torch.nn.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead._get_layer_name"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "super", "(", "DensePoseDeepLabHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# fmt: off", "\n", "hidden_dim", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CONV_HEAD_DIM", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CONV_HEAD_KERNEL", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DEEPLAB", ".", "NORM", "\n", "self", ".", "n_stacked_convs", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_STACKED_CONVS", "\n", "self", ".", "use_nonlocal", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DEEPLAB", ".", "NONLOCAL_ON", "\n", "# fmt: on", "\n", "pad_size", "=", "kernel_size", "//", "2", "\n", "n_channels", "=", "input_channels", "\n", "\n", "self", ".", "ASPP", "=", "ASPP", "(", "input_channels", ",", "[", "6", ",", "12", ",", "56", "]", ",", "n_channels", ")", "# 6, 12, 56", "\n", "self", ".", "add_module", "(", "\"ASPP\"", ",", "self", ".", "ASPP", ")", "# pyre-ignore[16]", "\n", "\n", "if", "self", ".", "use_nonlocal", ":", "\n", "            ", "self", ".", "NLBlock", "=", "NONLocalBlock2D", "(", "input_channels", ",", "bn_layer", "=", "True", ")", "\n", "self", ".", "add_module", "(", "\"NLBlock\"", ",", "self", ".", "NLBlock", ")", "\n", "# weight_init.c2_msra_fill(self.ASPP)", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "n_stacked_convs", ")", ":", "\n", "            ", "norm_module", "=", "nn", ".", "GroupNorm", "(", "32", ",", "hidden_dim", ")", "if", "norm", "==", "\"GN\"", "else", "None", "\n", "layer", "=", "Conv2d", "(", "\n", "n_channels", ",", "\n", "hidden_dim", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "pad_size", ",", "\n", "bias", "=", "not", "norm", ",", "\n", "norm", "=", "norm_module", ",", "\n", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "n_channels", "=", "hidden_dim", "\n", "layer_name", "=", "self", ".", "_get_layer_name", "(", "i", ")", "\n", "self", ".", "add_module", "(", "layer_name", ",", "layer", ")", "\n", "", "self", ".", "n_out_channels", "=", "hidden_dim", "\n", "# initialize_module_params(self)", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead.forward": [[60, 72], ["deeplab.DensePoseDeepLabHead.ASPP", "range", "deeplab.DensePoseDeepLabHead.NLBlock", "deeplab.DensePoseDeepLabHead._get_layer_name", "torch.nn.functional.relu", "getattr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead._get_layer_name"], ["", "def", "forward", "(", "self", ",", "features", ")", ":", "\n", "        ", "x0", "=", "features", "\n", "x", "=", "self", ".", "ASPP", "(", "x0", ")", "\n", "if", "self", ".", "use_nonlocal", ":", "\n", "            ", "x", "=", "self", ".", "NLBlock", "(", "x", ")", "\n", "", "output", "=", "x", "\n", "for", "i", "in", "range", "(", "self", ".", "n_stacked_convs", ")", ":", "\n", "            ", "layer_name", "=", "self", ".", "_get_layer_name", "(", "i", ")", "\n", "x", "=", "getattr", "(", "self", ",", "layer_name", ")", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "output", "=", "x", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.DensePoseDeepLabHead._get_layer_name": [[73, 76], ["None"], "methods", ["None"], ["", "def", "_get_layer_name", "(", "self", ",", "i", ":", "int", ")", ":", "\n", "        ", "layer_name", "=", "\"body_conv_fcn{}\"", ".", "format", "(", "i", "+", "1", ")", "\n", "return", "layer_name", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.ASPPConv.__init__": [[82, 91], ["torch.nn.Sequential.__init__", "torch.nn.Conv2d", "torch.nn.GroupNorm", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "dilation", ")", ":", "\n", "        ", "modules", "=", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "3", ",", "padding", "=", "dilation", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", "\n", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "32", ",", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "]", "\n", "super", "(", "ASPPConv", ",", "self", ")", ".", "__init__", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.ASPPPooling.__init__": [[94, 100], ["torch.nn.Sequential.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Conv2d", "torch.nn.GroupNorm", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", "ASPPPooling", ",", "self", ")", ".", "__init__", "(", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "32", ",", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.ASPPPooling.forward": [[102, 106], ["super().forward", "torch.nn.functional.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "x", "=", "super", "(", "ASPPPooling", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "return", "F", ".", "interpolate", "(", "x", ",", "size", "=", "size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.ASPP.__init__": [[109, 132], ["torch.nn.Module.__init__", "modules.append", "tuple", "modules.append", "modules.append", "modules.append", "modules.append", "torch.nn.ModuleList", "torch.nn.Sequential", "torch.nn.Sequential", "deeplab.ASPPConv", "deeplab.ASPPConv", "deeplab.ASPPConv", "deeplab.ASPPPooling", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.GroupNorm", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "atrous_rates", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", "ASPP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "modules", "=", "[", "]", "\n", "modules", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "32", ",", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "rate1", ",", "rate2", ",", "rate3", "=", "tuple", "(", "atrous_rates", ")", "\n", "modules", ".", "append", "(", "ASPPConv", "(", "in_channels", ",", "out_channels", ",", "rate1", ")", ")", "\n", "modules", ".", "append", "(", "ASPPConv", "(", "in_channels", ",", "out_channels", ",", "rate2", ")", ")", "\n", "modules", ".", "append", "(", "ASPPConv", "(", "in_channels", ",", "out_channels", ",", "rate3", ")", ")", "\n", "modules", ".", "append", "(", "ASPPPooling", "(", "in_channels", ",", "out_channels", ")", ")", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "modules", ")", "\n", "\n", "self", ".", "project", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "5", "*", "out_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "# nn.BatchNorm2d(out_channels),", "\n", "nn", ".", "ReLU", "(", ")", "\n", "# nn.Dropout(0.5)", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.ASPP.forward": [[135, 141], ["torch.cat", "deeplab.ASPP.project", "torch.cat.append", "conv"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "res", ".", "append", "(", "conv", "(", "x", ")", ")", "\n", "", "res", "=", "torch", ".", "cat", "(", "res", ",", "dim", "=", "1", ")", "\n", "return", "self", ".", "project", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab._NonLocalBlockND.__init__": [[147, 228], ["torch.nn.Module.__init__", "conv_nd", "conv_nd", "conv_nd", "torch.nn.MaxPool3d", "torch.nn.Sequential", "torch.nn.init.constant_", "torch.nn.init.constant_", "conv_nd", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.MaxPool2d", "torch.nn.MaxPool1d", "conv_nd", "bn"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "inter_channels", "=", "None", ",", "dimension", "=", "3", ",", "sub_sample", "=", "True", ",", "bn_layer", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", "_NonLocalBlockND", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "dimension", "in", "[", "1", ",", "2", ",", "3", "]", "\n", "\n", "self", ".", "dimension", "=", "dimension", "\n", "self", ".", "sub_sample", "=", "sub_sample", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "inter_channels", "=", "inter_channels", "\n", "\n", "if", "self", ".", "inter_channels", "is", "None", ":", "\n", "            ", "self", ".", "inter_channels", "=", "in_channels", "//", "2", "\n", "if", "self", ".", "inter_channels", "==", "0", ":", "\n", "                ", "self", ".", "inter_channels", "=", "1", "\n", "\n", "", "", "if", "dimension", "==", "3", ":", "\n", "            ", "conv_nd", "=", "nn", ".", "Conv3d", "\n", "max_pool_layer", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "1", ",", "2", ",", "2", ")", ")", "\n", "bn", "=", "nn", ".", "GroupNorm", "# (32, hidden_dim) #nn.BatchNorm3d", "\n", "", "elif", "dimension", "==", "2", ":", "\n", "            ", "conv_nd", "=", "nn", ".", "Conv2d", "\n", "max_pool_layer", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "(", "2", ",", "2", ")", ")", "\n", "bn", "=", "nn", ".", "GroupNorm", "# (32, hidden_dim)nn.BatchNorm2d", "\n", "", "else", ":", "\n", "            ", "conv_nd", "=", "nn", ".", "Conv1d", "\n", "max_pool_layer", "=", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "2", ")", "\n", "bn", "=", "nn", ".", "GroupNorm", "# (32, hidden_dim)nn.BatchNorm1d", "\n", "\n", "", "self", ".", "g", "=", "conv_nd", "(", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "out_channels", "=", "self", ".", "inter_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", ")", "\n", "\n", "if", "bn_layer", ":", "\n", "            ", "self", ".", "W", "=", "nn", ".", "Sequential", "(", "\n", "conv_nd", "(", "\n", "in_channels", "=", "self", ".", "inter_channels", ",", "\n", "out_channels", "=", "self", ".", "in_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", ")", ",", "\n", "bn", "(", "32", ",", "self", ".", "in_channels", ")", ",", "\n", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "W", "[", "1", "]", ".", "weight", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "W", "[", "1", "]", ".", "bias", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "W", "=", "conv_nd", "(", "\n", "in_channels", "=", "self", ".", "inter_channels", ",", "\n", "out_channels", "=", "self", ".", "in_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "W", ".", "weight", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "W", ".", "bias", ",", "0", ")", "\n", "\n", "", "self", ".", "theta", "=", "conv_nd", "(", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "out_channels", "=", "self", ".", "inter_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", ")", "\n", "self", ".", "phi", "=", "conv_nd", "(", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "out_channels", "=", "self", ".", "inter_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", ")", "\n", "\n", "if", "sub_sample", ":", "\n", "            ", "self", ".", "g", "=", "nn", ".", "Sequential", "(", "self", ".", "g", ",", "max_pool_layer", ")", "\n", "self", ".", "phi", "=", "nn", ".", "Sequential", "(", "self", ".", "phi", ",", "max_pool_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab._NonLocalBlockND.forward": [[229, 253], ["x.size", "deeplab._NonLocalBlockND.g().view", "g_x.permute.permute.permute", "deeplab._NonLocalBlockND.theta().view", "theta_x.permute.permute.permute", "deeplab._NonLocalBlockND.phi().view", "torch.matmul", "torch.nn.functional.softmax", "torch.matmul", "y.view.view.permute().contiguous", "y.view.view.view", "deeplab._NonLocalBlockND.W", "deeplab._NonLocalBlockND.g", "deeplab._NonLocalBlockND.theta", "deeplab._NonLocalBlockND.phi", "y.view.view.permute", "x.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        :param x: (b, c, t, h, w)\n        :return:\n        \"\"\"", "\n", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "g_x", "=", "self", ".", "g", "(", "x", ")", ".", "view", "(", "batch_size", ",", "self", ".", "inter_channels", ",", "-", "1", ")", "\n", "g_x", "=", "g_x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "theta_x", "=", "self", ".", "theta", "(", "x", ")", ".", "view", "(", "batch_size", ",", "self", ".", "inter_channels", ",", "-", "1", ")", "\n", "theta_x", "=", "theta_x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "phi_x", "=", "self", ".", "phi", "(", "x", ")", ".", "view", "(", "batch_size", ",", "self", ".", "inter_channels", ",", "-", "1", ")", "\n", "f", "=", "torch", ".", "matmul", "(", "theta_x", ",", "phi_x", ")", "\n", "f_div_C", "=", "F", ".", "softmax", "(", "f", ",", "dim", "=", "-", "1", ")", "\n", "\n", "y", "=", "torch", ".", "matmul", "(", "f_div_C", ",", "g_x", ")", "\n", "y", "=", "y", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "y", "=", "y", ".", "view", "(", "batch_size", ",", "self", ".", "inter_channels", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "W_y", "=", "self", ".", "W", "(", "y", ")", "\n", "z", "=", "W_y", "+", "x", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.deeplab.NONLocalBlock2D.__init__": [[256, 263], ["deeplab._NonLocalBlockND.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "inter_channels", "=", "None", ",", "sub_sample", "=", "True", ",", "bn_layer", "=", "True", ")", ":", "\n", "        ", "super", "(", "NONLocalBlock2D", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "\n", "inter_channels", "=", "inter_channels", ",", "\n", "dimension", "=", "2", ",", "\n", "sub_sample", "=", "sub_sample", ",", "\n", "bn_layer", "=", "bn_layer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.Decoder.__init__": [[33, 73], ["torch.Module.__init__", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "max", "range", "roi_head.Decoder.scale_heads.append", "roi_head.Decoder.add_module", "input_shape.items", "input_shape.items", "int", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "head_ops.append", "torch.Sequential", "torch.Sequential", "head_ops.append", "numpy.log2", "numpy.log2", "detectron2.layers.get_norm", "torch.Upsample", "torch.Upsample"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ",", "in_features", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# fmt: off", "\n", "self", ".", "in_features", "=", "in_features", "\n", "feature_strides", "=", "{", "k", ":", "v", ".", "stride", "for", "k", ",", "v", "in", "input_shape", ".", "items", "(", ")", "}", "\n", "feature_channels", "=", "{", "k", ":", "v", ".", "channels", "for", "k", ",", "v", "in", "input_shape", ".", "items", "(", ")", "}", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECODER_NUM_CLASSES", "\n", "conv_dims", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECODER_CONV_DIMS", "\n", "self", ".", "common_stride", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECODER_COMMON_STRIDE", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECODER_NORM", "\n", "# fmt: on", "\n", "\n", "self", ".", "scale_heads", "=", "[", "]", "\n", "for", "in_feature", "in", "self", ".", "in_features", ":", "\n", "            ", "head_ops", "=", "[", "]", "\n", "head_length", "=", "max", "(", "\n", "1", ",", "int", "(", "np", ".", "log2", "(", "feature_strides", "[", "in_feature", "]", ")", "-", "np", ".", "log2", "(", "self", ".", "common_stride", ")", ")", "\n", ")", "\n", "for", "k", "in", "range", "(", "head_length", ")", ":", "\n", "                ", "conv", "=", "Conv2d", "(", "\n", "feature_channels", "[", "in_feature", "]", "if", "k", "==", "0", "else", "conv_dims", ",", "\n", "conv_dims", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "norm", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "conv_dims", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "conv", ")", "\n", "head_ops", ".", "append", "(", "conv", ")", "\n", "if", "feature_strides", "[", "in_feature", "]", "!=", "self", ".", "common_stride", ":", "\n", "                    ", "head_ops", ".", "append", "(", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", ")", "\n", "", "", "self", ".", "scale_heads", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "head_ops", ")", ")", "\n", "self", ".", "add_module", "(", "in_feature", ",", "self", ".", "scale_heads", "[", "-", "1", "]", ")", "# pyre-ignore[16]", "\n", "", "self", ".", "predictor", "=", "Conv2d", "(", "conv_dims", ",", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "predictor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.Decoder.forward": [[74, 82], ["enumerate", "roi_head.Decoder.predictor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "in_features", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "x", "=", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "+", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "i", "]", ")", "\n", "", "", "x", "=", "self", ".", "predictor", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.__init__": [[90, 93], ["detectron2.modeling.StandardROIHeads.__init__", "roi_head.DensePoseROIHeads._init_densepose_head"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads._init_densepose_head"], ["def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "input_shape", ")", "\n", "self", ".", "_init_densepose_head", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads._init_densepose_head": [[94, 126], ["build_densepose_data_filter", "detectron2.modeling.poolers.ROIPooler", "build_densepose_head", "build_densepose_predictor", "build_densepose_losses", "build_densepose_embedder", "tuple", "roi_head.Decoder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_data_filter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_predictor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_embedder"], ["", "def", "_init_densepose_head", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "self", ".", "densepose_on", "=", "cfg", ".", "MODEL", ".", "DENSEPOSE_ON", "\n", "if", "not", "self", ".", "densepose_on", ":", "\n", "            ", "return", "\n", "", "self", ".", "densepose_data_filter", "=", "build_densepose_data_filter", "(", "cfg", ")", "\n", "dp_pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "POOLER_RESOLUTION", "\n", "dp_pooler_sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "dp_pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "POOLER_TYPE", "\n", "self", ".", "use_decoder", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECODER_ON", "\n", "# fmt: on", "\n", "if", "self", ".", "use_decoder", ":", "\n", "            ", "dp_pooler_scales", "=", "(", "1.0", "/", "input_shape", "[", "self", ".", "in_features", "[", "0", "]", "]", ".", "stride", ",", ")", "\n", "", "else", ":", "\n", "            ", "dp_pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "self", ".", "in_features", ")", "\n", "", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "self", ".", "in_features", "]", "[", "0", "]", "\n", "\n", "if", "self", ".", "use_decoder", ":", "\n", "            ", "self", ".", "decoder", "=", "Decoder", "(", "cfg", ",", "input_shape", ",", "self", ".", "in_features", ")", "\n", "\n", "", "self", ".", "densepose_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "dp_pooler_resolution", ",", "\n", "scales", "=", "dp_pooler_scales", ",", "\n", "sampling_ratio", "=", "dp_pooler_sampling_ratio", ",", "\n", "pooler_type", "=", "dp_pooler_type", ",", "\n", ")", "\n", "self", ".", "densepose_head", "=", "build_densepose_head", "(", "cfg", ",", "in_channels", ")", "\n", "self", ".", "densepose_predictor", "=", "build_densepose_predictor", "(", "\n", "cfg", ",", "self", ".", "densepose_head", ".", "n_out_channels", "\n", ")", "\n", "self", ".", "densepose_losses", "=", "build_densepose_losses", "(", "cfg", ")", "\n", "self", ".", "embedder", "=", "build_densepose_embedder", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads._forward_densepose": [[127, 180], ["detectron2.modeling.roi_heads.select_foreground_proposals", "roi_head.DensePoseROIHeads.densepose_data_filter", "roi_head.DensePoseROIHeads.densepose_pooler", "densepose_inference", "len", "roi_head.DensePoseROIHeads.densepose_pooler", "roi_head.DensePoseROIHeads.densepose_head", "roi_head.DensePoseROIHeads.densepose_predictor", "roi_head.DensePoseROIHeads.densepose_losses", "len", "roi_head.DensePoseROIHeads.densepose_head", "roi_head.DensePoseROIHeads.densepose_predictor", "roi_head.DensePoseROIHeads.decoder", "roi_head.DensePoseROIHeads.decoder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.select_foreground_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.inference.densepose_inference"], ["", "def", "_forward_densepose", "(", "self", ",", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Forward logic of the densepose prediction branch.\n\n        Args:\n            features (dict[str, Tensor]): input data as a mapping from feature\n                map name to tensor. Axis 0 represents the number of images `N` in\n                the input data; axes 1-3 are channels, height, and width, which may\n                vary between feature maps (e.g., if a feature pyramid is used).\n            instances (list[Instances]): length `N` list of `Instances`. The i-th\n                `Instances` contains instances for the i-th input image,\n                In training, they can be the proposals.\n                In inference, they can be the predicted boxes.\n\n        Returns:\n            In training, a dict of losses.\n            In inference, update `instances` with new fields \"densepose\" and return it.\n        \"\"\"", "\n", "if", "not", "self", ".", "densepose_on", ":", "\n", "            ", "return", "{", "}", "if", "self", ".", "training", "else", "instances", "\n", "\n", "", "features_list", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "if", "self", ".", "training", ":", "\n", "            ", "proposals", ",", "_", "=", "select_foreground_proposals", "(", "instances", ",", "self", ".", "num_classes", ")", "\n", "features_list", ",", "proposals", "=", "self", ".", "densepose_data_filter", "(", "features_list", ",", "proposals", ")", "\n", "if", "len", "(", "proposals", ")", ">", "0", ":", "\n", "                ", "proposal_boxes", "=", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", "\n", "\n", "if", "self", ".", "use_decoder", ":", "\n", "                    ", "features_list", "=", "[", "self", ".", "decoder", "(", "features_list", ")", "]", "# pyre-ignore[16]", "\n", "\n", "", "features_dp", "=", "self", ".", "densepose_pooler", "(", "features_list", ",", "proposal_boxes", ")", "\n", "densepose_head_outputs", "=", "self", ".", "densepose_head", "(", "features_dp", ")", "\n", "densepose_predictor_outputs", "=", "self", ".", "densepose_predictor", "(", "densepose_head_outputs", ")", "\n", "densepose_loss_dict", "=", "self", ".", "densepose_losses", "(", "\n", "proposals", ",", "densepose_predictor_outputs", ",", "embedder", "=", "self", ".", "embedder", "\n", ")", "\n", "return", "densepose_loss_dict", "\n", "", "", "else", ":", "\n", "            ", "pred_boxes", "=", "[", "x", ".", "pred_boxes", "for", "x", "in", "instances", "]", "\n", "\n", "if", "self", ".", "use_decoder", ":", "\n", "                ", "features_list", "=", "[", "self", ".", "decoder", "(", "features_list", ")", "]", "\n", "\n", "", "features_dp", "=", "self", ".", "densepose_pooler", "(", "features_list", ",", "pred_boxes", ")", "\n", "if", "len", "(", "features_dp", ")", ">", "0", ":", "\n", "                ", "densepose_head_outputs", "=", "self", ".", "densepose_head", "(", "features_dp", ")", "\n", "densepose_predictor_outputs", "=", "self", ".", "densepose_predictor", "(", "densepose_head_outputs", ")", "\n", "", "else", ":", "\n", "                ", "densepose_predictor_outputs", "=", "None", "\n", "\n", "", "densepose_inference", "(", "densepose_predictor_outputs", ",", "instances", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward": [[181, 194], ["super().forward", "losses.update", "roi_head.DensePoseROIHeads._forward_densepose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads._forward_densepose"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "targets", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "instances", ",", "losses", "=", "super", "(", ")", ".", "forward", "(", "images", ",", "features", ",", "proposals", ",", "targets", ")", "\n", "del", "targets", ",", "images", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "losses", ".", "update", "(", "self", ".", "_forward_densepose", "(", "features", ",", "instances", ")", ")", "\n", "", "return", "instances", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward_with_given_boxes": [[195, 219], ["super().forward_with_given_boxes", "roi_head.DensePoseROIHeads._forward_densepose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads._forward_densepose"], ["", "def", "forward_with_given_boxes", "(", "\n", "self", ",", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "instances", ":", "List", "[", "Instances", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Use the given boxes in `instances` to produce other (non-box) per-ROI outputs.\n\n        This is useful for downstream tasks where a box is known, but need to obtain\n        other attributes (outputs of other heads).\n        Test-time augmentation also uses this.\n\n        Args:\n            features: same as in `forward()`\n            instances (list[Instances]): instances to predict other outputs. Expect the keys\n                \"pred_boxes\" and \"pred_classes\" to exist.\n\n        Returns:\n            instances (list[Instances]):\n                the same `Instances` objects, with extra\n                fields such as `pred_masks` or `pred_keypoints`.\n        \"\"\"", "\n", "\n", "instances", "=", "super", "(", ")", ".", "forward_with_given_boxes", "(", "features", ",", "instances", ")", "\n", "instances", "=", "self", ".", "_forward_densepose", "(", "features", ",", "instances", ")", "\n", "return", "instances", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.mask_head.ROIMaskHead.__init__": [[37, 45], ["super().__init__", "cfg.clone", "roi_mask_feature_extractors.make_roi_mask_feature_extractor", "roi_mask_predictors.make_roi_mask_predictor", "inference.make_roi_mask_post_processor", "loss.make_roi_mask_loss_evaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_feature_extractors.make_roi_mask_feature_extractor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_predictors.make_roi_mask_predictor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.make_roi_mask_post_processor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.make_roi_mask_loss_evaluator"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ROIMaskHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "self", ".", "feature_extractor", "=", "make_roi_mask_feature_extractor", "(", "cfg", ",", "in_channels", ")", "\n", "self", ".", "predictor", "=", "make_roi_mask_predictor", "(", "\n", "cfg", ",", "self", ".", "feature_extractor", ".", "out_channels", ")", "\n", "self", ".", "post_processor", "=", "make_roi_mask_post_processor", "(", "cfg", ")", "\n", "self", ".", "loss_evaluator", "=", "make_roi_mask_loss_evaluator", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.mask_head.ROIMaskHead.forward": [[46, 80], ["mask_head.ROIMaskHead.predictor", "mask_head.ROIMaskHead.loss_evaluator", "mask_head.keep_only_positive_boxes", "mask_head.ROIMaskHead.feature_extractor", "mask_head.ROIMaskHead.post_processor", "dict", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.mask_head.keep_only_positive_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            features (list[Tensor]): feature-maps from possibly several levels\n            proposals (list[BoxList]): proposal boxes\n            targets (list[BoxList], optional): the ground-truth targets.\n\n        Returns:\n            x (Tensor): the result of the feature extractor\n            proposals (list[BoxList]): during training, the original proposals\n                are returned. During testing, the predicted boxlists are returned\n                with the `mask` field set\n            losses (dict[Tensor]): During training, returns the losses for the\n                head. During testing, returns an empty dict.\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# during training, only focus on positive boxes", "\n", "            ", "all_proposals", "=", "proposals", "\n", "proposals", ",", "positive_inds", "=", "keep_only_positive_boxes", "(", "proposals", ")", "\n", "", "if", "self", ".", "training", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "x", "=", "features", "\n", "x", "=", "x", "[", "torch", ".", "cat", "(", "positive_inds", ",", "dim", "=", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n", "", "mask_logits", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "mask_logits", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_mask", "=", "self", ".", "loss_evaluator", "(", "proposals", ",", "mask_logits", ",", "targets", ")", "\n", "\n", "return", "x", ",", "all_proposals", ",", "dict", "(", "loss_mask", "=", "loss_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.mask_head.keep_only_positive_boxes": [[13, 34], ["isinstance", "isinstance", "boxes[].has_field", "boxes_per_image.get_field", "inds_mask.nonzero().squeeze", "positive_boxes.append", "positive_inds.append", "inds_mask.nonzero"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.has_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["def", "keep_only_positive_boxes", "(", "boxes", ")", ":", "\n", "    ", "\"\"\"\n    Given a set of BoxList containing the `labels` field,\n    return a set of BoxList for which `labels > 0`.\n\n    Arguments:\n        boxes (list of BoxList)\n    \"\"\"", "\n", "assert", "isinstance", "(", "boxes", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "boxes", "[", "0", "]", ",", "BoxList", ")", "\n", "assert", "boxes", "[", "0", "]", ".", "has_field", "(", "\"labels\"", ")", "\n", "positive_boxes", "=", "[", "]", "\n", "positive_inds", "=", "[", "]", "\n", "num_boxes", "=", "0", "\n", "for", "boxes_per_image", "in", "boxes", ":", "\n", "        ", "labels", "=", "boxes_per_image", ".", "get_field", "(", "\"labels\"", ")", "\n", "inds_mask", "=", "labels", ">", "0", "\n", "inds", "=", "inds_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "positive_boxes", ".", "append", "(", "boxes_per_image", "[", "inds", "]", ")", "\n", "positive_inds", ".", "append", "(", "inds_mask", ")", "\n", "", "return", "positive_boxes", ",", "positive_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.mask_head.build_roi_mask_head": [[82, 84], ["mask_head.ROIMaskHead"], "function", ["None"], ["", "", "def", "build_roi_mask_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "ROIMaskHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_predictors.MaskRCNNC4Predictor.__init__": [[12, 28], ["torch.nn.Module.__init__", "fcos_core.layers.ConvTranspose2d", "fcos_core.layers.Conv2d", "roi_mask_predictors.MaskRCNNC4Predictor.named_parameters", "torch.nn.init.constant_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "MaskRCNNC4Predictor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CLASSES", "\n", "dim_reduced", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "CONV_LAYERS", "[", "-", "1", "]", "\n", "num_inputs", "=", "in_channels", "\n", "\n", "self", ".", "conv5_mask", "=", "ConvTranspose2d", "(", "num_inputs", ",", "dim_reduced", ",", "2", ",", "2", ",", "0", ")", "\n", "self", ".", "mask_fcn_logits", "=", "Conv2d", "(", "dim_reduced", ",", "num_classes", ",", "1", ",", "1", ",", "0", ")", "\n", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "\"bias\"", "in", "name", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "param", ",", "0", ")", "\n", "", "elif", "\"weight\"", "in", "name", ":", "\n", "# Caffe2 implementation uses MSRAFill, which in fact", "\n", "# corresponds to kaiming_normal_ in PyTorch", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "param", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_predictors.MaskRCNNC4Predictor.forward": [[29, 32], ["torch.nn.functional.relu", "roi_mask_predictors.MaskRCNNC4Predictor.mask_fcn_logits", "roi_mask_predictors.MaskRCNNC4Predictor.conv5_mask"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "conv5_mask", "(", "x", ")", ")", "\n", "return", "self", ".", "mask_fcn_logits", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_predictors.MaskRCNNConv1x1Predictor.__init__": [[36, 50], ["torch.nn.Module.__init__", "fcos_core.layers.Conv2d", "roi_mask_predictors.MaskRCNNConv1x1Predictor.named_parameters", "torch.nn.init.constant_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "MaskRCNNConv1x1Predictor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CLASSES", "\n", "num_inputs", "=", "in_channels", "\n", "\n", "self", ".", "mask_fcn_logits", "=", "Conv2d", "(", "num_inputs", ",", "num_classes", ",", "1", ",", "1", ",", "0", ")", "\n", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "\"bias\"", "in", "name", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "param", ",", "0", ")", "\n", "", "elif", "\"weight\"", "in", "name", ":", "\n", "# Caffe2 implementation uses MSRAFill, which in fact", "\n", "# corresponds to kaiming_normal_ in PyTorch", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "param", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_predictors.MaskRCNNConv1x1Predictor.forward": [[51, 53], ["roi_mask_predictors.MaskRCNNConv1x1Predictor.mask_fcn_logits"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mask_fcn_logits", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_predictors.make_roi_mask_predictor": [[55, 58], ["func"], "function", ["None"], ["", "", "def", "make_roi_mask_predictor", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "func", "=", "registry", ".", "ROI_MASK_PREDICTOR", "[", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "PREDICTOR", "]", "\n", "return", "func", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.MaskPostProcessor.__init__": [[23, 26], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.MaskPostProcessor.forward": [[27, 62], ["x.sigmoid", "torch.cat", "torch.arange", "inference.MaskPostProcessor.split", "zip", "fcos_core.structures.bounding_box.BoxList.get_field", "len", "inference.MaskPostProcessor.masker", "fcos_core.structures.bounding_box.BoxList", "box.fields", "fcos_core.structures.bounding_box.BoxList.add_field", "results.append", "fcos_core.structures.bounding_box.BoxList.add_field", "box.get_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n", "            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.MaskPostProcessorCOCOFormat.forward": [[71, 86], ["inference.MaskPostProcessor.forward", "result.get_field().cpu", "result.add_field", "rle[].decode", "result.get_field", "mask_util.encode", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.Masker.__init__": [[163, 166], ["None"], "methods", ["None"], ["[", "boxlist", ".", "get_field", "(", "\"objectness\"", ")", "for", "boxlist", "in", "boxlists", "]", ",", "dim", "=", "0", "\n", ")", "\n", "box_sizes", "=", "[", "len", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.Masker.forward_single_image": [[167, 179], ["boxes.convert.convert.convert", "inference.paste_mask_in_image", "len", "masks.new_empty", "zip", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.paste_mask_in_image"], ["_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", ")", "\n", "inds_mask", "=", "torch", ".", "zeros_like", "(", "objectness", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "inds_mask", "[", "inds_sorted", "]", "=", "1", "\n", "inds_mask", "=", "inds_mask", ".", "split", "(", "box_sizes", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_mask", "[", "i", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "objectness", "=", "boxlists", "[", "i", "]", ".", "get_field", "(", "\"objectness\"", ")", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n", "_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "\n", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.Masker.__call__": [[180, 195], ["isinstance", "zip", "len", "len", "inference.Masker.forward_single_image", "results.append", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.Masker.forward_single_image"], ["boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_sorted", "]", "\n", "", "", "return", "boxlists", "\n", "\n", "\n", "", "", "def", "make_rpn_postprocessor", "(", "config", ",", "rpn_box_coder", ",", "is_train", ")", ":", "\n", "    ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TRAIN", "\n", "if", "not", "is_train", ":", "\n", "        ", "fpn_post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_TOP_N_TEST", "\n", "\n", "", "pre_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TRAIN", "\n", "post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TRAIN", "\n", "if", "not", "is_train", ":", "\n", "        ", "pre_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TEST", "\n", "post_nms_top_n", "=", "config", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TEST", "\n", "", "fpn_post_nms_per_batch", "=", "config", ".", "MODEL", ".", "RPN", ".", "FPN_POST_NMS_PER_BATCH", "\n", "nms_thresh", "=", "config", ".", "MODEL", ".", "RPN", ".", "NMS_THRESH", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.expand_boxes": [[91, 106], ["torch.zeros_like"], "function", ["None"], ["\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", "[", ":", ",", "None", "]", "\n", "box_regression", "=", "box_regression", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "image_shapes", "=", "[", "box", ".", "size", "for", "box", "in", "anchors", "]", "\n", "concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.expand_masks": [[108, 116], ["mask.new_zeros", "float"], "function", ["None"], ["proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.paste_mask_in_image": [[118, 155], ["inference.expand_masks", "box.to.to", "int", "int", "max", "max", "fcos_core.layers.misc.interpolate.expand", "fcos_core.layers.misc.interpolate.to", "fcos_core.layers.misc.interpolate", "torch.zeros", "max", "min", "max", "min", "inference.expand_boxes"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.expand_masks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.expand_boxes"], ["self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n", "result", ".", "append", "(", "boxlist", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[list[BoxList]]\n            objectness: list[tensor]\n            box_regression: list[tensor]\n\n        Returns:\n            boxlists (list[BoxList]): the post-processed anchors, after\n                applying box decoding and NMS\n        \"\"\"", "\n", "sampled_boxes", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "objectness", ")", "\n", "anchors", "=", "list", "(", "zip", "(", "*", "anchors", ")", ")", "\n", "for", "a", ",", "o", ",", "b", "in", "zip", "(", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "            ", "sampled_boxes", ".", "append", "(", "self", ".", "forward_for_single_feature_map", "(", "a", ",", "o", ",", "b", ")", ")", "\n", "\n", "", "boxlists", "=", "list", "(", "zip", "(", "*", "sampled_boxes", ")", ")", "\n", "boxlists", "=", "[", "cat_boxlist", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "\n", "if", "num_levels", ">", "1", ":", "\n", "            ", "boxlists", "=", "self", ".", "select_over_all_levels", "(", "boxlists", ")", "\n", "\n", "# append ground-truth bboxes to proposals", "\n", "", "if", "self", ".", "training", "and", "targets", "is", "not", "None", ":", "\n", "            ", "boxlists", "=", "self", ".", "add_gt_proposals", "(", "boxlists", ",", "targets", ")", "\n", "\n", "", "return", "boxlists", "\n", "\n", "", "def", "select_over_all_levels", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "num_images", "=", "len", "(", "boxlists", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.inference.make_roi_mask_post_processor": [[197, 205], ["inference.MaskPostProcessor", "inference.Masker"], "function", ["None"], ["box_selector", "=", "RPNPostProcessor", "(", "\n", "pre_nms_top_n", "=", "pre_nms_top_n", ",", "\n", "post_nms_top_n", "=", "post_nms_top_n", ",", "\n", "nms_thresh", "=", "nms_thresh", ",", "\n", "min_size", "=", "min_size", ",", "\n", "box_coder", "=", "rpn_box_coder", ",", "\n", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", ",", "\n", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_feature_extractors.MaskRCNNFPNFeatureExtractor.__init__": [[22, 58], ["torch.nn.Module.__init__", "fcos_core.modeling.poolers.Pooler", "enumerate", "fcos_core.modeling.make_layers.make_conv3x3", "roi_mask_feature_extractors.MaskRCNNFPNFeatureExtractor.add_module", "roi_mask_feature_extractors.MaskRCNNFPNFeatureExtractor.blocks.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.make_conv3x3"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            num_classes (int): number of output classes\n            input_size (int): number of channels of the input once it's flattened\n            representation_size (int): size of the intermediate representation\n        \"\"\"", "\n", "super", "(", "MaskRCNNFPNFeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "resolution", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "input_size", "=", "in_channels", "\n", "self", ".", "pooler", "=", "pooler", "\n", "\n", "use_gn", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "USE_GN", "\n", "layers", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "CONV_LAYERS", "\n", "dilation", "=", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "DILATION", "\n", "\n", "next_feature", "=", "input_size", "\n", "self", ".", "blocks", "=", "[", "]", "\n", "for", "layer_idx", ",", "layer_features", "in", "enumerate", "(", "layers", ",", "1", ")", ":", "\n", "            ", "layer_name", "=", "\"mask_fcn{}\"", ".", "format", "(", "layer_idx", ")", "\n", "module", "=", "make_conv3x3", "(", "\n", "next_feature", ",", "layer_features", ",", "\n", "dilation", "=", "dilation", ",", "stride", "=", "1", ",", "use_gn", "=", "use_gn", "\n", ")", "\n", "self", ".", "add_module", "(", "layer_name", ",", "module", ")", "\n", "next_feature", "=", "layer_features", "\n", "self", ".", "blocks", ".", "append", "(", "layer_name", ")", "\n", "", "self", ".", "out_channels", "=", "layer_features", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_feature_extractors.MaskRCNNFPNFeatureExtractor.forward": [[59, 66], ["roi_mask_feature_extractors.MaskRCNNFPNFeatureExtractor.pooler", "torch.nn.functional.relu", "getattr"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposals", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "x", ",", "proposals", ")", "\n", "\n", "for", "layer_name", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "getattr", "(", "self", ",", "layer_name", ")", "(", "x", ")", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.roi_mask_feature_extractors.make_roi_mask_feature_extractor": [[68, 73], ["func"], "function", ["None"], ["", "", "def", "make_roi_mask_feature_extractor", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "func", "=", "registry", ".", "ROI_MASK_FEATURE_EXTRACTORS", "[", "\n", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "FEATURE_EXTRACTOR", "\n", "]", "\n", "return", "func", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.MaskRCNNLossComputation.__init__": [[46, 54], ["None"], "methods", ["None"], ["# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n", "matched_targets", ".", "add_field", "(", "\"matched_idxs\"", ",", "matched_idxs", ")", "\n", "return", "matched_targets", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.MaskRCNNLossComputation.match_targets_to_proposals": [[55, 67], ["fcos_core.structures.boxlist_ops.boxlist_iou", "loss.MaskRCNNLossComputation.proposal_matcher", "target.copy_with_fields.copy_with_fields.copy_with_fields", "matched_targets.add_field", "loss.MaskRCNNLossComputation.clamp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["\n", "", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.MaskRCNNLossComputation.prepare_targets": [[68, 101], ["zip", "loss.MaskRCNNLossComputation.match_targets_to_proposals", "loss.MaskRCNNLossComputation.get_field", "loss.MaskRCNNLossComputation.get_field", "labels_per_image.to.to.to", "torch.nonzero().squeeze", "loss.MaskRCNNLossComputation.get_field", "loss.project_masks_on_boxes", "labels.append", "masks.append", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.match_targets_to_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.project_masks_on_boxes"], ["\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n", "# compute regression targets", "\n", "", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "labels_per_image", ")", "\n", "regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n", "", "", "if", "require_boxes_info", ":", "\n", "            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.MaskRCNNLossComputation.__call__": [[102, 129], ["loss.MaskRCNNLossComputation.prepare_targets", "fcos_core.modeling.utils.cat", "fcos_core.modeling.utils.cat", "torch.nonzero().squeeze", "torch.nn.functional.binary_cross_entropy_with_logits", "fcos_core.modeling.utils.cat.numel", "torch.nonzero", "mask_logits.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["\n", "anchors", "=", "[", "cat_boxlist", "(", "anchors_per_image", ")", "for", "anchors_per_image", "in", "anchors", "]", "\n", "labels", ",", "regression_targets", "=", "self", ".", "prepare_targets", "(", "anchors", ",", "targets", ")", "\n", "sampled_pos_inds", ",", "sampled_neg_inds", "=", "self", ".", "fg_bg_sampler", "(", "labels", ")", "\n", "sampled_pos_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_pos_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sampled_neg_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_neg_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "sampled_inds", "=", "torch", ".", "cat", "(", "[", "sampled_pos_inds", ",", "sampled_neg_inds", "]", ",", "dim", "=", "0", ")", "\n", "\n", "objectness", ",", "box_regression", "=", "concat_box_prediction_layers", "(", "objectness", ",", "box_regression", ")", "\n", "\n", "objectness", "=", "objectness", ".", "squeeze", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "regression_targets", "=", "torch", ".", "cat", "(", "regression_targets", ",", "dim", "=", "0", ")", "\n", "\n", "box_loss", "=", "smooth_l1_loss", "(", "\n", "box_regression", "[", "sampled_pos_inds", "]", ",", "\n", "regression_targets", "[", "sampled_pos_inds", "]", ",", "\n", "beta", "=", "1.0", "/", "9", ",", "\n", "size_average", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.project_masks_on_boxes": [[11, 43], ["proposals.bbox.to.convert", "proposals.bbox.to.bbox.to", "zip", "torch.stack().to", "torch.device", "segmentation_mask.crop", "segmentation_mask.crop.resize", "cropped_mask.resize.get_mask_tensor", "masks.append", "len", "torch.empty", "torch.stack"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.get_mask_tensor"], ["\n", "from", ".", ".", "balanced_positive_negative_sampler", "import", "BalancedPositiveNegativeSampler", "\n", "from", ".", ".", "utils", "import", "cat", "\n", "\n", "from", "maskrcnn_benchmark", ".", "layers", "import", "smooth_l1_loss", "\n", "from", "maskrcnn_benchmark", ".", "modeling", ".", "matcher", "import", "Matcher", "\n", "from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "boxlist_iou", "\n", "from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "cat_boxlist", "\n", "\n", "\n", "class", "RPNLossComputation", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    This class computes the RPN loss.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n", "generate_labels_func", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n", "self", ".", "copied_fields", "=", "[", "]", "\n", "self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n", "", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n", "        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.mask_head.loss.make_roi_mask_loss_evaluator": [[131, 143], ["fcos_core.modeling.matcher.Matcher", "loss.MaskRCNNLossComputation"], "function", ["None"], ["\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "objectness", "[", "sampled_inds", "]", ",", "labels", "[", "sampled_inds", "]", "\n", ")", "\n", "\n", "return", "objectness_loss", ",", "box_loss", "\n", "\n", "# This function should be overwritten in RetinaNet", "\n", "", "", "def", "generate_rpn_labels", "(", "matched_targets", ")", ":", "\n", "    ", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "matched_idxs", ">=", "0", "\n", "return", "labels_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_predictors.FastRCNNPredictor.__init__": [[8, 25], ["torch.nn.Module.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.normal_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FastRCNNPredictor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "in_channels", "is", "not", "None", "\n", "\n", "num_inputs", "=", "in_channels", "\n", "\n", "num_classes", "=", "config", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CLASSES", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "cls_score", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "num_classes", ")", "\n", "num_bbox_reg_classes", "=", "2", "if", "config", ".", "MODEL", ".", "CLS_AGNOSTIC_BBOX_REG", "else", "num_classes", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "num_bbox_reg_classes", "*", "4", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "cls_score", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_score", ".", "bias", ",", "0", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "bbox_pred", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "0.001", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bbox_pred", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_predictors.FastRCNNPredictor.forward": [[26, 32], ["roi_box_predictors.FastRCNNPredictor.avgpool", "x.view.view.view", "roi_box_predictors.FastRCNNPredictor.cls_score", "roi_box_predictors.FastRCNNPredictor.bbox_pred", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "cls_logit", "=", "self", ".", "cls_score", "(", "x", ")", "\n", "bbox_pred", "=", "self", ".", "bbox_pred", "(", "x", ")", "\n", "return", "cls_logit", ",", "bbox_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_predictors.FPNPredictor.__init__": [[36, 49], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FPNPredictor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CLASSES", "\n", "representation_size", "=", "in_channels", "\n", "\n", "self", ".", "cls_score", "=", "nn", ".", "Linear", "(", "representation_size", ",", "num_classes", ")", "\n", "num_bbox_reg_classes", "=", "2", "if", "cfg", ".", "MODEL", ".", "CLS_AGNOSTIC_BBOX_REG", "else", "num_classes", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Linear", "(", "representation_size", ",", "num_bbox_reg_classes", "*", "4", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "cls_score", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "bbox_pred", ".", "weight", ",", "std", "=", "0.001", ")", "\n", "for", "l", "in", "[", "self", ".", "cls_score", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_predictors.FPNPredictor.forward": [[50, 58], ["roi_box_predictors.FPNPredictor.cls_score", "roi_box_predictors.FPNPredictor.bbox_pred", "x.view.view.ndimension", "x.view.view.view", "list", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "ndimension", "(", ")", "==", "4", ":", "\n", "            ", "assert", "list", "(", "x", ".", "shape", "[", "2", ":", "]", ")", "==", "[", "1", ",", "1", "]", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "", "scores", "=", "self", ".", "cls_score", "(", "x", ")", "\n", "bbox_deltas", "=", "self", ".", "bbox_pred", "(", "x", ")", "\n", "\n", "return", "scores", ",", "bbox_deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_predictors.make_roi_box_predictor": [[60, 63], ["func"], "function", ["None"], ["", "", "def", "make_roi_box_predictor", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "func", "=", "registry", ".", "ROI_BOX_PREDICTOR", "[", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "PREDICTOR", "]", "\n", "return", "func", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.PostProcessor.__init__": [[19, 44], ["torch.nn.Module.__init__", "fcos_core.modeling.box_coder.BoxCoder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.PostProcessor.forward": [[45, 88], ["torch.softmax", "torch.softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inference.PostProcessor.box_coder.decode", "proposals.repeat.repeat.split", "class_prob.split.split.split", "zip", "len", "box_regression.view", "proposals.repeat.repeat.repeat", "inference.PostProcessor.prepare_boxlist", "inference.PostProcessor.clip_to_image", "results.append", "sum", "inference.PostProcessor.filter_results"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.PostProcessor.prepare_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.PostProcessor.filter_results"], ["            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n", "for", "gt_box", "in", "gt_boxes", ":", "\n", "            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.PostProcessor.prepare_boxlist": [[89, 107], ["boxes.reshape.reshape.reshape", "scores.reshape.reshape.reshape", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.bounding_box.BoxList.add_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", "[", ":", ",", "None", "]", "\n", "box_regression", "=", "box_regression", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "image_shapes", "=", "[", "box", ".", "size", "for", "box", "in", "anchors", "]", "\n", "concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.PostProcessor.filter_results": [[108, 150], ["boxlist.bbox.reshape", "boxlist.get_field().reshape", "range", "fcos_core.structures.boxlist_ops.cat_boxlist", "len", "inds_all[].nonzero().squeeze", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.boxlist_ops.boxlist_nms.add_field", "fcos_core.structures.boxlist_ops.boxlist_nms", "len", "fcos_core.structures.boxlist_ops.boxlist_nms.add_field", "fcos_core.structures.boxlist_ops.cat_boxlist.append", "fcos_core.structures.boxlist_ops.cat_boxlist.get_field", "torch.kthvalue", "torch.kthvalue", "torch.kthvalue", "torch.kthvalue", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "boxlist.get_field", "torch.full", "torch.full", "torch.full", "torch.full", "fcos_core.structures.boxlist_ops.cat_boxlist.get_field.cpu", "image_thresh.item", "inds_all[].nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.boxlist_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n", "result", ".", "append", "(", "boxlist", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[list[BoxList]]\n            objectness: list[tensor]\n            box_regression: list[tensor]\n\n        Returns:\n            boxlists (list[BoxList]): the post-processed anchors, after\n                applying box decoding and NMS\n        \"\"\"", "\n", "sampled_boxes", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "objectness", ")", "\n", "anchors", "=", "list", "(", "zip", "(", "*", "anchors", ")", ")", "\n", "for", "a", ",", "o", ",", "b", "in", "zip", "(", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "            ", "sampled_boxes", ".", "append", "(", "self", ".", "forward_for_single_feature_map", "(", "a", ",", "o", ",", "b", ")", ")", "\n", "\n", "", "boxlists", "=", "list", "(", "zip", "(", "*", "sampled_boxes", ")", ")", "\n", "boxlists", "=", "[", "cat_boxlist", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "\n", "if", "num_levels", ">", "1", ":", "\n", "            ", "boxlists", "=", "self", ".", "select_over_all_levels", "(", "boxlists", ")", "\n", "\n", "# append ground-truth bboxes to proposals", "\n", "", "if", "self", ".", "training", "and", "targets", "is", "not", "None", ":", "\n", "            ", "boxlists", "=", "self", ".", "add_gt_proposals", "(", "boxlists", ",", "targets", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.make_roi_box_post_processor": [[152, 173], ["fcos_core.modeling.box_coder.BoxCoder", "inference.PostProcessor"], "function", ["None"], ["", "return", "boxlists", "\n", "\n", "", "def", "select_over_all_levels", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "num_images", "=", "len", "(", "boxlists", ")", "\n", "# different behavior during training and during testing:", "\n", "# during training, post_nms_top_n is over *all* the proposals combined, while", "\n", "# during testing, it is over the proposals for each image", "\n", "# NOTE: it should be per image, and not per batch. However, to be consistent ", "\n", "# with Detectron, the default is per batch (see Issue #672)", "\n", "if", "self", ".", "training", "and", "self", ".", "fpn_post_nms_per_batch", ":", "\n", "            ", "objectness", "=", "torch", ".", "cat", "(", "\n", "[", "boxlist", ".", "get_field", "(", "\"objectness\"", ")", "for", "boxlist", "in", "boxlists", "]", ",", "dim", "=", "0", "\n", ")", "\n", "box_sizes", "=", "[", "len", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "post_nms_top_n", "=", "min", "(", "self", ".", "fpn_post_nms_top_n", ",", "len", "(", "objectness", ")", ")", "\n", "_", ",", "inds_sorted", "=", "torch", ".", "topk", "(", "objectness", ",", "post_nms_top_n", ",", "dim", "=", "0", ",", "sorted", "=", "True", ")", "\n", "inds_mask", "=", "torch", ".", "zeros_like", "(", "objectness", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "inds_mask", "[", "inds_sorted", "]", "=", "1", "\n", "inds_mask", "=", "inds_mask", ".", "split", "(", "box_sizes", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "                ", "boxlists", "[", "i", "]", "=", "boxlists", "[", "i", "]", "[", "inds_mask", "[", "i", "]", "]", "\n", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.ResNet50Conv5ROIFeatureExtractor.__init__": [[15, 42], ["torch.nn.Module.__init__", "fcos_core.modeling.poolers.Pooler", "fcos_core.modeling.backbone.resnet.StageSpec", "fcos_core.modeling.backbone.resnet.ResNetHead"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ResNet50Conv5ROIFeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "resolution", "=", "config", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "config", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "config", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "\n", "stage", "=", "resnet", ".", "StageSpec", "(", "index", "=", "4", ",", "block_count", "=", "3", ",", "return_features", "=", "False", ")", "\n", "head", "=", "resnet", ".", "ResNetHead", "(", "\n", "block_module", "=", "config", ".", "MODEL", ".", "RESNETS", ".", "TRANS_FUNC", ",", "\n", "stages", "=", "(", "stage", ",", ")", ",", "\n", "num_groups", "=", "config", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", ",", "\n", "width_per_group", "=", "config", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", ",", "\n", "stride_in_1x1", "=", "config", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", ",", "\n", "stride_init", "=", "None", ",", "\n", "res2_out_channels", "=", "config", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", ",", "\n", "dilation", "=", "config", ".", "MODEL", ".", "RESNETS", ".", "RES5_DILATION", "\n", ")", "\n", "\n", "self", ".", "pooler", "=", "pooler", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "out_channels", "=", "head", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.ResNet50Conv5ROIFeatureExtractor.forward": [[43, 47], ["roi_box_feature_extractors.ResNet50Conv5ROIFeatureExtractor.pooler", "roi_box_feature_extractors.ResNet50Conv5ROIFeatureExtractor.head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposals", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "x", ",", "proposals", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.FPN2MLPFeatureExtractor.__init__": [[55, 73], ["torch.nn.Module.__init__", "fcos_core.modeling.poolers.Pooler", "fcos_core.modeling.make_layers.make_fc", "fcos_core.modeling.make_layers.make_fc"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.make_fc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.make_fc"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FPN2MLPFeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "input_size", "=", "in_channels", "*", "resolution", "**", "2", "\n", "representation_size", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "MLP_HEAD_DIM", "\n", "use_gn", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "USE_GN", "\n", "self", ".", "pooler", "=", "pooler", "\n", "self", ".", "fc6", "=", "make_fc", "(", "input_size", ",", "representation_size", ",", "use_gn", ")", "\n", "self", ".", "fc7", "=", "make_fc", "(", "representation_size", ",", "representation_size", ",", "use_gn", ")", "\n", "self", ".", "out_channels", "=", "representation_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.FPN2MLPFeatureExtractor.forward": [[74, 82], ["roi_box_feature_extractors.FPN2MLPFeatureExtractor.pooler", "torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.size", "roi_box_feature_extractors.FPN2MLPFeatureExtractor.fc6", "roi_box_feature_extractors.FPN2MLPFeatureExtractor.fc7"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposals", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "x", ",", "proposals", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc6", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc7", "(", "x", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.FPNXconv1fcFeatureExtractor.__init__": [[90, 138], ["torch.nn.Module.__init__", "fcos_core.modeling.poolers.Pooler", "range", "roi_box_feature_extractors.FPNXconv1fcFeatureExtractor.add_module", "fcos_core.modeling.make_layers.make_fc", "xconvs.append", "xconvs.append", "torch.nn.Sequential", "modules.modules", "torch.nn.Conv2d", "xconvs.append", "torch.nn.ReLU", "isinstance", "fcos_core.modeling.make_layers.group_norm", "torch.nn.init.normal_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.make_fc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.group_norm"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FPNXconv1fcFeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "self", ".", "pooler", "=", "pooler", "\n", "\n", "use_gn", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "USE_GN", "\n", "conv_head_dim", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CONV_HEAD_DIM", "\n", "num_stacked_convs", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_STACKED_CONVS", "\n", "dilation", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "DILATION", "\n", "\n", "xconvs", "=", "[", "]", "\n", "for", "ix", "in", "range", "(", "num_stacked_convs", ")", ":", "\n", "            ", "xconvs", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "conv_head_dim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", "if", "use_gn", "else", "True", "\n", ")", "\n", ")", "\n", "in_channels", "=", "conv_head_dim", "\n", "if", "use_gn", ":", "\n", "                ", "xconvs", ".", "append", "(", "group_norm", "(", "in_channels", ")", ")", "\n", "", "xconvs", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "\"xconvs\"", ",", "nn", ".", "Sequential", "(", "*", "xconvs", ")", ")", "\n", "for", "modules", "in", "[", "self", ".", "xconvs", ",", "]", ":", "\n", "            ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "if", "not", "use_gn", ":", "\n", "                        ", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "", "", "", "", "input_size", "=", "conv_head_dim", "*", "resolution", "**", "2", "\n", "representation_size", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "MLP_HEAD_DIM", "\n", "self", ".", "fc6", "=", "make_fc", "(", "input_size", ",", "representation_size", ",", "use_gn", "=", "False", ")", "\n", "self", ".", "out_channels", "=", "representation_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.FPNXconv1fcFeatureExtractor.forward": [[139, 145], ["roi_box_feature_extractors.FPNXconv1fcFeatureExtractor.pooler", "roi_box_feature_extractors.FPNXconv1fcFeatureExtractor.xconvs", "torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.relu.size", "roi_box_feature_extractors.FPNXconv1fcFeatureExtractor.fc6"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposals", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "x", ",", "proposals", ")", "\n", "x", "=", "self", ".", "xconvs", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc6", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.make_roi_box_feature_extractor": [[147, 152], ["func"], "function", ["None"], ["", "", "def", "make_roi_box_feature_extractor", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "func", "=", "registry", ".", "ROI_BOX_FEATURE_EXTRACTORS", "[", "\n", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "FEATURE_EXTRACTOR", "\n", "]", "\n", "return", "func", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.FastRCNNLossComputation.__init__": [[21, 38], ["None"], "methods", ["None"], ["class", "RPNLossComputation", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    This class computes the RPN loss.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n", "generate_labels_func", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n", "self", ".", "copied_fields", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.FastRCNNLossComputation.match_targets_to_proposals": [[39, 51], ["fcos_core.structures.boxlist_ops.boxlist_iou", "loss.FastRCNNLossComputation.proposal_matcher", "target.copy_with_fields.copy_with_fields.copy_with_fields", "matched_targets.add_field", "loss.FastRCNNLossComputation.clamp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n", "", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n", "        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.FastRCNNLossComputation.prepare_targets": [[52, 81], ["zip", "loss.FastRCNNLossComputation.match_targets_to_proposals", "loss.FastRCNNLossComputation.get_field", "loss.FastRCNNLossComputation.get_field", "labels_per_image.to.to.to", "loss.FastRCNNLossComputation.box_coder.encode", "labels.append", "regression_targets.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.match_targets_to_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n", "matched_targets", ".", "add_field", "(", "\"matched_idxs\"", ",", "matched_idxs", ")", "\n", "return", "matched_targets", "\n", "\n", "", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.FastRCNNLossComputation.subsample": [[82, 117], ["loss.FastRCNNLossComputation.prepare_targets", "loss.FastRCNNLossComputation.fg_bg_sampler", "list", "zip", "enumerate", "proposals_per_image.add_field", "proposals_per_image.add_field", "zip", "torch.nonzero().squeeze", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["# compute regression targets", "\n", "", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "labels_per_image", ")", "\n", "regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n", "", "", "if", "require_boxes_info", ":", "\n", "            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors (list[list[BoxList]])\n            objectness (list[Tensor])\n            box_regression (list[Tensor])\n            targets (list[BoxList])\n\n        Returns:\n            objectness_loss (Tensor)\n            box_loss (Tensor)\n        \"\"\"", "\n", "anchors", "=", "[", "cat_boxlist", "(", "anchors_per_image", ")", "for", "anchors_per_image", "in", "anchors", "]", "\n", "labels", ",", "regression_targets", "=", "self", ".", "prepare_targets", "(", "anchors", ",", "targets", ")", "\n", "sampled_pos_inds", ",", "sampled_neg_inds", "=", "self", ".", "fg_bg_sampler", "(", "labels", ")", "\n", "sampled_pos_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_pos_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sampled_neg_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_neg_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "sampled_inds", "=", "torch", ".", "cat", "(", "[", "sampled_pos_inds", ",", "sampled_neg_inds", "]", ",", "dim", "=", "0", ")", "\n", "\n", "objectness", ",", "box_regression", "="]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.FastRCNNLossComputation.__call__": [[118, 168], ["fcos_core.modeling.utils.cat", "fcos_core.modeling.utils.cat", "fcos_core.modeling.utils.cat", "fcos_core.modeling.utils.cat", "torch.nn.functional.cross_entropy", "torch.nonzero().squeeze", "fcos_core.layers.smooth_l1_loss", "hasattr", "RuntimeError", "torch.tensor", "fcos_core.modeling.utils.cat.numel", "proposal.get_field", "proposal.get_field", "torch.nonzero", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["concat_box_prediction_layers", "(", "objectness", ",", "box_regression", ")", "\n", "\n", "objectness", "=", "objectness", ".", "squeeze", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "regression_targets", "=", "torch", ".", "cat", "(", "regression_targets", ",", "dim", "=", "0", ")", "\n", "\n", "box_loss", "=", "smooth_l1_loss", "(", "\n", "box_regression", "[", "sampled_pos_inds", "]", ",", "\n", "regression_targets", "[", "sampled_pos_inds", "]", ",", "\n", "beta", "=", "1.0", "/", "9", ",", "\n", "size_average", "=", "False", ",", "\n", ")", "/", "(", "sampled_inds", ".", "numel", "(", ")", ")", "\n", "\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "objectness", "[", "sampled_inds", "]", ",", "labels", "[", "sampled_inds", "]", "\n", ")", "\n", "\n", "return", "objectness_loss", ",", "box_loss", "\n", "\n", "# This function should be overwritten in RetinaNet", "\n", "", "", "def", "generate_rpn_labels", "(", "matched_targets", ")", ":", "\n", "    ", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "matched_idxs", ">=", "0", "\n", "return", "labels_per_image", "\n", "\n", "\n", "", "def", "make_rpn_loss_evaluator", "(", "cfg", ",", "box_coder", ")", ":", "\n", "    ", "matcher", "=", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "FG_IOU_THRESHOLD", ",", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BG_IOU_THRESHOLD", ",", "\n", "allow_low_quality_matches", "=", "True", ",", "\n", ")", "\n", "\n", "fg_bg_sampler", "=", "BalancedPositiveNegativeSampler", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "\n", ")", "\n", "\n", "loss_evaluator", "=", "RPNLossComputation", "(", "\n", "matcher", ",", "\n", "fg_bg_sampler", ",", "\n", "box_coder", ",", "\n", "generate_rpn_labels", "\n", ")", "\n", "return", "loss_evaluator", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.make_roi_box_loss_evaluator": [[170, 194], ["fcos_core.modeling.matcher.Matcher", "fcos_core.modeling.box_coder.BoxCoder", "fcos_core.modeling.balanced_positive_negative_sampler.BalancedPositiveNegativeSampler", "loss.FastRCNNLossComputation"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.box_head.ROIBoxHead.__init__": [[16, 23], ["super().__init__", "roi_box_feature_extractors.make_roi_box_feature_extractor", "roi_box_predictors.make_roi_box_predictor", "inference.make_roi_box_post_processor", "loss.make_roi_box_loss_evaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_feature_extractors.make_roi_box_feature_extractor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.roi_box_predictors.make_roi_box_predictor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.inference.make_roi_box_post_processor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.loss.make_roi_box_loss_evaluator"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ROIBoxHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_extractor", "=", "make_roi_box_feature_extractor", "(", "cfg", ",", "in_channels", ")", "\n", "self", ".", "predictor", "=", "make_roi_box_predictor", "(", "\n", "cfg", ",", "self", ".", "feature_extractor", ".", "out_channels", ")", "\n", "self", ".", "post_processor", "=", "make_roi_box_post_processor", "(", "cfg", ")", "\n", "self", ".", "loss_evaluator", "=", "make_roi_box_loss_evaluator", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.box_head.ROIBoxHead.forward": [[24, 62], ["box_head.ROIBoxHead.feature_extractor", "box_head.ROIBoxHead.predictor", "box_head.ROIBoxHead.loss_evaluator", "box_head.ROIBoxHead.post_processor", "dict", "torch.no_grad", "box_head.ROIBoxHead.loss_evaluator.subsample"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.subsample"], ["", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            features (list[Tensor]): feature-maps from possibly several levels\n            proposals (list[BoxList]): proposal boxes\n            targets (list[BoxList], optional): the ground-truth targets.\n\n        Returns:\n            x (Tensor): the result of the feature extractor\n            proposals (list[BoxList]): during training, the subsampled proposals\n                are returned. During testing, the predicted boxlists are returned\n            losses (dict[Tensor]): During training, returns the losses for the\n                head. During testing, returns an empty dict.\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# Faster R-CNN subsamples during training the proposals with a fixed", "\n", "# positive / negative ratio", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "proposals", "=", "self", ".", "loss_evaluator", ".", "subsample", "(", "proposals", ",", "targets", ")", "\n", "\n", "# extract features that will be fed to the final classifier. The", "\n", "# feature_extractor generally corresponds to the pooler + heads", "\n", "", "", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n", "# final classifier that converts the features into predictions", "\n", "class_logits", ",", "box_regression", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "(", "class_logits", ",", "box_regression", ")", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_classifier", ",", "loss_box_reg", "=", "self", ".", "loss_evaluator", "(", "\n", "[", "class_logits", "]", ",", "[", "box_regression", "]", "\n", ")", "\n", "return", "(", "\n", "x", ",", "\n", "proposals", ",", "\n", "dict", "(", "loss_classifier", "=", "loss_classifier", ",", "loss_box_reg", "=", "loss_box_reg", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_head.box_head.build_roi_box_head": [[65, 72], ["box_head.ROIBoxHead"], "function", ["None"], ["", "", "def", "build_roi_box_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "\"\"\"\n    Constructs a new box head.\n    By default, uses ROIBoxHead, but if it turns out not to be enough, just register a new class\n    and make it a parameter in the config\n    \"\"\"", "\n", "return", "ROIBoxHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_feature_extractors.KeypointRCNNFeatureExtractor.__init__": [[12, 38], ["torch.nn.Module.__init__", "fcos_core.modeling.poolers.Pooler", "enumerate", "fcos_core.layers.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.constant_", "roi_keypoint_feature_extractors.KeypointRCNNFeatureExtractor.add_module", "roi_keypoint_feature_extractors.KeypointRCNNFeatureExtractor.blocks.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "KeypointRCNNFeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "resolution", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_RESOLUTION", "\n", "scales", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_SCALES", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler", "=", "Pooler", "(", "\n", "output_size", "=", "(", "resolution", ",", "resolution", ")", ",", "\n", "scales", "=", "scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", ")", "\n", "self", ".", "pooler", "=", "pooler", "\n", "\n", "input_features", "=", "in_channels", "\n", "layers", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "CONV_LAYERS", "\n", "next_feature", "=", "input_features", "\n", "self", ".", "blocks", "=", "[", "]", "\n", "for", "layer_idx", ",", "layer_features", "in", "enumerate", "(", "layers", ",", "1", ")", ":", "\n", "            ", "layer_name", "=", "\"conv_fcn{}\"", ".", "format", "(", "layer_idx", ")", "\n", "module", "=", "Conv2d", "(", "next_feature", ",", "layer_features", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "module", ".", "weight", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0", ")", "\n", "self", ".", "add_module", "(", "layer_name", ",", "module", ")", "\n", "next_feature", "=", "layer_features", "\n", "self", ".", "blocks", ".", "append", "(", "layer_name", ")", "\n", "", "self", ".", "out_channels", "=", "layer_features", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_feature_extractors.KeypointRCNNFeatureExtractor.forward": [[39, 44], ["roi_keypoint_feature_extractors.KeypointRCNNFeatureExtractor.pooler", "torch.nn.functional.relu", "getattr"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposals", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "x", ",", "proposals", ")", "\n", "for", "layer_name", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "getattr", "(", "self", ",", "layer_name", ")", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_feature_extractors.make_roi_keypoint_feature_extractor": [[46, 51], ["func"], "function", ["None"], ["", "", "def", "make_roi_keypoint_feature_extractor", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "func", "=", "registry", ".", "ROI_KEYPOINT_FEATURE_EXTRACTORS", "[", "\n", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "FEATURE_EXTRACTOR", "\n", "]", "\n", "return", "func", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_predictors.KeypointRCNNPredictor.__init__": [[9, 27], ["torch.nn.Module.__init__", "fcos_core.layers.ConvTranspose2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "KeypointRCNNPredictor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_features", "=", "in_channels", "\n", "num_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "NUM_CLASSES", "\n", "deconv_kernel", "=", "4", "\n", "self", ".", "kps_score_lowres", "=", "layers", ".", "ConvTranspose2d", "(", "\n", "input_features", ",", "\n", "num_keypoints", ",", "\n", "deconv_kernel", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "deconv_kernel", "//", "2", "-", "1", ",", "\n", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "\n", "self", ".", "kps_score_lowres", ".", "weight", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", "\n", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "kps_score_lowres", ".", "bias", ",", "0", ")", "\n", "self", ".", "up_scale", "=", "2", "\n", "self", ".", "out_channels", "=", "num_keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_predictors.KeypointRCNNPredictor.forward": [[28, 34], ["roi_keypoint_predictors.KeypointRCNNPredictor.kps_score_lowres", "fcos_core.layers.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "kps_score_lowres", "(", "x", ")", "\n", "x", "=", "layers", ".", "interpolate", "(", "\n", "x", ",", "scale_factor", "=", "self", ".", "up_scale", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_predictors.make_roi_keypoint_predictor": [[36, 39], ["func"], "function", ["None"], ["", "", "def", "make_roi_keypoint_predictor", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "func", "=", "registry", ".", "ROI_KEYPOINT_PREDICTOR", "[", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "PREDICTOR", "]", "\n", "return", "func", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.KeypointPostProcessor.__init__": [[6, 9], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "cat_boxlist", "\n", "from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "boxlist_nms", "\n", "from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "remove_small_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.KeypointPostProcessor.forward": [[10, 33], ["mask_prob.split.split.split", "scores.split.split.split", "zip", "inference.KeypointPostProcessor.keypointer", "len", "box.bbox.size", "fcos_core.structures.bounding_box.BoxList", "box.fields", "fcos_core.structures.keypoint.PersonKeypoints", "fcos_core.structures.keypoint.PersonKeypoints.add_field", "fcos_core.structures.bounding_box.BoxList.add_field", "results.append", "fcos_core.structures.bounding_box.BoxList.add_field", "box.get_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["from", ".", ".", "utils", "import", "cat", "\n", "from", ".", "utils", "import", "permute_and_flatten", "\n", "\n", "class", "RPNPostProcessor", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Performs post-processing on the outputs of the RPN boxes, before feeding the\n    proposals to the heads\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.Keypointer.__init__": [[107, 109], ["None"], "methods", ["None"], ["\n", "proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.Keypointer.__call__": [[110, 120], ["isinstance", "inference.heatmaps_to_keypoints", "len", "masks.detach().cpu().numpy", "boxes[].bbox.cpu().numpy", "torch.from_numpy().to", "torch.as_tensor", "masks.detach().cpu", "boxes[].bbox.cpu", "torch.from_numpy", "masks.detach"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.heatmaps_to_keypoints", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.heatmaps_to_keypoints": [[40, 95], ["numpy.maximum", "numpy.maximum", "numpy.ceil", "numpy.ceil", "numpy.transpose", "numpy.zeros", "numpy.zeros", "range", "len", "cv2.resize", "numpy.transpose", "np.transpose.reshape().argmax", "numpy.transpose", "len", "len", "int", "int", "numpy.maximum", "numpy.maximum", "np.transpose.reshape", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n", "if", "box_coder", "is", "None", ":", "\n", "            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n", "for", "gt_box", "in", "gt_boxes", ":", "\n", "            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n", "\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.make_roi_keypoint_post_processor": [[122, 126], ["inference.Keypointer", "inference.KeypointPostProcessor"], "function", ["None"], ["result", ".", "append", "(", "boxlist", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "forward", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.keypoint_head.ROIKeypointHead.__init__": [[10, 18], ["super().__init__", "cfg.clone", "roi_keypoint_feature_extractors.make_roi_keypoint_feature_extractor", "roi_keypoint_predictors.make_roi_keypoint_predictor", "inference.make_roi_keypoint_post_processor", "loss.make_roi_keypoint_loss_evaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_feature_extractors.make_roi_keypoint_feature_extractor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.roi_keypoint_predictors.make_roi_keypoint_predictor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.inference.make_roi_keypoint_post_processor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.make_roi_keypoint_loss_evaluator"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ROIKeypointHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "self", ".", "feature_extractor", "=", "make_roi_keypoint_feature_extractor", "(", "cfg", ",", "in_channels", ")", "\n", "self", ".", "predictor", "=", "make_roi_keypoint_predictor", "(", "\n", "cfg", ",", "self", ".", "feature_extractor", ".", "out_channels", ")", "\n", "self", ".", "post_processor", "=", "make_roi_keypoint_post_processor", "(", "cfg", ")", "\n", "self", ".", "loss_evaluator", "=", "make_roi_keypoint_loss_evaluator", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.keypoint_head.ROIKeypointHead.forward": [[19, 48], ["keypoint_head.ROIKeypointHead.feature_extractor", "keypoint_head.ROIKeypointHead.predictor", "keypoint_head.ROIKeypointHead.loss_evaluator", "keypoint_head.ROIKeypointHead.post_processor", "dict", "torch.no_grad", "keypoint_head.ROIKeypointHead.loss_evaluator.subsample"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.subsample"], ["", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            features (list[Tensor]): feature-maps from possibly several levels\n            proposals (list[BoxList]): proposal boxes\n            targets (list[BoxList], optional): the ground-truth targets.\n\n        Returns:\n            x (Tensor): the result of the feature extractor\n            proposals (list[BoxList]): during training, the original proposals\n                are returned. During testing, the predicted boxlists are returned\n                with the `mask` field set\n            losses (dict[Tensor]): During training, returns the losses for the\n                head. During testing, returns an empty dict.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "proposals", "=", "self", ".", "loss_evaluator", ".", "subsample", "(", "proposals", ",", "targets", ")", "\n", "\n", "", "", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n", "kp_logits", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "kp_logits", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_kp", "=", "self", ".", "loss_evaluator", "(", "proposals", ",", "kp_logits", ")", "\n", "\n", "return", "x", ",", "proposals", ",", "dict", "(", "loss_kp", "=", "loss_kp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.keypoint_head.build_roi_keypoint_head": [[50, 52], ["keypoint_head.ROIKeypointHead"], "function", ["None"], ["", "", "def", "build_roi_keypoint_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "ROIKeypointHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.__init__": [[55, 65], ["None"], "methods", ["None"], ["\n", "", "def", "prepare_targets", "(", "self", ",", "anchors", ",", "targets", ",", "require_boxes_info", "=", "False", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "regression_targets", "=", "[", "]", "\n", "matched_targets_boxes", "=", "[", "]", "\n", "for", "anchors_per_image", ",", "targets_per_image", "in", "zip", "(", "anchors", ",", "targets", ")", ":", "\n", "            ", "matched_targets", "=", "self", ".", "match_targets_to_anchors", "(", "\n", "anchors_per_image", ",", "targets_per_image", ",", "self", ".", "copied_fields", "\n", ")", "\n", "\n", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.match_targets_to_proposals": [[66, 78], ["fcos_core.structures.boxlist_ops.boxlist_iou", "loss.KeypointRCNNLossComputation.proposal_matcher", "target.copy_with_fields.copy_with_fields.copy_with_fields", "matched_targets.add_field", "loss.KeypointRCNNLossComputation.clamp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["labels_per_image", "=", "self", ".", "generate_labels_func", "(", "matched_targets", ")", "\n", "labels_per_image", "=", "labels_per_image", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Background (negative examples)", "\n", "bg_indices", "=", "matched_idxs", "==", "Matcher", ".", "BELOW_LOW_THRESHOLD", "\n", "labels_per_image", "[", "bg_indices", "]", "=", "0", "\n", "\n", "# discard anchors that go out of the boundaries of the image", "\n", "if", "\"not_visibility\"", "in", "self", ".", "discard_cases", ":", "\n", "                ", "labels_per_image", "[", "~", "anchors_per_image", ".", "get_field", "(", "\"visibility\"", ")", "]", "=", "-", "1", "\n", "\n", "# discard indices that are between thresholds", "\n", "", "if", "\"between_thresholds\"", "in", "self", ".", "discard_cases", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets": [[79, 110], ["zip", "loss.KeypointRCNNLossComputation.match_targets_to_proposals", "loss.KeypointRCNNLossComputation.get_field", "loss.KeypointRCNNLossComputation.get_field", "labels_per_image.to.to.to", "loss.KeypointRCNNLossComputation.get_field", "loss._within_box", "labels.append", "keypoints.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.match_targets_to_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss._within_box"], ["                ", "inds_to_discard", "=", "matched_idxs", "==", "Matcher", ".", "BETWEEN_THRESHOLDS", "\n", "labels_per_image", "[", "inds_to_discard", "]", "=", "-", "1", "\n", "\n", "# compute regression targets", "\n", "", "regression_targets_per_image", "=", "self", ".", "box_coder", ".", "encode", "(", "\n", "matched_targets", ".", "bbox", ",", "anchors_per_image", ".", "bbox", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "labels_per_image", ")", "\n", "regression_targets", ".", "append", "(", "regression_targets_per_image", ")", "\n", "if", "require_boxes_info", ":", "\n", "                ", "matched_targets_boxes", ".", "append", "(", "matched_targets", ".", "bbox", ")", "\n", "", "", "if", "require_boxes_info", ":", "\n", "            ", "return", "labels", ",", "regression_targets", ",", "matched_targets_boxes", "\n", "", "else", ":", "\n", "            ", "return", "labels", ",", "regression_targets", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors (list[list[BoxList]])\n            objectness (list[Tensor])\n            box_regression (list[Tensor])\n            targets (list[BoxList])\n\n        Returns:\n            objectness_loss (Tensor)\n            box_loss (Tensor)\n        \"\"\"", "\n", "anchors", "=", "[", "cat_boxlist", "(", "anchors_per_image", ")", "for", "anchors_per_image", "in", "anchors", "]", "\n", "labels", ",", "regression_targets", "=", "self", ".", "prepare_targets", "(", "anchors", ",", "targets", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.subsample": [[111, 144], ["loss.KeypointRCNNLossComputation.prepare_targets", "loss.KeypointRCNNLossComputation.fg_bg_sampler", "list", "zip", "enumerate", "proposals_per_image.add_field", "proposals_per_image.add_field", "zip", "torch.nonzero().squeeze", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.prepare_targets", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["sampled_pos_inds", ",", "sampled_neg_inds", "=", "self", ".", "fg_bg_sampler", "(", "labels", ")", "\n", "sampled_pos_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_pos_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sampled_neg_inds", "=", "torch", ".", "nonzero", "(", "torch", ".", "cat", "(", "sampled_neg_inds", ",", "dim", "=", "0", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "sampled_inds", "=", "torch", ".", "cat", "(", "[", "sampled_pos_inds", ",", "sampled_neg_inds", "]", ",", "dim", "=", "0", ")", "\n", "\n", "objectness", ",", "box_regression", "=", "concat_box_prediction_layers", "(", "objectness", ",", "box_regression", ")", "\n", "\n", "objectness", "=", "objectness", ".", "squeeze", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "regression_targets", "=", "torch", ".", "cat", "(", "regression_targets", ",", "dim", "=", "0", ")", "\n", "\n", "box_loss", "=", "smooth_l1_loss", "(", "\n", "box_regression", "[", "sampled_pos_inds", "]", ",", "\n", "regression_targets", "[", "sampled_pos_inds", "]", ",", "\n", "beta", "=", "1.0", "/", "9", ",", "\n", "size_average", "=", "False", ",", "\n", ")", "/", "(", "sampled_inds", ".", "numel", "(", ")", ")", "\n", "\n", "objectness_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "objectness", "[", "sampled_inds", "]", ",", "labels", "[", "sampled_inds", "]", "\n", ")", "\n", "\n", "return", "objectness_loss", ",", "box_loss", "\n", "\n", "# This function should be overwritten in RetinaNet", "\n", "", "", "def", "generate_rpn_labels", "(", "matched_targets", ")", ":", "\n", "    ", "matched_idxs", "=", "matched_targets", ".", "get_field", "(", "\"matched_idxs\"", ")", "\n", "labels_per_image", "=", "matched_idxs", ">=", "0", "\n", "return", "labels_per_image", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.KeypointRCNNLossComputation.__call__": [[145, 170], ["fcos_core.modeling.utils.cat", "fcos_core.modeling.utils.cat().to", "torch.nonzero().squeeze", "keypoint_logits.view.view.view", "torch.nn.functional.cross_entropy", "proposals_per_image.get_field", "loss.project_keypoints_to_heatmap", "heatmaps.append", "torch.nonzero().squeeze.append", "heatmaps_per_image.view", "valid_per_image.view", "fcos_core.modeling.utils.cat", "torch.nonzero", "fcos_core.modeling.utils.cat.numel", "len", "keypoint_logits.view.view.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.project_keypoints_to_heatmap", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "make_rpn_loss_evaluator", "(", "cfg", ",", "box_coder", ")", ":", "\n", "    ", "matcher", "=", "Matcher", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "FG_IOU_THRESHOLD", ",", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BG_IOU_THRESHOLD", ",", "\n", "allow_low_quality_matches", "=", "True", ",", "\n", ")", "\n", "\n", "fg_bg_sampler", "=", "BalancedPositiveNegativeSampler", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "\n", ")", "\n", "\n", "loss_evaluator", "=", "RPNLossComputation", "(", "\n", "matcher", ",", "\n", "fg_bg_sampler", ",", "\n", "box_coder", ",", "\n", "generate_rpn_labels", "\n", ")", "\n", "return", "loss_evaluator", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.project_keypoints_to_heatmap": [[17, 21], ["proposals.convert.convert", "fcos_core.structures.keypoint.keypoints_to_heat_map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.keypoints_to_heat_map"], ["from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "boxlist_iou", "\n", "from", "maskrcnn_benchmark", ".", "structures", ".", "boxlist_ops", "import", "cat_boxlist", "\n", "\n", "\n", "class", "RPNLossComputation", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.cat_boxlist_with_keypoints": [[24, 37], ["all", "fcos_core.modeling.utils.cat", "boxlists[].get_fields", "fcos_core.structures.boxlist_ops.cat_boxlist", "fcos_core.structures.boxlist_ops.cat_boxlist.add_field", "boxlist.copy_with_fields", "boxlist.has_field", "boxlist.get_field"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.has_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["\n", "\n", "def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n", "generate_labels_func", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss._within_box": [[39, 52], ["None"], "function", ["None"], ["self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n", "", "def", "match_targets_to_anchors", "(", "self", ",", "anchor", ",", "target", ",", "copied_fields", "=", "[", "]", ")", ":", "\n", "        ", "match_quality_matrix", "=", "boxlist_iou", "(", "target", ",", "anchor", ")", "\n", "matched_idxs", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "# RPN doesn't need any fields from target", "\n", "# for creating the labels, so clear them all", "\n", "target", "=", "target", ".", "copy_with_fields", "(", "copied_fields", ")", "\n", "# get the targets corresponding GT for each anchor", "\n", "# NB: need to clamp the indices because we can have a single", "\n", "# GT in the image, and matched_idxs can be -2, which goes", "\n", "# out of bounds", "\n", "matched_targets", "=", "target", "[", "matched_idxs", ".", "clamp", "(", "min", "=", "0", ")", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.keypoint_head.loss.make_roi_keypoint_loss_evaluator": [[172, 184], ["fcos_core.modeling.matcher.Matcher", "fcos_core.modeling.balanced_positive_negative_sampler.BalancedPositiveNegativeSampler", "loss.KeypointRCNNLossComputation"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_modeldef.add_archs": [[4, 9], ["None"], "function", ["None"], ["def", "add_archs", "(", "archs", ")", ":", "\n", "    ", "global", "MODEL_ARCH", "\n", "for", "x", "in", "archs", ":", "\n", "        ", "assert", "x", "not", "in", "MODEL_ARCH", ",", "\"Duplicated model name {} existed\"", ".", "format", "(", "x", ")", "\n", "MODEL_ARCH", "[", "x", "]", "=", "archs", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.FPN.__init__": [[14, 42], ["torch.nn.Module.__init__", "enumerate", "conv_block", "conv_block", "fpn.FPN.add_module", "fpn.FPN.add_module", "fpn.FPN.inner_blocks.append", "fpn.FPN.layer_blocks.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_channels_list", ",", "out_channels", ",", "conv_block", ",", "top_blocks", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            in_channels_list (list[int]): number of channels for each feature map that\n                will be fed\n            out_channels (int): number of channels of the FPN representation\n            top_blocks (nn.Module or None): if provided, an extra operation will\n                be performed on the output of the last (smallest resolution)\n                FPN output, and the result will extend the result list\n        \"\"\"", "\n", "super", "(", "FPN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inner_blocks", "=", "[", "]", "\n", "self", ".", "layer_blocks", "=", "[", "]", "\n", "for", "idx", ",", "in_channels", "in", "enumerate", "(", "in_channels_list", ",", "1", ")", ":", "\n", "            ", "inner_block", "=", "\"fpn_inner{}\"", ".", "format", "(", "idx", ")", "\n", "layer_block", "=", "\"fpn_layer{}\"", ".", "format", "(", "idx", ")", "\n", "\n", "if", "in_channels", "==", "0", ":", "\n", "                ", "continue", "\n", "", "inner_block_module", "=", "conv_block", "(", "in_channels", ",", "out_channels", ",", "1", ")", "\n", "layer_block_module", "=", "conv_block", "(", "out_channels", ",", "out_channels", ",", "3", ",", "1", ")", "\n", "self", ".", "add_module", "(", "inner_block", ",", "inner_block_module", ")", "\n", "self", ".", "add_module", "(", "layer_block", ",", "layer_block_module", ")", "\n", "self", ".", "inner_blocks", ".", "append", "(", "inner_block", ")", "\n", "self", ".", "layer_blocks", ".", "append", "(", "layer_block", ")", "\n", "", "self", ".", "top_blocks", "=", "top_blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.FPN.forward": [[43, 76], ["results.append", "zip", "isinstance", "tuple", "getattr", "torch.interpolate", "torch.interpolate", "results.insert", "fpn.FPN.top_blocks", "results.extend", "isinstance", "getattr", "getattr", "fpn.FPN.top_blocks", "results.extend", "getattr", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            x (list[Tensor]): feature maps for each feature level.\n        Returns:\n            results (tuple[Tensor]): feature maps after FPN layers.\n                They are ordered from highest resolution first.\n        \"\"\"", "\n", "last_inner", "=", "getattr", "(", "self", ",", "self", ".", "inner_blocks", "[", "-", "1", "]", ")", "(", "x", "[", "-", "1", "]", ")", "\n", "results", "=", "[", "]", "\n", "results", ".", "append", "(", "getattr", "(", "self", ",", "self", ".", "layer_blocks", "[", "-", "1", "]", ")", "(", "last_inner", ")", ")", "\n", "for", "feature", ",", "inner_block", ",", "layer_block", "in", "zip", "(", "\n", "x", "[", ":", "-", "1", "]", "[", ":", ":", "-", "1", "]", ",", "self", ".", "inner_blocks", "[", ":", "-", "1", "]", "[", ":", ":", "-", "1", "]", ",", "self", ".", "layer_blocks", "[", ":", "-", "1", "]", "[", ":", ":", "-", "1", "]", "\n", ")", ":", "\n", "            ", "if", "not", "inner_block", ":", "\n", "                ", "continue", "\n", "", "inner_top_down", "=", "F", ".", "interpolate", "(", "last_inner", ",", "scale_factor", "=", "2", ",", "mode", "=", "\"nearest\"", ")", "\n", "inner_lateral", "=", "getattr", "(", "self", ",", "inner_block", ")", "(", "feature", ")", "\n", "# TODO use size instead of scale to make it robust to different sizes", "\n", "# inner_top_down = F.upsample(last_inner, size=inner_lateral.shape[-2:],", "\n", "# mode='bilinear', align_corners=False)", "\n", "last_inner", "=", "inner_lateral", "+", "inner_top_down", "\n", "results", ".", "insert", "(", "0", ",", "getattr", "(", "self", ",", "layer_block", ")", "(", "last_inner", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "top_blocks", ",", "LastLevelP6P7", ")", ":", "\n", "            ", "last_results", "=", "self", ".", "top_blocks", "(", "x", "[", "-", "1", "]", ",", "results", "[", "-", "1", "]", ")", "\n", "results", ".", "extend", "(", "last_results", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "top_blocks", ",", "LastLevelMaxPool", ")", ":", "\n", "            ", "last_results", "=", "self", ".", "top_blocks", "(", "results", "[", "-", "1", "]", ")", "\n", "results", ".", "extend", "(", "last_results", ")", "\n", "\n", "", "return", "tuple", "(", "results", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.LastLevelMaxPool.forward": [[79, 81], ["torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["        ", "return", "[", "F", ".", "max_pool2d", "(", "x", ",", "1", ",", "2", ",", "0", ")", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.LastLevelP6P7.__init__": [[87, 95], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["        ", "super", "(", "LastLevelP6P7", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p6", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "p7", "=", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "for", "module", "in", "[", "self", ".", "p6", ",", "self", ".", "p7", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "module", ".", "weight", ",", "a", "=", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0", ")", "\n", "", "self", ".", "use_P5", "=", "in_channels", "==", "out_channels", "\n", "\n", "", "def", "forward", "(", "self", ",", "c5", ",", "p5", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.LastLevelP6P7.forward": [[96, 101], ["fpn.LastLevelP6P7.p6", "fpn.LastLevelP6P7.p7", "torch.relu", "torch.relu"], "methods", ["None"], ["        ", "x", "=", "p5", "if", "self", ".", "use_P5", "else", "c5", "\n", "p6", "=", "self", ".", "p6", "(", "x", ")", "\n", "p7", "=", "self", ".", "p7", "(", "F", ".", "relu", "(", "p6", ")", ")", "\n", "return", "[", "p6", ",", "p7", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet.__init__": [[82, 133], ["torch.nn.Module.__init__", "stem_module", "resnet.ResNet._freeze_backbone", "resnet._make_stage", "resnet.ResNet.add_module", "resnet.ResNet.stages.append", "str", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2._freeze_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet._make_stage"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# If we want to use the cfg in forward(), then we should make a copy", "\n", "# of it and store it for later use:", "\n", "# self.cfg = cfg.clone()", "\n", "\n", "# Translate string names to implementations", "\n", "stem_module", "=", "_STEM_MODULES", "[", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_FUNC", "]", "\n", "stage_specs", "=", "_STAGE_SPECS", "[", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "]", "\n", "transformation_module", "=", "_TRANSFORMATION_MODULES", "[", "cfg", ".", "MODEL", ".", "RESNETS", ".", "TRANS_FUNC", "]", "\n", "\n", "# Construct the stem module", "\n", "self", ".", "stem", "=", "stem_module", "(", "cfg", ")", "\n", "\n", "# Constuct the specified ResNet stages", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n", "width_per_group", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "\n", "in_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "stage2_bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "stage2_out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "self", ".", "stages", "=", "[", "]", "\n", "self", ".", "return_features", "=", "{", "}", "\n", "for", "stage_spec", "in", "stage_specs", ":", "\n", "            ", "name", "=", "\"layer\"", "+", "str", "(", "stage_spec", ".", "index", ")", "\n", "stage2_relative_factor", "=", "2", "**", "(", "stage_spec", ".", "index", "-", "1", ")", "\n", "bottleneck_channels", "=", "stage2_bottleneck_channels", "*", "stage2_relative_factor", "\n", "out_channels", "=", "stage2_out_channels", "*", "stage2_relative_factor", "\n", "stage_with_dcn", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STAGE_WITH_DCN", "[", "stage_spec", ".", "index", "-", "1", "]", "\n", "module", "=", "_make_stage", "(", "\n", "transformation_module", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "stage_spec", ".", "block_count", ",", "\n", "num_groups", ",", "\n", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", ",", "\n", "first_stride", "=", "int", "(", "stage_spec", ".", "index", ">", "1", ")", "+", "1", ",", "\n", "dcn_config", "=", "{", "\n", "\"stage_with_dcn\"", ":", "stage_with_dcn", ",", "\n", "\"with_modulated_dcn\"", ":", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WITH_MODULATED_DCN", ",", "\n", "\"deformable_groups\"", ":", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORMABLE_GROUPS", ",", "\n", "}", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "self", ".", "add_module", "(", "name", ",", "module", ")", "\n", "self", ".", "stages", ".", "append", "(", "name", ")", "\n", "self", ".", "return_features", "[", "name", "]", "=", "stage_spec", ".", "return_features", "\n", "\n", "# Optionally freeze (requires_grad=False) parts of the backbone", "\n", "", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_CONV_BODY_AT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet._freeze_backbone": [[134, 144], ["range", "getattr.parameters", "getattr", "str"], "methods", ["None"], ["", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "if", "freeze_at", "<", "0", ":", "\n", "            ", "return", "\n", "", "for", "stage_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "if", "stage_index", "==", "0", ":", "\n", "                ", "m", "=", "self", ".", "stem", "# stage 0 is the stem", "\n", "", "else", ":", "\n", "                ", "m", "=", "getattr", "(", "self", ",", "\"layer\"", "+", "str", "(", "stage_index", ")", ")", "\n", "", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet.forward": [[145, 153], ["resnet.ResNet.stem", "getattr", "outputs.append"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "for", "stage_name", "in", "self", ".", "stages", ":", "\n", "            ", "x", "=", "getattr", "(", "self", ",", "stage_name", ")", "(", "x", ")", "\n", "if", "self", ".", "return_features", "[", "stage_name", "]", ":", "\n", "                ", "outputs", ".", "append", "(", "x", ")", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNetHead.__init__": [[156, 200], ["torch.nn.Module.__init__", "resnet._make_stage", "resnet.ResNetHead.add_module", "resnet.ResNetHead.stages.append", "str", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet._make_stage"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "block_module", ",", "\n", "stages", ",", "\n", "num_groups", "=", "1", ",", "\n", "width_per_group", "=", "64", ",", "\n", "stride_in_1x1", "=", "True", ",", "\n", "stride_init", "=", "None", ",", "\n", "res2_out_channels", "=", "256", ",", "\n", "dilation", "=", "1", ",", "\n", "dcn_config", "=", "{", "}", "\n", ")", ":", "\n", "        ", "super", "(", "ResNetHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "stage2_relative_factor", "=", "2", "**", "(", "stages", "[", "0", "]", ".", "index", "-", "1", ")", "\n", "stage2_bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "out_channels", "=", "res2_out_channels", "*", "stage2_relative_factor", "\n", "in_channels", "=", "out_channels", "//", "2", "\n", "bottleneck_channels", "=", "stage2_bottleneck_channels", "*", "stage2_relative_factor", "\n", "\n", "block_module", "=", "_TRANSFORMATION_MODULES", "[", "block_module", "]", "\n", "\n", "self", ".", "stages", "=", "[", "]", "\n", "stride", "=", "stride_init", "\n", "for", "stage", "in", "stages", ":", "\n", "            ", "name", "=", "\"layer\"", "+", "str", "(", "stage", ".", "index", ")", "\n", "if", "not", "stride", ":", "\n", "                ", "stride", "=", "int", "(", "stage", ".", "index", ">", "1", ")", "+", "1", "\n", "", "module", "=", "_make_stage", "(", "\n", "block_module", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "stage", ".", "block_count", ",", "\n", "num_groups", ",", "\n", "stride_in_1x1", ",", "\n", "first_stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dcn_config", "=", "dcn_config", "\n", ")", "\n", "stride", "=", "None", "\n", "self", ".", "add_module", "(", "name", ",", "module", ")", "\n", "self", ".", "stages", ".", "append", "(", "name", ")", "\n", "", "self", ".", "out_channels", "=", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNetHead.forward": [[201, 205], ["getattr"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "stage", "in", "self", ".", "stages", ":", "\n", "            ", "x", "=", "getattr", "(", "self", ",", "stage", ")", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.Bottleneck.__init__": [[240, 323], ["torch.nn.Module.__init__", "fcos_core.layers.Conv2d", "norm_func", "dcn_config.get", "norm_func", "fcos_core.layers.Conv2d", "norm_func", "torch.nn.Sequential", "torch.nn.Sequential", "dcn_config.get", "dcn_config.get", "fcos_core.layers.DFConv2d", "fcos_core.layers.Conv2d", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_uniform_", "fcos_core.layers.Conv2d", "norm_func", "modules.modules", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_uniform_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "num_groups", ",", "\n", "stride_in_1x1", ",", "\n", "stride", ",", "\n", "dilation", ",", "\n", "norm_func", ",", "\n", "dcn_config", "\n", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "downsample", "=", "None", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "down_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "down_stride", ",", "bias", "=", "False", "\n", ")", ",", "\n", "norm_func", "(", "out_channels", ")", ",", "\n", ")", "\n", "for", "modules", "in", "[", "self", ".", "downsample", ",", "]", ":", "\n", "                ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "l", ",", "Conv2d", ")", ":", "\n", "                        ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n", "", "", "", "", "if", "dilation", ">", "1", ":", "\n", "            ", "stride", "=", "1", "# reset to be 1", "\n", "\n", "# The original MSRA ResNet models have stride in the first 1x1 conv", "\n", "# The subsequent fb.torch.resnet and Caffe2 ResNe[X]t implementations have", "\n", "# stride in the 3x3 conv", "\n", "", "stride_1x1", ",", "stride_3x3", "=", "(", "stride", ",", "1", ")", "if", "stride_in_1x1", "else", "(", "1", ",", "stride", ")", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride_1x1", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "bn1", "=", "norm_func", "(", "bottleneck_channels", ")", "\n", "# TODO: specify init for the above", "\n", "with_dcn", "=", "dcn_config", ".", "get", "(", "\"stage_with_dcn\"", ",", "False", ")", "\n", "if", "with_dcn", ":", "\n", "            ", "deformable_groups", "=", "dcn_config", ".", "get", "(", "\"deformable_groups\"", ",", "1", ")", "\n", "with_modulated_dcn", "=", "dcn_config", ".", "get", "(", "\"with_modulated_dcn\"", ",", "False", ")", "\n", "self", ".", "conv2", "=", "DFConv2d", "(", "\n", "bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "with_modulated_dcn", "=", "with_modulated_dcn", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilation", "=", "dilation", ",", "\n", "deformable_groups", "=", "deformable_groups", ",", "\n", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "padding", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilation", "=", "dilation", "\n", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "conv2", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n", "", "self", ".", "bn2", "=", "norm_func", "(", "bottleneck_channels", ")", "\n", "\n", "self", ".", "conv3", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn3", "=", "norm_func", "(", "out_channels", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv1", ",", "self", ".", "conv3", ",", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.Bottleneck.forward": [[324, 345], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "torch.relu_", "torch.relu_", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "torch.relu_", "torch.relu_", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "torch.relu_", "torch.relu_", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BaseStem.__init__": [[348, 360], ["torch.nn.Module.__init__", "fcos_core.layers.Conv2d", "norm_func", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_uniform_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "norm_func", ")", ":", "\n", "        ", "super", "(", "BaseStem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "3", ",", "out_channels", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn1", "=", "norm_func", "(", "out_channels", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv1", ",", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BaseStem.forward": [[361, 367], ["resnet.BaseStem.conv1", "resnet.BaseStem.bn1", "torch.relu_", "torch.relu_", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu_", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BottleneckWithFixedBatchNorm.__init__": [[370, 391], ["resnet.Bottleneck.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "num_groups", "=", "1", ",", "\n", "stride_in_1x1", "=", "True", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "dcn_config", "=", "{", "}", "\n", ")", ":", "\n", "        ", "super", "(", "BottleneckWithFixedBatchNorm", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "bottleneck_channels", "=", "bottleneck_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_groups", "=", "num_groups", ",", "\n", "stride_in_1x1", "=", "stride_in_1x1", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "norm_func", "=", "FrozenBatchNorm2d", ",", "\n", "dcn_config", "=", "dcn_config", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.StemWithFixedBatchNorm.__init__": [[395, 398], ["resnet.BaseStem.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "StemWithFixedBatchNorm", ",", "self", ")", ".", "__init__", "(", "\n", "cfg", ",", "norm_func", "=", "FrozenBatchNorm2d", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BottleneckWithGN.__init__": [[402, 423], ["resnet.Bottleneck.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "num_groups", "=", "1", ",", "\n", "stride_in_1x1", "=", "True", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "dcn_config", "=", "{", "}", "\n", ")", ":", "\n", "        ", "super", "(", "BottleneckWithGN", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "bottleneck_channels", "=", "bottleneck_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_groups", "=", "num_groups", ",", "\n", "stride_in_1x1", "=", "stride_in_1x1", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "norm_func", "=", "group_norm", ",", "\n", "dcn_config", "=", "dcn_config", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.StemWithGN.__init__": [[427, 429], ["resnet.BaseStem.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "StemWithGN", ",", "self", ")", ".", "__init__", "(", "cfg", ",", "norm_func", "=", "group_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet._make_stage": [[207, 237], ["range", "torch.nn.Sequential", "blocks.append", "transformation_module"], "function", ["None"], ["", "", "def", "_make_stage", "(", "\n", "transformation_module", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "block_count", ",", "\n", "num_groups", ",", "\n", "stride_in_1x1", ",", "\n", "first_stride", ",", "\n", "dilation", "=", "1", ",", "\n", "dcn_config", "=", "{", "}", "\n", ")", ":", "\n", "    ", "blocks", "=", "[", "]", "\n", "stride", "=", "first_stride", "\n", "for", "_", "in", "range", "(", "block_count", ")", ":", "\n", "        ", "blocks", ".", "append", "(", "\n", "transformation_module", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "num_groups", ",", "\n", "stride_in_1x1", ",", "\n", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dcn_config", "=", "dcn_config", "\n", ")", "\n", ")", "\n", "stride", "=", "1", "\n", "in_channels", "=", "out_channels", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.Identity.__init__": [[196, 211], ["torch.Module.__init__", "fbnet_builder.ConvBNRelu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "C_in", ",", "C_out", ",", "stride", ")", ":", "\n", "        ", "super", "(", "Identity", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "(", "\n", "ConvBNRelu", "(", "\n", "C_in", ",", "\n", "C_out", ",", "\n", "kernel", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "pad", "=", "0", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", ",", "\n", "bn_type", "=", "\"bn\"", ",", "\n", ")", "\n", "if", "C_in", "!=", "C_out", "or", "stride", "!=", "1", "\n", "else", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.Identity.forward": [[213, 219], ["fbnet_builder.Identity.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "conv", ":", "\n", "            ", "out", "=", "self", ".", "conv", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.CascadeConv3x3.__init__": [[222, 233], ["torch.Sequential.__init__", "fcos_core.layers.Conv2d", "fcos_core.layers.BatchNorm2d", "torch.ReLU", "torch.ReLU", "fcos_core.layers.Conv2d", "fcos_core.layers.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "C_in", ",", "C_out", ",", "stride", ")", ":", "\n", "        ", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "ops", "=", "[", "\n", "Conv2d", "(", "C_in", ",", "C_in", ",", "3", ",", "stride", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "C_in", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv2d", "(", "C_in", ",", "C_out", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "C_out", ")", ",", "\n", "]", "\n", "super", "(", "CascadeConv3x3", ",", "self", ")", ".", "__init__", "(", "*", "ops", ")", "\n", "self", ".", "res_connect", "=", "(", "stride", "==", "1", ")", "and", "(", "C_in", "==", "C_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.CascadeConv3x3.forward": [[234, 239], ["super().forward"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "super", "(", "CascadeConv3x3", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "if", "self", ".", "res_connect", ":", "\n", "            ", "y", "+=", "x", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.Shift.__init__": [[242, 268], ["torch.Module.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "fbnet_builder.Shift.register_parameter", "torch.Parameter", "torch.Parameter", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "C", ",", "kernel_size", ",", "stride", ",", "padding", ")", ":", "\n", "        ", "super", "(", "Shift", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "C", "=", "C", "\n", "kernel", "=", "torch", ".", "zeros", "(", "(", "C", ",", "1", ",", "kernel_size", ",", "kernel_size", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "ch_idx", "=", "0", "\n", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dilation", "=", "1", "\n", "\n", "hks", "=", "kernel_size", "//", "2", "\n", "ksq", "=", "kernel_size", "**", "2", "\n", "\n", "for", "i", "in", "range", "(", "kernel_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "kernel_size", ")", ":", "\n", "                ", "if", "i", "==", "hks", "and", "j", "==", "hks", ":", "\n", "                    ", "num_ch", "=", "C", "//", "ksq", "+", "C", "%", "ksq", "\n", "", "else", ":", "\n", "                    ", "num_ch", "=", "C", "//", "ksq", "\n", "", "kernel", "[", "ch_idx", ":", "ch_idx", "+", "num_ch", ",", "0", ",", "i", ",", "j", "]", "=", "1", "\n", "ch_idx", "+=", "num_ch", "\n", "\n", "", "", "self", ".", "register_parameter", "(", "\"bias\"", ",", "None", ")", "\n", "self", ".", "kernel", "=", "nn", ".", "Parameter", "(", "kernel", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.Shift.forward": [[269, 293], ["fcos_core.layers.misc._NewEmptyTensorOp.apply", "x.numel", "torch.functional.conv2d", "torch.functional.conv2d", "zip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "return", "nn", ".", "functional", ".", "conv2d", "(", "\n", "x", ",", "\n", "self", ".", "kernel", ",", "\n", "self", ".", "bias", ",", "\n", "(", "self", ".", "stride", ",", "self", ".", "stride", ")", ",", "\n", "(", "self", ".", "padding", ",", "self", ".", "padding", ")", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "C", ",", "# groups", "\n", ")", "\n", "\n", "", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "d", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "d", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "\n", "(", "self", ".", "padding", ",", "self", ".", "dilation", ")", ",", "\n", "(", "self", ".", "dilation", ",", "self", ".", "dilation", ")", ",", "\n", "(", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", ")", ",", "\n", "(", "self", ".", "stride", ",", "self", ".", "stride", ")", ",", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "C", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.ShiftBlock5x5.__init__": [[296, 314], ["fbnet_builder._get_divisible_by", "torch.Sequential.__init__", "fcos_core.layers.Conv2d", "fcos_core.layers.BatchNorm2d", "torch.ReLU", "torch.ReLU", "fbnet_builder.Shift", "fcos_core.layers.Conv2d", "fcos_core.layers.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._get_divisible_by", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "C_in", ",", "C_out", ",", "expansion", ",", "stride", ")", ":", "\n", "        ", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "self", ".", "res_connect", "=", "(", "stride", "==", "1", ")", "and", "(", "C_in", "==", "C_out", ")", "\n", "\n", "C_mid", "=", "_get_divisible_by", "(", "C_in", "*", "expansion", ",", "8", ",", "8", ")", "\n", "\n", "ops", "=", "[", "\n", "# pw", "\n", "Conv2d", "(", "C_in", ",", "C_mid", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "C_mid", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "# shift", "\n", "Shift", "(", "C_mid", ",", "5", ",", "stride", ",", "2", ")", ",", "\n", "# pw-linear", "\n", "Conv2d", "(", "C_mid", ",", "C_out", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "C_out", ")", ",", "\n", "]", "\n", "super", "(", "ShiftBlock5x5", ",", "self", ")", ".", "__init__", "(", "*", "ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.ShiftBlock5x5.forward": [[315, 320], ["super().forward"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "super", "(", "ShiftBlock5x5", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "if", "self", ".", "res_connect", ":", "\n", "            ", "y", "+=", "x", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.ChannelShuffle.__init__": [[323, 326], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "groups", ")", ":", "\n", "        ", "super", "(", "ChannelShuffle", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.ChannelShuffle.forward": [[327, 339], ["x.size", "x.view().permute().contiguous().view", "x.view().permute().contiguous", "x.view().permute", "x.view", "int"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]\"\"\"", "\n", "N", ",", "C", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "g", "=", "self", ".", "groups", "\n", "assert", "C", "%", "g", "==", "0", ",", "\"Incompatible group size {} for input channel {}\"", ".", "format", "(", "\n", "g", ",", "C", "\n", ")", "\n", "return", "(", "\n", "x", ".", "view", "(", "N", ",", "g", ",", "int", "(", "C", "/", "g", ")", ",", "H", ",", "W", ")", "\n", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "N", ",", "C", ",", "H", ",", "W", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.ConvBNRelu.__init__": [[343, 395], ["torch.Sequential.__init__", "isinstance", "fcos_core.layers.Conv2d", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "fbnet_builder.ConvBNRelu.add_module", "torch.init.constant_", "torch.init.constant_", "fcos_core.layers.BatchNorm2d", "fbnet_builder.ConvBNRelu.add_module", "fbnet_builder.ConvBNRelu.add_module", "len", "torch.GroupNorm", "torch.GroupNorm", "torch.ReLU", "torch.ReLU", "fcos_core.layers.FrozenBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_depth", ",", "\n", "output_depth", ",", "\n", "kernel", ",", "\n", "stride", ",", "\n", "pad", ",", "\n", "no_bias", ",", "\n", "use_relu", ",", "\n", "bn_type", ",", "\n", "group", "=", "1", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "ConvBNRelu", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "use_relu", "in", "[", "\"relu\"", ",", "None", "]", "\n", "if", "isinstance", "(", "bn_type", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "bn_type", ")", "==", "2", "\n", "assert", "bn_type", "[", "0", "]", "==", "\"gn\"", "\n", "gn_group", "=", "bn_type", "[", "1", "]", "\n", "bn_type", "=", "bn_type", "[", "0", "]", "\n", "", "assert", "bn_type", "in", "[", "\"bn\"", ",", "\"af\"", ",", "\"gn\"", ",", "None", "]", "\n", "assert", "stride", "in", "[", "1", ",", "2", ",", "4", "]", "\n", "\n", "op", "=", "Conv2d", "(", "\n", "input_depth", ",", "\n", "output_depth", ",", "\n", "kernel_size", "=", "kernel", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "pad", ",", "\n", "bias", "=", "not", "no_bias", ",", "\n", "groups", "=", "group", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "op", ".", "weight", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "if", "op", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "op", ".", "bias", ",", "0.0", ")", "\n", "", "self", ".", "add_module", "(", "\"conv\"", ",", "op", ")", "\n", "\n", "if", "bn_type", "==", "\"bn\"", ":", "\n", "            ", "bn_op", "=", "BatchNorm2d", "(", "output_depth", ")", "\n", "", "elif", "bn_type", "==", "\"gn\"", ":", "\n", "            ", "bn_op", "=", "nn", ".", "GroupNorm", "(", "num_groups", "=", "gn_group", ",", "num_channels", "=", "output_depth", ")", "\n", "", "elif", "bn_type", "==", "\"af\"", ":", "\n", "            ", "bn_op", "=", "FrozenBatchNorm2d", "(", "output_depth", ")", "\n", "", "if", "bn_type", "is", "not", "None", ":", "\n", "            ", "self", ".", "add_module", "(", "\"bn\"", ",", "bn_op", ")", "\n", "\n", "", "if", "use_relu", "==", "\"relu\"", ":", "\n", "            ", "self", ".", "add_module", "(", "\"relu\"", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.SEModule.__init__": [[400, 408], ["torch.Module.__init__", "max", "fcos_core.layers.Conv2d", "fcos_core.layers.Conv2d", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.ReLU", "torch.ReLU", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "C", ")", ":", "\n", "        ", "super", "(", "SEModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "mid", "=", "max", "(", "C", "//", "self", ".", "reduction", ",", "8", ")", "\n", "conv1", "=", "Conv2d", "(", "C", ",", "mid", ",", "1", ",", "1", ",", "0", ")", "\n", "conv2", "=", "Conv2d", "(", "mid", ",", "C", ",", "1", ",", "1", ",", "0", ")", "\n", "\n", "self", ".", "op", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", ",", "conv1", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "conv2", ",", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.SEModule.forward": [[410, 412], ["fbnet_builder.SEModule.op"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "self", ".", "op", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.Upsample.__init__": [[415, 420], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale_factor", ",", "mode", ",", "align_corners", "=", "None", ")", ":", "\n", "        ", "super", "(", "Upsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale_factor", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "align_corners", "=", "align_corners", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.Upsample.forward": [[421, 425], ["fcos_core.layers.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "interpolate", "(", "\n", "x", ",", "scale_factor", "=", "self", ".", "scale", ",", "mode", "=", "self", ".", "mode", ",", "\n", "align_corners", "=", "self", ".", "align_corners", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.IRFBlock.__init__": [[446, 548], ["torch.Module.__init__", "int", "fbnet_builder._get_divisible_by", "fbnet_builder.ConvBNRelu", "fbnet_builder._get_upsample_op", "fbnet_builder.ConvBNRelu", "torch.Sequential", "torch.Sequential", "fbnet_builder.ChannelShuffle", "fbnet_builder.SEModule", "torch.Sequential", "torch.Sequential", "fbnet_builder.ConvBNRelu", "fbnet_builder.ConvBNRelu", "torch.Sequential", "torch.Sequential", "fbnet_builder.ConvBNRelu", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._get_divisible_by", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._get_upsample_op"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_depth", ",", "\n", "output_depth", ",", "\n", "expansion", ",", "\n", "stride", ",", "\n", "bn_type", "=", "\"bn\"", ",", "\n", "kernel", "=", "3", ",", "\n", "width_divisor", "=", "1", ",", "\n", "shuffle_type", "=", "None", ",", "\n", "pw_group", "=", "1", ",", "\n", "se", "=", "False", ",", "\n", "cdw", "=", "False", ",", "\n", "dw_skip_bn", "=", "False", ",", "\n", "dw_skip_relu", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IRFBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "kernel", "in", "[", "1", ",", "3", ",", "5", ",", "7", "]", ",", "kernel", "\n", "\n", "self", ".", "use_res_connect", "=", "stride", "==", "1", "and", "input_depth", "==", "output_depth", "\n", "self", ".", "output_depth", "=", "output_depth", "\n", "\n", "mid_depth", "=", "int", "(", "input_depth", "*", "expansion", ")", "\n", "mid_depth", "=", "_get_divisible_by", "(", "mid_depth", ",", "width_divisor", ",", "width_divisor", ")", "\n", "\n", "# pw", "\n", "self", ".", "pw", "=", "ConvBNRelu", "(", "\n", "input_depth", ",", "\n", "mid_depth", ",", "\n", "kernel", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "pad", "=", "0", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", ",", "\n", "bn_type", "=", "bn_type", ",", "\n", "group", "=", "pw_group", ",", "\n", ")", "\n", "\n", "# negative stride to do upsampling", "\n", "self", ".", "upscale", ",", "stride", "=", "_get_upsample_op", "(", "stride", ")", "\n", "\n", "# dw", "\n", "if", "kernel", "==", "1", ":", "\n", "            ", "self", ".", "dw", "=", "nn", ".", "Sequential", "(", ")", "\n", "", "elif", "cdw", ":", "\n", "            ", "dw1", "=", "ConvBNRelu", "(", "\n", "mid_depth", ",", "\n", "mid_depth", ",", "\n", "kernel", "=", "kernel", ",", "\n", "stride", "=", "stride", ",", "\n", "pad", "=", "(", "kernel", "//", "2", ")", ",", "\n", "group", "=", "mid_depth", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", ",", "\n", "bn_type", "=", "bn_type", ",", "\n", ")", "\n", "dw2", "=", "ConvBNRelu", "(", "\n", "mid_depth", ",", "\n", "mid_depth", ",", "\n", "kernel", "=", "kernel", ",", "\n", "stride", "=", "1", ",", "\n", "pad", "=", "(", "kernel", "//", "2", ")", ",", "\n", "group", "=", "mid_depth", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", "if", "not", "dw_skip_relu", "else", "None", ",", "\n", "bn_type", "=", "bn_type", "if", "not", "dw_skip_bn", "else", "None", ",", "\n", ")", "\n", "self", ".", "dw", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"dw1\"", ",", "dw1", ")", ",", "(", "\"dw2\"", ",", "dw2", ")", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dw", "=", "ConvBNRelu", "(", "\n", "mid_depth", ",", "\n", "mid_depth", ",", "\n", "kernel", "=", "kernel", ",", "\n", "stride", "=", "stride", ",", "\n", "pad", "=", "(", "kernel", "//", "2", ")", ",", "\n", "group", "=", "mid_depth", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", "if", "not", "dw_skip_relu", "else", "None", ",", "\n", "bn_type", "=", "bn_type", "if", "not", "dw_skip_bn", "else", "None", ",", "\n", ")", "\n", "\n", "# pw-linear", "\n", "", "self", ".", "pwl", "=", "ConvBNRelu", "(", "\n", "mid_depth", ",", "\n", "output_depth", ",", "\n", "kernel", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "pad", "=", "0", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "None", ",", "\n", "bn_type", "=", "bn_type", ",", "\n", "group", "=", "pw_group", ",", "\n", ")", "\n", "\n", "self", ".", "shuffle_type", "=", "shuffle_type", "\n", "if", "shuffle_type", "is", "not", "None", ":", "\n", "            ", "self", ".", "shuffle", "=", "ChannelShuffle", "(", "pw_group", ")", "\n", "\n", "", "self", ".", "se4", "=", "SEModule", "(", "output_depth", ")", "if", "se", "else", "nn", ".", "Sequential", "(", ")", "\n", "\n", "self", ".", "output_depth", "=", "output_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.IRFBlock.forward": [[549, 561], ["fbnet_builder.IRFBlock.pw", "fbnet_builder.IRFBlock.dw", "fbnet_builder.IRFBlock.pwl", "fbnet_builder.IRFBlock.se4", "fbnet_builder.IRFBlock.shuffle", "fbnet_builder.IRFBlock.upscale"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "pw", "(", "x", ")", "\n", "if", "self", ".", "shuffle_type", "==", "\"mid\"", ":", "\n", "            ", "y", "=", "self", ".", "shuffle", "(", "y", ")", "\n", "", "if", "self", ".", "upscale", "is", "not", "None", ":", "\n", "            ", "y", "=", "self", ".", "upscale", "(", "y", ")", "\n", "", "y", "=", "self", ".", "dw", "(", "y", ")", "\n", "y", "=", "self", ".", "pwl", "(", "y", ")", "\n", "if", "self", ".", "use_res_connect", ":", "\n", "            ", "y", "+=", "x", "\n", "", "y", "=", "self", ".", "se4", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.__init__": [[694, 708], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "width_ratio", ",", "\n", "bn_type", "=", "\"bn\"", ",", "\n", "width_divisor", "=", "1", ",", "\n", "dw_skip_bn", "=", "False", ",", "\n", "dw_skip_relu", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "width_ratio", "=", "width_ratio", "\n", "self", ".", "last_depth", "=", "-", "1", "\n", "self", ".", "bn_type", "=", "bn_type", "\n", "self", ".", "width_divisor", "=", "width_divisor", "\n", "self", ".", "dw_skip_bn", "=", "dw_skip_bn", "\n", "self", ".", "dw_skip_relu", "=", "dw_skip_relu", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_first": [[709, 731], ["fbnet_builder.FBNetBuilder._get_divisible_width", "fbnet_builder.ConvBNRelu", "len", "int", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder._get_divisible_width"], ["", "def", "add_first", "(", "self", ",", "stage_info", ",", "dim_in", "=", "3", ",", "pad", "=", "True", ")", ":", "\n", "# stage_info: [c, s, kernel]", "\n", "        ", "assert", "len", "(", "stage_info", ")", ">=", "2", "\n", "channel", "=", "stage_info", "[", "0", "]", "\n", "stride", "=", "stage_info", "[", "1", "]", "\n", "out_depth", "=", "self", ".", "_get_divisible_width", "(", "int", "(", "channel", "*", "self", ".", "width_ratio", ")", ")", "\n", "kernel", "=", "3", "\n", "if", "len", "(", "stage_info", ")", ">", "2", ":", "\n", "            ", "kernel", "=", "stage_info", "[", "2", "]", "\n", "\n", "", "out", "=", "ConvBNRelu", "(", "\n", "dim_in", ",", "\n", "out_depth", ",", "\n", "kernel", "=", "kernel", ",", "\n", "stride", "=", "stride", ",", "\n", "pad", "=", "kernel", "//", "2", "if", "pad", "else", "0", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", ",", "\n", "bn_type", "=", "self", ".", "bn_type", ",", "\n", ")", "\n", "self", ".", "last_depth", "=", "out_depth", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_blocks": [[732, 753], ["collections.OrderedDict", "torch.Sequential", "torch.Sequential", "isinstance", "all", "fbnet_builder.FBNetBuilder.add_ir_block", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_ir_block"], ["", "def", "add_blocks", "(", "self", ",", "blocks", ")", ":", "\n", "        ", "\"\"\" blocks: [{}, {}, ...]\n        \"\"\"", "\n", "assert", "isinstance", "(", "blocks", ",", "list", ")", "and", "all", "(", "\n", "isinstance", "(", "x", ",", "dict", ")", "for", "x", "in", "blocks", "\n", ")", ",", "blocks", "\n", "\n", "modules", "=", "OrderedDict", "(", ")", "\n", "for", "block", "in", "blocks", ":", "\n", "            ", "stage_idx", "=", "block", "[", "\"stage_idx\"", "]", "\n", "block_idx", "=", "block", "[", "\"block_idx\"", "]", "\n", "block_op_type", "=", "block", "[", "\"block_op_type\"", "]", "\n", "tcns", "=", "block", "[", "\"block\"", "]", "\n", "n", "=", "tcns", "[", "2", "]", "\n", "assert", "n", "==", "1", "\n", "nnblock", "=", "self", ".", "add_ir_block", "(", "tcns", ",", "[", "block_op_type", "]", ")", "\n", "nn_name", "=", "\"xif{}_{}\"", ".", "format", "(", "stage_idx", ",", "block_idx", ")", "\n", "assert", "nn_name", "not", "in", "modules", "\n", "modules", "[", "nn_name", "]", "=", "nnblock", "\n", "", "ret", "=", "nn", ".", "Sequential", "(", "modules", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_last": [[754, 790], ["fbnet_builder.FBNetBuilder._get_divisible_width", "fbnet_builder.ConvBNRelu", "len", "torch.Sequential", "torch.Sequential", "int", "int", "torch.Sequential", "torch.Sequential", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder._get_divisible_width"], ["", "def", "add_last", "(", "self", ",", "stage_info", ")", ":", "\n", "        ", "\"\"\" skip last layer if channel_scale == 0\n            use the same output channel if channel_scale < 0\n        \"\"\"", "\n", "assert", "len", "(", "stage_info", ")", "==", "2", "\n", "channels", "=", "stage_info", "[", "0", "]", "\n", "channel_scale", "=", "stage_info", "[", "1", "]", "\n", "\n", "if", "channel_scale", "==", "0.0", ":", "\n", "            ", "return", "nn", ".", "Sequential", "(", ")", "\n", "\n", "", "if", "channel_scale", ">", "0", ":", "\n", "            ", "last_channel", "=", "(", "\n", "int", "(", "channels", "*", "self", ".", "width_ratio", ")", "if", "self", ".", "width_ratio", ">", "1.0", "else", "channels", "\n", ")", "\n", "last_channel", "=", "int", "(", "last_channel", "*", "channel_scale", ")", "\n", "", "else", ":", "\n", "            ", "last_channel", "=", "int", "(", "self", ".", "last_depth", "*", "(", "-", "channel_scale", ")", ")", "\n", "", "last_channel", "=", "self", ".", "_get_divisible_width", "(", "last_channel", ")", "\n", "\n", "if", "last_channel", "==", "0", ":", "\n", "            ", "return", "nn", ".", "Sequential", "(", ")", "\n", "\n", "", "dim_in", "=", "self", ".", "last_depth", "\n", "ret", "=", "ConvBNRelu", "(", "\n", "dim_in", ",", "\n", "last_channel", ",", "\n", "kernel", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "pad", "=", "0", ",", "\n", "no_bias", "=", "1", ",", "\n", "use_relu", "=", "\"relu\"", ",", "\n", "bn_type", "=", "self", ".", "bn_type", ",", "\n", ")", "\n", "self", ".", "last_depth", "=", "last_channel", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder._add_ir_block": [[795, 810], ["None"], "methods", ["None"], ["", "def", "_add_ir_block", "(", "\n", "self", ",", "dim_in", ",", "dim_out", ",", "stride", ",", "expand_ratio", ",", "block_op_type", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "ret", "=", "PRIMITIVES", "[", "block_op_type", "]", "(", "\n", "dim_in", ",", "\n", "dim_out", ",", "\n", "expansion", "=", "expand_ratio", ",", "\n", "stride", "=", "stride", ",", "\n", "bn_type", "=", "self", ".", "bn_type", ",", "\n", "width_divisor", "=", "self", ".", "width_divisor", ",", "\n", "dw_skip_bn", "=", "self", ".", "dw_skip_bn", ",", "\n", "dw_skip_relu", "=", "self", ".", "dw_skip_relu", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "ret", ",", "ret", ".", "output_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_ir_block": [[811, 826], ["fbnet_builder.FBNetBuilder._get_divisible_width", "fbnet_builder.FBNetBuilder._add_ir_block", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder._get_divisible_width", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder._add_ir_block"], ["", "def", "add_ir_block", "(", "self", ",", "tcns", ",", "block_op_types", ",", "**", "kwargs", ")", ":", "\n", "        ", "t", ",", "c", ",", "n", ",", "s", "=", "tcns", "\n", "assert", "n", "==", "1", "\n", "out_depth", "=", "self", ".", "_get_divisible_width", "(", "int", "(", "c", "*", "self", ".", "width_ratio", ")", ")", "\n", "dim_in", "=", "self", ".", "last_depth", "\n", "op", ",", "ret_depth", "=", "self", ".", "_add_ir_block", "(", "\n", "dim_in", ",", "\n", "out_depth", ",", "\n", "stride", "=", "s", ",", "\n", "expand_ratio", "=", "t", ",", "\n", "block_op_type", "=", "block_op_types", "[", "0", "]", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "last_depth", "=", "ret_depth", "\n", "return", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder._get_divisible_width": [[827, 830], ["fbnet_builder._get_divisible_by", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._get_divisible_by"], ["", "def", "_get_divisible_width", "(", "self", ",", "width", ")", ":", "\n", "        ", "ret", "=", "_get_divisible_by", "(", "int", "(", "width", ")", ",", "self", ".", "width_divisor", ",", "self", ".", "width_divisor", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._py2_round": [[26, 28], ["math.floor", "math.ceil"], "function", ["None"], ["def", "_py2_round", "(", "x", ")", ":", "\n", "    ", "return", "math", ".", "floor", "(", "x", "+", "0.5", ")", "if", "x", ">=", "0.0", "else", "math", ".", "ceil", "(", "x", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._get_divisible_by": [[30, 35], ["int", "int", "fbnet_builder._py2_round"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._py2_round"], ["", "def", "_get_divisible_by", "(", "num", ",", "divisible_by", ",", "min_val", ")", ":", "\n", "    ", "ret", "=", "int", "(", "num", ")", "\n", "if", "divisible_by", ">", "0", "and", "num", "%", "divisible_by", "!=", "0", ":", "\n", "        ", "ret", "=", "int", "(", "(", "_py2_round", "(", "num", "/", "divisible_by", ")", "or", "min_val", ")", "*", "divisible_by", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._get_upsample_op": [[428, 443], ["isinstance", "fbnet_builder.Upsample", "isinstance", "all", "isinstance"], "function", ["None"], ["", "", "def", "_get_upsample_op", "(", "stride", ")", ":", "\n", "    ", "assert", "(", "\n", "stride", "in", "[", "1", ",", "2", ",", "4", "]", "\n", "or", "stride", "in", "[", "-", "1", ",", "-", "2", ",", "-", "4", "]", "\n", "or", "(", "isinstance", "(", "stride", ",", "tuple", ")", "and", "all", "(", "x", "in", "[", "-", "1", ",", "-", "2", ",", "-", "4", "]", "for", "x", "in", "stride", ")", ")", "\n", ")", "\n", "\n", "scales", "=", "stride", "\n", "ret", "=", "None", "\n", "if", "isinstance", "(", "stride", ",", "tuple", ")", "or", "stride", "<", "0", ":", "\n", "        ", "scales", "=", "[", "-", "x", "for", "x", "in", "stride", "]", "if", "isinstance", "(", "stride", ",", "tuple", ")", "else", "-", "stride", "\n", "stride", "=", "1", "\n", "ret", "=", "Upsample", "(", "scale_factor", "=", "scales", ",", "mode", "=", "\"nearest\"", ",", "align_corners", "=", "None", ")", "\n", "\n", "", "return", "ret", ",", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._expand_block_cfg": [[563, 572], ["isinstance", "range", "copy.deepcopy", "ret.append"], "function", ["None"], ["", "", "def", "_expand_block_cfg", "(", "block_cfg", ")", ":", "\n", "    ", "assert", "isinstance", "(", "block_cfg", ",", "list", ")", "\n", "ret", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "block_cfg", "[", "2", "]", ")", ":", "\n", "        ", "cur", "=", "copy", ".", "deepcopy", "(", "block_cfg", ")", "\n", "cur", "[", "2", "]", "=", "1", "\n", "cur", "[", "3", "]", "=", "1", "if", "idx", ">=", "1", "else", "cur", "[", "3", "]", "\n", "ret", ".", "append", "(", "cur", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.expand_stage_cfg": [[574, 581], ["isinstance", "fbnet_builder._expand_block_cfg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._expand_block_cfg"], ["", "def", "expand_stage_cfg", "(", "stage_cfg", ")", ":", "\n", "    ", "\"\"\" For a single stage \"\"\"", "\n", "assert", "isinstance", "(", "stage_cfg", ",", "list", ")", "\n", "ret", "=", "[", "]", "\n", "for", "x", "in", "stage_cfg", ":", "\n", "        ", "ret", "+=", "_expand_block_cfg", "(", "x", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.expand_stages_cfg": [[583, 590], ["isinstance", "ret.append", "fbnet_builder.expand_stage_cfg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.expand_stage_cfg"], ["", "def", "expand_stages_cfg", "(", "stage_cfgs", ")", ":", "\n", "    ", "\"\"\" For a list of stages \"\"\"", "\n", "assert", "isinstance", "(", "stage_cfgs", ",", "list", ")", "\n", "ret", "=", "[", "]", "\n", "for", "x", "in", "stage_cfgs", ":", "\n", "        ", "ret", ".", "append", "(", "expand_stage_cfg", "(", "x", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._block_cfgs_to_list": [[592, 601], ["isinstance", "enumerate", "fbnet_builder.expand_stage_cfg", "enumerate", "ret.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.expand_stage_cfg"], ["", "def", "_block_cfgs_to_list", "(", "block_cfgs", ")", ":", "\n", "    ", "assert", "isinstance", "(", "block_cfgs", ",", "list", ")", "\n", "ret", "=", "[", "]", "\n", "for", "stage_idx", ",", "stage", "in", "enumerate", "(", "block_cfgs", ")", ":", "\n", "        ", "stage", "=", "expand_stage_cfg", "(", "stage", ")", "\n", "for", "block_idx", ",", "block", "in", "enumerate", "(", "stage", ")", ":", "\n", "            ", "cur", "=", "{", "\"stage_idx\"", ":", "stage_idx", ",", "\"block_idx\"", ":", "block_idx", ",", "\"block\"", ":", "block", "}", "\n", "ret", ".", "append", "(", "cur", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._add_to_arch": [[603, 639], ["enumerate", "isinstance", "all", "isinstance", "all", "enumerate", "isinstance", "isinstance"], "function", ["None"], ["", "def", "_add_to_arch", "(", "arch", ",", "info", ",", "name", ")", ":", "\n", "    ", "\"\"\" arch = [{block_0}, {block_1}, ...]\n        info = [\n            # stage 0\n            [\n                block0_info,\n                block1_info,\n                ...\n            ], ...\n        ]\n        convert to:\n        arch = [\n            {\n                block_0,\n                name: block0_info,\n            },\n            {\n                block_1,\n                name: block1_info,\n            }, ...\n        ]\n    \"\"\"", "\n", "assert", "isinstance", "(", "arch", ",", "list", ")", "and", "all", "(", "isinstance", "(", "x", ",", "dict", ")", "for", "x", "in", "arch", ")", "\n", "assert", "isinstance", "(", "info", ",", "list", ")", "and", "all", "(", "isinstance", "(", "x", ",", "list", ")", "for", "x", "in", "info", ")", "\n", "idx", "=", "0", "\n", "for", "stage_idx", ",", "stage", "in", "enumerate", "(", "info", ")", ":", "\n", "        ", "for", "block_idx", ",", "block", "in", "enumerate", "(", "stage", ")", ":", "\n", "            ", "assert", "(", "\n", "arch", "[", "idx", "]", "[", "\"stage_idx\"", "]", "==", "stage_idx", "\n", "and", "arch", "[", "idx", "]", "[", "\"block_idx\"", "]", "==", "block_idx", "\n", ")", ",", "\"Index ({}, {}) does not match for block {}\"", ".", "format", "(", "\n", "stage_idx", ",", "block_idx", ",", "arch", "[", "idx", "]", "\n", ")", "\n", "assert", "name", "not", "in", "arch", "[", "idx", "]", "\n", "arch", "[", "idx", "]", "[", "name", "]", "=", "block", "\n", "idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.unify_arch_def": [[641, 669], ["copy.deepcopy", "copy.deepcopy.update", "fbnet_builder._block_cfgs_to_list", "fbnet_builder._add_to_arch"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._block_cfgs_to_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder._add_to_arch"], ["", "", "", "def", "unify_arch_def", "(", "arch_def", ")", ":", "\n", "    ", "\"\"\" unify the arch_def to:\n        {\n            ...,\n            \"arch\": [\n                {\n                    \"stage_idx\": idx,\n                    \"block_idx\": idx,\n                    ...\n                },\n                {}, ...\n            ]\n        }\n    \"\"\"", "\n", "ret", "=", "copy", ".", "deepcopy", "(", "arch_def", ")", "\n", "\n", "assert", "\"block_cfg\"", "in", "arch_def", "and", "\"stages\"", "in", "arch_def", "[", "\"block_cfg\"", "]", "\n", "assert", "\"stages\"", "not", "in", "ret", "\n", "# copy 'first', 'last' etc. inside arch_def['block_cfg'] to ret", "\n", "ret", ".", "update", "(", "{", "x", ":", "arch_def", "[", "\"block_cfg\"", "]", "[", "x", "]", "for", "x", "in", "arch_def", "[", "\"block_cfg\"", "]", "}", ")", "\n", "ret", "[", "\"stages\"", "]", "=", "_block_cfgs_to_list", "(", "arch_def", "[", "\"block_cfg\"", "]", "[", "\"stages\"", "]", ")", "\n", "del", "ret", "[", "\"block_cfg\"", "]", "\n", "\n", "assert", "\"block_op_type\"", "in", "arch_def", "\n", "_add_to_arch", "(", "ret", "[", "\"stages\"", "]", ",", "arch_def", "[", "\"block_op_type\"", "]", ",", "\"block_op_type\"", ")", "\n", "del", "ret", "[", "\"block_op_type\"", "]", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_num_stages": [[671, 677], ["max"], "function", ["None"], ["", "def", "get_num_stages", "(", "arch_def", ")", ":", "\n", "    ", "ret", "=", "0", "\n", "for", "x", "in", "arch_def", "[", "\"stages\"", "]", ":", "\n", "        ", "ret", "=", "max", "(", "x", "[", "\"stage_idx\"", "]", ",", "ret", ")", "\n", "", "ret", "=", "ret", "+", "1", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_blocks": [[679, 691], ["copy.deepcopy", "ret[].append"], "function", ["None"], ["", "def", "get_blocks", "(", "arch_def", ",", "stage_indices", "=", "None", ",", "block_indices", "=", "None", ")", ":", "\n", "    ", "ret", "=", "copy", ".", "deepcopy", "(", "arch_def", ")", "\n", "ret", "[", "\"stages\"", "]", "=", "[", "]", "\n", "for", "block", "in", "arch_def", "[", "\"stages\"", "]", ":", "\n", "        ", "keep", "=", "True", "\n", "if", "stage_indices", "not", "in", "(", "None", ",", "[", "]", ")", "and", "block", "[", "\"stage_idx\"", "]", "not", "in", "stage_indices", ":", "\n", "            ", "keep", "=", "False", "\n", "", "if", "block_indices", "not", "in", "(", "None", ",", "[", "]", ")", "and", "block", "[", "\"block_idx\"", "]", "not", "in", "block_indices", ":", "\n", "            ", "keep", "=", "False", "\n", "", "if", "keep", ":", "\n", "            ", "ret", "[", "\"stages\"", "]", ".", "append", "(", "block", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.FBNetTrunk.__init__": [[80, 87], ["torch.Module.__init__", "builder.add_first", "fbnet._get_trunk_cfg", "builder.add_blocks"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_first", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet._get_trunk_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_blocks"], ["    ", "def", "__init__", "(", "\n", "self", ",", "builder", ",", "arch_def", ",", "dim_in", ",", "\n", ")", ":", "\n", "        ", "super", "(", "FBNetTrunk", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "first", "=", "builder", ".", "add_first", "(", "arch_def", "[", "\"first\"", "]", ",", "dim_in", "=", "dim_in", ")", "\n", "trunk_cfg", "=", "_get_trunk_cfg", "(", "arch_def", ")", "\n", "self", ".", "stages", "=", "builder", ".", "add_blocks", "(", "trunk_cfg", "[", "\"stages\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.FBNetTrunk.forward": [[89, 94], ["fbnet.FBNetTrunk.first", "fbnet.FBNetTrunk.stages"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "first", "(", "x", ")", "\n", "y", "=", "self", ".", "stages", "(", "y", ")", "\n", "ret", "=", "[", "y", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.FBNetRPNHead.__init__": [[122, 137], ["torch.Module.__init__", "fbnet._get_rpn_stage", "builder.add_blocks", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet._get_rpn_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_blocks"], ["    ", "def", "__init__", "(", "\n", "self", ",", "cfg", ",", "in_channels", ",", "builder", ",", "arch_def", ",", "\n", ")", ":", "\n", "        ", "super", "(", "FBNetRPNHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "in_channels", "==", "builder", ".", "last_depth", "\n", "\n", "rpn_bn_type", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "RPN_BN_TYPE", "\n", "if", "len", "(", "rpn_bn_type", ")", ">", "0", ":", "\n", "            ", "builder", ".", "bn_type", "=", "rpn_bn_type", "\n", "\n", "", "use_blocks", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "RPN_HEAD_BLOCKS", "\n", "stages", "=", "_get_rpn_stage", "(", "arch_def", ",", "use_blocks", ")", "\n", "\n", "self", ".", "head", "=", "builder", ".", "add_blocks", "(", "stages", ")", "\n", "self", ".", "out_channels", "=", "builder", ".", "last_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.FBNetRPNHead.forward": [[138, 141], ["fbnet.FBNetRPNHead.head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "[", "self", ".", "head", "(", "y", ")", "for", "y", "in", "x", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.FBNetROIHead.__init__": [[175, 203], ["torch.Module.__init__", "isinstance", "fcos_core.modeling.poolers.make_pooler", "fbnet._get_head_stage", "builder.add_blocks", "copy.deepcopy", "builder.add_last", "torch.Sequential", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.make_pooler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet._get_head_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_blocks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.FBNetBuilder.add_last"], ["    ", "def", "__init__", "(", "\n", "self", ",", "cfg", ",", "in_channels", ",", "builder", ",", "arch_def", ",", "\n", "head_name", ",", "use_blocks", ",", "stride_init", ",", "last_layer_scale", ",", "\n", ")", ":", "\n", "        ", "super", "(", "FBNetROIHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "in_channels", "==", "builder", ".", "last_depth", "\n", "assert", "isinstance", "(", "use_blocks", ",", "list", ")", "\n", "\n", "head_cfg_name", "=", "ARCH_CFG_NAME_MAPPING", "[", "head_name", "]", "\n", "self", ".", "pooler", "=", "poolers", ".", "make_pooler", "(", "cfg", ",", "head_cfg_name", ")", "\n", "\n", "stage", "=", "_get_head_stage", "(", "arch_def", ",", "head_name", ",", "use_blocks", ")", "\n", "\n", "assert", "stride_init", "in", "[", "0", ",", "1", ",", "2", "]", "\n", "if", "stride_init", "!=", "0", ":", "\n", "            ", "stage", "[", "0", "]", "[", "\"block\"", "]", "[", "3", "]", "=", "stride_init", "\n", "", "blocks", "=", "builder", ".", "add_blocks", "(", "stage", ")", "\n", "\n", "last_info", "=", "copy", ".", "deepcopy", "(", "arch_def", "[", "\"last\"", "]", ")", "\n", "last_info", "[", "1", "]", "=", "last_layer_scale", "\n", "last", "=", "builder", ".", "add_last", "(", "last_info", ")", "\n", "\n", "self", ".", "head", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"blocks\"", ",", "blocks", ")", ",", "\n", "(", "\"last\"", ",", "last", ")", "\n", "]", ")", ")", "\n", "\n", "self", ".", "out_channels", "=", "builder", ".", "last_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.FBNetROIHead.forward": [[204, 208], ["fbnet.FBNetROIHead.pooler", "fbnet.FBNetROIHead.head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposals", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooler", "(", "x", ",", "proposals", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.create_builder": [[21, 69], ["fbnet_builder.unify_arch_def", "json.loads.get", "logger.info", "fbnet_builder.FBNetBuilder", "len", "json.loads", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.unify_arch_def", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "create_builder", "(", "cfg", ")", ":", "\n", "    ", "bn_type", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "BN_TYPE", "\n", "if", "bn_type", "==", "\"gn\"", ":", "\n", "        ", "bn_type", "=", "(", "bn_type", ",", "cfg", ".", "GROUP_NORM", ".", "NUM_GROUPS", ")", "\n", "", "factor", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "SCALE_FACTOR", "\n", "\n", "arch", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "ARCH", "\n", "arch_def", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "ARCH_DEF", "\n", "if", "len", "(", "arch_def", ")", ">", "0", ":", "\n", "        ", "arch_def", "=", "json", ".", "loads", "(", "arch_def", ")", "\n", "", "if", "arch", "in", "modeldef", ".", "MODEL_ARCH", ":", "\n", "        ", "if", "len", "(", "arch_def", ")", ">", "0", ":", "\n", "            ", "assert", "(", "\n", "arch_def", "==", "modeldef", ".", "MODEL_ARCH", "[", "arch", "]", "\n", ")", ",", "\"Two architectures with the same name {},\\n{},\\n{}\"", ".", "format", "(", "\n", "arch", ",", "arch_def", ",", "modeldef", ".", "MODEL_ARCH", "[", "arch", "]", "\n", ")", "\n", "", "arch_def", "=", "modeldef", ".", "MODEL_ARCH", "[", "arch", "]", "\n", "", "else", ":", "\n", "        ", "assert", "arch_def", "is", "not", "None", "and", "len", "(", "arch_def", ")", ">", "0", "\n", "", "arch_def", "=", "mbuilder", ".", "unify_arch_def", "(", "arch_def", ")", "\n", "\n", "rpn_stride", "=", "arch_def", ".", "get", "(", "\"rpn_stride\"", ",", "None", ")", "\n", "if", "rpn_stride", "is", "not", "None", ":", "\n", "        ", "assert", "(", "\n", "cfg", ".", "MODEL", ".", "RPN", ".", "ANCHOR_STRIDE", "[", "0", "]", "==", "rpn_stride", "\n", ")", ",", "\"Needs to set cfg.MODEL.RPN.ANCHOR_STRIDE to {}, got {}\"", ".", "format", "(", "\n", "rpn_stride", ",", "cfg", ".", "MODEL", ".", "RPN", ".", "ANCHOR_STRIDE", "\n", ")", "\n", "", "width_divisor", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "WIDTH_DIVISOR", "\n", "dw_skip_bn", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "DW_CONV_SKIP_BN", "\n", "dw_skip_relu", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "DW_CONV_SKIP_RELU", "\n", "\n", "logger", ".", "info", "(", "\n", "\"Building fbnet model with arch {} (without scaling):\\n{}\"", ".", "format", "(", "\n", "arch", ",", "arch_def", "\n", ")", "\n", ")", "\n", "\n", "builder", "=", "mbuilder", ".", "FBNetBuilder", "(", "\n", "width_ratio", "=", "factor", ",", "\n", "bn_type", "=", "bn_type", ",", "\n", "width_divisor", "=", "width_divisor", ",", "\n", "dw_skip_bn", "=", "dw_skip_bn", ",", "\n", "dw_skip_relu", "=", "dw_skip_relu", ",", "\n", ")", "\n", "\n", "return", "builder", ",", "arch_def", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet._get_trunk_cfg": [[71, 77], ["fbnet_builder.get_num_stages", "arch_def.get", "fbnet_builder.get_blocks", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_num_stages", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_blocks"], ["", "def", "_get_trunk_cfg", "(", "arch_def", ")", ":", "\n", "    ", "\"\"\" Get all stages except the last one \"\"\"", "\n", "num_stages", "=", "mbuilder", ".", "get_num_stages", "(", "arch_def", ")", "\n", "trunk_stages", "=", "arch_def", ".", "get", "(", "\"backbone\"", ",", "range", "(", "num_stages", "-", "1", ")", ")", "\n", "ret", "=", "mbuilder", ".", "get_blocks", "(", "arch_def", ",", "stage_indices", "=", "trunk_stages", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.add_conv_body": [[96, 105], ["fcos_core.modeling.registry.BACKBONES.register", "fbnet.create_builder", "fbnet.FBNetTrunk", "torch.Sequential", "collections.OrderedDict"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.create_builder"], ["", "", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"FBNet\"", ")", "\n", "def", "add_conv_body", "(", "cfg", ",", "dim_in", "=", "3", ")", ":", "\n", "    ", "builder", ",", "arch_def", "=", "create_builder", "(", "cfg", ")", "\n", "\n", "body", "=", "FBNetTrunk", "(", "builder", ",", "arch_def", ",", "dim_in", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"body\"", ",", "body", ")", "]", ")", ")", "\n", "model", ".", "out_channels", "=", "builder", ".", "last_depth", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet._get_rpn_stage": [[107, 119], ["arch_def.get", "fbnet_builder.get_blocks", "logger.warn", "len", "range", "fbnet_builder.get_blocks"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_blocks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_blocks"], ["", "def", "_get_rpn_stage", "(", "arch_def", ",", "num_blocks", ")", ":", "\n", "    ", "rpn_stage", "=", "arch_def", ".", "get", "(", "\"rpn\"", ")", "\n", "ret", "=", "mbuilder", ".", "get_blocks", "(", "arch_def", ",", "stage_indices", "=", "rpn_stage", ")", "\n", "if", "num_blocks", ">", "0", ":", "\n", "        ", "logger", ".", "warn", "(", "'Use last {} blocks in {} as rpn'", ".", "format", "(", "num_blocks", ",", "ret", ")", ")", "\n", "block_count", "=", "len", "(", "ret", "[", "\"stages\"", "]", ")", "\n", "assert", "num_blocks", "<=", "block_count", ",", "\"use block {}, block count {}\"", ".", "format", "(", "\n", "num_blocks", ",", "block_count", "\n", ")", "\n", "blocks", "=", "range", "(", "block_count", "-", "num_blocks", ",", "block_count", ")", "\n", "ret", "=", "mbuilder", ".", "get_blocks", "(", "ret", ",", "block_indices", "=", "blocks", ")", "\n", "", "return", "ret", "[", "\"stages\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.add_rpn_head": [[143, 155], ["fcos_core.modeling.registry.RPN_HEADS.register", "fbnet.create_builder", "fbnet.FBNetRPNHead", "fcos_core.modeling.rpn.rpn.RPNHeadConvRegressor", "torch.Sequential"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.create_builder"], ["", "", "@", "registry", ".", "RPN_HEADS", ".", "register", "(", "\"FBNet.rpn_head\"", ")", "\n", "def", "add_rpn_head", "(", "cfg", ",", "in_channels", ",", "num_anchors", ")", ":", "\n", "    ", "builder", ",", "model_arch", "=", "create_builder", "(", "cfg", ")", "\n", "builder", ".", "last_depth", "=", "in_channels", "\n", "\n", "assert", "in_channels", "==", "builder", ".", "last_depth", "\n", "# builder.name_prefix = \"[rpn]\"", "\n", "\n", "rpn_feature", "=", "FBNetRPNHead", "(", "cfg", ",", "in_channels", ",", "builder", ",", "model_arch", ")", "\n", "rpn_regressor", "=", "rpn", ".", "RPNHeadConvRegressor", "(", "\n", "cfg", ",", "rpn_feature", ".", "out_channels", ",", "num_anchors", ")", "\n", "return", "nn", ".", "Sequential", "(", "rpn_feature", ",", "rpn_regressor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet._get_head_stage": [[157, 164], ["arch.get", "fbnet_builder.get_blocks"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet_builder.get_blocks"], ["", "def", "_get_head_stage", "(", "arch", ",", "head_name", ",", "blocks", ")", ":", "\n", "# use default name 'head' if the specific name 'head_name' does not existed", "\n", "    ", "if", "head_name", "not", "in", "arch", ":", "\n", "        ", "head_name", "=", "\"head\"", "\n", "", "head_stage", "=", "arch", ".", "get", "(", "head_name", ")", "\n", "ret", "=", "mbuilder", ".", "get_blocks", "(", "arch", ",", "stage_indices", "=", "head_stage", ",", "block_indices", "=", "blocks", ")", "\n", "return", "ret", "[", "\"stages\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.add_roi_head": [[210, 222], ["fcos_core.modeling.registry.ROI_BOX_FEATURE_EXTRACTORS.register", "fbnet.create_builder", "fbnet.FBNetROIHead"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.create_builder"], ["", "", "@", "registry", ".", "ROI_BOX_FEATURE_EXTRACTORS", ".", "register", "(", "\"FBNet.roi_head\"", ")", "\n", "def", "add_roi_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "builder", ",", "model_arch", "=", "create_builder", "(", "cfg", ")", "\n", "builder", ".", "last_depth", "=", "in_channels", "\n", "# builder.name_prefix = \"_[bbox]_\"", "\n", "\n", "return", "FBNetROIHead", "(", "\n", "cfg", ",", "in_channels", ",", "builder", ",", "model_arch", ",", "\n", "head_name", "=", "\"bbox\"", ",", "\n", "use_blocks", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "DET_HEAD_BLOCKS", ",", "\n", "stride_init", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "DET_HEAD_STRIDE", ",", "\n", "last_layer_scale", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "DET_HEAD_LAST_SCALE", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.add_roi_head_keypoints": [[225, 237], ["fcos_core.modeling.registry.ROI_KEYPOINT_FEATURE_EXTRACTORS.register", "fbnet.create_builder", "fbnet.FBNetROIHead"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.create_builder"], ["", "@", "registry", ".", "ROI_KEYPOINT_FEATURE_EXTRACTORS", ".", "register", "(", "\"FBNet.roi_head_keypoints\"", ")", "\n", "def", "add_roi_head_keypoints", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "builder", ",", "model_arch", "=", "create_builder", "(", "cfg", ")", "\n", "builder", ".", "last_depth", "=", "in_channels", "\n", "# builder.name_prefix = \"_[kpts]_\"", "\n", "\n", "return", "FBNetROIHead", "(", "\n", "cfg", ",", "in_channels", ",", "builder", ",", "model_arch", ",", "\n", "head_name", "=", "\"kpts\"", ",", "\n", "use_blocks", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "KPTS_HEAD_BLOCKS", ",", "\n", "stride_init", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "KPTS_HEAD_STRIDE", ",", "\n", "last_layer_scale", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "KPTS_HEAD_LAST_SCALE", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.add_roi_head_mask": [[240, 252], ["fcos_core.modeling.registry.ROI_MASK_FEATURE_EXTRACTORS.register", "fbnet.create_builder", "fbnet.FBNetROIHead"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fbnet.create_builder"], ["", "@", "registry", ".", "ROI_MASK_FEATURE_EXTRACTORS", ".", "register", "(", "\"FBNet.roi_head_mask\"", ")", "\n", "def", "add_roi_head_mask", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "builder", ",", "model_arch", "=", "create_builder", "(", "cfg", ")", "\n", "builder", ".", "last_depth", "=", "in_channels", "\n", "# builder.name_prefix = \"_[mask]_\"", "\n", "\n", "return", "FBNetROIHead", "(", "\n", "cfg", ",", "in_channels", ",", "builder", ",", "model_arch", ",", "\n", "head_name", "=", "\"mask\"", ",", "\n", "use_blocks", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "MASK_HEAD_BLOCKS", ",", "\n", "stride_init", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "MASK_HEAD_STRIDE", ",", "\n", "last_layer_scale", "=", "cfg", ".", "MODEL", ".", "FBNET", ".", "MASK_HEAD_LAST_SCALE", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.build_resnet_backbone": [[13, 22], ["fcos_core.modeling.registry.BACKBONES.register", "fcos_core.modeling.registry.BACKBONES.register", "fcos_core.modeling.registry.BACKBONES.register", "fcos_core.modeling.registry.BACKBONES.register", "resnet.ResNet", "torch.nn.Sequential", "collections.OrderedDict"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register"], ["@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-50-C5\"", ")", "\n", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-C4\"", ")", "\n", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-C5\"", ")", "\n", "def", "build_resnet_backbone", "(", "cfg", ")", ":", "\n", "    ", "body", "=", "resnet", ".", "ResNet", "(", "cfg", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"body\"", ",", "body", ")", "]", ")", ")", "\n", "model", ".", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "\n", "return", "model", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.build_resnet_fpn_backbone": [[24, 47], ["fcos_core.modeling.registry.BACKBONES.register", "fcos_core.modeling.registry.BACKBONES.register", "fcos_core.modeling.registry.BACKBONES.register", "resnet.ResNet", "fpn.FPN", "torch.nn.Sequential", "collections.OrderedDict", "fcos_core.modeling.make_layers.conv_with_kaiming_uniform", "fpn.LastLevelMaxPool"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.conv_with_kaiming_uniform"], ["@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-FPN\"", ")", "\n", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-152-FPN\"", ")", "\n", "def", "build_resnet_fpn_backbone", "(", "cfg", ")", ":", "\n", "    ", "body", "=", "resnet", ".", "ResNet", "(", "cfg", ")", "\n", "in_channels_stage2", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "\n", "fpn", "=", "fpn_module", ".", "FPN", "(", "\n", "in_channels_list", "=", "[", "\n", "in_channels_stage2", ",", "\n", "in_channels_stage2", "*", "2", ",", "\n", "in_channels_stage2", "*", "4", ",", "\n", "in_channels_stage2", "*", "8", ",", "\n", "]", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "conv_block", "=", "conv_with_kaiming_uniform", "(", "\n", "cfg", ".", "MODEL", ".", "FPN", ".", "USE_GN", ",", "cfg", ".", "MODEL", ".", "FPN", ".", "USE_RELU", "\n", ")", ",", "\n", "top_blocks", "=", "fpn_module", ".", "LastLevelMaxPool", "(", ")", ",", "\n", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"body\"", ",", "body", ")", ",", "(", "\"fpn\"", ",", "fpn", ")", "]", ")", ")", "\n", "model", ".", "out_channels", "=", "out_channels", "\n", "return", "model", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.build_resnet_fpn_p3p7_backbone": [[49, 73], ["fcos_core.modeling.registry.BACKBONES.register", "fcos_core.modeling.registry.BACKBONES.register", "resnet.ResNet", "fpn.FPN", "torch.nn.Sequential", "collections.OrderedDict", "fcos_core.modeling.make_layers.conv_with_kaiming_uniform", "fpn.LastLevelP6P7"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.conv_with_kaiming_uniform"], ["@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-FPN-RETINANET\"", ")", "\n", "def", "build_resnet_fpn_p3p7_backbone", "(", "cfg", ")", ":", "\n", "    ", "body", "=", "resnet", ".", "ResNet", "(", "cfg", ")", "\n", "in_channels_stage2", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "\n", "in_channels_p6p7", "=", "in_channels_stage2", "*", "8", "if", "cfg", ".", "MODEL", ".", "RETINANET", ".", "USE_C5", "else", "out_channels", "\n", "fpn", "=", "fpn_module", ".", "FPN", "(", "\n", "in_channels_list", "=", "[", "\n", "0", ",", "\n", "in_channels_stage2", "*", "2", ",", "\n", "in_channels_stage2", "*", "4", ",", "\n", "in_channels_stage2", "*", "8", ",", "\n", "]", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "conv_block", "=", "conv_with_kaiming_uniform", "(", "\n", "cfg", ".", "MODEL", ".", "FPN", ".", "USE_GN", ",", "cfg", ".", "MODEL", ".", "FPN", ".", "USE_RELU", "\n", ")", ",", "\n", "top_blocks", "=", "fpn_module", ".", "LastLevelP6P7", "(", "in_channels_p6p7", ",", "out_channels", ")", ",", "\n", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"body\"", ",", "body", ")", ",", "(", "\"fpn\"", ",", "fpn", ")", "]", ")", ")", "\n", "model", ".", "out_channels", "=", "out_channels", "\n", "return", "model", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.build_backbone": [[98, 104], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone": [[20, 34], ["isinstance", "detectron2.layers.ShapeSpec", "BACKBONE_REGISTRY.get", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "if", "not", "isinstance", "(", "dataset_list", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"dataset_list should be a list of strings, got {}\"", ".", "format", "(", "dataset_list", ")", "\n", ")", "\n", "", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "dataset_list", ":", "\n", "        ", "data", "=", "dataset_catalog", ".", "get", "(", "dataset_name", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.FPN.size_divisibility": [[109, 112], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.FPN.output_shape": [[156, 162], ["detectron2.layers.ShapeSpec"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.LastLevelMaxPool.__init__": [[181, 185], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn._assert_strides_are_log2_contiguous": [[165, 172], ["enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.build_resnet_fpn_backbone": [[211, 232], ["build.BACKBONE_REGISTRY.register", "resnet.build_resnet_backbone", "fpn.FPN", "fpn.LastLevelMaxPool"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.build_resnet_backbone"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.fpn.build_retinanet_resnet_fpn_backbone": [[234, 256], ["build.BACKBONE_REGISTRY.register", "resnet.build_resnet_backbone", "fpn.FPN", "resnet.build_resnet_backbone.output_shape", "fpn.LastLevelP6P7"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.build_resnet_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BasicBlock.__init__": [[38, 84], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["\"return_features\"", ",", "# True => return the last feature map from this stage", "\n", "]", ",", "\n", ")", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# Standard ResNet models", "\n", "# -----------------------------------------------------------------------------", "\n", "# ResNet-50 (including all stages)", "\n", "ResNet50StagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "6", ",", "False", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-50 up to stage 4 (excludes stage 5)", "\n", "ResNet50StagesTo4", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "6", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-101 (including all stages)", "\n", "ResNet101StagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "23", ",", "False", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-101 up to stage 4 (excludes stage 5)", "\n", "ResNet101StagesTo4", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "23", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-50-FPN (including all stages)", "\n", "ResNet50FPNStagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "True", ")", ",", "(", "2", ",", "4", ",", "True", ")", ",", "(", "3", ",", "6", ",", "True", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-101-FPN (including all stages)", "\n", "ResNet101FPNStagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "True", ")", ",", "(", "2", ",", "4", ",", "True", ")", ",", "(", "3", ",", "23", ",", "True", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-152-FPN (including all stages)", "\n", "ResNet152FPNStagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "True", ")", ",", "(", "2", ",", "8", ",", "True", ")", ",", "(", "3", ",", "36", ",", "True", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "\n", "class", "ResNet", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BasicBlock.forward": [[85, 98], ["resnet.BasicBlock.conv1", "torch.relu_", "torch.relu_", "resnet.BasicBlock.conv2", "torch.relu_", "torch.relu_", "resnet.BasicBlock.shortcut"], "methods", ["None"], ["# If we want to use the cfg in forward(), then we should make a copy", "\n", "# of it and store it for later use:", "\n", "# self.cfg = cfg.clone()", "\n", "\n", "# Translate string names to implementations", "\n", "stem_module", "=", "_STEM_MODULES", "[", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_FUNC", "]", "\n", "stage_specs", "=", "_STAGE_SPECS", "[", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "]", "\n", "transformation_module", "=", "_TRANSFORMATION_MODULES", "[", "cfg", ".", "MODEL", ".", "RESNETS", ".", "TRANS_FUNC", "]", "\n", "\n", "# Construct the stem module", "\n", "self", ".", "stem", "=", "stem_module", "(", "cfg", ")", "\n", "\n", "# Constuct the specified ResNet stages", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BottleneckBlock.__init__": [[107, 181], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["stage2_relative_factor", "=", "2", "**", "(", "stage_spec", ".", "index", "-", "1", ")", "\n", "bottleneck_channels", "=", "stage2_bottleneck_channels", "*", "stage2_relative_factor", "\n", "out_channels", "=", "stage2_out_channels", "*", "stage2_relative_factor", "\n", "stage_with_dcn", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STAGE_WITH_DCN", "[", "stage_spec", ".", "index", "-", "1", "]", "\n", "module", "=", "_make_stage", "(", "\n", "transformation_module", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "stage_spec", ".", "block_count", ",", "\n", "num_groups", ",", "\n", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", ",", "\n", "first_stride", "=", "int", "(", "stage_spec", ".", "index", ">", "1", ")", "+", "1", ",", "\n", "dcn_config", "=", "{", "\n", "\"stage_with_dcn\"", ":", "stage_with_dcn", ",", "\n", "\"with_modulated_dcn\"", ":", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WITH_MODULATED_DCN", ",", "\n", "\"deformable_groups\"", ":", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORMABLE_GROUPS", ",", "\n", "}", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "self", ".", "add_module", "(", "name", ",", "module", ")", "\n", "self", ".", "stages", ".", "append", "(", "name", ")", "\n", "self", ".", "return_features", "[", "name", "]", "=", "stage_spec", ".", "return_features", "\n", "\n", "# Optionally freeze (requires_grad=False) parts of the backbone", "\n", "", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_CONV_BODY_AT", ")", "\n", "\n", "", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "if", "freeze_at", "<", "0", ":", "\n", "            ", "return", "\n", "", "for", "stage_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "if", "stage_index", "==", "0", ":", "\n", "                ", "m", "=", "self", ".", "stem", "# stage 0 is the stem", "\n", "", "else", ":", "\n", "                ", "m", "=", "getattr", "(", "self", ",", "\"layer\"", "+", "str", "(", "stage_index", ")", ")", "\n", "", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "for", "stage_name", "in", "self", ".", "stages", ":", "\n", "            ", "x", "=", "getattr", "(", "self", ",", "stage_name", ")", "(", "x", ")", "\n", "if", "self", ".", "return_features", "[", "stage_name", "]", ":", "\n", "                ", "outputs", ".", "append", "(", "x", ")", "\n", "", "", "return", "outputs", "\n", "\n", "\n", "", "", "class", "ResNetHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "block_module", ",", "\n", "stages", ",", "\n", "num_groups", "=", "1", ",", "\n", "width_per_group", "=", "64", ",", "\n", "stride_in_1x1", "=", "True", ",", "\n", "stride_init", "=", "None", ",", "\n", "res2_out_channels", "=", "256", ",", "\n", "dilation", "=", "1", ",", "\n", "dcn_config", "=", "{", "}", "\n", ")", ":", "\n", "        ", "super", "(", "ResNetHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "stage2_relative_factor", "=", "2", "**", "(", "stages", "[", "0", "]", ".", "index", "-", "1", ")", "\n", "stage2_bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "out_channels", "=", "res2_out_channels", "*", "stage2_relative_factor", "\n", "in_channels", "=", "out_channels", "//", "2", "\n", "bottleneck_channels", "=", "stage2_bottleneck_channels", "*", "stage2_relative_factor", "\n", "\n", "block_module", "=", "_TRANSFORMATION_MODULES", "[", "block_module", "]", "\n", "\n", "self", ".", "stages", "=", "[", "]", "\n", "stride", "=", "stride_init", "\n", "for", "stage", "in", "stages", ":", "\n", "            ", "name", "=", "\"layer\"", "+", "str", "(", "stage", ".", "index", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BottleneckBlock.forward": [[194, 211], ["resnet.BottleneckBlock.conv1", "torch.relu_", "torch.relu_", "resnet.BottleneckBlock.conv2", "torch.relu_", "torch.relu_", "resnet.BottleneckBlock.conv3", "torch.relu_", "torch.relu_", "resnet.BottleneckBlock.shortcut"], "methods", ["None"], ["dcn_config", "=", "dcn_config", "\n", ")", "\n", "stride", "=", "None", "\n", "self", ".", "add_module", "(", "name", ",", "module", ")", "\n", "self", ".", "stages", ".", "append", "(", "name", ")", "\n", "", "self", ".", "out_channels", "=", "out_channels", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "stage", "in", "self", ".", "stages", ":", "\n", "            ", "x", "=", "getattr", "(", "self", ",", "stage", ")", "(", "x", ")", "\n", "", "return", "x", "\n", "\n", "\n", "", "", "def", "_make_stage", "(", "\n", "transformation_module", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.DeformBottleneckBlock.__init__": [[219, 302], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "deform_conv_op", "detectron2.layers.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["    ", "blocks", "=", "[", "]", "\n", "stride", "=", "first_stride", "\n", "for", "_", "in", "range", "(", "block_count", ")", ":", "\n", "        ", "blocks", ".", "append", "(", "\n", "transformation_module", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "num_groups", ",", "\n", "stride_in_1x1", ",", "\n", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dcn_config", "=", "dcn_config", "\n", ")", "\n", ")", "\n", "stride", "=", "1", "\n", "in_channels", "=", "out_channels", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "\n", "", "class", "Bottleneck", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "num_groups", ",", "\n", "stride_in_1x1", ",", "\n", "stride", ",", "\n", "dilation", ",", "\n", "norm_func", ",", "\n", "dcn_config", "\n", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "downsample", "=", "None", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "down_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "down_stride", ",", "bias", "=", "False", "\n", ")", ",", "\n", "norm_func", "(", "out_channels", ")", ",", "\n", ")", "\n", "for", "modules", "in", "[", "self", ".", "downsample", ",", "]", ":", "\n", "                ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "l", ",", "Conv2d", ")", ":", "\n", "                        ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n", "", "", "", "", "if", "dilation", ">", "1", ":", "\n", "            ", "stride", "=", "1", "# reset to be 1", "\n", "\n", "# The original MSRA ResNet models have stride in the first 1x1 conv", "\n", "# The subsequent fb.torch.resnet and Caffe2 ResNe[X]t implementations have", "\n", "# stride in the 3x3 conv", "\n", "", "stride_1x1", ",", "stride_3x3", "=", "(", "stride", ",", "1", ")", "if", "stride_in_1x1", "else", "(", "1", ",", "stride", ")", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride_1x1", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "bn1", "=", "norm_func", "(", "bottleneck_channels", ")", "\n", "# TODO: specify init for the above", "\n", "with_dcn", "=", "dcn_config", ".", "get", "(", "\"stage_with_dcn\"", ",", "False", ")", "\n", "if", "with_dcn", ":", "\n", "            ", "deformable_groups", "=", "dcn_config", ".", "get", "(", "\"deformable_groups\"", ",", "1", ")", "\n", "with_modulated_dcn", "=", "dcn_config", ".", "get", "(", "\"with_modulated_dcn\"", ",", "False", ")", "\n", "self", ".", "conv2", "=", "DFConv2d", "(", "\n", "bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "with_modulated_dcn", "=", "with_modulated_dcn", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilation", "=", "dilation", ",", "\n", "deformable_groups", "=", "deformable_groups", ",", "\n", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2", "=", "Conv2d", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.DeformBottleneckBlock.forward": [[303, 328], ["resnet.DeformBottleneckBlock.conv1", "torch.relu_", "torch.relu_", "torch.relu_", "torch.relu_", "resnet.DeformBottleneckBlock.conv3", "torch.relu_", "torch.relu_", "resnet.DeformBottleneckBlock.conv2_offset", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mask.sigmoid.sigmoid.sigmoid", "resnet.DeformBottleneckBlock.conv2", "resnet.DeformBottleneckBlock.conv2_offset", "resnet.DeformBottleneckBlock.conv2", "resnet.DeformBottleneckBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "padding", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilation", "=", "dilation", "\n", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "conv2", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n", "", "self", ".", "bn2", "=", "norm_func", "(", "bottleneck_channels", ")", "\n", "\n", "self", ".", "conv3", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn3", "=", "norm_func", "(", "out_channels", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv1", ",", "self", ".", "conv3", ",", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BasicStem.__init__": [[335, 353], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n", "\n", "", "", "class", "BaseStem", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "norm_func", ")", ":", "\n", "        ", "super", "(", "BaseStem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.BasicStem.forward": [[354, 359], ["resnet.BasicStem.conv1", "torch.relu_", "torch.relu_", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["3", ",", "out_channels", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn1", "=", "norm_func", "(", "out_channels", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv1", ",", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet.output_shape": [[459, 465], ["detectron2.layers.ShapeSpec"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet.freeze": [[467, 490], ["enumerate", "resnet.ResNet.stem.freeze", "stage.children", "block.freeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet.make_stage": [[491, 545], ["range", "kwargs.items", "blocks.append", "k.endswith", "block_class", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.ResNet.make_default_stages": [[546, 597], ["zip", "ret.append", "resnet.ResNet.make_stage"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage": [[605, 610], ["resnet.ResNet.make_stage"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.build_resnet_backbone": [[612, 694], ["build.BACKBONE_REGISTRY.register", "resnet.BasicStem", "enumerate", "resnet.ResNet", "range", "resnet.ResNet.make_stage", "stages.append", "any"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.__init__": [[15, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-C5\"", ")", "\n", "def", "build_resnet_backbone", "(", "cfg", ")", ":", "\n", "    ", "body", "=", "resnet", ".", "ResNet", "(", "cfg", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"body\"", ",", "body", ")", "]", ")", ")", "\n", "model", ".", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "\n", "return", "model", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.forward": [[21, 30], ["None"], "methods", ["None"], ["\n", "\n", "", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-50-FPN\"", ")", "\n", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-FPN\"", ")", "\n", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-152-FPN\"", ")", "\n", "def", "build_resnet_fpn_backbone", "(", "cfg", ")", ":", "\n", "    ", "body", "=", "resnet", ".", "ResNet", "(", "cfg", ")", "\n", "in_channels_stage2", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "\n", "fpn", "=", "fpn_module", ".", "FPN", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.size_divisibility": [[31, 41], ["None"], "methods", ["None"], ["in_channels_list", "=", "[", "\n", "in_channels_stage2", ",", "\n", "in_channels_stage2", "*", "2", ",", "\n", "in_channels_stage2", "*", "4", ",", "\n", "in_channels_stage2", "*", "8", ",", "\n", "]", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "conv_block", "=", "conv_with_kaiming_uniform", "(", "\n", "cfg", ".", "MODEL", ".", "FPN", ".", "USE_GN", ",", "cfg", ".", "MODEL", ".", "FPN", ".", "USE_RELU", "\n", ")", ",", "\n", "top_blocks", "=", "fpn_module", ".", "LastLevelMaxPool", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape": [[42, 53], ["detectron2.layers.ShapeSpec"], "methods", ["None"], [")", "\n", "model", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "\"body\"", ",", "body", ")", ",", "(", "\"fpn\"", ",", "fpn", ")", "]", ")", ")", "\n", "model", ".", "out_channels", "=", "out_channels", "\n", "return", "model", "\n", "\n", "\n", "", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-50-FPN-RETINANET\"", ")", "\n", "@", "registry", ".", "BACKBONES", ".", "register", "(", "\"R-101-FPN-RETINANET\"", ")", "\n", "def", "build_resnet_fpn_p3p7_backbone", "(", "cfg", ")", ":", "\n", "    ", "body", "=", "resnet", ".", "ResNet", "(", "cfg", ")", "\n", "in_channels_stage2", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.InvertedResidual.__init__": [[28, 59], ["torch.nn.Module.__init__", "int", "round", "torch.nn.Sequential", "torch.nn.Sequential", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inp", ",", "oup", ",", "stride", ",", "expand_ratio", ")", ":", "\n", "        ", "super", "(", "InvertedResidual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "\n", "hidden_dim", "=", "int", "(", "round", "(", "inp", "*", "expand_ratio", ")", ")", "\n", "self", ".", "use_res_connect", "=", "self", ".", "stride", "==", "1", "and", "inp", "==", "oup", "\n", "\n", "if", "expand_ratio", "==", "1", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "# dw", "\n", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "3", ",", "stride", ",", "1", ",", "groups", "=", "hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", "# pw-linear", "\n", "Conv2d", "(", "hidden_dim", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "# pw", "\n", "Conv2d", "(", "inp", ",", "hidden_dim", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", "# dw", "\n", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "3", ",", "stride", ",", "1", ",", "groups", "=", "hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", "# pw-linear", "\n", "Conv2d", "(", "hidden_dim", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.InvertedResidual.forward": [[61, 66], ["mobilenet.InvertedResidual.conv", "mobilenet.InvertedResidual.conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "use_res_connect", ":", "\n", "            ", "return", "x", "+", "self", ".", "conv", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2.__init__": [[72, 107], ["torch.nn.Module.__init__", "int", "torch.nn.ModuleList", "mobilenet.MobileNetV2._initialize_weights", "mobilenet.MobileNetV2._freeze_backbone", "int", "range", "mobilenet.conv_bn", "mobilenet.MobileNetV2.features.append", "mobilenet.MobileNetV2.features.append", "mobilenet.MobileNetV2.return_features_num_channels.append", "block", "block", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2._initialize_weights", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2._freeze_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.conv_bn"], ["def", "__init__", "(", "self", ",", "cfg", ",", "n_class", "=", "1000", ",", "input_size", "=", "224", ",", "width_mult", "=", "1.", ")", ":", "\n", "        ", "super", "(", "MobileNetV2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "block", "=", "InvertedResidual", "\n", "input_channel", "=", "32", "\n", "interverted_residual_setting", "=", "[", "\n", "# t, c, n, s", "\n", "[", "1", ",", "16", ",", "1", ",", "1", "]", ",", "\n", "[", "6", ",", "24", ",", "2", ",", "2", "]", ",", "\n", "[", "6", ",", "32", ",", "3", ",", "2", "]", ",", "\n", "[", "6", ",", "64", ",", "4", ",", "2", "]", ",", "\n", "[", "6", ",", "96", ",", "3", ",", "1", "]", ",", "\n", "[", "6", ",", "160", ",", "3", ",", "2", "]", ",", "\n", "[", "6", ",", "320", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "\n", "# building first layer", "\n", "assert", "input_size", "%", "32", "==", "0", "\n", "input_channel", "=", "int", "(", "input_channel", "*", "width_mult", ")", "\n", "self", ".", "return_features_indices", "=", "[", "3", ",", "6", ",", "13", ",", "17", "]", "\n", "self", ".", "return_features_num_channels", "=", "[", "]", "\n", "self", ".", "features", "=", "nn", ".", "ModuleList", "(", "[", "conv_bn", "(", "3", ",", "input_channel", ",", "2", ")", "]", ")", "\n", "# building inverted residual blocks", "\n", "for", "t", ",", "c", ",", "n", ",", "s", "in", "interverted_residual_setting", ":", "\n", "            ", "output_channel", "=", "int", "(", "c", "*", "width_mult", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "self", ".", "features", ".", "append", "(", "block", "(", "input_channel", ",", "output_channel", ",", "s", ",", "expand_ratio", "=", "t", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "features", ".", "append", "(", "block", "(", "input_channel", ",", "output_channel", ",", "1", ",", "expand_ratio", "=", "t", ")", ")", "\n", "", "input_channel", "=", "output_channel", "\n", "if", "len", "(", "self", ".", "features", ")", "-", "1", "in", "self", ".", "return_features_indices", ":", "\n", "                    ", "self", ".", "return_features_num_channels", ".", "append", "(", "output_channel", ")", "\n", "\n", "", "", "", "self", ".", "_initialize_weights", "(", ")", "\n", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_CONV_BODY_AT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2._freeze_backbone": [[108, 112], ["range", "mobilenet.MobileNetV2.features[].parameters"], "methods", ["None"], ["", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "for", "layer_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "for", "p", "in", "self", ".", "features", "[", "layer_index", "]", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2.forward": [[113, 120], ["enumerate", "m", "res.append"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "features", ")", ":", "\n", "            ", "x", "=", "m", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "return_features_indices", ":", "\n", "                ", "res", ".", "append", "(", "x", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.MobileNetV2._initialize_weights": [[121, 135], ["mobilenet.MobileNetV2.modules", "isinstance", "m.weight.data.normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.size", "m.weight.data.normal_", "m.bias.data.zero_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", "0.5", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "n", "=", "m", ".", "weight", ".", "size", "(", "1", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.conv_bn": [[11, 16], ["torch.nn.Sequential", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6"], "function", ["None"], ["def", "conv_bn", "(", "inp", ",", "oup", ",", "stride", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "inp", ",", "oup", ",", "3", ",", "stride", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.mobilenet.conv_1x1_bn": [[19, 24], ["torch.nn.Sequential", "fcos_core.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6"], "function", ["None"], ["", "def", "conv_1x1_bn", "(", "inp", ",", "oup", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "inp", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.build_mnv2_fpn_backbone": [[75, 96], ["fcos_core.modeling.registry.BACKBONES.register", "mobilenet.MobileNetV2", "fpn.FPN", "torch.nn.Sequential", "collections.OrderedDict", "fcos_core.modeling.make_layers.conv_with_kaiming_uniform", "fpn.LastLevelP6P7"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.make_layers.conv_with_kaiming_uniform"], ["    ", "assert", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "in", "registry", ".", "BACKBONES", ",", "\"cfg.MODEL.BACKBONE.CONV_BODY: {} are not registered in registry\"", ".", "format", "(", "\n", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "\n", ")", "\n", "return", "registry", ".", "BACKBONES", "[", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "]", "(", "cfg", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detector.detectors.build_detection_model": [[8, 11], ["meta_arch"], "function", ["None"], ["def", "build_detection_model", "(", "cfg", ")", ":", "\n", "    ", "meta_arch", "=", "_DETECTION_META_ARCHITECTURES", "[", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "]", "\n", "return", "meta_arch", "(", "cfg", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detector.generalized_rcnn.GeneralizedRCNN.__init__": [[26, 32], ["torch.nn.Module.__init__", "backbone.build_backbone", "rpn.rpn.build_rpn", "roi_heads.roi_heads.build_roi_heads"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.rpn.build_rpn", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.build_roi_heads"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "GeneralizedRCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "self", ".", "rpn", "=", "build_rpn", "(", "cfg", ",", "self", ".", "backbone", ".", "out_channels", ")", "\n", "self", ".", "roi_heads", "=", "build_roi_heads", "(", "cfg", ",", "self", ".", "backbone", ".", "out_channels", ")", "\n", "self", ".", "search", "=", "cfg", ".", "AUTOAUG", ".", "SEARCH", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detector.generalized_rcnn.GeneralizedRCNN.forward": [[33, 66], ["fcos_core.structures.image_list.to_image_list", "generalized_rcnn.GeneralizedRCNN.backbone", "generalized_rcnn.GeneralizedRCNN.rpn", "ValueError", "generalized_rcnn.GeneralizedRCNN.roi_heads", "losses.update", "losses.update"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["\n", "", "def", "forward", "(", "self", ",", "images", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (list[Tensor] or ImageList): images to be processed\n            targets (list[BoxList]): ground-truth boxes present in the image (optional)\n\n        Returns:\n            result (list[BoxList] or dict[Tensor]): the output from the model.\n                During training, it returns a dict[Tensor] which contains the losses.\n                During testing, it returns list[BoxList] contains additional fields\n                like `scores`, `labels` and `mask` (for Mask R-CNN models).\n\n        \"\"\"", "\n", "if", "self", ".", "training", "and", "targets", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"In training mode, targets should be passed\"", ")", "\n", "", "images", "=", "to_image_list", "(", "images", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensors", ")", "\n", "loss_scale", "=", "None", "\n", "\n", "if", "self", ".", "search", "and", "self", ".", "training", ":", "\n", "            ", "proposals", ",", "proposal_losses", ",", "loss_scale", "=", "self", ".", "rpn", "(", "images", ",", "features", ",", "targets", ",", "self", ".", "search", ")", "\n", "", "else", ":", "\n", "            ", "proposals", ",", "proposal_losses", "=", "self", ".", "rpn", "(", "images", ",", "features", ",", "targets", ")", "\n", "", "if", "self", ".", "roi_heads", ":", "\n", "            ", "x", ",", "result", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "features", ",", "proposals", ",", "targets", ")", "\n", "", "else", ":", "\n", "# RPN-only models don't have roi_heads", "\n", "            ", "x", "=", "features", "\n", "result", "=", "proposals", "\n", "detector_losses", "=", "{", "}", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "losses", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.__init__": [[38, 83], ["isinstance", "tuple", "masks.masks.clone.masks.clone.clone", "isinstance", "len", "len", "isinstance", "isinstance", "torch.stack().clone", "masks.masks.clone.masks.clone.masks.clone", "RuntimeError", "isinstance", "RuntimeError", "torch.stack", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["def", "__init__", "(", "self", ",", "masks", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n            Arguments:\n                masks: Either torch.tensor of [num_instances, H, W]\n                    or list of torch.tensors of [H, W] with num_instances elems,\n                    or RLE (Run Length Encoding) - interpreted as list of dicts,\n                    or BinaryMaskList.\n                size: absolute image size, width first\n\n            After initialization, a hard copy will be made, to leave the\n            initializing source data intact.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "size", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "size", ")", "==", "2", "\n", "\n", "if", "isinstance", "(", "masks", ",", "torch", ".", "Tensor", ")", ":", "\n", "# The raw data representation is passed as argument", "\n", "            ", "masks", "=", "masks", ".", "clone", "(", ")", "\n", "", "elif", "isinstance", "(", "masks", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "masks", ")", "==", "0", ":", "\n", "                ", "masks", "=", "torch", ".", "empty", "(", "[", "0", ",", "size", "[", "1", "]", ",", "size", "[", "0", "]", "]", ")", "# num_instances = 0!", "\n", "", "elif", "isinstance", "(", "masks", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "masks", "=", "torch", ".", "stack", "(", "masks", ",", "dim", "=", "0", ")", ".", "clone", "(", ")", "\n", "", "elif", "isinstance", "(", "masks", "[", "0", "]", ",", "dict", ")", "and", "\"counts\"", "in", "masks", "[", "0", "]", ":", "\n", "                ", "if", "(", "isinstance", "(", "masks", "[", "0", "]", "[", "\"counts\"", "]", ",", "(", "list", ",", "tuple", ")", ")", ")", ":", "\n", "                    ", "masks", "=", "mask_utils", ".", "frPyObjects", "(", "masks", ",", "size", "[", "1", "]", ",", "size", "[", "0", "]", ")", "\n", "# RLE interpretation", "\n", "", "rle_sizes", "=", "[", "tuple", "(", "inst", "[", "\"size\"", "]", ")", "for", "inst", "in", "masks", "]", "\n", "\n", "masks", "=", "mask_utils", ".", "decode", "(", "masks", ")", "# [h, w, n]", "\n", "masks", "=", "torch", ".", "tensor", "(", "masks", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# [n, h, w]", "\n", "\n", "assert", "rle_sizes", ".", "count", "(", "rle_sizes", "[", "0", "]", ")", "==", "len", "(", "rle_sizes", ")", ",", "(", "\n", "\"All the sizes must be the same size: %s\"", "%", "rle_sizes", "\n", ")", "\n", "\n", "# in RLE, height come first in \"size\"", "\n", "rle_height", ",", "rle_width", "=", "rle_sizes", "[", "0", "]", "\n", "assert", "masks", ".", "shape", "[", "1", "]", "==", "rle_height", "\n", "assert", "masks", ".", "shape", "[", "2", "]", "==", "rle_width", "\n", "\n", "width", ",", "height", "=", "size", "\n", "if", "width", "!=", "rle_width", "or", "height", "!=", "rle_height", ":", "\n", "                    ", "masks", "=", "interpolate", "(", "\n", "input", "=", "masks", "[", "None", "]", ".", "float", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.transpose": [[84, 88], ["segmentation_mask.BinaryMaskList.masks.flip", "segmentation_mask.BinaryMaskList"], "methods", ["None"], ["size", "=", "(", "height", ",", "width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "[", "0", "]", ".", "type_as", "(", "masks", ")", "\n", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.crop": [[89, 109], ["isinstance", "str", "str", "min", "min", "min", "min", "max", "max", "segmentation_mask.BinaryMaskList", "type", "round", "max", "max", "max", "max", "float"], "methods", ["None"], ["                ", "RuntimeError", "(", "\n", "\"Type of `masks[0]` could not be interpreted: %s\"", "\n", "%", "type", "(", "masks", ")", "\n", ")", "\n", "", "", "elif", "isinstance", "(", "masks", ",", "BinaryMaskList", ")", ":", "\n", "# just hard copy the BinaryMaskList instance's underlying data", "\n", "            ", "masks", "=", "masks", ".", "masks", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "RuntimeError", "(", "\n", "\"Type of `masks` argument could not be interpreted:%s\"", "\n", "%", "type", "(", "masks", ")", "\n", ")", "\n", "\n", "", "if", "len", "(", "masks", ".", "shape", ")", "==", "2", ":", "\n", "# if only a single instance mask is passed", "\n", "            ", "masks", "=", "masks", "[", "None", "]", "\n", "\n", "", "assert", "len", "(", "masks", ".", "shape", ")", "==", "3", "\n", "assert", "masks", ".", "shape", "[", "1", "]", "==", "size", "[", "1", "]", ",", "\"%s != %s\"", "%", "(", "masks", ".", "shape", "[", "1", "]", ",", "size", "[", "1", "]", ")", "\n", "assert", "masks", ".", "shape", "[", "2", "]", "==", "size", "[", "0", "]", ",", "\"%s != %s\"", "%", "(", "masks", ".", "shape", "[", "2", "]", ",", "size", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.resize": [[110, 130], ["map", "[].type_as", "segmentation_mask.BinaryMaskList", "iter", "isinstance", "torch.nn.functional.interpolate", "segmentation_mask.BinaryMaskList.masks[].float"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["self", ".", "masks", "=", "masks", "\n", "self", ".", "size", "=", "tuple", "(", "size", ")", "\n", "\n", "", "def", "transpose", "(", "self", ",", "method", ")", ":", "\n", "        ", "dim", "=", "1", "if", "method", "==", "FLIP_TOP_BOTTOM", "else", "2", "\n", "flipped_masks", "=", "self", ".", "masks", ".", "flip", "(", "dim", ")", "\n", "return", "BinaryMaskList", "(", "flipped_masks", ",", "self", ".", "size", ")", "\n", "\n", "", "def", "crop", "(", "self", ",", "box", ")", ":", "\n", "        ", "assert", "isinstance", "(", "box", ",", "(", "list", ",", "tuple", ",", "torch", ".", "Tensor", ")", ")", ",", "str", "(", "type", "(", "box", ")", ")", "\n", "# box is assumed to be xyxy", "\n", "current_width", ",", "current_height", "=", "self", ".", "size", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "[", "round", "(", "float", "(", "b", ")", ")", "for", "b", "in", "box", "]", "\n", "\n", "assert", "xmin", "<=", "xmax", "and", "ymin", "<=", "ymax", ",", "str", "(", "box", ")", "\n", "xmin", "=", "min", "(", "max", "(", "xmin", ",", "0", ")", ",", "current_width", "-", "1", ")", "\n", "ymin", "=", "min", "(", "max", "(", "ymin", ",", "0", ")", ",", "current_height", "-", "1", ")", "\n", "\n", "xmax", "=", "min", "(", "max", "(", "xmax", ",", "0", ")", ",", "current_width", ")", "\n", "ymax", "=", "min", "(", "max", "(", "ymax", ",", "0", ")", ",", "current_height", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.convert_to_polygon": [[131, 134], ["segmentation_mask.BinaryMaskList._findContours", "segmentation_mask.PolygonList"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList._findContours"], ["xmax", "=", "max", "(", "xmax", ",", "xmin", "+", "1", ")", "\n", "ymax", "=", "max", "(", "ymax", ",", "ymin", "+", "1", ")", "\n", "\n", "width", ",", "height", "=", "xmax", "-", "xmin", ",", "ymax", "-", "ymin", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.to": [[135, 137], ["None"], "methods", ["None"], ["cropped_masks", "=", "self", ".", "masks", "[", ":", ",", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "\n", "cropped_size", "=", "width", ",", "height", "\n", "return", "BinaryMaskList", "(", "cropped_masks", ",", "cropped_size", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList._findContours": [[138, 154], ["segmentation_mask.BinaryMaskList.masks.detach().numpy", "cv2.UMat", "cv2.findContours", "contours.append", "segmentation_mask.BinaryMaskList.masks.detach", "reshaped_contour.append", "len", "entity.reshape().tolist", "entity.reshape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours"], ["\n", "", "def", "resize", "(", "self", ",", "size", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "iter", "(", "size", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "assert", "isinstance", "(", "size", ",", "(", "int", ",", "float", ")", ")", "\n", "size", "=", "size", ",", "size", "\n", "", "width", ",", "height", "=", "map", "(", "int", ",", "size", ")", "\n", "\n", "assert", "width", ">", "0", "\n", "assert", "height", ">", "0", "\n", "\n", "# Height comes first here!", "\n", "resized_masks", "=", "interpolate", "(", "\n", "input", "=", "self", ".", "masks", "[", "None", "]", ".", "float", "(", ")", ",", "\n", "size", "=", "(", "height", ",", "width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.__len__": [[155, 157], ["len"], "methods", ["None"], ["align_corners", "=", "False", ",", "\n", ")", "[", "0", "]", ".", "type_as", "(", "self", ".", "masks", ")", "\n", "resized_size", "=", "width", ",", "height", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.__getitem__": [[158, 163], ["segmentation_mask.BinaryMaskList.masks[].clone", "segmentation_mask.BinaryMaskList"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["return", "BinaryMaskList", "(", "resized_masks", ",", "resized_size", ")", "\n", "\n", "", "def", "convert_to_polygon", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "masks", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "return", "PolygonList", "(", "[", "]", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.__iter__": [[164, 166], ["iter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "contours", "=", "self", ".", "_findContours", "(", ")", "\n", "return", "PolygonList", "(", "contours", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.__repr__": [[167, 173], ["len"], "methods", ["None"], ["", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", "\n", "\n", "", "def", "_findContours", "(", "self", ")", ":", "\n", "        ", "contours", "=", "[", "]", "\n", "masks", "=", "self", ".", "masks", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "for", "mask", "in", "masks", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.__init__": [[182, 214], ["isinstance", "tuple", "isinstance", "torch.as_tensor", "copy.copy", "RuntimeError", "len", "valid_polygons.append", "type"], "methods", ["None"], ["assert", "(", "\n", "entity", ".", "shape", "[", "1", "]", "==", "1", "\n", ")", ",", "\"Hierarchical contours are not allowed\"", "\n", "reshaped_contour", ".", "append", "(", "entity", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "", "contours", ".", "append", "(", "reshaped_contour", ")", "\n", "", "return", "contours", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "masks", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "masks", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Indexing empty BinaryMaskList\"", ")", "\n", "", "return", "BinaryMaskList", "(", "self", ".", "masks", "[", "index", "]", ",", "self", ".", "size", ")", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "masks", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={}, \"", ".", "format", "(", "len", "(", "self", ".", "masks", ")", ")", "\n", "s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "size", "[", "0", "]", ")", "\n", "s", "+=", "\"image_height={})\"", ".", "format", "(", "self", ".", "size", "[", "1", "]", ")", "\n", "return", "s", "\n", "\n", "\n", "", "", "class", "PolygonInstance", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    This class holds a set of polygons that represents a single instance\n    of an object mask. The object can be represented as a set of\n    polygons\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.transpose": [[215, 237], ["segmentation_mask.PolygonInstance", "NotImplementedError", "poly.clone", "flipped_polygons.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["def", "__init__", "(", "self", ",", "polygons", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n            Arguments:\n                a list of lists of numbers.\n                The first level refers to all the polygons that compose the\n                object, and the second level to the polygon coordinates.\n        \"\"\"", "\n", "if", "isinstance", "(", "polygons", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "valid_polygons", "=", "[", "]", "\n", "for", "p", "in", "polygons", ":", "\n", "                ", "p", "=", "torch", ".", "as_tensor", "(", "p", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "if", "len", "(", "p", ")", ">=", "6", ":", "# 3 * 2 coordinates", "\n", "                    ", "valid_polygons", ".", "append", "(", "p", ")", "\n", "", "", "polygons", "=", "valid_polygons", "\n", "\n", "", "elif", "isinstance", "(", "polygons", ",", "PolygonInstance", ")", ":", "\n", "            ", "polygons", "=", "copy", ".", "copy", "(", "polygons", ".", "polygons", ")", "\n", "\n", "", "else", ":", "\n", "            ", "RuntimeError", "(", "\n", "\"Type of argument `polygons` is not allowed:%s\"", "\n", "%", "(", "type", "(", "polygons", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.crop": [[238, 265], ["isinstance", "str", "map", "str", "min", "min", "min", "min", "max", "max", "segmentation_mask.PolygonInstance", "type", "max", "max", "max", "max", "poly.clone", "cropped_polygons.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["\n", "", "\"\"\" This crashes the training way too many times...\n        for p in polygons:\n            assert p[::2].min() >= 0\n            assert p[::2].max() < size[0]\n            assert p[1::2].min() >= 0\n            assert p[1::2].max() , size[1]\n        \"\"\"", "\n", "\n", "self", ".", "polygons", "=", "polygons", "\n", "self", ".", "size", "=", "tuple", "(", "size", ")", "\n", "\n", "", "def", "transpose", "(", "self", ",", "method", ")", ":", "\n", "        ", "if", "method", "not", "in", "(", "FLIP_LEFT_RIGHT", ",", "FLIP_TOP_BOTTOM", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented\"", "\n", ")", "\n", "\n", "", "flipped_polygons", "=", "[", "]", "\n", "width", ",", "height", "=", "self", ".", "size", "\n", "if", "method", "==", "FLIP_LEFT_RIGHT", ":", "\n", "            ", "dim", "=", "width", "\n", "idx", "=", "0", "\n", "", "elif", "method", "==", "FLIP_TOP_BOTTOM", ":", "\n", "            ", "dim", "=", "height", "\n", "idx", "=", "1", "\n", "\n", "", "for", "poly", "in", "self", ".", "polygons", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.resize": [[266, 289], ["tuple", "segmentation_mask.PolygonInstance", "iter", "segmentation_mask.PolygonInstance", "poly.clone", "scaled_polygons.append", "isinstance", "float", "float", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["            ", "p", "=", "poly", ".", "clone", "(", ")", "\n", "TO_REMOVE", "=", "1", "\n", "p", "[", "idx", ":", ":", "2", "]", "=", "dim", "-", "poly", "[", "idx", ":", ":", "2", "]", "-", "TO_REMOVE", "\n", "flipped_polygons", ".", "append", "(", "p", ")", "\n", "\n", "", "return", "PolygonInstance", "(", "flipped_polygons", ",", "size", "=", "self", ".", "size", ")", "\n", "\n", "", "def", "crop", "(", "self", ",", "box", ")", ":", "\n", "        ", "assert", "isinstance", "(", "box", ",", "(", "list", ",", "tuple", ",", "torch", ".", "Tensor", ")", ")", ",", "str", "(", "type", "(", "box", ")", ")", "\n", "\n", "# box is assumed to be xyxy", "\n", "current_width", ",", "current_height", "=", "self", ".", "size", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "map", "(", "float", ",", "box", ")", "\n", "\n", "assert", "xmin", "<=", "xmax", "and", "ymin", "<=", "ymax", ",", "str", "(", "box", ")", "\n", "xmin", "=", "min", "(", "max", "(", "xmin", ",", "0", ")", ",", "current_width", "-", "1", ")", "\n", "ymin", "=", "min", "(", "max", "(", "ymin", ",", "0", ")", ",", "current_height", "-", "1", ")", "\n", "\n", "xmax", "=", "min", "(", "max", "(", "xmax", ",", "0", ")", ",", "current_width", ")", "\n", "ymax", "=", "min", "(", "max", "(", "ymax", ",", "0", ")", ",", "current_height", ")", "\n", "\n", "xmax", "=", "max", "(", "xmax", ",", "xmin", "+", "1", ")", "\n", "ymax", "=", "max", "(", "ymax", ",", "ymin", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.convert_to_binarymask": [[290, 299], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.decode", "torch.from_numpy", "p.numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["w", ",", "h", "=", "xmax", "-", "xmin", ",", "ymax", "-", "ymin", "\n", "\n", "cropped_polygons", "=", "[", "]", "\n", "for", "poly", "in", "self", ".", "polygons", ":", "\n", "            ", "p", "=", "poly", ".", "clone", "(", ")", "\n", "p", "[", "0", ":", ":", "2", "]", "=", "p", "[", "0", ":", ":", "2", "]", "-", "xmin", "# .clamp(min=0, max=w)", "\n", "p", "[", "1", ":", ":", "2", "]", "=", "p", "[", "1", ":", ":", "2", "]", "-", "ymin", "# .clamp(min=0, max=h)", "\n", "cropped_polygons", ".", "append", "(", "p", ")", "\n", "\n", "", "return", "PolygonInstance", "(", "cropped_polygons", ",", "size", "=", "(", "w", ",", "h", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.__len__": [[300, 302], ["len"], "methods", ["None"], ["\n", "", "def", "resize", "(", "self", ",", "size", ")", ":", "\n", "        ", "try", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonInstance.__repr__": [[303, 309], ["len"], "methods", ["None"], ["            ", "iter", "(", "size", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "assert", "isinstance", "(", "size", ",", "(", "int", ",", "float", ")", ")", "\n", "size", "=", "size", ",", "size", "\n", "\n", "", "ratios", "=", "tuple", "(", "\n", "float", "(", "s", ")", "/", "float", "(", "s_orig", ")", "for", "s", ",", "s_orig", "in", "zip", "(", "size", ",", "self", ".", "size", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.__init__": [[316, 364], ["isinstance", "isinstance", "str", "tuple", "isinstance", "isinstance", "type", "segmentation_mask.PolygonInstance", "len", "isinstance", "str", "isinstance", "str", "RuntimeError", "len", "segmentation_mask.PolygonList.polygons.append", "type", "type", "type"], "methods", ["None"], ["\n", "", "ratio_w", ",", "ratio_h", "=", "ratios", "\n", "scaled_polygons", "=", "[", "]", "\n", "for", "poly", "in", "self", ".", "polygons", ":", "\n", "            ", "p", "=", "poly", ".", "clone", "(", ")", "\n", "p", "[", "0", ":", ":", "2", "]", "*=", "ratio_w", "\n", "p", "[", "1", ":", ":", "2", "]", "*=", "ratio_h", "\n", "scaled_polygons", ".", "append", "(", "p", ")", "\n", "\n", "", "return", "PolygonInstance", "(", "scaled_polygons", ",", "size", "=", "size", ")", "\n", "\n", "", "def", "convert_to_binarymask", "(", "self", ")", ":", "\n", "        ", "width", ",", "height", "=", "self", ".", "size", "\n", "# formatting for COCO PythonAPI", "\n", "polygons", "=", "[", "p", ".", "numpy", "(", ")", "for", "p", "in", "self", ".", "polygons", "]", "\n", "rles", "=", "mask_utils", ".", "frPyObjects", "(", "polygons", ",", "height", ",", "width", ")", "\n", "rle", "=", "mask_utils", ".", "merge", "(", "rles", ")", "\n", "mask", "=", "mask_utils", ".", "decode", "(", "rle", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "return", "mask", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "polygons", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_groups={}, \"", ".", "format", "(", "len", "(", "self", ".", "polygons", ")", ")", "\n", "s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "size", "[", "0", "]", ")", "\n", "s", "+=", "\"image_height={})\"", ".", "format", "(", "self", ".", "size", "[", "1", "]", ")", "\n", "return", "s", "\n", "\n", "\n", "", "", "class", "PolygonList", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    This class handles PolygonInstances for all objects in the image\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "polygons", ",", "size", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.transpose": [[365, 376], ["segmentation_mask.PolygonList", "NotImplementedError", "flipped_polygons.append", "polygon.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["\n", "if", "isinstance", "(", "polygons", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "polygons", ")", "==", "0", ":", "\n", "                ", "polygons", "=", "[", "[", "[", "]", "]", "]", "\n", "", "if", "isinstance", "(", "polygons", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.crop": [[377, 385], ["segmentation_mask.PolygonList", "cropped_polygons.append", "polygon.crop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop"], ["                ", "assert", "isinstance", "(", "polygons", "[", "0", "]", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ",", "str", "(", "\n", "type", "(", "polygons", "[", "0", "]", "[", "0", "]", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "polygons", "[", "0", "]", ",", "PolygonInstance", ")", ",", "str", "(", "\n", "type", "(", "polygons", "[", "0", "]", ")", "\n", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "polygons", ",", "PolygonList", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.resize": [[386, 393], ["segmentation_mask.PolygonList", "resized_polygons.append", "polygon.resize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize"], ["            ", "size", "=", "polygons", ".", "size", "\n", "polygons", "=", "polygons", ".", "polygons", "\n", "\n", "", "else", ":", "\n", "            ", "RuntimeError", "(", "\n", "\"Type of argument `polygons` is not allowed:%s\"", "\n", "%", "(", "type", "(", "polygons", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.to": [[394, 396], ["None"], "methods", ["None"], ["\n", "", "assert", "isinstance", "(", "size", ",", "(", "list", ",", "tuple", ")", ")", ",", "str", "(", "type", "(", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.convert_to_binarymask": [[397, 405], ["segmentation_mask.BinaryMaskList", "len", "torch.stack", "torch.empty", "p.convert_to_binarymask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.convert_to_binarymask"], ["self", ".", "polygons", "=", "[", "]", "\n", "for", "p", "in", "polygons", ":", "\n", "            ", "p", "=", "PolygonInstance", "(", "p", ",", "size", ")", "\n", "if", "len", "(", "p", ")", ">", "0", ":", "\n", "                ", "self", ".", "polygons", ".", "append", "(", "p", ")", "\n", "\n", "", "", "self", ".", "size", "=", "tuple", "(", "size", ")", "\n", "\n", "", "def", "transpose", "(", "self", ",", "method", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.__len__": [[406, 408], ["len"], "methods", ["None"], ["        ", "if", "method", "not", "in", "(", "FLIP_LEFT_RIGHT", ",", "FLIP_TOP_BOTTOM", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.__getitem__": [[409, 425], ["isinstance", "segmentation_mask.PolygonList", "isinstance", "item.tolist.tolist.nonzero", "item.tolist.tolist.tolist", "selected_polygons.append", "isinstance", "item.tolist.tolist.squeeze", "item.tolist.tolist.numel"], "methods", ["None"], [")", "\n", "\n", "", "flipped_polygons", "=", "[", "]", "\n", "for", "polygon", "in", "self", ".", "polygons", ":", "\n", "            ", "flipped_polygons", ".", "append", "(", "polygon", ".", "transpose", "(", "method", ")", ")", "\n", "\n", "", "return", "PolygonList", "(", "flipped_polygons", ",", "size", "=", "self", ".", "size", ")", "\n", "\n", "", "def", "crop", "(", "self", ",", "box", ")", ":", "\n", "        ", "w", ",", "h", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", ",", "box", "[", "3", "]", "-", "box", "[", "1", "]", "\n", "cropped_polygons", "=", "[", "]", "\n", "for", "polygon", "in", "self", ".", "polygons", ":", "\n", "            ", "cropped_polygons", ".", "append", "(", "polygon", ".", "crop", "(", "box", ")", ")", "\n", "\n", "", "cropped_size", "=", "w", ",", "h", "\n", "return", "PolygonList", "(", "cropped_polygons", ",", "cropped_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.__iter__": [[426, 428], ["iter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "def", "resize", "(", "self", ",", "size", ")", ":", "\n", "        ", "resized_polygons", "=", "[", "]", "\n", "for", "polygon", "in", "self", ".", "polygons", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.__repr__": [[429, 435], ["len"], "methods", ["None"], ["            ", "resized_polygons", ".", "append", "(", "polygon", ".", "resize", "(", "size", ")", ")", "\n", "\n", "", "resized_size", "=", "size", "\n", "return", "PolygonList", "(", "resized_polygons", ",", "resized_size", ")", "\n", "\n", "", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.__init__": [[444, 472], ["isinstance", "isinstance", "isinstance", "isinstance", "tuple", "len", "isinstance", "segmentation_mask.PolygonList", "size[].item", "size[].item", "segmentation_mask.BinaryMaskList", "NotImplementedError", "str"], "methods", ["None"], ["masks", "=", "torch", ".", "empty", "(", "[", "0", ",", "size", "[", "1", "]", ",", "size", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "\n", "", "return", "BinaryMaskList", "(", "masks", ",", "size", "=", "self", ".", "size", ")", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "polygons", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "item", "]", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "slice", ")", ":", "\n", "            ", "selected_polygons", "=", "self", ".", "polygons", "[", "item", "]", "\n", "", "else", ":", "\n", "# advanced indexing on a single dimension", "\n", "            ", "selected_polygons", "=", "[", "]", "\n", "if", "isinstance", "(", "item", ",", "torch", ".", "Tensor", ")", "and", "item", ".", "dtype", "==", "torch", ".", "bool", ":", "\n", "                ", "item", "=", "item", ".", "nonzero", "(", ")", "\n", "item", "=", "item", ".", "squeeze", "(", "1", ")", "if", "item", ".", "numel", "(", ")", ">", "0", "else", "item", "\n", "item", "=", "item", ".", "tolist", "(", ")", "\n", "", "for", "i", "in", "item", ":", "\n", "                ", "selected_polygons", ".", "append", "(", "self", ".", "polygons", "[", "i", "]", ")", "\n", "", "", "return", "PolygonList", "(", "selected_polygons", ",", "size", "=", "self", ".", "size", ")", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "polygons", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={}, \"", ".", "format", "(", "len", "(", "self", ".", "polygons", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.transpose": [[473, 476], ["segmentation_mask.SegmentationMask.instances.transpose", "segmentation_mask.SegmentationMask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "size", "[", "0", "]", ")", "\n", "s", "+=", "\"image_height={})\"", ".", "format", "(", "self", ".", "size", "[", "1", "]", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.crop": [[477, 481], ["segmentation_mask.SegmentationMask.instances.crop", "segmentation_mask.SegmentationMask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop"], ["\n", "", "", "class", "SegmentationMask", "(", "object", ")", ":", "\n", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.resize": [[482, 486], ["segmentation_mask.SegmentationMask.instances.resize", "segmentation_mask.SegmentationMask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize"], ["\n", "\n", "def", "__init__", "(", "self", ",", "instances", ",", "size", ",", "mode", "=", "\"poly\"", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.to": [[487, 489], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.convert": [[490, 502], ["segmentation_mask.SegmentationMask", "segmentation_mask.SegmentationMask.instances.convert_to_polygon", "segmentation_mask.SegmentationMask.instances.convert_to_binarymask", "NotImplementedError", "str"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.BinaryMaskList.convert_to_polygon", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.convert_to_binarymask"], ["\n", "\n", "assert", "isinstance", "(", "size", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "size", ")", "==", "2", "\n", "if", "isinstance", "(", "size", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "assert", "isinstance", "(", "size", "[", "1", "]", ",", "torch", ".", "Tensor", ")", "\n", "size", "=", "size", "[", "0", "]", ".", "item", "(", ")", ",", "size", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "", "assert", "isinstance", "(", "size", "[", "0", "]", ",", "(", "int", ",", "float", ")", ")", "\n", "assert", "isinstance", "(", "size", "[", "1", "]", ",", "(", "int", ",", "float", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.get_mask_tensor": [[503, 509], ["instances.convert_to_binarymask.convert_to_binarymask.masks.squeeze", "instances.convert_to_binarymask.convert_to_binarymask.convert_to_binarymask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.PolygonList.convert_to_binarymask"], ["\n", "if", "mode", "==", "\"poly\"", ":", "\n", "            ", "self", ".", "instances", "=", "PolygonList", "(", "instances", ",", "size", ")", "\n", "", "elif", "mode", "==", "\"mask\"", ":", "\n", "            ", "self", ".", "instances", "=", "BinaryMaskList", "(", "instances", ",", "size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Unknown mode: %s\"", "%", "str", "(", "mode", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.__len__": [[510, 512], ["len"], "methods", ["None"], ["\n", "", "self", ".", "mode", "=", "mode", "\n", "self", ".", "size", "=", "tuple", "(", "size", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.__getitem__": [[513, 516], ["segmentation_mask.SegmentationMask.instances.__getitem__", "segmentation_mask.SegmentationMask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__getitem__"], ["\n", "", "def", "transpose", "(", "self", ",", "method", ")", ":", "\n", "        ", "flipped_instances", "=", "self", ".", "instances", ".", "transpose", "(", "method", ")", "\n", "return", "SegmentationMask", "(", "flipped_instances", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.__iter__": [[517, 520], ["None"], "methods", ["None"], ["\n", "", "def", "crop", "(", "self", ",", "box", ")", ":", "\n", "        ", "cropped_instances", "=", "self", ".", "instances", ".", "crop", "(", "box", ")", "\n", "cropped_size", "=", "cropped_instances", ".", "size", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.__next__": [[521, 527], ["StopIteration", "segmentation_mask.SegmentationMask.__len__", "segmentation_mask.SegmentationMask.__getitem__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__len__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__getitem__"], ["return", "SegmentationMask", "(", "cropped_instances", ",", "cropped_size", ",", "self", ".", "mode", ")", "\n", "\n", "", "def", "resize", "(", "self", ",", "size", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "resized_instances", "=", "self", ".", "instances", ".", "resize", "(", "size", ")", "\n", "resized_size", "=", "size", "\n", "return", "SegmentationMask", "(", "resized_instances", ",", "resized_size", ",", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.__repr__": [[530, 537], ["len"], "methods", ["None"], ["\n", "", "def", "convert", "(", "self", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "self", ".", "mode", ":", "\n", "            ", "return", "self", "\n", "\n", "", "if", "mode", "==", "\"poly\"", ":", "\n", "            ", "converted_instances", "=", "self", ".", "instances", ".", "convert_to_polygon", "(", ")", "\n", "", "elif", "mode", "==", "\"mask\"", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.__init__": [[15, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tensors", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            tensors (tensor)\n            image_sizes (list[tuple[int, int]])\n        \"\"\"", "\n", "self", ".", "tensors", "=", "tensors", "\n", "self", ".", "image_sizes", "=", "image_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.to": [[24, 27], ["image_list.ImageList.tensors.to", "image_list.ImageList"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cast_tensor", "=", "self", ".", "tensors", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "ImageList", "(", "cast_tensor", ",", "self", ".", "image_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list": [[29, 73], ["isinstance", "isinstance", "isinstance", "image_list.ImageList", "isinstance", "tensors.dim", "tensors.dim", "tuple", "tensors[].new().zero_", "zip", "image_list.ImageList", "TypeError", "list", "int", "int", "tuple", "pad_img[].copy_", "max", "len", "tensors[].new", "type", "zip", "math.ceil", "math.ceil"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "", "def", "to_image_list", "(", "tensors", ",", "size_divisible", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    tensors can be an ImageList, a torch.Tensor or\n    an iterable of Tensors. It can't be a numpy array.\n    When tensors is an iterable of Tensors, it pads\n    the Tensors with zeros so that they have the same\n    shape\n    \"\"\"", "\n", "if", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", "and", "size_divisible", ">", "0", ":", "\n", "        ", "tensors", "=", "[", "tensors", "]", "\n", "\n", "", "if", "isinstance", "(", "tensors", ",", "ImageList", ")", ":", "\n", "        ", "return", "tensors", "\n", "", "elif", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", ":", "\n", "# single tensor shape can be inferred", "\n", "        ", "if", "tensors", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "tensors", "=", "tensors", "[", "None", "]", "\n", "", "assert", "tensors", ".", "dim", "(", ")", "==", "4", "\n", "image_sizes", "=", "[", "tensor", ".", "shape", "[", "-", "2", ":", "]", "for", "tensor", "in", "tensors", "]", "\n", "return", "ImageList", "(", "tensors", ",", "image_sizes", ")", "\n", "", "elif", "isinstance", "(", "tensors", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "max_size", "=", "tuple", "(", "max", "(", "s", ")", "for", "s", "in", "zip", "(", "*", "[", "img", ".", "shape", "for", "img", "in", "tensors", "]", ")", ")", "\n", "\n", "# TODO Ideally, just remove this and let me model handle arbitrary", "\n", "# input sizs", "\n", "if", "size_divisible", ">", "0", ":", "\n", "            ", "import", "math", "\n", "\n", "stride", "=", "size_divisible", "\n", "max_size", "=", "list", "(", "max_size", ")", "\n", "max_size", "[", "1", "]", "=", "int", "(", "math", ".", "ceil", "(", "max_size", "[", "1", "]", "/", "stride", ")", "*", "stride", ")", "\n", "max_size", "[", "2", "]", "=", "int", "(", "math", ".", "ceil", "(", "max_size", "[", "2", "]", "/", "stride", ")", "*", "stride", ")", "\n", "max_size", "=", "tuple", "(", "max_size", ")", "\n", "\n", "", "batch_shape", "=", "(", "len", "(", "tensors", ")", ",", ")", "+", "max_size", "\n", "batched_imgs", "=", "tensors", "[", "0", "]", ".", "new", "(", "*", "batch_shape", ")", ".", "zero_", "(", ")", "\n", "for", "img", ",", "pad_img", "in", "zip", "(", "tensors", ",", "batched_imgs", ")", ":", "\n", "            ", "pad_img", "[", ":", "img", ".", "shape", "[", "0", "]", ",", ":", "img", ".", "shape", "[", "1", "]", ",", ":", "img", ".", "shape", "[", "2", "]", "]", ".", "copy_", "(", "img", ")", "\n", "\n", "", "image_sizes", "=", "[", "im", ".", "shape", "[", "-", "2", ":", "]", "for", "im", "in", "tensors", "]", "\n", "\n", "return", "ImageList", "(", "batched_imgs", ",", "image_sizes", ")", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"Unsupported type for to_image_list: {}\"", ".", "format", "(", "type", "(", "tensors", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.__init__": [[19, 38], ["torch.as_tensor", "isinstance", "torch.device", "torch.as_tensor.ndimension", "ValueError", "torch.as_tensor.size", "ValueError", "ValueError", "torch.as_tensor.ndimension", "torch.as_tensor.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "__init__", "(", "self", ",", "bbox", ",", "image_size", ",", "mode", "=", "\"xyxy\"", ")", ":", "\n", "        ", "device", "=", "bbox", ".", "device", "if", "isinstance", "(", "bbox", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "bbox", "=", "torch", ".", "as_tensor", "(", "bbox", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "if", "bbox", ".", "ndimension", "(", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"bbox should have 2 dimensions, got {}\"", ".", "format", "(", "bbox", ".", "ndimension", "(", ")", ")", "\n", ")", "\n", "", "if", "bbox", ".", "size", "(", "-", "1", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"last dimension of bbox should have a \"", "\n", "\"size of 4, got {}\"", ".", "format", "(", "bbox", ".", "size", "(", "-", "1", ")", ")", "\n", ")", "\n", "", "if", "mode", "not", "in", "(", "\"xyxy\"", ",", "\"xywh\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode should be 'xyxy' or 'xywh'\"", ")", "\n", "\n", "", "self", ".", "bbox", "=", "bbox", "\n", "self", ".", "size", "=", "image_size", "# (image_width, image_height)", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "extra_fields", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.add_field": [[39, 41], ["None"], "methods", ["None"], ["", "def", "add_field", "(", "self", ",", "field", ",", "field_data", ")", ":", "\n", "        ", "self", ".", "extra_fields", "[", "field", "]", "=", "field_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.get_field": [[42, 44], ["None"], "methods", ["None"], ["", "def", "get_field", "(", "self", ",", "field", ")", ":", "\n", "        ", "return", "self", ".", "extra_fields", "[", "field", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.has_field": [[45, 47], ["None"], "methods", ["None"], ["", "def", "has_field", "(", "self", ",", "field", ")", ":", "\n", "        ", "return", "field", "in", "self", ".", "extra_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields": [[48, 50], ["list", "bounding_box.BoxList.extra_fields.keys"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "fields", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "extra_fields", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._copy_extra_fields": [[51, 54], ["bbox.extra_fields.items"], "methods", ["None"], ["", "def", "_copy_extra_fields", "(", "self", ",", "bbox", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "bbox", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "extra_fields", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.convert": [[55, 74], ["bounding_box.BoxList._split_into_xyxy", "bounding_box.BoxList._copy_extra_fields", "ValueError", "torch.cat", "bounding_box.BoxList", "torch.cat", "bounding_box.BoxList"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._split_into_xyxy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._copy_extra_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "", "def", "convert", "(", "self", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "not", "in", "(", "\"xyxy\"", ",", "\"xywh\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode should be 'xyxy' or 'xywh'\"", ")", "\n", "", "if", "mode", "==", "self", ".", "mode", ":", "\n", "            ", "return", "self", "\n", "# we only have two modes, so don't need to check", "\n", "# self.mode", "\n", "", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "self", ".", "_split_into_xyxy", "(", ")", "\n", "if", "mode", "==", "\"xyxy\"", ":", "\n", "            ", "bbox", "=", "torch", ".", "cat", "(", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ",", "dim", "=", "-", "1", ")", "\n", "bbox", "=", "BoxList", "(", "bbox", ",", "self", ".", "size", ",", "mode", "=", "mode", ")", "\n", "", "else", ":", "\n", "            ", "TO_REMOVE", "=", "1", "\n", "bbox", "=", "torch", ".", "cat", "(", "\n", "(", "xmin", ",", "ymin", ",", "xmax", "-", "xmin", "+", "TO_REMOVE", ",", "ymax", "-", "ymin", "+", "TO_REMOVE", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "bbox", "=", "BoxList", "(", "bbox", ",", "self", ".", "size", ",", "mode", "=", "mode", ")", "\n", "", "bbox", ".", "_copy_extra_fields", "(", "self", ")", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._split_into_xyxy": [[75, 90], ["bounding_box.BoxList.bbox.split", "bounding_box.BoxList.bbox.split", "RuntimeError"], "methods", ["None"], ["", "def", "_split_into_xyxy", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "\"xyxy\"", ":", "\n", "            ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "self", ".", "bbox", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "", "elif", "self", ".", "mode", "==", "\"xywh\"", ":", "\n", "            ", "TO_REMOVE", "=", "1", "\n", "xmin", ",", "ymin", ",", "w", ",", "h", "=", "self", ".", "bbox", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "return", "(", "\n", "xmin", ",", "\n", "ymin", ",", "\n", "xmin", "+", "(", "w", "-", "TO_REMOVE", ")", ".", "clamp", "(", "min", "=", "0", ")", ",", "\n", "ymin", "+", "(", "h", "-", "TO_REMOVE", ")", ".", "clamp", "(", "min", "=", "0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Should not be here\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.resize": [[91, 128], ["tuple", "bounding_box.BoxList._split_into_xyxy", "torch.cat", "bounding_box.BoxList", "bounding_box.BoxList.extra_fields.items", "bounding_box.BoxList.convert", "bounding_box.BoxList", "bounding_box.BoxList.extra_fields.items", "bounding_box.BoxList.add_field", "bounding_box.BoxList.add_field", "isinstance", "v.resize.resize.resize", "float", "float", "zip", "isinstance", "v.resize.resize.resize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._split_into_xyxy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize"], ["", "", "def", "resize", "(", "self", ",", "size", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns a resized copy of this bounding box\n\n        :param size: The requested size in pixels, as a 2-tuple:\n            (width, height).\n        \"\"\"", "\n", "\n", "ratios", "=", "tuple", "(", "float", "(", "s", ")", "/", "float", "(", "s_orig", ")", "for", "s", ",", "s_orig", "in", "zip", "(", "size", ",", "self", ".", "size", ")", ")", "\n", "if", "ratios", "[", "0", "]", "==", "ratios", "[", "1", "]", ":", "\n", "            ", "ratio", "=", "ratios", "[", "0", "]", "\n", "scaled_box", "=", "self", ".", "bbox", "*", "ratio", "\n", "bbox", "=", "BoxList", "(", "scaled_box", ",", "size", ",", "mode", "=", "self", ".", "mode", ")", "\n", "# bbox._copy_extra_fields(self)", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "v", "=", "v", ".", "resize", "(", "size", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "bbox", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "bbox", "\n", "\n", "", "ratio_width", ",", "ratio_height", "=", "ratios", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "self", ".", "_split_into_xyxy", "(", ")", "\n", "scaled_xmin", "=", "xmin", "*", "ratio_width", "\n", "scaled_xmax", "=", "xmax", "*", "ratio_width", "\n", "scaled_ymin", "=", "ymin", "*", "ratio_height", "\n", "scaled_ymax", "=", "ymax", "*", "ratio_height", "\n", "scaled_box", "=", "torch", ".", "cat", "(", "\n", "(", "scaled_xmin", ",", "scaled_ymin", ",", "scaled_xmax", ",", "scaled_ymax", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "bbox", "=", "BoxList", "(", "scaled_box", ",", "size", ",", "mode", "=", "\"xyxy\"", ")", "\n", "# bbox._copy_extra_fields(self)", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "resize", "(", "size", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "bbox", ".", "add_field", "(", "k", ",", "v", ")", "\n", "\n", "", "return", "bbox", ".", "convert", "(", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.transpose": [[129, 166], ["bounding_box.BoxList._split_into_xyxy", "torch.cat", "bounding_box.BoxList", "bounding_box.BoxList.extra_fields.items", "bounding_box.BoxList.convert", "NotImplementedError", "bounding_box.BoxList.add_field", "isinstance", "v.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._split_into_xyxy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "transpose", "(", "self", ",", "method", ")", ":", "\n", "        ", "\"\"\"\n        Transpose bounding box (flip or rotate in 90 degree steps)\n        :param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`,\n          :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`,\n          :py:attr:`PIL.Image.ROTATE_180`, :py:attr:`PIL.Image.ROTATE_270`,\n          :py:attr:`PIL.Image.TRANSPOSE` or :py:attr:`PIL.Image.TRANSVERSE`.\n        \"\"\"", "\n", "if", "method", "not", "in", "(", "FLIP_LEFT_RIGHT", ",", "FLIP_TOP_BOTTOM", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented\"", "\n", ")", "\n", "\n", "", "image_width", ",", "image_height", "=", "self", ".", "size", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "self", ".", "_split_into_xyxy", "(", ")", "\n", "if", "method", "==", "FLIP_LEFT_RIGHT", ":", "\n", "            ", "TO_REMOVE", "=", "1", "\n", "transposed_xmin", "=", "image_width", "-", "xmax", "-", "TO_REMOVE", "\n", "transposed_xmax", "=", "image_width", "-", "xmin", "-", "TO_REMOVE", "\n", "transposed_ymin", "=", "ymin", "\n", "transposed_ymax", "=", "ymax", "\n", "", "elif", "method", "==", "FLIP_TOP_BOTTOM", ":", "\n", "            ", "transposed_xmin", "=", "xmin", "\n", "transposed_xmax", "=", "xmax", "\n", "transposed_ymin", "=", "image_height", "-", "ymax", "\n", "transposed_ymax", "=", "image_height", "-", "ymin", "\n", "\n", "", "transposed_boxes", "=", "torch", ".", "cat", "(", "\n", "(", "transposed_xmin", ",", "transposed_ymin", ",", "transposed_xmax", ",", "transposed_ymax", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "bbox", "=", "BoxList", "(", "transposed_boxes", ",", "self", ".", "size", ",", "mode", "=", "\"xyxy\"", ")", "\n", "# bbox._copy_extra_fields(self)", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "transpose", "(", "method", ")", "\n", "", "bbox", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "bbox", ".", "convert", "(", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.crop": [[167, 194], ["bounding_box.BoxList._split_into_xyxy", "torch.cat", "bounding_box.BoxList", "bounding_box.BoxList.extra_fields.items", "bounding_box.BoxList.convert", "bounding_box.BoxList.add_field", "isinstance", "v.crop.crop.crop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList._split_into_xyxy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop"], ["", "def", "crop", "(", "self", ",", "box", ")", ":", "\n", "        ", "\"\"\"\n        Crops a rectangular region from this bounding box. The box is a\n        4-tuple defining the left, upper, right, and lower pixel\n        coordinate.\n        \"\"\"", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "self", ".", "_split_into_xyxy", "(", ")", "\n", "w", ",", "h", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", ",", "box", "[", "3", "]", "-", "box", "[", "1", "]", "\n", "cropped_xmin", "=", "(", "xmin", "-", "box", "[", "0", "]", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "cropped_ymin", "=", "(", "ymin", "-", "box", "[", "1", "]", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "cropped_xmax", "=", "(", "xmax", "-", "box", "[", "0", "]", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "cropped_ymax", "=", "(", "ymax", "-", "box", "[", "1", "]", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "\n", "# TODO should I filter empty boxes here?", "\n", "if", "False", ":", "\n", "            ", "is_empty", "=", "(", "cropped_xmin", "==", "cropped_xmax", ")", "|", "(", "cropped_ymin", "==", "cropped_ymax", ")", "\n", "\n", "", "cropped_box", "=", "torch", ".", "cat", "(", "\n", "(", "cropped_xmin", ",", "cropped_ymin", ",", "cropped_xmax", ",", "cropped_ymax", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "bbox", "=", "BoxList", "(", "cropped_box", ",", "(", "w", ",", "h", ")", ",", "mode", "=", "\"xyxy\"", ")", "\n", "# bbox._copy_extra_fields(self)", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "crop", "(", "box", ")", "\n", "", "bbox", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "bbox", ".", "convert", "(", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.to": [[197, 204], ["bounding_box.BoxList", "bounding_box.BoxList.extra_fields.items", "bounding_box.BoxList.bbox.to", "hasattr", "bounding_box.BoxList.add_field", "v.to.to.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "bbox", "=", "BoxList", "(", "self", ".", "bbox", ".", "to", "(", "device", ")", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "v", ",", "\"to\"", ")", ":", "\n", "                ", "v", "=", "v", ".", "to", "(", "device", ")", "\n", "", "bbox", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.__getitem__": [[205, 210], ["bounding_box.BoxList", "bounding_box.BoxList.extra_fields.items", "bounding_box.BoxList.add_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "bbox", "=", "BoxList", "(", "self", ".", "bbox", "[", "item", "]", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "bbox", ".", "add_field", "(", "k", ",", "v", "[", "item", "]", ")", "\n", "", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.__len__": [[211, 213], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "bbox", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image": [[214, 225], ["bounding_box.BoxList.bbox[].clamp_", "bounding_box.BoxList.bbox[].clamp_", "bounding_box.BoxList.bbox[].clamp_", "bounding_box.BoxList.bbox[].clamp_"], "methods", ["None"], ["", "def", "clip_to_image", "(", "self", ",", "remove_empty", "=", "True", ")", ":", "\n", "        ", "TO_REMOVE", "=", "1", "\n", "self", ".", "bbox", "[", ":", ",", "0", "]", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "self", ".", "size", "[", "0", "]", "-", "TO_REMOVE", ")", "\n", "self", ".", "bbox", "[", ":", ",", "1", "]", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "self", ".", "size", "[", "1", "]", "-", "TO_REMOVE", ")", "\n", "self", ".", "bbox", "[", ":", ",", "2", "]", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "self", ".", "size", "[", "0", "]", "-", "TO_REMOVE", ")", "\n", "self", ".", "bbox", "[", ":", ",", "3", "]", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "self", ".", "size", "[", "1", "]", "-", "TO_REMOVE", ")", "\n", "if", "remove_empty", ":", "\n", "            ", "box", "=", "self", ".", "bbox", "\n", "keep", "=", "(", "box", "[", ":", ",", "3", "]", ">", "box", "[", ":", ",", "1", "]", ")", "&", "(", "box", "[", ":", ",", "2", "]", ">", "box", "[", ":", ",", "0", "]", ")", "\n", "return", "self", "[", "keep", "]", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.area": [[226, 237], ["RuntimeError"], "methods", ["None"], ["", "def", "area", "(", "self", ")", ":", "\n", "        ", "box", "=", "self", ".", "bbox", "\n", "if", "self", ".", "mode", "==", "\"xyxy\"", ":", "\n", "            ", "TO_REMOVE", "=", "1", "\n", "area", "=", "(", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", "+", "TO_REMOVE", ")", "*", "(", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", "+", "TO_REMOVE", ")", "\n", "", "elif", "self", ".", "mode", "==", "\"xywh\"", ":", "\n", "            ", "area", "=", "box", "[", ":", ",", "2", "]", "*", "box", "[", ":", ",", "3", "]", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Should not be here\"", ")", "\n", "\n", "", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields": [[238, 248], ["bounding_box.BoxList", "isinstance", "bounding_box.BoxList.has_field", "bounding_box.BoxList.add_field", "bounding_box.BoxList.get_field", "KeyError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.has_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "copy_with_fields", "(", "self", ",", "fields", ",", "skip_missing", "=", "False", ")", ":", "\n", "        ", "bbox", "=", "BoxList", "(", "self", ".", "bbox", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n", "if", "not", "isinstance", "(", "fields", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "fields", "=", "[", "fields", "]", "\n", "", "for", "field", "in", "fields", ":", "\n", "            ", "if", "self", ".", "has_field", "(", "field", ")", ":", "\n", "                ", "bbox", ".", "add_field", "(", "field", ",", "self", ".", "get_field", "(", "field", ")", ")", "\n", "", "elif", "not", "skip_missing", ":", "\n", "                ", "raise", "KeyError", "(", "\"Field '{}' not found in {}\"", ".", "format", "(", "field", ",", "self", ")", ")", "\n", "", "", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.__repr__": [[249, 256], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_boxes={}, \"", ".", "format", "(", "len", "(", "self", ")", ")", "\n", "s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "size", "[", "0", "]", ")", "\n", "s", "+=", "\"image_height={}, \"", ".", "format", "(", "self", ".", "size", "[", "1", "]", ")", "\n", "s", "+=", "\"mode={})\"", ".", "format", "(", "self", ".", "mode", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_nms": [[10, 33], ["boxlist.convert.convert", "boxlist.convert.get_field", "fcos_core.layers.nms", "boxlist.convert.convert"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["def", "boxlist_nms", "(", "boxlist", ",", "nms_thresh", ",", "max_proposals", "=", "-", "1", ",", "score_field", "=", "\"scores\"", ")", ":", "\n", "    ", "\"\"\"\n    Performs non-maximum suppression on a boxlist, with scores specified\n    in a boxlist field via score_field.\n\n    Arguments:\n        boxlist(BoxList)\n        nms_thresh (float)\n        max_proposals (int): if > 0, then only the top max_proposals are kept\n            after non-maximum suppression\n        score_field (str)\n    \"\"\"", "\n", "if", "nms_thresh", "<=", "0", ":", "\n", "        ", "return", "boxlist", "\n", "", "mode", "=", "boxlist", ".", "mode", "\n", "boxlist", "=", "boxlist", ".", "convert", "(", "\"xyxy\"", ")", "\n", "boxes", "=", "boxlist", ".", "bbox", "\n", "score", "=", "boxlist", ".", "get_field", "(", "score_field", ")", "\n", "keep", "=", "_box_nms", "(", "boxes", ",", "score", ",", "nms_thresh", ")", "\n", "if", "max_proposals", ">", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "max_proposals", "]", "\n", "", "boxlist", "=", "boxlist", "[", "keep", "]", "\n", "return", "boxlist", ".", "convert", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_ml_nms": [[35, 60], ["boxlist.convert.convert", "boxlist.convert.get_field", "boxlist.convert.get_field", "fcos_core.layers.ml_nms", "boxlist.convert.convert", "boxlist.get_field.float"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "boxlist_ml_nms", "(", "boxlist", ",", "nms_thresh", ",", "max_proposals", "=", "-", "1", ",", "\n", "score_field", "=", "\"scores\"", ",", "label_field", "=", "\"labels\"", ")", ":", "\n", "    ", "\"\"\"\n    Performs non-maximum suppression on a boxlist, with scores specified\n    in a boxlist field via score_field.\n\n    Arguments:\n        boxlist(BoxList)\n        nms_thresh (float)\n        max_proposals (int): if > 0, then only the top max_proposals are kept\n            after non-maximum suppression\n        score_field (str)\n    \"\"\"", "\n", "if", "nms_thresh", "<=", "0", ":", "\n", "        ", "return", "boxlist", "\n", "", "mode", "=", "boxlist", ".", "mode", "\n", "boxlist", "=", "boxlist", ".", "convert", "(", "\"xyxy\"", ")", "\n", "boxes", "=", "boxlist", ".", "bbox", "\n", "scores", "=", "boxlist", ".", "get_field", "(", "score_field", ")", "\n", "labels", "=", "boxlist", ".", "get_field", "(", "label_field", ")", "\n", "keep", "=", "_box_ml_nms", "(", "boxes", ",", "scores", ",", "labels", ".", "float", "(", ")", ",", "nms_thresh", ")", "\n", "if", "max_proposals", ">", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "max_proposals", "]", "\n", "", "boxlist", "=", "boxlist", "[", "keep", "]", "\n", "return", "boxlist", ".", "convert", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.remove_small_boxes": [[62, 77], ["xywh_boxes.unbind", "boxlist.convert"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "remove_small_boxes", "(", "boxlist", ",", "min_size", ")", ":", "\n", "    ", "\"\"\"\n    Only keep boxes with both sides >= min_size\n\n    Arguments:\n        boxlist (Boxlist)\n        min_size (int)\n    \"\"\"", "\n", "# TODO maybe add an API for querying the ws / hs", "\n", "xywh_boxes", "=", "boxlist", ".", "convert", "(", "\"xywh\"", ")", ".", "bbox", "\n", "_", ",", "_", ",", "ws", ",", "hs", "=", "xywh_boxes", ".", "unbind", "(", "dim", "=", "1", ")", "\n", "keep", "=", "(", "\n", "(", "ws", ">=", "min_size", ")", "&", "(", "hs", ">=", "min_size", ")", "\n", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "boxlist", "[", "keep", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou": [[81, 117], ["len", "len", "boxlist1.area", "boxlist2.area", "torch.max", "torch.min", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area"], ["", "def", "boxlist_iou", "(", "boxlist1", ",", "boxlist2", ")", ":", "\n", "    ", "\"\"\"Compute the intersection over union of two set of boxes.\n    The box order must be (xmin, ymin, xmax, ymax).\n\n    Arguments:\n      box1: (BoxList) bounding boxes, sized [N,4].\n      box2: (BoxList) bounding boxes, sized [M,4].\n\n    Returns:\n      (tensor) iou, sized [N,M].\n\n    Reference:\n      https://github.com/chainer/chainercv/blob/master/chainercv/utils/bbox/bbox_iou.py\n    \"\"\"", "\n", "if", "boxlist1", ".", "size", "!=", "boxlist2", ".", "size", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"boxlists should have same image size, got {}, {}\"", ".", "format", "(", "boxlist1", ",", "boxlist2", ")", ")", "\n", "", "boxlist1", "=", "boxlist1", ".", "convert", "(", "\"xyxy\"", ")", "\n", "boxlist2", "=", "boxlist2", ".", "convert", "(", "\"xyxy\"", ")", "\n", "N", "=", "len", "(", "boxlist1", ")", "\n", "M", "=", "len", "(", "boxlist2", ")", "\n", "\n", "area1", "=", "boxlist1", ".", "area", "(", ")", "\n", "area2", "=", "boxlist2", ".", "area", "(", ")", "\n", "\n", "box1", ",", "box2", "=", "boxlist1", ".", "bbox", ",", "boxlist2", ".", "bbox", "\n", "\n", "lt", "=", "torch", ".", "max", "(", "box1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "box2", "[", ":", ",", ":", "2", "]", ")", "# [N,M,2]", "\n", "rb", "=", "torch", ".", "min", "(", "box1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "box2", "[", ":", ",", "2", ":", "]", ")", "# [N,M,2]", "\n", "\n", "TO_REMOVE", "=", "1", "\n", "\n", "wh", "=", "(", "rb", "-", "lt", "+", "TO_REMOVE", ")", ".", "clamp", "(", "min", "=", "0", ")", "# [N,M,2]", "\n", "inter", "=", "wh", "[", ":", ",", ":", ",", "0", "]", "*", "wh", "[", ":", ",", ":", ",", "1", "]", "# [N,M]", "\n", "\n", "iou", "=", "inter", "/", "(", "area1", "[", ":", ",", "None", "]", "+", "area2", "-", "inter", ")", "\n", "return", "iou", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops._cat": [[120, 128], ["isinstance", "torch.cat", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["# TODO redundant, remove", "\n", "", "def", "_cat", "(", "tensors", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist": [[130, 157], ["isinstance", "all", "all", "all", "set", "all", "bounding_box.BoxList", "bboxes[].fields", "boxlist_ops._cat", "boxlist_ops._cat", "bounding_box.BoxList.add_field", "isinstance", "set", "bbox.get_field", "bbox.fields"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops._cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops._cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields"], ["\n", "", "def", "cat_boxlist", "(", "bboxes", ")", ":", "\n", "    ", "\"\"\"\n    Concatenates a list of BoxList (having the same image size) into a\n    single BoxList\n\n    Arguments:\n        bboxes (list[BoxList])\n    \"\"\"", "\n", "assert", "isinstance", "(", "bboxes", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "all", "(", "isinstance", "(", "bbox", ",", "BoxList", ")", "for", "bbox", "in", "bboxes", ")", "\n", "\n", "size", "=", "bboxes", "[", "0", "]", ".", "size", "\n", "assert", "all", "(", "bbox", ".", "size", "==", "size", "for", "bbox", "in", "bboxes", ")", "\n", "\n", "mode", "=", "bboxes", "[", "0", "]", ".", "mode", "\n", "assert", "all", "(", "bbox", ".", "mode", "==", "mode", "for", "bbox", "in", "bboxes", ")", "\n", "\n", "fields", "=", "set", "(", "bboxes", "[", "0", "]", ".", "fields", "(", ")", ")", "\n", "assert", "all", "(", "set", "(", "bbox", ".", "fields", "(", ")", ")", "==", "fields", "for", "bbox", "in", "bboxes", ")", "\n", "\n", "cat_boxes", "=", "BoxList", "(", "_cat", "(", "[", "bbox", ".", "bbox", "for", "bbox", "in", "bboxes", "]", ",", "dim", "=", "0", ")", ",", "size", ",", "mode", ")", "\n", "\n", "for", "field", "in", "fields", ":", "\n", "        ", "data", "=", "_cat", "(", "[", "bbox", ".", "get_field", "(", "field", ")", "for", "bbox", "in", "bboxes", "]", ",", "dim", "=", "0", ")", "\n", "cat_boxes", ".", "add_field", "(", "field", ",", "data", ")", "\n", "\n", "", "return", "cat_boxes", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.__init__": [[9, 25], ["torch.as_tensor", "isinstance", "torch.device", "keypoints.view.view.view"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["    ", "def", "__init__", "(", "self", ",", "keypoints", ",", "size", ",", "mode", "=", "None", ")", ":", "\n", "# FIXME remove check once we have better integration with device", "\n", "# in my version this would consistently return a CPU tensor", "\n", "        ", "device", "=", "keypoints", ".", "device", "if", "isinstance", "(", "keypoints", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "keypoints", "=", "torch", ".", "as_tensor", "(", "keypoints", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "num_keypoints", "=", "keypoints", ".", "shape", "[", "0", "]", "\n", "if", "num_keypoints", ":", "\n", "            ", "keypoints", "=", "keypoints", ".", "view", "(", "num_keypoints", ",", "-", "1", ",", "3", ")", "\n", "\n", "# TODO should I split them?", "\n", "# self.visibility = keypoints[..., 2]", "\n", "", "self", ".", "keypoints", "=", "keypoints", "# [..., :2]", "\n", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "extra_fields", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop": [[26, 28], ["NotImplementedError"], "methods", ["None"], ["", "def", "crop", "(", "self", ",", "box", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize": [[29, 39], ["tuple", "keypoint.Keypoints.keypoints.clone", "keypoint.Keypoints.extra_fields.items", "type", "keypoints.add_field", "float", "float", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["", "def", "resize", "(", "self", ",", "size", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "ratios", "=", "tuple", "(", "float", "(", "s", ")", "/", "float", "(", "s_orig", ")", "for", "s", ",", "s_orig", "in", "zip", "(", "size", ",", "self", ".", "size", ")", ")", "\n", "ratio_w", ",", "ratio_h", "=", "ratios", "\n", "resized_data", "=", "self", ".", "keypoints", ".", "clone", "(", ")", "\n", "resized_data", "[", "...", ",", "0", "]", "*=", "ratio_w", "\n", "resized_data", "[", "...", ",", "1", "]", "*=", "ratio_h", "\n", "keypoints", "=", "type", "(", "self", ")", "(", "resized_data", ",", "size", ",", "self", ".", "mode", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "keypoints", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose": [[40, 60], ["keypoint.Keypoints.extra_fields.items", "NotImplementedError", "type", "type", "keypoints.add_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["", "def", "transpose", "(", "self", ",", "method", ")", ":", "\n", "        ", "if", "method", "not", "in", "(", "FLIP_LEFT_RIGHT", ",", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Only FLIP_LEFT_RIGHT implemented\"", ")", "\n", "\n", "", "flip_inds", "=", "type", "(", "self", ")", ".", "FLIP_INDS", "\n", "flipped_data", "=", "self", ".", "keypoints", "[", ":", ",", "flip_inds", "]", "\n", "width", "=", "self", ".", "size", "[", "0", "]", "\n", "TO_REMOVE", "=", "1", "\n", "# Flip x coordinates", "\n", "flipped_data", "[", "...", ",", "0", "]", "=", "width", "-", "flipped_data", "[", "...", ",", "0", "]", "-", "TO_REMOVE", "\n", "\n", "# Maintain COCO convention that if visibility == 0, then x, y = 0", "\n", "inds", "=", "flipped_data", "[", "...", ",", "2", "]", "==", "0", "\n", "flipped_data", "[", "inds", "]", "=", "0", "\n", "\n", "keypoints", "=", "type", "(", "self", ")", "(", "flipped_data", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "keypoints", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.to": [[61, 68], ["keypoint.Keypoints.extra_fields.items", "type", "keypoint.Keypoints.keypoints.to", "hasattr", "keypoints.add_field", "v.to.to.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "keypoints", "=", "type", "(", "self", ")", "(", "self", ".", "keypoints", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "v", ",", "\"to\"", ")", ":", "\n", "                ", "v", "=", "v", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "keypoints", ".", "add_field", "(", "k", ",", "v", ")", "\n", "", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.__getitem__": [[69, 74], ["keypoint.Keypoints.extra_fields.items", "type", "keypoints.add_field"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "keypoints", "=", "type", "(", "self", ")", "(", "self", ".", "keypoints", "[", "item", "]", ",", "self", ".", "size", ",", "self", ".", "mode", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "keypoints", ".", "add_field", "(", "k", ",", "v", "[", "item", "]", ")", "\n", "", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field": [[75, 77], ["None"], "methods", ["None"], ["", "def", "add_field", "(", "self", ",", "field", ",", "field_data", ")", ":", "\n", "        ", "self", ".", "extra_fields", "[", "field", "]", "=", "field_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field": [[78, 80], ["None"], "methods", ["None"], ["", "def", "get_field", "(", "self", ",", "field", ")", ":", "\n", "        ", "return", "self", ".", "extra_fields", "[", "field", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.__repr__": [[81, 87], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "s", "+=", "'num_instances={}, '", ".", "format", "(", "len", "(", "self", ".", "keypoints", ")", ")", "\n", "s", "+=", "'image_width={}, '", ".", "format", "(", "self", ".", "size", "[", "0", "]", ")", "\n", "s", "+=", "'image_height={})'", ".", "format", "(", "self", ".", "size", "[", "1", "]", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint._create_flip_indices": [[89, 95], ["flip_map.copy", "flip_map.copy.update", "torch.tensor", "names.index", "flip_map.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "", "def", "_create_flip_indices", "(", "names", ",", "flip_map", ")", ":", "\n", "    ", "full_flip_map", "=", "flip_map", ".", "copy", "(", ")", "\n", "full_flip_map", ".", "update", "(", "{", "v", ":", "k", "for", "k", ",", "v", "in", "flip_map", ".", "items", "(", ")", "}", ")", "\n", "flipped_names", "=", "[", "i", "if", "i", "not", "in", "full_flip_map", "else", "full_flip_map", "[", "i", "]", "for", "i", "in", "names", "]", "\n", "flip_indices", "=", "[", "names", ".", "index", "(", "i", ")", "for", "i", "in", "flipped_names", "]", "\n", "return", "torch", ".", "tensor", "(", "flip_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.kp_connections": [[131, 150], ["keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index", "keypoints.index"], "function", ["None"], ["def", "kp_connections", "(", "keypoints", ")", ":", "\n", "    ", "kp_lines", "=", "[", "\n", "[", "keypoints", ".", "index", "(", "'left_eye'", ")", ",", "keypoints", ".", "index", "(", "'right_eye'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'left_eye'", ")", ",", "keypoints", ".", "index", "(", "'nose'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_eye'", ")", ",", "keypoints", ".", "index", "(", "'nose'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_eye'", ")", ",", "keypoints", ".", "index", "(", "'right_ear'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'left_eye'", ")", ",", "keypoints", ".", "index", "(", "'left_ear'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_shoulder'", ")", ",", "keypoints", ".", "index", "(", "'right_elbow'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_elbow'", ")", ",", "keypoints", ".", "index", "(", "'right_wrist'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'left_shoulder'", ")", ",", "keypoints", ".", "index", "(", "'left_elbow'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'left_elbow'", ")", ",", "keypoints", ".", "index", "(", "'left_wrist'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_hip'", ")", ",", "keypoints", ".", "index", "(", "'right_knee'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_knee'", ")", ",", "keypoints", ".", "index", "(", "'right_ankle'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'left_hip'", ")", ",", "keypoints", ".", "index", "(", "'left_knee'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'left_knee'", ")", ",", "keypoints", ".", "index", "(", "'left_ankle'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_shoulder'", ")", ",", "keypoints", ".", "index", "(", "'left_shoulder'", ")", "]", ",", "\n", "[", "keypoints", ".", "index", "(", "'right_hip'", ")", ",", "keypoints", ".", "index", "(", "'left_hip'", ")", "]", ",", "\n", "]", "\n", "return", "kp_lines", "\n", "", "PersonKeypoints", ".", "CONNECTIONS", "=", "kp_connections", "(", "PersonKeypoints", ".", "NAMES", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.keypoints_to_heat_map": [[154, 189], ["x.floor().long.floor().long", "y.floor().long.floor().long", "rois.numel", "rois.new().long", "rois.new().long", "x.floor().long.floor", "y.floor().long.floor", "rois.new", "rois.new"], "function", ["None"], ["def", "keypoints_to_heat_map", "(", "keypoints", ",", "rois", ",", "heatmap_size", ")", ":", "\n", "    ", "if", "rois", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "rois", ".", "new", "(", ")", ".", "long", "(", ")", ",", "rois", ".", "new", "(", ")", ".", "long", "(", ")", "\n", "", "offset_x", "=", "rois", "[", ":", ",", "0", "]", "\n", "offset_y", "=", "rois", "[", ":", ",", "1", "]", "\n", "scale_x", "=", "heatmap_size", "/", "(", "rois", "[", ":", ",", "2", "]", "-", "rois", "[", ":", ",", "0", "]", ")", "\n", "scale_y", "=", "heatmap_size", "/", "(", "rois", "[", ":", ",", "3", "]", "-", "rois", "[", ":", ",", "1", "]", ")", "\n", "\n", "offset_x", "=", "offset_x", "[", ":", ",", "None", "]", "\n", "offset_y", "=", "offset_y", "[", ":", ",", "None", "]", "\n", "scale_x", "=", "scale_x", "[", ":", ",", "None", "]", "\n", "scale_y", "=", "scale_y", "[", ":", ",", "None", "]", "\n", "\n", "x", "=", "keypoints", "[", "...", ",", "0", "]", "\n", "y", "=", "keypoints", "[", "...", ",", "1", "]", "\n", "\n", "x_boundary_inds", "=", "x", "==", "rois", "[", ":", ",", "2", "]", "[", ":", ",", "None", "]", "\n", "y_boundary_inds", "=", "y", "==", "rois", "[", ":", ",", "3", "]", "[", ":", ",", "None", "]", "\n", "\n", "x", "=", "(", "x", "-", "offset_x", ")", "*", "scale_x", "\n", "x", "=", "x", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "y", "=", "(", "y", "-", "offset_y", ")", "*", "scale_y", "\n", "y", "=", "y", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "\n", "x", "[", "x_boundary_inds", "]", "=", "heatmap_size", "-", "1", "\n", "y", "[", "y_boundary_inds", "]", "=", "heatmap_size", "-", "1", "\n", "\n", "valid_loc", "=", "(", "x", ">=", "0", ")", "&", "(", "y", ">=", "0", ")", "&", "(", "x", "<", "heatmap_size", ")", "&", "(", "y", "<", "heatmap_size", ")", "\n", "vis", "=", "keypoints", "[", "...", ",", "2", "]", ">", "0", "\n", "valid", "=", "(", "valid_loc", "&", "vis", ")", ".", "long", "(", ")", "\n", "\n", "lin_ind", "=", "y", "*", "heatmap_size", "+", "x", "\n", "heatmaps", "=", "lin_ind", "*", "valid", "\n", "\n", "return", "heatmaps", ",", "valid", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.__init__": [[20, 222], ["torch.as_tensor", "tensor.reshape().to.reshape().to.size", "isinstance", "torch.device", "tensor.reshape().to.reshape().to.numel", "tensor.reshape().to.reshape().to.reshape().to", "tensor.reshape().to.reshape().to.dim", "tensor.reshape().to.reshape().to.size", "tensor.reshape().to.reshape().to.reshape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor[float]): a Nx5 matrix.  Each row is\n                (x_center, y_center, width, height, angle),\n                in which angle is represented in degrees.\n                While there's no strict range restriction for it,\n                the recommended principal range is between [-180, 180) degrees.\n\n        Assume we have a horizontal box B = (x_center, y_center, width, height),\n        where width is along the x-axis and height is along the y-axis.\n        The rotated box B_rot (x_center, y_center, width, height, angle)\n        can be seen as:\n\n        1. When angle == 0:\n           B_rot == B\n        2. When angle > 0:\n           B_rot is obtained by rotating B w.r.t its center by :math:`|angle|` degrees CCW;\n        3. When angle < 0:\n           B_rot is obtained by rotating B w.r.t its center by :math:`|angle|` degrees CW.\n\n        Mathematically, since the right-handed coordinate system for image space\n        is (y, x), where y is top->down and x is left->right, the 4 vertices of the\n        rotated rectangle :math:`(yr_i, xr_i)` (i = 1, 2, 3, 4) can be obtained from\n        the vertices of the horizontal rectangle :math:`(y_i, x_i)` (i = 1, 2, 3, 4)\n        in the following way (:math:`\\\\theta = angle*\\\\pi/180` is the angle in radians,\n        :math:`(y_c, x_c)` is the center of the rectangle):\n\n        .. math::\n\n            yr_i = \\\\cos(\\\\theta) (y_i - y_c) - \\\\sin(\\\\theta) (x_i - x_c) + y_c,\n\n            xr_i = \\\\sin(\\\\theta) (y_i - y_c) + \\\\cos(\\\\theta) (x_i - x_c) + x_c,\n\n        which is the standard rigid-body rotation transformation.\n\n        Intuitively, the angle is\n        (1) the rotation angle from y-axis in image space\n        to the height vector (top->down in the box's local coordinate system)\n        of the box in CCW, and\n        (2) the rotation angle from x-axis in image space\n        to the width vector (left->right in the box's local coordinate system)\n        of the box in CCW.\n\n        More intuitively, consider the following horizontal box ABCD represented\n        in (x1, y1, x2, y2): (3, 2, 7, 4),\n        covering the [3, 7] x [2, 4] region of the continuous coordinate system\n        which looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  A---B\n            |  |   |\n            |  D---C\n            |\n            v y\n\n        Note that each capital letter represents one 0-dimensional geometric point\n        instead of a 'square pixel' here.\n\n        In the example above, using (x, y) to represent a point we have:\n\n        .. math::\n\n            O = (0, 0), A = (3, 2), B = (7, 2), C = (7, 4), D = (3, 4)\n\n        We name vector AB = vector DC as the width vector in box's local coordinate system, and\n        vector AD = vector BC as the height vector in box's local coordinate system. Initially,\n        when angle = 0 degree, they're aligned with the positive directions of x-axis and y-axis\n        in the image space, respectively.\n\n        For better illustration, we denote the center of the box as E,\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  A---B\n            |  | E |\n            |  D---C\n            |\n            v y\n\n        where the center E = ((3+7)/2, (2+4)/2) = (5, 3).\n\n        Also,\n\n        .. math::\n\n            width = |AB| = |CD| = 7 - 3 = 4,\n            height = |AD| = |BC| = 4 - 2 = 2.\n\n        Therefore, the corresponding representation for the same shape in rotated box in\n        (x_center, y_center, width, height, angle) format is:\n\n        (5, 3, 4, 2, 0),\n\n        Now, let's consider (5, 3, 4, 2, 90), which is rotated by 90 degrees\n        CCW (counter-clockwise) by definition. It looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |   B-C\n            |   | |\n            |   |E|\n            |   | |\n            |   A-D\n            v y\n\n        The center E is still located at the same point (5, 3), while the vertices\n        ABCD are rotated by 90 degrees CCW with regard to E:\n        A = (4, 5), B = (4, 1), C = (6, 1), D = (6, 5)\n\n        Here, 90 degrees can be seen as the CCW angle to rotate from y-axis to\n        vector AD or vector BC (the top->down height vector in box's local coordinate system),\n        or the CCW angle to rotate from x-axis to vector AB or vector DC (the left->right\n        width vector in box's local coordinate system).\n\n        .. math::\n\n            width = |AB| = |CD| = 5 - 1 = 4,\n            height = |AD| = |BC| = 6 - 4 = 2.\n\n        Next, how about (5, 3, 4, 2, -90), which is rotated by 90 degrees CW (clockwise)\n        by definition? It looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |   D-A\n            |   | |\n            |   |E|\n            |   | |\n            |   C-B\n            v y\n\n        The center E is still located at the same point (5, 3), while the vertices\n        ABCD are rotated by 90 degrees CW with regard to E:\n        A = (6, 1), B = (6, 5), C = (4, 5), D = (4, 1)\n\n        .. math::\n\n            width = |AB| = |CD| = 5 - 1 = 4,\n            height = |AD| = |BC| = 6 - 4 = 2.\n\n        This covers exactly the same region as (5, 3, 4, 2, 90) does, and their IoU\n        will be 1. However, these two will generate different RoI Pooling results and\n        should not be treated as an identical box.\n\n        On the other hand, it's easy to see that (X, Y, W, H, A) is identical to\n        (X, Y, W, H, A+360N), for any integer N. For example (5, 3, 4, 2, 270) would be\n        identical to (5, 3, 4, 2, -90), because rotating the shape 270 degrees CCW is\n        equivalent to rotating the same shape 90 degrees CW.\n\n        We could rotate further to get (5, 3, 4, 2, 180), or (5, 3, 4, 2, -180):\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  C---D\n            |  | E |\n            |  B---A\n            |\n            v y\n\n        .. math::\n\n            A = (7, 4), B = (3, 4), C = (3, 2), D = (7, 2),\n\n            width = |AB| = |CD| = 7 - 3 = 4,\n            height = |AD| = |BC| = 4 - 2 = 2.\n\n        Finally, this is a very inaccurate (heavily quantized) illustration of\n        how (5, 3, 4, 2, 60) looks like in case anyone wonders:\n\n        .. code:: none\n\n            O--------> x\n            |     B\\\n            |    /  C\n            |   /E /\n            |  A  /\n            |   `D\n            v y\n\n        It's still a rectangle with center of (5, 3), width of 4 and height of 2,\n        but its angle (and thus orientation) is somewhere between\n        (5, 3, 4, 2, 0) and (5, 3, 4, 2, 90).\n        \"\"\"", "\n", "device", "=", "tensor", ".", "device", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "if", "tensor", ".", "numel", "(", ")", "==", "0", ":", "\n", "# Use reshape, so we don't end up creating a new tensor that does not depend on", "\n", "# the inputs (and consequently confuses jit)", "\n", "            ", "tensor", "=", "tensor", ".", "reshape", "(", "(", "0", ",", "5", ")", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "", "assert", "tensor", ".", "dim", "(", ")", "==", "2", "and", "tensor", ".", "size", "(", "-", "1", ")", "==", "5", ",", "tensor", ".", "size", "(", ")", "\n", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.clone": [[223, 231], ["rotated_boxes.RotatedBoxes", "rotated_boxes.RotatedBoxes.tensor.clone"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "def", "clone", "(", "self", ")", "->", "\"RotatedBoxes\"", ":", "\n", "        ", "\"\"\"\n        Clone the RotatedBoxes.\n\n        Returns:\n            RotatedBoxes\n        \"\"\"", "\n", "return", "RotatedBoxes", "(", "self", ".", "tensor", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.to": [[232, 236], ["rotated_boxes.RotatedBoxes", "rotated_boxes.RotatedBoxes.tensor.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "@", "_maybe_jit_unused", "\n", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "# Boxes are assumed float32 and does not support to(dtype)", "\n", "        ", "return", "RotatedBoxes", "(", "self", ".", "tensor", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.area": [[237, 247], ["None"], "methods", ["None"], ["", "def", "area", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the area of all the boxes.\n\n        Returns:\n            torch.Tensor: a vector with areas of each box.\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "area", "=", "box", "[", ":", ",", "2", "]", "*", "box", "[", ":", ",", "3", "]", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.normalize_angles": [[248, 253], ["None"], "methods", ["None"], ["", "def", "normalize_angles", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Restrict angles to the range of [-180, 180) degrees\n        \"\"\"", "\n", "self", ".", "tensor", "[", ":", ",", "4", "]", "=", "(", "self", ".", "tensor", "[", ":", ",", "4", "]", "+", "180.0", ")", "%", "360.0", "-", "180.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.clip": [[254, 303], ["rotated_boxes.RotatedBoxes.normalize_angles", "x1.clamp_", "y1.clamp_", "x2.clamp_", "y2.clamp_", "torch.min", "torch.min", "torch.where", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.normalize_angles"], ["", "def", "clip", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "clip_angle_threshold", ":", "float", "=", "1.0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Clip (in place) the boxes by limiting x coordinates to the range [0, width]\n        and y coordinates to the range [0, height].\n\n        For RRPN:\n        Only clip boxes that are almost horizontal with a tolerance of\n        clip_angle_threshold to maintain backward compatibility.\n\n        Rotated boxes beyond this threshold are not clipped for two reasons:\n\n        1. There are potentially multiple ways to clip a rotated box to make it\n           fit within the image.\n        2. It's tricky to make the entire rectangular box fit within the image\n           and still be able to not leave out pixels of interest.\n\n        Therefore we rely on ops like RoIAlignRotated to safely handle this.\n\n        Args:\n            box_size (height, width): The clipping box's size.\n            clip_angle_threshold:\n                Iff. abs(normalized(angle)) <= clip_angle_threshold (in degrees),\n                we do the clipping as horizontal boxes.\n        \"\"\"", "\n", "h", ",", "w", "=", "box_size", "\n", "\n", "# normalize angles to be within (-180, 180] degrees", "\n", "self", ".", "normalize_angles", "(", ")", "\n", "\n", "idx", "=", "torch", ".", "where", "(", "torch", ".", "abs", "(", "self", ".", "tensor", "[", ":", ",", "4", "]", ")", "<=", "clip_angle_threshold", ")", "[", "0", "]", "\n", "\n", "# convert to (x1, y1, x2, y2)", "\n", "x1", "=", "self", ".", "tensor", "[", "idx", ",", "0", "]", "-", "self", ".", "tensor", "[", "idx", ",", "2", "]", "/", "2.0", "\n", "y1", "=", "self", ".", "tensor", "[", "idx", ",", "1", "]", "-", "self", ".", "tensor", "[", "idx", ",", "3", "]", "/", "2.0", "\n", "x2", "=", "self", ".", "tensor", "[", "idx", ",", "0", "]", "+", "self", ".", "tensor", "[", "idx", ",", "2", "]", "/", "2.0", "\n", "y2", "=", "self", ".", "tensor", "[", "idx", ",", "1", "]", "+", "self", ".", "tensor", "[", "idx", ",", "3", "]", "/", "2.0", "\n", "\n", "# clip", "\n", "x1", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y1", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "x2", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y2", ".", "clamp_", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "\n", "# convert back to (xc, yc, w, h)", "\n", "self", ".", "tensor", "[", "idx", ",", "0", "]", "=", "(", "x1", "+", "x2", ")", "/", "2.0", "\n", "self", ".", "tensor", "[", "idx", ",", "1", "]", "=", "(", "y1", "+", "y2", ")", "/", "2.0", "\n", "# make sure widths and heights do not increase due to numerical errors", "\n", "self", ".", "tensor", "[", "idx", ",", "2", "]", "=", "torch", ".", "min", "(", "self", ".", "tensor", "[", "idx", ",", "2", "]", ",", "x2", "-", "x1", ")", "\n", "self", ".", "tensor", "[", "idx", ",", "3", "]", "=", "torch", ".", "min", "(", "self", ".", "tensor", "[", "idx", ",", "3", "]", ",", "y2", "-", "y1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.nonempty": [[304, 318], ["None"], "methods", ["None"], ["", "def", "nonempty", "(", "self", ",", "threshold", ":", "float", "=", "0.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find boxes that are non-empty.\n        A box is considered empty, if either of its side is no larger than threshold.\n\n        Returns:\n            Tensor: a binary vector which represents\n            whether each box is empty (False) or non-empty (True).\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "widths", "=", "box", "[", ":", ",", "2", "]", "\n", "heights", "=", "box", "[", ":", ",", "3", "]", "\n", "keep", "=", "(", "widths", ">", "threshold", ")", "&", "(", "heights", ">", "threshold", ")", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.__getitem__": [[319, 341], ["isinstance", "rotated_boxes.RotatedBoxes", "rotated_boxes.RotatedBoxes", "b.dim", "rotated_boxes.RotatedBoxes.tensor[].view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", "->", "\"RotatedBoxes\"", ":", "\n", "        ", "\"\"\"\n        Returns:\n            RotatedBoxes: Create a new :class:`RotatedBoxes` by indexing.\n\n        The following usage are allowed:\n\n        1. `new_boxes = boxes[3]`: return a `RotatedBoxes` which contains only one box.\n        2. `new_boxes = boxes[2:10]`: return a slice of boxes.\n        3. `new_boxes = boxes[vector]`, where vector is a torch.ByteTensor\n           with `length = len(boxes)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned RotatedBoxes might share storage with this RotatedBoxes,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "RotatedBoxes", "(", "self", ".", "tensor", "[", "item", "]", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "b", "=", "self", ".", "tensor", "[", "item", "]", "\n", "assert", "b", ".", "dim", "(", ")", "==", "2", ",", "\"Indexing on RotatedBoxes with {} failed to return a matrix!\"", ".", "format", "(", "\n", "item", "\n", ")", "\n", "return", "RotatedBoxes", "(", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.__len__": [[342, 344], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.__repr__": [[345, 347], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "\"RotatedBoxes(\"", "+", "str", "(", "self", ".", "tensor", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.inside_box": [[348, 384], ["torch.abs", "torch.abs", "torch.cos", "torch.sin"], "methods", ["None"], ["", "def", "inside_box", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "boundary_threshold", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_size (height, width): Size of the reference box covering\n                [0, width] x [0, height]\n            boundary_threshold (int): Boxes that extend beyond the reference box\n                boundary by more than boundary_threshold are considered \"outside\".\n\n        For RRPN, it might not be necessary to call this function since it's common\n        for rotated box to extend to outside of the image boundaries\n        (the clip function only clips the near-horizontal boxes)\n\n        Returns:\n            a binary vector, indicating whether each box is inside the reference box.\n        \"\"\"", "\n", "height", ",", "width", "=", "box_size", "\n", "\n", "cnt_x", "=", "self", ".", "tensor", "[", "...", ",", "0", "]", "\n", "cnt_y", "=", "self", ".", "tensor", "[", "...", ",", "1", "]", "\n", "half_w", "=", "self", ".", "tensor", "[", "...", ",", "2", "]", "/", "2.0", "\n", "half_h", "=", "self", ".", "tensor", "[", "...", ",", "3", "]", "/", "2.0", "\n", "a", "=", "self", ".", "tensor", "[", "...", ",", "4", "]", "\n", "c", "=", "torch", ".", "abs", "(", "torch", ".", "cos", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "s", "=", "torch", ".", "abs", "(", "torch", ".", "sin", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "# This basically computes the horizontal bounding rectangle of the rotated box", "\n", "max_rect_dx", "=", "c", "*", "half_w", "+", "s", "*", "half_h", "\n", "max_rect_dy", "=", "c", "*", "half_h", "+", "s", "*", "half_w", "\n", "\n", "inds_inside", "=", "(", "\n", "(", "cnt_x", "-", "max_rect_dx", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "cnt_y", "-", "max_rect_dy", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "cnt_x", "+", "max_rect_dx", "<", "width", "+", "boundary_threshold", ")", "\n", "&", "(", "cnt_y", "+", "max_rect_dy", "<", "height", "+", "boundary_threshold", ")", "\n", ")", "\n", "\n", "return", "inds_inside", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.get_centers": [[385, 391], ["None"], "methods", ["None"], ["", "def", "get_centers", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns:\n            The box centers in a Nx2 array of (x, y).\n        \"\"\"", "\n", "return", "self", ".", "tensor", "[", ":", ",", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.scale": [[392, 456], ["torch.cos", "torch.sin", "torch.sqrt", "torch.sqrt", "torch.atan2"], "methods", ["None"], ["", "def", "scale", "(", "self", ",", "scale_x", ":", "float", ",", "scale_y", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Scale the rotated box with horizontal and vertical scaling factors\n        Note: when scale_factor_x != scale_factor_y,\n        the rotated box does not preserve the rectangular shape when the angle\n        is not a multiple of 90 degrees under resize transformation.\n        Instead, the shape is a parallelogram (that has skew)\n        Here we make an approximation by fitting a rotated rectangle to the parallelogram.\n        \"\"\"", "\n", "self", ".", "tensor", "[", ":", ",", "0", "]", "*=", "scale_x", "\n", "self", ".", "tensor", "[", ":", ",", "1", "]", "*=", "scale_y", "\n", "theta", "=", "self", ".", "tensor", "[", ":", ",", "4", "]", "*", "math", ".", "pi", "/", "180.0", "\n", "c", "=", "torch", ".", "cos", "(", "theta", ")", "\n", "s", "=", "torch", ".", "sin", "(", "theta", ")", "\n", "\n", "# In image space, y is top->down and x is left->right", "\n", "# Consider the local coordintate system for the rotated box,", "\n", "# where the box center is located at (0, 0), and the four vertices ABCD are", "\n", "# A(-w / 2, -h / 2), B(w / 2, -h / 2), C(w / 2, h / 2), D(-w / 2, h / 2)", "\n", "# the midpoint of the left edge AD of the rotated box E is:", "\n", "# E = (A+D)/2 = (-w / 2, 0)", "\n", "# the midpoint of the top edge AB of the rotated box F is:", "\n", "# F(0, -h / 2)", "\n", "# To get the old coordinates in the global system, apply the rotation transformation", "\n", "# (Note: the right-handed coordinate system for image space is yOx):", "\n", "# (old_x, old_y) = (s * y + c * x, c * y - s * x)", "\n", "# E(old) = (s * 0 + c * (-w/2), c * 0 - s * (-w/2)) = (-c * w / 2, s * w / 2)", "\n", "# F(old) = (s * (-h / 2) + c * 0, c * (-h / 2) - s * 0) = (-s * h / 2, -c * h / 2)", "\n", "# After applying the scaling factor (sfx, sfy):", "\n", "# E(new) = (-sfx * c * w / 2, sfy * s * w / 2)", "\n", "# F(new) = (-sfx * s * h / 2, -sfy * c * h / 2)", "\n", "# The new width after scaling tranformation becomes:", "\n", "\n", "# w(new) = |E(new) - O| * 2", "\n", "#        = sqrt[(sfx * c * w / 2)^2 + (sfy * s * w / 2)^2] * 2", "\n", "#        = sqrt[(sfx * c)^2 + (sfy * s)^2] * w", "\n", "# i.e., scale_factor_w = sqrt[(sfx * c)^2 + (sfy * s)^2]", "\n", "#", "\n", "# For example,", "\n", "# when angle = 0 or 180, |c| = 1, s = 0, scale_factor_w == scale_factor_x;", "\n", "# when |angle| = 90, c = 0, |s| = 1, scale_factor_w == scale_factor_y", "\n", "self", ".", "tensor", "[", ":", ",", "2", "]", "*=", "torch", ".", "sqrt", "(", "(", "scale_x", "*", "c", ")", "**", "2", "+", "(", "scale_y", "*", "s", ")", "**", "2", ")", "\n", "\n", "# h(new) = |F(new) - O| * 2", "\n", "#        = sqrt[(sfx * s * h / 2)^2 + (sfy * c * h / 2)^2] * 2", "\n", "#        = sqrt[(sfx * s)^2 + (sfy * c)^2] * h", "\n", "# i.e., scale_factor_h = sqrt[(sfx * s)^2 + (sfy * c)^2]", "\n", "#", "\n", "# For example,", "\n", "# when angle = 0 or 180, |c| = 1, s = 0, scale_factor_h == scale_factor_y;", "\n", "# when |angle| = 90, c = 0, |s| = 1, scale_factor_h == scale_factor_x", "\n", "self", ".", "tensor", "[", ":", ",", "3", "]", "*=", "torch", ".", "sqrt", "(", "(", "scale_x", "*", "s", ")", "**", "2", "+", "(", "scale_y", "*", "c", ")", "**", "2", ")", "\n", "\n", "# The angle is the rotation angle from y-axis in image space to the height", "\n", "# vector (top->down in the box's local coordinate system) of the box in CCW.", "\n", "#", "\n", "# angle(new) = angle_yOx(O - F(new))", "\n", "#            = angle_yOx( (sfx * s * h / 2, sfy * c * h / 2) )", "\n", "#            = atan2(sfx * s * h / 2, sfy * c * h / 2)", "\n", "#            = atan2(sfx * s, sfy * c)", "\n", "#", "\n", "# For example,", "\n", "# when sfx == sfy, angle(new) == atan2(s, c) == angle(old)", "\n", "self", ".", "tensor", "[", ":", ",", "4", "]", "=", "torch", ".", "atan2", "(", "scale_x", "*", "s", ",", "scale_y", "*", "c", ")", "*", "180", "/", "math", ".", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.cat": [[457, 477], ["isinstance", "all", "cls", "len", "cls", "torch.cat", "torch.empty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "@", "classmethod", "\n", "@", "_maybe_jit_unused", "\n", "def", "cat", "(", "cls", ",", "boxes_list", ":", "List", "[", "\"RotatedBoxes\"", "]", ")", "->", "\"RotatedBoxes\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of RotatedBoxes into a single RotatedBoxes\n\n        Arguments:\n            boxes_list (list[RotatedBoxes])\n\n        Returns:\n            RotatedBoxes: the concatenated RotatedBoxes\n        \"\"\"", "\n", "assert", "isinstance", "(", "boxes_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "boxes_list", ")", "==", "0", ":", "\n", "            ", "return", "cls", "(", "torch", ".", "empty", "(", "0", ")", ")", "\n", "", "assert", "all", "(", "[", "isinstance", "(", "box", ",", "RotatedBoxes", ")", "for", "box", "in", "boxes_list", "]", ")", "\n", "\n", "# use torch.cat (v.s. layers.cat) so the returned boxes never share storage with input", "\n", "cat_boxes", "=", "cls", "(", "torch", ".", "cat", "(", "[", "b", ".", "tensor", "for", "b", "in", "boxes_list", "]", ",", "dim", "=", "0", ")", ")", "\n", "return", "cat_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.device": [[478, 481], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.RotatedBoxes.__iter__": [[482, 488], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Yield a box as a Tensor of shape (5,) at a time.\n        \"\"\"", "\n", "yield", "from", "self", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.rotated_boxes.pairwise_iou": [[490, 506], ["detectron2.layers.rotated_boxes.pairwise_iou_rotated"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.rotated_boxes.pairwise_iou_rotated"], ["", "", "def", "pairwise_iou", "(", "boxes1", ":", "RotatedBoxes", ",", "boxes2", ":", "RotatedBoxes", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Given two lists of rotated boxes of size N and M,\n    compute the IoU (intersection over union)\n    between **all** N x M pairs of boxes.\n    The box order must be (x_center, y_center, width, height, angle).\n\n    Args:\n        boxes1, boxes2 (RotatedBoxes):\n            two `RotatedBoxes`. Contains N & M rotated boxes, respectively.\n\n    Returns:\n        Tensor: IoU, sized [N,M].\n    \"\"\"", "\n", "\n", "return", "pairwise_iou_rotated", "(", "boxes1", ".", "tensor", ",", "boxes2", ".", "tensor", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "assert", "tensors", ".", "dim", "(", ")", "==", "4", "\n", "image_sizes", "=", "[", "tensor", ".", "shape", "[", "-", "2", ":", "]", "for", "tensor", "in", "tensors", "]", "\n", "return", "ImageList", "(", "tensors", ",", "image_sizes", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.__getitem__": [[49, 61], ["None"], "methods", ["None"], ["", "elif", "isinstance", "(", "tensors", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "max_size", "=", "tuple", "(", "max", "(", "s", ")", "for", "s", "in", "zip", "(", "*", "[", "img", ".", "shape", "for", "img", "in", "tensors", "]", ")", ")", "\n", "\n", "# TODO Ideally, just remove this and let me model handle arbitrary", "\n", "# input sizs", "\n", "if", "size_divisible", ">", "0", ":", "\n", "            ", "import", "math", "\n", "\n", "stride", "=", "size_divisible", "\n", "max_size", "=", "list", "(", "max_size", ")", "\n", "max_size", "[", "1", "]", "=", "int", "(", "math", ".", "ceil", "(", "max_size", "[", "1", "]", "/", "stride", ")", "*", "stride", ")", "\n", "max_size", "[", "2", "]", "=", "int", "(", "math", ".", "ceil", "(", "max_size", "[", "2", "]", "/", "stride", ")", "*", "stride", ")", "\n", "max_size", "=", "tuple", "(", "max_size", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.device": [[67, 70], ["None"], "methods", ["None"], ["\n", "", "image_sizes", "=", "[", "im", ".", "shape", "[", "-", "2", ":", "]", "for", "im", "in", "tensors", "]", "\n", "\n", "return", "ImageList", "(", "batched_imgs", ",", "image_sizes", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors": [[71, 125], ["isinstance", "torch.jit.is_scripting", "image_list.ImageList", "len", "isinstance", "type", "image_list._as_tensor", "torch.stack().max", "max_size.to().tolist", "len", "torch.nn.functional.pad().unsqueeze_", "tensors[].new_full", "zip", "tensors[].new_full.contiguous", "torch.jit.is_tracing", "list", "pad_img[].copy_", "torch.stack", "max_size.to", "torch.nn.functional.pad", "list", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features._as_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"Unsupported type for to_image_list: {}\"", ".", "format", "(", "type", "(", "tensors", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list._as_tensor": [[11, 22], ["torch.jit.is_scripting", "torch.as_tensor", "torch.as_tensor", "isinstance", "all", "torch.stack", "isinstance"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "tensors", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            tensors (tensor)\n            image_sizes (list[tuple[int, int]])\n        \"\"\"", "\n", "self", ".", "tensors", "=", "tensors", "\n", "self", ".", "image_sizes", "=", "image_sizes", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__init__": [[38, 48], ["kwargs.items", "instances.Instances.set"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["def", "__init__", "(", "self", ",", "image_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "**", "kwargs", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_size (height, width): the spatial size of the image.\n            kwargs: fields to add to this `Instances`.\n        \"\"\"", "\n", "self", ".", "_image_size", "=", "image_size", "\n", "self", ".", "_fields", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "set", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.image_size": [[49, 56], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "image_size", "(", "self", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple: height, width\n        \"\"\"", "\n", "return", "self", ".", "_image_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__setattr__": [[57, 62], ["name.startswith", "super().__setattr__", "instances.Instances.set"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__setattr__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "def", "__setattr__", "(", "self", ",", "name", ":", "str", ",", "val", ":", "Any", ")", "->", "None", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "set", "(", "name", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__getattr__": [[63, 67], ["AttributeError"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "if", "name", "==", "\"_fields\"", "or", "name", "not", "in", "self", ".", "_fields", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Cannot find field '{}' in the given Instances!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "self", ".", "_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.set": [[68, 80], ["len", "len", "len", "len"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "name", ":", "str", ",", "value", ":", "Any", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set the field named `name` to `value`.\n        The length of `value` must be the number of instances,\n        and must agree with other existing fields in this object.\n        \"\"\"", "\n", "data_len", "=", "len", "(", "value", ")", "\n", "if", "len", "(", "self", ".", "_fields", ")", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "self", ")", "==", "data_len", "\n", ")", ",", "\"Adding a field of length {} to a Instances of length {}\"", ".", "format", "(", "data_len", ",", "len", "(", "self", ")", ")", "\n", "", "self", ".", "_fields", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.has": [[81, 87], ["None"], "methods", ["None"], ["", "def", "has", "(", "self", ",", "name", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Returns:\n            bool: whether the field called `name` exists.\n        \"\"\"", "\n", "return", "name", "in", "self", ".", "_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.remove": [[88, 93], ["None"], "methods", ["None"], ["", "def", "remove", "(", "self", ",", "name", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Remove the field called `name`.\n        \"\"\"", "\n", "del", "self", ".", "_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.get": [[94, 99], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Returns the field called `name`.\n        \"\"\"", "\n", "return", "self", ".", "_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.get_fields": [[100, 108], ["None"], "methods", ["None"], ["", "def", "get_fields", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict: a dict which maps names (str) to data of the fields\n\n        Modifying the returned dict will modify this instance.\n        \"\"\"", "\n", "return", "self", ".", "_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.to": [[110, 121], ["instances.Instances", "instances.Instances._fields.items", "hasattr", "instances.Instances.set", "v.to.to.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"Instances\"", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Instances: all fields are called with a `to(device)`, if the field has this method.\n        \"\"\"", "\n", "ret", "=", "Instances", "(", "self", ".", "_image_size", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "v", ",", "\"to\"", ")", ":", "\n", "                ", "v", "=", "v", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "ret", ".", "set", "(", "k", ",", "v", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__getitem__": [[122, 141], ["instances.Instances", "instances.Instances._fields.items", "type", "instances.Instances.set", "IndexError", "slice", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"Instances\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            item: an index-like object and will be used to index all the fields.\n\n        Returns:\n            If `item` is a string, return the data in the corresponding field.\n            Otherwise, returns an `Instances` where all fields are indexed by `item`.\n        \"\"\"", "\n", "if", "type", "(", "item", ")", "==", "int", ":", "\n", "            ", "if", "item", ">=", "len", "(", "self", ")", "or", "item", "<", "-", "len", "(", "self", ")", ":", "\n", "                ", "raise", "IndexError", "(", "\"Instances index out of range!\"", ")", "\n", "", "else", ":", "\n", "                ", "item", "=", "slice", "(", "item", ",", "None", ",", "len", "(", "self", ")", ")", "\n", "\n", "", "", "ret", "=", "Instances", "(", "self", ".", "_image_size", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_fields", ".", "items", "(", ")", ":", "\n", "            ", "ret", ".", "set", "(", "k", ",", "v", "[", "item", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__len__": [[142, 147], ["instances.Instances._fields.values", "NotImplementedError", "v.__len__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__len__"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "for", "v", "in", "self", ".", "_fields", ".", "values", "(", ")", ":", "\n", "# use __len__ because len() has to be int and is not friendly to tracing", "\n", "            ", "return", "v", ".", "__len__", "(", ")", "\n", "", "raise", "NotImplementedError", "(", "\"Empty Instances does not support __len__!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__iter__": [[148, 150], ["NotImplementedError"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"`Instances` object is not iterable!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.cat": [[151, 182], ["all", "instances.Instances", "instance_lists[]._fields.keys", "len", "len", "isinstance", "instances.Instances.set", "isinstance", "i.get", "torch.cat", "isinstance", "list", "hasattr", "itertools.chain", "type", "type().cat", "ValueError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "@", "staticmethod", "\n", "def", "cat", "(", "instance_lists", ":", "List", "[", "\"Instances\"", "]", ")", "->", "\"Instances\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            instance_lists (list[Instances])\n\n        Returns:\n            Instances\n        \"\"\"", "\n", "assert", "all", "(", "isinstance", "(", "i", ",", "Instances", ")", "for", "i", "in", "instance_lists", ")", "\n", "assert", "len", "(", "instance_lists", ")", ">", "0", "\n", "if", "len", "(", "instance_lists", ")", "==", "1", ":", "\n", "            ", "return", "instance_lists", "[", "0", "]", "\n", "\n", "", "image_size", "=", "instance_lists", "[", "0", "]", ".", "image_size", "\n", "for", "i", "in", "instance_lists", "[", "1", ":", "]", ":", "\n", "            ", "assert", "i", ".", "image_size", "==", "image_size", "\n", "", "ret", "=", "Instances", "(", "image_size", ")", "\n", "for", "k", "in", "instance_lists", "[", "0", "]", ".", "_fields", ".", "keys", "(", ")", ":", "\n", "            ", "values", "=", "[", "i", ".", "get", "(", "k", ")", "for", "i", "in", "instance_lists", "]", "\n", "v0", "=", "values", "[", "0", "]", "\n", "if", "isinstance", "(", "v0", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "values", "=", "torch", ".", "cat", "(", "values", ",", "dim", "=", "0", ")", "\n", "", "elif", "isinstance", "(", "v0", ",", "list", ")", ":", "\n", "                ", "values", "=", "list", "(", "itertools", ".", "chain", "(", "*", "values", ")", ")", "\n", "", "elif", "hasattr", "(", "type", "(", "v0", ")", ",", "\"cat\"", ")", ":", "\n", "                ", "values", "=", "type", "(", "v0", ")", ".", "cat", "(", "values", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported type {} for concatenation\"", ".", "format", "(", "type", "(", "v0", ")", ")", ")", "\n", "", "ret", ".", "set", "(", "k", ",", "values", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.instances.Instances.__str__": [[183, 190], ["len", "instances.Instances._fields.items"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={}, \"", ".", "format", "(", "len", "(", "self", ")", ")", "\n", "s", "+=", "\"image_height={}, \"", ".", "format", "(", "self", ".", "_image_size", "[", "0", "]", ")", "\n", "s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "_image_size", "[", "1", "]", ")", "\n", "s", "+=", "\"fields=[{}])\"", ".", "format", "(", "\", \"", ".", "join", "(", "(", "f\"{k}: {v}\"", "for", "k", ",", "v", "in", "self", ".", "_fields", ".", "items", "(", ")", ")", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.__init__": [[32, 43], ["torch.as_tensor", "isinstance", "torch.device", "torch.as_tensor.dim"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "__init__", "(", "self", ",", "keypoints", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", ",", "List", "[", "List", "[", "float", "]", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            keypoints: A Tensor, numpy array, or list of the x, y, and visibility of each keypoint.\n                The shape should be (N, K, 3) where N is the number of\n                instances, and K is the number of keypoints per instance.\n        \"\"\"", "\n", "device", "=", "keypoints", ".", "device", "if", "isinstance", "(", "keypoints", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "keypoints", "=", "torch", ".", "as_tensor", "(", "keypoints", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "assert", "keypoints", ".", "dim", "(", ")", "==", "3", "and", "keypoints", ".", "shape", "[", "2", "]", "==", "3", ",", "keypoints", ".", "shape", "\n", "self", ".", "tensor", "=", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.__len__": [[44, 46], ["keypoints.Keypoints.tensor.size"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.to": [[47, 49], ["type", "keypoints.Keypoints.tensor.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"Keypoints\"", ":", "\n", "        ", "return", "type", "(", "self", ")", "(", "self", ".", "tensor", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.device": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.to_heatmap": [[54, 70], ["keypoints._keypoints_to_heatmap"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints._keypoints_to_heatmap"], ["", "def", "to_heatmap", "(", "self", ",", "boxes", ":", "torch", ".", "Tensor", ",", "heatmap_size", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Convert keypoint annotations to a heatmap of one-hot labels for training,\n        as described in :paper:`Mask R-CNN`.\n\n        Arguments:\n            boxes: Nx4 tensor, the boxes to draw the keypoints to\n\n        Returns:\n            heatmaps:\n                A tensor of shape (N, K), each element is integer spatial label\n                in the range [0, heatmap_size**2 - 1] for each keypoint in the input.\n            valid:\n                A tensor of shape (N, K) containing whether each keypoint is in the roi or not.\n        \"\"\"", "\n", "return", "_keypoints_to_heatmap", "(", "self", ".", "tensor", ",", "boxes", ",", "heatmap_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.__getitem__": [[71, 88], ["isinstance", "keypoints.Keypoints", "keypoints.Keypoints"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"Keypoints\"", ":", "\n", "        ", "\"\"\"\n        Create a new `Keypoints` by indexing on this `Keypoints`.\n\n        The following usage are allowed:\n\n        1. `new_kpts = kpts[3]`: return a `Keypoints` which contains only one instance.\n        2. `new_kpts = kpts[2:10]`: return a slice of key points.\n        3. `new_kpts = kpts[vector]`, where vector is a torch.ByteTensor\n           with `length = len(kpts)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned Keypoints might share storage with this Keypoints,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "Keypoints", "(", "[", "self", ".", "tensor", "[", "item", "]", "]", ")", "\n", "", "return", "Keypoints", "(", "self", ".", "tensor", "[", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.Keypoints.__repr__": [[89, 93], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={})\"", ".", "format", "(", "len", "(", "self", ".", "tensor", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints._keypoints_to_heatmap": [[96, 153], ["x.floor().long.floor().long", "y.floor().long.floor().long", "rois.numel", "rois.new().long", "rois.new().long", "x.floor().long.floor", "y.floor().long.floor", "rois.new", "rois.new"], "function", ["None"], ["", "", "def", "_keypoints_to_heatmap", "(", "\n", "keypoints", ":", "torch", ".", "Tensor", ",", "rois", ":", "torch", ".", "Tensor", ",", "heatmap_size", ":", "int", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Encode keypoint locations into a target heatmap for use in SoftmaxWithLoss across space.\n\n    Maps keypoints from the half-open interval [x1, x2) on continuous image coordinates to the\n    closed interval [0, heatmap_size - 1] on discrete image coordinates. We use the\n    continuous-discrete conversion from Heckbert 1990 (\"What is the coordinate of a pixel?\"):\n    d = floor(c) and c = d + 0.5, where d is a discrete coordinate and c is a continuous coordinate.\n\n    Arguments:\n        keypoints: tensor of keypoint locations in of shape (N, K, 3).\n        rois: Nx4 tensor of rois in xyxy format\n        heatmap_size: integer side length of square heatmap.\n\n    Returns:\n        heatmaps: A tensor of shape (N, K) containing an integer spatial label\n            in the range [0, heatmap_size**2 - 1] for each keypoint in the input.\n        valid: A tensor of shape (N, K) containing whether each keypoint is in\n            the roi or not.\n    \"\"\"", "\n", "\n", "if", "rois", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "rois", ".", "new", "(", ")", ".", "long", "(", ")", ",", "rois", ".", "new", "(", ")", ".", "long", "(", ")", "\n", "", "offset_x", "=", "rois", "[", ":", ",", "0", "]", "\n", "offset_y", "=", "rois", "[", ":", ",", "1", "]", "\n", "scale_x", "=", "heatmap_size", "/", "(", "rois", "[", ":", ",", "2", "]", "-", "rois", "[", ":", ",", "0", "]", ")", "\n", "scale_y", "=", "heatmap_size", "/", "(", "rois", "[", ":", ",", "3", "]", "-", "rois", "[", ":", ",", "1", "]", ")", "\n", "\n", "offset_x", "=", "offset_x", "[", ":", ",", "None", "]", "\n", "offset_y", "=", "offset_y", "[", ":", ",", "None", "]", "\n", "scale_x", "=", "scale_x", "[", ":", ",", "None", "]", "\n", "scale_y", "=", "scale_y", "[", ":", ",", "None", "]", "\n", "\n", "x", "=", "keypoints", "[", "...", ",", "0", "]", "\n", "y", "=", "keypoints", "[", "...", ",", "1", "]", "\n", "\n", "x_boundary_inds", "=", "x", "==", "rois", "[", ":", ",", "2", "]", "[", ":", ",", "None", "]", "\n", "y_boundary_inds", "=", "y", "==", "rois", "[", ":", ",", "3", "]", "[", ":", ",", "None", "]", "\n", "\n", "x", "=", "(", "x", "-", "offset_x", ")", "*", "scale_x", "\n", "x", "=", "x", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "y", "=", "(", "y", "-", "offset_y", ")", "*", "scale_y", "\n", "y", "=", "y", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "\n", "x", "[", "x_boundary_inds", "]", "=", "heatmap_size", "-", "1", "\n", "y", "[", "y_boundary_inds", "]", "=", "heatmap_size", "-", "1", "\n", "\n", "valid_loc", "=", "(", "x", ">=", "0", ")", "&", "(", "y", ">=", "0", ")", "&", "(", "x", "<", "heatmap_size", ")", "&", "(", "y", "<", "heatmap_size", ")", "\n", "vis", "=", "keypoints", "[", "...", ",", "2", "]", ">", "0", "\n", "valid", "=", "(", "valid_loc", "&", "vis", ")", ".", "long", "(", ")", "\n", "\n", "lin_ind", "=", "y", "*", "heatmap_size", "+", "x", "\n", "heatmaps", "=", "lin_ind", "*", "valid", "\n", "\n", "return", "heatmaps", ",", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoints.heatmaps_to_keypoints": [[155, 231], ["maps.detach.detach", "rois.detach.detach", "widths.ceil", "heights.ceil", "maps.detach.new_zeros", "torch.arange", "range", "torch.nn.functional.interpolate().squeeze", "F.interpolate().squeeze.view().max", "max_score.view.view", "F.interpolate().squeeze.view().argmax", "int", "int", "tmp_pool_resolution.sum", "torch.nn.functional.interpolate", "F.interpolate().squeeze.view", "F.interpolate().squeeze.view", "x_int.float", "y_int.float", "roi_map_scores.view().max", "roi_map_scores.view"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "@", "script_if_tracing", "\n", "def", "heatmaps_to_keypoints", "(", "maps", ":", "torch", ".", "Tensor", ",", "rois", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Extract predicted keypoint locations from heatmaps.\n\n    Args:\n        maps (Tensor): (#ROIs, #keypoints, POOL_H, POOL_W). The predicted heatmap of logits for\n            each ROI and each keypoint.\n        rois (Tensor): (#ROIs, 4). The box of each ROI.\n\n    Returns:\n        Tensor of shape (#ROIs, #keypoints, 4) with the last dimension corresponding to\n        (x, y, logit, score) for each keypoint.\n\n    When converting discrete pixel indices in an NxN image to a continuous keypoint coordinate,\n    we maintain consistency with :meth:`Keypoints.to_heatmap` by using the conversion from\n    Heckbert 1990: c = d + 0.5, where d is a discrete coordinate and c is a continuous coordinate.\n    \"\"\"", "\n", "# The decorator use of torch.no_grad() was not supported by torchscript.", "\n", "# https://github.com/pytorch/pytorch/issues/44768", "\n", "maps", "=", "maps", ".", "detach", "(", ")", "\n", "rois", "=", "rois", ".", "detach", "(", ")", "\n", "\n", "offset_x", "=", "rois", "[", ":", ",", "0", "]", "\n", "offset_y", "=", "rois", "[", ":", ",", "1", "]", "\n", "\n", "widths", "=", "(", "rois", "[", ":", ",", "2", "]", "-", "rois", "[", ":", ",", "0", "]", ")", ".", "clamp", "(", "min", "=", "1", ")", "\n", "heights", "=", "(", "rois", "[", ":", ",", "3", "]", "-", "rois", "[", ":", ",", "1", "]", ")", ".", "clamp", "(", "min", "=", "1", ")", "\n", "widths_ceil", "=", "widths", ".", "ceil", "(", ")", "\n", "heights_ceil", "=", "heights", ".", "ceil", "(", ")", "\n", "\n", "num_rois", ",", "num_keypoints", "=", "maps", ".", "shape", "[", ":", "2", "]", "\n", "xy_preds", "=", "maps", ".", "new_zeros", "(", "rois", ".", "shape", "[", "0", "]", ",", "num_keypoints", ",", "4", ")", "\n", "\n", "width_corrections", "=", "widths", "/", "widths_ceil", "\n", "height_corrections", "=", "heights", "/", "heights_ceil", "\n", "\n", "keypoints_idx", "=", "torch", ".", "arange", "(", "num_keypoints", ",", "device", "=", "maps", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_rois", ")", ":", "\n", "        ", "outsize", "=", "(", "int", "(", "heights_ceil", "[", "i", "]", ")", ",", "int", "(", "widths_ceil", "[", "i", "]", ")", ")", "\n", "roi_map", "=", "F", ".", "interpolate", "(", "\n", "maps", "[", "[", "i", "]", "]", ",", "size", "=", "outsize", ",", "mode", "=", "\"bicubic\"", ",", "align_corners", "=", "False", "\n", ")", ".", "squeeze", "(", "\n", "0", "\n", ")", "# #keypoints x H x W", "\n", "\n", "# softmax over the spatial region", "\n", "max_score", ",", "_", "=", "roi_map", ".", "view", "(", "num_keypoints", ",", "-", "1", ")", ".", "max", "(", "1", ")", "\n", "max_score", "=", "max_score", ".", "view", "(", "num_keypoints", ",", "1", ",", "1", ")", "\n", "tmp_full_resolution", "=", "(", "roi_map", "-", "max_score", ")", ".", "exp_", "(", ")", "\n", "tmp_pool_resolution", "=", "(", "maps", "[", "i", "]", "-", "max_score", ")", ".", "exp_", "(", ")", "\n", "# Produce scores over the region H x W, but normalize with POOL_H x POOL_W,", "\n", "# so that the scores of objects of different absolute sizes will be more comparable", "\n", "roi_map_scores", "=", "tmp_full_resolution", "/", "tmp_pool_resolution", ".", "sum", "(", "(", "1", ",", "2", ")", ",", "keepdim", "=", "True", ")", "\n", "\n", "w", "=", "roi_map", ".", "shape", "[", "2", "]", "\n", "pos", "=", "roi_map", ".", "view", "(", "num_keypoints", ",", "-", "1", ")", ".", "argmax", "(", "1", ")", "\n", "\n", "x_int", "=", "pos", "%", "w", "\n", "y_int", "=", "(", "pos", "-", "x_int", ")", "//", "w", "\n", "\n", "assert", "(", "\n", "roi_map_scores", "[", "keypoints_idx", ",", "y_int", ",", "x_int", "]", "\n", "==", "roi_map_scores", ".", "view", "(", "num_keypoints", ",", "-", "1", ")", ".", "max", "(", "1", ")", "[", "0", "]", "\n", ")", ".", "all", "(", ")", "\n", "\n", "x", "=", "(", "x_int", ".", "float", "(", ")", "+", "0.5", ")", "*", "width_corrections", "[", "i", "]", "\n", "y", "=", "(", "y_int", ".", "float", "(", ")", "+", "0.5", ")", "*", "height_corrections", "[", "i", "]", "\n", "\n", "xy_preds", "[", "i", ",", ":", ",", "0", "]", "=", "x", "+", "offset_x", "[", "i", "]", "\n", "xy_preds", "[", "i", ",", ":", ",", "1", "]", "=", "y", "+", "offset_y", "[", "i", "]", "\n", "xy_preds", "[", "i", ",", ":", ",", "2", "]", "=", "roi_map", "[", "keypoints_idx", ",", "y_int", ",", "x_int", "]", "\n", "xy_preds", "[", "i", ",", ":", ",", "3", "]", "=", "roi_map_scores", "[", "keypoints_idx", ",", "y_int", ",", "x_int", "]", "\n", "\n", "", "return", "xy_preds", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.__init__": [[93, 103], ["torch.as_tensor", "torch.as_tensor.size", "isinstance", "torch.device", "torch.as_tensor.dim"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "__init__", "(", "self", ",", "tensor", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor: bool Tensor of N,H,W, representing N instances in the image.\n        \"\"\"", "\n", "device", "=", "tensor", ".", "device", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "3", ",", "tensor", ".", "size", "(", ")", "\n", "self", ".", "image_size", "=", "tensor", ".", "shape", "[", "1", ":", "]", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.to": [[104, 106], ["masks.BitMasks", "masks.BitMasks.tensor.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "return", "BitMasks", "(", "self", ".", "tensor", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.device": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.__getitem__": [[111, 133], ["isinstance", "masks.BitMasks", "masks.BitMasks", "m.dim", "masks.BitMasks.tensor[].view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "\"\"\"\n        Returns:\n            BitMasks: Create a new :class:`BitMasks` by indexing.\n\n        The following usage are allowed:\n\n        1. `new_masks = masks[3]`: return a `BitMasks` which contains only one mask.\n        2. `new_masks = masks[2:10]`: return a slice of masks.\n        3. `new_masks = masks[vector]`, where vector is a torch.BoolTensor\n           with `length = len(masks)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned object might share storage with this object,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "BitMasks", "(", "self", ".", "tensor", "[", "item", "]", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "m", "=", "self", ".", "tensor", "[", "item", "]", "\n", "assert", "m", ".", "dim", "(", ")", "==", "3", ",", "\"Indexing on BitMasks with {} returns a tensor with shape {}!\"", ".", "format", "(", "\n", "item", ",", "m", ".", "shape", "\n", ")", "\n", "return", "BitMasks", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.__iter__": [[134, 136], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "yield", "from", "self", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.__repr__": [[137, 141], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={})\"", ".", "format", "(", "len", "(", "self", ".", "tensor", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.__len__": [[142, 144], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.nonempty": [[145, 154], ["masks.BitMasks.tensor.flatten().any", "masks.BitMasks.tensor.flatten"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "def", "nonempty", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find masks that are non-empty.\n\n        Returns:\n            Tensor: a BoolTensor which represents\n                whether each mask is empty (False) or non-empty (True).\n        \"\"\"", "\n", "return", "self", ".", "tensor", ".", "flatten", "(", "1", ")", ".", "any", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.from_polygon_masks": [[155, 168], ["isinstance", "masks.BitMasks", "masks.polygons_to_bitmask", "torch.stack", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.polygons_to_bitmask"], ["", "@", "staticmethod", "\n", "def", "from_polygon_masks", "(", "\n", "polygon_masks", ":", "Union", "[", "\"PolygonMasks\"", ",", "List", "[", "List", "[", "np", ".", "ndarray", "]", "]", "]", ",", "height", ":", "int", ",", "width", ":", "int", "\n", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            polygon_masks (list[list[ndarray]] or PolygonMasks)\n            height, width (int)\n        \"\"\"", "\n", "if", "isinstance", "(", "polygon_masks", ",", "PolygonMasks", ")", ":", "\n", "            ", "polygon_masks", "=", "polygon_masks", ".", "polygons", "\n", "", "masks", "=", "[", "polygons_to_bitmask", "(", "p", ",", "height", ",", "width", ")", "for", "p", "in", "polygon_masks", "]", "\n", "return", "BitMasks", "(", "torch", ".", "stack", "(", "[", "torch", ".", "from_numpy", "(", "x", ")", "for", "x", "in", "masks", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.crop_and_resize": [[169, 201], ["torch.cat", "masks.BitMasks.tensor.to", "rois.to.to.to", "detectron2.layers.roi_align.ROIAlign().forward().squeeze", "len", "len", "len", "len", "torch.arange().to", "detectron2.layers.roi_align.ROIAlign().forward", "torch.arange", "len", "detectron2.layers.roi_align.ROIAlign"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "def", "crop_and_resize", "(", "self", ",", "boxes", ":", "torch", ".", "Tensor", ",", "mask_size", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Crop each bitmask by the given box, and resize results to (mask_size, mask_size).\n        This can be used to prepare training targets for Mask R-CNN.\n        It has less reconstruction error compared to rasterization with polygons.\n        However we observe no difference in accuracy,\n        but BitMasks requires more memory to store all the masks.\n\n        Args:\n            boxes (Tensor): Nx4 tensor storing the boxes for each mask\n            mask_size (int): the size of the rasterized mask.\n\n        Returns:\n            Tensor:\n                A bool tensor of shape (N, mask_size, mask_size), where\n                N is the number of predicted boxes for this image.\n        \"\"\"", "\n", "assert", "len", "(", "boxes", ")", "==", "len", "(", "self", ")", ",", "\"{} != {}\"", ".", "format", "(", "len", "(", "boxes", ")", ",", "len", "(", "self", ")", ")", "\n", "device", "=", "self", ".", "tensor", ".", "device", "\n", "\n", "batch_inds", "=", "torch", ".", "arange", "(", "len", "(", "boxes", ")", ",", "device", "=", "device", ")", ".", "to", "(", "dtype", "=", "boxes", ".", "dtype", ")", "[", ":", ",", "None", "]", "\n", "rois", "=", "torch", ".", "cat", "(", "[", "batch_inds", ",", "boxes", "]", ",", "dim", "=", "1", ")", "# Nx5", "\n", "\n", "bit_masks", "=", "self", ".", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "rois", "=", "rois", ".", "to", "(", "device", "=", "device", ")", "\n", "output", "=", "(", "\n", "ROIAlign", "(", "(", "mask_size", ",", "mask_size", ")", ",", "1.0", ",", "0", ",", "aligned", "=", "True", ")", "\n", ".", "forward", "(", "bit_masks", "[", ":", ",", "None", ",", ":", ",", ":", "]", ",", "rois", ")", "\n", ".", "squeeze", "(", "1", ")", "\n", ")", "\n", "output", "=", "output", ">=", "0.5", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.get_bounding_boxes": [[202, 219], ["torch.zeros", "torch.any", "torch.any", "range", "torch.zeros.Boxes", "torch.where", "torch.where", "torch.as_tensor", "len", "len"], "methods", ["None"], ["", "def", "get_bounding_boxes", "(", "self", ")", "->", "Boxes", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Boxes: tight bounding boxes around bitmasks.\n            If a mask is empty, it's bounding box will be all zero.\n        \"\"\"", "\n", "boxes", "=", "torch", ".", "zeros", "(", "self", ".", "tensor", ".", "shape", "[", "0", "]", ",", "4", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "x_any", "=", "torch", ".", "any", "(", "self", ".", "tensor", ",", "dim", "=", "1", ")", "\n", "y_any", "=", "torch", ".", "any", "(", "self", ".", "tensor", ",", "dim", "=", "2", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "tensor", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "x", "=", "torch", ".", "where", "(", "x_any", "[", "idx", ",", ":", "]", ")", "[", "0", "]", "\n", "y", "=", "torch", ".", "where", "(", "y_any", "[", "idx", ",", ":", "]", ")", "[", "0", "]", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "len", "(", "y", ")", ">", "0", ":", "\n", "                ", "boxes", "[", "idx", ",", ":", "]", "=", "torch", ".", "as_tensor", "(", "\n", "[", "x", "[", "0", "]", ",", "y", "[", "0", "]", ",", "x", "[", "-", "1", "]", "+", "1", ",", "y", "[", "-", "1", "]", "+", "1", "]", ",", "dtype", "=", "torch", ".", "float32", "\n", ")", "\n", "", "", "return", "Boxes", "(", "boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.BitMasks.cat": [[220, 237], ["isinstance", "all", "len", "type", "torch.cat", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "@", "staticmethod", "\n", "def", "cat", "(", "bitmasks_list", ":", "List", "[", "\"BitMasks\"", "]", ")", "->", "\"BitMasks\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of BitMasks into a single BitMasks\n\n        Arguments:\n            bitmasks_list (list[BitMasks])\n\n        Returns:\n            BitMasks: the concatenated BitMasks\n        \"\"\"", "\n", "assert", "isinstance", "(", "bitmasks_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "bitmasks_list", ")", ">", "0", "\n", "assert", "all", "(", "isinstance", "(", "bitmask", ",", "BitMasks", ")", "for", "bitmask", "in", "bitmasks_list", ")", "\n", "\n", "cat_bitmasks", "=", "type", "(", "bitmasks_list", "[", "0", "]", ")", "(", "torch", ".", "cat", "(", "[", "bm", ".", "tensor", "for", "bm", "in", "bitmasks_list", "]", ",", "dim", "=", "0", ")", ")", "\n", "return", "cat_bitmasks", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.__init__": [[247, 289], ["isinstance", "ValueError", "isinstance", "numpy.asarray().astype", "masks.PolygonMasks.__init__.process_polygons"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "polygons", ":", "List", "[", "List", "[", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            polygons (list[list[np.ndarray]]): The first\n                level of the list correspond to individual instances,\n                the second level to all the polygons that compose the\n                instance, and the third level to the polygon coordinates.\n                The third level array should have the format of\n                [x0, y0, x1, y1, ..., xn, yn] (n >= 3).\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "polygons", ",", "list", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot create PolygonMasks: Expect a list of list of polygons per image. \"", "\n", "\"Got '{}' instead.\"", ".", "format", "(", "type", "(", "polygons", ")", ")", "\n", ")", "\n", "\n", "", "def", "_make_array", "(", "t", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "# Use float64 for higher precision, because why not?", "\n", "# Always put polygons on CPU (self.to is a no-op) since they", "\n", "# are supposed to be small tensors.", "\n", "# May need to change this assumption if GPU placement becomes useful", "\n", "            ", "if", "isinstance", "(", "t", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "t", "=", "t", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "np", ".", "asarray", "(", "t", ")", ".", "astype", "(", "\"float64\"", ")", "\n", "\n", "", "def", "process_polygons", "(", "\n", "polygons_per_instance", ":", "List", "[", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", "]", "\n", ")", "->", "List", "[", "np", ".", "ndarray", "]", ":", "\n", "            ", "if", "not", "isinstance", "(", "polygons_per_instance", ",", "list", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot create polygons: Expect a list of polygons per instance. \"", "\n", "\"Got '{}' instead.\"", ".", "format", "(", "type", "(", "polygons_per_instance", ")", ")", "\n", ")", "\n", "# transform each polygon to a numpy array", "\n", "", "polygons_per_instance", "=", "[", "_make_array", "(", "p", ")", "for", "p", "in", "polygons_per_instance", "]", "\n", "for", "polygon", "in", "polygons_per_instance", ":", "\n", "                ", "if", "len", "(", "polygon", ")", "%", "2", "!=", "0", "or", "len", "(", "polygon", ")", "<", "6", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Cannot create a polygon from {len(polygon)} coordinates.\"", ")", "\n", "", "", "return", "polygons_per_instance", "\n", "\n", "", "self", ".", "polygons", ":", "List", "[", "List", "[", "np", ".", "ndarray", "]", "]", "=", "[", "\n", "process_polygons", "(", "polygons_per_instance", ")", "for", "polygons_per_instance", "in", "polygons", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.to": [[291, 293], ["None"], "methods", ["None"], ["", "def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "**", "kwargs", ":", "Any", ")", "->", "\"PolygonMasks\"", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.device": [[294, 297], ["torch.device"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.get_bounding_boxes": [[298, 314], ["torch.zeros", "enumerate", "torch.zeros.Boxes", "len", "torch.as_tensor", "torch.zeros", "torch.from_numpy().view().to", "torch.min", "torch.max", "float", "float", "torch.from_numpy().view", "torch.min", "torch.max", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "get_bounding_boxes", "(", "self", ")", "->", "Boxes", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Boxes: tight bounding boxes around polygon masks.\n        \"\"\"", "\n", "boxes", "=", "torch", ".", "zeros", "(", "len", "(", "self", ".", "polygons", ")", ",", "4", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "idx", ",", "polygons_per_instance", "in", "enumerate", "(", "self", ".", "polygons", ")", ":", "\n", "            ", "minxy", "=", "torch", ".", "as_tensor", "(", "[", "float", "(", "\"inf\"", ")", ",", "float", "(", "\"inf\"", ")", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "maxxy", "=", "torch", ".", "zeros", "(", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "polygon", "in", "polygons_per_instance", ":", "\n", "                ", "coords", "=", "torch", ".", "from_numpy", "(", "polygon", ")", ".", "view", "(", "-", "1", ",", "2", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "minxy", "=", "torch", ".", "min", "(", "minxy", ",", "torch", ".", "min", "(", "coords", ",", "dim", "=", "0", ")", ".", "values", ")", "\n", "maxxy", "=", "torch", ".", "max", "(", "maxxy", ",", "torch", ".", "max", "(", "coords", ",", "dim", "=", "0", ")", ".", "values", ")", "\n", "", "boxes", "[", "idx", ",", ":", "2", "]", "=", "minxy", "\n", "boxes", "[", "idx", ",", "2", ":", "]", "=", "maxxy", "\n", "", "return", "Boxes", "(", "boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.nonempty": [[315, 325], ["torch.from_numpy", "numpy.asarray", "len"], "methods", ["None"], ["", "def", "nonempty", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find masks that are non-empty.\n\n        Returns:\n            Tensor:\n                a BoolTensor which represents whether each mask is empty (False) or not (True).\n        \"\"\"", "\n", "keep", "=", "[", "1", "if", "len", "(", "polygon", ")", ">", "0", "else", "0", "for", "polygon", "in", "self", ".", "polygons", "]", "\n", "return", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "keep", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.__getitem__": [[326, 355], ["isinstance", "masks.PolygonMasks", "isinstance", "isinstance", "isinstance", "item.cpu().numpy().tolist.cpu().numpy().tolist.nonzero().squeeze().cpu().numpy().tolist", "item.cpu().numpy().tolist.cpu().numpy().tolist.dim", "item.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy().tolist", "ValueError", "item.cpu().numpy().tolist.cpu().numpy().tolist.nonzero().squeeze().cpu().numpy", "item.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy", "item.cpu().numpy().tolist.cpu().numpy().tolist.nonzero().squeeze().cpu", "item.cpu().numpy().tolist.cpu().numpy().tolist.cpu", "item.cpu().numpy().tolist.cpu().numpy().tolist.nonzero().squeeze", "item.cpu().numpy().tolist.cpu().numpy().tolist.nonzero"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "Union", "[", "int", ",", "slice", ",", "List", "[", "int", "]", ",", "torch", ".", "BoolTensor", "]", ")", "->", "\"PolygonMasks\"", ":", "\n", "        ", "\"\"\"\n        Support indexing over the instances and return a `PolygonMasks` object.\n        `item` can be:\n\n        1. An integer. It will return an object with only one instance.\n        2. A slice. It will return an object with the selected instances.\n        3. A list[int]. It will return an object with the selected instances,\n           correpsonding to the indices in the list.\n        4. A vector mask of type BoolTensor, whose length is num_instances.\n           It will return an object with the instances whose mask is nonzero.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "item", "]", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "slice", ")", ":", "\n", "            ", "selected_polygons", "=", "self", ".", "polygons", "[", "item", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "list", ")", ":", "\n", "            ", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "i", "]", "for", "i", "in", "item", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "torch", ".", "Tensor", ")", ":", "\n", "# Polygons is a list, so we have to move the indices back to CPU.", "\n", "            ", "if", "item", ".", "dtype", "==", "torch", ".", "bool", ":", "\n", "                ", "assert", "item", ".", "dim", "(", ")", "==", "1", ",", "item", ".", "shape", "\n", "item", "=", "item", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "", "elif", "item", ".", "dtype", "in", "[", "torch", ".", "int32", ",", "torch", ".", "int64", "]", ":", "\n", "                ", "item", "=", "item", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported tensor dtype={} for indexing!\"", ".", "format", "(", "item", ".", "dtype", ")", ")", "\n", "", "selected_polygons", "=", "[", "self", ".", "polygons", "[", "i", "]", "for", "i", "in", "item", "]", "\n", "", "return", "PolygonMasks", "(", "selected_polygons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.__iter__": [[356, 363], ["iter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "List", "[", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Yields:\n            list[ndarray]: the polygons for one instance.\n            Each Tensor is a float64 vector representing a polygon.\n        \"\"\"", "\n", "return", "iter", "(", "self", ".", "polygons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.__repr__": [[364, 368], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={})\"", ".", "format", "(", "len", "(", "self", ".", "polygons", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.__len__": [[369, 371], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "polygons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.crop_and_resize": [[372, 403], ["boxes.to.to.to", "torch.stack().to", "len", "len", "len", "len", "torch.device", "masks.rasterize_polygons_within_box", "len", "torch.empty", "box.numpy", "zip", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.rasterize_polygons_within_box"], ["", "def", "crop_and_resize", "(", "self", ",", "boxes", ":", "torch", ".", "Tensor", ",", "mask_size", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Crop each mask by the given box, and resize results to (mask_size, mask_size).\n        This can be used to prepare training targets for Mask R-CNN.\n\n        Args:\n            boxes (Tensor): Nx4 tensor storing the boxes for each mask\n            mask_size (int): the size of the rasterized mask.\n\n        Returns:\n            Tensor: A bool tensor of shape (N, mask_size, mask_size), where\n            N is the number of predicted boxes for this image.\n        \"\"\"", "\n", "assert", "len", "(", "boxes", ")", "==", "len", "(", "self", ")", ",", "\"{} != {}\"", ".", "format", "(", "len", "(", "boxes", ")", ",", "len", "(", "self", ")", ")", "\n", "\n", "device", "=", "boxes", ".", "device", "\n", "# Put boxes on the CPU, as the polygon representation is not efficient GPU-wise", "\n", "# (several small tensors for representing a single instance mask)", "\n", "boxes", "=", "boxes", ".", "to", "(", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "results", "=", "[", "\n", "rasterize_polygons_within_box", "(", "poly", ",", "box", ".", "numpy", "(", ")", ",", "mask_size", ")", "\n", "for", "poly", ",", "box", "in", "zip", "(", "self", ".", "polygons", ",", "boxes", ")", "\n", "]", "\n", "\"\"\"\n        poly: list[list[float]], the polygons for one instance\n        box: a tensor of shape (4,)\n        \"\"\"", "\n", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "            ", "return", "torch", ".", "empty", "(", "0", ",", "mask_size", ",", "mask_size", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "", "return", "torch", ".", "stack", "(", "results", ",", "dim", "=", "0", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.area": [[404, 422], ["torch.tensor", "area.append", "masks.polygon_area"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.polygon_area"], ["", "def", "area", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Computes area of the mask.\n        Only works with Polygons, using the shoelace formula:\n        https://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates\n\n        Returns:\n            Tensor: a vector, area for each instance\n        \"\"\"", "\n", "\n", "area", "=", "[", "]", "\n", "for", "polygons_per_instance", "in", "self", ".", "polygons", ":", "\n", "            ", "area_per_instance", "=", "0", "\n", "for", "p", "in", "polygons_per_instance", ":", "\n", "                ", "area_per_instance", "+=", "polygon_area", "(", "p", "[", "0", ":", ":", "2", "]", ",", "p", "[", "1", ":", ":", "2", "]", ")", "\n", "", "area", ".", "append", "(", "area_per_instance", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "area", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.cat": [[423, 442], ["isinstance", "all", "len", "type", "list", "isinstance", "itertools.chain.from_iterable"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "@", "staticmethod", "\n", "def", "cat", "(", "polymasks_list", ":", "List", "[", "\"PolygonMasks\"", "]", ")", "->", "\"PolygonMasks\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of PolygonMasks into a single PolygonMasks\n\n        Arguments:\n            polymasks_list (list[PolygonMasks])\n\n        Returns:\n            PolygonMasks: the concatenated PolygonMasks\n        \"\"\"", "\n", "assert", "isinstance", "(", "polymasks_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "polymasks_list", ")", ">", "0", "\n", "assert", "all", "(", "isinstance", "(", "polymask", ",", "PolygonMasks", ")", "for", "polymask", "in", "polymasks_list", ")", "\n", "\n", "cat_polymasks", "=", "type", "(", "polymasks_list", "[", "0", "]", ")", "(", "\n", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "pm", ".", "polygons", "for", "pm", "in", "polymasks_list", ")", ")", "\n", ")", "\n", "return", "cat_polymasks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.polygon_area": [[14, 18], ["numpy.abs", "numpy.dot", "numpy.dot", "numpy.roll", "numpy.roll"], "function", ["None"], ["def", "polygon_area", "(", "x", ",", "y", ")", ":", "\n", "# Using the shoelace formula", "\n", "# https://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates", "\n", "    ", "return", "0.5", "*", "np", ".", "abs", "(", "np", ".", "dot", "(", "x", ",", "np", ".", "roll", "(", "y", ",", "1", ")", ")", "-", "np", ".", "dot", "(", "y", ",", "np", ".", "roll", "(", "x", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.polygons_to_bitmask": [[20, 33], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.decode().astype", "len", "pycocotools.decode"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["", "def", "polygons_to_bitmask", "(", "polygons", ":", "List", "[", "np", ".", "ndarray", "]", ",", "height", ":", "int", ",", "width", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Args:\n        polygons (list[ndarray]): each array has shape (Nx2,)\n        height, width (int)\n\n    Returns:\n        ndarray: a bool mask of shape (height, width)\n    \"\"\"", "\n", "assert", "len", "(", "polygons", ")", ">", "0", ",", "\"COCOAPI does not support empty polygons\"", "\n", "rles", "=", "mask_util", ".", "frPyObjects", "(", "polygons", ",", "height", ",", "width", ")", "\n", "rle", "=", "mask_util", ".", "merge", "(", "rles", ")", "\n", "return", "mask_util", ".", "decode", "(", "rle", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.rasterize_polygons_within_box": [[35, 82], ["copy.deepcopy", "masks.polygons_to_bitmask", "torch.from_numpy", "max", "max"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.polygons_to_bitmask"], ["", "def", "rasterize_polygons_within_box", "(", "\n", "polygons", ":", "List", "[", "np", ".", "ndarray", "]", ",", "box", ":", "np", ".", "ndarray", ",", "mask_size", ":", "int", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Rasterize the polygons into a mask image and\n    crop the mask content in the given box.\n    The cropped mask is resized to (mask_size, mask_size).\n\n    This function is used when generating training targets for mask head in Mask R-CNN.\n    Given original ground-truth masks for an image, new ground-truth mask\n    training targets in the size of `mask_size x mask_size`\n    must be provided for each predicted box. This function will be called to\n    produce such targets.\n\n    Args:\n        polygons (list[ndarray[float]]): a list of polygons, which represents an instance.\n        box: 4-element numpy array\n        mask_size (int):\n\n    Returns:\n        Tensor: BoolTensor of shape (mask_size, mask_size)\n    \"\"\"", "\n", "# 1. Shift the polygons w.r.t the boxes", "\n", "w", ",", "h", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", ",", "box", "[", "3", "]", "-", "box", "[", "1", "]", "\n", "\n", "polygons", "=", "copy", ".", "deepcopy", "(", "polygons", ")", "\n", "for", "p", "in", "polygons", ":", "\n", "        ", "p", "[", "0", ":", ":", "2", "]", "=", "p", "[", "0", ":", ":", "2", "]", "-", "box", "[", "0", "]", "\n", "p", "[", "1", ":", ":", "2", "]", "=", "p", "[", "1", ":", ":", "2", "]", "-", "box", "[", "1", "]", "\n", "\n", "# 2. Rescale the polygons to the new box size", "\n", "# max() to avoid division by small number", "\n", "", "ratio_h", "=", "mask_size", "/", "max", "(", "h", ",", "0.1", ")", "\n", "ratio_w", "=", "mask_size", "/", "max", "(", "w", ",", "0.1", ")", "\n", "\n", "if", "ratio_h", "==", "ratio_w", ":", "\n", "        ", "for", "p", "in", "polygons", ":", "\n", "            ", "p", "*=", "ratio_h", "\n", "", "", "else", ":", "\n", "        ", "for", "p", "in", "polygons", ":", "\n", "            ", "p", "[", "0", ":", ":", "2", "]", "*=", "ratio_w", "\n", "p", "[", "1", ":", ":", "2", "]", "*=", "ratio_h", "\n", "\n", "# 3. Rasterize the polygons with coco api", "\n", "", "", "mask", "=", "polygons_to_bitmask", "(", "polygons", ",", "mask_size", ",", "mask_size", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.BoxMode.convert": [[53, 138], ["type", "isinstance", "isinstance", "torch.cat().to.double", "torch.abs", "torch.abs", "arr[].to", "type.", "torch.cat().to.numpy", "torch.tensor", "torch.from_numpy().clone", "box.clone", "torch.cos", "torch.sin", "torch.cat().to.double", "torch.zeros", "torch.cat().to", "torch.cat().to.flatten().tolist", "len", "len", "torch.from_numpy", "torch.cat", "NotImplementedError", "torch.cat().to.flatten", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["@", "staticmethod", "\n", "def", "convert", "(", "box", ":", "_RawBoxType", ",", "from_mode", ":", "\"BoxMode\"", ",", "to_mode", ":", "\"BoxMode\"", ")", "->", "_RawBoxType", ":", "\n", "        ", "\"\"\"\n        Args:\n            box: can be a k-tuple, k-list or an Nxk array/tensor, where k = 4 or 5\n            from_mode, to_mode (BoxMode)\n\n        Returns:\n            The converted box of the same type.\n        \"\"\"", "\n", "if", "from_mode", "==", "to_mode", ":", "\n", "            ", "return", "box", "\n", "\n", "", "original_type", "=", "type", "(", "box", ")", "\n", "is_numpy", "=", "isinstance", "(", "box", ",", "np", ".", "ndarray", ")", "\n", "single_box", "=", "isinstance", "(", "box", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "single_box", ":", "\n", "            ", "assert", "len", "(", "box", ")", "==", "4", "or", "len", "(", "box", ")", "==", "5", ",", "(", "\n", "\"BoxMode.convert takes either a k-tuple/list or an Nxk array/tensor,\"", "\n", "\" where k == 4 or 5\"", "\n", ")", "\n", "arr", "=", "torch", ".", "tensor", "(", "box", ")", "[", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "# avoid modifying the input box", "\n", "            ", "if", "is_numpy", ":", "\n", "                ", "arr", "=", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "box", ")", ")", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                ", "arr", "=", "box", ".", "clone", "(", ")", "\n", "\n", "", "", "assert", "to_mode", "not", "in", "[", "BoxMode", ".", "XYXY_REL", ",", "BoxMode", ".", "XYWH_REL", "]", "and", "from_mode", "not", "in", "[", "\n", "BoxMode", ".", "XYXY_REL", ",", "\n", "BoxMode", ".", "XYWH_REL", ",", "\n", "]", ",", "\"Relative mode not yet supported!\"", "\n", "\n", "if", "from_mode", "==", "BoxMode", ".", "XYWHA_ABS", "and", "to_mode", "==", "BoxMode", ".", "XYXY_ABS", ":", "\n", "            ", "assert", "(", "\n", "arr", ".", "shape", "[", "-", "1", "]", "==", "5", "\n", ")", ",", "\"The last dimension of input shape must be 5 for XYWHA format\"", "\n", "original_dtype", "=", "arr", ".", "dtype", "\n", "arr", "=", "arr", ".", "double", "(", ")", "\n", "\n", "w", "=", "arr", "[", ":", ",", "2", "]", "\n", "h", "=", "arr", "[", ":", ",", "3", "]", "\n", "a", "=", "arr", "[", ":", ",", "4", "]", "\n", "c", "=", "torch", ".", "abs", "(", "torch", ".", "cos", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "s", "=", "torch", ".", "abs", "(", "torch", ".", "sin", "(", "a", "*", "math", ".", "pi", "/", "180.0", ")", ")", "\n", "# This basically computes the horizontal bounding rectangle of the rotated box", "\n", "new_w", "=", "c", "*", "w", "+", "s", "*", "h", "\n", "new_h", "=", "c", "*", "h", "+", "s", "*", "w", "\n", "\n", "# convert center to top-left corner", "\n", "arr", "[", ":", ",", "0", "]", "-=", "new_w", "/", "2.0", "\n", "arr", "[", ":", ",", "1", "]", "-=", "new_h", "/", "2.0", "\n", "# bottom-right corner", "\n", "arr", "[", ":", ",", "2", "]", "=", "arr", "[", ":", ",", "0", "]", "+", "new_w", "\n", "arr", "[", ":", ",", "3", "]", "=", "arr", "[", ":", ",", "1", "]", "+", "new_h", "\n", "\n", "arr", "=", "arr", "[", ":", ",", ":", "4", "]", ".", "to", "(", "dtype", "=", "original_dtype", ")", "\n", "", "elif", "from_mode", "==", "BoxMode", ".", "XYWH_ABS", "and", "to_mode", "==", "BoxMode", ".", "XYWHA_ABS", ":", "\n", "            ", "original_dtype", "=", "arr", ".", "dtype", "\n", "arr", "=", "arr", ".", "double", "(", ")", "\n", "arr", "[", ":", ",", "0", "]", "+=", "arr", "[", ":", ",", "2", "]", "/", "2.0", "\n", "arr", "[", ":", ",", "1", "]", "+=", "arr", "[", ":", ",", "3", "]", "/", "2.0", "\n", "angles", "=", "torch", ".", "zeros", "(", "(", "arr", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "arr", ".", "dtype", ")", "\n", "arr", "=", "torch", ".", "cat", "(", "(", "arr", ",", "angles", ")", ",", "axis", "=", "1", ")", ".", "to", "(", "dtype", "=", "original_dtype", ")", "\n", "", "else", ":", "\n", "            ", "if", "to_mode", "==", "BoxMode", ".", "XYXY_ABS", "and", "from_mode", "==", "BoxMode", ".", "XYWH_ABS", ":", "\n", "                ", "arr", "[", ":", ",", "2", "]", "+=", "arr", "[", ":", ",", "0", "]", "\n", "arr", "[", ":", ",", "3", "]", "+=", "arr", "[", ":", ",", "1", "]", "\n", "", "elif", "from_mode", "==", "BoxMode", ".", "XYXY_ABS", "and", "to_mode", "==", "BoxMode", ".", "XYWH_ABS", ":", "\n", "                ", "arr", "[", ":", ",", "2", "]", "-=", "arr", "[", ":", ",", "0", "]", "\n", "arr", "[", ":", ",", "3", "]", "-=", "arr", "[", ":", ",", "1", "]", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Conversion from BoxMode {} to {} is not supported yet\"", ".", "format", "(", "\n", "from_mode", ",", "to_mode", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "single_box", ":", "\n", "            ", "return", "original_type", "(", "arr", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "if", "is_numpy", ":", "\n", "            ", "return", "arr", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.__init__": [[152, 166], ["torch.as_tensor", "tensor.reshape().to.reshape().to.size", "isinstance", "torch.device", "tensor.reshape().to.reshape().to.numel", "tensor.reshape().to.reshape().to.reshape().to", "tensor.reshape().to.reshape().to.dim", "tensor.reshape().to.reshape().to.size", "tensor.reshape().to.reshape().to.reshape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor[float]): a Nx4 matrix.  Each row is (x1, y1, x2, y2).\n        \"\"\"", "\n", "device", "=", "tensor", ".", "device", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "if", "tensor", ".", "numel", "(", ")", "==", "0", ":", "\n", "# Use reshape, so we don't end up creating a new tensor that does not depend on", "\n", "# the inputs (and consequently confuses jit)", "\n", "            ", "tensor", "=", "tensor", ".", "reshape", "(", "(", "-", "1", ",", "4", ")", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "", "assert", "tensor", ".", "dim", "(", ")", "==", "2", "and", "tensor", ".", "size", "(", "-", "1", ")", "==", "4", ",", "tensor", ".", "size", "(", ")", "\n", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone": [[167, 175], ["boxes.Boxes", "boxes.Boxes.tensor.clone"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "def", "clone", "(", "self", ")", "->", "\"Boxes\"", ":", "\n", "        ", "\"\"\"\n        Clone the Boxes.\n\n        Returns:\n            Boxes\n        \"\"\"", "\n", "return", "Boxes", "(", "self", ".", "tensor", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.to": [[176, 180], ["boxes.Boxes", "boxes.Boxes.tensor.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "@", "_maybe_jit_unused", "\n", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "# Boxes are assumed float32 and does not support to(dtype)", "\n", "        ", "return", "Boxes", "(", "self", ".", "tensor", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area": [[181, 191], ["None"], "methods", ["None"], ["", "def", "area", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the area of all the boxes.\n\n        Returns:\n            torch.Tensor: a vector with areas of each box.\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "area", "=", "(", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", ")", "*", "(", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", ")", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip": [[192, 207], ["torch.isfinite().all", "boxes.Boxes.tensor[].clamp", "boxes.Boxes.tensor[].clamp", "boxes.Boxes.tensor[].clamp", "boxes.Boxes.tensor[].clamp", "torch.stack", "torch.isfinite"], "methods", ["None"], ["", "def", "clip", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Clip (in place) the boxes by limiting x coordinates to the range [0, width]\n        and y coordinates to the range [0, height].\n\n        Args:\n            box_size (height, width): The clipping box's size.\n        \"\"\"", "\n", "assert", "torch", ".", "isfinite", "(", "self", ".", "tensor", ")", ".", "all", "(", ")", ",", "\"Box tensor contains infinite or NaN!\"", "\n", "h", ",", "w", "=", "box_size", "\n", "x1", "=", "self", ".", "tensor", "[", ":", ",", "0", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y1", "=", "self", ".", "tensor", "[", ":", ",", "1", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "x2", "=", "self", ".", "tensor", "[", ":", ",", "2", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", ")", "\n", "y2", "=", "self", ".", "tensor", "[", ":", ",", "3", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", ")", "\n", "self", ".", "tensor", "=", "torch", ".", "stack", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty": [[208, 223], ["None"], "methods", ["None"], ["", "def", "nonempty", "(", "self", ",", "threshold", ":", "float", "=", "0.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find boxes that are non-empty.\n        A box is considered empty, if either of its side is no larger than threshold.\n\n        Returns:\n            Tensor:\n                a binary vector which represents whether each box is empty\n                (False) or non-empty (True).\n        \"\"\"", "\n", "box", "=", "self", ".", "tensor", "\n", "widths", "=", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", "\n", "heights", "=", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", "\n", "keep", "=", "(", "widths", ">", "threshold", ")", "&", "(", "heights", ">", "threshold", ")", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.__getitem__": [[224, 247], ["isinstance", "boxes.Boxes", "boxes.Boxes", "b.dim", "boxes.Boxes.tensor[].view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", "->", "\"Boxes\"", ":", "\n", "        ", "\"\"\"\n        Args:\n            item: int, slice, or a BoolTensor\n\n        Returns:\n            Boxes: Create a new :class:`Boxes` by indexing.\n\n        The following usage are allowed:\n\n        1. `new_boxes = boxes[3]`: return a `Boxes` which contains only one box.\n        2. `new_boxes = boxes[2:10]`: return a slice of boxes.\n        3. `new_boxes = boxes[vector]`, where vector is a torch.BoolTensor\n           with `length = len(boxes)`. Nonzero elements in the vector will be selected.\n\n        Note that the returned Boxes might share storage with this Boxes,\n        subject to Pytorch's indexing semantics.\n        \"\"\"", "\n", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "Boxes", "(", "self", ".", "tensor", "[", "item", "]", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "b", "=", "self", ".", "tensor", "[", "item", "]", "\n", "assert", "b", ".", "dim", "(", ")", "==", "2", ",", "\"Indexing on Boxes with {} failed to return a matrix!\"", ".", "format", "(", "item", ")", "\n", "return", "Boxes", "(", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.__len__": [[248, 250], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.__repr__": [[251, 253], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "\"Boxes(\"", "+", "str", "(", "self", ".", "tensor", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.inside_box": [[254, 272], ["None"], "methods", ["None"], ["", "def", "inside_box", "(", "self", ",", "box_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "boundary_threshold", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_size (height, width): Size of the reference box.\n            boundary_threshold (int): Boxes that extend beyond the reference box\n                boundary by more than boundary_threshold are considered \"outside\".\n\n        Returns:\n            a binary vector, indicating whether each box is inside the reference box.\n        \"\"\"", "\n", "height", ",", "width", "=", "box_size", "\n", "inds_inside", "=", "(", "\n", "(", "self", ".", "tensor", "[", "...", ",", "0", "]", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "self", ".", "tensor", "[", "...", ",", "1", "]", ">=", "-", "boundary_threshold", ")", "\n", "&", "(", "self", ".", "tensor", "[", "...", ",", "2", "]", "<", "width", "+", "boundary_threshold", ")", "\n", "&", "(", "self", ".", "tensor", "[", "...", ",", "3", "]", "<", "height", "+", "boundary_threshold", ")", "\n", ")", "\n", "return", "inds_inside", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.get_centers": [[273, 279], ["None"], "methods", ["None"], ["", "def", "get_centers", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns:\n            The box centers in a Nx2 array of (x, y).\n        \"\"\"", "\n", "return", "(", "self", ".", "tensor", "[", ":", ",", ":", "2", "]", "+", "self", ".", "tensor", "[", ":", ",", "2", ":", "]", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.scale": [[280, 286], ["None"], "methods", ["None"], ["", "def", "scale", "(", "self", ",", "scale_x", ":", "float", ",", "scale_y", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Scale the box with horizontal and vertical scaling factors\n        \"\"\"", "\n", "self", ".", "tensor", "[", ":", ",", "0", ":", ":", "2", "]", "*=", "scale_x", "\n", "self", ".", "tensor", "[", ":", ",", "1", ":", ":", "2", "]", "*=", "scale_y", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.cat": [[287, 307], ["isinstance", "all", "cls", "len", "cls", "torch.cat", "torch.empty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "@", "classmethod", "\n", "@", "_maybe_jit_unused", "\n", "def", "cat", "(", "cls", ",", "boxes_list", ":", "List", "[", "\"Boxes\"", "]", ")", "->", "\"Boxes\"", ":", "\n", "        ", "\"\"\"\n        Concatenates a list of Boxes into a single Boxes\n\n        Arguments:\n            boxes_list (list[Boxes])\n\n        Returns:\n            Boxes: the concatenated Boxes\n        \"\"\"", "\n", "assert", "isinstance", "(", "boxes_list", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "boxes_list", ")", "==", "0", ":", "\n", "            ", "return", "cls", "(", "torch", ".", "empty", "(", "0", ")", ")", "\n", "", "assert", "all", "(", "[", "isinstance", "(", "box", ",", "Boxes", ")", "for", "box", "in", "boxes_list", "]", ")", "\n", "\n", "# use torch.cat (v.s. layers.cat) so the returned boxes never share storage with input", "\n", "cat_boxes", "=", "cls", "(", "torch", ".", "cat", "(", "[", "b", ".", "tensor", "for", "b", "in", "boxes_list", "]", ",", "dim", "=", "0", ")", ")", "\n", "return", "cat_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.device": [[308, 311], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "device", ":", "\n", "        ", "return", "self", ".", "tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.__iter__": [[314, 320], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Yield a box as a Tensor of shape (4,) at a time.\n        \"\"\"", "\n", "yield", "from", "self", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_intersection": [[322, 342], ["width_height.clamp_", "width_height.prod", "torch.min", "torch.max"], "function", ["None"], ["", "", "def", "pairwise_intersection", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Given two lists of boxes of size N and M,\n    compute the intersection area between __all__ N x M pairs of boxes.\n    The box order must be (xmin, ymin, xmax, ymax)\n\n    Args:\n        boxes1,boxes2 (Boxes): two `Boxes`. Contains N & M boxes, respectively.\n\n    Returns:\n        Tensor: intersection, sized [N,M].\n    \"\"\"", "\n", "boxes1", ",", "boxes2", "=", "boxes1", ".", "tensor", ",", "boxes2", ".", "tensor", "\n", "width_height", "=", "torch", ".", "min", "(", "boxes1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "boxes2", "[", ":", ",", "2", ":", "]", ")", "-", "torch", ".", "max", "(", "\n", "boxes1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "boxes2", "[", ":", ",", ":", "2", "]", "\n", ")", "# [N,M,2]", "\n", "\n", "width_height", ".", "clamp_", "(", "min", "=", "0", ")", "# [N,M,2]", "\n", "intersection", "=", "width_height", ".", "prod", "(", "dim", "=", "2", ")", "# [N,M]", "\n", "return", "intersection", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_iou": [[346, 369], ["boxes1.area", "boxes2.area", "boxes.pairwise_intersection", "torch.where", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_intersection"], ["", "def", "pairwise_iou", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Given two lists of boxes of size N and M, compute the IoU\n    (intersection over union) between **all** N x M pairs of boxes.\n    The box order must be (xmin, ymin, xmax, ymax).\n\n    Args:\n        boxes1,boxes2 (Boxes): two `Boxes`. Contains N & M boxes, respectively.\n\n    Returns:\n        Tensor: IoU, sized [N,M].\n    \"\"\"", "\n", "area1", "=", "boxes1", ".", "area", "(", ")", "# [N]", "\n", "area2", "=", "boxes2", ".", "area", "(", ")", "# [M]", "\n", "inter", "=", "pairwise_intersection", "(", "boxes1", ",", "boxes2", ")", "\n", "\n", "# handle empty boxes", "\n", "iou", "=", "torch", ".", "where", "(", "\n", "inter", ">", "0", ",", "\n", "inter", "/", "(", "area1", "[", ":", ",", "None", "]", "+", "area2", "-", "inter", ")", ",", "\n", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "inter", ".", "dtype", ",", "device", "=", "inter", ".", "device", ")", ",", "\n", ")", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_ioa": [[371, 389], ["boxes2.area", "boxes.pairwise_intersection", "torch.where", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_intersection"], ["", "def", "pairwise_ioa", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Similar to :func:`pariwise_iou` but compute the IoA (intersection over boxes2 area).\n\n    Args:\n        boxes1,boxes2 (Boxes): two `Boxes`. Contains N & M boxes, respectively.\n\n    Returns:\n        Tensor: IoA, sized [N,M].\n    \"\"\"", "\n", "area2", "=", "boxes2", ".", "area", "(", ")", "# [M]", "\n", "inter", "=", "pairwise_intersection", "(", "boxes1", ",", "boxes2", ")", "\n", "\n", "# handle empty boxes", "\n", "ioa", "=", "torch", ".", "where", "(", "\n", "inter", ">", "0", ",", "inter", "/", "area2", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "inter", ".", "dtype", ",", "device", "=", "inter", ".", "device", ")", "\n", ")", "\n", "return", "ioa", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.matched_boxlist_iou": [[391, 417], ["boxes1.area", "boxes2.area", "torch.max", "torch.min", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area"], ["", "def", "matched_boxlist_iou", "(", "boxes1", ":", "Boxes", ",", "boxes2", ":", "Boxes", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Compute pairwise intersection over union (IOU) of two sets of matched\n    boxes. The box order must be (xmin, ymin, xmax, ymax).\n    Similar to boxlist_iou, but computes only diagonal elements of the matrix\n\n    Args:\n        boxes1: (Boxes) bounding boxes, sized [N,4].\n        boxes2: (Boxes) bounding boxes, sized [N,4].\n    Returns:\n        Tensor: iou, sized [N].\n    \"\"\"", "\n", "assert", "len", "(", "boxes1", ")", "==", "len", "(", "\n", "boxes2", "\n", ")", ",", "\"boxlists should have the same\"", "\"number of entries, got {}, {}\"", ".", "format", "(", "\n", "len", "(", "boxes1", ")", ",", "len", "(", "boxes2", ")", "\n", ")", "\n", "area1", "=", "boxes1", ".", "area", "(", ")", "# [N]", "\n", "area2", "=", "boxes2", ".", "area", "(", ")", "# [N]", "\n", "box1", ",", "box2", "=", "boxes1", ".", "tensor", ",", "boxes2", ".", "tensor", "\n", "lt", "=", "torch", ".", "max", "(", "box1", "[", ":", ",", ":", "2", "]", ",", "box2", "[", ":", ",", ":", "2", "]", ")", "# [N,2]", "\n", "rb", "=", "torch", ".", "min", "(", "box1", "[", ":", ",", "2", ":", "]", ",", "box2", "[", ":", ",", "2", ":", "]", ")", "# [N,2]", "\n", "wh", "=", "(", "rb", "-", "lt", ")", ".", "clamp", "(", "min", "=", "0", ")", "# [N,2]", "\n", "inter", "=", "wh", "[", ":", ",", "0", "]", "*", "wh", "[", ":", ",", "1", "]", "# [N]", "\n", "iou", "=", "inter", "/", "(", "area1", "+", "area2", "-", "inter", ")", "# [N]", "\n", "return", "iou", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.__init__": [[50, 74], ["torch.as_tensor", "torch.as_tensor", "torch.device", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "densepose.data.meshes.catalog.MeshCatalog.get_mesh_id", "data_relative.DensePoseDataRelative.extract_segmentation_mask", "data_relative.DensePoseDataRelative.cleanup_annotation"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.get_mesh_id", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.extract_segmentation_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.cleanup_annotation"], ["def", "__init__", "(", "self", ",", "annotation", ",", "cleanup", "=", "False", ")", ":", "\n", "        ", "self", ".", "x", "=", "torch", ".", "as_tensor", "(", "annotation", "[", "DensePoseDataRelative", ".", "X_KEY", "]", ")", "\n", "self", ".", "y", "=", "torch", ".", "as_tensor", "(", "annotation", "[", "DensePoseDataRelative", ".", "Y_KEY", "]", ")", "\n", "if", "(", "\n", "DensePoseDataRelative", ".", "I_KEY", "in", "annotation", "\n", "and", "DensePoseDataRelative", ".", "U_KEY", "in", "annotation", "\n", "and", "DensePoseDataRelative", ".", "V_KEY", "in", "annotation", "\n", ")", ":", "\n", "            ", "self", ".", "i", "=", "torch", ".", "as_tensor", "(", "annotation", "[", "DensePoseDataRelative", ".", "I_KEY", "]", ")", "\n", "self", ".", "u", "=", "torch", ".", "as_tensor", "(", "annotation", "[", "DensePoseDataRelative", ".", "U_KEY", "]", ")", "\n", "self", ".", "v", "=", "torch", ".", "as_tensor", "(", "annotation", "[", "DensePoseDataRelative", ".", "V_KEY", "]", ")", "\n", "", "if", "(", "\n", "DensePoseDataRelative", ".", "VERTEX_IDS_KEY", "in", "annotation", "\n", "and", "DensePoseDataRelative", ".", "MESH_NAME_KEY", "in", "annotation", "\n", ")", ":", "\n", "            ", "self", ".", "vertex_ids", "=", "torch", ".", "as_tensor", "(", "\n", "annotation", "[", "DensePoseDataRelative", ".", "VERTEX_IDS_KEY", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "self", ".", "mesh_id", "=", "MeshCatalog", ".", "get_mesh_id", "(", "annotation", "[", "DensePoseDataRelative", ".", "MESH_NAME_KEY", "]", ")", "\n", "", "if", "DensePoseDataRelative", ".", "S_KEY", "in", "annotation", ":", "\n", "            ", "self", ".", "segm", "=", "DensePoseDataRelative", ".", "extract_segmentation_mask", "(", "annotation", ")", "\n", "", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "if", "cleanup", ":", "\n", "            ", "DensePoseDataRelative", ".", "cleanup_annotation", "(", "annotation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.to": [[75, 88], ["object.__new__", "data_relative.DensePoseDataRelative.x.to", "data_relative.DensePoseDataRelative.y.to", "hasattr", "hasattr", "setattr", "getattr().to", "getattr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.shape_spec.ShapeSpec.__new__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "if", "self", ".", "device", "==", "device", ":", "\n", "            ", "return", "self", "\n", "", "new_data", "=", "DensePoseDataRelative", ".", "__new__", "(", "DensePoseDataRelative", ")", "\n", "new_data", ".", "x", "=", "self", ".", "x", ".", "to", "(", "device", ")", "\n", "new_data", ".", "y", "=", "self", ".", "y", ".", "to", "(", "device", ")", "\n", "for", "attr", "in", "[", "\"i\"", ",", "\"u\"", ",", "\"v\"", ",", "\"vertex_ids\"", ",", "\"segm\"", "]", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "attr", ")", ":", "\n", "                ", "setattr", "(", "new_data", ",", "attr", ",", "getattr", "(", "self", ",", "attr", ")", ".", "to", "(", "device", ")", ")", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"mesh_id\"", ")", ":", "\n", "            ", "new_data", ".", "mesh_id", "=", "self", ".", "mesh_id", "\n", "", "new_data", ".", "device", "=", "device", "\n", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.extract_segmentation_mask": [[89, 112], ["isinstance", "torch.zeros", "isinstance", "range", "mask_utils.decode", "len", "mask_utils.decode"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["", "@", "staticmethod", "\n", "def", "extract_segmentation_mask", "(", "annotation", ")", ":", "\n", "        ", "import", "pycocotools", ".", "mask", "as", "mask_utils", "\n", "\n", "# TODO: annotation instance is accepted if it contains either", "\n", "# DensePose segmentation or instance segmentation. However, here we", "\n", "# only rely on DensePose segmentation", "\n", "poly_specs", "=", "annotation", "[", "DensePoseDataRelative", ".", "S_KEY", "]", "\n", "if", "isinstance", "(", "poly_specs", ",", "torch", ".", "Tensor", ")", ":", "\n", "# data is already given as mask tensors, no need to decode", "\n", "            ", "return", "poly_specs", "\n", "", "segm", "=", "torch", ".", "zeros", "(", "(", "DensePoseDataRelative", ".", "MASK_SIZE", ",", ")", "*", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "if", "isinstance", "(", "poly_specs", ",", "dict", ")", ":", "\n", "            ", "if", "poly_specs", ":", "\n", "                ", "mask", "=", "mask_utils", ".", "decode", "(", "poly_specs", ")", "\n", "segm", "[", "mask", ">", "0", "]", "=", "1", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "poly_specs", ")", ")", ":", "\n", "                ", "poly_i", "=", "poly_specs", "[", "i", "]", "\n", "if", "poly_i", ":", "\n", "                    ", "mask_i", "=", "mask_utils", ".", "decode", "(", "poly_i", ")", "\n", "segm", "[", "mask_i", ">", "0", "]", "=", "i", "+", "1", "\n", "", "", "", "return", "segm", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.validate_annotation": [[113, 156], ["all", "all"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "validate_annotation", "(", "annotation", ")", ":", "\n", "        ", "for", "key", "in", "[", "\n", "DensePoseDataRelative", ".", "X_KEY", ",", "\n", "DensePoseDataRelative", ".", "Y_KEY", ",", "\n", "]", ":", "\n", "            ", "if", "key", "not", "in", "annotation", ":", "\n", "                ", "return", "False", ",", "\"no {key} data in the annotation\"", ".", "format", "(", "key", "=", "key", ")", "\n", "", "", "valid_for_iuv_setting", "=", "all", "(", "\n", "key", "in", "annotation", "\n", "for", "key", "in", "[", "\n", "DensePoseDataRelative", ".", "I_KEY", ",", "\n", "DensePoseDataRelative", ".", "U_KEY", ",", "\n", "DensePoseDataRelative", ".", "V_KEY", ",", "\n", "]", "\n", ")", "\n", "valid_for_cse_setting", "=", "all", "(", "\n", "key", "in", "annotation", "\n", "for", "key", "in", "[", "\n", "DensePoseDataRelative", ".", "VERTEX_IDS_KEY", ",", "\n", "DensePoseDataRelative", ".", "MESH_NAME_KEY", ",", "\n", "]", "\n", ")", "\n", "if", "not", "valid_for_iuv_setting", "and", "not", "valid_for_cse_setting", ":", "\n", "            ", "return", "(", "\n", "False", ",", "\n", "\"expected either {} (IUV setting) or {} (CSE setting) annotations\"", ".", "format", "(", "\n", "\", \"", ".", "join", "(", "\n", "[", "\n", "DensePoseDataRelative", ".", "I_KEY", ",", "\n", "DensePoseDataRelative", ".", "U_KEY", ",", "\n", "DensePoseDataRelative", ".", "V_KEY", ",", "\n", "]", "\n", ")", ",", "\n", "\", \"", ".", "join", "(", "\n", "[", "\n", "DensePoseDataRelative", ".", "VERTEX_IDS_KEY", ",", "\n", "DensePoseDataRelative", ".", "MESH_NAME_KEY", ",", "\n", "]", "\n", ")", ",", "\n", ")", ",", "\n", ")", "\n", "", "return", "True", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.cleanup_annotation": [[157, 171], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "cleanup_annotation", "(", "annotation", ")", ":", "\n", "        ", "for", "key", "in", "[", "\n", "DensePoseDataRelative", ".", "X_KEY", ",", "\n", "DensePoseDataRelative", ".", "Y_KEY", ",", "\n", "DensePoseDataRelative", ".", "I_KEY", ",", "\n", "DensePoseDataRelative", ".", "U_KEY", ",", "\n", "DensePoseDataRelative", ".", "V_KEY", ",", "\n", "DensePoseDataRelative", ".", "S_KEY", ",", "\n", "DensePoseDataRelative", ".", "VERTEX_IDS_KEY", ",", "\n", "DensePoseDataRelative", ".", "MESH_NAME_KEY", ",", "\n", "]", ":", "\n", "            ", "if", "key", "in", "annotation", ":", "\n", "                ", "del", "annotation", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.apply_transform": [[172, 176], ["data_relative.DensePoseDataRelative._transform_pts", "hasattr", "data_relative.DensePoseDataRelative._transform_segm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._transform_pts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._transform_segm"], ["", "", "", "def", "apply_transform", "(", "self", ",", "transforms", ",", "densepose_transform_data", ")", ":", "\n", "        ", "self", ".", "_transform_pts", "(", "transforms", ",", "densepose_transform_data", ")", "\n", "if", "hasattr", "(", "self", ",", "\"segm\"", ")", ":", "\n", "            ", "self", ".", "_transform_segm", "(", "transforms", ",", "densepose_transform_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._transform_pts": [[177, 194], ["hasattr", "hasattr", "isinstance", "sum", "data_relative.DensePoseDataRelative._flip_iuv_semantics", "data_relative.DensePoseDataRelative._flip_vertices", "t.apply_coords", "numpy.array", "torch.tensor", "isinstance", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._flip_iuv_semantics", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._flip_vertices", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_coords"], ["", "", "def", "_transform_pts", "(", "self", ",", "transforms", ",", "dp_transform_data", ")", ":", "\n", "        ", "import", "detectron2", ".", "data", ".", "transforms", "as", "T", "\n", "\n", "# NOTE: This assumes that HorizFlipTransform is the only one that does flip", "\n", "do_hflip", "=", "sum", "(", "isinstance", "(", "t", ",", "T", ".", "HFlipTransform", ")", "for", "t", "in", "transforms", ".", "transforms", ")", "%", "2", "==", "1", "\n", "if", "do_hflip", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "MASK_SIZE", "-", "self", ".", "x", "\n", "if", "hasattr", "(", "self", ",", "\"i\"", ")", ":", "\n", "                ", "self", ".", "_flip_iuv_semantics", "(", "dp_transform_data", ")", "\n", "", "if", "hasattr", "(", "self", ",", "\"vertex_ids\"", ")", ":", "\n", "                ", "self", ".", "_flip_vertices", "(", ")", "\n", "\n", "", "", "for", "t", "in", "transforms", ".", "transforms", ":", "\n", "            ", "if", "isinstance", "(", "t", ",", "T", ".", "RotationTransform", ")", ":", "\n", "                ", "xy_scale", "=", "np", ".", "array", "(", "(", "t", ".", "w", ",", "t", ".", "h", ")", ")", "/", "DensePoseDataRelative", ".", "MASK_SIZE", "\n", "xy", "=", "t", ".", "apply_coords", "(", "np", ".", "stack", "(", "(", "self", ".", "x", ",", "self", ".", "y", ")", ",", "axis", "=", "1", ")", "*", "xy_scale", ")", "\n", "self", ".", "x", ",", "self", ".", "y", "=", "torch", ".", "tensor", "(", "xy", "/", "xy_scale", ",", "dtype", "=", "self", ".", "x", ".", "dtype", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._flip_iuv_semantics": [[195, 211], ["data_relative.DensePoseDataRelative.i.clone", "range", "[].to", "[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "", "def", "_flip_iuv_semantics", "(", "self", ",", "dp_transform_data", ":", "DensePoseTransformData", ")", "->", "None", ":", "\n", "        ", "i_old", "=", "self", ".", "i", ".", "clone", "(", ")", "\n", "uv_symmetries", "=", "dp_transform_data", ".", "uv_symmetries", "\n", "pt_label_symmetries", "=", "dp_transform_data", ".", "point_label_symmetries", "\n", "for", "i", "in", "range", "(", "self", ".", "N_PART_LABELS", ")", ":", "\n", "            ", "if", "i", "+", "1", "in", "i_old", ":", "\n", "                ", "annot_indices_i", "=", "i_old", "==", "i", "+", "1", "\n", "if", "pt_label_symmetries", "[", "i", "+", "1", "]", "!=", "i", "+", "1", ":", "\n", "                    ", "self", ".", "i", "[", "annot_indices_i", "]", "=", "pt_label_symmetries", "[", "i", "+", "1", "]", "\n", "", "u_loc", "=", "(", "self", ".", "u", "[", "annot_indices_i", "]", "*", "255", ")", ".", "long", "(", ")", "\n", "v_loc", "=", "(", "self", ".", "v", "[", "annot_indices_i", "]", "*", "255", ")", ".", "long", "(", ")", "\n", "self", ".", "u", "[", "annot_indices_i", "]", "=", "uv_symmetries", "[", "\"U_transforms\"", "]", "[", "i", "]", "[", "v_loc", ",", "u_loc", "]", ".", "to", "(", "\n", "device", "=", "self", ".", "u", ".", "device", "\n", ")", "\n", "self", ".", "v", "[", "annot_indices_i", "]", "=", "uv_symmetries", "[", "\"V_transforms\"", "]", "[", "i", "]", "[", "v_loc", ",", "u_loc", "]", ".", "to", "(", "\n", "device", "=", "self", ".", "v", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._flip_vertices": [[213, 219], ["densepose.structures.mesh.load_mesh_symmetry", "densepose.data.meshes.catalog.MeshCatalog.get_mesh_name"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_symmetry", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.get_mesh_name"], ["", "", "", "def", "_flip_vertices", "(", "self", ")", ":", "\n", "        ", "mesh_info", "=", "MeshCatalog", "[", "MeshCatalog", ".", "get_mesh_name", "(", "self", ".", "mesh_id", ")", "]", "\n", "mesh_symmetry", "=", "(", "\n", "load_mesh_symmetry", "(", "mesh_info", ".", "symmetry", ")", "if", "mesh_info", ".", "symmetry", "is", "not", "None", "else", "None", "\n", ")", "\n", "self", ".", "vertex_ids", "=", "mesh_symmetry", "[", "\"vertex_transforms\"", "]", "[", "self", ".", "vertex_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._transform_segm": [[220, 232], ["torch.flip", "data_relative.DensePoseDataRelative._flip_segm_semantics", "isinstance", "sum", "data_relative.DensePoseDataRelative._transform_segm_rotation", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._flip_segm_semantics", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._transform_segm_rotation"], ["", "def", "_transform_segm", "(", "self", ",", "transforms", ",", "dp_transform_data", ")", ":", "\n", "        ", "import", "detectron2", ".", "data", ".", "transforms", "as", "T", "\n", "\n", "# NOTE: This assumes that HorizFlipTransform is the only one that does flip", "\n", "do_hflip", "=", "sum", "(", "isinstance", "(", "t", ",", "T", ".", "HFlipTransform", ")", "for", "t", "in", "transforms", ".", "transforms", ")", "%", "2", "==", "1", "\n", "if", "do_hflip", ":", "\n", "            ", "self", ".", "segm", "=", "torch", ".", "flip", "(", "self", ".", "segm", ",", "[", "1", "]", ")", "\n", "self", ".", "_flip_segm_semantics", "(", "dp_transform_data", ")", "\n", "\n", "", "for", "t", "in", "transforms", ".", "transforms", ":", "\n", "            ", "if", "isinstance", "(", "t", ",", "T", ".", "RotationTransform", ")", ":", "\n", "                ", "self", ".", "_transform_segm_rotation", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._flip_segm_semantics": [[233, 239], ["data_relative.DensePoseDataRelative.segm.clone", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "", "", "def", "_flip_segm_semantics", "(", "self", ",", "dp_transform_data", ")", ":", "\n", "        ", "old_segm", "=", "self", ".", "segm", ".", "clone", "(", ")", "\n", "mask_label_symmetries", "=", "dp_transform_data", ".", "mask_label_symmetries", "\n", "for", "i", "in", "range", "(", "self", ".", "N_BODY_PARTS", ")", ":", "\n", "            ", "if", "mask_label_symmetries", "[", "i", "+", "1", "]", "!=", "i", "+", "1", ":", "\n", "                ", "self", ".", "segm", "[", "old_segm", "==", "i", "+", "1", "]", "=", "mask_label_symmetries", "[", "i", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative._transform_segm_rotation": [[240, 244], ["torch.nn.functional.interpolate().numpy", "torch.tensor", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "rotation.apply_segmentation"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_segmentation"], ["", "", "", "def", "_transform_segm_rotation", "(", "self", ",", "rotation", ")", ":", "\n", "        ", "self", ".", "segm", "=", "F", ".", "interpolate", "(", "self", ".", "segm", "[", "None", ",", "None", ",", ":", "]", ",", "(", "rotation", ".", "h", ",", "rotation", ".", "w", ")", ")", ".", "numpy", "(", ")", "\n", "self", ".", "segm", "=", "torch", ".", "tensor", "(", "rotation", ".", "apply_segmentation", "(", "self", ".", "segm", "[", "0", ",", "0", "]", ")", ")", "[", "None", ",", "None", ",", ":", "]", "\n", "self", ".", "segm", "=", "F", ".", "interpolate", "(", "self", ".", "segm", ",", "[", "DensePoseDataRelative", ".", "MASK_SIZE", "]", "*", "2", ")", "[", "0", ",", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_confidence.decorate_predictor_output_class_with_confidences": [[9, 99], ["functools.lru_cache", "dataclasses.make_dataclass", "isinstance", "type", "super().__getitem__", "type.", "type", "super().to", "type.", "data[].unsqueeze", "isinstance", "chart_confidence.decorate_predictor_output_class_with_confidences.slice_if_not_none"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__getitem__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["\n", "from", "...", "structures", "import", "decorate_predictor_output_class_with_confidences", "\n", "from", ".", ".", "confidence", "import", "DensePoseConfidenceModelConfig", ",", "DensePoseUVConfidenceType", "\n", "from", ".", ".", "utils", "import", "initialize_module_params", "\n", "\n", "\n", "class", "DensePoseChartConfidencePredictorMixin", ":", "\n", "    ", "\"\"\"\n    Predictor contains the last layers of a DensePose model that take DensePose head\n    outputs as an input and produce model outputs. Confidence predictor mixin is used\n    to generate confidences for segmentation and UV tensors estimated by some\n    base predictor. Several assumptions need to hold for the base predictor:\n    1) the `forward` method must return SIUV tuple as the first result (\n        S = coarse segmentation, I = fine segmentation, U and V are intrinsic\n        chart coordinates)\n    2) `interp2d` method must be defined to perform bilinear interpolation;\n        the same method is typically used for SIUV and confidences\n    Confidence predictor mixin provides confidence estimates, as described in:\n        N. Neverova et al., Correlated Uncertainty for Learning Dense Correspondences\n            from Noisy Labels, NeurIPS 2019\n        A. Sanakoyeu et al., Transferring Dense Pose to Proximal Animal Classes, CVPR 2020\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence predictor using configuration options.\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): number of input channels\n        \"\"\"", "\n", "# we rely on base predictor to call nn.Module.__init__", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "input_channels", ")", "# pyre-ignore[19]", "\n", "self", ".", "confidence_model_cfg", "=", "DensePoseConfidenceModelConfig", ".", "from_cfg", "(", "cfg", ")", "\n", "self", ".", "_initialize_confidence_estimation_layers", "(", "cfg", ",", "input_channels", ")", "\n", "self", ".", "_registry", "=", "{", "}", "\n", "initialize_module_params", "(", "self", ")", "# pyre-ignore[6]", "\n", "\n", "", "def", "_initialize_confidence_estimation_layers", "(", "self", ",", "cfg", ":", "CfgNode", ",", "dim_in", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence estimation layers based on configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n            dim_in (int): number of input channels\n        \"\"\"", "\n", "dim_out_patches", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_PATCHES", "+", "1", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "enabled", ":", "\n", "            ", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "==", "DensePoseUVConfidenceType", ".", "IID_ISO", ":", "\n", "                ", "self", ".", "sigma_2_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "", "elif", "(", "\n", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "\n", "==", "DensePoseUVConfidenceType", ".", "INDEP_ANISO", "\n", ")", ":", "\n", "                ", "self", ".", "sigma_2_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "kappa_u_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "kappa_v_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Unknown confidence model type: \"", "\n", "f\"{self.confidence_model_cfg.confidence_model_type}\"", "\n", ")", "\n", "", "", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "            ", "self", ".", "fine_segm_confidence_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "1", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "coarse_segm_confidence_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "1", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "head_outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward operation on head outputs used as inputs for the predictor.\n        Calls forward method from the base predictor and uses its outputs to compute\n        confidences.\n\n        Args:\n            head_outputs (Tensor): head outputs used as predictor inputs\n        Return:\n            An instance of outputs with confidences,\n            see `decorate_predictor_output_class_with_confidences`\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.__init__": [[22, 78], ["all", "all", "torch.device", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "vertices", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "faces", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "geodists", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "symmetry", ":", "Optional", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "texcoords", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "mesh_info", ":", "Optional", "[", "MeshInfo", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            vertices (tensor [N, 3] of float32): vertex coordinates in 3D\n            faces (tensor [M, 3] of long): triangular face represented as 3\n                vertex indices\n            geodists (tensor [N, N] of float32): geodesic distances from\n                vertex `i` to vertex `j` (optional, default: None)\n            symmetry (dict: str -> tensor): various mesh symmetry data:\n                - \"vertex_transforms\": vertex mapping under horizontal flip,\n                  tensor of size [N] of type long; vertex `i` is mapped to\n                  vertex `tensor[i]` (optional, default: None)\n            texcoords (tensor [N, 2] of float32): texture coordinates, i.e. global\n                and normalized mesh UVs (optional, default: None)\n            mesh_info (MeshInfo type): necessary to load the attributes on-the-go,\n                can be used instead of passing all the variables one by one\n            device (torch.device): device of the Mesh. If not provided, will use\n                the device of the vertices\n        \"\"\"", "\n", "self", ".", "_vertices", "=", "vertices", "\n", "self", ".", "_faces", "=", "faces", "\n", "self", ".", "_geodists", "=", "geodists", "\n", "self", ".", "_symmetry", "=", "symmetry", "\n", "self", ".", "_texcoords", "=", "texcoords", "\n", "self", ".", "mesh_info", "=", "mesh_info", "\n", "self", ".", "device", "=", "device", "\n", "\n", "assert", "self", ".", "_vertices", "is", "not", "None", "or", "self", ".", "mesh_info", "is", "not", "None", "\n", "\n", "all_fields", "=", "[", "self", ".", "_vertices", ",", "self", ".", "_faces", ",", "self", ".", "_geodists", ",", "self", ".", "_texcoords", "]", "\n", "\n", "if", "self", ".", "device", "is", "None", ":", "\n", "            ", "for", "field", "in", "all_fields", ":", "\n", "                ", "if", "field", "is", "not", "None", ":", "\n", "                    ", "self", ".", "device", "=", "field", ".", "device", "\n", "break", "\n", "", "", "if", "self", ".", "device", "is", "None", "and", "symmetry", "is", "not", "None", ":", "\n", "                ", "for", "key", "in", "symmetry", ":", "\n", "                    ", "self", ".", "device", "=", "symmetry", "[", "key", "]", ".", "device", "\n", "break", "\n", "", "", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "self", ".", "device", "is", "None", "else", "self", ".", "device", "\n", "\n", "", "assert", "all", "(", "[", "var", ".", "device", "==", "self", ".", "device", "for", "var", "in", "all_fields", "if", "var", "is", "not", "None", "]", ")", "\n", "if", "symmetry", ":", "\n", "            ", "assert", "all", "(", "symmetry", "[", "key", "]", ".", "device", "==", "self", ".", "device", "for", "key", "in", "symmetry", ")", "\n", "", "if", "texcoords", "and", "vertices", ":", "\n", "            ", "assert", "len", "(", "vertices", ")", "==", "len", "(", "texcoords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.to": [[79, 91], ["mesh.Mesh", "mesh._maybe_copy_to_device", "mesh._maybe_copy_to_device", "mesh._maybe_copy_to_device", "mesh._maybe_copy_to_device", "value.to", "device_symmetry.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh._maybe_copy_to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh._maybe_copy_to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh._maybe_copy_to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh._maybe_copy_to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "device_symmetry", "=", "self", ".", "_symmetry", "\n", "if", "device_symmetry", ":", "\n", "            ", "device_symmetry", "=", "{", "key", ":", "value", ".", "to", "(", "device", ")", "for", "key", ",", "value", "in", "device_symmetry", ".", "items", "(", ")", "}", "\n", "", "return", "Mesh", "(", "\n", "_maybe_copy_to_device", "(", "self", ".", "_vertices", ",", "device", ")", ",", "\n", "_maybe_copy_to_device", "(", "self", ".", "_faces", ",", "device", ")", ",", "\n", "_maybe_copy_to_device", "(", "self", ".", "_geodists", ",", "device", ")", ",", "\n", "device_symmetry", ",", "\n", "_maybe_copy_to_device", "(", "self", ".", "_texcoords", ",", "device", ")", ",", "\n", "self", ".", "mesh_info", ",", "\n", "device", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.vertices": [[93, 98], ["mesh.load_mesh_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_data"], ["", "@", "property", "\n", "def", "vertices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_vertices", "is", "None", "and", "self", ".", "mesh_info", "is", "not", "None", ":", "\n", "            ", "self", ".", "_vertices", "=", "load_mesh_data", "(", "self", ".", "mesh_info", ".", "data", ",", "\"vertices\"", ",", "self", ".", "device", ")", "\n", "", "return", "self", ".", "_vertices", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.faces": [[99, 104], ["mesh.load_mesh_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_data"], ["", "@", "property", "\n", "def", "faces", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_faces", "is", "None", "and", "self", ".", "mesh_info", "is", "not", "None", ":", "\n", "            ", "self", ".", "_faces", "=", "load_mesh_data", "(", "self", ".", "mesh_info", ".", "data", ",", "\"faces\"", ",", "self", ".", "device", ")", "\n", "", "return", "self", ".", "_faces", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.geodists": [[105, 110], ["mesh.load_mesh_auxiliary_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_auxiliary_data"], ["", "@", "property", "\n", "def", "geodists", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_geodists", "is", "None", "and", "self", ".", "mesh_info", "is", "not", "None", ":", "\n", "            ", "self", ".", "_geodists", "=", "load_mesh_auxiliary_data", "(", "self", ".", "mesh_info", ".", "geodists", ",", "self", ".", "device", ")", "\n", "", "return", "self", ".", "_geodists", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.symmetry": [[111, 116], ["mesh.load_mesh_symmetry"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_symmetry"], ["", "@", "property", "\n", "def", "symmetry", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_symmetry", "is", "None", "and", "self", ".", "mesh_info", "is", "not", "None", ":", "\n", "            ", "self", ".", "_symmetry", "=", "load_mesh_symmetry", "(", "self", ".", "mesh_info", ".", "symmetry", ",", "self", ".", "device", ")", "\n", "", "return", "self", ".", "_symmetry", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.texcoords": [[117, 122], ["mesh.load_mesh_auxiliary_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_auxiliary_data"], ["", "@", "property", "\n", "def", "texcoords", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_texcoords", "is", "None", "and", "self", ".", "mesh_info", "is", "not", "None", ":", "\n", "            ", "self", ".", "_texcoords", "=", "load_mesh_auxiliary_data", "(", "self", ".", "mesh_info", ".", "texcoords", ",", "self", ".", "device", ")", "\n", "", "return", "self", ".", "_texcoords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh.get_geodists": [[123, 127], ["mesh.Mesh._compute_geodists"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh._compute_geodists"], ["", "def", "get_geodists", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "geodists", "is", "None", ":", "\n", "            ", "self", ".", "geodists", "=", "self", ".", "_compute_geodists", "(", ")", "\n", "", "return", "self", ".", "geodists", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.Mesh._compute_geodists": [[128, 132], ["None"], "methods", ["None"], ["", "def", "_compute_geodists", "(", "self", ")", ":", "\n", "# TODO: compute using Laplace-Beltrami", "\n", "        ", "geodists", "=", "None", "\n", "return", "geodists", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh._maybe_copy_to_device": [[13, 19], ["attribute.to"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "_maybe_copy_to_device", "(", "\n", "attribute", ":", "Optional", "[", "torch", ".", "Tensor", "]", ",", "device", ":", "torch", ".", "device", "\n", ")", "->", "Optional", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "attribute", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "return", "attribute", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_data": [[134, 142], ["detectron2.utils.file_io.PathManager.open", "torch.as_tensor().to", "torch.as_tensor", "pickle.load"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "", "def", "load_mesh_data", "(", "\n", "mesh_fpath", ":", "str", ",", "field", ":", "str", ",", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "    ", "with", "PathManager", ".", "open", "(", "mesh_fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "        ", "return", "torch", ".", "as_tensor", "(", "pickle", ".", "load", "(", "hFile", ")", "[", "field", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "# pyre-ignore[6]", "\n", "device", "\n", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_auxiliary_data": [[144, 151], ["detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.open", "torch.as_tensor().to", "torch.as_tensor", "pickle.load"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "load_mesh_auxiliary_data", "(", "\n", "fpath", ":", "str", ",", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", "\n", ")", "->", "Optional", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "fpath_local", "=", "PathManager", ".", "get_local_path", "(", "fpath", ")", "\n", "with", "PathManager", ".", "open", "(", "fpath_local", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "        ", "return", "torch", ".", "as_tensor", "(", "pickle", ".", "load", "(", "hFile", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "device", ")", "# pyre-ignore[6]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.load_mesh_symmetry": [[153, 166], ["functools.lru_cache", "detectron2.utils.file_io.PathManager.open", "pickle.load", "torch.as_tensor().to", "torch.as_tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "@", "lru_cache", "(", ")", "\n", "def", "load_mesh_symmetry", "(", "\n", "symmetry_fpath", ":", "str", ",", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "    ", "with", "PathManager", ".", "open", "(", "symmetry_fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "        ", "symmetry_loaded", "=", "pickle", ".", "load", "(", "hFile", ")", "# pyre-ignore[6]", "\n", "symmetry", "=", "{", "\n", "\"vertex_transforms\"", ":", "torch", ".", "as_tensor", "(", "\n", "symmetry_loaded", "[", "\"vertex_transforms\"", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "to", "(", "device", ")", ",", "\n", "}", "\n", "return", "symmetry", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.create_mesh": [[168, 171], ["functools.lru_cache", "mesh.Mesh"], "function", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "create_mesh", "(", "mesh_name", ":", "str", ",", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ")", ":", "\n", "    ", "return", "Mesh", "(", "mesh_info", "=", "MeshCatalog", "[", "mesh_name", "]", ",", "device", "=", "device", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.transform_data.DensePoseTransformData.__init__": [[27, 32], ["torch.device"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "__init__", "(", "self", ",", "uv_symmetries", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "self", ".", "mask_label_symmetries", "=", "DensePoseTransformData", ".", "MASK_LABEL_SYMMETRIES", "\n", "self", ".", "point_label_symmetries", "=", "DensePoseTransformData", ".", "POINT_LABEL_SYMMETRIES", "\n", "self", ".", "uv_symmetries", "=", "uv_symmetries", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.transform_data.DensePoseTransformData.to": [[33, 50], ["transform_data.DensePoseTransformData", "transform_data.DensePoseTransformData.uv_symmetries[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ",", "copy", ":", "bool", "=", "False", ")", "->", "\"DensePoseTransformData\"", ":", "\n", "        ", "\"\"\"\n        Convert transform data to the specified device\n\n        Args:\n            device (torch.device): device to convert the data to\n            copy (bool): flag that specifies whether to copy or to reference the data\n                in case the device is the same\n        Return:\n            An instance of `DensePoseTransformData` with data stored on the specified device\n        \"\"\"", "\n", "if", "self", ".", "device", "==", "device", "and", "not", "copy", ":", "\n", "            ", "return", "self", "\n", "", "uv_symmetry_map", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "uv_symmetries", ":", "\n", "            ", "uv_symmetry_map", "[", "key", "]", "=", "self", ".", "uv_symmetries", "[", "key", "]", ".", "to", "(", "device", "=", "device", ",", "copy", "=", "copy", ")", "\n", "", "return", "DensePoseTransformData", "(", "uv_symmetry_map", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.transform_data.DensePoseTransformData.load": [[51, 72], ["scipy.io.loadmat", "DensePoseTransformData.DensePoseTransformData", "range", "torch.stack", "map_dst.append", "torch.device", "torch.from_numpy().to", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "@", "staticmethod", "\n", "def", "load", "(", "io", ":", "Union", "[", "str", ",", "BinaryIO", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            io: (str or binary file-like object): input file to load data from\n        Returns:\n            An instance of `DensePoseTransformData` with transforms loaded from the file\n        \"\"\"", "\n", "import", "scipy", ".", "io", "\n", "\n", "uv_symmetry_map", "=", "scipy", ".", "io", ".", "loadmat", "(", "io", ")", "\n", "uv_symmetry_map_torch", "=", "{", "}", "\n", "for", "key", "in", "[", "\"U_transforms\"", ",", "\"V_transforms\"", "]", ":", "\n", "            ", "uv_symmetry_map_torch", "[", "key", "]", "=", "[", "]", "\n", "map_src", "=", "uv_symmetry_map", "[", "key", "]", "\n", "map_dst", "=", "uv_symmetry_map_torch", "[", "key", "]", "\n", "for", "i", "in", "range", "(", "map_src", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "map_dst", ".", "append", "(", "torch", ".", "from_numpy", "(", "map_src", "[", "0", ",", "i", "]", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "", "uv_symmetry_map_torch", "[", "key", "]", "=", "torch", ".", "stack", "(", "map_dst", ",", "dim", "=", "0", ")", "\n", "", "transform_data", "=", "DensePoseTransformData", "(", "uv_symmetry_map_torch", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "return", "transform_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.transform_data.normalized_coords_transform": [[6, 17], ["None"], "function", ["None"], ["def", "normalized_coords_transform", "(", "x0", ",", "y0", ",", "w", ",", "h", ")", ":", "\n", "    ", "\"\"\"\n    Coordinates transform that maps top left corner to (-1, -1) and bottom\n    right corner to (1, 1). Used for torch.grid_sample to initialize the\n    grid\n    \"\"\"", "\n", "\n", "def", "f", "(", "p", ")", ":", "\n", "        ", "return", "(", "2", "*", "(", "p", "[", "0", "]", "-", "x0", ")", "/", "w", "-", "1", ",", "2", "*", "(", "p", "[", "1", "]", "-", "y0", ")", "/", "h", "-", "1", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.list.DensePoseList.__init__": [[11, 30], ["boxes_xyxy_abs.to", "len", "len", "len", "len", "list.DensePoseList.densepose_datas.append", "isinstance", "type", "densepose_data.to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "__init__", "(", "self", ",", "densepose_datas", ",", "boxes_xyxy_abs", ",", "image_size_hw", ",", "device", "=", "_TORCH_DEVICE_CPU", ")", ":", "\n", "        ", "assert", "len", "(", "densepose_datas", ")", "==", "len", "(", "\n", "boxes_xyxy_abs", "\n", ")", ",", "\"Attempt to initialize DensePoseList with {} DensePose datas \"", "\"and {} boxes\"", ".", "format", "(", "\n", "len", "(", "densepose_datas", ")", ",", "len", "(", "boxes_xyxy_abs", ")", "\n", ")", "\n", "self", ".", "densepose_datas", "=", "[", "]", "\n", "for", "densepose_data", "in", "densepose_datas", ":", "\n", "            ", "assert", "isinstance", "(", "densepose_data", ",", "DensePoseDataRelative", ")", "or", "densepose_data", "is", "None", ",", "(", "\n", "\"Attempt to initialize DensePoseList with DensePose datas \"", "\n", "\"of type {}, expected DensePoseDataRelative\"", ".", "format", "(", "type", "(", "densepose_data", ")", ")", "\n", ")", "\n", "densepose_data_ondevice", "=", "(", "\n", "densepose_data", ".", "to", "(", "device", ")", "if", "densepose_data", "is", "not", "None", "else", "None", "\n", ")", "\n", "self", ".", "densepose_datas", ".", "append", "(", "densepose_data_ondevice", ")", "\n", "", "self", ".", "boxes_xyxy_abs", "=", "boxes_xyxy_abs", ".", "to", "(", "device", ")", "\n", "self", ".", "image_size_hw", "=", "image_size_hw", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.list.DensePoseList.to": [[31, 35], ["list.DensePoseList"], "methods", ["None"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "if", "self", ".", "device", "==", "device", ":", "\n", "            ", "return", "self", "\n", "", "return", "DensePoseList", "(", "self", ".", "densepose_datas", ",", "self", ".", "boxes_xyxy_abs", ",", "self", ".", "image_size_hw", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.list.DensePoseList.__iter__": [[36, 38], ["iter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "densepose_datas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.list.DensePoseList.__len__": [[39, 41], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "densepose_datas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.list.DensePoseList.__repr__": [[42, 48], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "s", "+=", "\"num_instances={}, \"", ".", "format", "(", "len", "(", "self", ".", "densepose_datas", ")", ")", "\n", "s", "+=", "\"image_width={}, \"", ".", "format", "(", "self", ".", "image_size_hw", "[", "1", "]", ")", "\n", "s", "+=", "\"image_height={})\"", ".", "format", "(", "self", ".", "image_size_hw", "[", "0", "]", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.list.DensePoseList.__getitem__": [[49, 70], ["isinstance", "isinstance", "list.DensePoseList", "isinstance", "list.DensePoseList", "list.DensePoseList", "enumerate"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "densepose_data_rel", "=", "self", ".", "densepose_datas", "[", "item", "]", "\n", "return", "densepose_data_rel", "\n", "", "elif", "isinstance", "(", "item", ",", "slice", ")", ":", "\n", "            ", "densepose_datas_rel", "=", "self", ".", "densepose_datas", "[", "item", "]", "\n", "boxes_xyxy_abs", "=", "self", ".", "boxes_xyxy_abs", "[", "item", "]", "\n", "return", "DensePoseList", "(", "\n", "densepose_datas_rel", ",", "boxes_xyxy_abs", ",", "self", ".", "image_size_hw", ",", "self", ".", "device", "\n", ")", "\n", "", "elif", "isinstance", "(", "item", ",", "torch", ".", "Tensor", ")", "and", "(", "item", ".", "dtype", "==", "torch", ".", "bool", ")", ":", "\n", "            ", "densepose_datas_rel", "=", "[", "self", ".", "densepose_datas", "[", "i", "]", "for", "i", ",", "x", "in", "enumerate", "(", "item", ")", "if", "x", ">", "0", "]", "\n", "boxes_xyxy_abs", "=", "self", ".", "boxes_xyxy_abs", "[", "item", "]", "\n", "return", "DensePoseList", "(", "\n", "densepose_datas_rel", ",", "boxes_xyxy_abs", ",", "self", ".", "image_size_hw", ",", "self", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "densepose_datas_rel", "=", "[", "self", ".", "densepose_datas", "[", "i", "]", "for", "i", "in", "item", "]", "\n", "boxes_xyxy_abs", "=", "self", ".", "boxes_xyxy_abs", "[", "item", "]", "\n", "return", "DensePoseList", "(", "\n", "densepose_datas_rel", ",", "boxes_xyxy_abs", ",", "self", ".", "image_size_hw", ",", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.cse.DensePoseEmbeddingPredictorOutput.__len__": [[21, 26], ["cse.DensePoseEmbeddingPredictorOutput.coarse_segm.size"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.cse.DensePoseEmbeddingPredictorOutput.__getitem__": [[27, 44], ["isinstance", "cse.DensePoseEmbeddingPredictorOutput", "cse.DensePoseEmbeddingPredictorOutput", "cse.DensePoseEmbeddingPredictorOutput.coarse_segm[].unsqueeze", "cse.DensePoseEmbeddingPredictorOutput.embedding[].unsqueeze"], "methods", ["None"], ["\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_in", "=", "input_channels", "\n", "n_segm_chan", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_COARSE_SEGM_CHANNELS", "\n", "embed_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBED_SIZE", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "# coarse segmentation", "\n", "self", ".", "coarse_segm_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "n_segm_chan", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# embedding", "\n", "self", ".", "embed_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "embed_size", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "scale_factor", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UP_SCALE", "\n", "initialize_module_params", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.cse.DensePoseEmbeddingPredictorOutput.to": [[46, 53], ["cse.DensePoseEmbeddingPredictorOutput.coarse_segm.to", "cse.DensePoseEmbeddingPredictorOutput.embedding.to", "cse.DensePoseEmbeddingPredictorOutput"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart.DensePoseChartPredictorOutput.__len__": [[32, 37], ["chart.DensePoseChartPredictorOutput.coarse_segm.size"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart.DensePoseChartPredictorOutput.__getitem__": [[38, 60], ["isinstance", "chart.DensePoseChartPredictorOutput", "chart.DensePoseChartPredictorOutput", "chart.DensePoseChartPredictorOutput.coarse_segm[].unsqueeze", "chart.DensePoseChartPredictorOutput.fine_segm[].unsqueeze", "chart.DensePoseChartPredictorOutput.u[].unsqueeze", "chart.DensePoseChartPredictorOutput.v[].unsqueeze"], "methods", ["None"], ["\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_in", "=", "input_channels", "\n", "n_segm_chan", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_COARSE_SEGM_CHANNELS", "\n", "dim_out_patches", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_PATCHES", "+", "1", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "# coarse segmentation", "\n", "self", ".", "ann_index_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "n_segm_chan", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# fine segmentation", "\n", "self", ".", "index_uv_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# U", "\n", "self", ".", "u_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# V", "\n", "self", ".", "v_lowres", "=", "ConvTranspose2d", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart.DensePoseChartPredictorOutput.to": [[62, 71], ["chart.DensePoseChartPredictorOutput.coarse_segm.to", "chart.DensePoseChartPredictorOutput.fine_segm.to", "chart.DensePoseChartPredictorOutput.u.to", "chart.DensePoseChartPredictorOutput.v.to", "chart.DensePoseChartPredictorOutput"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], [")", "\n", "self", ".", "scale_factor", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UP_SCALE", "\n", "initialize_module_params", "(", "self", ")", "\n", "\n", "", "def", "interp2d", "(", "self", ",", "tensor_nchw", ":", "torch", ".", "Tensor", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResult.to": [[25, 32], ["chart_result.DensePoseChartResult.labels.to", "chart_result.DensePoseChartResult.uv.to", "chart_result.DensePoseChartResult"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "\"\"\"\n        Transfers all tensors to the given device\n        \"\"\"", "\n", "labels", "=", "self", ".", "labels", ".", "to", "(", "device", ")", "\n", "uv", "=", "self", ".", "uv", ".", "to", "(", "device", ")", "\n", "return", "DensePoseChartResult", "(", "labels", "=", "labels", ",", "uv", "=", "uv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultWithConfidences.to": [[55, 74], ["chart_result.DensePoseChartResultWithConfidences", "isinstance", "var.to", "chart_result.DensePoseChartResultWithConfidences.labels.to", "chart_result.DensePoseChartResultWithConfidences.uv.to", "chart_result.DensePoseChartResultWithConfidences.to.to_device_if_tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "\"\"\"\n        Transfers all tensors to the given device, except if their value is None\n        \"\"\"", "\n", "\n", "def", "to_device_if_tensor", "(", "var", ":", "Any", ")", ":", "\n", "            ", "if", "isinstance", "(", "var", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "return", "var", ".", "to", "(", "device", ")", "\n", "", "return", "var", "\n", "\n", "", "return", "DensePoseChartResultWithConfidences", "(", "\n", "labels", "=", "self", ".", "labels", ".", "to", "(", "device", ")", ",", "\n", "uv", "=", "self", ".", "uv", ".", "to", "(", "device", ")", ",", "\n", "sigma_1", "=", "to_device_if_tensor", "(", "self", ".", "sigma_1", ")", ",", "\n", "sigma_2", "=", "to_device_if_tensor", "(", "self", ".", "sigma_2", ")", ",", "\n", "kappa_u", "=", "to_device_if_tensor", "(", "self", ".", "kappa_u", ")", ",", "\n", "kappa_v", "=", "to_device_if_tensor", "(", "self", ".", "kappa_v", ")", ",", "\n", "fine_segm_confidence", "=", "to_device_if_tensor", "(", "self", ".", "fine_segm_confidence", ")", ",", "\n", "coarse_segm_confidence", "=", "to_device_if_tensor", "(", "self", ".", "coarse_segm_confidence", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to": [[95, 101], ["chart_result.DensePoseChartResultQuantized.labels_uv_uint8.to", "chart_result.DensePoseChartResultQuantized"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "\"\"\"\n        Transfers all tensors to the given device\n        \"\"\"", "\n", "labels_uv_uint8", "=", "self", ".", "labels_uv_uint8", ".", "to", "(", "device", ")", "\n", "return", "DensePoseChartResultQuantized", "(", "labels_uv_uint8", "=", "labels_uv_uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.quantize_densepose_chart_result": [[120, 134], ["torch.zeros", "chart_result.DensePoseChartResultQuantized"], "function", ["None"], ["", "def", "quantize_densepose_chart_result", "(", "result", ":", "DensePoseChartResult", ")", "->", "DensePoseChartResultQuantized", ":", "\n", "    ", "\"\"\"\n    Applies quantization to DensePose chart-based result.\n\n    Args:\n        result (DensePoseChartResult): DensePose chart-based result\n    Return:\n        Quantized DensePose chart-based result (DensePoseChartResultQuantized)\n    \"\"\"", "\n", "h", ",", "w", "=", "result", ".", "labels", ".", "shape", "\n", "labels_uv_uint8", "=", "torch", ".", "zeros", "(", "[", "3", ",", "h", ",", "w", "]", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "result", ".", "labels", ".", "device", ")", "\n", "labels_uv_uint8", "[", "0", "]", "=", "result", ".", "labels", "\n", "labels_uv_uint8", "[", "1", ":", "]", "=", "(", "result", ".", "uv", "*", "255", ")", ".", "clamp", "(", "0", ",", "255", ")", ".", "byte", "(", ")", "\n", "return", "DensePoseChartResultQuantized", "(", "labels_uv_uint8", "=", "labels_uv_uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.compress_quantized_densepose_chart_result": [[136, 160], ["result.labels_uv_uint8.cpu().numpy", "np.moveaxis", "Image.fromarray", "BytesIO", "Image.fromarray.save", "base64.encodebytes().decode", "chart_result.DensePoseChartResultCompressed", "result.labels_uv_uint8.cpu", "base64.encodebytes", "BytesIO.getvalue"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["", "def", "compress_quantized_densepose_chart_result", "(", "\n", "result", ":", "DensePoseChartResultQuantized", ",", "\n", ")", "->", "DensePoseChartResultCompressed", ":", "\n", "    ", "\"\"\"\n    Compresses quantized DensePose chart-based result\n\n    Args:\n        result (DensePoseChartResultQuantized): quantized DensePose chart-based result\n    Return:\n        Compressed DensePose chart-based result (DensePoseChartResultCompressed)\n    \"\"\"", "\n", "import", "base64", "\n", "import", "numpy", "as", "np", "\n", "from", "io", "import", "BytesIO", "\n", "from", "PIL", "import", "Image", "\n", "\n", "labels_uv_uint8_np_chw", "=", "result", ".", "labels_uv_uint8", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels_uv_uint8_np_hwc", "=", "np", ".", "moveaxis", "(", "labels_uv_uint8_np_chw", ",", "0", ",", "-", "1", ")", "\n", "im", "=", "Image", ".", "fromarray", "(", "labels_uv_uint8_np_hwc", ")", "\n", "fstream", "=", "BytesIO", "(", ")", "\n", "im", ".", "save", "(", "fstream", ",", "format", "=", "\"png\"", ",", "optimize", "=", "True", ")", "\n", "labels_uv_str", "=", "base64", ".", "encodebytes", "(", "fstream", ".", "getvalue", "(", ")", ")", ".", "decode", "(", ")", "\n", "shape_chw", "=", "labels_uv_uint8_np_chw", ".", "shape", "\n", "return", "DensePoseChartResultCompressed", "(", "labels_uv_str", "=", "labels_uv_str", ",", "shape_chw", "=", "shape_chw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.decompress_compressed_densepose_chart_result": [[162, 183], ["BytesIO", "Image.open", "np.moveaxis", "chart_result.DensePoseChartResultQuantized", "base64.decodebytes", "np.array", "result.labels_uv_str.encode", "torch.from_numpy", "np.moveaxis.reshape"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["", "def", "decompress_compressed_densepose_chart_result", "(", "\n", "result", ":", "DensePoseChartResultCompressed", ",", "\n", ")", "->", "DensePoseChartResultQuantized", ":", "\n", "    ", "\"\"\"\n    Decompresses DensePose chart-based result encoded into a base64 string\n\n    Args:\n        result (DensePoseChartResultCompressed): compressed DensePose chart result\n    Return:\n        Quantized DensePose chart-based result (DensePoseChartResultQuantized)\n    \"\"\"", "\n", "import", "base64", "\n", "import", "numpy", "as", "np", "\n", "from", "io", "import", "BytesIO", "\n", "from", "PIL", "import", "Image", "\n", "\n", "fstream", "=", "BytesIO", "(", "base64", ".", "decodebytes", "(", "result", ".", "labels_uv_str", ".", "encode", "(", ")", ")", ")", "\n", "im", "=", "Image", ".", "open", "(", "fstream", ")", "\n", "labels_uv_uint8_np_chw", "=", "np", ".", "moveaxis", "(", "np", ".", "array", "(", "im", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "-", "1", ",", "0", ")", "\n", "return", "DensePoseChartResultQuantized", "(", "\n", "labels_uv_uint8", "=", "torch", ".", "from_numpy", "(", "labels_uv_uint8_np_chw", ".", "reshape", "(", "result", ".", "shape_chw", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.cse_confidence.decorate_cse_predictor_output_class_with_confidences": [[9, 79], ["functools.lru_cache", "dataclasses.make_dataclass", "isinstance", "type", "super().__getitem__", "type.", "type", "super().to", "type.", "data[].unsqueeze", "isinstance", "cse_confidence.decorate_cse_predictor_output_class_with_confidences.slice_if_not_none"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__getitem__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["\n", "from", "densepose", ".", "modeling", ".", "confidence", "import", "DensePoseConfidenceModelConfig", "\n", "from", "densepose", ".", "modeling", ".", "utils", "import", "initialize_module_params", "\n", "from", "densepose", ".", "structures", "import", "decorate_cse_predictor_output_class_with_confidences", "\n", "\n", "\n", "class", "DensePoseEmbeddingConfidencePredictorMixin", ":", "\n", "    ", "\"\"\"\n    Predictor contains the last layers of a DensePose model that take DensePose head\n    outputs as an input and produce model outputs. Confidence predictor mixin is used\n    to generate confidences for coarse segmentation estimated by some\n    base predictor. Several assumptions need to hold for the base predictor:\n    1) the `forward` method must return CSE DensePose head outputs,\n        tensor of shape [N, D, H, W]\n    2) `interp2d` method must be defined to perform bilinear interpolation;\n        the same method is typically used for masks and confidences\n    Confidence predictor mixin provides confidence estimates, as described in:\n        N. Neverova et al., Correlated Uncertainty for Learning Dense Correspondences\n            from Noisy Labels, NeurIPS 2019\n        A. Sanakoyeu et al., Transferring Dense Pose to Proximal Animal Classes, CVPR 2020\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence predictor using configuration options.\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): number of input channels\n        \"\"\"", "\n", "# we rely on base predictor to call nn.Module.__init__", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "input_channels", ")", "# pyre-ignore[19]", "\n", "self", ".", "confidence_model_cfg", "=", "DensePoseConfidenceModelConfig", ".", "from_cfg", "(", "cfg", ")", "\n", "self", ".", "_initialize_confidence_estimation_layers", "(", "cfg", ",", "input_channels", ")", "\n", "self", ".", "_registry", "=", "{", "}", "\n", "initialize_module_params", "(", "self", ")", "# pyre-ignore[6]", "\n", "\n", "", "def", "_initialize_confidence_estimation_layers", "(", "self", ",", "cfg", ":", "CfgNode", ",", "dim_in", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence estimation layers based on configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n            dim_in (int): number of input channels\n        \"\"\"", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "            ", "self", ".", "coarse_segm_confidence_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "1", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "head_outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward operation on head outputs used as inputs for the predictor.\n        Calls forward method from the base predictor and uses its outputs to compute\n        confidences.\n\n        Args:\n            head_outputs (Tensor): head outputs used as predictor inputs\n        Return:\n            An instance of outputs with confidences,\n            see `decorate_cse_predictor_output_class_with_confidences`\n        \"\"\"", "\n", "# assuming base class returns SIUV estimates in its first result", "\n", "base_predictor_outputs", "=", "super", "(", ")", ".", "forward", "(", "head_outputs", ")", "# pyre-ignore[16]", "\n", "\n", "# create output instance by extending base predictor outputs:", "\n", "output", "=", "self", ".", "_create_output_instance", "(", "base_predictor_outputs", ")", "\n", "\n", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "# base predictor outputs are assumed to have `coarse_segm` attribute", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.paths_catalog.DatasetCatalog.get": [[113, 138], ["RuntimeError", "dict", "dict", "dict", "dict", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["}", ",", "\n", "##############################################", "\n", "\n", "\"cityscapes_poly_instance_train\"", ":", "{", "\n", "\"img_dir\"", ":", "\"cityscapes/leftImg8bit/\"", ",", "\n", "\"ann_dir\"", ":", "\"cityscapes/gtFine/\"", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "\"mode\"", ":", "\"poly\"", ",", "\n", "}", ",", "\n", "\"cityscapes_poly_instance_val\"", ":", "{", "\n", "\"img_dir\"", ":", "\"cityscapes/leftImg8bit\"", ",", "\n", "\"ann_dir\"", ":", "\"cityscapes/gtFine\"", ",", "\n", "\"split\"", ":", "\"val\"", ",", "\n", "\"mode\"", ":", "\"poly\"", ",", "\n", "}", ",", "\n", "\"cityscapes_poly_instance_minival\"", ":", "{", "\n", "\"img_dir\"", ":", "\"cityscapes/leftImg8bit\"", ",", "\n", "\"ann_dir\"", ":", "\"cityscapes/gtFine\"", ",", "\n", "\"split\"", ":", "\"val\"", ",", "\n", "\"mode\"", ":", "\"poly\"", ",", "\n", "\"mini\"", ":", "10", ",", "\n", "}", ",", "\n", "\"cityscapes_mask_instance_train\"", ":", "{", "\n", "\"img_dir\"", ":", "\"cityscapes/leftImg8bit/\"", ",", "\n", "\"ann_dir\"", ":", "\"cityscapes/gtFine/\"", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.paths_catalog.ModelCatalog.get": [[166, 173], ["name.startswith", "name.startswith", "RuntimeError", "paths_catalog.ModelCatalog.get_c2_detectron_12_2017_baselines", "paths_catalog.ModelCatalog.get_c2_imagenet_pretrained"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.paths_catalog.ModelCatalog.get_c2_detectron_12_2017_baselines", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.paths_catalog.ModelCatalog.get_c2_imagenet_pretrained"], ["factory", "=", "\"COCODataset\"", ",", "\n", "args", "=", "args", ",", "\n", ")", "\n", "", "elif", "\"voc\"", "in", "name", ":", "\n", "            ", "data_dir", "=", "DatasetCatalog", ".", "DATA_DIR", "\n", "attrs", "=", "DatasetCatalog", ".", "DATASETS", "[", "name", "]", "\n", "args", "=", "dict", "(", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "attrs", "[", "\"data_dir\"", "]", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.paths_catalog.ModelCatalog.get_c2_imagenet_pretrained": [[174, 181], ["len"], "methods", ["None"], ["split", "=", "attrs", "[", "\"split\"", "]", ",", "\n", ")", "\n", "return", "dict", "(", "\n", "factory", "=", "\"PascalVOCDataset\"", ",", "\n", "args", "=", "args", ",", "\n", ")", "\n", "", "elif", "\"cityscapes\"", "in", "name", ":", "\n", "            ", "data_dir", "=", "DatasetCatalog", ".", "DATA_DIR", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.paths_catalog.ModelCatalog.get_c2_detectron_12_2017_baselines": [[182, 200], ["ModelCatalog.C2_DETECTRON_SUFFIX.format", "name.split", "len"], "methods", ["None"], ["attrs", "=", "deepcopy", "(", "DatasetCatalog", ".", "DATASETS", "[", "name", "]", ")", "\n", "attrs", "[", "\"img_dir\"", "]", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "attrs", "[", "\"img_dir\"", "]", ")", "\n", "attrs", "[", "\"ann_dir\"", "]", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "attrs", "[", "\"ann_dir\"", "]", ")", "\n", "return", "dict", "(", "factory", "=", "\"CityScapesDataset\"", ",", "args", "=", "attrs", ")", "\n", "", "raise", "RuntimeError", "(", "\"Dataset not available: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "\n", "", "", "class", "ModelCatalog", "(", "object", ")", ":", "\n", "    ", "S3_C2_DETECTRON_URL", "=", "\"https://dl.fbaipublicfiles.com/detectron\"", "\n", "C2_IMAGENET_MODELS", "=", "{", "\n", "\"MSRA/R-50\"", ":", "\"ImageNetPretrained/MSRA/R-50.pkl\"", ",", "\n", "\"MSRA/R-50-GN\"", ":", "\"ImageNetPretrained/47261647/R-50-GN.pkl\"", ",", "\n", "\"MSRA/R-101\"", ":", "\"ImageNetPretrained/MSRA/R-101.pkl\"", ",", "\n", "\"MSRA/R-101-GN\"", ":", "\"ImageNetPretrained/47592356/R-101-GN.pkl\"", ",", "\n", "\"FAIR/20171220/X-101-32x8d\"", ":", "\"ImageNetPretrained/20171220/X-101-32x8d.pkl\"", ",", "\n", "}", "\n", "\n", "C2_DETECTRON_SUFFIX", "=", "\"output/train/{}coco_2014_train%3A{}coco_2014_valminusminival/generalized_rcnn/model_final.pkl\"", "\n", "C2_DETECTRON_MODELS", "=", "{", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode._open_cfg": [[24, 27], ["detectron2.utils.file_io.PathManager.open"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file": [[29, 71], ["detectron2.utils.file_io.PathManager.isfile", "config.CfgNode.load_yaml_with_base", "logging.getLogger", "config.CfgNode.get", "type", "guess_version", "config.CfgNode.merge_from_other_cfg", "logging.getLogger.warning", "downgrade_config", "downgrade_config.merge_from_other_cfg", "upgrade_config", "config.CfgNode.clear", "config.CfgNode.update"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.guess_version", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.downgrade_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.upgrade_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n", "if", "loaded_ver", "is", "None", ":", "\n", "            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n", "loaded_ver", ",", "self", ".", "VERSION", "\n", ")", "\n", "\n", "if", "loaded_ver", "==", "self", ".", "VERSION", ":", "\n", "            ", "self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "", "else", ":", "\n", "# compat.py needs to import CfgNode", "\n", "            ", "from", ".", "compat", "import", "upgrade_config", ",", "downgrade_config", "\n", "\n", "logger", ".", "warning", "(", "\n", "\"Loading an old v{} config file '{}' by automatically upgrading to v{}. \"", "\n", "\"See docs/CHANGELOG.md for instructions to update your files.\"", ".", "format", "(", "\n", "loaded_ver", ",", "cfg_filename", ",", "self", ".", "VERSION", "\n", ")", "\n", ")", "\n", "# To convert, first obtain a full config at an old version", "\n", "old_self", "=", "downgrade_config", "(", "self", ",", "to_version", "=", "loaded_ver", ")", "\n", "old_self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "new_config", "=", "upgrade_config", "(", "old_self", ")", "\n", "self", ".", "clear", "(", ")", "\n", "self", ".", "update", "(", "new_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump": [[72, 79], ["super().dump"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["", "", "def", "dump", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            str: a yaml string representation of the config\n        \"\"\"", "\n", "# to make it show up in docs", "\n", "return", "super", "(", ")", ".", "dump", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg": [[84, 94], ["_C.clone"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["def", "get_cfg", "(", ")", "->", "CfgNode", ":", "\n", "    ", "\"\"\"\n    Get a copy of the default config.\n\n    Returns:\n        a detectron2 CfgNode instance.\n    \"\"\"", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "return", "_C", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.set_global_cfg": [[96, 113], ["global_cfg.clear", "global_cfg.update"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "def", "set_global_cfg", "(", "cfg", ":", "CfgNode", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Let the global config point to the given cfg.\n\n    Assume that the given \"cfg\" has the key \"KEY\", after calling\n    `set_global_cfg(cfg)`, the key can be accessed by:\n    ::\n        from detectron2.config import global_cfg\n        print(global_cfg.KEY)\n\n    By using a hacky global config, you can access these configs anywhere,\n    without having to pass the config object or the values deep into the code.\n    This is a hacky feature introduced for quick prototyping / research exploration.\n    \"\"\"", "\n", "global", "global_cfg", "\n", "global_cfg", ".", "clear", "(", ")", "\n", "global_cfg", ".", "update", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.configurable": [[115, 200], ["functools.wraps", "inspect.isfunction", "inspect.isfunction", "config._called_with_cfg", "functools.wraps", "inspect.ismethod", "TypeError", "config._get_args_from_config", "init_func", "init_func", "config._called_with_cfg", "type", "AttributeError", "config._get_args_from_config", "orig_func", "orig_func"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config._called_with_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config._get_args_from_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config._called_with_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config._get_args_from_config"], ["", "def", "configurable", "(", "init_func", "=", "None", ",", "*", ",", "from_config", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Decorate a function or a class's __init__ method so that it can be called\n    with a :class:`CfgNode` object using a :func:`from_config` function that translates\n    :class:`CfgNode` to arguments.\n\n    Examples:\n    ::\n        # Usage 1: Decorator on __init__:\n        class A:\n            @configurable\n            def __init__(self, a, b=2, c=3):\n                pass\n\n            @classmethod\n            def from_config(cls, cfg):   # 'cfg' must be the first argument\n                # Returns kwargs to be passed to __init__\n                return {\"a\": cfg.A, \"b\": cfg.B}\n\n        a1 = A(a=1, b=2)  # regular construction\n        a2 = A(cfg)       # construct with a cfg\n        a3 = A(cfg, b=3, c=4)  # construct with extra overwrite\n\n        # Usage 2: Decorator on any function. Needs an extra from_config argument:\n        @configurable(from_config=lambda cfg: {\"a: cfg.A, \"b\": cfg.B})\n        def a_func(a, b=2, c=3):\n            pass\n\n        a1 = a_func(a=1, b=2)  # regular call\n        a2 = a_func(cfg)       # call with a cfg\n        a3 = a_func(cfg, b=3, c=4)  # call with extra overwrite\n\n    Args:\n        init_func (callable): a class's ``__init__`` method in usage 1. The\n            class must have a ``from_config`` classmethod which takes `cfg` as\n            the first argument.\n        from_config (callable): the from_config function in usage 2. It must take `cfg`\n            as its first argument.\n    \"\"\"", "\n", "\n", "if", "init_func", "is", "not", "None", ":", "\n", "        ", "assert", "(", "\n", "inspect", ".", "isfunction", "(", "init_func", ")", "\n", "and", "from_config", "is", "None", "\n", "and", "init_func", ".", "__name__", "==", "\"__init__\"", "\n", ")", ",", "\"Incorrect use of @configurable. Check API documentation for examples.\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "init_func", ")", "\n", "def", "wrapped", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "from_config_func", "=", "type", "(", "self", ")", ".", "from_config", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "                ", "raise", "AttributeError", "(", "\n", "\"Class with @configurable must have a 'from_config' classmethod.\"", "\n", ")", "from", "e", "\n", "", "if", "not", "inspect", ".", "ismethod", "(", "from_config_func", ")", ":", "\n", "                ", "raise", "TypeError", "(", "\"Class with @configurable must have a 'from_config' classmethod.\"", ")", "\n", "\n", "", "if", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "explicit_args", "=", "_get_args_from_config", "(", "from_config_func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "init_func", "(", "self", ",", "**", "explicit_args", ")", "\n", "", "else", ":", "\n", "                ", "init_func", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapped", "\n", "\n", "", "else", ":", "\n", "        ", "if", "from_config", "is", "None", ":", "\n", "            ", "return", "configurable", "# @configurable() is made equivalent to @configurable", "\n", "", "assert", "inspect", ".", "isfunction", "(", "\n", "from_config", "\n", ")", ",", "\"from_config argument of configurable must be a function!\"", "\n", "\n", "def", "wrapper", "(", "orig_func", ")", ":", "\n", "            ", "@", "functools", ".", "wraps", "(", "orig_func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "if", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                    ", "explicit_args", "=", "_get_args_from_config", "(", "from_config", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "orig_func", "(", "**", "explicit_args", ")", "\n", "", "else", ":", "\n", "                    ", "return", "orig_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapped", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config._get_args_from_config": [[202, 233], ["inspect.signature", "any", "inspect.isfunction", "TypeError", "from_config_func", "set", "list", "from_config_func", "from_config_func.update", "list", "inspect.signature.parameters.keys", "kwargs.keys", "inspect.signature.parameters.keys", "inspect.signature.parameters.values", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "", "def", "_get_args_from_config", "(", "from_config_func", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Use `from_config` to obtain explicit arguments.\n\n    Returns:\n        dict: arguments to be used for cls.__init__\n    \"\"\"", "\n", "signature", "=", "inspect", ".", "signature", "(", "from_config_func", ")", "\n", "if", "list", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "[", "0", "]", "!=", "\"cfg\"", ":", "\n", "        ", "if", "inspect", ".", "isfunction", "(", "from_config_func", ")", ":", "\n", "            ", "name", "=", "from_config_func", ".", "__name__", "\n", "", "else", ":", "\n", "            ", "name", "=", "f\"{from_config_func.__self__}.from_config\"", "\n", "", "raise", "TypeError", "(", "f\"{name} must take 'cfg' as the first argument!\"", ")", "\n", "", "support_var_arg", "=", "any", "(", "\n", "param", ".", "kind", "in", "[", "param", ".", "VAR_POSITIONAL", ",", "param", ".", "VAR_KEYWORD", "]", "\n", "for", "param", "in", "signature", ".", "parameters", ".", "values", "(", ")", "\n", ")", "\n", "if", "support_var_arg", ":", "# forward all arguments to from_config, if from_config accepts them", "\n", "        ", "ret", "=", "from_config_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# forward supported arguments to from_config", "\n", "        ", "supported_arg_names", "=", "set", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "\n", "extra_kwargs", "=", "{", "}", "\n", "for", "name", "in", "list", "(", "kwargs", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "name", "not", "in", "supported_arg_names", ":", "\n", "                ", "extra_kwargs", "[", "name", "]", "=", "kwargs", ".", "pop", "(", "name", ")", "\n", "", "", "ret", "=", "from_config_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# forward the other arguments to __init__", "\n", "ret", ".", "update", "(", "extra_kwargs", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config._called_with_cfg": [[235, 250], ["isinstance", "len", "isinstance", "kwargs.pop"], "function", ["None"], ["", "def", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        bool: whether the arguments contain CfgNode and should be considered\n            forwarded to from_config.\n    \"\"\"", "\n", "from", "omegaconf", "import", "DictConfig", "\n", "\n", "if", "len", "(", "args", ")", "and", "isinstance", "(", "args", "[", "0", "]", ",", "(", "_CfgNode", ",", "DictConfig", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "if", "isinstance", "(", "kwargs", ".", "pop", "(", "\"cfg\"", ",", "None", ")", ",", "(", "_CfgNode", ",", "DictConfig", ")", ")", ":", "\n", "        ", "return", "True", "\n", "# `from_config`'s first argument is forced to be \"cfg\".", "\n", "# So the above check covers all cases.", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.LazyCall.__init__": [[101, 107], ["TypeError", "callable", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "target", ")", ":", "\n", "        ", "if", "not", "(", "callable", "(", "target", ")", "or", "isinstance", "(", "target", ",", "(", "str", ",", "abc", ".", "Mapping", ")", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"target of LazyCall must be a callable or defines a callable! Got {target}\"", "\n", ")", "\n", "", "self", ".", "_target", "=", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.LazyCall.__call__": [[108, 111], ["omegaconf.DictConfig"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", "[", "\"_target_\"", "]", "=", "self", ".", "_target", "\n", "return", "DictConfig", "(", "content", "=", "kwargs", ",", "flags", "=", "{", "\"allow_objects\"", ":", "True", "}", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.dump_dataclass": [[13, 35], ["dataclasses.fields", "dataclasses.is_dataclass", "detectron2.utils.registry._convert_target_to_string", "getattr", "dataclasses.is_dataclass", "isinstance", "isinstance", "type", "instantiate.dump_dataclass", "dataclasses.is_dataclass", "instantiate.dump_dataclass"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry._convert_target_to_string", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.dump_dataclass", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.dump_dataclass"], ["def", "dump_dataclass", "(", "obj", ":", "Any", ")", ":", "\n", "    ", "\"\"\"\n    Dump a dataclass recursively into a dict that can be later instantiated.\n\n    Args:\n        obj: a dataclass object\n\n    Returns:\n        dict\n    \"\"\"", "\n", "assert", "dataclasses", ".", "is_dataclass", "(", "obj", ")", "and", "not", "isinstance", "(", "\n", "obj", ",", "type", "\n", ")", ",", "\"dump_dataclass() requires an instance of a dataclass.\"", "\n", "ret", "=", "{", "\"_target_\"", ":", "_convert_target_to_string", "(", "type", "(", "obj", ")", ")", "}", "\n", "for", "f", "in", "dataclasses", ".", "fields", "(", "obj", ")", ":", "\n", "        ", "v", "=", "getattr", "(", "obj", ",", "f", ".", "name", ")", "\n", "if", "dataclasses", ".", "is_dataclass", "(", "v", ")", ":", "\n", "            ", "v", "=", "dump_dataclass", "(", "v", ")", "\n", "", "if", "isinstance", "(", "v", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "v", "=", "[", "dump_dataclass", "(", "x", ")", "if", "dataclasses", ".", "is_dataclass", "(", "x", ")", "else", "x", "for", "x", "in", "v", "]", "\n", "", "ret", "[", "f", ".", "name", "]", "=", "v", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.instantiate": [[37, 84], ["isinstance", "isinstance", "ListConfig", "isinstance", "cfg.pop", "instantiate.instantiate", "isinstance", "callable", "instantiate.instantiate", "instantiate.instantiate", "instantiate.instantiate", "detectron2.utils.registry.locate", "detectron2.utils.registry.locate.", "cfg.items", "logging.getLogger", "logging.getLogger.error", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.instantiate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.instantiate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.instantiate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.instantiate.instantiate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry.locate"], ["", "def", "instantiate", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Recursively instantiate objects defined in dictionaries by\n    \"_target_\" and arguments.\n\n    Args:\n        cfg: a dict-like object with \"_target_\" that defines the caller, and\n            other keys that define the arguments\n\n    Returns:\n        object instantiated by cfg\n    \"\"\"", "\n", "from", "omegaconf", "import", "ListConfig", "\n", "\n", "if", "isinstance", "(", "cfg", ",", "ListConfig", ")", ":", "\n", "        ", "lst", "=", "[", "instantiate", "(", "x", ")", "for", "x", "in", "cfg", "]", "\n", "return", "ListConfig", "(", "lst", ",", "flags", "=", "{", "\"allow_objects\"", ":", "True", "}", ")", "\n", "", "if", "isinstance", "(", "cfg", ",", "list", ")", ":", "\n", "# Specialize for list, because many classes take", "\n", "# list[objects] as arguments, such as ResNet, DatasetMapper", "\n", "        ", "return", "[", "instantiate", "(", "x", ")", "for", "x", "in", "cfg", "]", "\n", "\n", "", "if", "isinstance", "(", "cfg", ",", "abc", ".", "Mapping", ")", "and", "\"_target_\"", "in", "cfg", ":", "\n", "# conceptually equivalent to hydra.utils.instantiate(cfg) with _convert_=all,", "\n", "# but faster: https://github.com/facebookresearch/hydra/issues/1200", "\n", "        ", "cfg", "=", "{", "k", ":", "instantiate", "(", "v", ")", "for", "k", ",", "v", "in", "cfg", ".", "items", "(", ")", "}", "\n", "cls", "=", "cfg", ".", "pop", "(", "\"_target_\"", ")", "\n", "cls", "=", "instantiate", "(", "cls", ")", "\n", "\n", "if", "isinstance", "(", "cls", ",", "str", ")", ":", "\n", "            ", "cls_name", "=", "cls", "\n", "cls", "=", "locate", "(", "cls_name", ")", "\n", "assert", "cls", "is", "not", "None", ",", "cls_name", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "cls_name", "=", "cls", ".", "__module__", "+", "\".\"", "+", "cls", ".", "__qualname__", "\n", "", "except", "AttributeError", ":", "\n", "# target could be anything, so the above could fail", "\n", "                ", "cls_name", "=", "str", "(", "cls", ")", "\n", "", "", "assert", "callable", "(", "cls", ")", ",", "f\"_target_ {cls} does not define a callable object\"", "\n", "try", ":", "\n", "            ", "return", "cls", "(", "**", "cfg", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "error", "(", "f\"Error when instantiating {cls_name}!\"", ")", "\n", "raise", "\n", "", "", "return", "cfg", "# return as-is if don't know what to do", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._RenameConverter.upgrade": [[153, 157], ["compat._rename"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename"], ["@", "classmethod", "\n", "def", "upgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "for", "old", ",", "new", "in", "cls", ".", "RENAME", ":", "\n", "            ", "_rename", "(", "cfg", ",", "old", ",", "new", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._RenameConverter.downgrade": [[158, 162], ["compat._rename"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename"], ["", "", "@", "classmethod", "\n", "def", "downgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "for", "old", ",", "new", "in", "cls", ".", "RENAME", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "_rename", "(", "cfg", ",", "new", ",", "old", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.ConverterV2.upgrade": [[203, 220], ["compat._RenameConverter.upgrade", "compat._rename", "compat._rename", "compat._rename", "compat._rename"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.ConverterV2.upgrade", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename"], ["@", "classmethod", "\n", "def", "upgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "upgrade", "(", "cfg", ")", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "==", "\"RetinaNet\"", ":", "\n", "            ", "_rename", "(", "\n", "cfg", ",", "\"MODEL.RETINANET.ANCHOR_ASPECT_RATIOS\"", ",", "\"MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS\"", "\n", ")", "\n", "_rename", "(", "cfg", ",", "\"MODEL.RETINANET.ANCHOR_SIZES\"", ",", "\"MODEL.ANCHOR_GENERATOR.SIZES\"", ")", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RPN\"", "]", "[", "\"ANCHOR_SIZES\"", "]", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RPN\"", "]", "[", "\"ANCHOR_ASPECT_RATIOS\"", "]", "\n", "", "else", ":", "\n", "            ", "_rename", "(", "cfg", ",", "\"MODEL.RPN.ANCHOR_ASPECT_RATIOS\"", ",", "\"MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS\"", ")", "\n", "_rename", "(", "cfg", ",", "\"MODEL.RPN.ANCHOR_SIZES\"", ",", "\"MODEL.ANCHOR_GENERATOR.SIZES\"", ")", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RETINANET\"", "]", "[", "\"ANCHOR_SIZES\"", "]", "\n", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RETINANET\"", "]", "[", "\"ANCHOR_ASPECT_RATIOS\"", "]", "\n", "", "del", "cfg", "[", "\"MODEL\"", "]", "[", "\"RETINANET\"", "]", "[", "\"ANCHOR_STRIDES\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.ConverterV2.downgrade": [[221, 230], ["compat._RenameConverter.downgrade", "compat._rename", "compat._rename"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.ConverterV2.downgrade", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename"], ["", "@", "classmethod", "\n", "def", "downgrade", "(", "cls", ",", "cfg", ":", "CN", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "downgrade", "(", "cfg", ")", "\n", "\n", "_rename", "(", "cfg", ",", "\"MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS\"", ",", "\"MODEL.RPN.ANCHOR_ASPECT_RATIOS\"", ")", "\n", "_rename", "(", "cfg", ",", "\"MODEL.ANCHOR_GENERATOR.SIZES\"", ",", "\"MODEL.RPN.ANCHOR_SIZES\"", ")", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_ASPECT_RATIOS", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "ANCHOR_ASPECT_RATIOS", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_SIZES", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "ANCHOR_SIZES", "\n", "cfg", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_STRIDES", "=", "[", "]", "# this is not used anywhere in any version", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.upgrade_config": [[33, 53], ["cfg.clone.clone", "range", "converter.upgrade", "globals", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.ConverterV2.upgrade"], ["def", "upgrade_config", "(", "cfg", ":", "CN", ",", "to_version", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "CN", ":", "\n", "    ", "\"\"\"\n    Upgrade a config from its current version to a newer version.\n\n    Args:\n        cfg (CfgNode):\n        to_version (int): defaults to the latest version.\n    \"\"\"", "\n", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "if", "to_version", "is", "None", ":", "\n", "        ", "to_version", "=", "_C", ".", "VERSION", "\n", "\n", "", "assert", "cfg", ".", "VERSION", "<=", "to_version", ",", "\"Cannot upgrade from v{} to v{}!\"", ".", "format", "(", "\n", "cfg", ".", "VERSION", ",", "to_version", "\n", ")", "\n", "for", "k", "in", "range", "(", "cfg", ".", "VERSION", ",", "to_version", ")", ":", "\n", "        ", "converter", "=", "globals", "(", ")", "[", "\"ConverterV\"", "+", "str", "(", "k", "+", "1", ")", "]", "\n", "converter", ".", "upgrade", "(", "cfg", ")", "\n", "cfg", ".", "VERSION", "=", "k", "+", "1", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.downgrade_config": [[55, 80], ["cfg.clone.clone", "range", "converter.downgrade", "globals", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.ConverterV2.downgrade"], ["", "def", "downgrade_config", "(", "cfg", ":", "CN", ",", "to_version", ":", "int", ")", "->", "CN", ":", "\n", "    ", "\"\"\"\n    Downgrade a config from its current version to an older version.\n\n    Args:\n        cfg (CfgNode):\n        to_version (int):\n\n    Note:\n        A general downgrade of arbitrary configs is not always possible due to the\n        different functionalities in different versions.\n        The purpose of downgrade is only to recover the defaults in old versions,\n        allowing it to load an old partial yaml config.\n        Therefore, the implementation only needs to fill in the default values\n        in the old version when a general downgrade is not possible.\n    \"\"\"", "\n", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "assert", "cfg", ".", "VERSION", ">=", "to_version", ",", "\"Cannot downgrade from v{} to v{}!\"", ".", "format", "(", "\n", "cfg", ".", "VERSION", ",", "to_version", "\n", ")", "\n", "for", "k", "in", "range", "(", "cfg", ".", "VERSION", ",", "to_version", ",", "-", "1", ")", ":", "\n", "        ", "converter", "=", "globals", "(", ")", "[", "\"ConverterV\"", "+", "str", "(", "k", ")", "]", "\n", "converter", ".", "downgrade", "(", "cfg", ")", "\n", "cfg", ".", "VERSION", "=", "k", "-", "1", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat.guess_version": [[82, 114], ["logging.getLogger", "name.split", "compat.guess_version._has"], "function", ["None"], ["", "def", "guess_version", "(", "cfg", ":", "CN", ",", "filename", ":", "str", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Guess the version of a partial config where the VERSION field is not specified.\n    Returns the version, or the latest if cannot make a guess.\n\n    This makes it easier for users to migrate.\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "def", "_has", "(", "name", ":", "str", ")", "->", "bool", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "n", "in", "name", ".", "split", "(", "\".\"", ")", ":", "\n", "            ", "if", "n", "not", "in", "cur", ":", "\n", "                ", "return", "False", "\n", "", "cur", "=", "cur", "[", "n", "]", "\n", "", "return", "True", "\n", "\n", "# Most users' partial configs have \"MODEL.WEIGHT\", so guess on it", "\n", "", "ret", "=", "None", "\n", "if", "_has", "(", "\"MODEL.WEIGHT\"", ")", "or", "_has", "(", "\"TEST.AUG_ON\"", ")", ":", "\n", "        ", "ret", "=", "1", "\n", "\n", "", "if", "ret", "is", "not", "None", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Config '{}' has no VERSION. Assuming it to be v{}.\"", ".", "format", "(", "filename", ",", "ret", ")", ")", "\n", "", "else", ":", "\n", "        ", "ret", "=", "_C", ".", "VERSION", "\n", "logger", ".", "warning", "(", "\n", "\"Config '{}' has no VERSION. Assuming it to be compatible with latest v{}.\"", ".", "format", "(", "\n", "filename", ",", "ret", "\n", ")", "\n", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.compat._rename": [[116, 144], ["old.split", "new.split", "compat._rename._set"], "function", ["None"], ["", "def", "_rename", "(", "cfg", ":", "CN", ",", "old", ":", "str", ",", "new", ":", "str", ")", "->", "None", ":", "\n", "    ", "old_keys", "=", "old", ".", "split", "(", "\".\"", ")", "\n", "new_keys", "=", "new", ".", "split", "(", "\".\"", ")", "\n", "\n", "def", "_set", "(", "key_seq", ":", "List", "[", "str", "]", ",", "val", ":", "str", ")", "->", "None", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "k", "in", "key_seq", "[", ":", "-", "1", "]", ":", "\n", "            ", "if", "k", "not", "in", "cur", ":", "\n", "                ", "cur", "[", "k", "]", "=", "CN", "(", ")", "\n", "", "cur", "=", "cur", "[", "k", "]", "\n", "", "cur", "[", "key_seq", "[", "-", "1", "]", "]", "=", "val", "\n", "\n", "", "def", "_get", "(", "key_seq", ":", "List", "[", "str", "]", ")", "->", "CN", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "k", "in", "key_seq", ":", "\n", "            ", "cur", "=", "cur", "[", "k", "]", "\n", "", "return", "cur", "\n", "\n", "", "def", "_del", "(", "key_seq", ":", "List", "[", "str", "]", ")", "->", "None", ":", "\n", "        ", "cur", "=", "cfg", "\n", "for", "k", "in", "key_seq", "[", ":", "-", "1", "]", ":", "\n", "            ", "cur", "=", "cur", "[", "k", "]", "\n", "", "del", "cur", "[", "key_seq", "[", "-", "1", "]", "]", "\n", "if", "len", "(", "cur", ")", "==", "0", "and", "len", "(", "key_seq", ")", ">", "1", ":", "\n", "            ", "_del", "(", "key_seq", "[", ":", "-", "1", "]", ")", "\n", "\n", "", "", "_set", "(", "new_keys", ",", "_get", "(", "old_keys", ")", ")", "\n", "_del", "(", "old_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers._utils._load_C_extensions": [[14, 36], ["os.path.dirname", "os.path.dirname", "os.path.join", "glob.glob", "glob.glob", "glob.glob", "load_ext", "os.path.abspath", "os.path.join", "os.path.join", "os.path.join", "torch.cuda.is_available", "source.extend", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "_load_C_extensions", "(", ")", ":", "\n", "    ", "this_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "this_dir", "=", "os", ".", "path", ".", "dirname", "(", "this_dir", ")", "\n", "this_dir", "=", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"csrc\"", ")", "\n", "\n", "main_file", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"*.cpp\"", ")", ")", "\n", "source_cpu", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"cpu\"", ",", "\"*.cpp\"", ")", ")", "\n", "source_cuda", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"cuda\"", ",", "\"*.cu\"", ")", ")", "\n", "\n", "source", "=", "main_file", "+", "source_cpu", "\n", "\n", "extra_cflags", "=", "[", "]", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "CUDA_HOME", "is", "not", "None", ":", "\n", "        ", "source", ".", "extend", "(", "source_cuda", ")", "\n", "extra_cflags", "=", "[", "\"-DWITH_CUDA\"", "]", "\n", "", "source", "=", "[", "os", ".", "path", ".", "join", "(", "this_dir", ",", "s", ")", "for", "s", "in", "source", "]", "\n", "extra_include_paths", "=", "[", "this_dir", "]", "\n", "return", "load_ext", "(", "\n", "\"torchvision\"", ",", "\n", "source", ",", "\n", "extra_cflags", "=", "extra_cflags", ",", "\n", "extra_include_paths", "=", "extra_include_paths", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.sigmoid_focal_loss._SigmoidFocalLoss.forward": [[10, 22], ["ctx.save_for_backward", "fcos_core._C.sigmoid_focalloss_forward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "logits", ",", "targets", ",", "gamma", ",", "alpha", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "logits", ",", "targets", ")", "\n", "num_classes", "=", "logits", ".", "shape", "[", "1", "]", "\n", "ctx", ".", "num_classes", "=", "num_classes", "\n", "ctx", ".", "gamma", "=", "gamma", "\n", "ctx", ".", "alpha", "=", "alpha", "\n", "\n", "losses", "=", "_C", ".", "sigmoid_focalloss_forward", "(", "\n", "logits", ",", "targets", ",", "num_classes", ",", "gamma", ",", "alpha", "\n", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.sigmoid_focal_loss._SigmoidFocalLoss.backward": [[23, 35], ["d_loss.contiguous.contiguous.contiguous", "fcos_core._C.sigmoid_focalloss_backward"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "d_loss", ")", ":", "\n", "        ", "logits", ",", "targets", "=", "ctx", ".", "saved_tensors", "\n", "num_classes", "=", "ctx", ".", "num_classes", "\n", "gamma", "=", "ctx", ".", "gamma", "\n", "alpha", "=", "ctx", ".", "alpha", "\n", "d_loss", "=", "d_loss", ".", "contiguous", "(", ")", "\n", "d_logits", "=", "_C", ".", "sigmoid_focalloss_backward", "(", "\n", "logits", ",", "targets", ",", "d_loss", ",", "num_classes", ",", "gamma", ",", "alpha", "\n", ")", "\n", "return", "d_logits", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.sigmoid_focal_loss.SigmoidFocalLoss.__init__": [[56, 60], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "return_loss_vec", "=", "False", ")", ":", "\n", "        ", "device", "=", "logits", ".", "device", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.sigmoid_focal_loss.SigmoidFocalLoss.forward": [[61, 70], ["loss_func", "loss_func.sum"], "methods", ["None"], ["if", "logits", ".", "is_cuda", ":", "\n", "            ", "loss_func", "=", "sigmoid_focal_loss_cuda", "\n", "", "else", ":", "\n", "            ", "loss_func", "=", "sigmoid_focal_loss_cpu", "\n", "\n", "", "loss", "=", "loss_func", "(", "logits", ",", "targets", ",", "self", ".", "gamma", ",", "self", ".", "alpha", ")", "\n", "if", "return_loss_vec", ":", "\n", "            ", "return", "loss", ".", "sum", "(", ")", ",", "loss", "\n", "\n", "", "return", "loss", ".", "sum", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.sigmoid_focal_loss.SigmoidFocalLoss.__repr__": [[71, 77], ["str", "str"], "methods", ["None"], ["\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"gamma=\"", "+", "str", "(", "self", ".", "gamma", ")", "\n", "tmpstr", "+=", "\", alpha=\"", "+", "str", "(", "self", ".", "alpha", ")", "\n", "tmpstr", "+=", "\")\"", "\n", "return", "tmpstr", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.sigmoid_focal_loss.sigmoid_focal_loss_cpu": [[40, 53], ["torch.arange().unsqueeze", "targets.unsqueeze", "torch.sigmoid", "torch.log", "torch.log", "torch.arange"], "function", ["None"], ["def", "sigmoid_focal_loss_cpu", "(", "logits", ",", "targets", ",", "gamma", ",", "alpha", ")", ":", "\n", "    ", "num_classes", "=", "logits", ".", "shape", "[", "1", "]", "\n", "dtype", "=", "targets", ".", "dtype", "\n", "device", "=", "targets", ".", "device", "\n", "class_range", "=", "torch", ".", "arange", "(", "1", ",", "num_classes", "+", "1", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "t", "=", "targets", ".", "unsqueeze", "(", "1", ")", "\n", "p", "=", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "term1", "=", "(", "1", "-", "p", ")", "**", "gamma", "*", "torch", ".", "log", "(", "p", ")", "\n", "term2", "=", "p", "**", "gamma", "*", "torch", ".", "log", "(", "1", "-", "p", ")", "\n", "return", "-", "(", "t", "==", "class_range", ")", ".", "float", "(", ")", "*", "term1", "*", "alpha", "-", "(", "(", "t", "!=", "class_range", ")", "*", "(", "t", ">=", "0", ")", ")", ".", "float", "(", ")", "*", "term2", "*", "(", "1", "-", "alpha", ")", "\n", "\n", "\n", "", "class", "SigmoidFocalLoss", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.scale.Scale.__init__": [[6, 9], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_value", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "Scale", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "[", "init_value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.scale.Scale.forward": [[10, 12], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_pool._ROIPool.forward": [[12, 22], ["torch.nn.modules.utils._pair", "input.size", "fcos_core._C.roi_pool_forward", "ctx.save_for_backward"], "methods", ["None"], ["class", "_ROIPool", "(", "Function", ")", ":", "\n", "    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "roi", ",", "output_size", ",", "spatial_scale", ")", ":", "\n", "        ", "ctx", ".", "output_size", "=", "_pair", "(", "output_size", ")", "\n", "ctx", ".", "spatial_scale", "=", "spatial_scale", "\n", "ctx", ".", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "output", ",", "argmax", "=", "_C", ".", "roi_pool_forward", "(", "\n", "input", ",", "roi", ",", "spatial_scale", ",", "output_size", "[", "0", "]", ",", "output_size", "[", "1", "]", "\n", ")", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "roi", ",", "argmax", ")", "\n", "return", "output", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_pool._ROIPool.backward": [[23, 44], ["fcos_core._C.roi_pool_backward"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "rois", ",", "argmax", "=", "ctx", ".", "saved_tensors", "\n", "output_size", "=", "ctx", ".", "output_size", "\n", "spatial_scale", "=", "ctx", ".", "spatial_scale", "\n", "bs", ",", "ch", ",", "h", ",", "w", "=", "ctx", ".", "input_shape", "\n", "grad_input", "=", "_C", ".", "roi_pool_backward", "(", "\n", "grad_output", ",", "\n", "input", ",", "\n", "rois", ",", "\n", "argmax", ",", "\n", "spatial_scale", ",", "\n", "output_size", "[", "0", "]", ",", "\n", "output_size", "[", "1", "]", ",", "\n", "bs", ",", "\n", "ch", ",", "\n", "h", ",", "\n", "w", ",", "\n", ")", "\n", "return", "grad_input", ",", "None", ",", "None", ",", "None", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_pool.ROIPool.__init__": [[50, 54], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["class", "ROIPool", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "output_size", ",", "spatial_scale", ")", ":", "\n", "        ", "super", "(", "ROIPool", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "spatial_scale", "=", "spatial_scale", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_pool.ROIPool.forward": [[55, 57], ["roi_pool"], "methods", ["None"], ["\n", "", "@", "amp", ".", "float_function", "\n", "def", "forward", "(", "self", ",", "input", ",", "rois", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_pool.ROIPool.__repr__": [[58, 64], ["str", "str"], "methods", ["None"], ["        ", "return", "roi_pool", "(", "input", ",", "rois", ",", "self", ".", "output_size", ",", "self", ".", "spatial_scale", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"output_size=\"", "+", "str", "(", "self", ".", "output_size", ")", "\n", "tmpstr", "+=", "\", spatial_scale=\"", "+", "str", "(", "self", ".", "spatial_scale", ")", "\n", "tmpstr", "+=", "\")\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.__init__": [[12, 18], ["torch.nn.Module.__init__", "batch_norm.FrozenBatchNorm2d.register_buffer", "batch_norm.FrozenBatchNorm2d.register_buffer", "batch_norm.FrozenBatchNorm2d.register_buffer", "batch_norm.FrozenBatchNorm2d.register_buffer", "torch.ones", "torch.zeros", "torch.zeros", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "n", ")", ":", "\n", "        ", "super", "(", "FrozenBatchNorm2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "\"weight\"", ",", "torch", ".", "ones", "(", "n", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "zeros", "(", "n", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"running_mean\"", ",", "torch", ".", "zeros", "(", "n", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"running_var\"", ",", "torch", ".", "ones", "(", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.forward": [[19, 25], ["scale.reshape.reshape.reshape", "bias.reshape.reshape.reshape", "batch_norm.FrozenBatchNorm2d.running_var.rsqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# Cast all fixed parameters to half() if necessary", "\n", "        ", "if", "x", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "            ", "self", ".", "weight", "=", "self", ".", "weight", ".", "half", "(", ")", "\n", "self", ".", "bias", "=", "self", ".", "bias", ".", "half", "(", ")", "\n", "self", ".", "running_mean", "=", "self", ".", "running_mean", ".", "half", "(", ")", "\n", "self", ".", "running_var", "=", "self", ".", "running_var", ".", "half", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align._ROIAlign.forward": [[12, 23], ["ctx.save_for_backward", "torch.nn.modules.utils._pair", "input.size", "fcos_core._C.roi_align_forward"], "methods", ["None"], ["class", "_ROIAlign", "(", "Function", ")", ":", "\n", "    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "roi", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "roi", ")", "\n", "ctx", ".", "output_size", "=", "_pair", "(", "output_size", ")", "\n", "ctx", ".", "spatial_scale", "=", "spatial_scale", "\n", "ctx", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "ctx", ".", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "output", "=", "_C", ".", "roi_align_forward", "(", "\n", "input", ",", "roi", ",", "spatial_scale", ",", "output_size", "[", "0", "]", ",", "output_size", "[", "1", "]", ",", "sampling_ratio", "\n", ")", "\n", "return", "output", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align._ROIAlign.backward": [[24, 45], ["fcos_core._C.roi_align_backward"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "rois", ",", "=", "ctx", ".", "saved_tensors", "\n", "output_size", "=", "ctx", ".", "output_size", "\n", "spatial_scale", "=", "ctx", ".", "spatial_scale", "\n", "sampling_ratio", "=", "ctx", ".", "sampling_ratio", "\n", "bs", ",", "ch", ",", "h", ",", "w", "=", "ctx", ".", "input_shape", "\n", "grad_input", "=", "_C", ".", "roi_align_backward", "(", "\n", "grad_output", ",", "\n", "rois", ",", "\n", "spatial_scale", ",", "\n", "output_size", "[", "0", "]", ",", "\n", "output_size", "[", "1", "]", ",", "\n", "bs", ",", "\n", "ch", ",", "\n", "h", ",", "\n", "w", ",", "\n", "sampling_ratio", ",", "\n", ")", "\n", "return", "grad_input", ",", "None", ",", "None", ",", "None", ",", "None", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align.ROIAlign.__init__": [[51, 56], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ")", ":", "\n", "        ", "super", "(", "ROIAlign", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "spatial_scale", "=", "spatial_scale", "\n", "self", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align.ROIAlign.forward": [[57, 60], ["roi_align"], "methods", ["None"], ["", "@", "amp", ".", "float_function", "\n", "def", "forward", "(", "self", ",", "input", ",", "rois", ")", ":", "\n", "        ", "return", "roi_align", "(", "\n", "input", ",", "rois", ",", "self", ".", "output_size", ",", "self", ".", "spatial_scale", ",", "self", ".", "sampling_ratio", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align.ROIAlign.__repr__": [[62, 69], ["str", "str", "str"], "methods", ["None"], ["\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"output_size=\"", "+", "str", "(", "self", ".", "output_size", ")", "\n", "tmpstr", "+=", "\", spatial_scale=\"", "+", "str", "(", "self", ".", "spatial_scale", ")", "\n", "tmpstr", "+=", "\", sampling_ratio=\"", "+", "str", "(", "self", ".", "sampling_ratio", ")", "\n", "tmpstr", "+=", "\")\"", "\n", "return", "tmpstr", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc._NewEmptyTensorOp.forward": [[18, 22], ["x.new_empty"], "methods", ["None"], ["class", "_NewEmptyTensorOp", "(", "torch", ".", "autograd", ".", "Function", ")", ":", "\n", "    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "new_shape", ")", ":", "\n", "        ", "ctx", ".", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "new_empty", "(", "new_shape", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc._NewEmptyTensorOp.backward": [[23, 27], ["_NewEmptyTensorOp.apply"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "shape", "=", "ctx", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "grad", ",", "shape", ")", ",", "None", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.Conv2d.forward": [[30, 43], ["_NewEmptyTensorOp.apply", "x.numel", "super().forward", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "", "class", "Conv2d", "(", "torch", ".", "nn", ".", "Conv2d", ")", ":", "\n", "    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "return", "super", "(", "Conv2d", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "# get output shape", "\n", "\n", "", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "d", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "d", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.ConvTranspose2d.forward": [[46, 64], ["_NewEmptyTensorOp.apply", "x.numel", "super().forward", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "", "class", "ConvTranspose2d", "(", "torch", ".", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "return", "super", "(", "ConvTranspose2d", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "# get output shape", "\n", "\n", "", "output_shape", "=", "[", "\n", "(", "i", "-", "1", ")", "*", "d", "-", "2", "*", "p", "+", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", "+", "op", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "d", ",", "op", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "output_padding", ",", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "bias", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.BatchNorm2d.forward": [[67, 73], ["_NewEmptyTensorOp.apply", "x.numel", "super().forward"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "", "class", "BatchNorm2d", "(", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "return", "super", "(", "BatchNorm2d", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "# get output shape", "\n", "", "output_shape", "=", "x", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.DFConv2d.__init__": [[115, 171], ["super().__init__", "isinstance", "misc.Conv2d", "conv_block", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "\"\"\"Deformable convolutional layer\"\"\"", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "with_modulated_dcn", "=", "True", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "DFConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "kernel_size", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "kernel_size", ")", "==", "2", "\n", "offset_base_channels", "=", "kernel_size", "[", "0", "]", "*", "kernel_size", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "offset_base_channels", "=", "kernel_size", "*", "kernel_size", "\n", "", "if", "with_modulated_dcn", ":", "\n", "            ", "from", "maskrcnn_benchmark", ".", "layers", "import", "ModulatedDeformConv", "\n", "offset_channels", "=", "offset_base_channels", "*", "3", "# default: 27", "\n", "conv_block", "=", "ModulatedDeformConv", "\n", "", "else", ":", "\n", "            ", "from", "maskrcnn_benchmark", ".", "layers", "import", "DeformConv", "\n", "offset_channels", "=", "offset_base_channels", "*", "2", "# default: 18", "\n", "conv_block", "=", "DeformConv", "\n", "", "self", ".", "offset", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "deformable_groups", "*", "offset_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "groups", "=", "1", ",", "\n", "dilation", "=", "dilation", "\n", ")", "\n", "for", "l", "in", "[", "self", ".", "offset", ",", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0.", ")", "\n", "", "self", ".", "conv", "=", "conv_block", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "\n", "deformable_groups", "=", "deformable_groups", ",", "\n", "bias", "=", "bias", "\n", ")", "\n", "self", ".", "with_modulated_dcn", "=", "with_modulated_dcn", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "offset_base_channels", "=", "offset_base_channels", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.DFConv2d.forward": [[172, 185], ["misc.DFConv2d.numel", "misc.DFConv2d.numel", "misc.DFConv2d.offset", "misc.DFConv2d.conv", "misc.DFConv2d.offset", "offset_mask[].sigmoid", "misc.DFConv2d.conv"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "numel", "(", ")", ">", "0", ",", "\"only non-empty tensors are supported\"", "\n", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "if", "not", "self", ".", "with_modulated_dcn", ":", "\n", "                ", "offset", "=", "self", ".", "offset", "(", "x", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ",", "offset", ")", "\n", "", "else", ":", "\n", "                ", "offset_mask", "=", "self", ".", "offset", "(", "x", ")", "\n", "split_point", "=", "self", ".", "offset_base_channels", "*", "2", "\n", "offset", "=", "offset_mask", "[", ":", ",", ":", "split_point", ",", ":", ",", ":", "]", "\n", "mask", "=", "offset_mask", "[", ":", ",", "split_point", ":", ",", ":", ",", ":", "]", ".", "sigmoid", "(", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ",", "offset", ",", "mask", ")", "\n", "", "return", "x", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate": [[75, 111], ["tuple", "_NewEmptyTensorOp.apply", "input.numel", "torch.nn.functional.interpolate", "misc.interpolate._check_size_scale_factor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["\n", "", "", "def", "interpolate", "(", "\n", "input", ",", "size", "=", "None", ",", "scale_factor", "=", "None", ",", "mode", "=", "\"nearest\"", ",", "align_corners", "=", "None", "\n", ")", ":", "\n", "    ", "if", "input", ".", "numel", "(", ")", ">", "0", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "input", ",", "size", ",", "scale_factor", ",", "mode", ",", "align_corners", "\n", ")", "\n", "\n", "", "def", "_check_size_scale_factor", "(", "dim", ")", ":", "\n", "        ", "if", "size", "is", "None", "and", "scale_factor", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"either size or scale_factor should be defined\"", ")", "\n", "", "if", "size", "is", "not", "None", "and", "scale_factor", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"only one of size or scale_factor should be defined\"", ")", "\n", "", "if", "(", "\n", "scale_factor", "is", "not", "None", "\n", "and", "isinstance", "(", "scale_factor", ",", "tuple", ")", "\n", "and", "len", "(", "scale_factor", ")", "!=", "dim", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"scale_factor shape must match input shape. \"", "\n", "\"Input is {}D, scale_factor size is {}\"", ".", "format", "(", "dim", ",", "len", "(", "scale_factor", ")", ")", "\n", ")", "\n", "\n", "", "", "def", "_output_size", "(", "dim", ")", ":", "\n", "        ", "_check_size_scale_factor", "(", "dim", ")", "\n", "if", "size", "is", "not", "None", ":", "\n", "            ", "return", "size", "\n", "", "scale_factors", "=", "_ntuple", "(", "dim", ")", "(", "scale_factor", ")", "\n", "# math.floor might return float in py2.7", "\n", "return", "[", "\n", "int", "(", "math", ".", "floor", "(", "input", ".", "size", "(", "i", "+", "2", ")", "*", "scale_factors", "[", "i", "]", ")", ")", "for", "i", "in", "range", "(", "dim", ")", "\n", "]", "\n", "\n", "", "output_shape", "=", "tuple", "(", "_output_size", "(", "2", ")", ")", "\n", "output_shape", "=", "input", ".", "shape", "[", ":", "-", "2", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "input", ",", "output_shape", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.iou_loss.IOULoss.__init__": [[8, 11], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "loss_type", "=", "\"iou\"", ")", ":", "\n", "        ", "super", "(", "IOULoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_type", "=", "loss_type", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.iou_loss.IOULoss.forward": [[12, 52], ["torch.min", "torch.min", "torch.max", "torch.max", "torch.min", "torch.min", "torch.max", "torch.max", "losses.sum", "torch.log", "weight.sum", "losses.numel"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred", ",", "target", ",", "weight", "=", "None", ")", ":", "\n", "        ", "pred_left", "=", "pred", "[", ":", ",", "0", "]", "\n", "pred_top", "=", "pred", "[", ":", ",", "1", "]", "\n", "pred_right", "=", "pred", "[", ":", ",", "2", "]", "\n", "pred_bottom", "=", "pred", "[", ":", ",", "3", "]", "\n", "\n", "target_left", "=", "target", "[", ":", ",", "0", "]", "\n", "target_top", "=", "target", "[", ":", ",", "1", "]", "\n", "target_right", "=", "target", "[", ":", ",", "2", "]", "\n", "target_bottom", "=", "target", "[", ":", ",", "3", "]", "\n", "\n", "target_area", "=", "(", "target_left", "+", "target_right", ")", "*", "(", "target_top", "+", "target_bottom", ")", "\n", "pred_area", "=", "(", "pred_left", "+", "pred_right", ")", "*", "(", "pred_top", "+", "pred_bottom", ")", "\n", "\n", "w_intersect", "=", "torch", ".", "min", "(", "pred_left", ",", "target_left", ")", "+", "torch", ".", "min", "(", "pred_right", ",", "target_right", ")", "\n", "g_w_intersect", "=", "torch", ".", "max", "(", "pred_left", ",", "target_left", ")", "+", "torch", ".", "max", "(", "\n", "pred_right", ",", "target_right", ")", "\n", "h_intersect", "=", "torch", ".", "min", "(", "pred_bottom", ",", "target_bottom", ")", "+", "torch", ".", "min", "(", "pred_top", ",", "target_top", ")", "\n", "g_h_intersect", "=", "torch", ".", "max", "(", "pred_bottom", ",", "target_bottom", ")", "+", "torch", ".", "max", "(", "pred_top", ",", "target_top", ")", "\n", "ac_uion", "=", "g_w_intersect", "*", "g_h_intersect", "+", "1e-7", "\n", "area_intersect", "=", "w_intersect", "*", "h_intersect", "\n", "area_union", "=", "target_area", "+", "pred_area", "-", "area_intersect", "\n", "ious", "=", "(", "area_intersect", "+", "1.0", ")", "/", "(", "area_union", "+", "1.0", ")", "\n", "gious", "=", "ious", "-", "(", "ac_uion", "-", "area_union", ")", "/", "ac_uion", "\n", "if", "self", ".", "loss_type", "==", "'iou'", ":", "\n", "            ", "losses", "=", "-", "torch", ".", "log", "(", "ious", ")", "\n", "", "elif", "self", ".", "loss_type", "==", "'linear_iou'", ":", "\n", "            ", "losses", "=", "1", "-", "ious", "\n", "", "elif", "self", ".", "loss_type", "==", "'giou'", ":", "\n", "            ", "losses", "=", "1", "-", "gious", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "weight", "is", "not", "None", "and", "weight", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "return", "(", "losses", "*", "weight", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "losses", ".", "numel", "(", ")", "!=", "0", "\n", "return", "losses", ".", "sum", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss": [[6, 17], ["torch.abs", "torch.where", "torch.where.sum", "torch.where.mean"], "function", ["None"], ["def", "smooth_l1_loss", "(", "input", ",", "target", ",", "beta", "=", "1.", "/", "9", ",", "size_average", "=", "True", ",", "return_loss_vec", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    very similar to the smooth_l1_loss from pytorch, but with\n    the extra beta parameter\n    \"\"\"", "\n", "n", "=", "torch", ".", "abs", "(", "input", "-", "target", ")", "\n", "cond", "=", "n", "<", "beta", "\n", "loss", "=", "torch", ".", "where", "(", "cond", ",", "0.5", "*", "n", "**", "2", "/", "beta", ",", "n", "-", "0.5", "*", "beta", ")", "\n", "if", "size_average", ":", "\n", "        ", "ret_loss", "=", "loss", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "        ", "ret_loss", "=", "loss", ".", "sum", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers._NewEmptyTensorOp.forward": [[37, 41], ["x.new_empty"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "new_shape", ")", ":", "\n", "        ", "ctx", ".", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "new_empty", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers._NewEmptyTensorOp.backward": [[42, 46], ["_NewEmptyTensorOp.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "shape", "=", "ctx", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "grad", ",", "shape", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.Conv2d.__init__": [[53, 69], ["kwargs.pop", "kwargs.pop", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Extra keyword arguments supported in addition to those in `torch.nn.Conv2d`:\n\n        Args:\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n\n        It assumes that norm layer is used before activation.\n        \"\"\"", "\n", "norm", "=", "kwargs", ".", "pop", "(", "\"norm\"", ",", "None", ")", "\n", "activation", "=", "kwargs", ".", "pop", "(", "\"activation\"", ",", "None", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.Conv2d.forward": [[70, 92], ["torch.nn.functional.conv2d", "torch.jit.is_scripting", "wrappers.Conv2d.norm", "wrappers.Conv2d.activation", "wrappers.Conv2d.numel", "isinstance"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# torchscript does not support SyncBatchNorm yet", "\n", "# https://github.com/pytorch/pytorch/issues/40507", "\n", "# and we skip these codes in torchscript since:", "\n", "# 1. currently we only support torchscript in evaluation mode", "\n", "# 2. features needed by exporting module to torchscript are added in PyTorch 1.6 or", "\n", "# later version, `Conv2d` in these PyTorch versions has already supported empty inputs.", "\n", "        ", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "if", "x", ".", "numel", "(", ")", "==", "0", "and", "self", ".", "training", ":", "\n", "# https://github.com/pytorch/pytorch/issues/12013", "\n", "                ", "assert", "not", "isinstance", "(", "\n", "self", ".", "norm", ",", "torch", ".", "nn", ".", "SyncBatchNorm", "\n", ")", ",", "\"SyncBatchNorm does not support empty inputs!\"", "\n", "\n", "", "", "x", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", "\n", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat": [[16, 24], ["isinstance", "torch.cat", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["def", "cat", "(", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "dim", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy": [[26, 34], ["torch.nn.functional.cross_entropy", "target.numel", "input.sum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy"], ["", "def", "cross_entropy", "(", "input", ",", "target", ",", "*", ",", "reduction", "=", "\"mean\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Same as `torch.nn.functional.cross_entropy`, but returns 0 (instead of nan)\n    for empty inputs.\n    \"\"\"", "\n", "if", "target", ".", "numel", "(", ")", "==", "0", "and", "reduction", "==", "\"mean\"", ":", "\n", "        ", "return", "input", ".", "sum", "(", ")", "*", "0.0", "# connect the gradient", "\n", "", "return", "F", ".", "cross_entropy", "(", "input", ",", "target", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple": [[100, 111], ["torch.jit.is_scripting", "x.nonzero().unbind", "x.nonzero", "x.dim", "x.unsqueeze().nonzero().unbind", "x.nonzero", "x.unsqueeze().nonzero", "x.unsqueeze"], "function", ["None"], ["def", "nonzero_tuple", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    A 'as_tuple=True' version of torch.nonzero to support torchscript.\n    because of https://github.com/pytorch/pytorch/issues/38718\n    \"\"\"", "\n", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "return", "x", ".", "unsqueeze", "(", "0", ")", ".", "nonzero", "(", ")", ".", "unbind", "(", "1", ")", "\n", "", "return", "x", ".", "nonzero", "(", ")", ".", "unbind", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms": [[19, 40], ["scores.new_zeros", "torch.jit.annotate", "scores.new_zeros.nonzero().view", "len", "torchvision.ops.boxes.batched_nms", "scores.size", "torch.unique().cpu().tolist", "torchvision.ops.nms", "torchvision.ops.boxes.float", "scores.new_zeros.nonzero", "scores[].argsort", "torch.unique().cpu", "torch.unique"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.nms_rotated": [[44, 106], ["nms_rotated_func"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms_rotated": [[110, 159], ["boxes.float.float", "boxes.float.clone", "nms.nms_rotated", "boxes.float.numel", "torch.empty", "idxs.to", "torch.max", "torch.min", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.nms_rotated", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.aspp.ASPP.__init__": [[19, 128], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "aspp.ASPP.convs.append", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "aspp.ASPP.convs.append", "wrappers.Conv2d", "fvcore.c2_xavier_fill", "len", "len", "wrappers.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "aspp.ASPP.convs.append", "aspp.ASPP.convs.append", "fvcore.c2_xavier_fill", "torch.nn.AdaptiveAvgPool2d", "wrappers.Conv2d", "torch.nn.AvgPool2d", "wrappers.Conv2d", "batch_norm.get_norm", "copy.deepcopy", "batch_norm.get_norm", "copy.deepcopy", "blocks.DepthwiseSeparableConv2d", "wrappers.Conv2d", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "batch_norm.get_norm", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "dilations", ",", "\n", "*", ",", "\n", "norm", ",", "\n", "activation", ",", "\n", "pool_kernel_size", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "use_depthwise_separable_conv", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            in_channels (int): number of input channels for ASPP.\n            out_channels (int): number of output channels.\n            dilations (list): a list of 3 dilations in ASPP.\n            norm (str or callable): normalization for all conv layers.\n                See :func:`layers.get_norm` for supported format. norm is\n                applied to all conv layers except the conv following\n                global average pooling.\n            activation (callable): activation function.\n            pool_kernel_size (tuple, list): the average pooling size (kh, kw)\n                for image pooling layer in ASPP. If set to None, it always\n                performs global average pooling. If not None, it must be\n                divisible by the shape of inputs in forward(). It is recommended\n                to use a fixed input feature size in training, and set this\n                option to match this size, so that it performs global average\n                pooling in training, and the size of the pooling window stays\n                consistent in inference.\n            dropout (float): apply dropout on the output of ASPP. It is used in\n                the official DeepLab implementation with a rate of 0.1:\n                https://github.com/tensorflow/models/blob/21b73d22f3ed05b650e85ac50849408dd36de32e/research/deeplab/model.py#L532  # noqa\n            use_depthwise_separable_conv (bool): use DepthwiseSeparableConv2d\n                for 3x3 convs in ASPP, proposed in :paper:`DeepLabV3+`.\n        \"\"\"", "\n", "super", "(", "ASPP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "dilations", ")", "==", "3", ",", "\"ASPP expects 3 dilations, got {}\"", ".", "format", "(", "len", "(", "dilations", ")", ")", "\n", "self", ".", "pool_kernel_size", "=", "pool_kernel_size", "\n", "self", ".", "dropout", "=", "dropout", "\n", "use_bias", "=", "norm", "==", "\"\"", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# conv 1x1", "\n", "self", ".", "convs", ".", "append", "(", "\n", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", "activation", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "convs", "[", "-", "1", "]", ")", "\n", "# atrous convs", "\n", "for", "dilation", "in", "dilations", ":", "\n", "            ", "if", "use_depthwise_separable_conv", ":", "\n", "                ", "self", ".", "convs", ".", "append", "(", "\n", "DepthwiseSeparableConv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "norm1", "=", "norm", ",", "\n", "activation1", "=", "deepcopy", "(", "activation", ")", ",", "\n", "norm2", "=", "norm", ",", "\n", "activation2", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "convs", ".", "append", "(", "\n", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", "activation", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "convs", "[", "-", "1", "]", ")", "\n", "# image pooling", "\n", "# We do not add BatchNorm because the spatial resolution is 1x1,", "\n", "# the original TF implementation has BatchNorm.", "\n", "", "", "if", "pool_kernel_size", "is", "None", ":", "\n", "            ", "image_pooling", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", ",", "\n", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "True", ",", "activation", "=", "deepcopy", "(", "activation", ")", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "image_pooling", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "pool_kernel_size", ",", "stride", "=", "1", ")", ",", "\n", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "True", ",", "activation", "=", "deepcopy", "(", "activation", ")", ")", ",", "\n", ")", "\n", "", "weight_init", ".", "c2_xavier_fill", "(", "image_pooling", "[", "1", "]", ")", "\n", "self", ".", "convs", ".", "append", "(", "image_pooling", ")", "\n", "\n", "self", ".", "project", "=", "Conv2d", "(", "\n", "5", "*", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", "activation", "=", "deepcopy", "(", "activation", ")", ",", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "project", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.aspp.ASPP.forward": [[129, 145], ["torch.nn.functional.interpolate", "torch.cat", "aspp.ASPP.project", "aspp.ASPP.append", "torch.nn.functional.dropout", "ValueError", "conv"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "if", "self", ".", "pool_kernel_size", "is", "not", "None", ":", "\n", "            ", "if", "size", "[", "0", "]", "%", "self", ".", "pool_kernel_size", "[", "0", "]", "or", "size", "[", "1", "]", "%", "self", ".", "pool_kernel_size", "[", "1", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"`pool_kernel_size` must be divisible by the shape of inputs. \"", "\n", "\"Input size: {} `pool_kernel_size`: {}\"", ".", "format", "(", "size", ",", "self", ".", "pool_kernel_size", ")", "\n", ")", "\n", "", "", "res", "=", "[", "]", "\n", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "res", ".", "append", "(", "conv", "(", "x", ")", ")", "\n", "", "res", "[", "-", "1", "]", "=", "F", ".", "interpolate", "(", "res", "[", "-", "1", "]", ",", "size", "=", "size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "res", "=", "torch", ".", "cat", "(", "res", ",", "dim", "=", "1", ")", "\n", "res", "=", "self", ".", "project", "(", "res", ")", "\n", "res", "=", "F", ".", "dropout", "(", "res", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "if", "self", ".", "dropout", ">", "0", "else", "res", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.rotated_boxes.pairwise_iou_rotated": [[7, 23], ["detectron2._C.box_iou_rotated"], "function", ["None"], ["\n", "from", ".", "boxes", "import", "Boxes", ",", "_maybe_jit_unused", "\n", "\n", "\n", "class", "RotatedBoxes", "(", "Boxes", ")", ":", "\n", "    ", "\"\"\"\n    This structure stores a list of rotated boxes as a Nx5 torch.Tensor.\n    It supports some common methods about boxes\n    (`area`, `clip`, `nonempty`, etc),\n    and also behaves like a Tensor\n    (support indexing, `to(device)`, `.device`, and iteration over all boxes)\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._DeformConv.forward": [[17, 81], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "ctx.save_for_backward", "input.new_empty", "ValueError", "deform_conv._DeformConv._output_size", "input.new_empty", "input.new_empty", "torchvision.ops.deform_conv2d", "deform_conv._DeformConv._cal_im2col_step", "detectron2._C.deform_conv_forward", "input.dim", "NotImplementedError", "weight.size", "weight.size", "input.dim"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.DeformConvFunction._output_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._DeformConv._cal_im2col_step"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "input", ",", "\n", "offset", ",", "\n", "weight", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "im2col_step", "=", "64", ",", "\n", ")", ":", "\n", "        ", "if", "input", "is", "not", "None", "and", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected 4D tensor as input, got {}D tensor instead.\"", ".", "format", "(", "input", ".", "dim", "(", ")", ")", "\n", ")", "\n", "", "ctx", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "ctx", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "ctx", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "ctx", ".", "groups", "=", "groups", "\n", "ctx", ".", "deformable_groups", "=", "deformable_groups", "\n", "ctx", ".", "im2col_step", "=", "im2col_step", "\n", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "offset", ",", "weight", ")", "\n", "\n", "output", "=", "input", ".", "new_empty", "(", "\n", "_DeformConv", ".", "_output_size", "(", "input", ",", "weight", ",", "ctx", ".", "padding", ",", "ctx", ".", "dilation", ",", "ctx", ".", "stride", ")", "\n", ")", "\n", "\n", "ctx", ".", "bufs_", "=", "[", "input", ".", "new_empty", "(", "0", ")", ",", "input", ".", "new_empty", "(", "0", ")", "]", "# columns, ones", "\n", "\n", "if", "not", "input", ".", "is_cuda", ":", "\n", "            ", "if", "deformable_groups", "!=", "1", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Deformable Conv with deformable_groups != 1 is not supported on CPUs!\"", "\n", ")", "\n", "", "return", "deform_conv2d", "(", "\n", "input", ",", "offset", ",", "weight", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cur_im2col_step", "=", "_DeformConv", ".", "_cal_im2col_step", "(", "input", ".", "shape", "[", "0", "]", ",", "ctx", ".", "im2col_step", ")", "\n", "assert", "(", "input", ".", "shape", "[", "0", "]", "%", "cur_im2col_step", ")", "==", "0", ",", "\"im2col step must divide batchsize\"", "\n", "\n", "_C", ".", "deform_conv_forward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "offset", ",", "\n", "output", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "ctx", ".", "bufs_", "[", "1", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "cur_im2col_step", ",", "\n", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._DeformConv.backward": [[82, 143], ["NotImplementedError", "deform_conv._DeformConv._cal_im2col_step", "torch.zeros_like", "torch.zeros_like", "detectron2._C.deform_conv_backward_input", "torch.zeros_like", "detectron2._C.deform_conv_backward_filter", "weight.size", "weight.size", "weight.size", "weight.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._DeformConv._cal_im2col_step"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "offset", ",", "weight", "=", "ctx", ".", "saved_tensors", "\n", "\n", "grad_input", "=", "grad_offset", "=", "grad_weight", "=", "None", "\n", "\n", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Deformable Conv is not supported on CPUs!\"", ")", "\n", "", "else", ":", "\n", "            ", "cur_im2col_step", "=", "_DeformConv", ".", "_cal_im2col_step", "(", "input", ".", "shape", "[", "0", "]", ",", "ctx", ".", "im2col_step", ")", "\n", "assert", "(", "input", ".", "shape", "[", "0", "]", "%", "cur_im2col_step", ")", "==", "0", ",", "\"im2col step must divide batchsize\"", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", "or", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "                ", "grad_input", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "_C", ".", "deform_conv_backward_input", "(", "\n", "input", ",", "\n", "offset", ",", "\n", "grad_output", ",", "\n", "grad_input", ",", "\n", "grad_offset", ",", "\n", "weight", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "cur_im2col_step", ",", "\n", ")", "\n", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "2", "]", ":", "\n", "                ", "grad_weight", "=", "torch", ".", "zeros_like", "(", "weight", ")", "\n", "_C", ".", "deform_conv_backward_filter", "(", "\n", "input", ",", "\n", "offset", ",", "\n", "grad_output", ",", "\n", "grad_weight", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "ctx", ".", "bufs_", "[", "1", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "1", ",", "\n", "cur_im2col_step", ",", "\n", ")", "\n", "\n", "", "", "return", "grad_input", ",", "grad_offset", ",", "grad_weight", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._DeformConv._output_size": [[144, 161], ["weight.size", "range", "input.size", "input.size", "all", "ValueError", "input.dim", "map", "weight.size", "map"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_output_size", "(", "input", ",", "weight", ",", "padding", ",", "dilation", ",", "stride", ")", ":", "\n", "        ", "channels", "=", "weight", ".", "size", "(", "0", ")", "\n", "output_size", "=", "(", "input", ".", "size", "(", "0", ")", ",", "channels", ")", "\n", "for", "d", "in", "range", "(", "input", ".", "dim", "(", ")", "-", "2", ")", ":", "\n", "            ", "in_size", "=", "input", ".", "size", "(", "d", "+", "2", ")", "\n", "pad", "=", "padding", "[", "d", "]", "\n", "kernel", "=", "dilation", "[", "d", "]", "*", "(", "weight", ".", "size", "(", "d", "+", "2", ")", "-", "1", ")", "+", "1", "\n", "stride_", "=", "stride", "[", "d", "]", "\n", "output_size", "+=", "(", "(", "in_size", "+", "(", "2", "*", "pad", ")", "-", "kernel", ")", "//", "stride_", "+", "1", ",", ")", "\n", "", "if", "not", "all", "(", "map", "(", "lambda", "s", ":", "s", ">", "0", ",", "output_size", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"convolution input is too small (output would be {})\"", ".", "format", "(", "\n", "\"x\"", ".", "join", "(", "map", "(", "str", ",", "output_size", ")", ")", "\n", ")", "\n", ")", "\n", "", "return", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._DeformConv._cal_im2col_step": [[162, 184], ["functools.lru_cache", "range", "min", "int", "math.sqrt"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "lru_cache", "(", "maxsize", "=", "128", ")", "\n", "def", "_cal_im2col_step", "(", "input_size", ",", "default_size", ")", ":", "\n", "        ", "\"\"\"\n        Calculate proper im2col step size, which should be divisible by input_size and not larger\n        than prefer_size. Meanwhile the step size should be as large as possible to be more\n        efficient. So we choose the largest one among all divisors of input_size which are smaller\n        than prefer_size.\n        :param input_size: input batch size .\n        :param default_size: default preferred im2col step size.\n        :return: the largest proper step size.\n        \"\"\"", "\n", "if", "input_size", "<=", "default_size", ":", "\n", "            ", "return", "input_size", "\n", "", "best_step", "=", "1", "\n", "for", "step", "in", "range", "(", "2", ",", "min", "(", "int", "(", "math", ".", "sqrt", "(", "input_size", ")", ")", "+", "1", ",", "default_size", ")", ")", ":", "\n", "            ", "if", "input_size", "%", "step", "==", "0", ":", "\n", "                ", "if", "input_size", "//", "step", "<=", "default_size", ":", "\n", "                    ", "return", "input_size", "//", "step", "\n", "", "best_step", "=", "step", "\n", "\n", "", "", "return", "best_step", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._ModulatedDeformConv.forward": [[187, 242], ["input.new_empty", "detectron2._C.modulated_deform_conv_forward", "input.new_empty", "NotImplementedError", "ctx.save_for_backward", "deform_conv._ModulatedDeformConv._infer_shape", "input.new_empty", "input.new_empty"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.ModulatedDeformConvFunction._infer_shape"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "input", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "weight", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", ")", ":", "\n", "        ", "ctx", ".", "stride", "=", "stride", "\n", "ctx", ".", "padding", "=", "padding", "\n", "ctx", ".", "dilation", "=", "dilation", "\n", "ctx", ".", "groups", "=", "groups", "\n", "ctx", ".", "deformable_groups", "=", "deformable_groups", "\n", "ctx", ".", "with_bias", "=", "bias", "is", "not", "None", "\n", "if", "not", "ctx", ".", "with_bias", ":", "\n", "            ", "bias", "=", "input", ".", "new_empty", "(", "1", ")", "# fake tensor", "\n", "", "if", "not", "input", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Deformable Conv is not supported on CPUs!\"", ")", "\n", "", "if", "(", "\n", "weight", ".", "requires_grad", "\n", "or", "mask", ".", "requires_grad", "\n", "or", "offset", ".", "requires_grad", "\n", "or", "input", ".", "requires_grad", "\n", ")", ":", "\n", "            ", "ctx", ".", "save_for_backward", "(", "input", ",", "offset", ",", "mask", ",", "weight", ",", "bias", ")", "\n", "", "output", "=", "input", ".", "new_empty", "(", "_ModulatedDeformConv", ".", "_infer_shape", "(", "ctx", ",", "input", ",", "weight", ")", ")", "\n", "ctx", ".", "_bufs", "=", "[", "input", ".", "new_empty", "(", "0", ")", ",", "input", ".", "new_empty", "(", "0", ")", "]", "\n", "_C", ".", "modulated_deform_conv_forward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", ",", "\n", "ctx", ".", "_bufs", "[", "0", "]", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "output", ",", "\n", "ctx", ".", "_bufs", "[", "1", "]", ",", "\n", "weight", ".", "shape", "[", "2", "]", ",", "\n", "weight", ".", "shape", "[", "3", "]", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "ctx", ".", "with_bias", ",", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._ModulatedDeformConv.backward": [[243, 294], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "detectron2._C.modulated_deform_conv_backward", "NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Deformable Conv is not supported on CPUs!\"", ")", "\n", "", "input", ",", "offset", ",", "mask", ",", "weight", ",", "bias", "=", "ctx", ".", "saved_tensors", "\n", "grad_input", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "grad_mask", "=", "torch", ".", "zeros_like", "(", "mask", ")", "\n", "grad_weight", "=", "torch", ".", "zeros_like", "(", "weight", ")", "\n", "grad_bias", "=", "torch", ".", "zeros_like", "(", "bias", ")", "\n", "_C", ".", "modulated_deform_conv_backward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", ",", "\n", "ctx", ".", "_bufs", "[", "0", "]", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "ctx", ".", "_bufs", "[", "1", "]", ",", "\n", "grad_input", ",", "\n", "grad_weight", ",", "\n", "grad_bias", ",", "\n", "grad_offset", ",", "\n", "grad_mask", ",", "\n", "grad_output", ",", "\n", "weight", ".", "shape", "[", "2", "]", ",", "\n", "weight", ".", "shape", "[", "3", "]", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "ctx", ".", "with_bias", ",", "\n", ")", "\n", "if", "not", "ctx", ".", "with_bias", ":", "\n", "            ", "grad_bias", "=", "None", "\n", "\n", "", "return", "(", "\n", "grad_input", ",", "\n", "grad_offset", ",", "\n", "grad_mask", ",", "\n", "grad_weight", ",", "\n", "grad_bias", ",", "\n", "None", ",", "\n", "None", ",", "\n", "None", ",", "\n", "None", ",", "\n", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv._ModulatedDeformConv._infer_shape": [[296, 309], ["input.size", "weight.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_infer_shape", "(", "ctx", ",", "input", ",", "weight", ")", ":", "\n", "        ", "n", "=", "input", ".", "size", "(", "0", ")", "\n", "channels_out", "=", "weight", ".", "size", "(", "0", ")", "\n", "height", ",", "width", "=", "input", ".", "shape", "[", "2", ":", "4", "]", "\n", "kernel_h", ",", "kernel_w", "=", "weight", ".", "shape", "[", "2", ":", "4", "]", "\n", "height_out", "=", "(", "\n", "height", "+", "2", "*", "ctx", ".", "padding", "-", "(", "ctx", ".", "dilation", "*", "(", "kernel_h", "-", "1", ")", "+", "1", ")", "\n", ")", "//", "ctx", ".", "stride", "+", "1", "\n", "width_out", "=", "(", "\n", "width", "+", "2", "*", "ctx", ".", "padding", "-", "(", "ctx", ".", "dilation", "*", "(", "kernel_w", "-", "1", ")", "+", "1", ")", "\n", ")", "//", "ctx", ".", "stride", "+", "1", "\n", "return", "n", ",", "channels_out", ",", "height_out", ",", "width_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv.DeformConv.__init__": [[316, 367], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.Parameter", "torch.nn.init.kaiming_uniform_", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Deformable convolution from :paper:`deformconv`.\n\n        Arguments are similar to :class:`Conv2D`. Extra arguments:\n\n        Args:\n            deformable_groups (int): number of groups used in deformable convolution.\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n        \"\"\"", "\n", "super", "(", "DeformConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "bias", "\n", "assert", "in_channels", "%", "groups", "==", "0", ",", "\"in_channels {} cannot be divisible by groups {}\"", ".", "format", "(", "\n", "in_channels", ",", "groups", "\n", ")", "\n", "assert", "(", "\n", "out_channels", "%", "groups", "==", "0", "\n", ")", ",", "\"out_channels {} cannot be divisible by groups {}\"", ".", "format", "(", "out_channels", ",", "groups", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "self", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "self", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "deformable_groups", "=", "deformable_groups", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "self", ".", "groups", ",", "*", "self", ".", "kernel_size", ")", "\n", ")", "\n", "self", ".", "bias", "=", "None", "\n", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv.DeformConv.forward": [[368, 398], ["deform_conv", "deform_conv.DeformConv.numel", "wrappers._NewEmptyTensorOp.apply", "deform_conv.DeformConv.norm", "deform_conv.DeformConv.activation", "zip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "offset", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", "==", "0", ":", "\n", "# When input is empty, we want to return a empty tensor with \"correct\" shape,", "\n", "# So that the following operations will not panic", "\n", "# if they check for the shape of the tensor.", "\n", "# This computes the height and width of the output tensor", "\n", "            ", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "s", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "s", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "\n", "", "x", "=", "deform_conv", "(", "\n", "x", ",", "\n", "offset", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", "self", ".", "deformable_groups", ",", "\n", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv.DeformConv.extra_repr": [[399, 410], ["str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "\"in_channels=\"", "+", "str", "(", "self", ".", "in_channels", ")", "\n", "tmpstr", "+=", "\", out_channels=\"", "+", "str", "(", "self", ".", "out_channels", ")", "\n", "tmpstr", "+=", "\", kernel_size=\"", "+", "str", "(", "self", ".", "kernel_size", ")", "\n", "tmpstr", "+=", "\", stride=\"", "+", "str", "(", "self", ".", "stride", ")", "\n", "tmpstr", "+=", "\", padding=\"", "+", "str", "(", "self", ".", "padding", ")", "\n", "tmpstr", "+=", "\", dilation=\"", "+", "str", "(", "self", ".", "dilation", ")", "\n", "tmpstr", "+=", "\", groups=\"", "+", "str", "(", "self", ".", "groups", ")", "\n", "tmpstr", "+=", "\", deformable_groups=\"", "+", "str", "(", "self", ".", "deformable_groups", ")", "\n", "tmpstr", "+=", "\", bias=False\"", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv.ModulatedDeformConv.__init__": [[413, 461], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.Parameter", "torch.nn.init.kaiming_uniform_", "torch.Tensor", "torch.nn.Parameter", "torch.nn.init.constant_", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "norm", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Modulated deformable convolution from :paper:`deformconv2`.\n\n        Arguments are similar to :class:`Conv2D`. Extra arguments:\n\n        Args:\n            deformable_groups (int): number of groups used in deformable convolution.\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n        \"\"\"", "\n", "super", "(", "ModulatedDeformConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "deformable_groups", "=", "deformable_groups", "\n", "self", ".", "with_bias", "=", "bias", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "self", ".", "kernel_size", ")", "\n", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv.ModulatedDeformConv.forward": [[462, 490], ["modulated_deform_conv", "deform_conv.ModulatedDeformConv.numel", "wrappers._NewEmptyTensorOp.apply", "deform_conv.ModulatedDeformConv.norm", "deform_conv.ModulatedDeformConv.activation", "zip"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "offset", ",", "mask", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "s", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "s", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "\n", "", "x", "=", "modulated_deform_conv", "(", "\n", "x", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", "self", ".", "deformable_groups", ",", "\n", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.deform_conv.ModulatedDeformConv.extra_repr": [[491, 502], ["str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "\"in_channels=\"", "+", "str", "(", "self", ".", "in_channels", ")", "\n", "tmpstr", "+=", "\", out_channels=\"", "+", "str", "(", "self", ".", "out_channels", ")", "\n", "tmpstr", "+=", "\", kernel_size=\"", "+", "str", "(", "self", ".", "kernel_size", ")", "\n", "tmpstr", "+=", "\", stride=\"", "+", "str", "(", "self", ".", "stride", ")", "\n", "tmpstr", "+=", "\", padding=\"", "+", "str", "(", "self", ".", "padding", ")", "\n", "tmpstr", "+=", "\", dilation=\"", "+", "str", "(", "self", ".", "dilation", ")", "\n", "tmpstr", "+=", "\", groups=\"", "+", "str", "(", "self", ".", "groups", ")", "\n", "tmpstr", "+=", "\", deformable_groups=\"", "+", "str", "(", "self", ".", "deformable_groups", ")", "\n", "tmpstr", "+=", "\", bias=\"", "+", "str", "(", "self", ".", "with_bias", ")", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.__init__": [[29, 42], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "stride", ")", ":", "\n", "        ", "\"\"\"\n        The `__init__` method of any subclass should also contain these arguments.\n\n        Args:\n            in_channels (int):\n            out_channels (int):\n            stride (int):\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze": [[43, 56], ["blocks.CNNBlockBase.parameters", "batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm"], ["", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Make this block not trainable.\n        This method sets all parameters to `requires_grad=False`,\n        and convert all BatchNorm layers to FrozenBatchNorm\n\n        Returns:\n            the block itself\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "FrozenBatchNorm2d", ".", "convert_frozen_batchnorm", "(", "self", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.DepthwiseSeparableConv2d.__init__": [[66, 109], ["torch.nn.Module.__init__", "wrappers.Conv2d", "wrappers.Conv2d", "fvcore.c2_msra_fill", "fvcore.c2_msra_fill", "batch_norm.get_norm", "batch_norm.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "*", ",", "\n", "norm1", "=", "None", ",", "\n", "activation1", "=", "None", ",", "\n", "norm2", "=", "None", ",", "\n", "activation2", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            norm1, norm2 (str or callable): normalization for the two conv layers.\n            activation1, activation2 (callable(Tensor) -> Tensor): activation\n                function for the two conv layers.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depthwise", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "groups", "=", "in_channels", ",", "\n", "bias", "=", "not", "norm1", ",", "\n", "norm", "=", "get_norm", "(", "norm1", ",", "in_channels", ")", ",", "\n", "activation", "=", "activation1", ",", "\n", ")", "\n", "self", ".", "pointwise", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "not", "norm2", ",", "\n", "norm", "=", "get_norm", "(", "norm2", ",", "out_channels", ")", ",", "\n", "activation", "=", "activation2", ",", "\n", ")", "\n", "\n", "# default initialization", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "depthwise", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "pointwise", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.DepthwiseSeparableConv2d.forward": [[110, 112], ["blocks.DepthwiseSeparableConv2d.pointwise", "blocks.DepthwiseSeparableConv2d.depthwise"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "pointwise", "(", "self", ".", "depthwise", "(", "x", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops._do_paste_mask": [[19, 72], ["torch.split", "img_x[].expand", "img_y[].expand", "torch.stack", "torch.nn.functional.grid_sample", "torch.clamp().to", "torch.clamp().to", "torch.clamp().to", "torch.arange", "torch.arange", "img_y.size", "img_x.size", "img_y.size", "img_x.size", "torch.jit.is_scripting", "torch.stack.to", "torch.jit.is_scripting", "masks.float.float", "torch.jit.is_scripting", "torch.clamp", "torch.clamp", "torch.clamp", "slice", "slice", "boxes[].max().ceil", "boxes[].max().ceil", "boxes.min().values.floor", "boxes[].max", "boxes[].max", "boxes.min"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "_do_paste_mask", "(", "masks", ",", "boxes", ",", "img_h", ":", "int", ",", "img_w", ":", "int", ",", "skip_empty", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        masks: N, 1, H, W\n        boxes: N, 4\n        img_h, img_w (int):\n        skip_empty (bool): only paste masks within the region that\n            tightly bound all boxes, and returns the results this region only.\n            An important optimization for CPU.\n\n    Returns:\n        if skip_empty == False, a mask of shape (N, img_h, img_w)\n        if skip_empty == True, a mask of shape (N, h', w'), and the slice\n            object for the corresponding region.\n    \"\"\"", "\n", "# On GPU, paste all masks together (up to chunk size)", "\n", "# by using the entire image to sample the masks", "\n", "# Compared to pasting them one by one,", "\n", "# this has more operations but is faster on COCO-scale dataset.", "\n", "device", "=", "masks", ".", "device", "\n", "\n", "if", "skip_empty", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "x0_int", ",", "y0_int", "=", "torch", ".", "clamp", "(", "boxes", ".", "min", "(", "dim", "=", "0", ")", ".", "values", ".", "floor", "(", ")", "[", ":", "2", "]", "-", "1", ",", "min", "=", "0", ")", ".", "to", "(", "\n", "dtype", "=", "torch", ".", "int32", "\n", ")", "\n", "x1_int", "=", "torch", ".", "clamp", "(", "boxes", "[", ":", ",", "2", "]", ".", "max", "(", ")", ".", "ceil", "(", ")", "+", "1", ",", "max", "=", "img_w", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", "\n", "y1_int", "=", "torch", ".", "clamp", "(", "boxes", "[", ":", ",", "3", "]", ".", "max", "(", ")", ".", "ceil", "(", ")", "+", "1", ",", "max", "=", "img_h", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "x0_int", ",", "y0_int", "=", "0", ",", "0", "\n", "x1_int", ",", "y1_int", "=", "img_w", ",", "img_h", "\n", "", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "torch", ".", "split", "(", "boxes", ",", "1", ",", "dim", "=", "1", ")", "# each is Nx1", "\n", "\n", "N", "=", "masks", ".", "shape", "[", "0", "]", "\n", "\n", "img_y", "=", "torch", ".", "arange", "(", "y0_int", ",", "y1_int", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "+", "0.5", "\n", "img_x", "=", "torch", ".", "arange", "(", "x0_int", ",", "x1_int", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "+", "0.5", "\n", "img_y", "=", "(", "img_y", "-", "y0", ")", "/", "(", "y1", "-", "y0", ")", "*", "2", "-", "1", "\n", "img_x", "=", "(", "img_x", "-", "x0", ")", "/", "(", "x1", "-", "x0", ")", "*", "2", "-", "1", "\n", "# img_x, img_y have shapes (N, w), (N, h)", "\n", "\n", "gx", "=", "img_x", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "N", ",", "img_y", ".", "size", "(", "1", ")", ",", "img_x", ".", "size", "(", "1", ")", ")", "\n", "gy", "=", "img_y", "[", ":", ",", ":", ",", "None", "]", ".", "expand", "(", "N", ",", "img_y", ".", "size", "(", "1", ")", ",", "img_x", ".", "size", "(", "1", ")", ")", "\n", "grid", "=", "torch", ".", "stack", "(", "[", "gx", ",", "gy", "]", ",", "dim", "=", "3", ")", "\n", "\n", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "if", "not", "masks", ".", "dtype", ".", "is_floating_point", ":", "\n", "            ", "masks", "=", "masks", ".", "float", "(", ")", "\n", "", "", "img_masks", "=", "F", ".", "grid_sample", "(", "masks", ",", "grid", ".", "to", "(", "masks", ".", "dtype", ")", ",", "align_corners", "=", "False", ")", "\n", "\n", "if", "skip_empty", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "return", "img_masks", "[", ":", ",", "0", "]", ",", "(", "slice", "(", "y0_int", ",", "y1_int", ")", ",", "slice", "(", "x0_int", ",", "x1_int", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "img_masks", "[", ":", ",", "0", "]", ",", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops.paste_masks_in_image": [[74, 148], ["len", "torch.chunk", "torch.zeros", "masks.new_empty", "isinstance", "len", "torch.jit.is_scripting", "int", "torch.arange", "mask_ops._do_paste_mask", "torch.jit.is_scripting", "numpy.ceil", "int", "int"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops._do_paste_mask"], ["", "", "def", "paste_masks_in_image", "(", "\n", "masks", ":", "torch", ".", "Tensor", ",", "boxes", ":", "Boxes", ",", "image_shape", ":", "Tuple", "[", "int", ",", "int", "]", ",", "threshold", ":", "float", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Paste a set of masks that are of a fixed resolution (e.g., 28 x 28) into an image.\n    The location, height, and width for pasting each mask is determined by their\n    corresponding bounding boxes in boxes.\n\n    Note:\n        This is a complicated but more accurate implementation. In actual deployment, it is\n        often enough to use a faster but less accurate implementation.\n        See :func:`paste_mask_in_image_old` in this file for an alternative implementation.\n\n    Args:\n        masks (tensor): Tensor of shape (Bimg, Hmask, Wmask), where Bimg is the number of\n            detected object instances in the image and Hmask, Wmask are the mask width and mask\n            height of the predicted mask (e.g., Hmask = Wmask = 28). Values are in [0, 1].\n        boxes (Boxes or Tensor): A Boxes of length Bimg or Tensor of shape (Bimg, 4).\n            boxes[i] and masks[i] correspond to the same object instance.\n        image_shape (tuple): height, width\n        threshold (float): A threshold in [0, 1] for converting the (soft) masks to\n            binary masks.\n\n    Returns:\n        img_masks (Tensor): A tensor of shape (Bimg, Himage, Wimage), where Bimg is the\n        number of detected object instances and Himage, Wimage are the image width\n        and height. img_masks[i] is a binary mask for object instance i.\n    \"\"\"", "\n", "\n", "assert", "masks", ".", "shape", "[", "-", "1", "]", "==", "masks", ".", "shape", "[", "-", "2", "]", ",", "\"Only square mask predictions are supported\"", "\n", "N", "=", "len", "(", "masks", ")", "\n", "if", "N", "==", "0", ":", "\n", "        ", "return", "masks", ".", "new_empty", "(", "(", "0", ",", ")", "+", "image_shape", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "", "if", "not", "isinstance", "(", "boxes", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "boxes", "=", "boxes", ".", "tensor", "\n", "", "device", "=", "boxes", ".", "device", "\n", "assert", "len", "(", "boxes", ")", "==", "N", ",", "boxes", ".", "shape", "\n", "\n", "img_h", ",", "img_w", "=", "image_shape", "\n", "\n", "# The actual implementation split the input into chunks,", "\n", "# and paste them chunk by chunk.", "\n", "if", "device", ".", "type", "==", "\"cpu\"", "or", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "# CPU is most efficient when they are pasted one by one with skip_empty=True", "\n", "# so that it performs minimal number of operations.", "\n", "        ", "num_chunks", "=", "N", "\n", "", "else", ":", "\n", "# GPU benefits from parallelism for larger chunks, but may have memory issue", "\n", "# int(img_h) because shape may be tensors in tracing", "\n", "        ", "num_chunks", "=", "int", "(", "np", ".", "ceil", "(", "N", "*", "int", "(", "img_h", ")", "*", "int", "(", "img_w", ")", "*", "BYTES_PER_FLOAT", "/", "GPU_MEM_LIMIT", ")", ")", "\n", "assert", "(", "\n", "num_chunks", "<=", "N", "\n", ")", ",", "\"Default GPU_MEM_LIMIT in mask_ops.py is too small; try increasing it\"", "\n", "", "chunks", "=", "torch", ".", "chunk", "(", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", ",", "num_chunks", ")", "\n", "\n", "img_masks", "=", "torch", ".", "zeros", "(", "\n", "N", ",", "img_h", ",", "img_w", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "bool", "if", "threshold", ">=", "0", "else", "torch", ".", "uint8", "\n", ")", "\n", "for", "inds", "in", "chunks", ":", "\n", "        ", "masks_chunk", ",", "spatial_inds", "=", "_do_paste_mask", "(", "\n", "masks", "[", "inds", ",", "None", ",", ":", ",", ":", "]", ",", "boxes", "[", "inds", "]", ",", "img_h", ",", "img_w", ",", "skip_empty", "=", "device", ".", "type", "==", "\"cpu\"", "\n", ")", "\n", "\n", "if", "threshold", ">=", "0", ":", "\n", "            ", "masks_chunk", "=", "(", "masks_chunk", ">=", "threshold", ")", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", "\n", "", "else", ":", "\n", "# for visualization and debugging", "\n", "            ", "masks_chunk", "=", "(", "masks_chunk", "*", "255", ")", ".", "to", "(", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "# Scripting does not use the optimized codepath", "\n", "            ", "img_masks", "[", "inds", "]", "=", "masks_chunk", "\n", "", "else", ":", "\n", "            ", "img_masks", "[", "(", "inds", ",", ")", "+", "spatial_inds", "]", "=", "masks_chunk", "\n", "", "", "return", "img_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops.paste_mask_in_image_old": [[155, 208], ["box.to.to", "PIL.Image.fromarray", "torch.from_numpy().to.resize", "numpy.array", "torch.zeros", "max", "min", "max", "min", "torch.from_numpy().to.cpu().numpy", "numpy.array", "torch.from_numpy", "torch.from_numpy().to", "torch.from_numpy().to.cpu", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "paste_mask_in_image_old", "(", "mask", ",", "box", ",", "img_h", ",", "img_w", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"\n    Paste a single mask in an image.\n    This is a per-box implementation of :func:`paste_masks_in_image`.\n    This function has larger quantization error due to incorrect pixel\n    modeling and is not used any more.\n\n    Args:\n        mask (Tensor): A tensor of shape (Hmask, Wmask) storing the mask of a single\n            object instance. Values are in [0, 1].\n        box (Tensor): A tensor of shape (4, ) storing the x0, y0, x1, y1 box corners\n            of the object instance.\n        img_h, img_w (int): Image height and width.\n        threshold (float): Mask binarization threshold in [0, 1].\n\n    Returns:\n        im_mask (Tensor):\n            The resized and binarized object mask pasted into the original\n            image plane (a tensor of shape (img_h, img_w)).\n    \"\"\"", "\n", "# Conversion from continuous box coordinates to discrete pixel coordinates", "\n", "# via truncation (cast to int32). This determines which pixels to paste the", "\n", "# mask onto.", "\n", "box", "=", "box", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", "# Continuous to discrete coordinate conversion", "\n", "# An example (1D) box with continuous coordinates (x0=0.7, x1=4.3) will map to", "\n", "# a discrete coordinates (x0=0, x1=4). Note that box is mapped to 5 = x1 - x0 + 1", "\n", "# pixels (not x1 - x0 pixels).", "\n", "samples_w", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1", "# Number of pixel samples, *not* geometric width", "\n", "samples_h", "=", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1", "# Number of pixel samples, *not* geometric height", "\n", "\n", "# Resample the mask from it's original grid to the new samples_w x samples_h grid", "\n", "mask", "=", "Image", ".", "fromarray", "(", "mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "mask", "=", "mask", ".", "resize", "(", "(", "samples_w", ",", "samples_h", ")", ",", "resample", "=", "Image", ".", "BILINEAR", ")", "\n", "mask", "=", "np", ".", "array", "(", "mask", ",", "copy", "=", "False", ")", "\n", "\n", "if", "threshold", ">=", "0", ":", "\n", "        ", "mask", "=", "np", ".", "array", "(", "mask", ">", "threshold", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "", "else", ":", "\n", "# for visualization and debugging, we also", "\n", "# allow it to return an unmodified mask", "\n", "        ", "mask", "=", "torch", ".", "from_numpy", "(", "mask", "*", "255", ")", ".", "to", "(", "torch", ".", "uint8", ")", "\n", "\n", "", "im_mask", "=", "torch", ".", "zeros", "(", "(", "img_h", ",", "img_w", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "x_0", "=", "max", "(", "box", "[", "0", "]", ",", "0", ")", "\n", "x_1", "=", "min", "(", "box", "[", "2", "]", "+", "1", ",", "img_w", ")", "\n", "y_0", "=", "max", "(", "box", "[", "1", "]", ",", "0", ")", "\n", "y_1", "=", "min", "(", "box", "[", "3", "]", "+", "1", ",", "img_h", ")", "\n", "\n", "im_mask", "[", "y_0", ":", "y_1", ",", "x_0", ":", "x_1", "]", "=", "mask", "[", "\n", "(", "y_0", "-", "box", "[", "1", "]", ")", ":", "(", "y_1", "-", "box", "[", "1", "]", ")", ",", "(", "x_0", "-", "box", "[", "0", "]", ")", ":", "(", "x_1", "-", "box", "[", "0", "]", ")", "\n", "]", "\n", "return", "im_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops.pad_masks": [[219, 235], ["masks.new_zeros", "float"], "function", ["None"], ["", "def", "pad_masks", "(", "masks", ",", "padding", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        masks (tensor): A tensor of shape (B, M, M) representing B masks.\n        padding (int): Number of cells to pad on all sides.\n\n    Returns:\n        The padded masks and the scale factor of the padding size / original size.\n    \"\"\"", "\n", "B", "=", "masks", ".", "shape", "[", "0", "]", "\n", "M", "=", "masks", ".", "shape", "[", "-", "1", "]", "\n", "pad2", "=", "2", "*", "padding", "\n", "scale", "=", "float", "(", "M", "+", "pad2", ")", "/", "M", "\n", "padded_masks", "=", "masks", ".", "new_zeros", "(", "(", "B", ",", "M", "+", "pad2", ",", "M", "+", "pad2", ")", ")", "\n", "padded_masks", "[", ":", ",", "padding", ":", "-", "padding", ",", "padding", ":", "-", "padding", "]", "=", "masks", "\n", "return", "padded_masks", ",", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops.scale_boxes": [[237, 261], ["torch.zeros_like"], "function", ["None"], ["", "def", "scale_boxes", "(", "boxes", ",", "scale", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        boxes (tensor): A tensor of shape (B, 4) representing B boxes with 4\n            coords representing the corners x0, y0, x1, y1,\n        scale (float): The box scaling factor.\n\n    Returns:\n        Scaled boxes.\n    \"\"\"", "\n", "w_half", "=", "(", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", ")", "*", "0.5", "\n", "h_half", "=", "(", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", ")", "*", "0.5", "\n", "x_c", "=", "(", "boxes", "[", ":", ",", "2", "]", "+", "boxes", "[", ":", ",", "0", "]", ")", "*", "0.5", "\n", "y_c", "=", "(", "boxes", "[", ":", ",", "3", "]", "+", "boxes", "[", ":", ",", "1", "]", ")", "*", "0.5", "\n", "\n", "w_half", "*=", "scale", "\n", "h_half", "*=", "scale", "\n", "\n", "scaled_boxes", "=", "torch", ".", "zeros_like", "(", "boxes", ")", "\n", "scaled_boxes", "[", ":", ",", "0", "]", "=", "x_c", "-", "w_half", "\n", "scaled_boxes", "[", ":", ",", "2", "]", "=", "x_c", "+", "w_half", "\n", "scaled_boxes", "[", ":", ",", "1", "]", "=", "y_c", "-", "h_half", "\n", "scaled_boxes", "[", ":", ",", "3", "]", "=", "y_c", "+", "h_half", "\n", "return", "scaled_boxes", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d._load_from_state_dict": [[68, 92], ["local_metadata.get", "super()._load_from_state_dict", "logging.getLogger", "logging.getLogger.info", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "prefix.rstrip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.roi_heads.PointRendROIHeads._load_from_state_dict"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.__repr__": [[94, 96], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm": [[97, 129], ["isinstance", "cls", "module.named_children", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "cls.convert_frozen_batchnorm", "cls.add_module", "module.weight.data.clone", "module.bias.data.clone"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.NaiveSyncBatchNorm.__init__": [[187, 191], ["wrappers.BatchNorm2d.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.NaiveSyncBatchNorm.forward": [[192, 232], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "scale.reshape.reshape.reshape", "bias.reshape.reshape.reshape", "super().forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.split", "torch.split", "torch.split", "torch.split", "fvcore.nn.distributed.differentiable_all_reduce", "vec[].detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.split", "torch.split", "torch.split", "torch.split", "detectron2.utils.comm.get_world_size", "fvcore.nn.distributed.differentiable_all_reduce", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max.clamp", "torch.max.clamp", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.mean.detach", "torch.mean.detach", "var.detach", "torch.get_world_size", "torch.get_world_size", "input.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm": [[131, 157], ["isinstance", "norm", "len", "torch.nn.GroupNorm"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.shape_spec.ShapeSpec.__new__": [[19, 21], ["super().__new__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.shape_spec.ShapeSpec.__new__"], ["def", "__new__", "(", "cls", ",", "channels", "=", "None", ",", "height", "=", "None", ",", "width", "=", "None", ",", "stride", "=", "None", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__new__", "(", "cls", ",", "channels", ",", "height", ",", "width", ",", "stride", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align_rotated._ROIAlignRotated.forward": [[12, 23], ["ctx.save_for_backward", "torch.nn.modules.utils._pair", "input.size", "detectron2._C.roi_align_rotated_forward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "roi", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "roi", ")", "\n", "ctx", ".", "output_size", "=", "_pair", "(", "output_size", ")", "\n", "ctx", ".", "spatial_scale", "=", "spatial_scale", "\n", "ctx", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "ctx", ".", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "output", "=", "_C", ".", "roi_align_rotated_forward", "(", "\n", "input", ",", "roi", ",", "spatial_scale", ",", "output_size", "[", "0", "]", ",", "output_size", "[", "1", "]", ",", "sampling_ratio", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align_rotated._ROIAlignRotated.backward": [[24, 45], ["detectron2._C.roi_align_rotated_backward"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "(", "rois", ",", ")", "=", "ctx", ".", "saved_tensors", "\n", "output_size", "=", "ctx", ".", "output_size", "\n", "spatial_scale", "=", "ctx", ".", "spatial_scale", "\n", "sampling_ratio", "=", "ctx", ".", "sampling_ratio", "\n", "bs", ",", "ch", ",", "h", ",", "w", "=", "ctx", ".", "input_shape", "\n", "grad_input", "=", "_C", ".", "roi_align_rotated_backward", "(", "\n", "grad_output", ",", "\n", "rois", ",", "\n", "spatial_scale", ",", "\n", "output_size", "[", "0", "]", ",", "\n", "output_size", "[", "1", "]", ",", "\n", "bs", ",", "\n", "ch", ",", "\n", "h", ",", "\n", "w", ",", "\n", "sampling_ratio", ",", "\n", ")", "\n", "return", "grad_input", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align_rotated.ROIAlignRotated.__init__": [[51, 70], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "spatial_scale", ",", "sampling_ratio", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (tuple): h, w\n            spatial_scale (float): scale the input boxes by this number\n            sampling_ratio (int): number of inputs samples to take for each output\n                sample. 0 to take samples densely.\n\n        Note:\n            ROIAlignRotated supports continuous coordinate by default:\n            Given a continuous coordinate c, its two neighboring pixel indices (in our\n            pixel model) are computed by floor(c - 0.5) and ceil(c - 0.5). For example,\n            c=1.3 has pixel neighbors with discrete indices [0] and [1] (which are sampled\n            from the underlying signal at continuous coordinates 0.5 and 1.5).\n        \"\"\"", "\n", "super", "(", "ROIAlignRotated", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "spatial_scale", "=", "spatial_scale", "\n", "self", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align_rotated.ROIAlignRotated.forward": [[71, 86], ["roi_align_rotated().to", "input.float.float.float", "rois.float.float.float", "rois.float.float.dim", "rois.float.float.size", "roi_align_rotated"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "forward", "(", "self", ",", "input", ",", "rois", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: NCHW images\n            rois: Bx6 boxes. First column is the index into N.\n                The other 5 columns are (x_ctr, y_ctr, width, height, angle_degrees).\n        \"\"\"", "\n", "assert", "rois", ".", "dim", "(", ")", "==", "2", "and", "rois", ".", "size", "(", "1", ")", "==", "6", "\n", "orig_dtype", "=", "input", ".", "dtype", "\n", "if", "orig_dtype", "==", "torch", ".", "float16", ":", "\n", "            ", "input", "=", "input", ".", "float", "(", ")", "\n", "rois", "=", "rois", ".", "float", "(", ")", "\n", "", "return", "roi_align_rotated", "(", "\n", "input", ",", "rois", ",", "self", ".", "output_size", ",", "self", ".", "spatial_scale", ",", "self", ".", "sampling_ratio", "\n", ")", ".", "to", "(", "dtype", "=", "orig_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.roi_align_rotated.ROIAlignRotated.__repr__": [[87, 94], ["str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"output_size=\"", "+", "str", "(", "self", ".", "output_size", ")", "\n", "tmpstr", "+=", "\", spatial_scale=\"", "+", "str", "(", "self", ".", "spatial_scale", ")", "\n", "tmpstr", "+=", "\", sampling_ratio=\"", "+", "str", "(", "self", ".", "sampling_ratio", ")", "\n", "tmpstr", "+=", "\")\"", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.swap_align2nat._SwapAlign2Nat.forward": [[10, 17], ["X.size", "tensormask._C.swap_align2nat_forward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "X", ",", "lambda_val", ",", "pad_val", ")", ":", "\n", "        ", "ctx", ".", "lambda_val", "=", "lambda_val", "\n", "ctx", ".", "input_shape", "=", "X", ".", "size", "(", ")", "\n", "\n", "Y", "=", "_C", ".", "swap_align2nat_forward", "(", "X", ",", "lambda_val", ",", "pad_val", ")", "\n", "return", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.swap_align2nat._SwapAlign2Nat.backward": [[18, 27], ["tensormask._C.swap_align2nat_backward"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "gY", ")", ":", "\n", "        ", "lambda_val", "=", "ctx", ".", "lambda_val", "\n", "bs", ",", "ch", ",", "h", ",", "w", "=", "ctx", ".", "input_shape", "\n", "\n", "gX", "=", "_C", ".", "swap_align2nat_backward", "(", "gY", ",", "lambda_val", ",", "bs", ",", "ch", ",", "h", ",", "w", ")", "\n", "\n", "return", "gX", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.swap_align2nat.SwapAlign2Nat.__init__": [[48, 52], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "lambda_val", ",", "pad_val", "=", "-", "6.0", ")", ":", "\n", "        ", "super", "(", "SwapAlign2Nat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_val", "=", "lambda_val", "\n", "self", ".", "pad_val", "=", "pad_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.swap_align2nat.SwapAlign2Nat.forward": [[53, 55], ["swap_align2nat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "return", "swap_align2nat", "(", "X", ",", "self", ".", "lambda_val", ",", "self", ".", "pad_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.swap_align2nat.SwapAlign2Nat.__repr__": [[56, 62], ["str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "tmpstr", "+=", "\"lambda_val=\"", "+", "str", "(", "self", ".", "lambda_val", ")", "\n", "tmpstr", "+=", "\", pad_val=\"", "+", "str", "(", "self", ".", "pad_val", ")", "\n", "tmpstr", "+=", "\")\"", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.DeformConvFunction.forward": [[10, 68], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "ctx.save_for_backward", "input.new_empty", "ValueError", "deform_conv_func.DeformConvFunction._output_size", "input.new_empty", "input.new_empty", "min", "fcos_core._C.deform_conv_forward", "input.dim", "weight.size", "weight.size", "input.dim"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.DeformConvFunction._output_size"], ["\n", "    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "input", ",", "\n", "offset", ",", "\n", "weight", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "im2col_step", "=", "64", "\n", ")", ":", "\n", "        ", "if", "input", "is", "not", "None", "and", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected 4D tensor as input, got {}D tensor instead.\"", ".", "format", "(", "\n", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "ctx", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "ctx", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "ctx", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "ctx", ".", "groups", "=", "groups", "\n", "ctx", ".", "deformable_groups", "=", "deformable_groups", "\n", "ctx", ".", "im2col_step", "=", "im2col_step", "\n", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "offset", ",", "weight", ")", "\n", "\n", "output", "=", "input", ".", "new_empty", "(", "\n", "DeformConvFunction", ".", "_output_size", "(", "input", ",", "weight", ",", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "ctx", ".", "stride", ")", ")", "\n", "\n", "ctx", ".", "bufs_", "=", "[", "input", ".", "new_empty", "(", "0", ")", ",", "input", ".", "new_empty", "(", "0", ")", "]", "# columns, ones", "\n", "\n", "if", "not", "input", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "cur_im2col_step", "=", "min", "(", "ctx", ".", "im2col_step", ",", "input", ".", "shape", "[", "0", "]", ")", "\n", "assert", "(", "input", ".", "shape", "[", "0", "]", "%", "\n", "cur_im2col_step", ")", "==", "0", ",", "'im2col step must divide batchsize'", "\n", "_C", ".", "deform_conv_forward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "offset", ",", "\n", "output", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "ctx", ".", "bufs_", "[", "1", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "cur_im2col_step", "\n", ")", "\n", "", "return", "output", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.DeformConvFunction.backward": [[69, 131], ["min", "torch.zeros_like", "torch.zeros_like", "fcos_core._C.deform_conv_backward_input", "torch.zeros_like", "fcos_core._C.deform_conv_backward_parameters", "weight.size", "weight.size", "weight.size", "weight.size"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "offset", ",", "weight", "=", "ctx", ".", "saved_tensors", "\n", "\n", "grad_input", "=", "grad_offset", "=", "grad_weight", "=", "None", "\n", "\n", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "cur_im2col_step", "=", "min", "(", "ctx", ".", "im2col_step", ",", "input", ".", "shape", "[", "0", "]", ")", "\n", "assert", "(", "input", ".", "shape", "[", "0", "]", "%", "\n", "cur_im2col_step", ")", "==", "0", ",", "'im2col step must divide batchsize'", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", "or", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "                ", "grad_input", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "_C", ".", "deform_conv_backward_input", "(", "\n", "input", ",", "\n", "offset", ",", "\n", "grad_output", ",", "\n", "grad_input", ",", "\n", "grad_offset", ",", "\n", "weight", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "cur_im2col_step", "\n", ")", "\n", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "2", "]", ":", "\n", "                ", "grad_weight", "=", "torch", ".", "zeros_like", "(", "weight", ")", "\n", "_C", ".", "deform_conv_backward_parameters", "(", "\n", "input", ",", "\n", "offset", ",", "\n", "grad_output", ",", "\n", "grad_weight", ",", "\n", "ctx", ".", "bufs_", "[", "0", "]", ",", "\n", "ctx", ".", "bufs_", "[", "1", "]", ",", "\n", "weight", ".", "size", "(", "3", ")", ",", "\n", "weight", ".", "size", "(", "2", ")", ",", "\n", "ctx", ".", "stride", "[", "1", "]", ",", "\n", "ctx", ".", "stride", "[", "0", "]", ",", "\n", "ctx", ".", "padding", "[", "1", "]", ",", "\n", "ctx", ".", "padding", "[", "0", "]", ",", "\n", "ctx", ".", "dilation", "[", "1", "]", ",", "\n", "ctx", ".", "dilation", "[", "0", "]", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "1", ",", "\n", "cur_im2col_step", "\n", ")", "\n", "\n", "", "", "return", "(", "grad_input", ",", "grad_offset", ",", "grad_weight", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.DeformConvFunction._output_size": [[132, 147], ["weight.size", "range", "input.size", "input.size", "all", "ValueError", "input.dim", "map", "weight.size", "map"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "def", "_output_size", "(", "input", ",", "weight", ",", "padding", ",", "dilation", ",", "stride", ")", ":", "\n", "        ", "channels", "=", "weight", ".", "size", "(", "0", ")", "\n", "output_size", "=", "(", "input", ".", "size", "(", "0", ")", ",", "channels", ")", "\n", "for", "d", "in", "range", "(", "input", ".", "dim", "(", ")", "-", "2", ")", ":", "\n", "            ", "in_size", "=", "input", ".", "size", "(", "d", "+", "2", ")", "\n", "pad", "=", "padding", "[", "d", "]", "\n", "kernel", "=", "dilation", "[", "d", "]", "*", "(", "weight", ".", "size", "(", "d", "+", "2", ")", "-", "1", ")", "+", "1", "\n", "stride_", "=", "stride", "[", "d", "]", "\n", "output_size", "+=", "(", "(", "in_size", "+", "(", "2", "*", "pad", ")", "-", "kernel", ")", "//", "stride_", "+", "1", ",", ")", "\n", "", "if", "not", "all", "(", "map", "(", "lambda", "s", ":", "s", ">", "0", ",", "output_size", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"convolution input is too small (output would be {})\"", ".", "format", "(", "\n", "'x'", ".", "join", "(", "map", "(", "str", ",", "output_size", ")", ")", ")", ")", "\n", "", "return", "output_size", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.ModulatedDeformConvFunction.forward": [[151, 203], ["input.new_empty", "fcos_core._C.modulated_deform_conv_forward", "input.new_empty", "ctx.save_for_backward", "deform_conv_func.ModulatedDeformConvFunction._infer_shape", "input.new_empty", "input.new_empty"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.ModulatedDeformConvFunction._infer_shape"], ["\n", "    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "input", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "weight", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", "\n", ")", ":", "\n", "        ", "ctx", ".", "stride", "=", "stride", "\n", "ctx", ".", "padding", "=", "padding", "\n", "ctx", ".", "dilation", "=", "dilation", "\n", "ctx", ".", "groups", "=", "groups", "\n", "ctx", ".", "deformable_groups", "=", "deformable_groups", "\n", "ctx", ".", "with_bias", "=", "bias", "is", "not", "None", "\n", "if", "not", "ctx", ".", "with_bias", ":", "\n", "            ", "bias", "=", "input", ".", "new_empty", "(", "1", ")", "# fake tensor", "\n", "", "if", "not", "input", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "weight", ".", "requires_grad", "or", "mask", ".", "requires_grad", "or", "offset", ".", "requires_grad", "or", "input", ".", "requires_grad", ":", "\n", "            ", "ctx", ".", "save_for_backward", "(", "input", ",", "offset", ",", "mask", ",", "weight", ",", "bias", ")", "\n", "", "output", "=", "input", ".", "new_empty", "(", "\n", "ModulatedDeformConvFunction", ".", "_infer_shape", "(", "ctx", ",", "input", ",", "weight", ")", ")", "\n", "ctx", ".", "_bufs", "=", "[", "input", ".", "new_empty", "(", "0", ")", ",", "input", ".", "new_empty", "(", "0", ")", "]", "\n", "_C", ".", "modulated_deform_conv_forward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", ",", "\n", "ctx", ".", "_bufs", "[", "0", "]", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "output", ",", "\n", "ctx", ".", "_bufs", "[", "1", "]", ",", "\n", "weight", ".", "shape", "[", "2", "]", ",", "\n", "weight", ".", "shape", "[", "3", "]", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "ctx", ".", "with_bias", "\n", ")", "\n", "return", "output", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.ModulatedDeformConvFunction.backward": [[204, 246], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "fcos_core._C.modulated_deform_conv_backward"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "input", ",", "offset", ",", "mask", ",", "weight", ",", "bias", "=", "ctx", ".", "saved_tensors", "\n", "grad_input", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "grad_mask", "=", "torch", ".", "zeros_like", "(", "mask", ")", "\n", "grad_weight", "=", "torch", ".", "zeros_like", "(", "weight", ")", "\n", "grad_bias", "=", "torch", ".", "zeros_like", "(", "bias", ")", "\n", "_C", ".", "modulated_deform_conv_backward", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", ",", "\n", "ctx", ".", "_bufs", "[", "0", "]", ",", "\n", "offset", ",", "\n", "mask", ",", "\n", "ctx", ".", "_bufs", "[", "1", "]", ",", "\n", "grad_input", ",", "\n", "grad_weight", ",", "\n", "grad_bias", ",", "\n", "grad_offset", ",", "\n", "grad_mask", ",", "\n", "grad_output", ",", "\n", "weight", ".", "shape", "[", "2", "]", ",", "\n", "weight", ".", "shape", "[", "3", "]", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "stride", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "padding", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "dilation", ",", "\n", "ctx", ".", "groups", ",", "\n", "ctx", ".", "deformable_groups", ",", "\n", "ctx", ".", "with_bias", "\n", ")", "\n", "if", "not", "ctx", ".", "with_bias", ":", "\n", "            ", "grad_bias", "=", "None", "\n", "\n", "", "return", "(", "grad_input", ",", "grad_offset", ",", "grad_mask", ",", "grad_weight", ",", "grad_bias", ",", "\n", "None", ",", "None", ",", "None", ",", "None", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_func.ModulatedDeformConvFunction._infer_shape": [[247, 258], ["input.size", "weight.size"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "def", "_infer_shape", "(", "ctx", ",", "input", ",", "weight", ")", ":", "\n", "        ", "n", "=", "input", ".", "size", "(", "0", ")", "\n", "channels_out", "=", "weight", ".", "size", "(", "0", ")", "\n", "height", ",", "width", "=", "input", ".", "shape", "[", "2", ":", "4", "]", "\n", "kernel_h", ",", "kernel_w", "=", "weight", ".", "shape", "[", "2", ":", "4", "]", "\n", "height_out", "=", "(", "height", "+", "2", "*", "ctx", ".", "padding", "-", "\n", "(", "ctx", ".", "dilation", "*", "(", "kernel_h", "-", "1", ")", "+", "1", ")", ")", "//", "ctx", ".", "stride", "+", "1", "\n", "width_out", "=", "(", "width", "+", "2", "*", "ctx", ".", "padding", "-", "\n", "(", "ctx", ".", "dilation", "*", "(", "kernel_w", "-", "1", ")", "+", "1", ")", ")", "//", "ctx", ".", "stride", "+", "1", "\n", "return", "n", ",", "channels_out", ",", "height_out", ",", "width_out", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.DeformConv.__init__": [[11, 48], ["torch.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.Parameter", "torch.Parameter", "deform_conv_module.DeformConv.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.reset_parameters"], ["\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "False", "\n", ")", ":", "\n", "        ", "assert", "not", "bias", "\n", "super", "(", "DeformConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "with_bias", "=", "bias", "\n", "\n", "assert", "in_channels", "%", "groups", "==", "0", ",", "'in_channels {} cannot be divisible by groups {}'", ".", "format", "(", "\n", "in_channels", ",", "groups", ")", "\n", "assert", "out_channels", "%", "groups", "==", "0", ",", "'out_channels {} cannot be divisible by groups {}'", ".", "format", "(", "\n", "out_channels", ",", "groups", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "self", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "self", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "deformable_groups", "=", "deformable_groups", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "self", ".", "groups", ",", "\n", "*", "self", ".", "kernel_size", ")", ")", "\n", "if", "self", ".", "with_bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.DeformConv.reset_parameters": [[49, 57], ["deform_conv_module.DeformConv.weight.data.uniform_", "math.sqrt", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "n", "=", "self", ".", "in_channels", "\n", "for", "k", "in", "self", ".", "kernel_size", ":", "\n", "            ", "n", "*=", "k", "\n", "", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "n", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "if", "self", ".", "with_bias", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.DeformConv.forward": [[58, 66], ["deform_conv_func.deform_conv", "len", "deform_conv_module.DeformConv.bias.reshape", "deform_conv_func.deform_conv.size"], "methods", ["None"], ["            ", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input", ",", "offset", ")", ":", "\n", "        ", "y", "=", "deform_conv", "(", "input", ",", "offset", ",", "self", ".", "weight", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ",", "\n", "self", ".", "deformable_groups", ")", "\n", "if", "self", ".", "with_bias", ":", "\n", "            ", "assert", "len", "(", "y", ".", "size", "(", ")", ")", "==", "4", "\n", "y", "=", "y", "+", "self", ".", "bias", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.DeformConv.__repr__": [[67, 79], ["None"], "methods", ["None"], ["", "return", "y", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", ".", "join", "(", "[", "\n", "\"{}(\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", ",", "\n", "\"in_channels={}, \"", ".", "format", "(", "self", ".", "in_channels", ")", ",", "\n", "\"out_channels={}, \"", ".", "format", "(", "self", ".", "out_channels", ")", ",", "\n", "\"kernel_size={}, \"", ".", "format", "(", "self", ".", "kernel_size", ")", ",", "\n", "\"stride={}, \"", ".", "format", "(", "self", ".", "stride", ")", ",", "\n", "\"dilation={}, \"", ".", "format", "(", "self", ".", "dilation", ")", ",", "\n", "\"padding={}, \"", ".", "format", "(", "self", ".", "padding", ")", ",", "\n", "\"groups={}, \"", ".", "format", "(", "self", ".", "groups", ")", ",", "\n", "\"deformable_groups={}, \"", ".", "format", "(", "self", ".", "deformable_groups", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConv.__init__": [[83, 116], ["torch.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.Parameter", "torch.Parameter", "deform_conv_module.ModulatedDeformConv.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "deform_conv_module.ModulatedDeformConv.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.reset_parameters"], ["\n", "", "", "class", "ModulatedDeformConv", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", "ModulatedDeformConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "deformable_groups", "=", "deformable_groups", "\n", "self", ".", "with_bias", "=", "bias", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "out_channels", ",", "\n", "in_channels", "//", "groups", ",", "\n", "*", "self", ".", "kernel_size", "\n", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConv.reset_parameters": [[117, 125], ["deform_conv_module.ModulatedDeformConv.weight.data.uniform_", "math.sqrt", "deform_conv_module.ModulatedDeformConv.bias.data.zero_"], "methods", ["None"], ["            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "n", "=", "self", ".", "in_channels", "\n", "for", "k", "in", "self", ".", "kernel_size", ":", "\n", "            ", "n", "*=", "k", "\n", "", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "n", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConv.forward": [[126, 130], ["deform_conv_func.modulated_deform_conv"], "methods", ["None"], ["if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input", ",", "offset", ",", "mask", ")", ":", "\n", "        ", "return", "modulated_deform_conv", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConv.__repr__": [[131, 143], ["None"], "methods", ["None"], ["input", ",", "offset", ",", "mask", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ",", "self", ".", "deformable_groups", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", ".", "join", "(", "[", "\n", "\"{}(\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", ",", "\n", "\"in_channels={}, \"", ".", "format", "(", "self", ".", "in_channels", ")", ",", "\n", "\"out_channels={}, \"", ".", "format", "(", "self", ".", "out_channels", ")", ",", "\n", "\"kernel_size={}, \"", ".", "format", "(", "self", ".", "kernel_size", ")", ",", "\n", "\"stride={}, \"", ".", "format", "(", "self", ".", "stride", ")", ",", "\n", "\"dilation={}, \"", ".", "format", "(", "self", ".", "dilation", ")", ",", "\n", "\"padding={}, \"", ".", "format", "(", "self", ".", "padding", ")", ",", "\n", "\"groups={}, \"", ".", "format", "(", "self", ".", "groups", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConvPack.__init__": [[147, 170], ["deform_conv_module.ModulatedDeformConv.__init__", "torch.Conv2d", "torch.Conv2d", "deform_conv_module.ModulatedDeformConvPack.init_offset", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConvPack.init_offset"], ["\n", "", "", "class", "ModulatedDeformConvPack", "(", "ModulatedDeformConv", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "ModulatedDeformConvPack", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "\n", "groups", ",", "deformable_groups", ",", "bias", ")", "\n", "\n", "self", ".", "conv_offset_mask", "=", "nn", ".", "Conv2d", "(", "\n", "self", ".", "in_channels", "//", "self", ".", "groups", ",", "\n", "self", ".", "deformable_groups", "*", "3", "*", "self", ".", "kernel_size", "[", "0", "]", "*", "\n", "self", ".", "kernel_size", "[", "1", "]", ",", "\n", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "stride", "=", "_pair", "(", "self", ".", "stride", ")", ",", "\n", "padding", "=", "_pair", "(", "self", ".", "padding", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConvPack.init_offset": [[171, 174], ["deform_conv_module.ModulatedDeformConvPack.conv_offset_mask.weight.data.zero_", "deform_conv_module.ModulatedDeformConvPack.conv_offset_mask.bias.data.zero_"], "methods", ["None"], ["bias", "=", "True", ")", "\n", "self", ".", "init_offset", "(", ")", "\n", "\n", "", "def", "init_offset", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_conv_module.ModulatedDeformConvPack.forward": [[175, 183], ["deform_conv_module.ModulatedDeformConvPack.conv_offset_mask", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "deform_conv_func.modulated_deform_conv"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["        ", "self", ".", "conv_offset_mask", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "conv_offset_mask", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv_offset_mask", "(", "input", ")", "\n", "o1", ",", "o2", ",", "mask", "=", "torch", ".", "chunk", "(", "out", ",", "3", ",", "dim", "=", "1", ")", "\n", "offset", "=", "torch", ".", "cat", "(", "(", "o1", ",", "o2", ")", ",", "dim", "=", "1", ")", "\n", "mask", "=", "torch", ".", "sigmoid", "(", "mask", ")", "\n", "return", "modulated_deform_conv", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_module.DeformRoIPooling.__init__": [[8, 26], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spatial_scale", ",", "\n", "out_size", ",", "\n", "out_channels", ",", "\n", "no_trans", ",", "\n", "group_size", "=", "1", ",", "\n", "part_size", "=", "None", ",", "\n", "sample_per_part", "=", "4", ",", "\n", "trans_std", "=", ".0", ")", ":", "\n", "        ", "super", "(", "DeformRoIPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "spatial_scale", "=", "spatial_scale", "\n", "self", ".", "out_size", "=", "out_size", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "no_trans", "=", "no_trans", "\n", "self", ".", "group_size", "=", "group_size", "\n", "self", ".", "part_size", "=", "out_size", "if", "part_size", "is", "None", "else", "part_size", "\n", "self", ".", "sample_per_part", "=", "sample_per_part", "\n", "self", ".", "trans_std", "=", "trans_std", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_module.DeformRoIPooling.forward": [[27, 34], ["deform_pool_func.deform_roi_pooling", "data.new_empty"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "data", ",", "rois", ",", "offset", ")", ":", "\n", "        ", "if", "self", ".", "no_trans", ":", "\n", "            ", "offset", "=", "data", ".", "new_empty", "(", "0", ")", "\n", "", "return", "deform_roi_pooling", "(", "\n", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "self", ".", "out_size", ",", "\n", "self", ".", "out_channels", ",", "self", ".", "no_trans", ",", "self", ".", "group_size", ",", "self", ".", "part_size", ",", "\n", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_module.DeformRoIPoolingPack.__init__": [[38, 65], ["deform_pool_module.DeformRoIPooling.__init__", "torch.nn.Sequential", "deform_pool_module.DeformRoIPoolingPack.offset_fc[].weight.data.zero_", "deform_pool_module.DeformRoIPoolingPack.offset_fc[].bias.data.zero_", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spatial_scale", ",", "\n", "out_size", ",", "\n", "out_channels", ",", "\n", "no_trans", ",", "\n", "group_size", "=", "1", ",", "\n", "part_size", "=", "None", ",", "\n", "sample_per_part", "=", "4", ",", "\n", "trans_std", "=", ".0", ",", "\n", "deform_fc_channels", "=", "1024", ")", ":", "\n", "        ", "super", "(", "DeformRoIPoolingPack", ",", "\n", "self", ")", ".", "__init__", "(", "spatial_scale", ",", "out_size", ",", "out_channels", ",", "no_trans", ",", "\n", "group_size", ",", "part_size", ",", "sample_per_part", ",", "trans_std", ")", "\n", "\n", "self", ".", "deform_fc_channels", "=", "deform_fc_channels", "\n", "\n", "if", "not", "no_trans", ":", "\n", "            ", "self", ".", "offset_fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "out_size", "*", "self", ".", "out_size", "*", "self", ".", "out_channels", ",", "\n", "self", ".", "deform_fc_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "deform_fc_channels", ",", "self", ".", "deform_fc_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "deform_fc_channels", ",", "\n", "self", ".", "out_size", "*", "self", ".", "out_size", "*", "2", ")", ")", "\n", "self", ".", "offset_fc", "[", "-", "1", "]", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "offset_fc", "[", "-", "1", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_module.DeformRoIPoolingPack.forward": [[66, 87], ["data.size", "data.new_empty", "deform_pool_func.deform_roi_pooling", "data.new_empty", "deform_pool_func.deform_roi_pooling", "deform_pool_module.DeformRoIPoolingPack.offset_fc", "offset.view.view.view", "deform_pool_func.deform_roi_pooling", "deform_pool_func.deform_roi_pooling.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "data", ",", "rois", ")", ":", "\n", "        ", "assert", "data", ".", "size", "(", "1", ")", "==", "self", ".", "out_channels", "\n", "if", "self", ".", "no_trans", ":", "\n", "            ", "offset", "=", "data", ".", "new_empty", "(", "0", ")", "\n", "return", "deform_roi_pooling", "(", "\n", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "self", ".", "out_size", ",", "\n", "self", ".", "out_channels", ",", "self", ".", "no_trans", ",", "self", ".", "group_size", ",", "\n", "self", ".", "part_size", ",", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "rois", ".", "shape", "[", "0", "]", "\n", "offset", "=", "data", ".", "new_empty", "(", "0", ")", "\n", "x", "=", "deform_roi_pooling", "(", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "\n", "self", ".", "out_size", ",", "self", ".", "out_channels", ",", "True", ",", "\n", "self", ".", "group_size", ",", "self", ".", "part_size", ",", "\n", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "\n", "offset", "=", "self", ".", "offset_fc", "(", "x", ".", "view", "(", "n", ",", "-", "1", ")", ")", "\n", "offset", "=", "offset", ".", "view", "(", "n", ",", "2", ",", "self", ".", "out_size", ",", "self", ".", "out_size", ")", "\n", "return", "deform_roi_pooling", "(", "\n", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "self", ".", "out_size", ",", "\n", "self", ".", "out_channels", ",", "self", ".", "no_trans", ",", "self", ".", "group_size", ",", "\n", "self", ".", "part_size", ",", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_module.ModulatedDeformRoIPoolingPack.__init__": [[91, 127], ["deform_pool_module.DeformRoIPooling.__init__", "torch.nn.Sequential", "deform_pool_module.ModulatedDeformRoIPoolingPack.offset_fc[].weight.data.zero_", "deform_pool_module.ModulatedDeformRoIPoolingPack.offset_fc[].bias.data.zero_", "torch.nn.Sequential", "deform_pool_module.ModulatedDeformRoIPoolingPack.mask_fc[].weight.data.zero_", "deform_pool_module.ModulatedDeformRoIPoolingPack.mask_fc[].bias.data.zero_", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spatial_scale", ",", "\n", "out_size", ",", "\n", "out_channels", ",", "\n", "no_trans", ",", "\n", "group_size", "=", "1", ",", "\n", "part_size", "=", "None", ",", "\n", "sample_per_part", "=", "4", ",", "\n", "trans_std", "=", ".0", ",", "\n", "deform_fc_channels", "=", "1024", ")", ":", "\n", "        ", "super", "(", "ModulatedDeformRoIPoolingPack", ",", "self", ")", ".", "__init__", "(", "\n", "spatial_scale", ",", "out_size", ",", "out_channels", ",", "no_trans", ",", "group_size", ",", "\n", "part_size", ",", "sample_per_part", ",", "trans_std", ")", "\n", "\n", "self", ".", "deform_fc_channels", "=", "deform_fc_channels", "\n", "\n", "if", "not", "no_trans", ":", "\n", "            ", "self", ".", "offset_fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "out_size", "*", "self", ".", "out_size", "*", "self", ".", "out_channels", ",", "\n", "self", ".", "deform_fc_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "deform_fc_channels", ",", "self", ".", "deform_fc_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "deform_fc_channels", ",", "\n", "self", ".", "out_size", "*", "self", ".", "out_size", "*", "2", ")", ")", "\n", "self", ".", "offset_fc", "[", "-", "1", "]", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "offset_fc", "[", "-", "1", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "mask_fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "out_size", "*", "self", ".", "out_size", "*", "self", ".", "out_channels", ",", "\n", "self", ".", "deform_fc_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "deform_fc_channels", ",", "\n", "self", ".", "out_size", "*", "self", ".", "out_size", "*", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "self", ".", "mask_fc", "[", "2", "]", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "mask_fc", "[", "2", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_module.ModulatedDeformRoIPoolingPack.forward": [[128, 151], ["data.size", "data.new_empty", "deform_pool_func.deform_roi_pooling", "data.new_empty", "deform_pool_func.deform_roi_pooling", "deform_pool_module.ModulatedDeformRoIPoolingPack.offset_fc", "offset.view.view.view", "deform_pool_module.ModulatedDeformRoIPoolingPack.mask_fc", "mask.view.view.view", "deform_pool_func.deform_roi_pooling.view", "deform_pool_func.deform_roi_pooling.view", "deform_pool_func.deform_roi_pooling"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "data", ",", "rois", ")", ":", "\n", "        ", "assert", "data", ".", "size", "(", "1", ")", "==", "self", ".", "out_channels", "\n", "if", "self", ".", "no_trans", ":", "\n", "            ", "offset", "=", "data", ".", "new_empty", "(", "0", ")", "\n", "return", "deform_roi_pooling", "(", "\n", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "self", ".", "out_size", ",", "\n", "self", ".", "out_channels", ",", "self", ".", "no_trans", ",", "self", ".", "group_size", ",", "\n", "self", ".", "part_size", ",", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "rois", ".", "shape", "[", "0", "]", "\n", "offset", "=", "data", ".", "new_empty", "(", "0", ")", "\n", "x", "=", "deform_roi_pooling", "(", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "\n", "self", ".", "out_size", ",", "self", ".", "out_channels", ",", "True", ",", "\n", "self", ".", "group_size", ",", "self", ".", "part_size", ",", "\n", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "\n", "offset", "=", "self", ".", "offset_fc", "(", "x", ".", "view", "(", "n", ",", "-", "1", ")", ")", "\n", "offset", "=", "offset", ".", "view", "(", "n", ",", "2", ",", "self", ".", "out_size", ",", "self", ".", "out_size", ")", "\n", "mask", "=", "self", ".", "mask_fc", "(", "x", ".", "view", "(", "n", ",", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "view", "(", "n", ",", "1", ",", "self", ".", "out_size", ",", "self", ".", "out_size", ")", "\n", "return", "deform_roi_pooling", "(", "\n", "data", ",", "rois", ",", "offset", ",", "self", ".", "spatial_scale", ",", "self", ".", "out_size", ",", "\n", "self", ".", "out_channels", ",", "self", ".", "no_trans", ",", "self", ".", "group_size", ",", "\n", "self", ".", "part_size", ",", "self", ".", "sample_per_part", ",", "self", ".", "trans_std", ")", "*", "mask", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_func.DeformRoIPoolingFunction.forward": [[10, 62], ["data.new_empty", "data.new_empty", "fcos_core._C.deform_psroi_pooling_forward", "ctx.save_for_backward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "\n", "data", ",", "\n", "rois", ",", "\n", "offset", ",", "\n", "spatial_scale", ",", "\n", "out_size", ",", "\n", "out_channels", ",", "\n", "no_trans", ",", "\n", "group_size", "=", "1", ",", "\n", "part_size", "=", "None", ",", "\n", "sample_per_part", "=", "4", ",", "\n", "trans_std", "=", ".0", "\n", ")", ":", "\n", "        ", "ctx", ".", "spatial_scale", "=", "spatial_scale", "\n", "ctx", ".", "out_size", "=", "out_size", "\n", "ctx", ".", "out_channels", "=", "out_channels", "\n", "ctx", ".", "no_trans", "=", "no_trans", "\n", "ctx", ".", "group_size", "=", "group_size", "\n", "ctx", ".", "part_size", "=", "out_size", "if", "part_size", "is", "None", "else", "part_size", "\n", "ctx", ".", "sample_per_part", "=", "sample_per_part", "\n", "ctx", ".", "trans_std", "=", "trans_std", "\n", "\n", "assert", "0.0", "<=", "ctx", ".", "trans_std", "<=", "1.0", "\n", "if", "not", "data", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "n", "=", "rois", ".", "shape", "[", "0", "]", "\n", "output", "=", "data", ".", "new_empty", "(", "n", ",", "out_channels", ",", "out_size", ",", "out_size", ")", "\n", "output_count", "=", "data", ".", "new_empty", "(", "n", ",", "out_channels", ",", "out_size", ",", "out_size", ")", "\n", "_C", ".", "deform_psroi_pooling_forward", "(", "\n", "data", ",", "\n", "rois", ",", "\n", "offset", ",", "\n", "output", ",", "\n", "output_count", ",", "\n", "ctx", ".", "no_trans", ",", "\n", "ctx", ".", "spatial_scale", ",", "\n", "ctx", ".", "out_channels", ",", "\n", "ctx", ".", "group_size", ",", "\n", "ctx", ".", "out_size", ",", "\n", "ctx", ".", "part_size", ",", "\n", "ctx", ".", "sample_per_part", ",", "\n", "ctx", ".", "trans_std", "\n", ")", "\n", "\n", "if", "data", ".", "requires_grad", "or", "rois", ".", "requires_grad", "or", "offset", ".", "requires_grad", ":", "\n", "            ", "ctx", ".", "save_for_backward", "(", "data", ",", "rois", ",", "offset", ")", "\n", "", "ctx", ".", "output_count", "=", "output_count", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_func.DeformRoIPoolingFunction.backward": [[63, 93], ["torch.zeros_like", "torch.zeros_like", "fcos_core._C.deform_psroi_pooling_backward"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "once_differentiable", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "if", "not", "grad_output", ".", "is_cuda", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "data", ",", "rois", ",", "offset", "=", "ctx", ".", "saved_tensors", "\n", "output_count", "=", "ctx", ".", "output_count", "\n", "grad_input", "=", "torch", ".", "zeros_like", "(", "data", ")", "\n", "grad_rois", "=", "None", "\n", "grad_offset", "=", "torch", ".", "zeros_like", "(", "offset", ")", "\n", "\n", "_C", ".", "deform_psroi_pooling_backward", "(", "\n", "grad_output", ",", "\n", "data", ",", "\n", "rois", ",", "\n", "offset", ",", "\n", "output_count", ",", "\n", "grad_input", ",", "\n", "grad_offset", ",", "\n", "ctx", ".", "no_trans", ",", "\n", "ctx", ".", "spatial_scale", ",", "\n", "ctx", ".", "out_channels", ",", "\n", "ctx", ".", "group_size", ",", "\n", "ctx", ".", "out_size", ",", "\n", "ctx", ".", "part_size", ",", "\n", "ctx", ".", "sample_per_part", ",", "\n", "ctx", ".", "trans_std", "\n", ")", "\n", "return", "(", "grad_input", ",", "grad_rois", ",", "grad_offset", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug.im_detect_bbox_aug": [[11, 71], ["range", "bbox_aug.im_detect_bbox", "bbox_aug.im_detect_bbox_aug.add_preds_t"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox"], ["def", "im_detect_bbox_aug", "(", "model", ",", "images", ",", "device", ")", ":", "\n", "# Collect detections computed under different transformations", "\n", "    ", "boxlists_ts", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "len", "(", "images", ")", ")", ":", "\n", "        ", "boxlists_ts", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "def", "add_preds_t", "(", "boxlists_t", ")", ":", "\n", "        ", "for", "i", ",", "boxlist_t", "in", "enumerate", "(", "boxlists_t", ")", ":", "\n", "            ", "if", "len", "(", "boxlists_ts", "[", "i", "]", ")", "==", "0", ":", "\n", "# The first one is identity transform, no need to resize the boxlist", "\n", "                ", "boxlists_ts", "[", "i", "]", ".", "append", "(", "boxlist_t", ")", "\n", "", "else", ":", "\n", "# Resize the boxlist as the first one", "\n", "                ", "boxlists_ts", "[", "i", "]", ".", "append", "(", "boxlist_t", ".", "resize", "(", "boxlists_ts", "[", "i", "]", "[", "0", "]", ".", "size", ")", ")", "\n", "\n", "# Compute detections for the original image (identity transform)", "\n", "", "", "", "boxlists_i", "=", "im_detect_bbox", "(", "\n", "model", ",", "images", ",", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", ",", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", ",", "device", "\n", ")", "\n", "add_preds_t", "(", "boxlists_i", ")", "\n", "\n", "# Perform detection on the horizontally flipped image", "\n", "if", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "H_FLIP", ":", "\n", "        ", "boxlists_hf", "=", "im_detect_bbox_hflip", "(", "\n", "model", ",", "images", ",", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", ",", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", ",", "device", "\n", ")", "\n", "add_preds_t", "(", "boxlists_hf", ")", "\n", "\n", "# Compute detections at different scales", "\n", "", "for", "scale", "in", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "SCALES", ":", "\n", "        ", "max_size", "=", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "MAX_SIZE", "\n", "boxlists_scl", "=", "im_detect_bbox_scale", "(", "\n", "model", ",", "images", ",", "scale", ",", "max_size", ",", "device", "\n", ")", "\n", "add_preds_t", "(", "boxlists_scl", ")", "\n", "\n", "if", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "SCALE_H_FLIP", ":", "\n", "            ", "boxlists_scl_hf", "=", "im_detect_bbox_scale", "(", "\n", "model", ",", "images", ",", "scale", ",", "max_size", ",", "device", ",", "hflip", "=", "True", "\n", ")", "\n", "add_preds_t", "(", "boxlists_scl_hf", ")", "\n", "\n", "# Merge boxlists detected by different bbox aug params", "\n", "", "", "boxlists", "=", "[", "]", "\n", "for", "i", ",", "boxlist_ts", "in", "enumerate", "(", "boxlists_ts", ")", ":", "\n", "        ", "bbox", "=", "torch", ".", "cat", "(", "[", "boxlist_t", ".", "bbox", "for", "boxlist_t", "in", "boxlist_ts", "]", ")", "\n", "scores", "=", "torch", ".", "cat", "(", "[", "boxlist_t", ".", "get_field", "(", "'scores'", ")", "for", "boxlist_t", "in", "boxlist_ts", "]", ")", "\n", "boxlist", "=", "BoxList", "(", "bbox", ",", "boxlist_ts", "[", "0", "]", ".", "size", ",", "boxlist_ts", "[", "0", "]", ".", "mode", ")", "\n", "boxlist", ".", "add_field", "(", "'scores'", ",", "scores", ")", "\n", "boxlists", ".", "append", "(", "boxlist", ")", "\n", "\n", "# Apply NMS and limit the final detections", "\n", "", "results", "=", "[", "]", "\n", "post_processor", "=", "make_roi_box_post_processor", "(", "cfg", ")", "\n", "for", "boxlist", "in", "boxlists", ":", "\n", "        ", "results", ".", "append", "(", "post_processor", ".", "filter_results", "(", "boxlist", ",", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CLASSES", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "\n", "", "def", "im_detect_bbox", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug.im_detect_bbox": [[73, 87], ["torchvision.Compose", "fcos_core.structures.image_list.to_image_list", "model", "TT.Compose.", "fcos_core.structures.image_list.to_image_list.to", "fcos_core.data.transforms.Resize", "torchvision.ToTensor", "fcos_core.data.transforms.Normalize", "fcos_core.config.cfg.INPUT.MIN_SIZE_TEST", "fcos_core.config.cfg.INPUT.MAX_SIZE_TEST"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["\n", "transform", "=", "TT", ".", "Compose", "(", "[", "\n", "T", ".", "Resize", "(", "target_scale", ",", "target_max_size", ")", ",", "\n", "TT", ".", "ToTensor", "(", ")", ",", "\n", "T", ".", "Normalize", "(", "\n", "mean", "=", "cfg", ".", "INPUT", ".", "PIXEL_MEAN", ",", "std", "=", "cfg", ".", "INPUT", ".", "PIXEL_STD", ",", "to_bgr255", "=", "cfg", ".", "INPUT", ".", "TO_BGR255", "\n", ")", "\n", "]", ")", "\n", "images", "=", "[", "transform", "(", "image", ")", "for", "image", "in", "images", "]", "\n", "images", "=", "to_image_list", "(", "images", ",", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "return", "model", "(", "images", ".", "to", "(", "device", ")", ")", "\n", "\n", "\n", "", "def", "im_detect_bbox_hflip", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug.im_detect_bbox_hflip": [[89, 109], ["torchvision.Compose", "fcos_core.structures.image_list.to_image_list", "model", "TT.Compose.", "fcos_core.structures.image_list.to_image_list.to", "boxlist.transpose", "fcos_core.data.transforms.Resize", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "fcos_core.data.transforms.Normalize", "fcos_core.config.cfg.INPUT.MIN_SIZE_TEST", "fcos_core.config.cfg.INPUT.MAX_SIZE_TEST"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["\n", "transform", "=", "TT", ".", "Compose", "(", "[", "\n", "T", ".", "Resize", "(", "target_scale", ",", "target_max_size", ")", ",", "\n", "TT", ".", "RandomHorizontalFlip", "(", "1.0", ")", ",", "\n", "TT", ".", "ToTensor", "(", ")", ",", "\n", "T", ".", "Normalize", "(", "\n", "mean", "=", "cfg", ".", "INPUT", ".", "PIXEL_MEAN", ",", "std", "=", "cfg", ".", "INPUT", ".", "PIXEL_STD", ",", "to_bgr255", "=", "cfg", ".", "INPUT", ".", "TO_BGR255", "\n", ")", "\n", "]", ")", "\n", "images", "=", "[", "transform", "(", "image", ")", "for", "image", "in", "images", "]", "\n", "images", "=", "to_image_list", "(", "images", ",", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "boxlists", "=", "model", "(", "images", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Invert the detections computed on the flipped image", "\n", "boxlists_inv", "=", "[", "boxlist", ".", "transpose", "(", "0", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "return", "boxlists_inv", "\n", "\n", "\n", "", "def", "im_detect_bbox_scale", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ",", "hflip", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug.im_detect_bbox_scale": [[111, 121], ["bbox_aug.im_detect_bbox_hflip", "bbox_aug.im_detect_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox_hflip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox"], ["\n", "if", "hflip", ":", "\n", "        ", "boxlists_scl", "=", "im_detect_bbox_hflip", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ")", "\n", "", "else", ":", "\n", "        ", "boxlists_scl", "=", "im_detect_bbox", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ")", "\n", "", "return", "boxlists_scl", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.inference.compute_on_dataset": [[19, 43], ["model.eval", "torch.device", "enumerate", "tqdm.tqdm", "results_dict.update", "torch.no_grad", "timer.tic", "model", "torch.cuda.synchronize", "timer.toc", "o.to", "bbox_aug_vote.im_detect_bbox_aug_vote", "bbox_aug.im_detect_bbox_aug", "images.to", "zip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.tic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.toc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox_aug_vote", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug.im_detect_bbox_aug", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pre_nms_top_n", ",", "\n", "post_nms_top_n", ",", "\n", "nms_thresh", ",", "\n", "min_size", ",", "\n", "box_coder", "=", "None", ",", "\n", "fpn_post_nms_top_n", "=", "None", ",", "\n", "fpn_post_nms_per_batch", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pre_nms_top_n (int)\n            post_nms_top_n (int)\n            nms_thresh (float)\n            min_size (int)\n            box_coder (BoxCoder)\n            fpn_post_nms_top_n (int)\n        \"\"\"", "\n", "super", "(", "RPNPostProcessor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_nms_top_n", "=", "pre_nms_top_n", "\n", "self", ".", "post_nms_top_n", "=", "post_nms_top_n", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "min_size", "=", "min_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.inference._accumulate_predictions_from_multiple_gpus": [[45, 65], ["utils.comm.all_gather", "list", "utils.comm.is_main_process", "predictions.update", "sorted", "len", "logging.getLogger", "logging.getLogger.warning", "predictions.keys"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["            ", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "", "self", ".", "box_coder", "=", "box_coder", "\n", "\n", "if", "fpn_post_nms_top_n", "is", "None", ":", "\n", "            ", "fpn_post_nms_top_n", "=", "post_nms_top_n", "\n", "", "self", ".", "fpn_post_nms_top_n", "=", "fpn_post_nms_top_n", "\n", "self", ".", "fpn_post_nms_per_batch", "=", "fpn_post_nms_per_batch", "\n", "\n", "", "def", "add_gt_proposals", "(", "self", ",", "proposals", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            proposals: list[BoxList]\n            targets: list[BoxList]\n        \"\"\"", "\n", "# Get the device we're operating on", "\n", "device", "=", "proposals", "[", "0", "]", ".", "bbox", ".", "device", "\n", "\n", "gt_boxes", "=", "[", "target", ".", "copy_with_fields", "(", "[", "]", ")", "for", "target", "in", "targets", "]", "\n", "\n", "# later cat of bbox requires all fields to be present for all bbox", "\n", "# so we need to add a dummy for objectness that's missing", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.inference.inference": [[67, 124], ["torch.device", "utils.comm.get_world_size", "logging.getLogger", "logging.getLogger.info", "utils.timer.Timer", "utils.timer.Timer", "utils.timer.Timer.tic", "inference.compute_on_dataset", "utils.comm.synchronize", "utils.timer.Timer.toc", "utils.timer.get_time_str", "logging.getLogger.info", "utils.timer.get_time_str", "logging.getLogger.info", "inference._accumulate_predictions_from_multiple_gpus", "dict", "fcos_core.data.datasets.evaluation.evaluate", "utils.comm.is_main_process", "torch.save", "len", "os.path.join", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.tic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.inference.compute_on_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.toc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.get_time_str", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.get_time_str", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.inference._accumulate_predictions_from_multiple_gpus", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["            ", "gt_box", ".", "add_field", "(", "\"objectness\"", ",", "torch", ".", "ones", "(", "len", "(", "gt_box", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "proposals", "=", "[", "\n", "cat_boxlist", "(", "(", "proposal", ",", "gt_box", ")", ")", "\n", "for", "proposal", ",", "gt_box", "in", "zip", "(", "proposals", ",", "gt_boxes", ")", "\n", "]", "\n", "\n", "return", "proposals", "\n", "\n", "", "def", "forward_for_single_feature_map", "(", "self", ",", "anchors", ",", "objectness", ",", "box_regression", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            anchors: list[BoxList]\n            objectness: tensor of size N, A, H, W\n            box_regression: tensor of size N, A * 4, H, W\n        \"\"\"", "\n", "device", "=", "objectness", ".", "device", "\n", "N", ",", "A", ",", "H", ",", "W", "=", "objectness", ".", "shape", "\n", "\n", "# put in the same format as anchors", "\n", "objectness", "=", "permute_and_flatten", "(", "objectness", ",", "N", ",", "A", ",", "1", ",", "H", ",", "W", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "objectness", "=", "objectness", ".", "sigmoid", "(", ")", "\n", "\n", "box_regression", "=", "permute_and_flatten", "(", "box_regression", ",", "N", ",", "A", ",", "4", ",", "H", ",", "W", ")", "\n", "\n", "num_anchors", "=", "A", "*", "H", "*", "W", "\n", "\n", "pre_nms_top_n", "=", "min", "(", "self", ".", "pre_nms_top_n", ",", "num_anchors", ")", "\n", "objectness", ",", "topk_idx", "=", "objectness", ".", "topk", "(", "pre_nms_top_n", ",", "dim", "=", "1", ",", "sorted", "=", "True", ")", "\n", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "N", ",", "device", "=", "device", ")", "[", ":", ",", "None", "]", "\n", "box_regression", "=", "box_regression", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "image_shapes", "=", "[", "box", ".", "size", "for", "box", "in", "anchors", "]", "\n", "concat_anchors", "=", "torch", ".", "cat", "(", "[", "a", ".", "bbox", "for", "a", "in", "anchors", "]", ",", "dim", "=", "0", ")", "\n", "concat_anchors", "=", "concat_anchors", ".", "reshape", "(", "N", ",", "-", "1", ",", "4", ")", "[", "batch_idx", ",", "topk_idx", "]", "\n", "\n", "proposals", "=", "self", ".", "box_coder", ".", "decode", "(", "\n", "box_regression", ".", "view", "(", "-", "1", ",", "4", ")", ",", "concat_anchors", ".", "view", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "proposals", "=", "proposals", ".", "view", "(", "N", ",", "-", "1", ",", "4", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "proposal", ",", "score", ",", "im_shape", "in", "zip", "(", "proposals", ",", "objectness", ",", "image_shapes", ")", ":", "\n", "            ", "boxlist", "=", "BoxList", "(", "proposal", ",", "im_shape", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist", ".", "add_field", "(", "\"objectness\"", ",", "score", ")", "\n", "boxlist", "=", "boxlist", ".", "clip_to_image", "(", "remove_empty", "=", "False", ")", "\n", "boxlist", "=", "remove_small_boxes", "(", "boxlist", ",", "self", ".", "min_size", ")", "\n", "boxlist", "=", "boxlist_nms", "(", "\n", "boxlist", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "max_proposals", "=", "self", ".", "post_nms_top_n", ",", "\n", "score_field", "=", "\"objectness\"", ",", "\n", ")", "\n", "result", ".", "append", "(", "boxlist", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.reduce_loss_dict": [[13, 36], ["fcos_core.utils.comm.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.reduce", "loss_dict.keys", "loss_names.append", "torch.stack.append", "torch.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["from", "maskrcnn_benchmark", ".", "utils", ".", "metric_logger", "import", "MetricLogger", "\n", "from", "maskrcnn_benchmark", ".", "engine", ".", "inference", "import", "inference", "\n", "\n", "from", "apex", "import", "amp", "\n", "\n", "def", "reduce_loss_dict", "(", "loss_dict", ")", ":", "\n", "    ", "\"\"\"\n    Reduce the loss dictionary from all processes so that process with rank\n    0 has the averaged results. Returns a dict with the same fields as\n    loss_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "loss_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "loss_names", "=", "[", "]", "\n", "all_losses", "=", "[", "]", "\n", "for", "k", "in", "sorted", "(", "loss_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "loss_names", ".", "append", "(", "k", ")", "\n", "all_losses", ".", "append", "(", "loss_dict", "[", "k", "]", ")", "\n", "", "all_losses", "=", "torch", ".", "stack", "(", "all_losses", ",", "dim", "=", "0", ")", "\n", "dist", ".", "reduce", "(", "all_losses", ",", "dst", "=", "0", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "# only main process gets accumulated, so only divide by", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer._update_loss_scale_hist": [[43, 51], ["torch.Tensor", "torch.Tensor", "range", "loss_vec[].sum", "loss_vec[].sum", "len"], "function", ["None"], ["", "def", "_update_loss_scale_hist", "(", "cfg", ",", "loss_scale", ",", "loss_hist", ")", ":", "\n", "    ", "loss_vec", ",", "gt_areas", "=", "loss_scale", "\n", "scale_splits", "=", "torch", ".", "Tensor", "(", "[", "0", "]", "+", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "+", "1", ")", ":", "\n", "        ", "_idx", "=", "(", "gt_areas", ">", "scale_splits", "[", "i", "-", "1", "]", ")", "*", "(", "gt_areas", "<", "scale_splits", "[", "i", "]", ")", "\n", "loss_hist", "[", "i", "-", "1", "]", "+=", "loss_vec", "[", "_idx", "]", ".", "sum", "(", ")", "\n", "", "loss_hist", "[", "-", "1", "]", "+=", "loss_vec", "[", "gt_areas", ">", "scale_splits", "[", "-", "1", "]", "]", ".", "sum", "(", ")", "\n", "return", "loss_hist", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.do_train": [[38, 120], ["logging.getLogger", "logging.getLogger.info", "fcos_core.utils.metric_logger.MetricLogger", "len", "model.train", "time.time", "time.time", "fcos_core.utils.comm.is_pytorch_1_1_0_or_later", "enumerate", "str", "logging.getLogger.info", "images.to.to", "model", "sum", "trainer.reduce_loss_dict", "sum", "fcos_core.utils.metric_logger.MetricLogger.update", "optimizer.zero_grad", "sum.backward", "optimizer.step", "time.time", "fcos_core.utils.metric_logger.MetricLogger.update", "str", "time.time", "datetime.timedelta", "time.time", "scheduler.step", "target.to", "scheduler.step", "time.time", "datetime.timedelta", "logging.getLogger.info", "checkpointer.save", "checkpointer.save", "fcos_core.utils.metric_logger.MetricLogger.delimiter.join().format", "model.values", "reduce_loss_dict.values", "int", "fcos_core.utils.metric_logger.MetricLogger.delimiter.join", "str", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_pytorch_1_1_0_or_later", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.reduce_loss_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_func.DeformRoIPoolingFunction.backward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["            ", "all_losses", "/=", "world_size", "\n", "", "reduced_losses", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "loss_names", ",", "all_losses", ")", "}", "\n", "", "return", "reduced_losses", "\n", "\n", "\n", "", "def", "_update_loss_scale_hist", "(", "cfg", ",", "loss_scale", ",", "loss_hist", ")", ":", "\n", "    ", "loss_vec", ",", "gt_areas", "=", "loss_scale", "\n", "scale_splits", "=", "torch", ".", "Tensor", "(", "[", "0", "]", "+", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "+", "1", ")", ":", "\n", "        ", "_idx", "=", "(", "gt_areas", ">", "scale_splits", "[", "i", "-", "1", "]", ")", "*", "(", "gt_areas", "<", "scale_splits", "[", "i", "]", ")", "\n", "loss_hist", "[", "i", "-", "1", "]", "+=", "loss_vec", "[", "_idx", "]", ".", "sum", "(", ")", "\n", "", "loss_hist", "[", "-", "1", "]", "+=", "loss_vec", "[", "gt_areas", ">", "scale_splits", "[", "-", "1", "]", "]", ".", "sum", "(", ")", "\n", "return", "loss_hist", "\n", "\n", "\n", "", "def", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "checkpointer", ",", "\n", "device", ",", "\n", "checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n", "search", "=", "None", ",", "\n", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.trainer\"", ")", "if", "search", "is", "None", "else", "search", "\n", "logger", ".", "info", "(", "\"Start training\"", ")", "\n", "meters", "=", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "max_iter", "=", "len", "(", "data_loader", ")", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", "\n", "model", ".", "train", "(", ")", "\n", "start_training_time", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "cfg", ".", "defrost", "(", ")", "\n", "\n", "loss_hist", "=", "torch", ".", "Tensor", "(", "[", "0", "]", "*", "(", "len", "(", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "+", "1", ")", ")", ".", "cuda", "(", ")", "if", "search", "else", "None", "\n", "\n", "for", "iteration", ",", "(", "images", ",", "targets", ",", "_", ")", "in", "enumerate", "(", "data_loader", ",", "start_iter", ")", ":", "\n", "\n", "        ", "if", "any", "(", "len", "(", "target", ")", "<", "1", "for", "target", "in", "targets", ")", ":", "\n", "            ", "logger", ".", "error", "(", "f\"Iteration={iteration + 1} || Image Ids used for training {_} || targets Length={[len(target) for target in targets]}\"", ")", "\n", "continue", "\n", "", "data_time", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "iteration", "=", "iteration", "+", "1", "\n", "arguments", "[", "\"iteration\"", "]", "=", "iteration", "\n", "\n", "images", "=", "images", ".", "to", "(", "device", ")", "\n", "targets", "=", "[", "target", ".", "to", "(", "device", ")", "for", "target", "in", "targets", "]", "\n", "\n", "loss_dict", ",", "loss_scale", "=", "model", "(", "images", ",", "targets", ")", "\n", "if", "search", ":", "\n", "            ", "loss_hist", "=", "_update_loss_scale_hist", "(", "cfg", ",", "loss_scale", ",", "loss_hist", ")", "\n", "\n", "", "losses", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "# reduce losses over all GPUs for logging purposes", "\n", "loss_dict_reduced", "=", "reduce_loss_dict", "(", "loss_dict", ")", "\n", "losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "meters", ".", "update", "(", "loss", "=", "losses_reduced", ",", "**", "loss_dict_reduced", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "# Note: If mixed precision is not used, this ends up doing nothing", "\n", "# Otherwise apply loss scaling for mixed-precision recipe", "\n", "with", "amp", ".", "scale_loss", "(", "losses", ",", "optimizer", ")", "as", "scaled_losses", ":", "\n", "            ", "scaled_losses", ".", "backward", "(", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "batch_time", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "meters", ".", "update", "(", "time", "=", "batch_time", ",", "data", "=", "data_time", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox_aug_vote": [[13, 67], ["range", "bbox_aug_vote.im_detect_bbox", "bbox_aug_vote.im_detect_bbox_aug_vote.add_preds_t"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox"], ["def", "im_detect_bbox_aug_vote", "(", "model", ",", "images", ",", "device", ")", ":", "\n", "# Collect detections computed under different transformations", "\n", "    ", "boxlists_ts", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "len", "(", "images", ")", ")", ":", "\n", "        ", "boxlists_ts", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "def", "add_preds_t", "(", "boxlists_t", ")", ":", "\n", "        ", "for", "i", ",", "boxlist_t", "in", "enumerate", "(", "boxlists_t", ")", ":", "\n", "            ", "if", "len", "(", "boxlists_ts", "[", "i", "]", ")", "==", "0", ":", "\n", "# The first one is identity transform, no need to resize the boxlist", "\n", "                ", "boxlists_ts", "[", "i", "]", ".", "append", "(", "boxlist_t", ")", "\n", "", "else", ":", "\n", "# Resize the boxlist as the first one", "\n", "                ", "boxlists_ts", "[", "i", "]", ".", "append", "(", "boxlist_t", ".", "resize", "(", "boxlists_ts", "[", "i", "]", "[", "0", "]", ".", "size", ")", ")", "\n", "\n", "# Compute detections for the original image (identity transform)", "\n", "", "", "", "boxlists_i", "=", "im_detect_bbox", "(", "model", ",", "images", ",", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", ",", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", ",", "device", ")", "\n", "add_preds_t", "(", "boxlists_i", ")", "\n", "\n", "# Perform detection on the horizontally flipped image", "\n", "if", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "H_FLIP", ":", "\n", "        ", "boxlists_hf", "=", "im_detect_bbox_hflip", "(", "model", ",", "images", ",", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", ",", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", ",", "device", ")", "\n", "add_preds_t", "(", "boxlists_hf", ")", "\n", "\n", "", "for", "idx", ",", "scale", "in", "enumerate", "(", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "SCALES", ")", ":", "\n", "        ", "max_size", "=", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "MAX_SIZE", "\n", "min_range", "=", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "SCALE_RANGES", "[", "idx", "]", "[", "0", "]", "\n", "max_range", "=", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "SCALE_RANGES", "[", "idx", "]", "[", "1", "]", "\n", "if", "scale", "<", "800", ":", "\n", "            ", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "\n", "\n", "", "boxlists_scl", "=", "im_detect_bbox_scale", "(", "model", ",", "images", ",", "scale", ",", "max_size", ",", "device", ")", "\n", "boxlists_scl", "=", "remove_boxes", "(", "boxlists_scl", ",", "min_range", ",", "max_range", ")", "\n", "add_preds_t", "(", "boxlists_scl", ")", "\n", "\n", "if", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "SCALE_H_FLIP", ":", "\n", "            ", "boxlists_scl_hf", "=", "im_detect_bbox_scale", "(", "model", ",", "images", ",", "scale", ",", "max_size", ",", "device", ",", "hflip", "=", "True", ")", "\n", "boxlists_scl_hf", "=", "remove_boxes", "(", "boxlists_scl_hf", ",", "min_range", ",", "max_range", ")", "\n", "add_preds_t", "(", "boxlists_scl_hf", ")", "\n", "\n", "# Merge boxlists detected by different bbox aug params", "\n", "", "", "boxlists", "=", "[", "]", "\n", "#from IPython import embed; embed()", "\n", "for", "_", ",", "boxlist_ts", "in", "enumerate", "(", "boxlists_ts", ")", ":", "\n", "        ", "bbox", "=", "torch", ".", "cat", "(", "[", "boxlist_t", ".", "bbox", "for", "boxlist_t", "in", "boxlist_ts", "]", ")", "\n", "scores", "=", "torch", ".", "cat", "(", "\n", "[", "boxlist_t", ".", "get_field", "(", "'scores'", ")", "for", "boxlist_t", "in", "boxlist_ts", "]", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "\n", "[", "boxlist_t", ".", "get_field", "(", "'labels'", ")", "for", "boxlist_t", "in", "boxlist_ts", "]", ")", "\n", "boxlist", "=", "BoxList", "(", "bbox", ",", "boxlist_ts", "[", "0", "]", ".", "size", ",", "boxlist_ts", "[", "0", "]", ".", "mode", ")", "\n", "boxlist", ".", "add_field", "(", "'scores'", ",", "scores", ")", "\n", "boxlist", ".", "add_field", "(", "'labels'", ",", "labels", ")", "\n", "boxlists", ".", "append", "(", "boxlist", ")", "\n", "", "results", "=", "merge_result_from_multi_scales", "(", "boxlists", ",", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "MERGE_TYPE", ",", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "VOTE_TH", ")", "\n", "return", "results", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox": [[69, 84], ["torchvision.Compose", "fcos_core.structures.image_list.to_image_list", "model", "TT.Compose.", "fcos_core.structures.image_list.to_image_list.to", "fcos_core.data.transforms.Resize", "torchvision.ToTensor", "fcos_core.data.transforms.Normalize", "fcos_core.config.cfg.INPUT.MIN_SIZE_TEST", "fcos_core.config.cfg.INPUT.MAX_SIZE_TEST"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["\n", "", "def", "im_detect_bbox", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Performs bbox detection on the original image.\n    \"\"\"", "\n", "transform", "=", "TT", ".", "Compose", "(", "[", "\n", "T", ".", "Resize", "(", "target_scale", ",", "target_max_size", ")", ",", "\n", "TT", ".", "ToTensor", "(", ")", ",", "\n", "T", ".", "Normalize", "(", "\n", "mean", "=", "cfg", ".", "INPUT", ".", "PIXEL_MEAN", ",", "\n", "std", "=", "cfg", ".", "INPUT", ".", "PIXEL_STD", ",", "\n", "to_bgr255", "=", "cfg", ".", "INPUT", ".", "TO_BGR255", ")", "\n", "]", ")", "\n", "images", "=", "[", "transform", "(", "image", ")", "for", "image", "in", "images", "]", "\n", "images", "=", "to_image_list", "(", "images", ",", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "return", "model", "(", "images", ".", "to", "(", "device", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox_hflip": [[86, 107], ["torchvision.Compose", "fcos_core.structures.image_list.to_image_list", "model", "TT.Compose.", "fcos_core.structures.image_list.to_image_list.to", "boxlist.transpose", "fcos_core.data.transforms.Resize", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "fcos_core.data.transforms.Normalize", "fcos_core.config.cfg.INPUT.MIN_SIZE_TEST", "fcos_core.config.cfg.INPUT.MAX_SIZE_TEST"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["\n", "", "def", "im_detect_bbox_hflip", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Performs bbox detection on the horizontally flipped image.\n    Function signature is the same as for im_detect_bbox.\n    \"\"\"", "\n", "transform", "=", "TT", ".", "Compose", "(", "[", "\n", "T", ".", "Resize", "(", "target_scale", ",", "target_max_size", ")", ",", "\n", "TT", ".", "RandomHorizontalFlip", "(", "1.0", ")", ",", "\n", "TT", ".", "ToTensor", "(", ")", ",", "\n", "T", ".", "Normalize", "(", "\n", "mean", "=", "cfg", ".", "INPUT", ".", "PIXEL_MEAN", ",", "\n", "std", "=", "cfg", ".", "INPUT", ".", "PIXEL_STD", ",", "\n", "to_bgr255", "=", "cfg", ".", "INPUT", ".", "TO_BGR255", ")", "\n", "]", ")", "\n", "images", "=", "[", "transform", "(", "image", ")", "for", "image", "in", "images", "]", "\n", "images", "=", "to_image_list", "(", "images", ",", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "boxlists", "=", "model", "(", "images", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Invert the detections computed on the flipped image", "\n", "boxlists_inv", "=", "[", "boxlist", ".", "transpose", "(", "0", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "return", "boxlists_inv", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox_scale": [[109, 121], ["bbox_aug_vote.im_detect_bbox_hflip", "bbox_aug_vote.im_detect_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox_hflip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.im_detect_bbox"], ["\n", "", "def", "im_detect_bbox_scale", "(", "model", ",", "images", ",", "target_scale", ",", "target_max_size", ",", "device", ",", "hflip", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Computes bbox detections at the given scale.\n    Returns predictions in the scaled image space.\n    \"\"\"", "\n", "if", "hflip", ":", "\n", "        ", "boxlists_scl", "=", "im_detect_bbox_hflip", "(", "model", ",", "images", ",", "target_scale", ",", "\n", "target_max_size", ",", "device", ")", "\n", "", "else", ":", "\n", "        ", "boxlists_scl", "=", "im_detect_bbox", "(", "model", ",", "images", ",", "target_scale", ",", "\n", "target_max_size", ",", "device", ")", "\n", "", "return", "boxlists_scl", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.remove_boxes": [[123, 137], ["enumerate", "boxlist_t.convert.convert", "enumerate", "new_boxlist_ts.append", "boxlist_t[].convert", "keep.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["\n", "", "def", "remove_boxes", "(", "boxlist_ts", ",", "min_scale", ",", "max_scale", ")", ":", "\n", "    ", "new_boxlist_ts", "=", "[", "]", "\n", "for", "_", ",", "boxlist_t", "in", "enumerate", "(", "boxlist_ts", ")", ":", "\n", "        ", "mode", "=", "boxlist_t", ".", "mode", "\n", "boxlist_t", "=", "boxlist_t", ".", "convert", "(", "\"xyxy\"", ")", "\n", "boxes", "=", "boxlist_t", ".", "bbox", "\n", "keep", "=", "[", "]", "\n", "for", "j", ",", "box", "in", "enumerate", "(", "boxes", ")", ":", "\n", "            ", "w", "=", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1", "\n", "h", "=", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1", "\n", "if", "(", "w", "*", "h", ">", "min_scale", "*", "min_scale", ")", "and", "(", "w", "*", "h", "<", "max_scale", "*", "max_scale", ")", ":", "\n", "                ", "keep", ".", "append", "(", "j", ")", "\n", "", "", "new_boxlist_ts", ".", "append", "(", "boxlist_t", "[", "keep", "]", ".", "convert", "(", "mode", ")", ")", "\n", "", "return", "new_boxlist_ts", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.merge_result_from_multi_scales": [[139, 177], ["len", "range", "boxlists[].get_field", "boxlists[].get_field", "range", "fcos_core.structures.boxlist_ops.cat_boxlist", "len", "results.append", "boxes[].view", "fcos_core.structures.bounding_box.BoxList", "boxlist_nms.add_field", "bbox_aug_vote.boxlist_nms", "len", "boxlist_nms.add_field", "fcos_core.structures.boxlist_ops.cat_boxlist.append", "fcos_core.structures.boxlist_ops.cat_boxlist.get_field", "torch.kthvalue", "torch.nonzero().squeeze", "torch.full", "result.get_field.cpu", "image_thresh.item", "torch.nonzero", "fcos_core.config.cfg.TEST.BBOX_AUG.MERGE_TYPE", "fcos_core.config.cfg.TEST.BBOX_AUG.VOTE_TH"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.cat_boxlist", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.boxlist_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["\n", "", "def", "merge_result_from_multi_scales", "(", "boxlists", ",", "nms_type", "=", "'nms'", ",", "vote_thresh", "=", "0.65", ")", ":", "\n", "    ", "num_images", "=", "len", "(", "boxlists", ")", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "        ", "scores", "=", "boxlists", "[", "i", "]", ".", "get_field", "(", "\"scores\"", ")", "\n", "labels", "=", "boxlists", "[", "i", "]", ".", "get_field", "(", "\"labels\"", ")", "\n", "boxes", "=", "boxlists", "[", "i", "]", ".", "bbox", "\n", "boxlist", "=", "boxlists", "[", "i", "]", "\n", "result", "=", "[", "]", "\n", "# skip the background", "\n", "for", "j", "in", "range", "(", "1", ",", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", ")", ":", "\n", "            ", "inds", "=", "(", "labels", "==", "j", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "scores_j", "=", "scores", "[", "inds", "]", "\n", "boxes_j", "=", "boxes", "[", "inds", ",", ":", "]", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "boxlist_for_class", "=", "BoxList", "(", "boxes_j", ",", "boxlist", ".", "size", ",", "mode", "=", "\"xyxy\"", ")", "\n", "boxlist_for_class", ".", "add_field", "(", "\"scores\"", ",", "scores_j", ")", "\n", "boxlist_for_class", "=", "boxlist_nms", "(", "boxlist_for_class", ",", "0.6", ",", "score_field", "=", "\"scores\"", ",", "# cfg.MODEL.ROI_HEADS.NMS; 0.8", "\n", "nms_type", "=", "nms_type", ",", "vote_thresh", "=", "vote_thresh", ")", "\n", "num_labels", "=", "len", "(", "boxlist_for_class", ")", "\n", "boxlist_for_class", ".", "add_field", "(", "\"labels\"", ",", "torch", ".", "full", "(", "(", "num_labels", ",", ")", ",", "j", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "scores", ".", "device", ")", ")", "\n", "result", ".", "append", "(", "boxlist_for_class", ")", "\n", "\n", "", "result", "=", "cat_boxlist", "(", "result", ")", "\n", "number_of_detections", "=", "len", "(", "result", ")", "\n", "\n", "# Limit to max_per_image detections **over all classes**", "\n", "if", "False", ":", "#number_of_detections > cfg.MODEL.ATSS.PRE_NMS_TOP_N > 0:", "\n", "            ", "cls_scores", "=", "result", ".", "get_field", "(", "\"scores\"", ")", "\n", "image_thresh", ",", "_", "=", "torch", ".", "kthvalue", "(", "\n", "cls_scores", ".", "cpu", "(", ")", ",", "\n", "number_of_detections", "-", "cfg", ".", "MODEL", ".", "ATSS", ".", "PRE_NMS_TOP_N", "+", "1", "\n", ")", "\n", "keep", "=", "cls_scores", ">=", "image_thresh", ".", "item", "(", ")", "\n", "keep", "=", "torch", ".", "nonzero", "(", "keep", ")", ".", "squeeze", "(", "1", ")", "\n", "result", "=", "result", "[", "keep", "]", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.boxlist_nms": [[179, 200], ["boxlist.convert.convert", "boxlist.convert.get_field", "boxlist.convert.convert", "fcos_core.layers.nms", "bbox_aug_vote.bbox_vote", "bbox_aug_vote.soft_bbox_vote", "len", "fcos_core.config.cfg.MODEL.ATSS.NMS_TH"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.bbox_vote", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.soft_bbox_vote"], ["\n", "", "def", "boxlist_nms", "(", "boxlist", ",", "nms_thresh", ",", "max_proposals", "=", "-", "1", ",", "score_field", "=", "\"scores\"", ",", "nms_type", "=", "'nms'", ",", "vote_thresh", "=", "0.65", ")", ":", "\n", "    ", "if", "nms_thresh", "<=", "0", ":", "\n", "        ", "return", "boxlist", "\n", "", "mode", "=", "boxlist", ".", "mode", "\n", "boxlist", "=", "boxlist", ".", "convert", "(", "\"xyxy\"", ")", "\n", "boxes", "=", "boxlist", ".", "bbox", "\n", "score", "=", "boxlist", ".", "get_field", "(", "score_field", ")", "\n", "if", "nms_type", "==", "'nms'", ":", "\n", "        ", "keep", "=", "_box_nms", "(", "boxes", ",", "score", ",", "nms_thresh", ")", "\n", "if", "max_proposals", ">", "0", ":", "\n", "            ", "keep", "=", "keep", "[", ":", "max_proposals", "]", "\n", "", "boxlist", "=", "boxlist", "[", "keep", "]", "\n", "", "else", ":", "\n", "        ", "if", "nms_type", "==", "'vote'", ":", "\n", "            ", "boxes_vote", ",", "scores_vote", "=", "bbox_vote", "(", "boxes", ",", "score", ",", "vote_thresh", ")", "\n", "", "else", ":", "\n", "            ", "boxes_vote", ",", "scores_vote", "=", "soft_bbox_vote", "(", "boxes", ",", "score", ",", "vote_thresh", ")", "\n", "", "if", "len", "(", "boxes_vote", ")", ">", "0", ":", "\n", "            ", "boxlist", ".", "bbox", "=", "boxes_vote", "\n", "boxlist", ".", "extra_fields", "[", "'scores'", "]", "=", "scores_vote", "\n", "", "", "return", "boxlist", ".", "convert", "(", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.bbox_vote": [[202, 249], ["torch.from_numpy().float().cuda.cpu().numpy", "torch.from_numpy().float().cuda.cpu().numpy().reshape", "numpy.concatenate", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "det[].ravel().argsort", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.delete", "torch.from_numpy().float().cuda.cpu", "torch.from_numpy().float().cuda.cpu().numpy", "numpy.zeros", "numpy.zeros", "numpy.where", "numpy.max", "numpy.zeros", "torch.from_numpy().float", "torch.from_numpy().float", "det[].ravel", "numpy.row_stack", "numpy.tile", "numpy.sum", "numpy.sum", "numpy.row_stack", "torch.from_numpy().float().cuda.cpu", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["\n", "", "def", "bbox_vote", "(", "boxes", ",", "scores", ",", "vote_thresh", ")", ":", "\n", "    ", "boxes", "=", "boxes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "scores", "=", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "det", "=", "np", ".", "concatenate", "(", "(", "boxes", ",", "scores", ")", ",", "axis", "=", "1", ")", "\n", "if", "det", ".", "shape", "[", "0", "]", "<=", "1", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ")", ",", "np", ".", "zeros", "(", "(", "0", ",", "1", ")", ")", "\n", "", "order", "=", "det", "[", ":", ",", "4", "]", ".", "ravel", "(", ")", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "det", "=", "det", "[", "order", ",", ":", "]", "\n", "dets", "=", "[", "]", "\n", "while", "det", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "# IOU", "\n", "        ", "area", "=", "(", "det", "[", ":", ",", "2", "]", "-", "det", "[", ":", ",", "0", "]", "+", "1", ")", "*", "(", "det", "[", ":", ",", "3", "]", "-", "det", "[", ":", ",", "1", "]", "+", "1", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "det", "[", "0", ",", "0", "]", ",", "det", "[", ":", ",", "0", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "det", "[", "0", ",", "1", "]", ",", "det", "[", ":", ",", "1", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "det", "[", "0", ",", "2", "]", ",", "det", "[", ":", ",", "2", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "det", "[", "0", ",", "3", "]", ",", "det", "[", ":", ",", "3", "]", ")", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "o", "=", "inter", "/", "(", "area", "[", "0", "]", "+", "area", "[", ":", "]", "-", "inter", ")", "\n", "\n", "# get needed merge det and delete these  det", "\n", "merge_index", "=", "np", ".", "where", "(", "o", ">=", "vote_thresh", ")", "[", "0", "]", "\n", "det_accu", "=", "det", "[", "merge_index", ",", ":", "]", "\n", "det", "=", "np", ".", "delete", "(", "det", ",", "merge_index", ",", "0", ")", "\n", "\n", "if", "merge_index", ".", "shape", "[", "0", "]", "<=", "1", ":", "\n", "            ", "try", ":", "\n", "                ", "dets", "=", "np", ".", "row_stack", "(", "(", "dets", ",", "det_accu", ")", ")", "\n", "", "except", ":", "\n", "                ", "dets", "=", "det_accu", "\n", "", "continue", "\n", "", "else", ":", "\n", "            ", "det_accu", "[", ":", ",", "0", ":", "4", "]", "=", "det_accu", "[", ":", ",", "0", ":", "4", "]", "*", "np", ".", "tile", "(", "det_accu", "[", ":", ",", "-", "1", ":", "]", ",", "(", "1", ",", "4", ")", ")", "\n", "max_score", "=", "np", ".", "max", "(", "det_accu", "[", ":", ",", "4", "]", ")", "\n", "det_accu_sum", "=", "np", ".", "zeros", "(", "(", "1", ",", "5", ")", ")", "\n", "det_accu_sum", "[", ":", ",", "0", ":", "4", "]", "=", "np", ".", "sum", "(", "det_accu", "[", ":", ",", "0", ":", "4", "]", ",", "axis", "=", "0", ")", "/", "np", ".", "sum", "(", "det_accu", "[", ":", ",", "-", "1", ":", "]", ")", "\n", "det_accu_sum", "[", ":", ",", "4", "]", "=", "max_score", "\n", "try", ":", "\n", "                ", "dets", "=", "np", ".", "row_stack", "(", "(", "dets", ",", "det_accu_sum", ")", ")", "\n", "", "except", ":", "\n", "                ", "dets", "=", "det_accu_sum", "\n", "\n", "", "", "", "boxes", "=", "torch", ".", "from_numpy", "(", "dets", "[", ":", ",", ":", "4", "]", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "scores", "=", "torch", ".", "from_numpy", "(", "dets", "[", ":", ",", "4", "]", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "return", "boxes", ",", "scores", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.bbox_aug_vote.soft_bbox_vote": [[251, 311], ["torch.from_numpy().float().cuda.cpu().numpy", "torch.from_numpy().float().cuda.cpu().numpy().reshape", "numpy.concatenate", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "det[].ravel().argsort", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.delete", "dets[].ravel().argsort", "torch.from_numpy().float().cuda.cpu", "torch.from_numpy().float().cuda.cpu().numpy", "numpy.zeros", "numpy.zeros", "numpy.where", "det_accu.copy", "numpy.max", "numpy.zeros", "torch.from_numpy().float", "torch.from_numpy().float", "det[].ravel", "numpy.row_stack", "numpy.where", "numpy.tile", "numpy.sum", "numpy.sum", "numpy.row_stack", "numpy.row_stack", "dets[].ravel", "torch.from_numpy().float().cuda.cpu", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["\n", "", "def", "soft_bbox_vote", "(", "boxes", ",", "scores", ",", "vote_thresh", ")", ":", "\n", "    ", "boxes", "=", "boxes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "scores", "=", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "det", "=", "np", ".", "concatenate", "(", "(", "boxes", ",", "scores", ")", ",", "axis", "=", "1", ")", "\n", "if", "det", ".", "shape", "[", "0", "]", "<=", "1", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ")", ",", "np", ".", "zeros", "(", "(", "0", ",", "1", ")", ")", "\n", "", "order", "=", "det", "[", ":", ",", "4", "]", ".", "ravel", "(", ")", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "det", "=", "det", "[", "order", ",", ":", "]", "\n", "dets", "=", "[", "]", "\n", "while", "det", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "# IOU", "\n", "        ", "area", "=", "(", "det", "[", ":", ",", "2", "]", "-", "det", "[", ":", ",", "0", "]", "+", "1", ")", "*", "(", "det", "[", ":", ",", "3", "]", "-", "det", "[", ":", ",", "1", "]", "+", "1", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "det", "[", "0", ",", "0", "]", ",", "det", "[", ":", ",", "0", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "det", "[", "0", ",", "1", "]", ",", "det", "[", ":", ",", "1", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "det", "[", "0", ",", "2", "]", ",", "det", "[", ":", ",", "2", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "det", "[", "0", ",", "3", "]", ",", "det", "[", ":", ",", "3", "]", ")", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "o", "=", "inter", "/", "(", "area", "[", "0", "]", "+", "area", "[", ":", "]", "-", "inter", ")", "\n", "\n", "# get needed merge det and delete these  det", "\n", "merge_index", "=", "np", ".", "where", "(", "o", ">=", "vote_thresh", ")", "[", "0", "]", "\n", "det_accu", "=", "det", "[", "merge_index", ",", ":", "]", "\n", "det_accu_iou", "=", "o", "[", "merge_index", "]", "\n", "det", "=", "np", ".", "delete", "(", "det", ",", "merge_index", ",", "0", ")", "\n", "\n", "if", "merge_index", ".", "shape", "[", "0", "]", "<=", "1", ":", "\n", "            ", "try", ":", "\n", "                ", "dets", "=", "np", ".", "row_stack", "(", "(", "dets", ",", "det_accu", ")", ")", "\n", "", "except", ":", "\n", "                ", "dets", "=", "det_accu", "\n", "", "continue", "\n", "", "else", ":", "\n", "            ", "soft_det_accu", "=", "det_accu", ".", "copy", "(", ")", "\n", "soft_det_accu", "[", ":", ",", "4", "]", "=", "soft_det_accu", "[", ":", ",", "4", "]", "*", "(", "1", "-", "det_accu_iou", ")", "\n", "soft_index", "=", "np", ".", "where", "(", "soft_det_accu", "[", ":", ",", "4", "]", ">=", "cfg", ".", "MODEL", ".", "RETINANET", ".", "INFERENCE_TH", ")", "[", "0", "]", "\n", "soft_det_accu", "=", "soft_det_accu", "[", "soft_index", ",", ":", "]", "\n", "\n", "det_accu", "[", ":", ",", "0", ":", "4", "]", "=", "det_accu", "[", ":", ",", "0", ":", "4", "]", "*", "np", ".", "tile", "(", "det_accu", "[", ":", ",", "-", "1", ":", "]", ",", "(", "1", ",", "4", ")", ")", "\n", "max_score", "=", "np", ".", "max", "(", "det_accu", "[", ":", ",", "4", "]", ")", "\n", "det_accu_sum", "=", "np", ".", "zeros", "(", "(", "1", ",", "5", ")", ")", "\n", "det_accu_sum", "[", ":", ",", "0", ":", "4", "]", "=", "np", ".", "sum", "(", "det_accu", "[", ":", ",", "0", ":", "4", "]", ",", "axis", "=", "0", ")", "/", "np", ".", "sum", "(", "det_accu", "[", ":", ",", "-", "1", ":", "]", ")", "\n", "det_accu_sum", "[", ":", ",", "4", "]", "=", "max_score", "\n", "\n", "if", "soft_det_accu", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                ", "det_accu_sum", "=", "np", ".", "row_stack", "(", "(", "det_accu_sum", ",", "soft_det_accu", ")", ")", "\n", "\n", "", "try", ":", "\n", "                ", "dets", "=", "np", ".", "row_stack", "(", "(", "dets", ",", "det_accu_sum", ")", ")", "\n", "", "except", ":", "\n", "                ", "dets", "=", "det_accu_sum", "\n", "\n", "", "", "", "order", "=", "dets", "[", ":", ",", "4", "]", ".", "ravel", "(", ")", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "dets", "=", "dets", "[", "order", ",", ":", "]", "\n", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "dets", "[", ":", ",", ":", "4", "]", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "scores", "=", "torch", ".", "from_numpy", "(", "dets", "[", ":", ",", "4", "]", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "return", "boxes", ",", "scores", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultPredictor.__init__": [[214, 230], ["cfg.clone", "detectron2.modeling.build_model", "defaults.DefaultPredictor.model.eval", "len", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer.load", "detectron2.ResizeShortestEdge", "detectron2.data.MetadataCatalog.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["# Target fraction of RoI minibatch that is labeled foreground (i.e. class > 0)", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "POSITIVE_FRACTION", "=", "0.25", "\n", "\n", "# Only used on test mode", "\n", "\n", "# Minimum score threshold (assuming scores in a [0, 1] range); a value chosen to", "\n", "# balance obtaining high recall with not having too many low precision", "\n", "# detections that will slow down inference post processing steps (like NMS)", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "SCORE_THRESH", "=", "0.05", "\n", "# Overlap threshold used for non-maximum suppression (suppress boxes with", "\n", "# IoU >= this threshold)", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "NMS", "=", "0.5", "\n", "# Maximum number of detections to return per image (100 is based on the limit", "\n", "# established for the COCO dataset)", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "DETECTIONS_PER_IMG", "=", "100", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultPredictor.__call__": [[231, 253], ["torch.no_grad", "defaults.DefaultPredictor.aug.get_transform().apply_image", "torch.as_tensor", "torch.as_tensor.astype().transpose", "defaults.DefaultPredictor.model", "defaults.DefaultPredictor.aug.get_transform", "torch.as_tensor.astype"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.get_transform"], ["_C", ".", "MODEL", ".", "ROI_BOX_HEAD", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "FEATURE_EXTRACTOR", "=", "\"ResNet50Conv5ROIFeatureExtractor\"", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "PREDICTOR", "=", "\"FastRCNNPredictor\"", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "=", "14", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "=", "0", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SCALES", "=", "(", "1.0", "/", "16", ",", ")", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CLASSES", "=", "81", "\n", "# Hidden layer dimension when using an MLP for the RoI box head", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "MLP_HEAD_DIM", "=", "1024", "\n", "# GN", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "USE_GN", "=", "False", "\n", "# Dilation", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "DILATION", "=", "1", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CONV_HEAD_DIM", "=", "256", "\n", "_C", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_STACKED_CONVS", "=", "4", "\n", "\n", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "FEATURE_EXTRACTOR", "=", "\"ResNet50Conv5ROIFeatureExtractor\"", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "PREDICTOR", "=", "\"MaskRCNNC4Predictor\"", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_RESOLUTION", "=", "14", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_SAMPLING_RATIO", "=", "0", "\n", "_C", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "POOLER_SCALES", "=", "(", "1.0", "/", "16", ",", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.__init__": [[298, 338], ["train_loop.TrainerBase.__init__", "logging.getLogger", "defaults.DefaultTrainer.auto_scale_workers", "defaults.DefaultTrainer.build_model", "defaults.DefaultTrainer.build_optimizer", "defaults.DefaultTrainer.build_train_loader", "defaults.DefaultTrainer.build_lr_scheduler", "detectron2.checkpoint.DetectionCheckpointer", "defaults.DefaultTrainer.register_hooks", "logging.getLogger.isEnabledFor", "detectron2.utils.logger.setup_logger", "detectron2.utils.comm.get_world_size", "detectron2.utils.comm.get_world_size", "torch.nn.parallel.DistributedDataParallel", "defaults.DefaultTrainer.build_hooks", "detectron2.utils.comm.get_local_rank"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.auto_scale_workers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_optimizer", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.register_hooks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_hooks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_local_rank"], ["_C", ".", "MODEL", ".", "RESNETS", ".", "STEM_FUNC", "=", "\"StemWithFixedBatchNorm\"", "\n", "\n", "# Apply dilation in stage \"res5\"", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "RES5_DILATION", "=", "1", "\n", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "BACKBONE_OUT_CHANNELS", "=", "256", "*", "4", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "=", "256", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "=", "64", "\n", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "STAGE_WITH_DCN", "=", "(", "False", ",", "False", ",", "False", ",", "False", ")", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "WITH_MODULATED_DCN", "=", "False", "\n", "_C", ".", "MODEL", ".", "RESNETS", ".", "DEFORMABLE_GROUPS", "=", "1", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# ATSS Options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "ATSS", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "NUM_CLASSES", "=", "81", "# the number of classes including background", "\n", "\n", "# Anchor parameter", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_SIZES", "=", "(", "64", ",", "128", ",", "256", ",", "512", ",", "1024", ")", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "ASPECT_RATIOS", "=", "(", "1.0", ",", ")", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "ANCHOR_STRIDES", "=", "(", "8", ",", "16", ",", "32", ",", "64", ",", "128", ")", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "STRADDLE_THRESH", "=", "0", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "OCTAVE", "=", "2.0", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "SCALES_PER_OCTAVE", "=", "1", "\n", "\n", "# Head parameter", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "NUM_CONVS", "=", "4", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "USE_DCN_IN_TOWER", "=", "False", "\n", "\n", "# Focal loss parameter", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "LOSS_ALPHA", "=", "0.25", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "LOSS_GAMMA", "=", "2.0", "\n", "\n", "# how to select positves: ATSS (Ours) , SSC (FCOS), IoU (RetinaNet), TOPK", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "POSITIVE_TYPE", "=", "'ATSS'", "\n", "\n", "# IoU parameter to select positves", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "FG_IOU_THRESHOLD", "=", "0.5", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "BG_IOU_THRESHOLD", "=", "0.4", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load": [[339, 364], ["defaults.DefaultTrainer.checkpointer.resume_or_load", "isinstance", "defaults.DefaultTrainer.checkpointer.has_checkpoint", "defaults.DefaultTrainer.get", "defaults.DefaultTrainer.model._sync_params_and_buffers", "detectron2.utils.comm.all_gather"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.checkpoint.Checkpointer.has_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather"], ["\n", "# topk for selecting candidate positive samples from each level", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "TOPK", "=", "9", "\n", "\n", "# regressing from a box ('BOX') or a point ('POINT')", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "REGRESSION_TYPE", "=", "'BOX'", "\n", "\n", "# Weight for bbox_regression loss", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "REG_LOSS_WEIGHT", "=", "2.0", "\n", "\n", "# Inference parameter", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "PRIOR_PROB", "=", "0.01", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "INFERENCE_TH", "=", "0.05", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "NMS_TH", "=", "0.6", "\n", "_C", ".", "MODEL", ".", "ATSS", ".", "PRE_NMS_TOP_N", "=", "1000", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# FCOS Options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "FCOS", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "NUM_CLASSES", "=", "81", "# the number of classes including background", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "FPN_STRIDES", "=", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "PRIOR_PROB", "=", "0.01", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "INFERENCE_TH", "=", "0.05", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "NMS_TH", "=", "0.6", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "PRE_NMS_TOP_N", "=", "1000", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_hooks": [[365, 412], ["defaults.DefaultTrainer.cfg.clone", "defaults.DefaultTrainer.defrost", "detectron2.utils.comm.is_main_process", "ret.append", "detectron2.utils.comm.is_main_process", "hooks.IterationTimer", "hooks.LRScheduler", "ret.append", "defaults.DefaultTrainer.test", "hooks.EvalHook", "ret.append", "hooks.PreciseBN", "hooks.PeriodicCheckpointer", "hooks.PeriodicWriter", "fvcore.nn.precise_bn.get_bn_modules", "defaults.DefaultTrainer.build_train_loader", "defaults.DefaultTrainer.build_writers"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_writers"], ["\n", "# Focal loss parameter: alpha", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "LOSS_ALPHA", "=", "0.25", "\n", "# Focal loss parameter: gamma", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "LOSS_GAMMA", "=", "2.0", "\n", "\n", "# the number of convolutions used in the cls and bbox tower", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "NUM_CONVS", "=", "4", "\n", "\n", "# if CENTER_SAMPLING_RADIUS <= 0, it will disable center sampling", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "CENTER_SAMPLING_RADIUS", "=", "0.0", "\n", "# IOU_LOSS_TYPE can be \"iou\", \"linear_iou\" or \"giou\"", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "IOU_LOSS_TYPE", "=", "\"iou\"", "\n", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "NORM_REG_TARGETS", "=", "False", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "CENTERNESS_ON_REG", "=", "False", "\n", "\n", "_C", ".", "MODEL", ".", "FCOS", ".", "USE_DCN_IN_TOWER", "=", "False", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# RetinaNet Options (Follow the Detectron version)", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "RETINANET", "=", "CN", "(", ")", "\n", "\n", "# This is the number of foreground classes and background.", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", "=", "81", "\n", "\n", "# Anchor aspect ratios to use", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_SIZES", "=", "(", "32", ",", "64", ",", "128", ",", "256", ",", "512", ")", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "ASPECT_RATIOS", "=", "(", "0.5", ",", "1.0", ",", "2.0", ")", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "ANCHOR_STRIDES", "=", "(", "8", ",", "16", ",", "32", ",", "64", ",", "128", ")", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "STRADDLE_THRESH", "=", "0", "\n", "\n", "# Anchor scales per octave", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "OCTAVE", "=", "2.0", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "SCALES_PER_OCTAVE", "=", "3", "\n", "\n", "# Use C5 or P5 to generate P6", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "USE_C5", "=", "True", "\n", "\n", "# Convolutions to use in the cls and bbox tower", "\n", "# NOTE: this doesn't include the last conv for logits", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "NUM_CONVS", "=", "4", "\n", "\n", "# Weight for bbox_regression loss", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "BBOX_REG_WEIGHT", "=", "4.0", "\n", "\n", "# Smooth L1 loss beta for bbox regression", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_writers": [[413, 423], ["defaults.default_writers"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_writers"], ["_C", ".", "MODEL", ".", "RETINANET", ".", "BBOX_REG_BETA", "=", "0.11", "\n", "\n", "# During inference, #locs to select based on cls score before NMS is performed", "\n", "# per FPN level", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "PRE_NMS_TOP_N", "=", "1000", "\n", "\n", "# IoU overlap ratio for labeling an anchor as positive", "\n", "# Anchors with >= iou overlap are labeled positive", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "FG_IOU_THRESHOLD", "=", "0.5", "\n", "\n", "# IoU overlap ratio for labeling an anchor as negative", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.train": [[424, 438], ["super().train", "len", "detectron2.utils.comm.is_main_process", "hasattr", "detectron2.evaluation.verify_results"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.verify_results"], ["# Anchors with < iou overlap are labeled negative", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "BG_IOU_THRESHOLD", "=", "0.4", "\n", "\n", "# Focal loss parameter: alpha", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "LOSS_ALPHA", "=", "0.25", "\n", "\n", "# Focal loss parameter: gamma", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "LOSS_GAMMA", "=", "2.0", "\n", "\n", "# Prior prob for the positives at the beginning of training. This is used to set", "\n", "# the bias init for the logits layer", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "PRIOR_PROB", "=", "0.01", "\n", "\n", "# Inference cls score threshold, anchors with score > INFERENCE_TH are", "\n", "# considered for inference", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.run_step": [[439, 442], ["defaults.DefaultTrainer._trainer.run_step"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.AMPTrainer.run_step"], ["_C", ".", "MODEL", ".", "RETINANET", ".", "INFERENCE_TH", "=", "0.05", "\n", "\n", "# NMS threshold used in RetinaNet", "\n", "_C", ".", "MODEL", ".", "RETINANET", ".", "NMS_TH", "=", "0.4", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_model": [[443, 456], ["detectron2.modeling.build_model", "logging.getLogger", "logging.getLogger.info"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model"], ["\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# FBNet options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "FBNET", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "ARCH", "=", "\"default\"", "\n", "# custom arch", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "ARCH_DEF", "=", "\"\"", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "BN_TYPE", "=", "\"bn\"", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "SCALE_FACTOR", "=", "1.0", "\n", "# the output channels will be divisible by WIDTH_DIVISOR", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "WIDTH_DIVISOR", "=", "1", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "DW_CONV_SKIP_BN", "=", "True", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_optimizer": [[457, 467], ["detectron2.solver.build_optimizer"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_optimizer"], ["_C", ".", "MODEL", ".", "FBNET", ".", "DW_CONV_SKIP_RELU", "=", "True", "\n", "\n", "# > 0 scale, == 0 skip, < 0 same dimension", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "DET_HEAD_LAST_SCALE", "=", "1.0", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "DET_HEAD_BLOCKS", "=", "[", "]", "\n", "# overwrite the stride for the head, 0 to use original value", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "DET_HEAD_STRIDE", "=", "0", "\n", "\n", "# > 0 scale, == 0 skip, < 0 same dimension", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "KPTS_HEAD_LAST_SCALE", "=", "0.0", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "KPTS_HEAD_BLOCKS", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_lr_scheduler": [[468, 475], ["detectron2.solver.build_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler"], ["# overwrite the stride for the head, 0 to use original value", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "KPTS_HEAD_STRIDE", "=", "0", "\n", "\n", "# > 0 scale, == 0 skip, < 0 same dimension", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "MASK_HEAD_LAST_SCALE", "=", "0.0", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "MASK_HEAD_BLOCKS", "=", "[", "]", "\n", "# overwrite the stride for the head, 0 to use original value", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "MASK_HEAD_STRIDE", "=", "0", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_train_loader": [[476, 486], ["detectron2.data.build_detection_train_loader"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader"], ["\n", "# 0 to use all blocks defined in arch_def", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "RPN_HEAD_BLOCKS", "=", "0", "\n", "_C", ".", "MODEL", ".", "FBNET", ".", "RPN_BN_TYPE", "=", "\"\"", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Solver", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "SOLVER", "=", "CN", "(", ")", "\n", "_C", ".", "SOLVER", ".", "MAX_ITER", "=", "40000", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_test_loader": [[487, 497], ["detectron2.data.build_detection_test_loader"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader"], ["\n", "_C", ".", "SOLVER", ".", "BASE_LR", "=", "0.001", "\n", "_C", ".", "SOLVER", ".", "BIAS_LR_FACTOR", "=", "2", "\n", "# the learning rate factor of deformable convolution offsets", "\n", "_C", ".", "SOLVER", ".", "DCONV_OFFSETS_LR_FACTOR", "=", "1.0", "\n", "\n", "_C", ".", "SOLVER", ".", "MOMENTUM", "=", "0.9", "\n", "\n", "_C", ".", "SOLVER", ".", "WEIGHT_DECAY", "=", "0.0005", "\n", "_C", ".", "SOLVER", ".", "WEIGHT_DECAY_BIAS", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.build_evaluator": [[498, 512], ["NotImplementedError"], "methods", ["None"], ["_C", ".", "SOLVER", ".", "GAMMA", "=", "0.1", "\n", "_C", ".", "SOLVER", ".", "STEPS", "=", "(", "30000", ",", ")", "\n", "\n", "_C", ".", "SOLVER", ".", "WARMUP_FACTOR", "=", "1.0", "/", "3", "\n", "_C", ".", "SOLVER", ".", "WARMUP_ITERS", "=", "500", "\n", "_C", ".", "SOLVER", ".", "WARMUP_METHOD", "=", "\"linear\"", "\n", "\n", "_C", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "=", "2500", "\n", "_C", ".", "SOLVER", ".", "TEST_PERIOD", "=", "0", "\n", "\n", "# Number of images per batch", "\n", "# This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will", "\n", "# see 2 images per batch", "\n", "_C", ".", "SOLVER", ".", "IMS_PER_BATCH", "=", "16", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.test": [[514, 566], ["logging.getLogger", "isinstance", "collections.OrderedDict", "enumerate", "cls.build_test_loader", "detectron2.evaluation.inference_on_dataset", "detectron2.utils.comm.is_main_process", "len", "len", "len", "len", "len", "isinstance", "logging.getLogger.info", "detectron2.evaluation.print_csv_format", "list", "cls.build_evaluator", "collections.OrderedDict.values", "logging.getLogger.warn"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.inference_on_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.print_csv_format", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_evaluator"], ["# Specific test options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "TEST", "=", "CN", "(", ")", "\n", "_C", ".", "TEST", ".", "EXPECTED_RESULTS", "=", "[", "]", "\n", "_C", ".", "TEST", ".", "EXPECTED_RESULTS_SIGMA_TOL", "=", "4", "\n", "# Number of images per batch", "\n", "# This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will", "\n", "# see 2 images per batch", "\n", "_C", ".", "TEST", ".", "IMS_PER_BATCH", "=", "8", "\n", "# Number of detections per image", "\n", "_C", ".", "TEST", ".", "DETECTIONS_PER_IMG", "=", "100", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Test-time augmentations for bounding box detection", "\n", "# See configs/test_time_aug/e2e_mask_rcnn_R-50-FPN_1x.yaml for an example", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", "=", "CN", "(", ")", "\n", "\n", "# Enable test-time augmentation for bounding box detection if True", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "=", "False", "\n", "\n", "# Horizontal flip at the original scale (id transform)", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "H_FLIP", "=", "False", "\n", "\n", "# Each scale is the pixel size of an image's shortest side", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "SCALES", "=", "(", ")", "\n", "\n", "# Max pixel size of the longer side", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "MAX_SIZE", "=", "4000", "\n", "\n", "# Horizontal flip at each scale", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "SCALE_H_FLIP", "=", "False", "\n", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "VOTE", "=", "False", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "VOTE_TH", "=", "0.66", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "SCALE_RANGES", "=", "(", ")", "\n", "_C", ".", "TEST", ".", "BBOX_AUG", ".", "MERGE_TYPE", "=", "'vote'", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Misc options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "OUTPUT_DIR", "=", "\".\"", "\n", "\n", "_C", ".", "PATHS_CATALOG", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"paths_catalog.py\"", ")", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Precision options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "\n", "# Precision of input, allowable: (float32, float16)", "\n", "_C", ".", "DTYPE", "=", "\"float32\"", "\n", "\n", "# Enable verbosity in apex.amp", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.auto_scale_workers": [[567, 637], ["cfg.clone.clone.clone", "cfg.clone.clone.is_frozen", "cfg.clone.clone.defrost", "int", "int", "int", "tuple", "int", "int", "logging.getLogger", "logging.getLogger.info", "round", "round", "round", "round", "round", "cfg.clone.clone.freeze", "int", "round"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], ["_C", ".", "AMP_VERBOSE", "=", "False", "\n", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_argument_parser": [[56, 116], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "hash", "os.getuid"], "function", ["None"], ["# Values to be used for image normalization", "\n", "_C", ".", "INPUT", ".", "PIXEL_STD", "=", "[", "1.", ",", "1.", ",", "1.", "]", "\n", "# Convert image to BGR format (for Caffe2 models), in range 0-255", "\n", "_C", ".", "INPUT", ".", "TO_BGR255", "=", "True", "\n", "\n", "# Image ColorJitter", "\n", "_C", ".", "INPUT", ".", "BRIGHTNESS", "=", "0.0", "\n", "_C", ".", "INPUT", ".", "CONTRAST", "=", "0.0", "\n", "_C", ".", "INPUT", ".", "SATURATION", "=", "0.0", "\n", "_C", ".", "INPUT", ".", "HUE", "=", "0.0", "\n", "\n", "# Flips", "\n", "_C", ".", "INPUT", ".", "HORIZONTAL_FLIP_PROB_TRAIN", "=", "0.5", "\n", "_C", ".", "INPUT", ".", "VERTICAL_FLIP_PROB_TRAIN", "=", "0.0", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# Dataset", "\n", "# -----------------------------------------------------------------------------", "\n", "_C", ".", "DATASETS", "=", "CN", "(", ")", "\n", "# List of the dataset names for training, as present in paths_catalog.py", "\n", "_C", ".", "DATASETS", ".", "TRAIN", "=", "(", ")", "\n", "# List of the dataset names for testing, as present in paths_catalog.py", "\n", "_C", ".", "DATASETS", ".", "TEST", "=", "(", ")", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# DataLoader", "\n", "# -----------------------------------------------------------------------------", "\n", "_C", ".", "DATALOADER", "=", "CN", "(", ")", "\n", "# Number of data loading threads", "\n", "_C", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "4", "\n", "# If > 0, this enforces that each collated batch should have a size divisible", "\n", "# by SIZE_DIVISIBILITY", "\n", "_C", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", "=", "0", "\n", "# If True, each batch should contain only images for which the aspect ratio", "\n", "# is compatible. This groups portrait images together, and landscape images", "\n", "# are not batched with portrait images.", "\n", "_C", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", "=", "True", "\n", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# Augmentation", "\n", "# -----------------------------------------------------------------------------", "\n", "_C", ".", "AUTOAUG", "=", "CN", "(", ")", "\n", "_C", ".", "AUTOAUG", ".", "USE", "=", "False", "\n", "_C", ".", "AUTOAUG", ".", "SEARCH", "=", "False", "\n", "_C", ".", "AUTOAUG", ".", "FT_WEIGHT", "=", "''", "\n", "_C", ".", "AUTOAUG", ".", "FT_ITERS", "=", "1000", "\n", "_C", ".", "AUTOAUG", ".", "FT_LR", "=", "5e-4", "\n", "_C", ".", "AUTOAUG", ".", "SCALE_SPLITS", "=", "[", "2048", ",", "10240", ",", "51200", "]", "\n", "_C", ".", "AUTOAUG", ".", "BOX_PROB", "=", "0.3", "\n", "_C", ".", "AUTOAUG", ".", "LIST_LENGTH", "=", "30", "+", "6", "+", "4", "\n", "_C", ".", "AUTOAUG", ".", "NUM_CHOICES", "=", "10", "\n", "_C", ".", "AUTOAUG", ".", "LIST", "=", "(", "6", ",", "9", ",", "5", ",", "3", ",", "3", ",", "4", ",", "2", ",", "4", ",", "4", ",", "4", ",", "5", ",", "2", ",", "4", ",", "1", ",", "4", ",", "2", ",", "6", ",", "4", ",", "2", ",", "2", ",", "2", ",", "6", ",", "2", ",", "2", ",", "2", ",", "0", ",", "5", ",", "1", ",", "3", ",", "0", ",", "8", ",", "5", ",", "2", ",", "8", ",", "7", ",", "5", ",", "1", ",", "3", ",", "3", ",", "3", ")", "\n", "_C", ".", "AUTOAUG", ".", "NUM_SUBPOLICIES", "=", "5", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Backbone options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "BACKBONE", "=", "CN", "(", ")", "\n", "\n", "# The backbone conv body to use", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup": [[118, 165], ["detectron2.utils.comm.get_rank", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.env.seed_all_rng", "detectron2.utils.comm.is_main_process", "detectron2.utils.file_io.PathManager.mkdirs", "hasattr", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.comm.is_main_process", "os.path.join", "detectron2.utils.logger.setup_logger.info", "detectron2.utils.comm.get_world_size", "detectron2.utils.collect_env.collect_env_info", "str", "detectron2.utils.file_io.PathManager.open", "f.write", "hasattr", "detectron2.utils.file_io.PathManager.open().read", "cfg.dump", "detectron2.utils.file_io.PathManager.open"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.seed_all_rng", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.collect_env.collect_env_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["# (e.g., 'FPN.add_fpn_ResNet101_conv5_body' to specify a ResNet-101-FPN", "\n", "# backbone)", "\n", "_C", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "=", "\"R-50-C4\"", "\n", "\n", "# Add StopGrad at a specified stage so the bottom layers are frozen", "\n", "_C", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_CONV_BODY_AT", "=", "2", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# FPN options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "FPN", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "FPN", ".", "USE_GN", "=", "False", "\n", "_C", ".", "MODEL", ".", "FPN", ".", "USE_RELU", "=", "False", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Group Norm options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "GROUP_NORM", "=", "CN", "(", ")", "\n", "# Number of dimensions per group in GroupNorm (-1 if using NUM_GROUPS)", "\n", "_C", ".", "MODEL", ".", "GROUP_NORM", ".", "DIM_PER_GP", "=", "-", "1", "\n", "# Number of groups in GroupNorm (-1 if using DIM_PER_GP)", "\n", "_C", ".", "MODEL", ".", "GROUP_NORM", ".", "NUM_GROUPS", "=", "32", "\n", "# GroupNorm's small constant in the denominator", "\n", "_C", ".", "MODEL", ".", "GROUP_NORM", ".", "EPSILON", "=", "1e-5", "\n", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# RPN options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "_C", ".", "MODEL", ".", "RPN", "=", "CN", "(", ")", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "USE_FPN", "=", "False", "\n", "# Base RPN anchor sizes given in absolute pixels w.r.t. the scaled network input", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "ANCHOR_SIZES", "=", "(", "32", ",", "64", ",", "128", ",", "256", ",", "512", ")", "\n", "# Stride of the feature map that RPN is attached.", "\n", "# For FPN, number of strides should match number of scales", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "ANCHOR_STRIDE", "=", "(", "16", ",", ")", "\n", "# RPN anchor aspect ratios", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "ASPECT_RATIOS", "=", "(", "0.5", ",", "1.0", ",", "2.0", ")", "\n", "# Remove RPN anchors that go outside the image by RPN_STRADDLE_THRESH pixels", "\n", "# Set to -1 or a large value, e.g. 100000, to disable pruning anchors", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "STRADDLE_THRESH", "=", "0", "\n", "# Minimum overlap required between an anchor and ground-truth box for the", "\n", "# (anchor, gt box) pair to be a positive example (IoU >= FG_IOU_THRESHOLD", "\n", "# ==> positive RPN example)", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "FG_IOU_THRESHOLD", "=", "0.7", "\n", "# Maximum overlap allowed between an anchor and ground-truth box for the", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_writers": [[167, 185], ["detectron2.utils.events.CommonMetricPrinter", "detectron2.utils.events.JSONWriter", "detectron2.utils.events.TensorboardXWriter", "os.path.join"], "function", ["None"], ["# ==> negative RPN example)", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "BG_IOU_THRESHOLD", "=", "0.3", "\n", "# Total number of RPN examples per image", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "BATCH_SIZE_PER_IMAGE", "=", "256", "\n", "# Target fraction of foreground (positive) examples per RPN minibatch", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "POSITIVE_FRACTION", "=", "0.5", "\n", "# Number of top scoring RPN proposals to keep before applying NMS", "\n", "# When FPN is used, this is *per FPN level* (not total)", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TRAIN", "=", "12000", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "PRE_NMS_TOP_N_TEST", "=", "6000", "\n", "# Number of top scoring RPN proposals to keep after applying NMS", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TRAIN", "=", "2000", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "POST_NMS_TOP_N_TEST", "=", "1000", "\n", "# NMS threshold used on RPN proposals", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "NMS_THRESH", "=", "0.7", "\n", "# Proposal height and width both need to be greater than RPN_MIN_SIZE", "\n", "# (a the scale used during training or inference)", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "MIN_SIZE", "=", "0", "\n", "# Number of top scoring RPN proposals to keep after combining proposals from", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.launch._find_free_port": [[15, 25], ["socket.socket", "socket.socket.bind", "socket.socket.close", "socket.socket.getsockname"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["def", "_find_free_port", "(", ")", ":", "\n", "    ", "import", "socket", "\n", "\n", "sock", "=", "socket", ".", "socket", "(", "socket", ".", "AF_INET", ",", "socket", ".", "SOCK_STREAM", ")", "\n", "# Binding to port 0 will cause the OS to find an available port for us", "\n", "sock", ".", "bind", "(", "(", "\"\"", ",", "0", ")", ")", "\n", "port", "=", "sock", ".", "getsockname", "(", ")", "[", "1", "]", "\n", "sock", ".", "close", "(", ")", "\n", "# NOTE: there is still a chance the port could be taken by other processes.", "\n", "return", "port", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.launch.launch": [[27, 83], ["torch.spawn", "main_func", "launch._find_free_port", "dist_url.startswith", "logging.getLogger", "logging.getLogger.warning"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage._find_free_port"], ["", "def", "launch", "(", "\n", "main_func", ",", "\n", "num_gpus_per_machine", ",", "\n", "num_machines", "=", "1", ",", "\n", "machine_rank", "=", "0", ",", "\n", "dist_url", "=", "None", ",", "\n", "args", "=", "(", ")", ",", "\n", "timeout", "=", "DEFAULT_TIMEOUT", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Launch multi-gpu or distributed training.\n    This function must be called on all machines involved in the training.\n    It will spawn child processes (defined by ``num_gpus_per_machine``) on each machine.\n\n    Args:\n        main_func: a function that will be called by `main_func(*args)`\n        num_gpus_per_machine (int): number of GPUs per machine\n        num_machines (int): the total number of machines\n        machine_rank (int): the rank of this machine\n        dist_url (str): url to connect to for distributed jobs, including protocol\n                       e.g. \"tcp://127.0.0.1:8686\".\n                       Can be set to \"auto\" to automatically select a free port on localhost\n        timeout (timedelta): timeout of the distributed workers\n        args (tuple): arguments passed to main_func\n    \"\"\"", "\n", "world_size", "=", "num_machines", "*", "num_gpus_per_machine", "\n", "if", "world_size", ">", "1", ":", "\n", "# https://github.com/pytorch/pytorch/pull/14391", "\n", "# TODO prctl in spawned processes", "\n", "\n", "        ", "if", "dist_url", "==", "\"auto\"", ":", "\n", "            ", "assert", "num_machines", "==", "1", ",", "\"dist_url=auto not supported in multi-machine jobs.\"", "\n", "port", "=", "_find_free_port", "(", ")", "\n", "dist_url", "=", "f\"tcp://127.0.0.1:{port}\"", "\n", "", "if", "num_machines", ">", "1", "and", "dist_url", ".", "startswith", "(", "\"file://\"", ")", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"file:// is not a reliable init_method in multi-machine jobs. Prefer tcp://\"", "\n", ")", "\n", "\n", "", "mp", ".", "spawn", "(", "\n", "_distributed_worker", ",", "\n", "nprocs", "=", "num_gpus_per_machine", ",", "\n", "args", "=", "(", "\n", "main_func", ",", "\n", "world_size", ",", "\n", "num_gpus_per_machine", ",", "\n", "machine_rank", ",", "\n", "dist_url", ",", "\n", "args", ",", "\n", "timeout", ",", "\n", ")", ",", "\n", "daemon", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "main_func", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.launch._distributed_worker": [[85, 126], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "detectron2.utils.comm.synchronize", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "range", "main_func", "torch.init_process_group", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "list", "torch.new_group", "logging.getLogger", "logging.getLogger.error", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "", "def", "_distributed_worker", "(", "\n", "local_rank", ",", "\n", "main_func", ",", "\n", "world_size", ",", "\n", "num_gpus_per_machine", ",", "\n", "machine_rank", ",", "\n", "dist_url", ",", "\n", "args", ",", "\n", "timeout", "=", "DEFAULT_TIMEOUT", ",", "\n", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"cuda is not available. Please check your installation.\"", "\n", "global_rank", "=", "machine_rank", "*", "num_gpus_per_machine", "+", "local_rank", "\n", "try", ":", "\n", "        ", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"NCCL\"", ",", "\n", "init_method", "=", "dist_url", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "global_rank", ",", "\n", "timeout", "=", "timeout", ",", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "error", "(", "\"Process group URL: {}\"", ".", "format", "(", "dist_url", ")", ")", "\n", "raise", "e", "\n", "# synchronize is needed here to prevent a possible timeout after calling init_process_group", "\n", "# See: https://github.com/facebookresearch/maskrcnn-benchmark/issues/172", "\n", "", "comm", ".", "synchronize", "(", ")", "\n", "\n", "assert", "num_gpus_per_machine", "<=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "\n", "# Setup the local process group (which contains ranks within the same machine)", "\n", "assert", "comm", ".", "_LOCAL_PROCESS_GROUP", "is", "None", "\n", "num_machines", "=", "world_size", "//", "num_gpus_per_machine", "\n", "for", "i", "in", "range", "(", "num_machines", ")", ":", "\n", "        ", "ranks_on_i", "=", "list", "(", "range", "(", "i", "*", "num_gpus_per_machine", ",", "(", "i", "+", "1", ")", "*", "num_gpus_per_machine", ")", ")", "\n", "pg", "=", "dist", ".", "new_group", "(", "ranks_on_i", ")", "\n", "if", "i", "==", "machine_rank", ":", "\n", "            ", "comm", ".", "_LOCAL_PROCESS_GROUP", "=", "pg", "\n", "\n", "", "", "main_func", "(", "*", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.CallbackHook.__init__": [[47, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", ",", "before_train", "=", "None", ",", "after_train", "=", "None", ",", "before_step", "=", "None", ",", "after_step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Each argument is a function that takes one argument: the trainer.\n        \"\"\"", "\n", "self", ".", "_before_train", "=", "before_train", "\n", "self", ".", "_before_step", "=", "before_step", "\n", "self", ".", "_after_step", "=", "after_step", "\n", "self", ".", "_after_train", "=", "after_train", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.CallbackHook.before_train": [[56, 59], ["hooks.CallbackHook._before_train"], "methods", ["None"], ["", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_before_train", ":", "\n", "            ", "self", ".", "_before_train", "(", "self", ".", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.CallbackHook.after_train": [[60, 67], ["hooks.CallbackHook._after_train"], "methods", ["None"], ["", "", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_after_train", ":", "\n", "            ", "self", ".", "_after_train", "(", "self", ".", "trainer", ")", "\n", "# The functions may be closures that hold reference to the trainer", "\n", "# Therefore, delete them to avoid circular reference.", "\n", "", "del", "self", ".", "_before_train", ",", "self", ".", "_after_train", "\n", "del", "self", ".", "_before_step", ",", "self", ".", "_after_step", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.CallbackHook.before_step": [[68, 71], ["hooks.CallbackHook._before_step"], "methods", ["None"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_before_step", ":", "\n", "            ", "self", ".", "_before_step", "(", "self", ".", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.CallbackHook.after_step": [[72, 75], ["hooks.CallbackHook._after_step"], "methods", ["None"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_after_step", ":", "\n", "            ", "self", ".", "_after_step", "(", "self", ".", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.IterationTimer.__init__": [[89, 99], ["fvcore.common.timer.Timer", "time.perf_counter", "fvcore.common.timer.Timer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "warmup_iter", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            warmup_iter (int): the number of iterations at the beginning to exclude\n                from timing.\n        \"\"\"", "\n", "self", ".", "_warmup_iter", "=", "warmup_iter", "\n", "self", ".", "_step_timer", "=", "Timer", "(", ")", "\n", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_total_timer", "=", "Timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.IterationTimer.before_train": [[100, 104], ["time.perf_counter", "hooks.IterationTimer._total_timer.reset", "hooks.IterationTimer._total_timer.pause"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset"], ["", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_total_timer", ".", "reset", "(", ")", "\n", "self", ".", "_total_timer", ".", "pause", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.IterationTimer.after_train": [[105, 128], ["logging.getLogger", "hooks.IterationTimer._total_timer.seconds", "logging.getLogger.info", "time.perf_counter", "logging.getLogger.info", "str", "str", "str", "datetime.timedelta", "datetime.timedelta", "datetime.timedelta", "int", "int", "int"], "methods", ["None"], ["", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_start_time", "\n", "total_time_minus_hooks", "=", "self", ".", "_total_timer", ".", "seconds", "(", ")", "\n", "hook_time", "=", "total_time", "-", "total_time_minus_hooks", "\n", "\n", "num_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "-", "self", ".", "trainer", ".", "start_iter", "-", "self", ".", "_warmup_iter", "\n", "\n", "if", "num_iter", ">", "0", "and", "total_time_minus_hooks", ">", "0", ":", "\n", "# Speed is meaningful only after warmup", "\n", "# NOTE this format is parsed by grep in some scripts", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Overall training speed: {} iterations in {} ({:.4f} s / it)\"", ".", "format", "(", "\n", "num_iter", ",", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time_minus_hooks", ")", ")", ")", ",", "\n", "total_time_minus_hooks", "/", "num_iter", ",", "\n", ")", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"Total training time: {} ({} on hooks)\"", ".", "format", "(", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", ",", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "hook_time", ")", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.IterationTimer.before_step": [[131, 134], ["hooks.IterationTimer._step_timer.reset", "hooks.IterationTimer._total_timer.resume"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_step_timer", ".", "reset", "(", ")", "\n", "self", ".", "_total_timer", ".", "resume", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.IterationTimer.after_step": [[135, 147], ["hooks.IterationTimer._total_timer.pause", "hooks.IterationTimer._step_timer.seconds", "hooks.IterationTimer.trainer.storage.put_scalars", "time.perf_counter", "hooks.IterationTimer._total_timer.reset"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalars", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "# +1 because we're in after_step, the current step is done", "\n", "# but not yet counted", "\n", "        ", "iter_done", "=", "self", ".", "trainer", ".", "iter", "-", "self", ".", "trainer", ".", "start_iter", "+", "1", "\n", "if", "iter_done", ">=", "self", ".", "_warmup_iter", ":", "\n", "            ", "sec", "=", "self", ".", "_step_timer", ".", "seconds", "(", ")", "\n", "self", ".", "trainer", ".", "storage", ".", "put_scalars", "(", "time", "=", "sec", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_total_timer", ".", "reset", "(", ")", "\n", "\n", "", "self", ".", "_total_timer", ".", "pause", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PeriodicWriter.__init__": [[157, 167], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "writers", ",", "period", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            writers (list[EventWriter]): a list of EventWriter objects\n            period (int):\n        \"\"\"", "\n", "self", ".", "_writers", "=", "writers", "\n", "for", "w", "in", "writers", ":", "\n", "            ", "assert", "isinstance", "(", "w", ",", "EventWriter", ")", ",", "w", "\n", "", "self", ".", "_period", "=", "period", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PeriodicWriter.after_step": [[168, 174], ["writer.write"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "if", "(", "self", ".", "trainer", ".", "iter", "+", "1", ")", "%", "self", ".", "_period", "==", "0", "or", "(", "\n", "self", ".", "trainer", ".", "iter", "==", "self", ".", "trainer", ".", "max_iter", "-", "1", "\n", ")", ":", "\n", "            ", "for", "writer", "in", "self", ".", "_writers", ":", "\n", "                ", "writer", ".", "write", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PeriodicWriter.after_train": [[175, 181], ["writer.write", "writer.close"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["", "", "", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "for", "writer", "in", "self", ".", "_writers", ":", "\n", "# If any new data is found (e.g. produced by other after_train),", "\n", "# write them before closing", "\n", "            ", "writer", ".", "write", "(", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PeriodicCheckpointer.before_train": [[194, 196], ["None"], "methods", ["None"], ["def", "before_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "max_iter", "=", "self", ".", "trainer", ".", "max_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PeriodicCheckpointer.after_step": [[197, 200], ["hooks.PeriodicCheckpointer.step"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "# No way to use **kwargs", "\n", "        ", "self", ".", "step", "(", "self", ".", "trainer", ".", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.LRScheduler.__init__": [[208, 220], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", "=", "None", ",", "scheduler", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            optimizer (torch.optim.Optimizer):\n            scheduler (torch.optim.LRScheduler or fvcore.common.param_scheduler.ParamScheduler):\n                if a :class:`ParamScheduler` object, it defines the multiplier over the base LR\n                in the optimizer.\n\n        If any argument is not given, will try to obtain it from the trainer.\n        \"\"\"", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_scheduler", "=", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.LRScheduler.before_train": [[221, 250], ["isinstance", "max", "detectron2.solver.LRMultiplier", "collections.Counter", "enumerate", "enumerate", "len", "collections.Counter.most_common", "len"], "methods", ["None"], ["", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "self", ".", "_optimizer", "or", "self", ".", "trainer", ".", "optimizer", "\n", "self", ".", "_scheduler", "=", "self", ".", "_scheduler", "or", "self", ".", "trainer", ".", "scheduler", "\n", "if", "isinstance", "(", "self", ".", "_scheduler", ",", "ParamScheduler", ")", ":", "\n", "            ", "self", ".", "_scheduler", "=", "LRMultiplier", "(", "\n", "self", ".", "_optimizer", ",", "\n", "self", ".", "_scheduler", ",", "\n", "self", ".", "trainer", ".", "max_iter", ",", "\n", "last_iter", "=", "self", ".", "trainer", ".", "iter", "-", "1", ",", "\n", ")", "\n", "\n", "# NOTE: some heuristics on what LR to summarize", "\n", "# summarize the param group with most parameters", "\n", "", "largest_group", "=", "max", "(", "len", "(", "g", "[", "\"params\"", "]", ")", "for", "g", "in", "self", ".", "_optimizer", ".", "param_groups", ")", "\n", "\n", "if", "largest_group", "==", "1", ":", "\n", "# If all groups have one parameter,", "\n", "# then find the most common initial LR, and use it for summary", "\n", "            ", "lr_count", "=", "Counter", "(", "[", "g", "[", "\"lr\"", "]", "for", "g", "in", "self", ".", "_optimizer", ".", "param_groups", "]", ")", "\n", "lr", "=", "lr_count", ".", "most_common", "(", ")", "[", "0", "]", "[", "0", "]", "\n", "for", "i", ",", "g", "in", "enumerate", "(", "self", ".", "_optimizer", ".", "param_groups", ")", ":", "\n", "                ", "if", "g", "[", "\"lr\"", "]", "==", "lr", ":", "\n", "                    ", "self", ".", "_best_param_group_id", "=", "i", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "for", "i", ",", "g", "in", "enumerate", "(", "self", ".", "_optimizer", ".", "param_groups", ")", ":", "\n", "                ", "if", "len", "(", "g", "[", "\"params\"", "]", ")", "==", "largest_group", ":", "\n", "                    ", "self", ".", "_best_param_group_id", "=", "i", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.LRScheduler.after_step": [[251, 255], ["hooks.LRScheduler.trainer.storage.put_scalar", "hooks.LRScheduler._scheduler.step"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step"], ["", "", "", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "lr", "=", "self", ".", "_optimizer", ".", "param_groups", "[", "self", ".", "_best_param_group_id", "]", "[", "\"lr\"", "]", "\n", "self", ".", "trainer", ".", "storage", ".", "put_scalar", "(", "\"lr\"", ",", "lr", ",", "smoothing_hint", "=", "False", ")", "\n", "self", ".", "_scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.AutogradProfiler.__init__": [[280, 292], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "enable_predicate", ",", "output_dir", ",", "*", ",", "use_cuda", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            enable_predicate (callable[trainer -> bool]): a function which takes a trainer,\n                and returns whether to enable the profiler.\n                It will be called once every step, and can be used to select which steps to profile.\n            output_dir (str): the output directory to dump tracing files.\n            use_cuda (bool): same as in `torch.autograd.profiler.profile`.\n        \"\"\"", "\n", "self", ".", "_enable_predicate", "=", "enable_predicate", "\n", "self", ".", "_use_cuda", "=", "use_cuda", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.AutogradProfiler.before_step": [[293, 299], ["hooks.AutogradProfiler._enable_predicate", "torch.autograd.profiler.profile", "hooks.AutogradProfiler._profiler.__enter__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.ScopedWS.__enter__"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_enable_predicate", "(", "self", ".", "trainer", ")", ":", "\n", "            ", "self", ".", "_profiler", "=", "torch", ".", "autograd", ".", "profiler", ".", "profile", "(", "use_cuda", "=", "self", ".", "_use_cuda", ")", "\n", "self", ".", "_profiler", ".", "__enter__", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_profiler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.AutogradProfiler.after_step": [[300, 319], ["hooks.AutogradProfiler._profiler.__exit__", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "hooks.AutogradProfiler._profiler.export_chrome_trace", "tempfile.TemporaryDirectory", "os.path.join", "hooks.AutogradProfiler._profiler.export_chrome_trace", "detectron2.utils.file_io.PathManager.open", "f.write", "open", "f.read"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.ScopedWS.__exit__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_profiler", "is", "None", ":", "\n", "            ", "return", "\n", "", "self", ".", "_profiler", ".", "__exit__", "(", "None", ",", "None", ",", "None", ")", "\n", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "out_file", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_output_dir", ",", "\"profiler-trace-iter{}.json\"", ".", "format", "(", "self", ".", "trainer", ".", "iter", ")", "\n", ")", "\n", "if", "\"://\"", "not", "in", "out_file", ":", "\n", "            ", "self", ".", "_profiler", ".", "export_chrome_trace", "(", "out_file", ")", "\n", "", "else", ":", "\n", "# Support non-posix filesystems", "\n", "            ", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"detectron2_profiler\"", ")", "as", "d", ":", "\n", "                ", "tmp_file", "=", "os", ".", "path", ".", "join", "(", "d", ",", "\"tmp.json\"", ")", "\n", "self", ".", "_profiler", ".", "export_chrome_trace", "(", "tmp_file", ")", "\n", "with", "open", "(", "tmp_file", ")", "as", "f", ":", "\n", "                    ", "content", "=", "f", ".", "read", "(", ")", "\n", "", "", "with", "PathManager", ".", "open", "(", "out_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.EvalHook.__init__": [[328, 343], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "eval_period", ",", "eval_function", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            eval_period (int): the period to run `eval_function`. Set to 0 to\n                not evaluate periodically (but still after the last iteration).\n            eval_function (callable): a function which takes no arguments, and\n                returns a nested dict of evaluation metrics.\n\n        Note:\n            This hook must be enabled in all or none workers.\n            If you would like only certain workers to perform evaluation,\n            give other workers a no-op function (`eval_function=lambda: None`).\n        \"\"\"", "\n", "self", ".", "_period", "=", "eval_period", "\n", "self", ".", "_func", "=", "eval_function", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.EvalHook._do_eval": [[344, 366], ["hooks.EvalHook._func", "detectron2.synchronize", "isinstance", "detectron2.evaluation.testing.flatten_results_dict", "detectron2.evaluation.testing.flatten_results_dict.items", "hooks.EvalHook.trainer.storage.put_scalars", "float", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.flatten_results_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalars"], ["", "def", "_do_eval", "(", "self", ")", ":", "\n", "        ", "results", "=", "self", ".", "_func", "(", ")", "\n", "\n", "if", "results", ":", "\n", "            ", "assert", "isinstance", "(", "\n", "results", ",", "dict", "\n", ")", ",", "\"Eval function must return a dict. Got {} instead.\"", ".", "format", "(", "results", ")", "\n", "\n", "flattened_results", "=", "flatten_results_dict", "(", "results", ")", "\n", "for", "k", ",", "v", "in", "flattened_results", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "float", "(", "v", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"[EvalHook] eval_function should return a nested dict of float. \"", "\n", "\"Got '{}: {}' instead.\"", ".", "format", "(", "k", ",", "v", ")", "\n", ")", "from", "e", "\n", "", "", "self", ".", "trainer", ".", "storage", ".", "put_scalars", "(", "**", "flattened_results", ",", "smoothing_hint", "=", "False", ")", "\n", "\n", "# Evaluation may take different time among workers.", "\n", "# A barrier make them start the next iteration together.", "\n", "", "comm", ".", "synchronize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.EvalHook.after_step": [[367, 371], ["hooks.EvalHook._do_eval"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.EvalHook._do_eval"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "next_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "\n", "if", "self", ".", "_period", ">", "0", "and", "next_iter", "%", "self", ".", "_period", "==", "0", ":", "\n", "            ", "self", ".", "_do_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.EvalHook.after_train": [[372, 379], ["hooks.EvalHook._do_eval"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.EvalHook._do_eval"], ["", "", "def", "after_train", "(", "self", ")", ":", "\n", "# This condition is to prevent the eval from running after a failed training", "\n", "        ", "if", "self", ".", "trainer", ".", "iter", "+", "1", ">=", "self", ".", "trainer", ".", "max_iter", ":", "\n", "            ", "self", ".", "_do_eval", "(", ")", "\n", "# func is likely a closure that holds reference to the trainer", "\n", "# therefore we clean it to avoid circular reference in the end", "\n", "", "del", "self", ".", "_func", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PreciseBN.__init__": [[391, 419], ["logging.getLogger", "len", "hooks.PreciseBN._logger.info", "fvcore.nn.precise_bn.get_bn_modules"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "period", ",", "model", ",", "data_loader", ",", "num_iter", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            period (int): the period this hook is run, or 0 to not run during training.\n                The hook will always run in the end of training.\n            model (nn.Module): a module whose all BN layers in training mode will be\n                updated by precise BN.\n                Note that user is responsible for ensuring the BN layers to be\n                updated are in training mode when this hook is triggered.\n            data_loader (iterable): it will produce data to be run by `model(data)`.\n            num_iter (int): number of iterations used to compute the precise\n                statistics.\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "len", "(", "get_bn_modules", "(", "model", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "\"PreciseBN is disabled because model does not contain BN layers in training mode.\"", "\n", ")", "\n", "self", ".", "_disabled", "=", "True", "\n", "return", "\n", "\n", "", "self", ".", "_model", "=", "model", "\n", "self", ".", "_data_loader", "=", "data_loader", "\n", "self", ".", "_num_iter", "=", "num_iter", "\n", "self", ".", "_period", "=", "period", "\n", "self", ".", "_disabled", "=", "False", "\n", "\n", "self", ".", "_data_iter", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PreciseBN.after_step": [[420, 425], ["hooks.PreciseBN.update_stats"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PreciseBN.update_stats"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "next_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "\n", "is_final", "=", "next_iter", "==", "self", ".", "trainer", ".", "max_iter", "\n", "if", "is_final", "or", "(", "self", ".", "_period", ">", "0", "and", "next_iter", "%", "self", ".", "_period", "==", "0", ")", ":", "\n", "            ", "self", ".", "update_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.hooks.PreciseBN.update_stats": [[426, 451], ["iter", "itertools.count", "detectron2.utils.events.EventStorage", "hooks.PreciseBN._logger.info", "fvcore.nn.precise_bn.update_bn_stats", "hooks.PreciseBN.update_stats.data_loader"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "", "def", "update_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Update the model with precise statistics. Users can manually call this method.\n        \"\"\"", "\n", "if", "self", ".", "_disabled", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "_data_iter", "is", "None", ":", "\n", "            ", "self", ".", "_data_iter", "=", "iter", "(", "self", ".", "_data_loader", ")", "\n", "\n", "", "def", "data_loader", "(", ")", ":", "\n", "            ", "for", "num_iter", "in", "itertools", ".", "count", "(", "1", ")", ":", "\n", "                ", "if", "num_iter", "%", "100", "==", "0", ":", "\n", "                    ", "self", ".", "_logger", ".", "info", "(", "\n", "\"Running precise-BN ... {}/{} iterations.\"", ".", "format", "(", "num_iter", ",", "self", ".", "_num_iter", ")", "\n", ")", "\n", "# This way we can reuse the same iterator", "\n", "", "yield", "next", "(", "self", ".", "_data_iter", ")", "\n", "\n", "", "", "with", "EventStorage", "(", ")", ":", "# capture events in a new storage to discard them", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "\"Running precise-BN for {} iterations...  \"", ".", "format", "(", "self", ".", "_num_iter", ")", "\n", "+", "\"Note that this could produce different statistics every time.\"", "\n", ")", "\n", "update_bn_stats", "(", "self", ".", "_model", ",", "data_loader", "(", ")", ",", "self", ".", "_num_iter", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.HookBase.before_train": [[55, 60], ["None"], "methods", ["None"], ["def", "before_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called before the first iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.HookBase.after_train": [[61, 66], ["None"], "methods", ["None"], ["", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called after the last iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.HookBase.before_step": [[67, 72], ["None"], "methods", ["None"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called before each iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.HookBase.after_step": [[73, 78], ["None"], "methods", ["None"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called after each iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.__init__": [[99, 106], ["detectron2.utils.logger._log_api_usage"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._log_api_usage"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_hooks", ":", "List", "[", "HookBase", "]", "=", "[", "]", "\n", "self", ".", "iter", ":", "int", "\n", "self", ".", "start_iter", ":", "int", "\n", "self", ".", "max_iter", ":", "int", "\n", "self", ".", "storage", ":", "EventStorage", "\n", "_log_api_usage", "(", "\"trainer.\"", "+", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.register_hooks": [[107, 124], ["train_loop.TrainerBase._hooks.extend", "isinstance", "weakref.proxy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "register_hooks", "(", "self", ",", "hooks", ":", "List", "[", "Optional", "[", "HookBase", "]", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Register hooks to the trainer. The hooks are executed in the order\n        they are registered.\n\n        Args:\n            hooks (list[Optional[HookBase]]): list of hooks\n        \"\"\"", "\n", "hooks", "=", "[", "h", "for", "h", "in", "hooks", "if", "h", "is", "not", "None", "]", "\n", "for", "h", "in", "hooks", ":", "\n", "            ", "assert", "isinstance", "(", "h", ",", "HookBase", ")", "\n", "# To avoid circular reference, hooks and trainer cannot own each other.", "\n", "# This normally does not matter, but will cause memory leak if the", "\n", "# involved objects contain __del__:", "\n", "# See http://engineering.hearsaysocial.com/2013/06/16/circular-references-in-python/", "\n", "h", ".", "trainer", "=", "weakref", ".", "proxy", "(", "self", ")", "\n", "", "self", ".", "_hooks", ".", "extend", "(", "hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train": [[125, 152], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.events.EventStorage", "train_loop.TrainerBase.before_train", "range", "train_loop.TrainerBase.after_train", "train_loop.TrainerBase.before_step", "train_loop.TrainerBase.run_step", "train_loop.TrainerBase.after_step", "logging.getLogger.exception"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.before_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.after_train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.before_step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.AMPTrainer.run_step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.after_step"], ["", "def", "train", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter, max_iter (int): See docs above\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "\n", "self", ".", "iter", "=", "self", ".", "start_iter", "=", "start_iter", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "self", ".", "storage", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "before_train", "(", ")", "\n", "for", "self", ".", "iter", "in", "range", "(", "start_iter", ",", "max_iter", ")", ":", "\n", "                    ", "self", ".", "before_step", "(", ")", "\n", "self", ".", "run_step", "(", ")", "\n", "self", ".", "after_step", "(", ")", "\n", "# self.iter == max_iter can be used by `after_train` to", "\n", "# tell whether the training successfully finished or failed", "\n", "# due to exceptions.", "\n", "", "self", ".", "iter", "+=", "1", "\n", "", "except", "Exception", ":", "\n", "                ", "logger", ".", "exception", "(", "\"Exception during training:\"", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "self", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.before_train": [[153, 156], ["h.before_train"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.before_train"], ["", "", "", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "before_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.after_train": [[157, 161], ["h.after_train"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.after_train"], ["", "", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "storage", ".", "iter", "=", "self", ".", "iter", "\n", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.before_step": [[162, 169], ["h.before_step"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.before_step"], ["", "", "def", "before_step", "(", "self", ")", ":", "\n", "# Maintain the invariant that storage.iter == trainer.iter", "\n", "# for the entire execution of each step", "\n", "        ", "self", ".", "storage", ".", "iter", "=", "self", ".", "iter", "\n", "\n", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "before_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.after_step": [[170, 173], ["h.after_step"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.after_step"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "for", "h", "in", "self", ".", "_hooks", ":", "\n", "            ", "h", ".", "after_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.run_step": [[174, 176], ["None"], "methods", ["None"], ["", "", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.SimpleTrainer.__init__": [[197, 219], ["train_loop.TrainerBase.__init__", "model.train", "iter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["def", "__init__", "(", "self", ",", "model", ",", "data_loader", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model: a torch Module. Takes a data from data_loader and returns a\n                dict of losses.\n            data_loader: an iterable. Contains data to be used to call model.\n            optimizer: a torch optimizer.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "\"\"\"\n        We set the model to training mode in the trainer.\n        However it's valid to train a model that's in eval mode.\n        If you want your model (or a submodule of it) to behave\n        like evaluation during training, you can overwrite its train() method.\n        \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "_data_loader_iter", "=", "iter", "(", "data_loader", ")", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.SimpleTrainer.run_step": [[220, 254], ["time.perf_counter", "next", "train_loop.SimpleTrainer.model", "sum", "train_loop.SimpleTrainer.optimizer.zero_grad", "sum.backward", "train_loop.SimpleTrainer._write_metrics", "train_loop.SimpleTrainer.optimizer.step", "time.perf_counter", "train_loop.SimpleTrainer.values"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_func.DeformRoIPoolingFunction.backward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.SimpleTrainer._write_metrics", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step"], ["", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Implement the standard training logic described above.\n        \"\"\"", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[SimpleTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\"\"\"\n        If you want to do something with the data, you can wrap the dataloader.\n        \"\"\"", "\n", "data", "=", "next", "(", "self", ".", "_data_loader_iter", ")", "\n", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "\"\"\"\n        If you want to do something with the losses, you can wrap the model.\n        \"\"\"", "\n", "loss_dict", "=", "self", ".", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "\"\"\"\n        If you need to accumulate gradients or do something similar, you can\n        wrap the optimizer with your custom `zero_grad()` method.\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "\n", "self", ".", "_write_metrics", "(", "loss_dict", ",", "data_time", ")", "\n", "\n", "\"\"\"\n        If you need gradient clipping/scaling or other processing, you can\n        wrap the optimizer with your custom `step()` method. But it is\n        suboptimal as explained in https://arxiv.org/abs/2006.15704 Sec 3.2.4\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.SimpleTrainer._write_metrics": [[255, 296], ["detectron2.gather", "detectron2.is_main_process", "v.detach().cpu().item", "detectron2.utils.events.get_event_storage", "numpy.max", "detectron2.utils.events.get_event_storage.put_scalar", "sum", "detectron2.utils.events.get_event_storage.put_scalar", "loss_dict.items", "numpy.mean", "metrics_dict.values", "numpy.isfinite", "FloatingPointError", "len", "detectron2.utils.events.get_event_storage.put_scalars", "v.detach().cpu", "x.pop", "all_metrics_dict[].keys", "v.detach"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalars"], ["", "def", "_write_metrics", "(", "\n", "self", ",", "\n", "loss_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "data_time", ":", "float", ",", "\n", "prefix", ":", "str", "=", "\"\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss_dict (dict): dict of scalar losses\n            data_time (float): time taken by the dataloader iteration\n        \"\"\"", "\n", "metrics_dict", "=", "{", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "for", "k", ",", "v", "in", "loss_dict", ".", "items", "(", ")", "}", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "\n", "# Gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "\n", "# data_time among workers can have high variance. The actual latency", "\n", "# caused by data_time is the maximum among workers.", "\n", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "# average the rest metrics", "\n", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "total_losses_reduced", "=", "sum", "(", "metrics_dict", ".", "values", "(", ")", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "total_losses_reduced", ")", ":", "\n", "                ", "raise", "FloatingPointError", "(", "\n", "f\"Loss became infinite or NaN at iteration={self.iter}!\\n\"", "\n", "f\"loss_dict = {metrics_dict}\"", "\n", ")", "\n", "\n", "", "storage", ".", "put_scalar", "(", "\"{}total_loss\"", ".", "format", "(", "prefix", ")", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.AMPTrainer.__init__": [[304, 322], ["isinstance", "train_loop.SimpleTrainer.__init__", "isinstance", "GradScaler", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "data_loader", ",", "optimizer", ",", "grad_scaler", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model, data_loader, optimizer: same as in :class:`SimpleTrainer`.\n            grad_scaler: torch GradScaler to automatically scale gradients.\n        \"\"\"", "\n", "unsupported", "=", "\"AMPTrainer does not support single-process multi-device training!\"", "\n", "if", "isinstance", "(", "model", ",", "DistributedDataParallel", ")", ":", "\n", "            ", "assert", "not", "(", "model", ".", "device_ids", "and", "len", "(", "model", ".", "device_ids", ")", ">", "1", ")", ",", "unsupported", "\n", "", "assert", "not", "isinstance", "(", "model", ",", "DataParallel", ")", ",", "unsupported", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "data_loader", ",", "optimizer", ")", "\n", "\n", "if", "grad_scaler", "is", "None", ":", "\n", "            ", "from", "torch", ".", "cuda", ".", "amp", "import", "GradScaler", "\n", "\n", "grad_scaler", "=", "GradScaler", "(", ")", "\n", "", "self", ".", "grad_scaler", "=", "grad_scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.AMPTrainer.run_step": [[323, 346], ["torch.cuda.is_available", "time.perf_counter", "next", "train_loop.AMPTrainer.optimizer.zero_grad", "train_loop.AMPTrainer.grad_scaler.scale().backward", "train_loop.AMPTrainer._write_metrics", "train_loop.AMPTrainer.grad_scaler.step", "train_loop.AMPTrainer.grad_scaler.update", "time.perf_counter", "autocast", "train_loop.AMPTrainer.model", "sum", "train_loop.AMPTrainer.values", "train_loop.AMPTrainer.grad_scaler.scale"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.dcn.deform_pool_func.DeformRoIPoolingFunction.backward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.SimpleTrainer._write_metrics", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.scale"], ["", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Implement the AMP training logic.\n        \"\"\"", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[AMPTrainer] model was changed to eval mode!\"", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"[AMPTrainer] CUDA is required for AMP training!\"", "\n", "from", "torch", ".", "cuda", ".", "amp", "import", "autocast", "\n", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "data", "=", "next", "(", "self", ".", "_data_loader_iter", ")", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "with", "autocast", "(", ")", ":", "\n", "            ", "loss_dict", "=", "self", ".", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "grad_scaler", ".", "scale", "(", "losses", ")", ".", "backward", "(", ")", "\n", "\n", "self", ".", "_write_metrics", "(", "loss_dict", ",", "data_time", ")", "\n", "\n", "self", ".", "grad_scaler", ".", "step", "(", "self", ".", "optimizer", ")", "\n", "self", ".", "grad_scaler", ".", "update", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountingLoader.__init__": [[38, 40], ["None"], "methods", ["None"], ["            ", "all_losses", "/=", "world_size", "\n", "", "reduced_losses", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "loss_names", ",", "all_losses", ")", "}", "\n", "", "return", "reduced_losses", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountingLoader.__iter__": [[41, 59], ["iter", "detectron2.utils.events.get_event_storage", "next", "len", "detectron2.utils.events.get_event_storage.put_scalar"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar"], ["\n", "\n", "", "def", "_update_loss_scale_hist", "(", "cfg", ",", "loss_scale", ",", "loss_hist", ")", ":", "\n", "    ", "loss_vec", ",", "gt_areas", "=", "loss_scale", "\n", "scale_splits", "=", "torch", ".", "Tensor", "(", "[", "0", "]", "+", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", ")", "+", "1", ")", ":", "\n", "        ", "_idx", "=", "(", "gt_areas", ">", "scale_splits", "[", "i", "-", "1", "]", ")", "*", "(", "gt_areas", "<", "scale_splits", "[", "i", "]", ")", "\n", "loss_hist", "[", "i", "-", "1", "]", "+=", "loss_vec", "[", "_idx", "]", ".", "sum", "(", ")", "\n", "", "loss_hist", "[", "-", "1", "]", "+=", "loss_vec", "[", "gt_areas", ">", "scale_splits", "[", "-", "1", "]", "]", ".", "sum", "(", ")", "\n", "return", "loss_hist", "\n", "\n", "\n", "", "def", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.__init__": [[62, 64], ["logging.getLogger"], "methods", ["None"], ["checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write": [[65, 72], ["detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.histories().items", "trainer.SampleCountMetricPrinter.logger.info", "key.startswith", "detectron2.utils.events.get_event_storage.histories", "batch_stats_strs.append", "buf.avg"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.histories", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.metric_logger.SmoothedValue.avg"], ["search", "=", "None", ",", "\n", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.trainer\"", ")", "if", "search", "is", "None", "else", "search", "\n", "logger", ".", "info", "(", "\"Start training\"", ")", "\n", "meters", "=", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "max_iter", "=", "len", "(", "data_loader", ")", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", "\n", "model", ".", "train", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.extract_embedder_from_model": [[75, 82], ["isinstance", "hasattr", "hasattr"], "methods", ["None"], ["\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "cfg", ".", "defrost", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test": [[85, 146], ["logging.getLogger", "isinstance", "collections.OrderedDict", "enumerate", "cls.build_test_loader", "detectron2.utils.comm.is_main_process", "len", "len", "len", "len", "len", "detectron2.utils.comm.is_main_process", "detectron2.evaluation.inference_on_dataset", "isinstance", "logging.getLogger.info", "detectron2.evaluation.print_csv_format", "list", "cls.extract_embedder_from_model", "cls.build_evaluator", "collections.OrderedDict.values", "logging.getLogger.warn"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.inference_on_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.print_csv_format", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.extract_embedder_from_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_evaluator"], ["\n", "for", "iteration", ",", "(", "images", ",", "targets", ",", "_", ")", "in", "enumerate", "(", "data_loader", ",", "start_iter", ")", ":", "\n", "\n", "        ", "if", "any", "(", "len", "(", "target", ")", "<", "1", "for", "target", "in", "targets", ")", ":", "\n", "            ", "logger", ".", "error", "(", "f\"Iteration={iteration + 1} || Image Ids used for training {_} || targets Length={[len(target) for target in targets]}\"", ")", "\n", "continue", "\n", "", "data_time", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "iteration", "=", "iteration", "+", "1", "\n", "arguments", "[", "\"iteration\"", "]", "=", "iteration", "\n", "\n", "images", "=", "images", ".", "to", "(", "device", ")", "\n", "targets", "=", "[", "target", ".", "to", "(", "device", ")", "for", "target", "in", "targets", "]", "\n", "\n", "loss_dict", ",", "loss_scale", "=", "model", "(", "images", ",", "targets", ")", "\n", "if", "search", ":", "\n", "            ", "loss_hist", "=", "_update_loss_scale_hist", "(", "cfg", ",", "loss_scale", ",", "loss_hist", ")", "\n", "\n", "", "losses", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "# reduce losses over all GPUs for logging purposes", "\n", "loss_dict_reduced", "=", "reduce_loss_dict", "(", "loss_dict", ")", "\n", "losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "meters", ".", "update", "(", "loss", "=", "losses_reduced", ",", "**", "loss_dict_reduced", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "# Note: If mixed precision is not used, this ends up doing nothing", "\n", "# Otherwise apply loss scaling for mixed-precision recipe", "\n", "with", "amp", ".", "scale_loss", "(", "losses", ",", "optimizer", ")", "as", "scaled_losses", ":", "\n", "            ", "scaled_losses", ".", "backward", "(", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "batch_time", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "meters", ".", "update", "(", "time", "=", "batch_time", ",", "data", "=", "data_time", ")", "\n", "\n", "eta_seconds", "=", "meters", ".", "time", ".", "global_avg", "*", "(", "max_iter", "-", "iteration", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "\n", "if", "iteration", "%", "20", "==", "0", "or", "iteration", "==", "max_iter", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "meters", ".", "delimiter", ".", "join", "(", "\n", "[", "\n", "\"eta: {eta}\"", ",", "\n", "\"iter: {iter}\"", ",", "\n", "\"{meters}\"", ",", "\n", "\"lr: {lr:.6f}\"", ",", "\n", "\"max mem: {memory:.0f}\"", ",", "\n", "]", "\n", ")", ".", "format", "(", "\n", "eta", "=", "eta_string", ",", "\n", "iter", "=", "iteration", ",", "\n", "meters", "=", "str", "(", "meters", ")", ",", "\n", "lr", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", ",", "\n", ")", "\n", ")", "\n", "", "if", "iteration", "%", "checkpoint_period", "==", "0", ":", "\n", "            ", "checkpointer", ".", "save", "(", "\"model_{:07d}\"", ".", "format", "(", "iteration", ")", ",", "**", "arguments", ")", "\n", "", "if", "data_loader_val", "is", "not", "None", "and", "test_period", ">", "0", "and", "iteration", "%", "test_period", "==", "0", ":", "\n", "            ", "meters_val", "=", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "synchronize", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_evaluator": [[147, 186], ["evaluators.append", "detectron2.evaluation.DatasetEvaluators", "os.path.join", "densepose.evaluation.d2_evaluator_adapter.Detectron2COCOEvaluatorAdapter", "densepose.evaluation.evaluator.build_densepose_evaluator_storage", "evaluators.append", "densepose.evaluation.evaluator.DensePoseCOCOEvaluator"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.build_densepose_evaluator_storage"], ["_", "=", "inference", "(", "# The result can be used for additional logging, e. g. for TensorBoard", "\n", "model", ",", "\n", "# The method changes the segmentation mask format in a data loader,", "\n", "# so every time a new data loader is created:", "\n", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "(", "get_world_size", "(", ")", ">", "1", ")", ",", "is_for_period", "=", "True", ")", ",", "\n", "dataset_name", "=", "\"[Validation]\"", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "box_only", "=", "False", "if", "cfg", ".", "MODEL", ".", "RETINANET_ON", "else", "cfg", ".", "MODEL", ".", "RPN_ONLY", ",", "\n", "device", "=", "cfg", ".", "MODEL", ".", "DEVICE", ",", "\n", "expected_results", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS", ",", "\n", "expected_results_sigma_tol", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS_SIGMA_TOL", ",", "\n", "output_folder", "=", "None", ",", "\n", ")", "\n", "synchronize", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Should be one image for each GPU:", "\n", "                ", "for", "iteration_val", ",", "(", "images_val", ",", "targets_val", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "data_loader_val", ")", ")", ":", "\n", "                    ", "images_val", "=", "images_val", ".", "to", "(", "device", ")", "\n", "targets_val", "=", "[", "target", ".", "to", "(", "device", ")", "for", "target", "in", "targets_val", "]", "\n", "loss_dict", "=", "model", "(", "images_val", ",", "targets_val", ")", "\n", "losses", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "loss_dict_reduced", "=", "reduce_loss_dict", "(", "loss_dict", ")", "\n", "losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "meters_val", ".", "update", "(", "loss", "=", "losses_reduced", ",", "**", "loss_dict_reduced", ")", "\n", "", "", "synchronize", "(", ")", "\n", "logger", ".", "info", "(", "\n", "meters_val", ".", "delimiter", ".", "join", "(", "\n", "[", "\n", "\"[Validation]: \"", ",", "\n", "\"eta: {eta}\"", ",", "\n", "\"iter: {iter}\"", ",", "\n", "\"{meters}\"", ",", "\n", "\"lr: {lr:.6f}\"", ",", "\n", "\"max mem: {memory:.0f}\"", ",", "\n", "]", "\n", ")", ".", "format", "(", "\n", "eta", "=", "eta_string", ",", "\n", "iter", "=", "iteration", ",", "\n", "meters", "=", "str", "(", "meters_val", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_optimizer": [[187, 212], ["detectron2.solver.build.get_default_optimizer_params", "torch.optim.SGD", "detectron2.solver.build.maybe_add_gradient_clipping"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.get_default_optimizer_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping"], ["lr", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", ",", "\n", ")", "\n", ")", "\n", "", "if", "iteration", "==", "max_iter", ":", "\n", "            ", "checkpointer", ".", "save", "(", "\"model_final\"", ",", "**", "arguments", ")", "\n", "\n", "", "", "total_training_time", "=", "time", ".", "time", "(", ")", "-", "start_training_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_training_time", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total training time: {} ({:.4f} s / it)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_training_time", "/", "(", "max_iter", ")", "\n", ")", "\n", ")", "\n", "return", "loss_hist", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_test_loader": [[213, 216], ["densepose.data.build_detection_test_loader", "densepose.data.DatasetMapper"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_train_loader": [[217, 231], ["densepose.data.build_detection_train_loader", "cls.build_model", "cls.build_model.to", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "densepose.data.build_inference_based_loaders", "densepose.data.build_combined_loader", "trainer.SampleCountingLoader", "densepose.data.has_inference_based_loaders", "densepose.data.DatasetMapper", "detectron2.checkpoint.DetectionCheckpointer"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_inference_based_loaders", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_combined_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.has_inference_based_loaders"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_writers": [[232, 236], ["super().build_writers", "super().build_writers.append", "trainer.SampleCountMetricPrinter"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.build_writers"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test_with_TTA": [[237, 256], ["logging.getLogger", "logging.getLogger.info", "densepose.load_from_cfg", "densepose.DensePoseGeneralizedRCNNWithTTA", "cls.test", "collections.OrderedDict", "densepose.DensePoseDatasetMapperTTA", "cls.build_evaluator", "os.path.join", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.transform.load_from_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_evaluator"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.augmentations.scale_aware_aug.SA_Aug.__init__": [[13, 50], ["fcos_core.augmentations.image_level_augs.img_level_augs.Img_augs", "list", "list", "range", "fcos_core.augmentations.box_level_augs.box_level_augs.Box_augs", "fcos_core.utils.comm.get_world_size", "fcos_core.augmentations.box_level_augs.color_augs.color_aug_func.keys", "fcos_core.augmentations.box_level_augs.geometric_augs.geometric_aug_func.keys", "policies.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "autoaug_list", "=", "cfg", ".", "AUTOAUG", ".", "LIST", "\n", "num_policies", "=", "cfg", ".", "AUTOAUG", ".", "NUM_SUBPOLICIES", "\n", "max_iters", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "scale_splits", "=", "cfg", ".", "AUTOAUG", ".", "SCALE_SPLITS", "\n", "box_prob", "=", "cfg", ".", "AUTOAUG", ".", "BOX_PROB", "\n", "self", ".", "search", "=", "cfg", ".", "AUTOAUG", ".", "SEARCH", "\n", "\n", "img_aug_list", "=", "autoaug_list", "[", ":", "4", "]", "\n", "img_augs_dict", "=", "{", "'zoom_out'", ":", "{", "'prob'", ":", "img_aug_list", "[", "0", "]", "*", "0.05", ",", "'level'", ":", "img_aug_list", "[", "1", "]", "}", ",", "\n", "'zoom_in'", ":", "{", "'prob'", ":", "img_aug_list", "[", "2", "]", "*", "0.05", ",", "'level'", ":", "img_aug_list", "[", "3", "]", "}", "}", "\n", "self", ".", "img_augs", "=", "Img_augs", "(", "img_augs_dict", "=", "img_augs_dict", ")", "\n", "\n", "box_aug_list", "=", "autoaug_list", "[", "4", ":", "]", "\n", "color_aug_types", "=", "list", "(", "color_aug_func", ".", "keys", "(", ")", ")", "\n", "geometric_aug_types", "=", "list", "(", "geometric_aug_func", ".", "keys", "(", ")", ")", "\n", "policies", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_policies", ")", ":", "\n", "            ", "_start_pos", "=", "i", "*", "6", "\n", "sub_policy", "=", "[", "(", "color_aug_types", "[", "box_aug_list", "[", "_start_pos", "+", "0", "]", "%", "len", "(", "color_aug_types", ")", "]", ",", "box_aug_list", "[", "_start_pos", "+", "1", "]", "*", "0.1", ",", "box_aug_list", "[", "_start_pos", "+", "2", "]", ",", ")", ",", "# box_color policy", "\n", "(", "geometric_aug_types", "[", "box_aug_list", "[", "_start_pos", "+", "3", "]", "%", "len", "(", "geometric_aug_types", ")", "]", ",", "box_aug_list", "[", "_start_pos", "+", "4", "]", "*", "0.1", ",", "box_aug_list", "[", "_start_pos", "+", "5", "]", ")", "]", "# box_geometric policy", "\n", "policies", ".", "append", "(", "sub_policy", ")", "\n", "\n", "", "_start_pos", "=", "num_policies", "*", "6", "\n", "scale_ratios", "=", "{", "'area'", ":", "[", "box_aug_list", "[", "_start_pos", "+", "0", "]", ",", "box_aug_list", "[", "_start_pos", "+", "1", "]", ",", "box_aug_list", "[", "_start_pos", "+", "2", "]", "]", ",", "\n", "'prob'", ":", "[", "box_aug_list", "[", "_start_pos", "+", "3", "]", ",", "box_aug_list", "[", "_start_pos", "+", "4", "]", ",", "box_aug_list", "[", "_start_pos", "+", "5", "]", "]", "}", "\n", "\n", "box_augs_dict", "=", "{", "'policies'", ":", "policies", ",", "'scale_ratios'", ":", "scale_ratios", "}", "\n", "\n", "self", ".", "box_augs", "=", "Box_augs", "(", "box_augs_dict", "=", "box_augs_dict", ",", "max_iters", "=", "max_iters", ",", "scale_splits", "=", "scale_splits", ",", "box_prob", "=", "box_prob", ")", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "\n", "self", ".", "count", "=", "0", "\n", "num_gpus", "=", "get_world_size", "(", ")", "\n", "self", ".", "batch_size", "=", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", "//", "num_gpus", "\n", "self", ".", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "\n", "if", "self", ".", "num_workers", "==", "0", ":", "\n", "            ", "self", ".", "num_workers", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.augmentations.scale_aware_aug.SA_Aug.__call__": [[51, 58], ["scale_aware_aug.SA_Aug.img_augs", "scale_aware_aug.SA_Aug.box_augs"], "methods", ["None"], ["\n", "", "", "def", "__call__", "(", "self", ",", "tensor", ",", "target", ")", ":", "\n", "\n", "        ", "iteration", "=", "self", ".", "max_iters", "if", "self", ".", "search", "else", "self", ".", "count", "//", "self", ".", "batch_size", "*", "self", ".", "num_workers", "\n", "tensor", ",", "target", "=", "self", ".", "img_augs", "(", "tensor", ",", "target", ")", "\n", "tensor_out", ",", "target_out", "=", "self", ".", "box_augs", "(", "tensor", ",", "target", ",", "iteration", "=", "iteration", ")", "\n", "self", ".", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.augmentations.vis._vis": [[6, 18], ["torch.clone", "torch.arange().long().tolist", "torchvision.utils.save_image", "copy.deepcopy", "torch.Tensor().reshape", "a[].float", "int", "int", "int", "int", "torch.arange().long", "torch.Tensor", "torch.arange"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["def", "_vis", "(", "tensor", ",", "boxes", ",", "iteration", "=", "0", ",", "prex", "=", "''", ")", ":", "\n", "\n", "    ", "a", "=", "torch", ".", "clone", "(", "tensor", ")", "\n", "width", "=", "3", "\n", "for", "box", "in", "boxes", ":", "\n", "        ", "y1", ",", "x1", ",", "y2", ",", "x2", "=", "int", "(", "box", "[", "0", "]", ")", ",", "int", "(", "box", "[", "1", "]", ")", ",", "int", "(", "box", "[", "2", "]", ")", ",", "int", "(", "box", "[", "3", "]", ")", "\n", "patch", "=", "copy", ".", "deepcopy", "(", "a", "[", ":", ",", "x1", "+", "width", ":", "x2", "-", "width", ",", "y1", "+", "width", ":", "y2", "-", "width", "]", ")", "\n", "a", "[", ":", ",", "x1", ":", "x2", ",", "y1", ":", "y2", "]", "=", "torch", ".", "Tensor", "(", "[", "1", ",", "0", ",", "0", "]", ")", ".", "reshape", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "a", "[", ":", ",", "x1", "+", "width", ":", "x2", "-", "width", ",", "y1", "+", "width", ":", "y2", "-", "width", "]", "=", "patch", "\n", "\n", "", "inv_idx", "=", "torch", ".", "arange", "(", "a", ".", "shape", "[", "0", "]", "-", "1", ",", "-", "1", ",", "-", "1", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "a", "[", "inv_idx", "]", ".", "float", "(", ")", ",", "'%s_tensor_%d.jpg'", "%", "(", "prex", ",", "iteration", ")", ",", "normalize", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.zoom_out.Zoom_out.__init__": [[11, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ratio", "=", "1.0", ",", "img_pool_size", "=", "100", ",", "iou_threshold", "=", "0.5", ",", "size_divisible", "=", "2", ")", ":", "\n", "        ", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "img_pool", "=", "[", "]", "\n", "self", ".", "img_pool_size", "=", "img_pool_size", "\n", "self", ".", "iou_threshold", "=", "iou_threshold", "\n", "self", ".", "size_divisible", "=", "size_divisible", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.zoom_out.Zoom_out.__call__": [[18, 76], ["zoom_out.Zoom_out.img_pool.append", "fcos_core.augmentations.image_level_augs.scale_jitter.scale_jitter", "len", "zoom_out.Zoom_out.img_pool.pop", "int", "int", "int", "int", "len", "random.sample", "in_tensor.new().zero_", "tensor_out[].copy_", "tensor_out[].copy_", "tensor_out[].copy_", "tensor_out[].copy_", "enumerate", "torch.cat", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.bounding_box.BoxList.add_field", "enumerate", "fcos_core.structures.segmentation_mask.SegmentationMask", "fcos_core.structures.bounding_box.BoxList.add_field", "fcos_core.augmentations.image_level_augs.scale_jitter.scale_jitter", "pad_tensors.append", "pad_targets.append", "pad_target.crop", "crop_targets.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat", "math.ceil", "math.ceil", "in_tensor.new", "pad_target.crop.area", "pad_target.area", "enumerate", "list", "numpy.array", "numpy.array", "int", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.scale_jitter.scale_jitter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.scale_jitter.scale_jitter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "__call__", "(", "self", ",", "tensor", ",", "target", ")", ":", "\n", "        ", "if", "self", ".", "ratio", ">=", "1.0", ":", "\n", "            ", "return", "tensor", ",", "target", "\n", "\n", "", "self", ".", "img_pool", ".", "append", "(", "{", "'tensor'", ":", "tensor", ",", "'target'", ":", "target", "}", ")", "\n", "\n", "if", "len", "(", "self", ".", "img_pool", ")", ">", "self", ".", "img_pool_size", ":", "\n", "            ", "self", ".", "img_pool", ".", "pop", "(", "0", ")", "\n", "\n", "", "c", ",", "h", ",", "w", "=", "tensor", ".", "shape", "\n", "if", "self", ".", "size_divisible", ">", "0", ":", "\n", "            ", "h", "=", "int", "(", "math", ".", "ceil", "(", "h", "/", "self", ".", "size_divisible", ")", "*", "self", ".", "size_divisible", ")", "\n", "w", "=", "int", "(", "math", ".", "ceil", "(", "w", "/", "self", ".", "size_divisible", ")", "*", "self", ".", "size_divisible", ")", "\n", "\n", "", "new_h", ",", "new_w", "=", "int", "(", "self", ".", "ratio", "*", "h", ")", ",", "int", "(", "self", ".", "ratio", "*", "w", ")", "\n", "in_tensor", ",", "in_target", "=", "scale_jitter", "(", "tensor", ",", "target", ",", "(", "new_h", ",", "new_w", ")", ")", "\n", "\n", "if", "len", "(", "self", ".", "img_pool", ")", "<", "4", ":", "\n", "            ", "tensor_out", ",", "target_out", "=", "in_tensor", ",", "in_target", "\n", "", "else", ":", "\n", "            ", "pad_imgs", "=", "random", ".", "sample", "(", "self", ".", "img_pool", ",", "3", ")", "\n", "pad_tensors", ",", "pad_targets", "=", "[", "]", ",", "[", "]", "\n", "for", "img", "in", "pad_imgs", ":", "\n", "                ", "pad_tensor", ",", "pad_target", "=", "scale_jitter", "(", "img", "[", "'tensor'", "]", ",", "img", "[", "'target'", "]", ",", "(", "new_h", ",", "new_w", ")", ")", "\n", "pad_tensors", ".", "append", "(", "pad_tensor", ")", "\n", "pad_targets", ".", "append", "(", "pad_target", ")", "\n", "\n", "", "crop_boxes", "=", "[", "(", "0", ",", "0", ",", "w", "-", "new_w", ",", "new_h", ")", ",", "(", "0", ",", "0", ",", "new_w", ",", "h", "-", "new_h", ")", ",", "(", "0", ",", "0", ",", "w", "-", "new_w", ",", "h", "-", "new_h", ")", "]", "\n", "\n", "tensor_out", "=", "in_tensor", ".", "new", "(", "*", "(", "c", ",", "h", ",", "w", ")", ")", ".", "zero_", "(", ")", "\n", "tensor_out", "[", ":", "c", ",", ":", "new_h", ",", ":", "new_w", "]", ".", "copy_", "(", "in_tensor", ")", "\n", "tensor_out", "[", ":", "c", ",", ":", "new_h", ",", "new_w", ":", "]", ".", "copy_", "(", "pad_tensors", "[", "0", "]", "[", ":", "c", ",", ":", "crop_boxes", "[", "0", "]", "[", "3", "]", ",", ":", "crop_boxes", "[", "0", "]", "[", "2", "]", "]", ")", "\n", "tensor_out", "[", ":", "c", ",", "new_h", ":", ",", ":", "new_w", "]", ".", "copy_", "(", "pad_tensors", "[", "1", "]", "[", ":", "c", ",", ":", "crop_boxes", "[", "1", "]", "[", "3", "]", ",", ":", "crop_boxes", "[", "1", "]", "[", "2", "]", "]", ")", "\n", "tensor_out", "[", ":", "c", ",", "new_h", ":", ",", "new_w", ":", "]", ".", "copy_", "(", "pad_tensors", "[", "2", "]", "[", ":", "c", ",", ":", "crop_boxes", "[", "2", "]", "[", "3", "]", ",", ":", "crop_boxes", "[", "2", "]", "[", "2", "]", "]", ")", "\n", "\n", "crop_targets", "=", "[", "]", "\n", "for", "i", ",", "pad_target", "in", "enumerate", "(", "pad_targets", ")", ":", "\n", "                ", "crop_target", "=", "pad_target", ".", "crop", "(", "crop_boxes", "[", "i", "]", ")", "\n", "ious", "=", "crop_target", ".", "area", "(", ")", "/", "pad_target", ".", "area", "(", ")", "\n", "crop_target", "=", "crop_target", "[", "ious", ">=", "self", ".", "iou_threshold", "]", "\n", "crop_targets", ".", "append", "(", "crop_target", ")", "\n", "\n", "", "offsets_box", "=", "[", "torch", ".", "Tensor", "(", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "new_w", ",", "0.0", ",", "new_w", ",", "0.0", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "0.0", ",", "new_h", ",", "0.0", ",", "new_h", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "new_w", ",", "new_h", ",", "new_w", ",", "new_h", "]", ")", "]", "\n", "target_out", "=", "torch", ".", "cat", "(", "[", "target", ".", "bbox", "+", "offsets_box", "[", "i", "]", "for", "i", ",", "target", "in", "enumerate", "(", "[", "in_target", "]", "+", "crop_targets", ")", "]", ",", "dim", "=", "0", ")", "\n", "target_out", "=", "BoxList", "(", "target_out", ",", "(", "w", ",", "h", ")", ",", "mode", "=", "'xyxy'", ")", "\n", "target_out", ".", "add_field", "(", "'labels'", ",", "torch", ".", "cat", "(", "[", "target", ".", "extra_fields", "[", "'labels'", "]", "for", "target", "in", "(", "[", "in_target", "]", "+", "crop_targets", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "polys_list", "=", "[", "[", "poly", ".", "polygons", "[", "0", "]", "for", "poly", "in", "target", ".", "extra_fields", "[", "'masks'", "]", ".", "instances", ".", "polygons", "]", "for", "target", "in", "(", "[", "in_target", "]", "+", "crop_targets", ")", "]", "\n", "offsets_mask", "=", "[", "[", "0.0", ",", "0.0", "]", ",", "[", "new_w", ",", "0.0", "]", ",", "[", "0.0", ",", "new_h", "]", ",", "[", "new_w", ",", "new_h", "]", "]", "\n", "\n", "syn_mask", "=", "[", "]", "\n", "for", "i", ",", "polys", "in", "enumerate", "(", "polys_list", ")", ":", "\n", "                ", "syn_mask", "+=", "[", "[", "list", "(", "np", ".", "array", "(", "poly", ")", "+", "np", ".", "array", "(", "offsets_mask", "[", "i", "]", "*", "int", "(", "len", "(", "poly", ")", "/", "2", ")", ")", ")", "]", "for", "poly", "in", "polys", "]", "\n", "\n", "", "syn_mask", "=", "SegmentationMask", "(", "syn_mask", ",", "(", "w", ",", "h", ")", ",", "mode", "=", "'poly'", ")", "\n", "target_out", ".", "add_field", "(", "'masks'", ",", "syn_mask", ")", "\n", "\n", "", "return", "tensor_out", ",", "target_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.scale_jitter.scale_jitter": [[4, 16], ["isinstance", "torch.nn.functional.interpolate().squeeze", "target.resize", "isinstance", "torch.nn.functional.interpolate", "int", "int", "tensor.unsqueeze"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["def", "scale_jitter", "(", "tensor", ",", "target", ",", "jitter_factor", ")", ":", "\n", "    ", "if", "isinstance", "(", "jitter_factor", ",", "tuple", ")", ":", "\n", "        ", "new_h", ",", "new_w", "=", "jitter_factor", "\n", "", "elif", "isinstance", "(", "jitter_factor", ",", "float", ")", ":", "\n", "        ", "_", ",", "h", ",", "w", "=", "tensor", ".", "shape", "\n", "new_h", ",", "new_w", "=", "int", "(", "h", "*", "jitter_factor", ")", ",", "int", "(", "w", "*", "jitter_factor", ")", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ",", "target", "\n", "\n", "", "tensor_out", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "tensor", ".", "unsqueeze", "(", "0", ")", ",", "size", "=", "(", "new_h", ",", "new_w", ")", ",", "mode", "=", "'nearest'", ")", ".", "squeeze", "(", "0", ")", "\n", "target_out", "=", "target", ".", "resize", "(", "(", "new_w", ",", "new_h", ")", ")", "\n", "return", "tensor_out", ",", "target_out", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.img_level_augs.Img_augs.__init__": [[8, 17], ["fcos_core.augmentations.image_level_augs.zoom_in.Zoom_in", "fcos_core.augmentations.image_level_augs.zoom_out.Zoom_out", "numpy.linspace", "numpy.linspace"], "methods", ["None"], ["class", "Img_augs", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "img_augs_dict", ")", ":", "\n", "        ", "self", ".", "zoom_in_prob", "=", "img_augs_dict", "[", "'zoom_in'", "]", "[", "'prob'", "]", "\n", "self", ".", "zoom_out_prob", "=", "img_augs_dict", "[", "'zoom_out'", "]", "[", "'prob'", "]", "\n", "\n", "zoom_in_ratio_range", "=", "np", ".", "linspace", "(", "1.0", ",", "1.5", ",", "11", ")", "[", "1", ":", "]", "\n", "zoom_out_ratio_range", "=", "np", ".", "linspace", "(", "1.0", ",", "0.5", ",", "11", ")", "[", "1", ":", "]", "\n", "\n", "self", ".", "Zoom_in", "=", "Zoom_in", "(", "ratio", "=", "zoom_in_ratio_range", "[", "img_augs_dict", "[", "'zoom_in'", "]", "[", "'level'", "]", "]", ")", "\n", "self", ".", "Zoom_out", "=", "Zoom_out", "(", "ratio", "=", "zoom_out_ratio_range", "[", "img_augs_dict", "[", "'zoom_out'", "]", "[", "'level'", "]", "]", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.img_level_augs.Img_augs.__call__": [[18, 28], ["random.random", "img_level_augs.Img_augs.Zoom_in", "random.random", "img_level_augs.Img_augs.Zoom_out"], "methods", ["None"], ["\n", "", "def", "__call__", "(", "self", ",", "tensor", ",", "target", ")", ":", "\n", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "zoom_in_prob", ":", "\n", "            ", "tensor_out", ",", "target_out", "=", "self", ".", "Zoom_in", "(", "tensor", "=", "tensor", ",", "target", "=", "target", ")", "\n", "", "elif", "random", ".", "random", "(", ")", "<", "self", ".", "zoom_in_prob", "+", "self", ".", "zoom_out_prob", ":", "\n", "            ", "tensor_out", ",", "target_out", "=", "self", ".", "Zoom_out", "(", "tensor", "=", "tensor", ",", "target", "=", "target", ")", "\n", "", "else", ":", "\n", "            ", "tensor_out", ",", "target_out", "=", "tensor", ",", "target", "\n", "\n", "", "jitter_factor", "=", "random", ".", "sample", "(", "np", ".", "linspace", "(", "0.75", ",", "1.25", ",", "5", ")", ".", "tolist", "(", ")", ",", "1", ")", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.zoom_in.Zoom_in.__init__": [[7, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ratio", "=", "1.0", ",", "iou_threshold", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "iou_threshold", "=", "iou_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.zoom_in.Zoom_in.__call__": [[11, 37], ["target.copy_with_fields", "fcos_core.augmentations.image_level_augs.scale_jitter.scale_jitter", "enlarged_target.copy_with_fields", "enlarged_target.crop", "int", "int", "list", "list", "numpy.random.randint", "numpy.random.randint", "enlarged_target.crop.area", "enlarged_target.copy_with_fields.area", "len", "target.extra_fields.keys", "enlarged_target.extra_fields.keys"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.scale_jitter.scale_jitter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.copy_with_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.crop", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area"], ["", "def", "__call__", "(", "self", ",", "tensor", ",", "target", ")", ":", "\n", "        ", "if", "self", ".", "ratio", "<=", "1.0", ":", "\n", "            ", "return", "tensor", ",", "target", "\n", "\n", "", "h", ",", "w", "=", "tensor", ".", "shape", "[", "1", "]", ",", "tensor", ".", "shape", "[", "2", "]", "\n", "new_h", ",", "new_w", "=", "int", "(", "h", "*", "self", ".", "ratio", ")", ",", "int", "(", "w", "*", "self", ".", "ratio", ")", "\n", "\n", "original_target", "=", "target", ".", "copy_with_fields", "(", "list", "(", "target", ".", "extra_fields", ".", "keys", "(", ")", ")", ")", "\n", "enlarged_tensor", ",", "enlarged_target", "=", "scale_jitter", "(", "tensor", ",", "target", ",", "(", "new_h", ",", "new_w", ")", ")", "\n", "original_enlarged_target", "=", "enlarged_target", ".", "copy_with_fields", "(", "list", "(", "enlarged_target", ".", "extra_fields", ".", "keys", "(", ")", ")", ")", "\n", "\n", "crop_x", ",", "crop_y", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "new_h", "-", "h", ")", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "new_w", "-", "w", ")", "\n", "crop_box", "=", "(", "crop_y", ",", "crop_x", ",", "crop_y", "+", "w", ",", "crop_x", "+", "h", ")", "\n", "cropped_tensor", "=", "enlarged_tensor", "[", ":", ",", "crop_box", "[", "1", "]", ":", "crop_box", "[", "3", "]", ",", "crop_box", "[", "0", "]", ":", "crop_box", "[", "2", "]", "]", "\n", "cropped_target", "=", "enlarged_target", ".", "crop", "(", "crop_box", ")", "\n", "ious", "=", "cropped_target", ".", "area", "(", ")", "/", "original_enlarged_target", ".", "area", "(", ")", "\n", "cropped_target", "=", "cropped_target", "[", "ious", ">=", "self", ".", "iou_threshold", "]", "\n", "\n", "if", "len", "(", "cropped_target", ")", ">", "0", ":", "\n", "            ", "tensor_out", "=", "cropped_tensor", "\n", "target_out", "=", "cropped_target", "\n", "", "else", ":", "\n", "            ", "tensor_out", "=", "tensor", "\n", "target_out", "=", "original_target", "\n", "\n", "", "return", "tensor_out", ",", "target_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.image_level_augs.scale_jitter._crop_boxes": [[43, 59], ["gt_boxes.tensor.split", "torch.isfinite().all", "torch.cat", "torch.isfinite"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs.Box_augs.__init__": [[55, 61], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "box_augs_dict", ",", "max_iters", ",", "scale_splits", ",", "box_prob", "=", "0.3", ")", ":", "\n", "        ", "self", ".", "max_iters", "=", "max_iters", "\n", "self", ".", "box_prob", "=", "box_prob", "\n", "self", ".", "scale_splits", "=", "scale_splits", "\n", "self", ".", "policies", "=", "box_augs_dict", "[", "'policies'", "]", "\n", "self", ".", "scale_ratios", "=", "box_augs_dict", "[", "'scale_ratios'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs.Box_augs.__call__": [[62, 69], ["random.choice", "box_level_augs._box_aug_per_img", "box_level_augs._box_aug_per_img", "float"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs._box_aug_per_img", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs._box_aug_per_img"], ["", "def", "__call__", "(", "self", ",", "tensor", ",", "target", ",", "iteration", ")", ":", "\n", "        ", "iter_ratio", "=", "float", "(", "iteration", ")", "/", "self", ".", "max_iters", "\n", "sub_policy", "=", "random", ".", "choice", "(", "self", ".", "policies", ")", "\n", "tensor", ",", "_", "=", "_box_aug_per_img", "(", "tensor", ",", "target", ",", "aug_type", "=", "sub_policy", "[", "0", "]", "[", "0", "]", ",", "scale_ratios", "=", "self", ".", "scale_ratios", ",", "scale_splits", "=", "self", ".", "scale_splits", ",", "img_prob", "=", "sub_policy", "[", "0", "]", "[", "1", "]", "*", "iter_ratio", ",", "box_prob", "=", "self", ".", "box_prob", ",", "level", "=", "sub_policy", "[", "0", "]", "[", "2", "]", ")", "\n", "tensor_out", ",", "target_out", "=", "_box_aug_per_img", "(", "tensor", ",", "target", ",", "aug_type", "=", "sub_policy", "[", "1", "]", "[", "0", "]", ",", "scale_ratios", "=", "self", ".", "scale_ratios", ",", "scale_splits", "=", "self", ".", "scale_splits", ",", "img_prob", "=", "sub_policy", "[", "1", "]", "[", "1", "]", "*", "iter_ratio", ",", "box_prob", "=", "self", ".", "box_prob", ",", "level", "=", "sub_policy", "[", "1", "]", "[", "2", "]", ")", "\n", "\n", "return", "tensor_out", ",", "target_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs._box_sample_prob": [[11, 26], ["numpy.array", "np.array.sum"], "function", ["None"], ["def", "_box_sample_prob", "(", "bbox", ",", "scale_ratios_splits", ",", "box_prob", "=", "0.3", ")", ":", "\n", "    ", "scale_ratios", ",", "scale_splits", "=", "scale_ratios_splits", "\n", "\n", "ratios", "=", "np", ".", "array", "(", "scale_ratios", ")", "\n", "ratios", "=", "ratios", "/", "ratios", ".", "sum", "(", ")", "\n", "area", "=", "(", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ")", "*", "(", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ")", "\n", "if", "area", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "if", "area", "<", "scale_splits", "[", "0", "]", ":", "\n", "        ", "scale_ratio", "=", "ratios", "[", "0", "]", "\n", "", "elif", "area", "<", "scale_splits", "[", "1", "]", ":", "\n", "        ", "scale_ratio", "=", "ratios", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "scale_ratio", "=", "ratios", "[", "2", "]", "\n", "", "return", "box_prob", "*", "scale_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs._box_aug_per_img": [[28, 52], ["torch.Tensor().reshape().to", "random.random", "torch.Tensor().reshape", "len", "box_level_augs._box_sample_prob", "ValueError", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.box_level_augs._box_sample_prob"], ["", "def", "_box_aug_per_img", "(", "img", ",", "target", ",", "aug_type", "=", "None", ",", "scale_ratios", "=", "None", ",", "scale_splits", "=", "None", ",", "img_prob", "=", "0.1", ",", "box_prob", "=", "0.3", ",", "level", "=", "1", ")", ":", "\n", "    ", "if", "random", ".", "random", "(", ")", ">", "img_prob", ":", "\n", "        ", "return", "img", ",", "target", "\n", "", "img_mean", "=", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "reshape", "(", "3", ",", "1", ",", "1", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "img", "+=", "img_mean", "\n", "img", "/=", "255.0", "\n", "\n", "tag", "=", "'prob'", "if", "aug_type", "in", "geometric_aug_func", "else", "'area'", "\n", "scale_ratios_splits", "=", "[", "scale_ratios", "[", "tag", "]", ",", "scale_splits", "]", "\n", "if", "scale_ratios", "is", "None", ":", "\n", "        ", "box_sample_prob", "=", "[", "box_prob", "]", "*", "len", "(", "target", ".", "bbox", ")", "\n", "", "else", ":", "\n", "        ", "box_sample_prob", "=", "[", "_box_sample_prob", "(", "bbox", ",", "scale_ratios_splits", ",", "box_prob", "=", "box_prob", ")", "for", "bbox", "in", "target", ".", "bbox", "]", "\n", "\n", "", "if", "aug_type", "in", "color_aug_func", ":", "\n", "        ", "img_aug", "=", "color_aug_func", "[", "aug_type", "]", "(", "img", ",", "level", ",", "target", ",", "[", "scale_ratios", "[", "'area'", "]", ",", "scale_splits", "]", ",", "box_sample_prob", ")", "\n", "", "elif", "aug_type", "in", "geometric_aug_func", ":", "\n", "        ", "img_aug", ",", "target", "=", "geometric_aug_func", "[", "aug_type", "]", "(", "img", ",", "level", ",", "target", ",", "box_sample_prob", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown box-level augmentation function %s.'", "%", "(", "aug_type", ")", ")", "\n", "\n", "", "out", "=", "img_aug", "*", "255.0", "-", "img_mean", "\n", "\n", "return", "out", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.gaussian_maps._gaussian_map": [[5, 42], ["torch.zeros().to", "torch.arange().to", "torch.arange().to", "torch.meshgrid", "torch.empty().to", "enumerate", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.exp().to", "torch.zeros", "torch.arange", "torch.arange", "torch.empty", "torch.tensor", "torch.tensor", "torch.tensor", "torch.exp", "xx.float", "yy.float"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "_gaussian_map", "(", "img", ",", "boxes", ",", "scale_splits", "=", "None", ",", "scale_ratios", "=", "None", ")", ":", "\n", "    ", "g_maps", "=", "torch", ".", "zeros", "(", "*", "img", ".", "shape", "[", "1", ":", "]", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "height", ",", "width", "=", "img", ".", "shape", "[", "1", "]", ",", "img", ".", "shape", "[", "2", "]", "\n", "\n", "x_range", "=", "torch", ".", "arange", "(", "0", ",", "height", ",", "1", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "y_range", "=", "torch", ".", "arange", "(", "0", ",", "width", ",", "1", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "xx", ",", "yy", "=", "torch", ".", "meshgrid", "(", "x_range", ",", "y_range", ")", "\n", "pos", "=", "torch", ".", "empty", "(", "xx", ".", "shape", "+", "(", "2", ",", ")", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "pos", "[", ":", ",", ":", ",", "0", "]", "=", "xx", "\n", "pos", "[", ":", ",", ":", ",", "1", "]", "=", "yy", "\n", "\n", "for", "j", ",", "box", "in", "enumerate", "(", "boxes", ")", ":", "\n", "        ", "y1", ",", "x1", ",", "y2", ",", "x2", "=", "box", "\n", "x", ",", "y", ",", "h", ",", "w", "=", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", "\n", "mean_torch", "=", "torch", ".", "tensor", "(", "[", "x", "+", "h", "//", "2", ",", "y", "+", "w", "//", "2", "]", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "if", "scale_ratios", "is", "None", ":", "\n", "            ", "scale_ratio", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "ratio_list", "=", "[", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", ",", "1.0", ",", "2", ",", "4", ",", "6", ",", "8", ",", "10", "]", "\n", "if", "h", "*", "w", "<", "scale_splits", "[", "0", "]", ":", "\n", "                ", "scale_ratio", "=", "ratio_list", "[", "scale_ratios", "[", "0", "]", "]", "*", "scale_splits", "[", "0", "]", "/", "(", "h", "*", "w", ")", "\n", "", "elif", "h", "*", "w", "<", "scale_splits", "[", "1", "]", ":", "\n", "                ", "scale_ratio", "=", "ratio_list", "[", "scale_ratios", "[", "1", "]", "]", "*", "(", "scale_splits", "[", "0", "]", "+", "scale_splits", "[", "1", "]", ")", "/", "2.0", "/", "(", "h", "*", "w", ")", "\n", "", "elif", "h", "*", "w", "<", "scale_splits", "[", "2", "]", ":", "\n", "                ", "scale_ratio", "=", "ratio_list", "[", "scale_ratios", "[", "2", "]", "]", "*", "scale_splits", "[", "2", "]", "/", "(", "h", "*", "w", ")", "\n", "", "else", ":", "\n", "                ", "scale_ratio", "=", "ratio_list", "[", "scale_ratios", "[", "2", "]", "]", "\n", "\n", "", "", "r_var", "=", "(", "scale_ratio", "*", "height", "*", "width", "/", "(", "2", "*", "math", ".", "pi", ")", ")", "**", "0.5", "\n", "var_x", "=", "torch", ".", "tensor", "(", "[", "(", "h", "/", "height", ")", "*", "r_var", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "var_y", "=", "torch", ".", "tensor", "(", "[", "(", "w", "/", "width", ")", "*", "r_var", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "img", ".", "device", ")", "\n", "g_map", "=", "torch", ".", "exp", "(", "\n", "-", "(", "(", "(", "xx", ".", "float", "(", ")", "-", "mean_torch", "[", "0", "]", ")", "**", "2", "/", "(", "2.0", "*", "var_x", "**", "2", ")", "+", "(", "yy", ".", "float", "(", ")", "-", "mean_torch", "[", "1", "]", ")", "**", "2", "/", "(", "\n", "2.0", "*", "var_y", "**", "2", ")", ")", ")", ")", ".", "to", "(", "\n", "img", ".", "device", ")", "\n", "g_maps", "+=", "g_map", "\n", "", "return", "g_maps", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.gaussian_maps._merge_gaussian": [[44, 48], ["gaussian_maps._gaussian_map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.gaussian_maps._gaussian_map"], ["", "def", "_merge_gaussian", "(", "img", ",", "img_aug", ",", "boxes", ",", "scale_ratios", ",", "scale_splits", ")", ":", "\n", "    ", "g_maps", "=", "_gaussian_map", "(", "img", ",", "boxes", ",", "scale_splits", ",", "scale_ratios", ")", "\n", "out", "=", "img", "*", "(", "1", "-", "g_maps", ")", "+", "img_aug", "*", "g_maps", "\n", "return", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.geometric_augs.scale_area": [[14, 22], ["torch.Tensor", "max", "max", "min", "min"], "function", ["None"], ["def", "scale_area", "(", "box", ",", "height", ",", "width", ",", "scale_ratio", "=", "1.0", ")", ":", "\n", "    ", "y1", ",", "x1", ",", "y2", ",", "x2", "=", "box", "\n", "h", ",", "w", "=", "x2", "-", "x1", ",", "y2", "-", "y1", "\n", "#scale_ratio = 4096 / (h * w) if h * w < 2048 else 1", "\n", "h_new", ",", "w_new", "=", "h", "*", "scale_ratio", ",", "w", "*", "scale_ratio", "\n", "x1", ",", "y1", "=", "max", "(", "x1", "+", "h", "/", "2", "-", "h_new", "/", "2", ",", "0", ")", ",", "max", "(", "y1", "+", "w", "/", "2", "-", "w_new", "/", "2", ",", "0", ")", "\n", "x2", ",", "y2", "=", "min", "(", "x1", "+", "h_new", ",", "height", ")", ",", "min", "(", "y1", "+", "w_new", ",", "width", ")", "\n", "box_new", "=", "torch", ".", "Tensor", "(", "[", "y1", ",", "x1", ",", "y2", ",", "x2", "]", ")", "\n", "return", "box_new", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.geometric_augs._geometric_aug_func": [[24, 78], ["enumerate", "geometric_augs._transform", "random.random", "geometric_augs.scale_area", "scale_area.long", "boxes_crops.append", "x_crops.append", "torch.cat", "torch.cat", "fcos_core.structures.segmentation_mask.SegmentationMask", "range", "x_crops.append", "transforms.functional.to_tensor().to.flip", "len", "len", "random.random", "torchvision.functional.to_pil_image", "torchvision.functional.affine", "torchvision.functional.to_tensor().to", "torch.stack", "torch.Tensor().long", "boxes_new.append", "polys_new.append", "labels_new.append", "transforms.functional.to_tensor().to.cpu", "list", "tuple", "torchvision.functional.to_tensor", "torch.Tensor", "numpy.array", "torch.Tensor", "numpy.array", "numpy.array", "int", "int", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.geometric_augs._transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.geometric_augs.scale_area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["\n", "", "def", "_geometric_aug_func", "(", "x", ",", "target", ",", "angle", "=", "0", ",", "translate", "=", "(", "0", ",", "0", ")", ",", "scale", "=", "1", ",", "shear", "=", "(", "0", ",", "0", ")", ",", "hflip", "=", "False", ",", "boxes_sample_prob", "=", "[", "]", ",", "scale_ratio", "=", "1.0", ")", ":", "\n", "    ", "boxes_and_labels", "=", "[", "(", "target", ".", "bbox", "[", "i", "]", ",", "target", ".", "extra_fields", "[", "'labels'", "]", "[", "i", "]", ",", "target", ".", "extra_fields", "[", "'masks'", "]", ".", "instances", ".", "polygons", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "target", ".", "bbox", ")", ")", "if", "random", ".", "random", "(", ")", "<", "boxes_sample_prob", "[", "i", "]", "]", "\n", "boxes", "=", "[", "b_and_l", "[", "0", "]", "for", "b_and_l", "in", "boxes_and_labels", "]", "\n", "labels", "=", "[", "b_and_l", "[", "1", "]", "for", "b_and_l", "in", "boxes_and_labels", "]", "\n", "polys", "=", "[", "b_and_l", "[", "2", "]", ".", "polygons", "[", "0", "]", "for", "b_and_l", "in", "boxes_and_labels", "]", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "        ", "angle", "*=", "-", "1", "\n", "translate", "=", "(", "-", "translate", "[", "0", "]", ",", "-", "translate", "[", "1", "]", ")", "\n", "shear", "=", "(", "-", "shear", "[", "0", "]", ",", "-", "shear", "[", "1", "]", ")", "\n", "\n", "#translate = (0, 0)", "\n", "", "height", ",", "width", "=", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "\n", "\n", "x_crops", "=", "[", "]", "\n", "boxes_crops", "=", "[", "]", "\n", "boxes_new", "=", "[", "]", "\n", "polys_new", "=", "[", "]", "\n", "labels_new", "=", "[", "]", "\n", "for", "i", ",", "box", "in", "enumerate", "(", "boxes", ")", ":", "\n", "        ", "box_crop", "=", "scale_area", "(", "box", ",", "height", ",", "width", ",", "scale_ratio", ")", "\n", "y1", ",", "x1", ",", "y2", ",", "x2", "=", "box_crop", ".", "long", "(", ")", "\n", "\n", "x_crop", "=", "x", "[", ":", ",", "x1", ":", "x2", ",", "y1", ":", "y2", "]", "\n", "boxes_crops", ".", "append", "(", "box_crop", ")", "\n", "\n", "if", "x1", ">=", "x2", "or", "y1", ">=", "y2", ":", "\n", "            ", "x_crops", ".", "append", "(", "x_crop", ")", "\n", "continue", "\n", "\n", "", "if", "hflip", ":", "\n", "            ", "x_crop", "=", "x_crop", ".", "flip", "(", "-", "1", ")", "\n", "", "elif", "translate", "[", "0", "]", "+", "translate", "[", "1", "]", "!=", "0", ":", "\n", "            ", "offset_y", "=", "(", "y2", "+", "translate", "[", "0", "]", ")", ".", "clamp", "(", "0", ",", "width", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "-", "y2", "\n", "offset_x", "=", "(", "x2", "+", "translate", "[", "1", "]", ")", ".", "clamp", "(", "0", ",", "height", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "-", "x2", "\n", "if", "offset_x", "!=", "0", "or", "offset_y", "!=", "0", ":", "\n", "                ", "offset", "=", "[", "offset_y", ",", "offset_x", "]", "\n", "boxes_new", ".", "append", "(", "box", "+", "torch", ".", "Tensor", "(", "offset", "*", "2", ")", ")", "\n", "polys_new", ".", "append", "(", "np", ".", "array", "(", "polys", "[", "i", "]", ")", "+", "np", ".", "array", "(", "offset", "*", "int", "(", "len", "(", "polys", "[", "i", "]", ")", "/", "2", ")", ")", ")", "\n", "labels_new", ".", "append", "(", "labels", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "x_crop", "=", "transforms", ".", "functional", ".", "to_pil_image", "(", "x_crop", ".", "cpu", "(", ")", ")", "\n", "x_crop", "=", "transforms", ".", "functional", ".", "affine", "(", "x_crop", ",", "angle", ",", "translate", ",", "scale", ",", "shear", ",", "resample", "=", "2", ",", "fillcolor", "=", "tuple", "(", "[", "int", "(", "i", ")", "for", "i", "in", "pixel_mean", "]", ")", ")", "\n", "x_crop", "=", "transforms", ".", "functional", ".", "to_tensor", "(", "x_crop", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "", "x_crops", ".", "append", "(", "x_crop", ")", "\n", "", "y", "=", "_transform", "(", "x", ",", "x_crops", ",", "boxes_crops", ",", "translate", ")", "\n", "\n", "if", "translate", "[", "0", "]", "+", "translate", "[", "1", "]", "!=", "0", "and", "len", "(", "boxes_new", ")", ">", "0", ":", "\n", "        ", "target", ".", "bbox", "=", "torch", ".", "cat", "(", "(", "target", ".", "bbox", ",", "torch", ".", "stack", "(", "boxes_new", ")", ")", ")", "\n", "target", ".", "extra_fields", "[", "'labels'", "]", "=", "torch", ".", "cat", "(", "(", "target", ".", "extra_fields", "[", "'labels'", "]", ",", "torch", ".", "Tensor", "(", "labels_new", ")", ".", "long", "(", ")", ")", ")", "\n", "polys", "=", "[", "poly", ".", "polygons", "[", "0", "]", "for", "poly", "in", "target", ".", "extra_fields", "[", "'masks'", "]", ".", "instances", ".", "polygons", "]", "+", "polys_new", "\n", "target", ".", "extra_fields", "[", "'masks'", "]", "=", "SegmentationMask", "(", "[", "[", "list", "(", "np", ".", "array", "(", "poly", ")", ")", "]", "for", "poly", "in", "polys", "]", ",", "target", ".", "extra_fields", "[", "'masks'", "]", ".", "size", ",", "mode", "=", "'poly'", ")", "\n", "\n", "", "return", "y", ",", "target", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.geometric_augs._transform": [[80, 102], ["copy.deepcopy", "enumerate", "boxes_crops[].long", "copy.deepcopy", "fcos_core.augmentations.box_level_augs.gaussian_maps._gaussian_map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.gaussian_maps._gaussian_map"], ["\n", "", "def", "_transform", "(", "x", ",", "x_crops", ",", "boxes_crops", ",", "translate", "=", "(", "0", ",", "0", ")", ")", ":", "\n", "    ", "y", "=", "copy", ".", "deepcopy", "(", "x", ")", "\n", "height", ",", "width", "=", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "\n", "\n", "for", "i", ",", "box", "in", "enumerate", "(", "boxes_crops", ")", ":", "\n", "        ", "y1_c", ",", "x1_c", ",", "y2_c", ",", "x2_c", "=", "boxes_crops", "[", "i", "]", ".", "long", "(", ")", "\n", "\n", "y1_c", "=", "(", "y1_c", "+", "translate", "[", "0", "]", ")", ".", "clamp", "(", "0", ",", "width", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "x1_c", "=", "(", "x1_c", "+", "translate", "[", "1", "]", ")", ".", "clamp", "(", "0", ",", "height", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "y2_c", "=", "(", "y2_c", "+", "translate", "[", "0", "]", ")", ".", "clamp", "(", "0", ",", "width", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "x2_c", "=", "(", "x2_c", "+", "translate", "[", "1", "]", ")", ".", "clamp", "(", "0", ",", "height", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "y_crop", "=", "copy", ".", "deepcopy", "(", "y", "[", ":", ",", "x1_c", ":", "x2_c", ",", "y1_c", ":", "y2_c", "]", ")", "\n", "x_crop", "=", "x_crops", "[", "i", "]", "[", ":", ",", ":", "y_crop", ".", "shape", "[", "1", "]", ",", ":", "y_crop", ".", "shape", "[", "2", "]", "]", "\n", "\n", "if", "y_crop", ".", "shape", "[", "1", "]", "*", "y_crop", ".", "shape", "[", "2", "]", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "g_maps", "=", "_gaussian_map", "(", "x_crop", ",", "[", "[", "0", ",", "0", ",", "y_crop", ".", "shape", "[", "2", "]", ",", "y_crop", ".", "shape", "[", "1", "]", "]", "]", ")", "\n", "_", ",", "_h", ",", "_w", "=", "y", "[", ":", ",", "x1_c", ":", "x2_c", ",", "y1_c", ":", "y2_c", "]", ".", "shape", "\n", "y", "[", ":", ",", "x1_c", ":", "x1_c", "+", "x_crop", ".", "shape", "[", "1", "]", ",", "y1_c", ":", "y1_c", "+", "x_crop", ".", "shape", "[", "2", "]", "]", "=", "g_maps", "*", "x_crop", "+", "(", "1", "-", "g_maps", ")", "*", "y_crop", "[", ":", ",", ":", "x_crop", ".", "shape", "[", "1", "]", ",", ":", "x_crop", ".", "shape", "[", "2", "]", "]", "\n", "", "return", "y", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.blend": [[9, 39], ["torch.clamp", "torch.clamp"], "function", ["None"], ["def", "blend", "(", "image1", ",", "image2", ",", "factor", ")", ":", "\n", "    ", "\"\"\"Blend image1 and image2 using 'factor'.\n    Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n    A value of 1.0 means only image2 is used.  A value between 0.0 and\n    1.0 means we linearly interpolate the pixel values between the two\n    images.  A value greater than 1.0 \"extrapolates\" the difference\n    between the two pixel values, and we clip the results to values\n    between 0 and 1.0.\n    \"\"\"", "\n", "\n", "if", "factor", "==", "0.0", ":", "\n", "        ", "return", "image1", "\n", "", "if", "factor", "==", "1.0", ":", "\n", "        ", "return", "image2", "\n", "\n", "", "difference", "=", "image2", "-", "image1", "\n", "scaled", "=", "factor", "*", "difference", "\n", "\n", "# Do addition in float.", "\n", "temp", "=", "image1", "+", "scaled", "\n", "\n", "# Interpolate", "\n", "if", "factor", ">", "0.0", "and", "factor", "<", "1.0", ":", "\n", "# Interpolation means we always stay within 0 and 255.", "\n", "        ", "return", "temp", "\n", "\n", "# Extrapolate:", "\n", "#", "\n", "# We need to clip and then cast.", "\n", "", "return", "torch", ".", "clamp", "(", "temp", ",", "0.0", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.solarize": [[41, 46], ["torch.where", "torch.where"], "function", ["None"], ["", "def", "solarize", "(", "image", ",", "threshold", "=", "0.5", ")", ":", "\n", "# For each pixel in the image, select the pixel", "\n", "# if the value is less than the threshold.", "\n", "# Otherwise, subtract 255 from the pixel.", "\n", "    ", "return", "torch", ".", "where", "(", "image", "<=", "threshold", ",", "image", ",", "1.0", "-", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.solarize_add": [[48, 56], ["torch.clamp", "torch.clamp", "torch.where", "torch.where"], "function", ["None"], ["", "def", "solarize_add", "(", "image", ",", "addition", "=", "0", ",", "threshold", "=", "0.5", ")", ":", "\n", "# For each pixel in the image less than threshold", "\n", "# we add 'addition' amount to it and then clip the", "\n", "# pixel value to be between 0 and 255. The value", "\n", "# of 'addition' is between -128 and 128.", "\n", "    ", "added_image", "=", "image", "+", "addition", "\n", "added_image", "=", "torch", ".", "clamp", "(", "added_image", ",", "0.0", ",", "1.0", ")", "\n", "return", "torch", ".", "where", "(", "image", "<=", "threshold", ",", "added_image", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.rgb2gray": [[58, 62], ["gray.unsqueeze().repeat.unsqueeze().repeat", "gray.unsqueeze().repeat.unsqueeze"], "function", ["None"], ["", "def", "rgb2gray", "(", "rgb", ")", ":", "\n", "    ", "gray", "=", "rgb", "[", "0", "]", "*", "0.2989", "+", "rgb", "[", "1", "]", "*", "0.5870", "+", "rgb", "[", "2", "]", "*", "0.1140", "\n", "gray", "=", "gray", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "return", "gray", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.color": [[64, 71], ["color_augs.rgb2gray", "color_augs.blend"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.rgb2gray", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.blend"], ["", "def", "color", "(", "img", ",", "factor", ")", ":", "\n", "    ", "\"\"\"Equivalent of PIL Color.\"\"\"", "\n", "if", "img", ".", "shape", "[", "0", "]", "==", "0", "or", "img", ".", "shape", "[", "1", "]", "==", "0", ":", "\n", "        ", "return", "img", "\n", "\n", "", "degenerate", "=", "rgb2gray", "(", "img", ")", "\n", "return", "blend", "(", "degenerate", ",", "img", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.contrast": [[73, 77], ["torch.mean", "torch.mean", "color_augs.blend", "torch.is_floating_point", "torch.is_floating_point", "rgb2gray().to", "max", "color_augs.rgb2gray"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.blend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.rgb2gray"], ["", "def", "contrast", "(", "img", ",", "factor", ")", ":", "\n", "    ", "dtype", "=", "img", ".", "dtype", "if", "torch", ".", "is_floating_point", "(", "img", ")", "else", "torch", ".", "float32", "\n", "mean", "=", "torch", ".", "mean", "(", "rgb2gray", "(", "img", ")", ".", "to", "(", "dtype", ")", ",", "dim", "=", "(", "-", "3", ",", "-", "2", ",", "-", "1", ")", ",", "keepdim", "=", "True", ")", "\n", "return", "blend", "(", "mean", ",", "img", ",", "max", "(", "factor", ",", "1e-6", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.brightness": [[79, 83], ["torch.zeros", "torch.zeros", "color_augs.blend"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.blend"], ["", "def", "brightness", "(", "image", ",", "factor", ")", ":", "\n", "    ", "\"\"\"Equivalent of PIL Brightness.\"\"\"", "\n", "degenerate", "=", "torch", ".", "zeros", "(", "image", ".", "shape", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.sharpness": [[85, 96], ["kernel.repeat.repeat", "image.unsqueeze", "torch.pad", "torch.conv2d().squeeze", "color_augs.blend", "torch.Tensor().reshape", "torch.Tensor().reshape", "torch.conv2d", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.blend"], ["", "def", "sharpness", "(", "image", ",", "factor", ")", ":", "\n", "    ", "\"\"\"Implements Sharpness function from PIL using TF ops.\"\"\"", "\n", "if", "image", ".", "shape", "[", "0", "]", "==", "0", "or", "image", ".", "shape", "[", "1", "]", "==", "0", ":", "\n", "        ", "return", "image", "\n", "", "channels", "=", "image", ".", "shape", "[", "0", "]", "\n", "kernel", "=", "torch", ".", "Tensor", "(", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "5", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ")", ".", "reshape", "(", "1", ",", "1", ",", "3", ",", "3", ")", "/", "13.0", "\n", "kernel", "=", "kernel", ".", "repeat", "(", "(", "3", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "image_newaxis", "=", "image", ".", "unsqueeze", "(", "0", ")", "\n", "image_pad", "=", "F", ".", "pad", "(", "image_newaxis", ",", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "mode", "=", "'reflect'", ")", "\n", "degenerate", "=", "F", ".", "conv2d", "(", "image_pad", ",", "weight", "=", "kernel", ",", "groups", "=", "channels", ")", ".", "squeeze", "(", "0", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.equalize": [[98, 140], ["color_augs.equalize.scale_channel"], "function", ["None"], ["", "def", "equalize", "(", "image", ")", ":", "\n", "    ", "\"\"\"Implements Equalize function from PIL using PyTorch ops based on:\n    https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py#L352\"\"\"", "\n", "image", "=", "image", "*", "255", "\n", "\n", "def", "scale_channel", "(", "im", ",", "c", ")", ":", "\n", "        ", "\"\"\"Scale the data in the channel to implement equalize.\"\"\"", "\n", "im", "=", "im", "[", "c", ",", ":", ",", ":", "]", "\n", "# Compute the histogram of the image channel.", "\n", "histo", "=", "torch", ".", "histc", "(", "im", ",", "bins", "=", "256", ",", "min", "=", "0", ",", "max", "=", "255", ")", "# .type(torch.int32)", "\n", "# For the purposes of computing the step, filter out the nonzeros.", "\n", "nonzero_histo", "=", "torch", ".", "reshape", "(", "histo", "[", "histo", "!=", "0", "]", ",", "[", "-", "1", "]", ")", "\n", "step", "=", "(", "torch", ".", "sum", "(", "nonzero_histo", ")", "-", "nonzero_histo", "[", "-", "1", "]", ")", "//", "255", "\n", "\n", "def", "build_lut", "(", "histo", ",", "step", ")", ":", "\n", "# Compute the cumulative sum, shifting by step // 2", "\n", "# and then normalization by step.", "\n", "            ", "lut", "=", "(", "torch", ".", "cumsum", "(", "histo", ",", "0", ")", "+", "(", "step", "//", "2", ")", ")", "//", "step", "\n", "# Shift lut, prepending with 0.", "\n", "lut", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "1", ")", ",", "lut", "[", ":", "-", "1", "]", "]", ")", "\n", "# Clip the counts to be in range.  This is done", "\n", "# in the C code for image.point.", "\n", "return", "torch", ".", "clamp", "(", "lut", ",", "0", ",", "255", ")", "\n", "\n", "# If step is zero, return the original image.  Otherwise, build", "\n", "# lut from the full histogram and step and then index from it.", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "result", "=", "im", "\n", "", "else", ":", "\n", "# can't index using 2d index. Have to flatten and then reshape", "\n", "            ", "result", "=", "torch", ".", "gather", "(", "build_lut", "(", "histo", ",", "step", ")", ",", "0", ",", "im", ".", "flatten", "(", ")", ".", "long", "(", ")", ")", "\n", "result", "=", "result", ".", "reshape_as", "(", "im", ")", "\n", "\n", "", "return", "result", "# .type(torch.uint8)", "\n", "\n", "# Assumes RGB for now.  Scales each channel independently", "\n", "# and then stacks the result.", "\n", "", "s1", "=", "scale_channel", "(", "image", ",", "0", ")", "\n", "s2", "=", "scale_channel", "(", "image", ",", "1", ")", "\n", "s3", "=", "scale_channel", "(", "image", ",", "2", ")", "\n", "image", "=", "torch", ".", "stack", "(", "[", "s1", ",", "s2", ",", "s3", "]", ",", "0", ")", "/", "255.0", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.autocontrast": [[142, 174], ["color_augs.equalize.scale_channel"], "function", ["None"], ["", "def", "autocontrast", "(", "image", ")", ":", "\n", "    ", "def", "scale_channel", "(", "image", ")", ":", "\n", "        ", "\"\"\"Scale the 2D image using the autocontrast rule.\"\"\"", "\n", "# A possibly cheaper version can be done using cumsum/unique_with_counts", "\n", "# over the histogram values, rather than iterating over the entire image.", "\n", "# to compute mins and maxes.", "\n", "lo", "=", "torch", ".", "min", "(", "image", ")", "\n", "hi", "=", "torch", ".", "max", "(", "image", ")", "\n", "\n", "# Scale the image, making the lowest value 0 and the highest value 1.", "\n", "def", "scale_values", "(", "im", ")", ":", "\n", "            ", "scale", "=", "1.0", "/", "(", "hi", "-", "lo", ")", "\n", "offset", "=", "-", "lo", "*", "scale", "\n", "im", "=", "im", "*", "scale", "+", "offset", "\n", "im", "=", "torch", ".", "clamp", "(", "im", ",", "0.0", ",", "1.0", ")", "\n", "return", "im", "\n", "\n", "", "if", "hi", ">", "lo", ":", "\n", "            ", "result", "=", "scale_values", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "result", "=", "image", "\n", "\n", "", "return", "result", "\n", "\n", "# Assumes RGB for now. Scales each channel independently", "\n", "# and then stacks the result.", "\n", "", "s1", "=", "scale_channel", "(", "image", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "s2", "=", "scale_channel", "(", "image", "[", "1", ",", ":", ",", ":", "]", ")", "\n", "s3", "=", "scale_channel", "(", "image", "[", "2", ",", ":", ",", ":", "]", ")", "\n", "image", "=", "torch", ".", "stack", "(", "[", "s1", ",", "s2", ",", "s3", "]", ",", "0", ")", "\n", "return", "image", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs.posterize": [[176, 185], ["image.long.long", "image_leftshift.float"], "function", ["None"], ["    ", "\"\"\"Equivalent of PIL Posterize.\"\"\"", "\n", "image", "*=", "255", "\n", "image", "=", "image", ".", "long", "(", ")", "\n", "shift", "=", "bits", "# 8 - bits", "\n", "image_rightshift", "=", "image", ">>", "shift", "\n", "image_leftshift", "=", "image_rightshift", "<<", "shift", "\n", "image_leftshift", "=", "image_leftshift", ".", "float", "(", ")", "/", "255.0", "\n", "return", "image_leftshift", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.color_augs._color_aug_func": [[187, 192], ["fcos_core.augmentations.box_level_augs.gaussian_maps._merge_gaussian", "enumerate", "random.random"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.box_level_augs.gaussian_maps._merge_gaussian"], ["    ", "scale_ratios", ",", "scale_splits", "=", "scale_ratios_splits", "\n", "boxes", "=", "[", "bbox", "for", "i", ",", "bbox", "in", "enumerate", "(", "target", ".", "bbox", ")", "if", "random", ".", "random", "(", ")", "<", "box_sample_probs", "[", "i", "]", "]", "\n", "img_aug", "=", "_merge_gaussian", "(", "img", ",", "img_aug", ",", "boxes", ",", "scale_ratios", ",", "scale_splits", ")", "\n", "return", "img_aug", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_dataset": [[17, 57], ["isinstance", "RuntimeError", "dataset_catalog.get", "getattr", "getattr.", "datasets.append", "len", "datasets.ConcatDataset"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "def", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "dataset_catalog", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        dataset_list (list[str]): Contains the names of the datasets, i.e.,\n            coco_2014_train, coco_2014_val, etc\n        transforms (callable): transforms to apply to each (image, target) sample\n        dataset_catalog (DatasetCatalog): contains the information on how to\n            construct a dataset.\n        is_train (bool): whether to setup the dataset for training or testing\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "dataset_list", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"dataset_list should be a list of strings, got {}\"", ".", "format", "(", "dataset_list", ")", "\n", ")", "\n", "", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "dataset_list", ":", "\n", "        ", "data", "=", "dataset_catalog", ".", "get", "(", "dataset_name", ")", "\n", "factory", "=", "getattr", "(", "D", ",", "data", "[", "\"factory\"", "]", ")", "\n", "args", "=", "data", "[", "\"args\"", "]", "\n", "# for COCODataset, we want to remove images without annotations", "\n", "# during training", "\n", "if", "data", "[", "\"factory\"", "]", "==", "\"COCODataset\"", ":", "\n", "            ", "args", "[", "\"remove_images_without_annotations\"", "]", "=", "is_train", "\n", "", "if", "data", "[", "\"factory\"", "]", "==", "\"PascalVOCDataset\"", ":", "\n", "            ", "args", "[", "\"use_difficult\"", "]", "=", "not", "is_train", "\n", "", "args", "[", "\"transforms\"", "]", "=", "transforms", "\n", "# make dataset from factory", "\n", "dataset", "=", "factory", "(", "**", "args", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "# for testing, return a list of datasets", "\n", "", "if", "not", "is_train", ":", "\n", "        ", "return", "datasets", "\n", "\n", "# for training, concatenate all datasets into a single one", "\n", "", "dataset", "=", "datasets", "[", "0", "]", "\n", "if", "len", "(", "datasets", ")", ">", "1", ":", "\n", "        ", "dataset", "=", "D", ".", "ConcatDataset", "(", "datasets", ")", "\n", "\n", "", "return", "[", "dataset", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_data_sampler": [[59, 67], ["samplers.DistributedSampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.SequentialSampler"], "function", ["None"], ["\n", "", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._quantize": [[69, 74], ["copy.copy", "sorted", "list", "map", "bisect.bisect_right"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["\n", "", "def", "_quantize", "(", "x", ",", "bins", ")", ":", "\n", "    ", "bins", "=", "copy", ".", "copy", "(", "bins", ")", "\n", "bins", "=", "sorted", "(", "bins", ")", "\n", "quantized", "=", "list", "(", "map", "(", "lambda", "y", ":", "bisect", ".", "bisect_right", "(", "bins", ",", "y", ")", ",", "x", ")", ")", "\n", "return", "quantized", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._compute_aspect_ratios": [[76, 83], ["range", "len", "dataset.get_img_info", "aspect_ratios.append", "float", "float"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info"], ["\n", "", "def", "_compute_aspect_ratios", "(", "dataset", ")", ":", "\n", "    ", "aspect_ratios", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "img_info", "=", "dataset", ".", "get_img_info", "(", "i", ")", "\n", "aspect_ratio", "=", "float", "(", "img_info", "[", "\"height\"", "]", ")", "/", "float", "(", "img_info", "[", "\"width\"", "]", ")", "\n", "aspect_ratios", ".", "append", "(", "aspect_ratio", ")", "\n", "", "return", "aspect_ratios", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_batch_data_sampler": [[85, 105], ["build._compute_aspect_ratios", "build._quantize", "samplers.GroupedBatchSampler", "torch.utils.data.sampler.BatchSampler", "samplers.IterationBasedBatchSampler", "isinstance"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._compute_aspect_ratios", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._quantize"], ["\n", "", "def", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_batch", ",", "num_iters", "=", "None", ",", "start_iter", "=", "0", "\n", ")", ":", "\n", "    ", "if", "aspect_grouping", ":", "\n", "        ", "if", "not", "isinstance", "(", "aspect_grouping", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "aspect_grouping", "=", "[", "aspect_grouping", "]", "\n", "", "aspect_ratios", "=", "_compute_aspect_ratios", "(", "dataset", ")", "\n", "group_ids", "=", "_quantize", "(", "aspect_ratios", ",", "aspect_grouping", ")", "\n", "batch_sampler", "=", "samplers", ".", "GroupedBatchSampler", "(", "\n", "sampler", ",", "group_ids", ",", "images_per_batch", ",", "drop_uneven", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "BatchSampler", "(", "\n", "sampler", ",", "images_per_batch", ",", "drop_last", "=", "False", "\n", ")", "\n", "", "if", "num_iters", "is", "not", "None", ":", "\n", "        ", "batch_sampler", "=", "samplers", ".", "IterationBasedBatchSampler", "(", "\n", "batch_sampler", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "", "return", "batch_sampler", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_data_loader": [[107, 178], ["fcos_core.utils.comm.get_world_size", "fcos_core.utils.imports.import_file", "build.build_dataset", "logging.getLogger", "logging.getLogger.warning", "transforms.build_transforms", "build.make_data_sampler", "build.make_batch_data_sampler", "torch.utils.data.DataLoader", "data_loaders.append", "collate_batch.BBoxAugCollator", "collate_batch.BatchCollator", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.build.build_transforms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_data_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.make_batch_data_sampler"], ["\n", "", "def", "make_data_loader", "(", "cfg", ",", "is_train", "=", "True", ",", "is_distributed", "=", "False", ",", "start_iter", "=", "0", ",", "is_for_period", "=", "False", ")", ":", "\n", "    ", "num_gpus", "=", "get_world_size", "(", ")", "\n", "if", "is_train", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "True", "\n", "num_iters", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "", "else", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "TEST", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "False", "if", "not", "is_distributed", "else", "True", "\n", "num_iters", "=", "None", "\n", "start_iter", "=", "0", "\n", "\n", "", "if", "images_per_gpu", ">", "1", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"When using more than one image per GPU you may encounter \"", "\n", "\"an out-of-memory (OOM) error if your GPU does not have \"", "\n", "\"sufficient memory. If this happens, you can reduce \"", "\n", "\"SOLVER.IMS_PER_BATCH (for training) or \"", "\n", "\"TEST.IMS_PER_BATCH (for inference). For training, you must \"", "\n", "\"also adjust the learning rate and schedule length according \"", "\n", "\"to the linear scaling rule. See for example: \"", "\n", "\"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"", "\n", ")", "\n", "\n", "# group images which have similar aspect ratio. In this case, we only", "\n", "# group in two cases: those with width / height > 1, and the other way around,", "\n", "# but the code supports more general grouping strategy", "\n", "", "aspect_grouping", "=", "[", "1", "]", "if", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", "else", "[", "]", "\n", "\n", "paths_catalog", "=", "import_file", "(", "\n", "\"maskrcnn_benchmark.config.paths_catalog\"", ",", "cfg", ".", "PATHS_CATALOG", ",", "True", "\n", ")", "\n", "DatasetCatalog", "=", "paths_catalog", ".", "DatasetCatalog", "\n", "dataset_list", "=", "cfg", ".", "DATASETS", ".", "TRAIN", "if", "is_train", "else", "cfg", ".", "DATASETS", ".", "TEST", "\n", "\n", "# If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later", "\n", "transforms", "=", "None", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "build_transforms", "(", "cfg", ",", "is_train", ")", "\n", "datasets", "=", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "DatasetCatalog", ",", "is_train", "or", "is_for_period", ")", "\n", "\n", "if", "is_train", ":", "\n", "# save category_id to label name mapping", "\n", "        ", "save_labels", "(", "datasets", ",", "cfg", ".", "OUTPUT_DIR", ")", "\n", "\n", "", "data_loaders", "=", "[", "]", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "sampler", "=", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "is_distributed", ")", "\n", "batch_sampler", "=", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_gpu", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "collator", "=", "BBoxAugCollator", "(", ")", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "BatchCollator", "(", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "collator", ",", "\n", ")", "\n", "data_loaders", ".", "append", "(", "data_loader", ")", "\n", "", "if", "is_train", "or", "is_for_period", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.collate_batch.BatchCollator.__init__": [[12, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size_divisible", "=", "0", ")", ":", "\n", "        ", "self", ".", "size_divisible", "=", "size_divisible", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.collate_batch.BatchCollator.__call__": [[15, 21], ["list", "fcos_core.structures.image_list.to_image_list", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.to_image_list"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "transposed_batch", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "images", "=", "to_image_list", "(", "transposed_batch", "[", "0", "]", ",", "self", ".", "size_divisible", ")", "\n", "targets", "=", "transposed_batch", "[", "1", "]", "\n", "img_ids", "=", "transposed_batch", "[", "2", "]", "\n", "return", "images", ",", "targets", ",", "img_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.collate_batch.BBoxAugCollator.__call__": [[30, 32], ["list", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.MapDataset.__init__": [[28, 34], ["detectron2.utils.serialize.PicklableWrapper", "random.Random", "set", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["def", "__init__", "(", "self", ",", "dataset", ",", "map_func", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_map_func", "=", "PicklableWrapper", "(", "map_func", ")", "# wrap so that a lambda will work", "\n", "\n", "self", ".", "_rng", "=", "random", ".", "Random", "(", "42", ")", "\n", "self", ".", "_fallback_candidates", "=", "set", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.MapDataset.__len__": [[35, 37], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.MapDataset.__getitem__": [[38, 58], ["int", "common.MapDataset._map_func", "common.MapDataset._fallback_candidates.discard", "common.MapDataset._fallback_candidates.add", "common.MapDataset._rng.sample", "logging.getLogger", "logging.getLogger.warning"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "retry_count", "=", "0", "\n", "cur_idx", "=", "int", "(", "idx", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "data", "=", "self", ".", "_map_func", "(", "self", ".", "_dataset", "[", "cur_idx", "]", ")", "\n", "if", "data", "is", "not", "None", ":", "\n", "                ", "self", ".", "_fallback_candidates", ".", "add", "(", "cur_idx", ")", "\n", "return", "data", "\n", "\n", "# _map_func fails for this idx, use a random new index from the pool", "\n", "", "retry_count", "+=", "1", "\n", "self", ".", "_fallback_candidates", ".", "discard", "(", "cur_idx", ")", "\n", "cur_idx", "=", "self", ".", "_rng", ".", "sample", "(", "self", ".", "_fallback_candidates", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "if", "retry_count", ">=", "3", ":", "\n", "                ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Failed to apply `_map_func` for idx: {}, retry count: {}\"", ".", "format", "(", "\n", "idx", ",", "retry_count", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.DatasetFromList.__init__": [[67, 98], ["pickle.dumps", "numpy.frombuffer", "logging.getLogger", "logging.getLogger.info", "numpy.asarray", "numpy.cumsum", "numpy.concatenate", "logging.getLogger.info", "common.DatasetFromList.__init__._serialize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lst", ":", "list", ",", "copy", ":", "bool", "=", "True", ",", "serialize", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            lst (list): a list which contains elements to produce.\n            copy (bool): whether to deepcopy the element when producing it,\n                so that the result can be modified in place without affecting the\n                source in the list.\n            serialize (bool): whether to hold memory using serialized objects, when\n                enabled, data loader workers can use shared RAM from master\n                process instead of making a copy.\n        \"\"\"", "\n", "self", ".", "_lst", "=", "lst", "\n", "self", ".", "_copy", "=", "copy", "\n", "self", ".", "_serialize", "=", "serialize", "\n", "\n", "def", "_serialize", "(", "data", ")", ":", "\n", "            ", "buffer", "=", "pickle", ".", "dumps", "(", "data", ",", "protocol", "=", "-", "1", ")", "\n", "return", "np", ".", "frombuffer", "(", "buffer", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "", "if", "self", ".", "_serialize", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\n", "\"Serializing {} elements to byte tensors and concatenating them all ...\"", ".", "format", "(", "\n", "len", "(", "self", ".", "_lst", ")", "\n", ")", "\n", ")", "\n", "self", ".", "_lst", "=", "[", "_serialize", "(", "x", ")", "for", "x", "in", "self", ".", "_lst", "]", "\n", "self", ".", "_addr", "=", "np", ".", "asarray", "(", "[", "len", "(", "x", ")", "for", "x", "in", "self", ".", "_lst", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "self", ".", "_addr", "=", "np", ".", "cumsum", "(", "self", ".", "_addr", ")", "\n", "self", ".", "_lst", "=", "np", ".", "concatenate", "(", "self", ".", "_lst", ")", "\n", "logger", ".", "info", "(", "\"Serialized dataset takes {:.2f} MiB\"", ".", "format", "(", "len", "(", "self", ".", "_lst", ")", "/", "1024", "**", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.DatasetFromList.__len__": [[99, 104], ["len", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_serialize", ":", "\n", "            ", "return", "len", "(", "self", ".", "_addr", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.DatasetFromList.__getitem__": [[105, 115], ["common.DatasetFromList._addr[].item", "memoryview", "pickle.loads", "common.DatasetFromList._addr[].item", "copy.deepcopy"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "_serialize", ":", "\n", "            ", "start_addr", "=", "0", "if", "idx", "==", "0", "else", "self", ".", "_addr", "[", "idx", "-", "1", "]", ".", "item", "(", ")", "\n", "end_addr", "=", "self", ".", "_addr", "[", "idx", "]", ".", "item", "(", ")", "\n", "bytes", "=", "memoryview", "(", "self", ".", "_lst", "[", "start_addr", ":", "end_addr", "]", ")", "\n", "return", "pickle", ".", "loads", "(", "bytes", ")", "\n", "", "elif", "self", ".", "_copy", ":", "\n", "            ", "return", "copy", ".", "deepcopy", "(", "self", ".", "_lst", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_lst", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.ToIterableDataset.__init__": [[123, 134], ["isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "sampler", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset (torch.utils.data.Dataset): an old-style dataset with ``__getitem__``\n            sampler (torch.utils.data.sampler.Sampler): a cheap iterable that produces indices\n                to be applied on ``dataset``.\n        \"\"\"", "\n", "assert", "not", "isinstance", "(", "dataset", ",", "data", ".", "IterableDataset", ")", ",", "dataset", "\n", "assert", "isinstance", "(", "sampler", ",", "Sampler", ")", ",", "sampler", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "sampler", "=", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.ToIterableDataset.__iter__": [[135, 150], ["torch.get_worker_info", "itertools.islice"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "worker_info", "=", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", "or", "worker_info", ".", "num_workers", "==", "1", ":", "\n", "            ", "for", "idx", "in", "self", ".", "sampler", ":", "\n", "                ", "yield", "self", ".", "dataset", "[", "idx", "]", "\n", "", "", "else", ":", "\n", "# With map-style dataset, `DataLoader(dataset, sampler)` runs the", "\n", "# sampler in main process only. But `DataLoader(ToIterableDataset(dataset, sampler))`", "\n", "# will run sampler in every of the N worker and only keep 1/N of the ids on each", "\n", "# worker. The assumption is that sampler is cheap to iterate and it's fine to discard", "\n", "# ids in workers.", "\n", "            ", "for", "idx", "in", "itertools", ".", "islice", "(", "\n", "self", ".", "sampler", ",", "worker_info", ".", "id", ",", "None", ",", "worker_info", ".", "num_workers", "\n", ")", ":", "\n", "                ", "yield", "self", ".", "dataset", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.AspectRatioGroupedDataset.__init__": [[165, 175], ["range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset: an iterable. Each element must be a dict with keys\n                \"width\" and \"height\", which will be used to batch data.\n            batch_size (int):\n        \"\"\"", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "# Hard-coded two aspect ratio groups: w > h and w < h.", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.common.AspectRatioGroupedDataset.__iter__": [[178, 187], ["bucket.append", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "d", "in", "self", ".", "dataset", ":", "\n", "            ", "w", ",", "h", "=", "d", "[", "\"width\"", "]", ",", "d", "[", "\"height\"", "]", "\n", "bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "bucket", "=", "self", ".", "_buckets", "[", "bucket_id", "]", "\n", "bucket", ".", "append", "(", "d", ")", "\n", "if", "len", "(", "bucket", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "yield", "bucket", "[", ":", "]", "\n", "del", "bucket", "[", ":", "]", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.convert_PIL_to_numpy": [[59, 90], ["numpy.asarray", "np.dot.convert", "numpy.expand_dims", "numpy.dot", "numpy.array"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["def", "convert_PIL_to_numpy", "(", "image", ",", "format", ")", ":", "\n", "    ", "\"\"\"\n    Convert PIL image to numpy array of target format.\n\n    Args:\n        image (PIL.Image): a PIL image\n        format (str): the format of output image\n\n    Returns:\n        (np.ndarray): also see `read_image`\n    \"\"\"", "\n", "if", "format", "is", "not", "None", ":", "\n", "# PIL only supports RGB, so convert to RGB and flip channels over below", "\n", "        ", "conversion_format", "=", "format", "\n", "if", "format", "in", "[", "\"BGR\"", ",", "\"YUV-BT.601\"", "]", ":", "\n", "            ", "conversion_format", "=", "\"RGB\"", "\n", "", "image", "=", "image", ".", "convert", "(", "conversion_format", ")", "\n", "", "image", "=", "np", ".", "asarray", "(", "image", ")", "\n", "# PIL squeezes out the channel dimension for \"L\", so make it HWC", "\n", "if", "format", "==", "\"L\"", ":", "\n", "        ", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "-", "1", ")", "\n", "\n", "# handle formats not supported by PIL", "\n", "", "elif", "format", "==", "\"BGR\"", ":", "\n", "# flip channels if needed", "\n", "        ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "elif", "format", "==", "\"YUV-BT.601\"", ":", "\n", "        ", "image", "=", "image", "/", "255.0", "\n", "image", "=", "np", ".", "dot", "(", "image", ",", "np", ".", "array", "(", "_M_RGB2YUV", ")", ".", "T", ")", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.convert_image_to_rgb": [[92, 116], ["isinstance", "np.asarray.cpu().numpy", "numpy.dot", "np.asarray.astype", "numpy.asarray", "np.asarray.cpu", "PIL.Image.fromarray().convert", "numpy.array", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "convert_image_to_rgb", "(", "image", ",", "format", ")", ":", "\n", "    ", "\"\"\"\n    Convert an image from given format to RGB.\n\n    Args:\n        image (np.ndarray or Tensor): an HWC image\n        format (str): the format of input image, also see `read_image`\n\n    Returns:\n        (np.ndarray): (H,W,3) RGB image in 0-255 range, can be either float or uint8\n    \"\"\"", "\n", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "image", "=", "image", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "format", "==", "\"BGR\"", ":", "\n", "        ", "image", "=", "image", "[", ":", ",", ":", ",", "[", "2", ",", "1", ",", "0", "]", "]", "\n", "", "elif", "format", "==", "\"YUV-BT.601\"", ":", "\n", "        ", "image", "=", "np", ".", "dot", "(", "image", ",", "np", ".", "array", "(", "_M_YUV2RGB", ")", ".", "T", ")", "\n", "image", "=", "image", "*", "255.0", "\n", "", "else", ":", "\n", "        ", "if", "format", "==", "\"L\"", ":", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", "0", "]", "\n", "", "image", "=", "image", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "image", "=", "np", ".", "asarray", "(", "Image", ".", "fromarray", "(", "image", ",", "mode", "=", "format", ")", ".", "convert", "(", "\"RGB\"", ")", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils._apply_exif_orientation": [[118, 163], ["image.getexif.get", "hasattr", "image.getexif", "image.transpose"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "_apply_exif_orientation", "(", "image", ")", ":", "\n", "    ", "\"\"\"\n    Applies the exif orientation correctly.\n\n    This code exists per the bug:\n      https://github.com/python-pillow/Pillow/issues/3973\n    with the function `ImageOps.exif_transpose`. The Pillow source raises errors with\n    various methods, especially `tobytes`\n\n    Function based on:\n      https://github.com/wkentaro/labelme/blob/v4.5.4/labelme/utils/image.py#L59\n      https://github.com/python-pillow/Pillow/blob/7.1.2/src/PIL/ImageOps.py#L527\n\n    Args:\n        image (PIL.Image): a PIL image\n\n    Returns:\n        (PIL.Image): the PIL image with exif orientation applied, if applicable\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "image", ",", "\"getexif\"", ")", ":", "\n", "        ", "return", "image", "\n", "\n", "", "try", ":", "\n", "        ", "exif", "=", "image", ".", "getexif", "(", ")", "\n", "", "except", "Exception", ":", "# https://github.com/facebookresearch/detectron2/issues/1885", "\n", "        ", "exif", "=", "None", "\n", "\n", "", "if", "exif", "is", "None", ":", "\n", "        ", "return", "image", "\n", "\n", "", "orientation", "=", "exif", ".", "get", "(", "_EXIF_ORIENT", ")", "\n", "\n", "method", "=", "{", "\n", "2", ":", "Image", ".", "FLIP_LEFT_RIGHT", ",", "\n", "3", ":", "Image", ".", "ROTATE_180", ",", "\n", "4", ":", "Image", ".", "FLIP_TOP_BOTTOM", ",", "\n", "5", ":", "Image", ".", "TRANSPOSE", ",", "\n", "6", ":", "Image", ".", "ROTATE_270", ",", "\n", "7", ":", "Image", ".", "TRANSVERSE", ",", "\n", "8", ":", "Image", ".", "ROTATE_90", ",", "\n", "}", ".", "get", "(", "orientation", ")", "\n", "\n", "if", "method", "is", "not", "None", ":", "\n", "        ", "return", "image", ".", "transpose", "(", "method", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image": [[165, 185], ["detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "detection_utils._apply_exif_orientation", "detection_utils.convert_PIL_to_numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils._apply_exif_orientation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.convert_PIL_to_numpy"], ["", "def", "read_image", "(", "file_name", ",", "format", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Read an image into the given format.\n    Will apply rotation and flipping if the image has such exif information.\n\n    Args:\n        file_name (str): image file path\n        format (str): one of the supported image modes in PIL, or \"BGR\" or \"YUV-BT.601\".\n\n    Returns:\n        image (np.ndarray):\n            an HWC image in the given format, which is 0-255, uint8 for\n            supported image modes in PIL or \"BGR\"; float (0-1 for Y) for YUV-BT.601.\n    \"\"\"", "\n", "with", "PathManager", ".", "open", "(", "file_name", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "image", "=", "Image", ".", "open", "(", "f", ")", "\n", "\n", "# work around this bug: https://github.com/python-pillow/Pillow/issues/3973", "\n", "image", "=", "_apply_exif_orientation", "(", "image", ")", "\n", "return", "convert_PIL_to_numpy", "(", "image", ",", "format", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_image_size": [[187, 211], ["detection_utils.SizeMismatchError"], "function", ["None"], ["", "", "def", "check_image_size", "(", "dataset_dict", ",", "image", ")", ":", "\n", "    ", "\"\"\"\n    Raise an error if the image does not match the size specified in the dict.\n    \"\"\"", "\n", "if", "\"width\"", "in", "dataset_dict", "or", "\"height\"", "in", "dataset_dict", ":", "\n", "        ", "image_wh", "=", "(", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "0", "]", ")", "\n", "expected_wh", "=", "(", "dataset_dict", "[", "\"width\"", "]", ",", "dataset_dict", "[", "\"height\"", "]", ")", "\n", "if", "not", "image_wh", "==", "expected_wh", ":", "\n", "            ", "raise", "SizeMismatchError", "(", "\n", "\"Mismatched image shape{}, got {}, expect {}.\"", ".", "format", "(", "\n", "\" for image \"", "+", "dataset_dict", "[", "\"file_name\"", "]", "\n", "if", "\"file_name\"", "in", "dataset_dict", "\n", "else", "\"\"", ",", "\n", "image_wh", ",", "\n", "expected_wh", ",", "\n", ")", "\n", "+", "\" Please check the width/height in your annotation.\"", "\n", ")", "\n", "\n", "# To ensure bbox always remap to original image size", "\n", "", "", "if", "\"width\"", "not", "in", "dataset_dict", ":", "\n", "        ", "dataset_dict", "[", "\"width\"", "]", "=", "image", ".", "shape", "[", "1", "]", "\n", "", "if", "\"height\"", "not", "in", "dataset_dict", ":", "\n", "        ", "dataset_dict", "[", "\"height\"", "]", "=", "image", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.transform_proposals": [[213, 254], ["transforms.apply_box", "detectron2.structures.Boxes", "torch.as_tensor", "detectron2.structures.Boxes.clip", "detectron2.structures.Boxes.nonempty", "detectron2.structures.Instances", "detectron2.structures.BoxMode.convert", "dataset_dict.pop().astype", "dataset_dict.pop", "dataset_dict.pop", "dataset_dict.pop"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "", "def", "transform_proposals", "(", "dataset_dict", ",", "image_shape", ",", "transforms", ",", "*", ",", "proposal_topk", ",", "min_box_size", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Apply transformations to the proposals in dataset_dict, if any.\n\n    Args:\n        dataset_dict (dict): a dict read from the dataset, possibly\n            contains fields \"proposal_boxes\", \"proposal_objectness_logits\", \"proposal_bbox_mode\"\n        image_shape (tuple): height, width\n        transforms (TransformList):\n        proposal_topk (int): only keep top-K scoring proposals\n        min_box_size (int): proposals with either side smaller than this\n            threshold are removed\n\n    The input dict is modified in-place, with abovementioned keys removed. A new\n    key \"proposals\" will be added. Its value is an `Instances`\n    object which contains the transformed proposals in its field\n    \"proposal_boxes\" and \"objectness_logits\".\n    \"\"\"", "\n", "if", "\"proposal_boxes\"", "in", "dataset_dict", ":", "\n", "# Transform proposal boxes", "\n", "        ", "boxes", "=", "transforms", ".", "apply_box", "(", "\n", "BoxMode", ".", "convert", "(", "\n", "dataset_dict", ".", "pop", "(", "\"proposal_boxes\"", ")", ",", "\n", "dataset_dict", ".", "pop", "(", "\"proposal_bbox_mode\"", ")", ",", "\n", "BoxMode", ".", "XYXY_ABS", ",", "\n", ")", "\n", ")", "\n", "boxes", "=", "Boxes", "(", "boxes", ")", "\n", "objectness_logits", "=", "torch", ".", "as_tensor", "(", "\n", "dataset_dict", ".", "pop", "(", "\"proposal_objectness_logits\"", ")", ".", "astype", "(", "\"float32\"", ")", "\n", ")", "\n", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "keep", "=", "boxes", ".", "nonempty", "(", "threshold", "=", "min_box_size", ")", "\n", "boxes", "=", "boxes", "[", "keep", "]", "\n", "objectness_logits", "=", "objectness_logits", "[", "keep", "]", "\n", "\n", "proposals", "=", "Instances", "(", "image_shape", ")", "\n", "proposals", ".", "proposal_boxes", "=", "boxes", "[", ":", "proposal_topk", "]", "\n", "proposals", ".", "objectness_logits", "=", "objectness_logits", "[", ":", "proposal_topk", "]", "\n", "dataset_dict", "[", "\"proposals\"", "]", "=", "proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.transform_instance_annotations": [[256, 318], ["isinstance", "detectron2.structures.BoxMode.convert", "[].clip", "numpy.minimum", "transforms.TransformList", "isinstance", "detection_utils.transform_keypoint_annotations", "list", "isinstance", "T.TransformList.apply_box", "numpy.asarray().reshape", "p.reshape", "pycocotools.decode", "T.TransformList.apply_segmentation", "ValueError", "numpy.array", "T.TransformList.apply_polygons", "tuple", "numpy.asarray", "type"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.transform_keypoint_annotations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_segmentation"], ["", "", "def", "transform_instance_annotations", "(", "\n", "annotation", ",", "transforms", ",", "image_size", ",", "*", ",", "keypoint_hflip_indices", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply transforms to box, segmentation and keypoints annotations of a single instance.\n\n    It will use `transforms.apply_box` for the box, and\n    `transforms.apply_coords` for segmentation polygons & keypoints.\n    If you need anything more specially designed for each data structure,\n    you'll need to implement your own version of this function or the transforms.\n\n    Args:\n        annotation (dict): dict of instance annotations for a single instance.\n            It will be modified in-place.\n        transforms (TransformList or list[Transform]):\n        image_size (tuple): the height, width of the transformed image\n        keypoint_hflip_indices (ndarray[int]): see `create_keypoint_hflip_indices`.\n\n    Returns:\n        dict:\n            the same input dict with fields \"bbox\", \"segmentation\", \"keypoints\"\n            transformed according to `transforms`.\n            The \"bbox_mode\" field will be set to XYXY_ABS.\n    \"\"\"", "\n", "if", "isinstance", "(", "transforms", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "transforms", "=", "T", ".", "TransformList", "(", "transforms", ")", "\n", "# bbox is 1d (per-instance bounding box)", "\n", "", "bbox", "=", "BoxMode", ".", "convert", "(", "annotation", "[", "\"bbox\"", "]", ",", "annotation", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "# clip transformed bbox to image size", "\n", "bbox", "=", "transforms", ".", "apply_box", "(", "np", ".", "array", "(", "[", "bbox", "]", ")", ")", "[", "0", "]", ".", "clip", "(", "min", "=", "0", ")", "\n", "annotation", "[", "\"bbox\"", "]", "=", "np", ".", "minimum", "(", "bbox", ",", "list", "(", "image_size", "+", "image_size", ")", "[", ":", ":", "-", "1", "]", ")", "\n", "annotation", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYXY_ABS", "\n", "\n", "if", "\"segmentation\"", "in", "annotation", ":", "\n", "# each instance contains 1 or more polygons", "\n", "        ", "segm", "=", "annotation", "[", "\"segmentation\"", "]", "\n", "if", "isinstance", "(", "segm", ",", "list", ")", ":", "\n", "# polygons", "\n", "            ", "polygons", "=", "[", "np", ".", "asarray", "(", "p", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", "for", "p", "in", "segm", "]", "\n", "annotation", "[", "\"segmentation\"", "]", "=", "[", "\n", "p", ".", "reshape", "(", "-", "1", ")", "for", "p", "in", "transforms", ".", "apply_polygons", "(", "polygons", ")", "\n", "]", "\n", "", "elif", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "# RLE", "\n", "            ", "mask", "=", "mask_util", ".", "decode", "(", "segm", ")", "\n", "mask", "=", "transforms", ".", "apply_segmentation", "(", "mask", ")", "\n", "assert", "tuple", "(", "mask", ".", "shape", "[", ":", "2", "]", ")", "==", "image_size", "\n", "annotation", "[", "\"segmentation\"", "]", "=", "mask", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot transform segmentation of type '{}'!\"", "\n", "\"Supported types are: polygons as list[list[float] or ndarray],\"", "\n", "\" COCO-style RLE as a dict.\"", ".", "format", "(", "type", "(", "segm", ")", ")", "\n", ")", "\n", "\n", "", "", "if", "\"keypoints\"", "in", "annotation", ":", "\n", "        ", "keypoints", "=", "transform_keypoint_annotations", "(", "\n", "annotation", "[", "\"keypoints\"", "]", ",", "transforms", ",", "image_size", ",", "keypoint_hflip_indices", "\n", ")", "\n", "annotation", "[", "\"keypoints\"", "]", "=", "keypoints", "\n", "\n", "", "return", "annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.transform_keypoint_annotations": [[320, 360], ["numpy.asarray().reshape", "transforms.apply_coords", "inside.all.all", "numpy.asarray", "numpy.array", "numpy.array", "sum", "isinstance"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_coords"], ["", "def", "transform_keypoint_annotations", "(", "keypoints", ",", "transforms", ",", "image_size", ",", "keypoint_hflip_indices", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Transform keypoint annotations of an image.\n    If a keypoint is transformed out of image boundary, it will be marked \"unlabeled\" (visibility=0)\n\n    Args:\n        keypoints (list[float]): Nx3 float in Detectron2's Dataset format.\n            Each point is represented by (x, y, visibility).\n        transforms (TransformList):\n        image_size (tuple): the height, width of the transformed image\n        keypoint_hflip_indices (ndarray[int]): see `create_keypoint_hflip_indices`.\n            When `transforms` includes horizontal flip, will use the index\n            mapping to flip keypoints.\n    \"\"\"", "\n", "# (N*3,) -> (N, 3)", "\n", "keypoints", "=", "np", ".", "asarray", "(", "keypoints", ",", "dtype", "=", "\"float64\"", ")", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "keypoints_xy", "=", "transforms", ".", "apply_coords", "(", "keypoints", "[", ":", ",", ":", "2", "]", ")", "\n", "\n", "# Set all out-of-boundary points to \"unlabeled\"", "\n", "inside", "=", "(", "keypoints_xy", ">=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", ")", "&", "(", "keypoints_xy", "<=", "np", ".", "array", "(", "image_size", "[", ":", ":", "-", "1", "]", ")", ")", "\n", "inside", "=", "inside", ".", "all", "(", "axis", "=", "1", ")", "\n", "keypoints", "[", ":", ",", ":", "2", "]", "=", "keypoints_xy", "\n", "keypoints", "[", ":", ",", "2", "]", "[", "~", "inside", "]", "=", "0", "\n", "\n", "# This assumes that HorizFlipTransform is the only one that does flip", "\n", "do_hflip", "=", "sum", "(", "isinstance", "(", "t", ",", "T", ".", "HFlipTransform", ")", "for", "t", "in", "transforms", ".", "transforms", ")", "%", "2", "==", "1", "\n", "\n", "# Alternative way: check if probe points was horizontally flipped.", "\n", "# probe = np.asarray([[0.0, 0.0], [image_width, 0.0]])", "\n", "# probe_aug = transforms.apply_coords(probe.copy())", "\n", "# do_hflip = np.sign(probe[1][0] - probe[0][0]) != np.sign(probe_aug[1][0] - probe_aug[0][0])  # noqa", "\n", "\n", "# If flipped, swap each keypoint with its opposite-handed equivalent", "\n", "if", "do_hflip", ":", "\n", "        ", "assert", "keypoint_hflip_indices", "is", "not", "None", "\n", "keypoints", "=", "keypoints", "[", "keypoint_hflip_indices", ",", ":", "]", "\n", "\n", "# Maintain COCO convention that if visibility == 0 (unlabeled), then x, y = 0", "\n", "", "keypoints", "[", "keypoints", "[", ":", ",", "2", "]", "==", "0", "]", "=", "0", "\n", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.annotations_to_instances": [[362, 429], ["detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.tensor", "detectron2.structures.BoxMode.convert", "int", "len", "len", "detectron2.structures.Keypoints", "detectron2.structures.BitMasks", "obj.get", "detectron2.structures.PolygonMasks", "isinstance", "torch.stack", "ValueError", "detectron2.structures.PolygonMasks.append", "isinstance", "detectron2.structures.polygons_to_bitmask", "detectron2.structures.PolygonMasks.append", "isinstance", "torch.from_numpy", "pycocotools.decode", "detectron2.structures.PolygonMasks.append", "ValueError", "numpy.ascontiguousarray", "type"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.polygons_to_bitmask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["", "def", "annotations_to_instances", "(", "annos", ",", "image_size", ",", "mask_format", "=", "\"polygon\"", ")", ":", "\n", "    ", "\"\"\"\n    Create an :class:`Instances` object used by the models,\n    from instance annotations in the dataset dict.\n\n    Args:\n        annos (list[dict]): a list of instance annotations in one image, each\n            element for one instance.\n        image_size (tuple): height, width\n\n    Returns:\n        Instances:\n            It will contain fields \"gt_boxes\", \"gt_classes\",\n            \"gt_masks\", \"gt_keypoints\", if they can be obtained from `annos`.\n            This is the format that builtin models expect.\n    \"\"\"", "\n", "boxes", "=", "[", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "obj", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "for", "obj", "in", "annos", "]", "\n", "target", "=", "Instances", "(", "image_size", ")", "\n", "target", ".", "gt_boxes", "=", "Boxes", "(", "boxes", ")", "\n", "\n", "classes", "=", "[", "int", "(", "obj", "[", "\"category_id\"", "]", ")", "for", "obj", "in", "annos", "]", "\n", "classes", "=", "torch", ".", "tensor", "(", "classes", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "target", ".", "gt_classes", "=", "classes", "\n", "\n", "if", "len", "(", "annos", ")", "and", "\"segmentation\"", "in", "annos", "[", "0", "]", ":", "\n", "        ", "segms", "=", "[", "obj", "[", "\"segmentation\"", "]", "for", "obj", "in", "annos", "]", "\n", "if", "mask_format", "==", "\"polygon\"", ":", "\n", "            ", "try", ":", "\n", "                ", "masks", "=", "PolygonMasks", "(", "segms", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Failed to use mask_format=='polygon' from the given annotations!\"", "\n", ")", "from", "e", "\n", "", "", "else", ":", "\n", "            ", "assert", "mask_format", "==", "\"bitmask\"", ",", "mask_format", "\n", "masks", "=", "[", "]", "\n", "for", "segm", "in", "segms", ":", "\n", "                ", "if", "isinstance", "(", "segm", ",", "list", ")", ":", "\n", "# polygon", "\n", "                    ", "masks", ".", "append", "(", "polygons_to_bitmask", "(", "segm", ",", "*", "image_size", ")", ")", "\n", "", "elif", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "# COCO RLE", "\n", "                    ", "masks", ".", "append", "(", "mask_util", ".", "decode", "(", "segm", ")", ")", "\n", "", "elif", "isinstance", "(", "segm", ",", "np", ".", "ndarray", ")", ":", "\n", "                    ", "assert", "segm", ".", "ndim", "==", "2", ",", "\"Expect segmentation of 2 dimensions, got {}.\"", ".", "format", "(", "\n", "segm", ".", "ndim", "\n", ")", "\n", "# mask array", "\n", "masks", ".", "append", "(", "segm", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Cannot convert segmentation of type '{}' to BitMasks!\"", "\n", "\"Supported types are: polygons as list[list[float] or ndarray],\"", "\n", "\" COCO-style RLE as a dict, or a binary segmentation mask \"", "\n", "\" in a 2D numpy array of shape HxW.\"", ".", "format", "(", "type", "(", "segm", ")", ")", "\n", ")", "\n", "# torch.from_numpy does not support array with negative stride.", "\n", "", "", "masks", "=", "BitMasks", "(", "\n", "torch", ".", "stack", "(", "[", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "x", ")", ")", "for", "x", "in", "masks", "]", ")", "\n", ")", "\n", "", "target", ".", "gt_masks", "=", "masks", "\n", "\n", "", "if", "len", "(", "annos", ")", "and", "\"keypoints\"", "in", "annos", "[", "0", "]", ":", "\n", "        ", "kpts", "=", "[", "obj", ".", "get", "(", "\"keypoints\"", ",", "[", "]", ")", "for", "obj", "in", "annos", "]", "\n", "target", ".", "gt_keypoints", "=", "Keypoints", "(", "kpts", ")", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.annotations_to_instances_rotated": [[431, 458], ["detectron2.structures.Instances", "detectron2.structures.RotatedBoxes", "detectron2.structures.RotatedBoxes.clip", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "annotations_to_instances_rotated", "(", "annos", ",", "image_size", ")", ":", "\n", "    ", "\"\"\"\n    Create an :class:`Instances` object used by the models,\n    from instance annotations in the dataset dict.\n    Compared to `annotations_to_instances`, this function is for rotated boxes only\n\n    Args:\n        annos (list[dict]): a list of instance annotations in one image, each\n            element for one instance.\n        image_size (tuple): height, width\n\n    Returns:\n        Instances:\n            Containing fields \"gt_boxes\", \"gt_classes\",\n            if they can be obtained from `annos`.\n            This is the format that builtin models expect.\n    \"\"\"", "\n", "boxes", "=", "[", "obj", "[", "\"bbox\"", "]", "for", "obj", "in", "annos", "]", "\n", "target", "=", "Instances", "(", "image_size", ")", "\n", "boxes", "=", "target", ".", "gt_boxes", "=", "RotatedBoxes", "(", "boxes", ")", "\n", "boxes", ".", "clip", "(", "image_size", ")", "\n", "\n", "classes", "=", "[", "obj", "[", "\"category_id\"", "]", "for", "obj", "in", "annos", "]", "\n", "classes", "=", "torch", ".", "tensor", "(", "classes", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "target", ".", "gt_classes", "=", "classes", "\n", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.filter_empty_instances": [[460, 488], ["r.append", "instances.has", "r.append", "instances.gt_boxes.nonempty", "instances.gt_masks.nonempty"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty"], ["", "def", "filter_empty_instances", "(", "instances", ",", "by_box", "=", "True", ",", "by_mask", "=", "True", ",", "box_threshold", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"\n    Filter out empty instances in an `Instances` object.\n\n    Args:\n        instances (Instances):\n        by_box (bool): whether to filter out instances with empty boxes\n        by_mask (bool): whether to filter out instances with empty masks\n        box_threshold (float): minimum width and height to be considered non-empty\n\n    Returns:\n        Instances: the filtered instances.\n    \"\"\"", "\n", "assert", "by_box", "or", "by_mask", "\n", "r", "=", "[", "]", "\n", "if", "by_box", ":", "\n", "        ", "r", ".", "append", "(", "instances", ".", "gt_boxes", ".", "nonempty", "(", "threshold", "=", "box_threshold", ")", ")", "\n", "", "if", "instances", ".", "has", "(", "\"gt_masks\"", ")", "and", "by_mask", ":", "\n", "        ", "r", ".", "append", "(", "instances", ".", "gt_masks", ".", "nonempty", "(", ")", ")", "\n", "\n", "# TODO: can also filter visible keypoints", "\n", "\n", "", "if", "not", "r", ":", "\n", "        ", "return", "instances", "\n", "", "m", "=", "r", "[", "0", "]", "\n", "for", "x", "in", "r", "[", "1", ":", "]", ":", "\n", "        ", "m", "=", "m", "&", "x", "\n", "", "return", "instances", "[", "m", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.create_keypoint_hflip_indices": [[490, 510], ["detection_utils.check_metadata_consistency", "detection_utils.check_metadata_consistency", "catalog.MetadataCatalog.get", "dict", "dict.update", "numpy.asarray", "names.index", "dict.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_metadata_consistency", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_metadata_consistency", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "def", "create_keypoint_hflip_indices", "(", "dataset_names", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        dataset_names (list[str]): list of dataset names\n    Returns:\n        ndarray[int]: a vector of size=#keypoints, storing the\n        horizontally-flipped keypoint indices.\n    \"\"\"", "\n", "\n", "check_metadata_consistency", "(", "\"keypoint_names\"", ",", "dataset_names", ")", "\n", "check_metadata_consistency", "(", "\"keypoint_flip_map\"", ",", "dataset_names", ")", "\n", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_names", "[", "0", "]", ")", "\n", "names", "=", "meta", ".", "keypoint_names", "\n", "# TODO flip -> hflip", "\n", "flip_map", "=", "dict", "(", "meta", ".", "keypoint_flip_map", ")", "\n", "flip_map", ".", "update", "(", "{", "v", ":", "k", "for", "k", ",", "v", "in", "flip_map", ".", "items", "(", ")", "}", ")", "\n", "flipped_names", "=", "[", "i", "if", "i", "not", "in", "flip_map", "else", "flip_map", "[", "i", "]", "for", "i", "in", "names", "]", "\n", "flip_indices", "=", "[", "names", ".", "index", "(", "i", ")", "for", "i", "in", "flipped_names", "]", "\n", "return", "np", ".", "asarray", "(", "flip_indices", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.gen_crop_transform_with_instance": [[512, 540], ["numpy.asarray", "detectron2.structures.BoxMode.convert", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.random.randint", "numpy.random.randint", "transforms.CropTransform", "numpy.ceil().astype", "numpy.floor().astype", "numpy.asarray", "numpy.ceil", "numpy.floor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "gen_crop_transform_with_instance", "(", "crop_size", ",", "image_size", ",", "instance", ")", ":", "\n", "    ", "\"\"\"\n    Generate a CropTransform so that the cropping region contains\n    the center of the given instance.\n\n    Args:\n        crop_size (tuple): h, w in pixels\n        image_size (tuple): h, w\n        instance (dict): an annotation dict of one instance, in Detectron2's\n            dataset format.\n    \"\"\"", "\n", "crop_size", "=", "np", ".", "asarray", "(", "crop_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "instance", "[", "\"bbox\"", "]", ",", "instance", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "center_yx", "=", "(", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ")", "*", "0.5", ",", "(", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ")", "*", "0.5", "\n", "assert", "(", "\n", "image_size", "[", "0", "]", ">=", "center_yx", "[", "0", "]", "and", "image_size", "[", "1", "]", ">=", "center_yx", "[", "1", "]", "\n", ")", ",", "\"The annotation bounding box is outside of the image!\"", "\n", "assert", "(", "\n", "image_size", "[", "0", "]", ">=", "crop_size", "[", "0", "]", "and", "image_size", "[", "1", "]", ">=", "crop_size", "[", "1", "]", "\n", ")", ",", "\"Crop size is larger than image size!\"", "\n", "\n", "min_yx", "=", "np", ".", "maximum", "(", "np", ".", "floor", "(", "center_yx", ")", ".", "astype", "(", "np", ".", "int32", ")", "-", "crop_size", ",", "0", ")", "\n", "max_yx", "=", "np", ".", "maximum", "(", "np", ".", "asarray", "(", "image_size", ",", "dtype", "=", "np", ".", "int32", ")", "-", "crop_size", ",", "0", ")", "\n", "max_yx", "=", "np", ".", "minimum", "(", "max_yx", ",", "np", ".", "ceil", "(", "center_yx", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "\n", "y0", "=", "np", ".", "random", ".", "randint", "(", "min_yx", "[", "0", "]", ",", "max_yx", "[", "0", "]", "+", "1", ")", "\n", "x0", "=", "np", ".", "random", ".", "randint", "(", "min_yx", "[", "1", "]", ",", "max_yx", "[", "1", "]", "+", "1", ")", "\n", "return", "T", ".", "CropTransform", "(", "x0", ",", "y0", ",", "crop_size", "[", "1", "]", ",", "crop_size", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_metadata_consistency": [[542, 569], ["logging.getLogger", "enumerate", "len", "getattr", "catalog.MetadataCatalog.get", "logging.getLogger.error", "logging.getLogger.error", "ValueError", "str", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "check_metadata_consistency", "(", "key", ",", "dataset_names", ")", ":", "\n", "    ", "\"\"\"\n    Check that the datasets have consistent metadata.\n\n    Args:\n        key (str): a metadata key\n        dataset_names (list[str]): a list of dataset names\n\n    Raises:\n        AttributeError: if the key does not exist in the metadata\n        ValueError: if the given datasets do not have the same metadata values defined by key\n    \"\"\"", "\n", "if", "len", "(", "dataset_names", ")", "==", "0", ":", "\n", "        ", "return", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "entries_per_dataset", "=", "[", "getattr", "(", "MetadataCatalog", ".", "get", "(", "d", ")", ",", "key", ")", "for", "d", "in", "dataset_names", "]", "\n", "for", "idx", ",", "entry", "in", "enumerate", "(", "entries_per_dataset", ")", ":", "\n", "        ", "if", "entry", "!=", "entries_per_dataset", "[", "0", "]", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Metadata '{}' for dataset '{}' is '{}'\"", ".", "format", "(", "key", ",", "dataset_names", "[", "idx", "]", ",", "str", "(", "entry", ")", ")", "\n", ")", "\n", "logger", ".", "error", "(", "\n", "\"Metadata '{}' for dataset '{}' is '{}'\"", ".", "format", "(", "\n", "key", ",", "dataset_names", "[", "0", "]", ",", "str", "(", "entries_per_dataset", "[", "0", "]", ")", "\n", ")", "\n", ")", "\n", "raise", "ValueError", "(", "\"Datasets have different metadata '{}'!\"", ".", "format", "(", "key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.build_augmentation": [[571, 596], ["transforms.ResizeShortestEdge", "augmentation.append", "transforms.RandomFlip"], "function", ["None"], ["", "", "", "def", "build_augmentation", "(", "cfg", ",", "is_train", ")", ":", "\n", "    ", "\"\"\"\n    Create a list of default :class:`Augmentation` from config.\n    Now it includes resizing and flipping.\n\n    Returns:\n        list[Augmentation]\n    \"\"\"", "\n", "if", "is_train", ":", "\n", "        ", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TRAIN", "\n", "sample_style", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN_SAMPLING", "\n", "", "else", ":", "\n", "        ", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "\n", "sample_style", "=", "\"choice\"", "\n", "", "augmentation", "=", "[", "T", ".", "ResizeShortestEdge", "(", "min_size", ",", "max_size", ",", "sample_style", ")", "]", "\n", "if", "is_train", "and", "cfg", ".", "INPUT", ".", "RANDOM_FLIP", "!=", "\"none\"", ":", "\n", "        ", "augmentation", ".", "append", "(", "\n", "T", ".", "RandomFlip", "(", "\n", "horizontal", "=", "cfg", ".", "INPUT", ".", "RANDOM_FLIP", "==", "\"horizontal\"", ",", "\n", "vertical", "=", "cfg", ".", "INPUT", ".", "RANDOM_FLIP", "==", "\"vertical\"", ",", "\n", ")", "\n", ")", "\n", "", "return", "augmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._DatasetCatalog.register": [[29, 39], ["callable"], "methods", ["None"], ["\"FAIR/X-101-64x4d\"", ":", "\"ImageNetPretrained/FBResNeXt/X-101-64x4d.pkl\"", ",", "\n", "\"FAIR/X-152-32x8d-IN5k\"", ":", "\"ImageNetPretrained/25093814/X-152-32x8d-IN5k.pkl\"", ",", "\n", "}", "\n", "\n", "C2_DETECTRON_PATH_FORMAT", "=", "(", "\n", "\"{prefix}/{url}/output/train/{dataset}/{type}/model_final.pkl\"", "# noqa B950", "\n", ")", "\n", "\n", "C2_DATASET_COCO", "=", "\"coco_2014_train%3Acoco_2014_valminusminival\"", "\n", "C2_DATASET_COCO_KEYPOINTS", "=", "\"keypoints_coco_2014_train%3Akeypoints_coco_2014_valminusminival\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._DatasetCatalog.get": [[40, 59], ["f", "KeyError", "catalog._DatasetCatalog.list"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["# format: {model_name} -> part of the url", "\n", "C2_DETECTRON_MODELS", "=", "{", "\n", "\"35857197/e2e_faster_rcnn_R-50-C4_1x\"", ":", "\"35857197/12_2017_baselines/e2e_faster_rcnn_R-50-C4_1x.yaml.01_33_49.iAX0mXvW\"", ",", "# noqa B950", "\n", "\"35857345/e2e_faster_rcnn_R-50-FPN_1x\"", ":", "\"35857345/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml.01_36_30.cUF7QR7I\"", ",", "# noqa B950", "\n", "\"35857890/e2e_faster_rcnn_R-101-FPN_1x\"", ":", "\"35857890/12_2017_baselines/e2e_faster_rcnn_R-101-FPN_1x.yaml.01_38_50.sNxI7sX7\"", ",", "# noqa B950", "\n", "\"36761737/e2e_faster_rcnn_X-101-32x8d-FPN_1x\"", ":", "\"36761737/12_2017_baselines/e2e_faster_rcnn_X-101-32x8d-FPN_1x.yaml.06_31_39.5MIHi1fZ\"", ",", "# noqa B950", "\n", "\"35858791/e2e_mask_rcnn_R-50-C4_1x\"", ":", "\"35858791/12_2017_baselines/e2e_mask_rcnn_R-50-C4_1x.yaml.01_45_57.ZgkA7hPB\"", ",", "# noqa B950", "\n", "\"35858933/e2e_mask_rcnn_R-50-FPN_1x\"", ":", "\"35858933/12_2017_baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml.01_48_14.DzEQe4wC\"", ",", "# noqa B950", "\n", "\"35861795/e2e_mask_rcnn_R-101-FPN_1x\"", ":", "\"35861795/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_1x.yaml.02_31_37.KqyEK4tT\"", ",", "# noqa B950", "\n", "\"36761843/e2e_mask_rcnn_X-101-32x8d-FPN_1x\"", ":", "\"36761843/12_2017_baselines/e2e_mask_rcnn_X-101-32x8d-FPN_1x.yaml.06_35_59.RZotkLKI\"", ",", "# noqa B950", "\n", "\"48616381/e2e_mask_rcnn_R-50-FPN_2x_gn\"", ":", "\"GN/48616381/04_2018_gn_baselines/e2e_mask_rcnn_R-50-FPN_2x_gn_0416.13_23_38.bTlTI97Q\"", ",", "# noqa B950", "\n", "\"37697547/e2e_keypoint_rcnn_R-50-FPN_1x\"", ":", "\"37697547/12_2017_baselines/e2e_keypoint_rcnn_R-50-FPN_1x.yaml.08_42_54.kdzV35ao\"", ",", "# noqa B950", "\n", "\"35998355/rpn_R-50-C4_1x\"", ":", "\"35998355/12_2017_baselines/rpn_R-50-C4_1x.yaml.08_00_43.njH5oD9L\"", ",", "# noqa B950", "\n", "\"35998814/rpn_R-50-FPN_1x\"", ":", "\"35998814/12_2017_baselines/rpn_R-50-FPN_1x.yaml.08_06_03.Axg0r179\"", ",", "# noqa B950", "\n", "\"36225147/fast_R-50-FPN_1x\"", ":", "\"36225147/12_2017_baselines/fast_rcnn_R-50-FPN_1x.yaml.08_39_09.L3obSdQ2\"", ",", "# noqa B950", "\n", "}", "\n", "\n", "@", "staticmethod", "\n", "def", "get", "(", "name", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"Caffe2Detectron/COCO\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._DatasetCatalog.list": [[60, 68], ["catalog._DatasetCatalog.list"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["            ", "return", "ModelCatalog", ".", "_get_c2_detectron_baseline", "(", "name", ")", "\n", "", "if", "name", ".", "startswith", "(", "\"ImageNetPretrained/\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_imagenet_pretrained", "(", "name", ")", "\n", "", "raise", "RuntimeError", "(", "\"model not present in the catalog: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_get_c2_imagenet_pretrained", "(", "name", ")", ":", "\n", "        ", "prefix", "=", "ModelCatalog", ".", "S3_C2_DETECTRON_PREFIX", "\n", "name", "=", "name", "[", "len", "(", "\"ImageNetPretrained/\"", ")", ":", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._DatasetCatalog.remove": [[69, 74], ["catalog._DatasetCatalog.pop"], "methods", ["None"], ["name", "=", "ModelCatalog", ".", "C2_IMAGENET_MODELS", "[", "name", "]", "\n", "url", "=", "\"/\"", ".", "join", "(", "[", "prefix", ",", "name", "]", ")", "\n", "return", "url", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_get_c2_detectron_baseline", "(", "name", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._DatasetCatalog.__str__": [[75, 77], ["catalog._DatasetCatalog.keys"], "methods", ["None"], ["        ", "name", "=", "name", "[", "len", "(", "\"Caffe2Detectron/COCO/\"", ")", ":", "]", "\n", "url", "=", "ModelCatalog", ".", "C2_DETECTRON_MODELS", "[", "name", "]", "\n", "if", "\"keypoint_rcnn\"", "in", "name", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog.Metadata.__getattr__": [[115, 133], ["detectron2.utils.logger.log_first_n", "getattr", "len", "AttributeError", "AttributeError", "str", "catalog.Metadata.__dict__.keys"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_first_n"], ["", "", "PathManager", ".", "register_handler", "(", "ModelCatalogHandler", "(", ")", ")", "\n", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog.Metadata.__setattr__": [[136, 154], ["detectron2.utils.logger.log_first_n", "setattr", "getattr", "types.SimpleNamespace.__setattr__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_first_n", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__setattr__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog.Metadata.as_dict": [[155, 161], ["copy.copy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog.Metadata.set": [[162, 169], ["kwargs.items", "setattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog.Metadata.get": [[170, 179], ["getattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.get": [[194, 208], ["len", "super().get", "catalog.Metadata"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list": [[209, 217], ["catalog._MetadataCatalog.list"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove": [[218, 223], ["catalog._MetadataCatalog.pop"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.__str__": [[224, 226], ["catalog._MetadataCatalog.keys"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.filter_images_with_only_crowd_annotations": [[38, 67], ["len", "len", "logging.getLogger", "logging.getLogger.info", "build.filter_images_with_only_crowd_annotations.valid"], "function", ["None"], ["# during training", "\n", "if", "data", "[", "\"factory\"", "]", "==", "\"COCODataset\"", ":", "\n", "            ", "args", "[", "\"remove_images_without_annotations\"", "]", "=", "is_train", "\n", "", "if", "data", "[", "\"factory\"", "]", "==", "\"PascalVOCDataset\"", ":", "\n", "            ", "args", "[", "\"use_difficult\"", "]", "=", "not", "is_train", "\n", "", "args", "[", "\"transforms\"", "]", "=", "transforms", "\n", "# make dataset from factory", "\n", "dataset", "=", "factory", "(", "**", "args", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "# for testing, return a list of datasets", "\n", "", "if", "not", "is_train", ":", "\n", "        ", "return", "datasets", "\n", "\n", "# for training, concatenate all datasets into a single one", "\n", "", "dataset", "=", "datasets", "[", "0", "]", "\n", "if", "len", "(", "datasets", ")", ">", "1", ":", "\n", "        ", "dataset", "=", "D", ".", "ConcatDataset", "(", "datasets", ")", "\n", "\n", "", "return", "[", "dataset", "]", "\n", "\n", "\n", "", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.filter_images_with_few_keypoints": [[69, 101], ["len", "len", "logging.getLogger", "logging.getLogger.info", "sum", "build.filter_images_with_few_keypoints.visible_keypoints_in_image"], "function", ["None"], ["\n", "", "def", "_quantize", "(", "x", ",", "bins", ")", ":", "\n", "    ", "bins", "=", "copy", ".", "copy", "(", "bins", ")", "\n", "bins", "=", "sorted", "(", "bins", ")", "\n", "quantized", "=", "list", "(", "map", "(", "lambda", "y", ":", "bisect", ".", "bisect_right", "(", "bins", ",", "y", ")", ",", "x", ")", ")", "\n", "return", "quantized", "\n", "\n", "\n", "", "def", "_compute_aspect_ratios", "(", "dataset", ")", ":", "\n", "    ", "aspect_ratios", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "img_info", "=", "dataset", ".", "get_img_info", "(", "i", ")", "\n", "aspect_ratio", "=", "float", "(", "img_info", "[", "\"height\"", "]", ")", "/", "float", "(", "img_info", "[", "\"width\"", "]", ")", "\n", "aspect_ratios", ".", "append", "(", "aspect_ratio", ")", "\n", "", "return", "aspect_ratios", "\n", "\n", "\n", "", "def", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_batch", ",", "num_iters", "=", "None", ",", "start_iter", "=", "0", "\n", ")", ":", "\n", "    ", "if", "aspect_grouping", ":", "\n", "        ", "if", "not", "isinstance", "(", "aspect_grouping", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "aspect_grouping", "=", "[", "aspect_grouping", "]", "\n", "", "aspect_ratios", "=", "_compute_aspect_ratios", "(", "dataset", ")", "\n", "group_ids", "=", "_quantize", "(", "aspect_ratios", ",", "aspect_grouping", ")", "\n", "batch_sampler", "=", "samplers", ".", "GroupedBatchSampler", "(", "\n", "sampler", ",", "group_ids", ",", "images_per_batch", ",", "drop_uneven", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "BatchSampler", "(", "\n", "sampler", ",", "images_per_batch", ",", "drop_last", "=", "False", "\n", ")", "\n", "", "if", "num_iters", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.load_proposals_into_dataset": [[103, 155], ["logging.getLogger", "logging.getLogger.info", "set", "detectron2.utils.file_io.PathManager.open", "pickle.load", "str", "detectron2.structures.BoxMode", "pickle.load.pop", "str", "enumerate", "objectness_logits.argsort", "str", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["batch_sampler", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "", "return", "batch_sampler", "\n", "\n", "\n", "", "def", "make_data_loader", "(", "cfg", ",", "is_train", "=", "True", ",", "is_distributed", "=", "False", ",", "start_iter", "=", "0", ",", "is_for_period", "=", "False", ")", ":", "\n", "    ", "num_gpus", "=", "get_world_size", "(", ")", "\n", "if", "is_train", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "True", "\n", "num_iters", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "", "else", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "TEST", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "False", "if", "not", "is_distributed", "else", "True", "\n", "num_iters", "=", "None", "\n", "start_iter", "=", "0", "\n", "\n", "", "if", "images_per_gpu", ">", "1", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"When using more than one image per GPU you may encounter \"", "\n", "\"an out-of-memory (OOM) error if your GPU does not have \"", "\n", "\"sufficient memory. If this happens, you can reduce \"", "\n", "\"SOLVER.IMS_PER_BATCH (for training) or \"", "\n", "\"TEST.IMS_PER_BATCH (for inference). For training, you must \"", "\n", "\"also adjust the learning rate and schedule length according \"", "\n", "\"to the linear scaling rule. See for example: \"", "\n", "\"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"", "\n", ")", "\n", "\n", "# group images which have similar aspect ratio. In this case, we only", "\n", "# group in two cases: those with width / height > 1, and the other way around,", "\n", "# but the code supports more general grouping strategy", "\n", "", "aspect_grouping", "=", "[", "1", "]", "if", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", "else", "[", "]", "\n", "\n", "paths_catalog", "=", "import_file", "(", "\n", "\"maskrcnn_benchmark.config.paths_catalog\"", ",", "cfg", ".", "PATHS_CATALOG", ",", "True", "\n", ")", "\n", "DatasetCatalog", "=", "paths_catalog", ".", "DatasetCatalog", "\n", "dataset_list", "=", "cfg", ".", "DATASETS", ".", "TRAIN", "if", "is_train", "else", "cfg", ".", "DATASETS", ".", "TEST", "\n", "\n", "# If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later", "\n", "transforms", "=", "None", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "build_transforms", "(", "cfg", ",", "is_train", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.print_instances_class_histogram": [[157, 206], ["len", "numpy.arange", "numpy.zeros", "min", "list", "sum", "itertools.zip_longest.extend", "itertools.zip_longest", "tabulate.tabulate", "detectron2.utils.logger.log_first_n", "numpy.asarray", "len", "itertools.chain", "itertools.zip_longest.extend", "numpy.histogram", "len", "len", "termcolor.colored", "np.asarray.min", "np.asarray.max", "np.asarray.min", "np.asarray.max", "len", "range", "x.get", "build.print_instances_class_histogram.short_name"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_first_n", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "if", "is_train", ":", "\n", "# save category_id to label name mapping", "\n", "        ", "save_labels", "(", "datasets", ",", "cfg", ".", "OUTPUT_DIR", ")", "\n", "\n", "", "data_loaders", "=", "[", "]", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "sampler", "=", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "is_distributed", ")", "\n", "batch_sampler", "=", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_gpu", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "collator", "=", "BBoxAugCollator", "(", ")", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "BatchCollator", "(", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "collator", ",", "\n", ")", "\n", "data_loaders", ".", "append", "(", "data_loader", ")", "\n", "", "if", "is_train", "or", "is_for_period", ":", "\n", "# during training, a single (possibly concatenated) data_loader is returned", "\n", "        ", "assert", "len", "(", "data_loaders", ")", "==", "1", "\n", "return", "data_loaders", "[", "0", "]", "\n", "", "return", "data_loaders", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.get_detection_dataset_dicts": [[209, 257], ["isinstance", "len", "zip", "list", "len", "catalog.DatasetCatalog.get", "len", "itertools.chain.from_iterable", "build.filter_images_with_only_crowd_annotations", "build.filter_images_with_few_keypoints", "len", "len", "build.load_proposals_into_dataset", "detection_utils.check_metadata_consistency", "build.print_instances_class_histogram", "zip", "catalog.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.filter_images_with_only_crowd_annotations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.filter_images_with_few_keypoints", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.load_proposals_into_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_metadata_consistency", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.print_instances_class_histogram", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_batch_data_loader": [[259, 303], ["detectron2.utils.comm.get_world_size", "torch.utils.data.DataLoader", "common.AspectRatioGroupedDataset", "torch.utils.data.sampler.BatchSampler", "torch.utils.data.DataLoader", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._train_loader_from_config": [[306, 342], ["build.get_detection_dataset_dicts", "detectron2.utils.logger._log_api_usage", "dataset_mapper.DatasetMapper", "logging.getLogger", "logging.getLogger.info", "samplers.TrainingSampler", "len", "samplers.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency", "samplers.RepeatFactorTrainingSampler", "ValueError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.get_detection_dataset_dicts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._log_api_usage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader": [[408, 442], ["build._add_category_whitelists_to_metadata", "build._add_category_maps_to_metadata", "build._maybe_add_class_to_mesh_name_map_to_metadata", "build.combine_detection_dataset_dicts", "detectron2.data.build.build_detection_train_loader", "dataset_mapper.DatasetMapper", "build._get_train_keep_instance_predicate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_whitelists_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_maps_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_add_class_to_mesh_name_map_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.combine_detection_dataset_dicts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._get_train_keep_instance_predicate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._test_loader_from_config": [[393, 410], ["build.get_detection_dataset_dicts", "dataset_mapper.DatasetMapper", "list().index", "list"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.get_detection_dataset_dicts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader": [[444, 480], ["build._add_category_whitelists_to_metadata", "build._add_category_maps_to_metadata", "build._maybe_add_class_to_mesh_name_map_to_metadata", "build.combine_detection_dataset_dicts", "detectron2.data.build.build_detection_test_loader", "torch.utils.data.SequentialSampler", "dataset_mapper.DatasetMapper", "build._get_test_keep_instance_predicate", "list().index", "list"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_whitelists_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_maps_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_add_class_to_mesh_name_map_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.combine_detection_dataset_dicts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_test_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._get_test_keep_instance_predicate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.trivial_batch_collator": [[463, 468], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.worker_init_reset_seed": [[470, 473], ["detectron2.utils.env.seed_all_rng", "torch.initial_seed"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env.seed_all_rng"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper.__init__": [[36, 73], ["dataset_mapper.build_augmentation", "detectron2.data.detection_utils.create_keypoint_hflip_indices", "detectron2.utils.file_io.PathManager.get_local_path", "densepose.structures.DensePoseTransformData.load", "len", "detectron2.data.MetadataCatalog.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.build_augmentation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.create_keypoint_hflip_indices", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "\n", "@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "is_train", ":", "bool", ",", "\n", "*", ",", "\n", "augmentations", ":", "List", "[", "Union", "[", "T", ".", "Augmentation", ",", "T", ".", "Transform", "]", "]", ",", "\n", "image_format", ":", "str", ",", "\n", "use_instance_mask", ":", "bool", "=", "False", ",", "\n", "use_keypoint", ":", "bool", "=", "False", ",", "\n", "instance_mask_format", ":", "str", "=", "\"polygon\"", ",", "\n", "keypoint_hflip_indices", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "precomputed_proposal_topk", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "recompute_boxes", ":", "bool", "=", "False", ",", "\n", "aug", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            is_train: whether it's used in training or inference\n            augmentations: a list of augmentations or deterministic transforms to apply\n            image_format: an image format supported by :func:`detection_utils.read_image`.\n            use_instance_mask: whether to process instance segmentation annotations, if available\n            use_keypoint: whether to process keypoint annotations if available\n            instance_mask_format: one of \"polygon\" or \"bitmask\". Process instance segmentation\n                masks into this format.\n            keypoint_hflip_indices: see :func:`detection_utils.create_keypoint_hflip_indices`\n            precomputed_proposal_topk: if given, will load pre-computed\n                proposals from dataset_dict and keep the top k proposals for each image.\n            recompute_boxes: whether to overwrite bounding box annotations\n                by computing tight bounding boxes from instance mask annotations.\n        \"\"\"", "\n", "if", "recompute_boxes", ":", "\n", "            ", "assert", "use_instance_mask", ",", "\"recompute_boxes requires instance masks\"", "\n", "# fmt: off", "\n", "", "self", ".", "is_train", "=", "is_train", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper.from_config": [[88, 118], ["detection_utils.build_augmentation", "detection_utils.build_augmentation.insert", "detection_utils.create_keypoint_hflip_indices", "detectron2.augmentations.scale_aware_aug.SA_Aug", "transforms.RandomCrop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.build_augmentation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.create_keypoint_hflip_indices"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "is_train", ":", "bool", "=", "True", ")", ":", "\n", "        ", "augs", "=", "utils", ".", "build_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", "and", "is_train", ":", "\n", "            ", "augs", ".", "insert", "(", "0", ",", "T", ".", "RandomCrop", "(", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", ",", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", ")", ")", "\n", "recompute_boxes", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "", "else", ":", "\n", "            ", "recompute_boxes", "=", "False", "\n", "\n", "", "ret", "=", "{", "\n", "\"is_train\"", ":", "is_train", ",", "\n", "\"augmentations\"", ":", "augs", ",", "\n", "\"image_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"use_instance_mask\"", ":", "cfg", ".", "MODEL", ".", "MASK_ON", ",", "\n", "\"instance_mask_format\"", ":", "cfg", ".", "INPUT", ".", "MASK_FORMAT", ",", "\n", "\"use_keypoint\"", ":", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\n", "\"recompute_boxes\"", ":", "recompute_boxes", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "ret", "[", "\"keypoint_hflip_indices\"", "]", "=", "utils", ".", "create_keypoint_hflip_indices", "(", "cfg", ".", "DATASETS", ".", "TRAIN", ")", "\n", "\n", "", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", ":", "\n", "            ", "ret", "[", "\"precomputed_proposal_topk\"", "]", "=", "(", "\n", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "\n", "if", "is_train", "\n", "else", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "\n", ")", "\n", "", "ret", "[", "\"aug\"", "]", "=", "SA_Aug", "(", "cfg", ")", "if", "cfg", ".", "AUTOAUG", ".", "USE", "and", "is_train", "else", "None", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper.__call__": [[74, 125], ["copy.deepcopy", "detectron2.data.detection_utils.read_image", "detectron2.data.detection_utils.check_image_size", "detectron2.data.transforms.apply_transform_gens", "torch.as_tensor", "detectron2.data.detection_utils.annotations_to_instances", "detectron2.data.detection_utils.read_image.transpose().astype", "copy.deepcopy.pop", "dataset_mapper.DatasetMapper._transform_densepose", "dataset_mapper.DatasetMapper._add_densepose_masks_as_segmentation", "obj.get", "densepose.structures.DensePoseList", "anno.pop", "anno.pop", "detectron2.data.detection_utils.transform_instance_annotations", "copy.deepcopy.pop", "all", "detectron2.data.detection_utils.annotations_to_instances.gt_boxes.nonempty", "detectron2.data.detection_utils.read_image.transpose", "obj.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_image_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.annotations_to_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper._transform_densepose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper._add_densepose_masks_as_segmentation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.transform_instance_annotations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["self", ".", "augmentations", "=", "T", ".", "AugmentationList", "(", "augmentations", ")", "\n", "self", ".", "image_format", "=", "image_format", "\n", "self", ".", "use_instance_mask", "=", "use_instance_mask", "\n", "self", ".", "instance_mask_format", "=", "instance_mask_format", "\n", "self", ".", "use_keypoint", "=", "use_keypoint", "\n", "self", ".", "keypoint_hflip_indices", "=", "keypoint_hflip_indices", "\n", "self", ".", "proposal_topk", "=", "precomputed_proposal_topk", "\n", "self", ".", "recompute_boxes", "=", "recompute_boxes", "\n", "self", ".", "aug", "=", "aug", "\n", "# fmt: on", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "mode", "=", "\"training\"", "if", "is_train", "else", "\"inference\"", "\n", "logger", ".", "info", "(", "f\"[DatasetMapper] Augmentations used in {mode}: {augmentations}\"", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "is_train", ":", "bool", "=", "True", ")", ":", "\n", "        ", "augs", "=", "utils", ".", "build_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", "and", "is_train", ":", "\n", "            ", "augs", ".", "insert", "(", "0", ",", "T", ".", "RandomCrop", "(", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", ",", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", ")", ")", "\n", "recompute_boxes", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "", "else", ":", "\n", "            ", "recompute_boxes", "=", "False", "\n", "\n", "", "ret", "=", "{", "\n", "\"is_train\"", ":", "is_train", ",", "\n", "\"augmentations\"", ":", "augs", ",", "\n", "\"image_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"use_instance_mask\"", ":", "cfg", ".", "MODEL", ".", "MASK_ON", ",", "\n", "\"instance_mask_format\"", ":", "cfg", ".", "INPUT", ".", "MASK_FORMAT", ",", "\n", "\"use_keypoint\"", ":", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\n", "\"recompute_boxes\"", ":", "recompute_boxes", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "ret", "[", "\"keypoint_hflip_indices\"", "]", "=", "utils", ".", "create_keypoint_hflip_indices", "(", "cfg", ".", "DATASETS", ".", "TRAIN", ")", "\n", "\n", "", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", ":", "\n", "            ", "ret", "[", "\"precomputed_proposal_topk\"", "]", "=", "(", "\n", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "\n", "if", "is_train", "\n", "else", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "\n", ")", "\n", "", "ret", "[", "\"aug\"", "]", "=", "SA_Aug", "(", "cfg", ")", "if", "cfg", ".", "AUTOAUG", ".", "USE", "and", "is_train", "else", "None", "\n", "return", "ret", "\n", "\n", "", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.combined_loader.CombinedDataLoader.__init__": [[23, 27], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loaders", ":", "Collection", "[", "Loader", "]", ",", "batch_size", ":", "int", ",", "ratios", ":", "Sequence", "[", "float", "]", ")", ":", "\n", "        ", "self", ".", "loaders", "=", "loaders", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "ratios", "=", "ratios", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.combined_loader.CombinedDataLoader.__iter__": [[28, 45], ["iter", "len", "collections.deque", "random.choices", "range", "combined_loader._pooled_next", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.combined_loader._pooled_next"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "List", "[", "Any", "]", "]", ":", "\n", "        ", "iters", "=", "[", "iter", "(", "loader", ")", "for", "loader", "in", "self", ".", "loaders", "]", "\n", "indices", "=", "[", "]", "\n", "pool", "=", "[", "deque", "(", ")", "]", "*", "len", "(", "iters", ")", "\n", "# infinite iterator, as in D2", "\n", "while", "True", ":", "\n", "            ", "if", "not", "indices", ":", "\n", "# just a buffer of indices, its size doesn't matter", "\n", "# as long as it's a multiple of batch_size", "\n", "                ", "k", "=", "self", ".", "batch_size", "*", "self", ".", "BATCH_COUNT", "\n", "indices", "=", "random", ".", "choices", "(", "range", "(", "len", "(", "self", ".", "loaders", ")", ")", ",", "self", ".", "ratios", ",", "k", "=", "k", ")", "\n", "", "try", ":", "\n", "                ", "batch", "=", "[", "_pooled_next", "(", "iters", "[", "i", "]", ",", "pool", "[", "i", "]", ")", "for", "i", "in", "indices", "[", ":", "self", ".", "batch_size", "]", "]", "\n", "", "except", "StopIteration", ":", "\n", "                ", "break", "\n", "", "indices", "=", "indices", "[", "self", ".", "batch_size", ":", "]", "\n", "yield", "batch", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.combined_loader._pooled_next": [[10, 14], ["pool.popleft", "pool.extend", "next"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["def", "_pooled_next", "(", "iterator", ":", "Iterator", "[", "Any", "]", ",", "pool", ":", "Deque", "[", "Any", "]", ")", ":", "\n", "    ", "if", "not", "pool", ":", "\n", "        ", "pool", ".", "extend", "(", "next", "(", "iterator", ")", ")", "\n", "", "return", "pool", ".", "popleft", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.image_list_dataset.ImageListDataset.__init__": [[22, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "image_list", ":", "List", "[", "str", "]", ",", "transform", ":", "Optional", "[", "ImageTransform", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_list (List[str]): list of paths to image files\n        \"\"\"", "\n", "self", ".", "image_list", "=", "image_list", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.image_list_dataset.ImageListDataset.__getitem__": [[30, 52], ["torch.from_numpy", "numpy.ascontiguousarray", "logging.getLogger", "logging.getLogger.warning", "detectron2.data.detection_utils.read_image", "image_list_dataset.ImageListDataset.transform", "torch.from_numpy.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Gets selected images from the list\n\n        Args:\n            idx (int): video index in the video list file\n        Returns:\n            image (torch.Tensor): tensor of size [H, W, 3]\n        \"\"\"", "\n", "fpath", "=", "self", ".", "image_list", "[", "idx", "]", "\n", "\n", "try", ":", "\n", "            ", "image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "read_image", "(", "fpath", ",", "format", "=", "\"BGR\"", ")", ")", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "# Transforms are done on batches", "\n", "                ", "image", "=", "self", ".", "transform", "(", "image", ".", "unsqueeze", "(", "0", ")", ")", "[", "0", "]", "# pyre-ignore[29]", "\n", "", "return", "image", "\n", "", "except", "(", "OSError", ",", "RuntimeError", ")", "as", "e", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "f\"Error opening image file container {fpath}: {e}\"", ")", "\n", "\n", "", "return", "self", ".", "_EMPTY_IMAGE", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.image_list_dataset.ImageListDataset.__len__": [[53, 55], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._BootstrapDatasetFactoryCatalog.register": [[661, 670], ["datasets.dataset_type.DatasetType.VIDEO_LIST", "build.build_video_list_dataset"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_video_list_dataset"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._compute_num_images_per_worker": [[56, 71], ["detectron2.utils.comm.get_world_size"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["\n", "", "return", "[", "dataset", "]", "\n", "\n", "\n", "", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n", "\n", "", "def", "_quantize", "(", "x", ",", "bins", ")", ":", "\n", "    ", "bins", "=", "copy", ".", "copy", "(", "bins", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._map_category_id_to_contiguous_id": [[73, 78], ["detectron2.data.catalog.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["quantized", "=", "list", "(", "map", "(", "lambda", "y", ":", "bisect", ".", "bisect_right", "(", "bins", ",", "y", ")", ",", "x", ")", ")", "\n", "return", "quantized", "\n", "\n", "\n", "", "def", "_compute_aspect_ratios", "(", "dataset", ")", ":", "\n", "    ", "aspect_ratios", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_id_to_contiguous_id_maps_to_metadata": [[109, 143], ["enumerate", "logging.getLogger", "merged_categories_per_dataset.items", "sorted", "detectron2.data.catalog.MetadataCatalog.get", "logging.getLogger.info", "sorted", "merged_categories.keys", "[].append", "hasattr", "MetadataCatalog.get.thing_classes.clear", "MetadataCatalog.get.thing_dataset_id_to_contiguous_id.clear", "MetadataCatalog.get.thing_dataset_id_to_merged_id.clear", "merged_categories.items", "collections.defaultdict", "logging.getLogger.info", "MetadataCatalog.get.thing_classes.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["    ", "num_gpus", "=", "get_world_size", "(", ")", "\n", "if", "is_train", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "True", "\n", "num_iters", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "", "else", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "TEST", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "False", "if", "not", "is_distributed", "else", "True", "\n", "num_iters", "=", "None", "\n", "start_iter", "=", "0", "\n", "\n", "", "if", "images_per_gpu", ">", "1", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"When using more than one image per GPU you may encounter \"", "\n", "\"an out-of-memory (OOM) error if your GPU does not have \"", "\n", "\"sufficient memory. If this happens, you can reduce \"", "\n", "\"SOLVER.IMS_PER_BATCH (for training) or \"", "\n", "\"TEST.IMS_PER_BATCH (for inference). For training, you must \"", "\n", "\"also adjust the learning rate and schedule length according \"", "\n", "\"to the linear scaling rule. See for example: \"", "\n", "\"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"", "\n", ")", "\n", "\n", "# group images which have similar aspect ratio. In this case, we only", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_general_keep_instance_predicate": [[145, 161], ["build._maybe_create_general_keep_instance_predicate.has_annotations"], "function", ["None"], ["# but the code supports more general grouping strategy", "\n", "", "aspect_grouping", "=", "[", "1", "]", "if", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", "else", "[", "]", "\n", "\n", "paths_catalog", "=", "import_file", "(", "\n", "\"maskrcnn_benchmark.config.paths_catalog\"", ",", "cfg", ".", "PATHS_CATALOG", ",", "True", "\n", ")", "\n", "DatasetCatalog", "=", "paths_catalog", ".", "DatasetCatalog", "\n", "dataset_list", "=", "cfg", ".", "DATASETS", ".", "TRAIN", "if", "is_train", "else", "cfg", ".", "DATASETS", ".", "TEST", "\n", "\n", "# If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later", "\n", "transforms", "=", "None", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "build_transforms", "(", "cfg", ",", "is_train", ")", "\n", "datasets", "=", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "DatasetCatalog", ",", "is_train", "or", "is_for_period", ")", "\n", "\n", "if", "is_train", ":", "\n", "# save category_id to label name mapping", "\n", "        ", "save_labels", "(", "datasets", ",", "cfg", ".", "OUTPUT_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_keypoints_keep_instance_predicate": [[163, 178], ["sum", "numpy.array"], "function", ["None"], ["for", "dataset", "in", "datasets", ":", "\n", "        ", "sampler", "=", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "is_distributed", ")", "\n", "batch_sampler", "=", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_gpu", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "collator", "=", "BBoxAugCollator", "(", ")", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "BatchCollator", "(", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "collator", ",", "\n", ")", "\n", "data_loaders", ".", "append", "(", "data_loader", ")", "\n", "", "if", "is_train", "or", "is_for_period", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_mask_keep_instance_predicate": [[180, 188], ["any"], "function", ["None"], ["        ", "assert", "len", "(", "data_loaders", ")", "==", "1", "\n", "return", "data_loaders", "[", "0", "]", "\n", "", "return", "data_loaders", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_densepose_keep_instance_predicate": [[190, 207], ["all", "all"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_specific_keep_instance_predicate": [[209, 224], ["creator", "any", "p"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._get_train_keep_instance_predicate": [[226, 240], ["build._maybe_create_general_keep_instance_predicate", "build._maybe_create_specific_keep_instance_predicate", "_maybe_create_general_keep_instance_predicate.", "_maybe_create_specific_keep_instance_predicate."], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_general_keep_instance_predicate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_specific_keep_instance_predicate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._get_test_keep_instance_predicate": [[242, 245], ["build._maybe_create_general_keep_instance_predicate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_create_general_keep_instance_predicate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_filter_and_map_categories": [[247, 264], ["detectron2.data.catalog.MetadataCatalog.get", "filtered_dataset_dicts.append", "anns.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_whitelists_to_metadata": [[266, 274], ["cfg.DATASETS.WHITELISTED_CATEGORIES.items", "detectron2.data.catalog.MetadataCatalog.get", "logging.getLogger", "logging.getLogger.info"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_maps_to_metadata": [[278, 287], ["cfg.DATASETS.CATEGORY_MAPS.items", "detectron2.data.catalog.MetadataCatalog.get", "logging.getLogger", "logging.getLogger.info", "int", "int", "category_map.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_add_class_to_mesh_name_map_to_metadata": [[289, 294], ["detectron2.data.catalog.MetadataCatalog.get", "hasattr", "utils.get_class_to_mesh_name_mapping"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.get_class_to_mesh_name_mapping"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._merge_categories": [[296, 333], ["collections.defaultdict", "collections.defaultdict.items", "detectron2.data.catalog.MetadataCatalog.get", "MetadataCatalog.get.get", "MetadataCatalog.get.get", "MetadataCatalog.get.categories.keys", "meta.get.get", "merged_categories[].append", "str", "build._DatasetCategory"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._warn_if_merged_different_categories": [[335, 348], ["logging.getLogger", "logging.getLogger.warning", "len", "all"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.combine_detection_dataset_dicts": [[352, 406], ["len", "build._merge_categories", "build._warn_if_merged_different_categories", "build._add_category_id_to_contiguous_id_maps_to_metadata", "zip", "len", "len", "detectron2.data.catalog.DatasetCatalog.get", "len", "len", "build._maybe_filter_and_map_categories", "detectron2.data.build.print_instances_class_histogram", "list", "len", "sorted", "detectron2.data.build.load_proposals_into_dataset", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "keep_instance_predicate", "dataset_name_to_dicts.values", "dataset_name_to_dicts.values"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._merge_categories", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._warn_if_merged_different_categories", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._add_category_id_to_contiguous_id_maps_to_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._maybe_filter_and_map_categories", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.print_instances_class_histogram", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.load_proposals_into_dataset"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_frame_selector": [[483, 494], ["video.FrameSelectionStrategy", "video.RandomKFramesSelector", "video.FirstKFramesSelector", "video.LastKFramesSelector"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_transform": [[496, 501], ["ValueError", "transform.ImageResizeTransform"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_combined_loader": [[503, 506], ["build._compute_num_images_per_worker", "combined_loader.CombinedDataLoader"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build._compute_num_images_per_worker"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_bootstrap_dataset": [[508, 529], ["logging.getLogger", "detectron2.data.catalog.MetadataCatalog.get", "BootstrapDatasetFactoryCatalog.get", "BootstrapDatasetFactoryCatalog.get.", "logging.getLogger.warning"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_data_sampler": [[531, 586], ["ValueError", "samplers.PredictionToGroundTruthSampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.DensePoseUniformSampler", "samplers.MaskFromDensePoseSampler", "samplers.PredictionToGroundTruthSampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.DensePoseConfidenceBasedSampler", "samplers.MaskFromDensePoseSampler", "samplers.PredictionToGroundTruthSampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.DensePoseConfidenceBasedSampler", "samplers.MaskFromDensePoseSampler", "samplers.PredictionToGroundTruthSampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.PredictionToGroundTruthSampler.register_sampler", "samplers.DensePoseConfidenceBasedSampler", "samplers.MaskFromDensePoseSampler"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_data_filter": [[588, 593], ["ValueError", "inference_based_loader.ScoreBasedFilter"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_inference_based_loader": [[595, 619], ["build.build_bootstrap_dataset", "detectron2.data.samplers.TrainingSampler", "torch.utils.data.DataLoader", "inference_based_loader.InferenceBasedLoader", "len", "build.build_data_sampler", "build.build_data_filter"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_bootstrap_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_data_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_data_filter"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.has_inference_based_loaders": [[622, 628], ["len"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_inference_based_loaders": [[630, 642], ["densepose.config.get_bootstrap_dataset_config().clone", "get_bootstrap_dataset_config().clone.merge_from_other_cfg", "build.build_inference_based_loader", "loaders.append", "ratios.append", "detectron2.config.CfgNode", "densepose.config.get_bootstrap_dataset_config"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_inference_based_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.get_bootstrap_dataset_config"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_video_list_dataset": [[644, 653], ["build.build_frame_selector", "build.build_transform", "video.video_list_from_file", "video.VideoKeyframeDataset", "hasattr"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_frame_selector", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.video_list_from_file"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper._transform_densepose": [[126, 144], ["densepose.structures.DensePoseDataRelative.validate_annotation", "densepose.structures.DensePoseDataRelative", "densepose.structures.DensePoseDataRelative.apply_transform", "densepose.structures.DensePoseDataRelative.cleanup_annotation"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.validate_annotation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.apply_transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.cleanup_annotation"], ["\n", "dataset_dict", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "# it will be modified by code below", "\n", "# USER: Write your own image loading if it's not from a file", "\n", "image", "=", "utils", ".", "read_image", "(", "dataset_dict", "[", "\"file_name\"", "]", ",", "format", "=", "self", ".", "image_format", ")", "\n", "utils", ".", "check_image_size", "(", "dataset_dict", ",", "image", ")", "\n", "\n", "# USER: Remove if you don't do semantic/panoptic segmentation.", "\n", "if", "\"sem_seg_file_name\"", "in", "dataset_dict", ":", "\n", "            ", "sem_seg_gt", "=", "utils", ".", "read_image", "(", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ")", ",", "\"L\"", ")", ".", "squeeze", "(", "2", ")", "\n", "", "else", ":", "\n", "            ", "sem_seg_gt", "=", "None", "\n", "\n", "", "aug_input", "=", "T", ".", "AugInput", "(", "image", ",", "sem_seg", "=", "sem_seg_gt", ")", "\n", "transforms", "=", "self", ".", "augmentations", "(", "aug_input", ")", "\n", "image", ",", "sem_seg_gt", "=", "aug_input", ".", "image", ",", "aug_input", ".", "sem_seg", "\n", "\n", "image_shape", "=", "image", ".", "shape", "[", ":", "2", "]", "# h, w", "\n", "# Pytorch's dataloader is efficient on torch.Tensor due to shared-memory,", "\n", "# but not efficient on large generic data structures due to the use of pickle & mp.Queue.", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.DatasetMapper._add_densepose_masks_as_segmentation": [[145, 169], ["torch.zeros_like", "torch.tensor", "detectron2.layers.ROIAlign().forward().squeeze", "torch.zeros", "v.item", "detectron2.structures.BoxMode.convert", "detectron2.layers.ROIAlign().forward", "torch.zeros_like.view", "detectron2.layers.ROIAlign"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["# Therefore it's important to use torch.Tensor.", "\n", "dataset_dict", "[", "\"image\"", "]", "=", "torch", ".", "as_tensor", "(", "np", ".", "ascontiguousarray", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "if", "sem_seg_gt", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "\"sem_seg\"", "]", "=", "torch", ".", "as_tensor", "(", "sem_seg_gt", ".", "astype", "(", "\"long\"", ")", ")", "\n", "\n", "# USER: Remove if you don't use pre-computed proposals.", "\n", "# Most users would not need this feature.", "\n", "", "if", "self", ".", "proposal_topk", "is", "not", "None", ":", "\n", "            ", "utils", ".", "transform_proposals", "(", "\n", "dataset_dict", ",", "image_shape", ",", "transforms", ",", "proposal_topk", "=", "self", ".", "proposal_topk", "\n", ")", "\n", "\n", "", "if", "not", "self", ".", "is_train", ":", "\n", "# USER: Modify this if you want to keep them for some reason.", "\n", "            ", "dataset_dict", ".", "pop", "(", "\"annotations\"", ",", "None", ")", "\n", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ",", "None", ")", "\n", "return", "dataset_dict", "\n", "\n", "", "if", "\"annotations\"", "in", "dataset_dict", ":", "\n", "# USER: Modify this if you want to keep them for some reason.", "\n", "            ", "for", "anno", "in", "dataset_dict", "[", "\"annotations\"", "]", ":", "\n", "                ", "if", "not", "self", ".", "use_instance_mask", ":", "\n", "                    ", "anno", ".", "pop", "(", "\"segmentation\"", ",", "None", ")", "\n", "", "if", "not", "self", ".", "use_keypoint", ":", "\n", "                    ", "anno", ".", "pop", "(", "\"keypoints\"", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.build_augmentation": [[19, 29], ["logging.getLogger", "detectron2.data.detection_utils.build_augmentation", "detectron2.data.transforms.RandomRotation", "utils.build_augmentation.append", "logging.getLogger.info", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.dataset_mapper.build_augmentation"], ["\n", "\n", "class", "DatasetMapper", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader.ScoreBasedFilter.__init__": [[39, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "min_score", ":", "float", "=", "0.8", ")", ":", "\n", "        ", "self", ".", "min_score", "=", "min_score", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader.ScoreBasedFilter.__call__": [[42, 50], ["instances.has"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["", "def", "__call__", "(", "self", ",", "model_output", ":", "ModelOutput", ")", "->", "ModelOutput", ":", "\n", "        ", "for", "model_output_i", "in", "model_output", ":", "\n", "            ", "instances", "=", "model_output_i", "[", "\"instances\"", "]", "\n", "if", "not", "instances", ".", "has", "(", "\"scores\"", ")", ":", "\n", "                ", "continue", "\n", "", "instances_filtered", "=", "instances", "[", "instances", ".", "scores", ">=", "self", ".", "min_score", "]", "\n", "model_output_i", "[", "\"instances\"", "]", "=", "instances_filtered", "\n", "", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader.InferenceBasedLoader.__init__": [[60, 98], ["inference_based_loader.InferenceBasedLoader.model.eval"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "data_loader", ":", "Iterable", "[", "List", "[", "torch", ".", "Tensor", "]", "]", ",", "\n", "data_sampler", ":", "Optional", "[", "Callable", "[", "[", "ModelOutput", "]", ",", "List", "[", "SampledData", "]", "]", "]", "=", "None", ",", "\n", "data_filter", ":", "Optional", "[", "Callable", "[", "[", "ModelOutput", "]", ",", "ModelOutput", "]", "]", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "batch_size", ":", "int", "=", "4", ",", "\n", "inference_batch_size", ":", "int", "=", "4", ",", "\n", "drop_last", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Constructor\n\n        Args:\n          model (torch.nn.Module): model used to produce data\n          data_loader (Iterable[Tensor]): iterable that provides images\n              to perform inference on\n          data_sampler (Callable: ModelOutput -> SampledData): functor\n              that produces annotation data from inference results;\n              (optional, default: None)\n          data_filter (Callable: ModelOutput -> ModelOutput): filter\n              that selects model outputs for for further processing\n              (optional, default: None)\n          shuffle (bool): if True, the input images get shuffled\n          batch_size (int): batch size for the produced annotation data\n          inference_batch_size (int): batch size for input images\n          drop_last (bool): if True, drop the last batch if it is undersized\n        \"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "data_sampler", "=", "data_sampler", "\n", "self", ".", "data_filter", "=", "data_filter", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "inference_batch_size", "=", "inference_batch_size", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader.InferenceBasedLoader.__iter__": [[99, 110], ["random.shuffle", "inference_based_loader.InferenceBasedLoader._produce_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader.InferenceBasedLoader._produce_data"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "List", "[", "SampledData", "]", "]", ":", "\n", "        ", "for", "batch", "in", "self", ".", "data_loader", ":", "\n", "# batch : List[Tensor[N, C, H, W]]", "\n", "# images_batch : Tensor[N, C, H, W]", "\n", "# image : Tensor[C, H, W]", "\n", "            ", "images", "=", "[", "image", "for", "images_batch", "in", "batch", "for", "image", "in", "images_batch", "]", "\n", "if", "not", "images", ":", "\n", "                ", "continue", "\n", "", "if", "self", ".", "shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "images", ")", "\n", "", "yield", "from", "self", ".", "_produce_data", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader.InferenceBasedLoader._produce_data": [[111, 153], ["inference_based_loader._grouper", "zip", "torch.no_grad", "inference_based_loader.InferenceBasedLoader.model", "inference_based_loader.InferenceBasedLoader.data_filter", "inference_based_loader.InferenceBasedLoader.data_sampler", "len", "len", "img.to", "data_batches.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_combine_data_loader._grouper", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "def", "_produce_data", "(", "self", ",", "images", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "Iterator", "[", "List", "[", "SampledData", "]", "]", ":", "\n", "        ", "\"\"\"\n        Produce batches of data from images\n\n        Args:\n          images (List[Tensor]): list of images to process\n\n        Returns:\n          Iterator over batches of data sampled from model outputs\n        \"\"\"", "\n", "data_batches", ":", "List", "[", "SampledData", "]", "=", "[", "]", "\n", "batched_images", "=", "_grouper", "(", "images", ",", "self", ".", "inference_batch_size", ")", "\n", "for", "batch", "in", "batched_images", ":", "\n", "            ", "batch", "=", "[", "\n", "{", "\"image\"", ":", "img", ".", "to", "(", "self", ".", "model", ".", "device", ")", "}", "# pyre-ignore[16]", "\n", "for", "img", "in", "batch", "\n", "if", "img", "is", "not", "None", "\n", "]", "\n", "if", "not", "batch", ":", "\n", "                ", "continue", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "model_output", "=", "self", ".", "model", "(", "batch", ")", "\n", "", "for", "model_output_i", ",", "batch_i", "in", "zip", "(", "model_output", ",", "batch", ")", ":", "\n", "                ", "model_output_i", "[", "\"image\"", "]", "=", "batch_i", "[", "\"image\"", "]", "\n", "", "model_output_filtered", "=", "(", "\n", "model_output", "\n", "if", "self", ".", "data_filter", "is", "None", "\n", "else", "self", ".", "data_filter", "(", "model_output", ")", "# pyre-ignore[29]", "\n", ")", "\n", "data", "=", "(", "\n", "model_output_filtered", "\n", "if", "self", ".", "data_sampler", "is", "None", "\n", "else", "self", ".", "data_sampler", "(", "model_output_filtered", ")", "# pyre-ignore[29]", "\n", ")", "\n", "for", "data_i", "in", "data", ":", "\n", "                ", "if", "len", "(", "data_i", "[", "\"instances\"", "]", ")", ":", "\n", "                    ", "data_batches", ".", "append", "(", "data_i", ")", "\n", "", "", "if", "len", "(", "data_batches", ")", ">=", "self", ".", "batch_size", ":", "\n", "                ", "yield", "data_batches", "[", ":", "self", ".", "batch_size", "]", "\n", "data_batches", "=", "data_batches", "[", "self", ".", "batch_size", ":", "]", "\n", "", "", "if", "not", "self", ".", "drop_last", "and", "data_batches", ":", "\n", "            ", "yield", "data_batches", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.inference_based_loader._grouper": [[12, 31], ["iter", "range", "values.append", "tuple", "next", "values.extend", "tuple", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["def", "_grouper", "(", "iterable", ":", "Iterable", "[", "Any", "]", ",", "n", ":", "int", ",", "fillvalue", "=", "None", ")", "->", "Iterator", "[", "Tuple", "[", "Any", "]", "]", ":", "\n", "    ", "\"\"\"\n    Group elements of an iterable by chunks of size `n`, e.g.\n    grouper(range(9), 4) ->\n        (0, 1, 2, 3), (4, 5, 6, 7), (8, None, None, None)\n    \"\"\"", "\n", "it", "=", "iter", "(", "iterable", ")", "\n", "while", "True", ":", "\n", "        ", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "value", "=", "next", "(", "it", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "if", "values", ":", "\n", "                    ", "values", ".", "extend", "(", "[", "fillvalue", "]", "*", "(", "n", "-", "len", "(", "values", ")", ")", ")", "\n", "yield", "tuple", "(", "values", ")", "# pyre-ignore[7]", "\n", "", "return", "\n", "", "values", ".", "append", "(", "value", ")", "\n", "", "yield", "tuple", "(", "values", ")", "# pyre-ignore[7]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.is_relative_local_path": [[9, 12], ["os.fsdecode", "os.path.isabs"], "function", ["None"], ["def", "cat", "(", "tensors", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path": [[14, 25], ["utils.is_relative_local_path", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.is_relative_local_path"], ["if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.get_class_to_mesh_name_mapping": [[27, 31], ["int", "cfg.DATASETS.CLASS_TO_MESH_NAME_MAPPING.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.COCODataset.__init__": [[40, 65], ["super().__init__", "sorted", "coco.COCODataset.coco.getAnnIds", "coco.COCODataset.coco.loadAnns", "coco.has_valid_annotation", "enumerate", "coco.COCODataset.json_category_id_to_contiguous_id.items", "enumerate", "ids.append", "coco.COCODataset.coco.getCatIds"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.has_valid_annotation"], ["    ", "def", "__init__", "(", "\n", "self", ",", "ann_file", ",", "root", ",", "remove_images_without_annotations", ",", "transforms", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", "COCODataset", ",", "self", ")", ".", "__init__", "(", "root", ",", "ann_file", ")", "\n", "# sort indices for reproducible results", "\n", "self", ".", "ids", "=", "sorted", "(", "self", ".", "ids", ")", "\n", "\n", "# filter images without detection annotations", "\n", "if", "remove_images_without_annotations", ":", "\n", "            ", "ids", "=", "[", "]", "\n", "for", "img_id", "in", "self", ".", "ids", ":", "\n", "                ", "ann_ids", "=", "self", ".", "coco", ".", "getAnnIds", "(", "imgIds", "=", "img_id", ",", "iscrowd", "=", "None", ")", "\n", "anno", "=", "self", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "if", "has_valid_annotation", "(", "anno", ")", ":", "\n", "                    ", "ids", ".", "append", "(", "img_id", ")", "\n", "", "", "self", ".", "ids", "=", "ids", "\n", "\n", "", "self", ".", "categories", "=", "{", "cat", "[", "'id'", "]", ":", "cat", "[", "'name'", "]", "for", "cat", "in", "self", ".", "coco", ".", "cats", ".", "values", "(", ")", "}", "\n", "\n", "self", ".", "json_category_id_to_contiguous_id", "=", "{", "\n", "v", ":", "i", "+", "1", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "coco", ".", "getCatIds", "(", ")", ")", "\n", "}", "\n", "self", ".", "contiguous_category_id_to_json_id", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "json_category_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "id_to_img_map", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "enumerate", "(", "self", ".", "ids", ")", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.COCODataset.__getitem__": [[66, 97], ["super().__getitem__", "torch.as_tensor().reshape", "fcos_core.structures.bounding_box.BoxList().convert", "torch.tensor", "target.clip_to_image.clip_to_image.add_field", "fcos_core.structures.segmentation_mask.SegmentationMask", "target.clip_to_image.clip_to_image.add_field", "target.clip_to_image.clip_to_image.clip_to_image", "fcos_core.structures.keypoint.PersonKeypoints", "target.clip_to_image.clip_to_image.add_field", "coco.COCODataset._transforms", "torch.as_tensor", "fcos_core.structures.bounding_box.BoxList"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__getitem__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["self", ".", "_transforms", "=", "transforms", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img", ",", "anno", "=", "super", "(", "COCODataset", ",", "self", ")", ".", "__getitem__", "(", "idx", ")", "\n", "\n", "# filter crowd annotations", "\n", "# TODO might be better to add an extra field", "\n", "anno", "=", "[", "obj", "for", "obj", "in", "anno", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "]", "\n", "\n", "boxes", "=", "[", "obj", "[", "\"bbox\"", "]", "for", "obj", "in", "anno", "]", "\n", "boxes", "=", "torch", ".", "as_tensor", "(", "boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "target", "=", "BoxList", "(", "boxes", ",", "img", ".", "size", ",", "mode", "=", "\"xywh\"", ")", ".", "convert", "(", "\"xyxy\"", ")", "\n", "\n", "classes", "=", "[", "obj", "[", "\"category_id\"", "]", "for", "obj", "in", "anno", "]", "\n", "classes", "=", "[", "self", ".", "json_category_id_to_contiguous_id", "[", "c", "]", "for", "c", "in", "classes", "]", "\n", "classes", "=", "torch", ".", "tensor", "(", "classes", ")", "\n", "target", ".", "add_field", "(", "\"labels\"", ",", "classes", ")", "\n", "\n", "if", "anno", "and", "\"segmentation\"", "in", "anno", "[", "0", "]", ":", "\n", "            ", "masks", "=", "[", "obj", "[", "\"segmentation\"", "]", "for", "obj", "in", "anno", "]", "\n", "masks", "=", "SegmentationMask", "(", "masks", ",", "img", ".", "size", ",", "mode", "=", "'poly'", ")", "\n", "target", ".", "add_field", "(", "\"masks\"", ",", "masks", ")", "\n", "\n", "", "if", "anno", "and", "\"keypoints\"", "in", "anno", "[", "0", "]", ":", "\n", "            ", "keypoints", "=", "[", "obj", "[", "\"keypoints\"", "]", "for", "obj", "in", "anno", "]", "\n", "keypoints", "=", "PersonKeypoints", "(", "keypoints", ",", "img", ".", "size", ")", "\n", "target", ".", "add_field", "(", "\"keypoints\"", ",", "keypoints", ")", "\n", "\n", "", "target", "=", "target", ".", "clip_to_image", "(", "remove_empty", "=", "True", ")", "\n", "\n", "if", "self", ".", "_transforms", "is", "not", "None", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "_transforms", "(", "img", ",", "target", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.COCODataset.get_img_info": [[98, 102], ["None"], "methods", ["None"], ["\n", "", "return", "img", ",", "target", ",", "idx", "\n", "\n", "", "def", "get_img_info", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "id_to_img_map", "[", "index", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._count_visible_keypoints": [[13, 15], ["sum", "sum"], "function", ["None"], ["def", "_count_visible_keypoints", "(", "anno", ")", ":", "\n", "    ", "return", "sum", "(", "sum", "(", "1", "for", "v", "in", "ann", "[", "\"keypoints\"", "]", "[", "2", ":", ":", "3", "]", "if", "v", ">", "0", ")", "for", "ann", "in", "anno", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._has_only_empty_bbox": [[17, 19], ["all", "any"], "function", ["None"], ["", "def", "_has_only_empty_bbox", "(", "anno", ")", ":", "\n", "    ", "return", "all", "(", "any", "(", "o", "<=", "1", "for", "o", "in", "obj", "[", "\"bbox\"", "]", "[", "2", ":", "]", ")", "for", "obj", "in", "anno", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.has_valid_annotation": [[21, 37], ["coco._has_only_empty_bbox", "len", "coco._count_visible_keypoints"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._has_only_empty_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._count_visible_keypoints"], ["", "def", "has_valid_annotation", "(", "anno", ")", ":", "\n", "# if it's empty, there is no annotation", "\n", "    ", "if", "len", "(", "anno", ")", "==", "0", ":", "\n", "        ", "return", "False", "\n", "# if all boxes have close to zero area, there is no annotation", "\n", "", "if", "_has_only_empty_bbox", "(", "anno", ")", ":", "\n", "        ", "return", "False", "\n", "# keypoints task have a slight different critera for considering", "\n", "# if an annotation is valid", "\n", "", "if", "\"keypoints\"", "not", "in", "anno", "[", "0", "]", ":", "\n", "        ", "return", "True", "\n", "# for keypoint detection tasks, only consider valid images those", "\n", "# containing at least min_keypoints_per_image", "\n", "", "if", "_count_visible_keypoints", "(", "anno", ")", ">=", "min_keypoints_per_image", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset.__init__": [[20, 88], ["os.path.abspath", "os.path.abspath", "os.path.exists", "os.path.exists", "cityscapes.CityScapesDataset.initMaps", "int", "os.path.join", "sorted", "sorted", "os.path.join", "os.path.join", "glob.glob", "os.path.join", "glob.glob", "len", "len", "os.path.join", "NotImplementedError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.abstract.AbstractDataset.initMaps"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "img_dir", ",", "\n", "ann_dir", ",", "\n", "split", ",", "\n", "mode", "=", "\"mask\"", ",", "\n", "transforms", "=", "None", ",", "\n", "min_area", "=", "0", ",", "\n", "mini", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            img_dir: /path/to/leftImg8bit/      has to contain {train,val,test}\n            ann_dir: /path/to/gtFine/           has to contain {train,val,test}\n            split: \"train\" or \"val\" or \"test\"\n            mode: \"poly\" or \"mask\", which annotation format to use\n            transforms: apply transformations to input/annotation\n            min_area: exclude intances below a specific area (bbox area)\n            mini: limit the size of the dataset, so len(dataset) == mini for\n                debugging purposes\n        \"\"\"", "\n", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "\n", "img_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "img_dir", ",", "split", ")", ")", "\n", "ann_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "split", ")", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "img_dir", ")", ",", "img_dir", "\n", "assert", "os", ".", "path", ".", "exists", "(", "ann_dir", ")", ",", "ann_dr", "\n", "\n", "self", ".", "ann_dir", "=", "ann_dir", "\n", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "CLASSES", "=", "[", "\"__background__\"", "]", "\n", "self", ".", "CLASSES", "+=", "[", "l", ".", "name", "for", "l", "in", "csHelpers", ".", "labels", "if", "l", ".", "hasInstances", "]", "\n", "\n", "# Adds name_to_id and id_to_name mapping", "\n", "self", ".", "initMaps", "(", ")", "\n", "\n", "# This is required for parsing binary masks", "\n", "self", ".", "cityscapesID_to_ind", "=", "{", "\n", "l", ".", "id", ":", "self", ".", "name_to_id", "[", "l", ".", "name", "]", "for", "l", "in", "csHelpers", ".", "labels", "if", "l", ".", "hasInstances", "\n", "}", "\n", "\n", "self", ".", "transforms", "=", "transforms", "\n", "self", ".", "min_area", "=", "int", "(", "min_area", ")", "\n", "\n", "img_pattern", "=", "os", ".", "path", ".", "join", "(", "img_dir", ",", "\"*\"", ",", "\"*_leftImg8bit.png\"", ")", "\n", "img_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "img_pattern", ")", ")", "\n", "\n", "if", "mode", "==", "\"mask\"", ":", "\n", "            ", "ann_pattern", "=", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "\"*\"", ",", "\"*_instanceIds.png\"", ")", "\n", "", "elif", "mode", "==", "\"poly\"", ":", "\n", "            ", "ann_pattern", "=", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "\"*\"", ",", "\"*_polygons.json\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Mode is not implemented yet: %s\"", "%", "mode", ")", "\n", "\n", "", "self", ".", "mode", "=", "mode", "\n", "ann_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "ann_pattern", ")", ")", "\n", "\n", "if", "mini", "is", "not", "None", ":", "\n", "# Keep the mini dataset diverse by setting the stride", "\n", "            ", "img_paths", "=", "img_paths", "[", ":", ":", "len", "(", "img_paths", ")", "//", "mini", "+", "1", "]", "\n", "ann_paths", "=", "ann_paths", "[", ":", ":", "len", "(", "ann_paths", ")", "//", "mini", "+", "1", "]", "\n", "\n", "", "assert", "len", "(", "img_paths", ")", "==", "len", "(", "ann_paths", ")", "\n", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "ann_paths", "=", "ann_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset.__getitem__": [[89, 125], ["cityscapes.CityScapesDataset._filterGT", "PIL.Image.open", "maskrcnn_benchmark.structures.bounding_box.BoxList", "maskrcnn_benchmark.structures.bounding_box.BoxList.add_field", "maskrcnn_benchmark.structures.segmentation_mask.SegmentationMask", "maskrcnn_benchmark.structures.bounding_box.BoxList.add_field", "torch.from_numpy", "cityscapes.CityScapesDataset._processBinayMasks", "cityscapes.CityScapesDataset._processPolygons", "len", "print", "torch.tensor", "cityscapes.CityScapesDataset.transforms", "numpy.asarray", "open", "json.load", "cityscapes.CityScapesDataset.get_img_info", "PIL.Image.open", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset._filterGT", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset._processBinayMasks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset._processPolygons", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_path", "=", "self", ".", "img_paths", "[", "idx", "]", "\n", "ann_path", "=", "self", ".", "ann_paths", "[", "idx", "]", "\n", "\n", "if", "self", ".", "mode", "==", "\"mask\"", ":", "\n", "            ", "ann", "=", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "Image", ".", "open", "(", "ann_path", ")", ")", ")", "\n", "# masks are represented with tensors", "\n", "boxes", ",", "segmentations", ",", "labels", "=", "self", ".", "_processBinayMasks", "(", "ann", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "ann_path", ",", "\"r\"", ")", "as", "ann_file", ":", "\n", "                ", "ann", "=", "json", ".", "load", "(", "ann_file", ")", "\n", "# masks are represented with polygons", "\n", "", "boxes", ",", "segmentations", ",", "labels", "=", "self", ".", "_processPolygons", "(", "ann", ")", "\n", "\n", "", "boxes", ",", "segmentations", ",", "labels", "=", "self", ".", "_filterGT", "(", "boxes", ",", "segmentations", ",", "labels", ")", "\n", "\n", "if", "len", "(", "segmentations", ")", "==", "0", ":", "\n", "            ", "empty_ann_path", "=", "self", ".", "get_img_info", "(", "idx", ")", "[", "\"ann_path\"", "]", "\n", "print", "(", "\"EMPTY ENTRY:\"", ",", "empty_ann_path", ")", "\n", "# self.img_paths.pop(idx)", "\n", "# self.ann_paths.pop(idx)", "\n", "img", ",", "target", ",", "_", "=", "self", "[", "(", "idx", "+", "1", ")", "%", "len", "(", "self", ")", "]", "\n", "\n", "# just override this image with the next", "\n", "return", "img", ",", "target", ",", "idx", "\n", "\n", "", "img", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "# Compose all into a BoxList instance", "\n", "target", "=", "BoxList", "(", "boxes", ",", "img", ".", "size", ",", "mode", "=", "\"xyxy\"", ")", "\n", "target", ".", "add_field", "(", "\"labels\"", ",", "torch", ".", "tensor", "(", "labels", ")", ")", "\n", "masks", "=", "SegmentationMask", "(", "segmentations", ",", "img", ".", "size", ",", "mode", "=", "self", ".", "mode", ")", "\n", "target", ".", "add_field", "(", "\"masks\"", ",", "masks", ")", "\n", "if", "self", ".", "transforms", "is", "not", "None", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "transforms", "(", "img", ",", "target", ")", "\n", "\n", "", "return", "img", ",", "target", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset._filterGT": [[126, 146], ["zip", "len", "len", "len", "torch.empty.append", "filtered_segmentations.append", "filtered_labels.append", "len", "torch.empty"], "methods", ["None"], ["", "def", "_filterGT", "(", "self", ",", "boxes", ",", "segmentations", ",", "labels", ")", ":", "\n", "        ", "filtered_boxes", "=", "[", "]", "\n", "filtered_segmentations", "=", "[", "]", "\n", "filtered_labels", "=", "[", "]", "\n", "assert", "len", "(", "segmentations", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "boxes", ")", "\n", "\n", "for", "box", ",", "segmentation", ",", "label", "in", "zip", "(", "boxes", ",", "segmentations", ",", "labels", ")", ":", "\n", "            ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "box", "\n", "area", "=", "(", "xmax", "-", "xmin", ")", "*", "(", "ymax", "-", "ymin", ")", "\n", "if", "area", "<", "self", ".", "min_area", ":", "\n", "                ", "continue", "\n", "\n", "", "filtered_boxes", ".", "append", "(", "box", ")", "\n", "filtered_segmentations", ".", "append", "(", "segmentation", ")", "\n", "filtered_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "if", "len", "(", "filtered_boxes", ")", "<", "1", ":", "\n", "            ", "filtered_boxes", "=", "torch", ".", "empty", "(", "0", ",", "4", ")", "\n", "\n", "", "return", "filtered_boxes", ",", "filtered_segmentations", ",", "filtered_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset._processPolygons": [[147, 190], ["int", "int", "int", "int", "cityscapes.CityScapesDataset._processPolygons.poly_to_tight_box"], "methods", ["None"], ["", "def", "_processPolygons", "(", "self", ",", "ann", ")", ":", "\n", "# For a single object polygon annotations are stored in CityScapes like", "\n", "# [[x1, y1], [x2, y2]...] and we need them in the following format:", "\n", "# [x1, y1, x2, y2, x3, y3 ...]", "\n", "        ", "polys", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "boxes", "=", "[", "]", "\n", "\n", "def", "poly_to_tight_box", "(", "poly", ")", ":", "\n", "            ", "xmin", "=", "int", "(", "min", "(", "poly", "[", ":", ":", "2", "]", ")", ")", "\n", "ymin", "=", "int", "(", "min", "(", "poly", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "xmax", "=", "int", "(", "max", "(", "poly", "[", ":", ":", "2", "]", ")", ")", "\n", "ymax", "=", "int", "(", "max", "(", "poly", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "bbox", "=", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "return", "bbox", "\n", "\n", "", "for", "inst", "in", "ann", "[", "\"objects\"", "]", ":", "\n", "            ", "label", "=", "inst", "[", "\"label\"", "]", "\n", "if", "label", "not", "in", "self", ".", "CLASSES", ":", "\n", "                ", "continue", "\n", "\n", "", "label", "=", "self", ".", "name_to_id", "[", "label", "]", "\n", "\n", "cityscapes_poly", "=", "inst", "[", "\"polygon\"", "]", "\n", "poly", "=", "[", "]", "\n", "for", "xy", "in", "cityscapes_poly", ":", "\n", "# Equivalent with `poly += xy` but this is more verbose", "\n", "                ", "x", "=", "xy", "[", "0", "]", "\n", "y", "=", "xy", "[", "1", "]", "\n", "poly", ".", "append", "(", "x", ")", "\n", "poly", ".", "append", "(", "y", ")", "\n", "\n", "# In CityScapes instances are described with single polygons only", "\n", "", "box", "=", "poly_to_tight_box", "(", "poly", ")", "\n", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "polys", ".", "append", "(", "[", "poly", "]", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "if", "len", "(", "boxes", ")", "<", "1", ":", "\n", "            ", "boxes", "=", "torch", ".", "empty", "(", "0", ",", "4", ")", "\n", "\n", "", "return", "boxes", ",", "polys", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset._processBinayMasks": [[191, 223], ["mask.nonzero", "list", "torch.sort", "int", "cityscapes.CityScapesDataset._processBinayMasks.mask_to_tight_box"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "_processBinayMasks", "(", "self", ",", "ann", ")", ":", "\n", "        ", "boxes", "=", "[", "]", "\n", "masks", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "def", "mask_to_tight_box", "(", "mask", ")", ":", "\n", "            ", "a", "=", "mask", ".", "nonzero", "(", ")", "\n", "bbox", "=", "[", "\n", "torch", ".", "min", "(", "a", "[", ":", ",", "1", "]", ")", ",", "\n", "torch", ".", "min", "(", "a", "[", ":", ",", "0", "]", ")", ",", "\n", "torch", ".", "max", "(", "a", "[", ":", ",", "1", "]", ")", ",", "\n", "torch", ".", "max", "(", "a", "[", ":", ",", "0", "]", ")", ",", "\n", "]", "\n", "bbox", "=", "list", "(", "map", "(", "int", ",", "bbox", ")", ")", "\n", "return", "bbox", "# xmin, ymin, xmax, ymax", "\n", "\n", "# Sort for consistent order between instances as the polygon annotation", "\n", "", "instIds", "=", "torch", ".", "sort", "(", "torch", ".", "unique", "(", "ann", ")", ")", "[", "0", "]", "\n", "for", "instId", "in", "instIds", ":", "\n", "            ", "if", "instId", "<", "1000", ":", "# group labels", "\n", "                ", "continue", "\n", "\n", "", "mask", "=", "ann", "==", "instId", "\n", "label", "=", "int", "(", "instId", "/", "1000", ")", "\n", "label", "=", "self", ".", "cityscapesID_to_ind", "[", "label", "]", "\n", "box", "=", "mask_to_tight_box", "(", "mask", ")", "\n", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "return", "boxes", ",", "masks", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset.__len__": [[224, 226], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.CityScapesDataset.get_img_info": [[227, 236], ["None"], "methods", ["None"], ["", "def", "get_img_info", "(", "self", ",", "index", ")", ":", "\n", "# Reverse engineered from voc.py", "\n", "# All the images have the same size", "\n", "        ", "return", "{", "\n", "\"height\"", ":", "1024", ",", "\n", "\"width\"", ":", "2048", ",", "\n", "\"idx\"", ":", "index", ",", "\n", "\"img_path\"", ":", "self", ".", "img_paths", "[", "index", "]", ",", "\n", "\"ann_path\"", ":", "self", ".", "ann_paths", "[", "index", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.abstract.AbstractDataset.__init__": [[30, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "name_to_id", "=", "None", "\n", "self", ".", "id_to_name", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.abstract.AbstractDataset.__getitem__": [[35, 37], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.abstract.AbstractDataset.initMaps": [[39, 61], ["isinstance", "dict", "dict", "zip", "zip", "range", "range", "len", "len"], "methods", ["None"], ["", "def", "initMaps", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Can be called optionally to initialize the id<->category name mapping\n\n\n        Initialize default mapping between:\n            class <==> index\n        class: this is a string that represents the class\n        index: positive int, used directly by the ROI heads.\n\n\n        NOTE:\n            make sure that the background is always indexed by 0.\n            \"__background__\" <==> 0\n\n            if initialized by hand, double check that the indexing is correct.\n        \"\"\"", "\n", "assert", "isinstance", "(", "self", ".", "CLASSES", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "self", ".", "CLASSES", "[", "0", "]", "==", "\"__background__\"", "\n", "cls", "=", "self", ".", "CLASSES", "\n", "self", ".", "name_to_id", "=", "dict", "(", "zip", "(", "cls", ",", "range", "(", "len", "(", "cls", ")", ")", ")", ")", "\n", "self", ".", "id_to_name", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "cls", ")", ")", ",", "cls", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.abstract.AbstractDataset.get_img_info": [[63, 65], ["None"], "methods", ["None"], ["", "def", "get_img_info", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.abstract.AbstractDataset.__len__": [[67, 69], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.list_dataset.ListDataset.__init__": [[12, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "image_lists", ",", "transforms", "=", "None", ")", ":", "\n", "        ", "self", ".", "image_lists", "=", "image_lists", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.list_dataset.ListDataset.__getitem__": [[16, 27], ["PIL.Image.open().convert", "fcos_core.structures.bounding_box.BoxList", "list_dataset.ListDataset.transforms", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "self", ".", "image_lists", "[", "item", "]", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "# dummy target", "\n", "w", ",", "h", "=", "img", ".", "size", "\n", "target", "=", "BoxList", "(", "[", "[", "0", ",", "0", ",", "w", ",", "h", "]", "]", ",", "img", ".", "size", ",", "mode", "=", "\"xyxy\"", ")", "\n", "\n", "if", "self", ".", "transforms", "is", "not", "None", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "transforms", "(", "img", ",", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.list_dataset.ListDataset.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_lists", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.list_dataset.ListDataset.get_img_info": [[31, 37], ["None"], "methods", ["None"], ["", "def", "get_img_info", "(", "self", ",", "item", ")", ":", "\n", "        ", "\"\"\"\n        Return the image dimensions for the image, without\n        loading and pre-processing it\n        \"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.concat_dataset.ConcatDataset.get_idxs": [[13, 20], ["bisect.bisect_right"], "methods", ["None"], ["def", "get_idxs", "(", "self", ",", "idx", ")", ":", "\n", "        ", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "idx", ")", "\n", "if", "dataset_idx", "==", "0", ":", "\n", "            ", "sample_idx", "=", "idx", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "idx", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "", "return", "dataset_idx", ",", "sample_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.concat_dataset.ConcatDataset.get_img_info": [[21, 24], ["concat_dataset.ConcatDataset.get_idxs", "concat_dataset.ConcatDataset.datasets[].get_img_info"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.concat_dataset.ConcatDataset.get_idxs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info"], ["", "def", "get_img_info", "(", "self", ",", "idx", ")", ":", "\n", "        ", "dataset_idx", ",", "sample_idx", "=", "self", ".", "get_idxs", "(", "idx", ")", "\n", "return", "self", ".", "datasets", "[", "dataset_idx", "]", ".", "get_img_info", "(", "sample_idx", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.__init__": [[43, 60], ["os.path.join", "os.path.join", "os.path.join", "dict", "open", "f.readlines", "x.strip", "zip", "enumerate", "range", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "split", ",", "use_difficult", "=", "False", ",", "transforms", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "data_dir", "\n", "self", ".", "image_set", "=", "split", "\n", "self", ".", "keep_difficult", "=", "use_difficult", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n", "self", ".", "_annopath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"Annotations\"", ",", "\"%s.xml\"", ")", "\n", "self", ".", "_imgpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"JPEGImages\"", ",", "\"%s.jpg\"", ")", "\n", "self", ".", "_imgsetpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"ImageSets\"", ",", "\"Main\"", ",", "\"%s.txt\"", ")", "\n", "\n", "with", "open", "(", "self", ".", "_imgsetpath", "%", "self", ".", "image_set", ")", "as", "f", ":", "\n", "            ", "self", ".", "ids", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "ids", "=", "[", "x", ".", "strip", "(", "\"\\n\"", ")", "for", "x", "in", "self", ".", "ids", "]", "\n", "self", ".", "id_to_img_map", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "enumerate", "(", "self", ".", "ids", ")", "}", "\n", "\n", "cls", "=", "PascalVOCDataset", ".", "CLASSES", "\n", "self", ".", "class_to_ind", "=", "dict", "(", "zip", "(", "cls", ",", "range", "(", "len", "(", "cls", ")", ")", ")", ")", "\n", "self", ".", "categories", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "cls", ")", ")", ",", "cls", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.__getitem__": [[61, 72], ["PIL.Image.open().convert", "voc.PascalVOCDataset.get_groundtruth", "target.clip_to_image.clip_to_image.clip_to_image", "voc.PascalVOCDataset.transforms", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_groundtruth", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.clip_to_image"], ["\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "self", ".", "_imgpath", "%", "img_id", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "target", "=", "self", ".", "get_groundtruth", "(", "index", ")", "\n", "target", "=", "target", ".", "clip_to_image", "(", "remove_empty", "=", "True", ")", "\n", "\n", "if", "self", ".", "transforms", "is", "not", "None", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "transforms", "(", "img", ",", "target", ")", "\n", "\n", "", "return", "img", ",", "target", ",", "index", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.__len__": [[73, 75], ["len"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_groundtruth": [[76, 86], ["ET.parse().getroot", "voc.PascalVOCDataset._preprocess_annotation", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.bounding_box.BoxList.add_field", "fcos_core.structures.bounding_box.BoxList.add_field", "ET.parse"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset._preprocess_annotation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.add_field"], ["\n", "", "def", "get_groundtruth", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "anno", "=", "ET", ".", "parse", "(", "self", ".", "_annopath", "%", "img_id", ")", ".", "getroot", "(", ")", "\n", "anno", "=", "self", ".", "_preprocess_annotation", "(", "anno", ")", "\n", "\n", "height", ",", "width", "=", "anno", "[", "\"im_info\"", "]", "\n", "target", "=", "BoxList", "(", "anno", "[", "\"boxes\"", "]", ",", "(", "width", ",", "height", ")", ",", "mode", "=", "\"xyxy\"", ")", "\n", "target", ".", "add_field", "(", "\"labels\"", ",", "anno", "[", "\"labels\"", "]", ")", "\n", "target", ".", "add_field", "(", "\"difficult\"", ",", "anno", "[", "\"difficult\"", "]", ")", "\n", "return", "target", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset._preprocess_annotation": [[87, 125], ["target.iter", "target.find", "tuple", "obj.find().text.lower().strip", "obj.find", "tuple", "boxes.append", "gt_classes.append", "difficult_boxes.append", "map", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "int", "map", "obj.find().text.lower", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find", "list", "obj.find", "map", "target.find.find", "target.find.find", "obj.find"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["\n", "", "def", "_preprocess_annotation", "(", "self", ",", "target", ")", ":", "\n", "        ", "boxes", "=", "[", "]", "\n", "gt_classes", "=", "[", "]", "\n", "difficult_boxes", "=", "[", "]", "\n", "TO_REMOVE", "=", "1", "\n", "\n", "for", "obj", "in", "target", ".", "iter", "(", "\"object\"", ")", ":", "\n", "            ", "difficult", "=", "int", "(", "obj", ".", "find", "(", "\"difficult\"", ")", ".", "text", ")", "==", "1", "\n", "if", "not", "self", ".", "keep_difficult", "and", "difficult", ":", "\n", "                ", "continue", "\n", "", "name", "=", "obj", ".", "find", "(", "\"name\"", ")", ".", "text", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "bb", "=", "obj", ".", "find", "(", "\"bndbox\"", ")", "\n", "# Make pixel indexes 0-based", "\n", "# Refer to \"https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/pascal_voc.py#L208-L211\"", "\n", "box", "=", "[", "\n", "bb", ".", "find", "(", "\"xmin\"", ")", ".", "text", ",", "\n", "bb", ".", "find", "(", "\"ymin\"", ")", ".", "text", ",", "\n", "bb", ".", "find", "(", "\"xmax\"", ")", ".", "text", ",", "\n", "bb", ".", "find", "(", "\"ymax\"", ")", ".", "text", ",", "\n", "]", "\n", "bndbox", "=", "tuple", "(", "\n", "map", "(", "lambda", "x", ":", "x", "-", "TO_REMOVE", ",", "list", "(", "map", "(", "int", ",", "box", ")", ")", ")", "\n", ")", "\n", "\n", "boxes", ".", "append", "(", "bndbox", ")", "\n", "gt_classes", ".", "append", "(", "self", ".", "class_to_ind", "[", "name", "]", ")", "\n", "difficult_boxes", ".", "append", "(", "difficult", ")", "\n", "\n", "", "size", "=", "target", ".", "find", "(", "\"size\"", ")", "\n", "im_info", "=", "tuple", "(", "map", "(", "int", ",", "(", "size", ".", "find", "(", "\"height\"", ")", ".", "text", ",", "size", ".", "find", "(", "\"width\"", ")", ".", "text", ")", ")", ")", "\n", "\n", "res", "=", "{", "\n", "\"boxes\"", ":", "torch", ".", "tensor", "(", "boxes", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "\"labels\"", ":", "torch", ".", "tensor", "(", "gt_classes", ")", ",", "\n", "\"difficult\"", ":", "torch", ".", "tensor", "(", "difficult_boxes", ")", ",", "\n", "\"im_info\"", ":", "im_info", ",", "\n", "}", "\n", "return", "res", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info": [[126, 132], ["ET.parse().getroot", "ET.parse().getroot.find", "tuple", "map", "ET.parse", "ET.parse().getroot.find.find", "ET.parse().getroot.find.find"], "methods", ["None"], ["\n", "", "def", "get_img_info", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "anno", "=", "ET", ".", "parse", "(", "self", ".", "_annopath", "%", "img_id", ")", ".", "getroot", "(", ")", "\n", "size", "=", "anno", ".", "find", "(", "\"size\"", ")", "\n", "im_info", "=", "tuple", "(", "map", "(", "int", ",", "(", "size", ".", "find", "(", "\"height\"", ")", ".", "text", ",", "size", ".", "find", "(", "\"width\"", ")", ".", "text", ")", ")", ")", "\n", "return", "{", "\"height\"", ":", "im_info", "[", "0", "]", ",", "\"width\"", ":", "im_info", "[", "1", "]", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.map_class_id_to_class_name": [[133, 135], ["None"], "methods", ["None"], ["\n", "", "def", "map_class_id_to_class_name", "(", "self", ",", "class_id", ")", ":", "\n", "        ", "return", "PascalVOCDataset", ".", "CLASSES", "[", "class_id", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.prepare_ade20k_sem_seg.convert": [[11, 16], ["numpy.asarray", "PIL.Image.fromarray().save", "PIL.Image.open", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["def", "convert", "(", "input", ",", "output", ")", ":", "\n", "    ", "img", "=", "np", ".", "asarray", "(", "Image", ".", "open", "(", "input", ")", ")", "\n", "assert", "img", ".", "dtype", "==", "np", ".", "uint8", "\n", "img", "=", "img", "-", "1", "# 0 (ignore) becomes 255. others are shifted by 1", "\n", "Image", ".", "fromarray", "(", "img", ")", ".", "save", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.prepare_cocofied_lvis.cocofy_lvis": [[96, 167], ["json.load.pop", "copy.deepcopy", "set", "collections.defaultdict", "set", "print", "open", "json.load", "synset_to_coco_cat_id.keys", "copy.deepcopy", "new_annos.append", "set.keys", "copy.deepcopy", "new_categories.append", "open", "json.dump", "new_category_list.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["def", "cocofy_lvis", "(", "input_filename", ",", "output_filename", ")", ":", "\n", "    ", "\"\"\"\n    Filter LVIS instance segmentation annotations to remove all categories that are not included in\n    COCO. The new json files can be used to evaluate COCO AP using `lvis-api`. The category ids in\n    the output json are the incontiguous COCO dataset ids.\n\n    Args:\n        input_filename (str): path to the LVIS json file.\n        output_filename (str): path to the COCOfied json file.\n    \"\"\"", "\n", "\n", "with", "open", "(", "input_filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lvis_json", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "lvis_annos", "=", "lvis_json", ".", "pop", "(", "\"annotations\"", ")", "\n", "cocofied_lvis", "=", "copy", ".", "deepcopy", "(", "lvis_json", ")", "\n", "lvis_json", "[", "\"annotations\"", "]", "=", "lvis_annos", "\n", "\n", "# Mapping from lvis cat id to coco cat id via synset", "\n", "lvis_cat_id_to_synset", "=", "{", "cat", "[", "\"id\"", "]", ":", "cat", "[", "\"synset\"", "]", "for", "cat", "in", "lvis_json", "[", "\"categories\"", "]", "}", "\n", "synset_to_coco_cat_id", "=", "{", "x", "[", "\"synset\"", "]", ":", "x", "[", "\"coco_cat_id\"", "]", "for", "x", "in", "COCO_SYNSET_CATEGORIES", "}", "\n", "# Synsets that we will keep in the dataset", "\n", "synsets_to_keep", "=", "set", "(", "synset_to_coco_cat_id", ".", "keys", "(", ")", ")", "\n", "coco_cat_id_with_instances", "=", "defaultdict", "(", "int", ")", "\n", "\n", "new_annos", "=", "[", "]", "\n", "ann_id", "=", "1", "\n", "for", "ann", "in", "lvis_annos", ":", "\n", "        ", "lvis_cat_id", "=", "ann", "[", "\"category_id\"", "]", "\n", "synset", "=", "lvis_cat_id_to_synset", "[", "lvis_cat_id", "]", "\n", "if", "synset", "not", "in", "synsets_to_keep", ":", "\n", "            ", "continue", "\n", "", "coco_cat_id", "=", "synset_to_coco_cat_id", "[", "synset", "]", "\n", "new_ann", "=", "copy", ".", "deepcopy", "(", "ann", ")", "\n", "new_ann", "[", "\"category_id\"", "]", "=", "coco_cat_id", "\n", "new_ann", "[", "\"id\"", "]", "=", "ann_id", "\n", "ann_id", "+=", "1", "\n", "new_annos", ".", "append", "(", "new_ann", ")", "\n", "coco_cat_id_with_instances", "[", "coco_cat_id", "]", "+=", "1", "\n", "", "cocofied_lvis", "[", "\"annotations\"", "]", "=", "new_annos", "\n", "\n", "for", "image", "in", "cocofied_lvis", "[", "\"images\"", "]", ":", "\n", "        ", "for", "key", "in", "[", "\"not_exhaustive_category_ids\"", ",", "\"neg_category_ids\"", "]", ":", "\n", "            ", "new_category_list", "=", "[", "]", "\n", "for", "lvis_cat_id", "in", "image", "[", "key", "]", ":", "\n", "                ", "synset", "=", "lvis_cat_id_to_synset", "[", "lvis_cat_id", "]", "\n", "if", "synset", "not", "in", "synsets_to_keep", ":", "\n", "                    ", "continue", "\n", "", "coco_cat_id", "=", "synset_to_coco_cat_id", "[", "synset", "]", "\n", "new_category_list", ".", "append", "(", "coco_cat_id", ")", "\n", "coco_cat_id_with_instances", "[", "coco_cat_id", "]", "+=", "1", "\n", "", "image", "[", "key", "]", "=", "new_category_list", "\n", "\n", "", "", "coco_cat_id_with_instances", "=", "set", "(", "coco_cat_id_with_instances", ".", "keys", "(", ")", ")", "\n", "\n", "new_categories", "=", "[", "]", "\n", "for", "cat", "in", "lvis_json", "[", "\"categories\"", "]", ":", "\n", "        ", "synset", "=", "cat", "[", "\"synset\"", "]", "\n", "if", "synset", "not", "in", "synsets_to_keep", ":", "\n", "            ", "continue", "\n", "", "coco_cat_id", "=", "synset_to_coco_cat_id", "[", "synset", "]", "\n", "if", "coco_cat_id", "not", "in", "coco_cat_id_with_instances", ":", "\n", "            ", "continue", "\n", "", "new_cat", "=", "copy", ".", "deepcopy", "(", "cat", ")", "\n", "new_cat", "[", "\"id\"", "]", "=", "coco_cat_id", "\n", "new_categories", ".", "append", "(", "new_cat", ")", "\n", "", "cocofied_lvis", "[", "\"categories\"", "]", "=", "new_categories", "\n", "\n", "with", "open", "(", "output_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "cocofied_lvis", ",", "f", ")", "\n", "", "print", "(", "\"{} is COCOfied and stored in {}.\"", ".", "format", "(", "input_filename", ",", "output_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.prepare_panoptic_fpn._process_panoptic_to_semantic": [[18, 27], ["numpy.asarray", "panopticapi.utils.rgb2id", "PIL.Image.fromarray().save", "PIL.Image.open", "numpy.zeros_like", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["def", "_process_panoptic_to_semantic", "(", "input_panoptic", ",", "output_semantic", ",", "segments", ",", "id_map", ")", ":", "\n", "    ", "panoptic", "=", "np", ".", "asarray", "(", "Image", ".", "open", "(", "input_panoptic", ")", ",", "dtype", "=", "np", ".", "uint32", ")", "\n", "panoptic", "=", "rgb2id", "(", "panoptic", ")", "\n", "output", "=", "np", ".", "zeros_like", "(", "panoptic", ",", "dtype", "=", "np", ".", "uint8", ")", "+", "255", "\n", "for", "seg", "in", "segments", ":", "\n", "        ", "cat_id", "=", "seg", "[", "\"category_id\"", "]", "\n", "new_cat_id", "=", "id_map", "[", "cat_id", "]", "\n", "output", "[", "panoptic", "==", "seg", "[", "\"id\"", "]", "]", "=", "new_cat_id", "\n", "", "Image", ".", "fromarray", "(", "output", ")", ".", "save", "(", "output_semantic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.prepare_panoptic_fpn.separate_coco_semantic_from_panoptic": [[29, 78], ["os.makedirs", "enumerate", "multiprocessing.Pool", "print", "time.time", "mp.Pool.starmap", "print", "len", "open", "json.load", "functools.partial", "prepare_panoptic_fpn.separate_coco_semantic_from_panoptic.iter_annotations"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "separate_coco_semantic_from_panoptic", "(", "panoptic_json", ",", "panoptic_root", ",", "sem_seg_root", ",", "categories", ")", ":", "\n", "    ", "\"\"\"\n    Create semantic segmentation annotations from panoptic segmentation\n    annotations, to be used by PanopticFPN.\n\n    It maps all thing categories to class 0, and maps all unlabeled pixels to class 255.\n    It maps all stuff categories to contiguous ids starting from 1.\n\n    Args:\n        panoptic_json (str): path to the panoptic json file, in COCO's format.\n        panoptic_root (str): a directory with panoptic annotation files, in COCO's format.\n        sem_seg_root (str): a directory to output semantic annotation files\n        categories (list[dict]): category metadata. Each dict needs to have:\n            \"id\": corresponds to the \"category_id\" in the json annotations\n            \"isthing\": 0 or 1\n    \"\"\"", "\n", "os", ".", "makedirs", "(", "sem_seg_root", ",", "exist_ok", "=", "True", ")", "\n", "\n", "stuff_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "categories", "if", "k", "[", "\"isthing\"", "]", "==", "0", "]", "\n", "thing_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "categories", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "id_map", "=", "{", "}", "# map from category id to id in the output semantic annotation", "\n", "assert", "len", "(", "stuff_ids", ")", "<=", "254", "\n", "for", "i", ",", "stuff_id", "in", "enumerate", "(", "stuff_ids", ")", ":", "\n", "        ", "id_map", "[", "stuff_id", "]", "=", "i", "+", "1", "\n", "", "for", "thing_id", "in", "thing_ids", ":", "\n", "        ", "id_map", "[", "thing_id", "]", "=", "0", "\n", "", "id_map", "[", "0", "]", "=", "255", "\n", "\n", "with", "open", "(", "panoptic_json", ")", "as", "f", ":", "\n", "        ", "obj", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "pool", "=", "mp", ".", "Pool", "(", "processes", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "//", "2", ",", "4", ")", ")", "\n", "\n", "def", "iter_annotations", "(", ")", ":", "\n", "        ", "for", "anno", "in", "obj", "[", "\"annotations\"", "]", ":", "\n", "            ", "file_name", "=", "anno", "[", "\"file_name\"", "]", "\n", "segments", "=", "anno", "[", "\"segments_info\"", "]", "\n", "input", "=", "os", ".", "path", ".", "join", "(", "panoptic_root", ",", "file_name", ")", "\n", "output", "=", "os", ".", "path", ".", "join", "(", "sem_seg_root", ",", "file_name", ")", "\n", "yield", "input", ",", "output", ",", "segments", "\n", "\n", "", "", "print", "(", "\"Start writing to {} ...\"", ".", "format", "(", "sem_seg_root", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "pool", ".", "starmap", "(", "\n", "functools", ".", "partial", "(", "_process_panoptic_to_semantic", ",", "id_map", "=", "id_map", ")", ",", "\n", "iter_annotations", "(", ")", ",", "\n", "chunksize", "=", "100", ",", "\n", ")", "\n", "print", "(", "\"Finished. time: {:.2f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes_panoptic.get_cityscapes_panoptic_files": [[18, 49], ["detectron2.utils.file_io.PathManager.ls", "logger.info", "len", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.isfile", "os.path.join", "detectron2.utils.file_io.PathManager.ls", "image_dict.get", "os.path.join", "files.append", "os.path.join", "basename.endswith", "len", "os.path.basename", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "get_cityscapes_panoptic_files", "(", "image_dir", ",", "gt_dir", ",", "json_info", ")", ":", "\n", "    ", "files", "=", "[", "]", "\n", "# scan through the directory", "\n", "cities", "=", "PathManager", ".", "ls", "(", "image_dir", ")", "\n", "logger", ".", "info", "(", "f\"{len(cities)} cities found in '{image_dir}'.\"", ")", "\n", "image_dict", "=", "{", "}", "\n", "for", "city", "in", "cities", ":", "\n", "        ", "city_img_dir", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "city", ")", "\n", "for", "basename", "in", "PathManager", ".", "ls", "(", "city_img_dir", ")", ":", "\n", "            ", "image_file", "=", "os", ".", "path", ".", "join", "(", "city_img_dir", ",", "basename", ")", "\n", "\n", "suffix", "=", "\"_leftImg8bit.png\"", "\n", "assert", "basename", ".", "endswith", "(", "suffix", ")", ",", "basename", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "basename", ")", "[", ":", "-", "len", "(", "suffix", ")", "]", "\n", "\n", "image_dict", "[", "basename", "]", "=", "image_file", "\n", "\n", "", "", "for", "ann", "in", "json_info", "[", "\"annotations\"", "]", ":", "\n", "        ", "image_file", "=", "image_dict", ".", "get", "(", "ann", "[", "\"image_id\"", "]", ",", "None", ")", "\n", "assert", "image_file", "is", "not", "None", ",", "\"No image {} found for annotation {}\"", ".", "format", "(", "\n", "ann", "[", "\"image_id\"", "]", ",", "ann", "[", "\"file_name\"", "]", "\n", ")", "\n", "label_file", "=", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "ann", "[", "\"file_name\"", "]", ")", "\n", "segments_info", "=", "ann", "[", "\"segments_info\"", "]", "\n", "\n", "files", ".", "append", "(", "(", "image_file", ",", "label_file", ",", "segments_info", ")", ")", "\n", "\n", "", "assert", "len", "(", "files", ")", ",", "\"No images found in {}\"", ".", "format", "(", "image_dir", ")", "\n", "assert", "PathManager", ".", "isfile", "(", "files", "[", "0", "]", "[", "0", "]", ")", ",", "files", "[", "0", "]", "[", "0", "]", "\n", "assert", "PathManager", ".", "isfile", "(", "files", "[", "0", "]", "[", "1", "]", ")", ",", "files", "[", "0", "]", "[", "1", "]", "\n", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes_panoptic.load_cityscapes_panoptic": [[51, 110], ["os.path.exists", "cityscapes_panoptic.get_cityscapes_panoptic_files", "len", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.isfile", "open", "json.load", "ret.append", "cityscapes_panoptic.load_cityscapes_panoptic._convert_category_id"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes_panoptic.get_cityscapes_panoptic_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id"], ["", "def", "load_cityscapes_panoptic", "(", "image_dir", ",", "gt_dir", ",", "gt_json", ",", "meta", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n        gt_dir (str): path to the raw annotations. e.g.,\n            \"~/cityscapes/gtFine/cityscapes_panoptic_train\".\n        gt_json (str): path to the json file. e.g.,\n            \"~/cityscapes/gtFine/cityscapes_panoptic_train.json\".\n        meta (dict): dictionary containing \"thing_dataset_id_to_contiguous_id\"\n            and \"stuff_dataset_id_to_contiguous_id\" to map category ids to\n            contiguous ids for training.\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n    \"\"\"", "\n", "\n", "def", "_convert_category_id", "(", "segment_info", ",", "meta", ")", ":", "\n", "        ", "if", "segment_info", "[", "\"category_id\"", "]", "in", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "else", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "return", "segment_info", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "\n", "gt_json", "\n", ")", ",", "\"Please run `python cityscapesscripts/preparation/createPanopticImgs.py` to generate label files.\"", "# noqa", "\n", "with", "open", "(", "gt_json", ")", "as", "f", ":", "\n", "        ", "json_info", "=", "json", ".", "load", "(", "f", ")", "\n", "", "files", "=", "get_cityscapes_panoptic_files", "(", "image_dir", ",", "gt_dir", ",", "json_info", ")", "\n", "ret", "=", "[", "]", "\n", "for", "image_file", ",", "label_file", ",", "segments_info", "in", "files", ":", "\n", "        ", "sem_label_file", "=", "(", "\n", "image_file", ".", "replace", "(", "\"leftImg8bit\"", ",", "\"gtFine\"", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "+", "\"_labelTrainIds.png\"", "\n", ")", "\n", "segments_info", "=", "[", "_convert_category_id", "(", "x", ",", "meta", ")", "for", "x", "in", "segments_info", "]", "\n", "ret", ".", "append", "(", "\n", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"image_id\"", ":", "\"_\"", ".", "join", "(", "\n", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "image_file", ")", ")", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "[", ":", "3", "]", "\n", ")", ",", "\n", "\"sem_seg_file_name\"", ":", "sem_label_file", ",", "\n", "\"pan_seg_file_name\"", ":", "label_file", ",", "\n", "\"segments_info\"", ":", "segments_info", ",", "\n", "}", "\n", ")", "\n", "", "assert", "len", "(", "ret", ")", ",", "f\"No images found in {image_dir}!\"", "\n", "assert", "PathManager", ".", "isfile", "(", "\n", "ret", "[", "0", "]", "[", "\"sem_seg_file_name\"", "]", "\n", ")", ",", "\"Please generate labelTrainIds.png with cityscapesscripts/preparation/createTrainIdLabelImgs.py\"", "# noqa", "\n", "assert", "PathManager", ".", "isfile", "(", "\n", "ret", "[", "0", "]", "[", "\"pan_seg_file_name\"", "]", "\n", ")", ",", "\"Please generate panoptic annotation with python cityscapesscripts/preparation/createPanopticImgs.py\"", "# noqa", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes_panoptic.register_all_cityscapes_panoptic": [[127, 187], ["_RAW_CITYSCAPES_PANOPTIC_SPLITS.items", "os.path.join", "os.path.join", "os.path.join", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "cityscapes_panoptic.load_cityscapes_panoptic", "detectron2.data.MetadataCatalog.get", "os.path.join.replace"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes_panoptic.load_cityscapes_panoptic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "register_all_cityscapes_panoptic", "(", "root", ")", ":", "\n", "    ", "meta", "=", "{", "}", "\n", "# The following metadata maps contiguous id from [0, #thing categories +", "\n", "# #stuff categories) to their names and colors. We have to replica of the", "\n", "# same name and color under \"thing_*\" and \"stuff_*\" because the current", "\n", "# visualization function in D2 handles thing and class classes differently", "\n", "# due to some heuristic used in Panoptic FPN. We keep the same naming to", "\n", "# enable reusing existing visualization functions.", "\n", "thing_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "thing_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "stuff_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "stuff_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "CITYSCAPES_CATEGORIES", "]", "\n", "\n", "meta", "[", "\"thing_classes\"", "]", "=", "thing_classes", "\n", "meta", "[", "\"thing_colors\"", "]", "=", "thing_colors", "\n", "meta", "[", "\"stuff_classes\"", "]", "=", "stuff_classes", "\n", "meta", "[", "\"stuff_colors\"", "]", "=", "stuff_colors", "\n", "\n", "# There are three types of ids in cityscapes panoptic segmentation:", "\n", "# (1) category id: like semantic segmentation, it is the class id for each", "\n", "#   pixel. Since there are some classes not used in evaluation, the category", "\n", "#   id is not always contiguous and thus we have two set of category ids:", "\n", "#       - original category id: category id in the original dataset, mainly", "\n", "#           used for evaluation.", "\n", "#       - contiguous category id: [0, #classes), in order to train the classifier", "\n", "# (2) instance id: this id is used to differentiate different instances from", "\n", "#   the same category. For \"stuff\" classes, the instance id is always 0; for", "\n", "#   \"thing\" classes, the instance id starts from 1 and 0 is reserved for", "\n", "#   ignored instances (e.g. crowd annotation).", "\n", "# (3) panoptic id: this is the compact id that encode both category and", "\n", "#   instance id by: category_id * 1000 + instance_id.", "\n", "thing_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "stuff_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "\n", "for", "k", "in", "CITYSCAPES_CATEGORIES", ":", "\n", "        ", "if", "k", "[", "\"isthing\"", "]", "==", "1", ":", "\n", "            ", "thing_dataset_id_to_contiguous_id", "[", "k", "[", "\"id\"", "]", "]", "=", "k", "[", "\"trainId\"", "]", "\n", "", "else", ":", "\n", "            ", "stuff_dataset_id_to_contiguous_id", "[", "k", "[", "\"id\"", "]", "]", "=", "k", "[", "\"trainId\"", "]", "\n", "\n", "", "", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "=", "thing_dataset_id_to_contiguous_id", "\n", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "=", "stuff_dataset_id_to_contiguous_id", "\n", "\n", "for", "key", ",", "(", "image_dir", ",", "gt_dir", ",", "gt_json", ")", "in", "_RAW_CITYSCAPES_PANOPTIC_SPLITS", ".", "items", "(", ")", ":", "\n", "        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "image_dir", ")", "\n", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "gt_dir", ")", "\n", "gt_json", "=", "os", ".", "path", ".", "join", "(", "root", ",", "gt_json", ")", "\n", "\n", "DatasetCatalog", ".", "register", "(", "\n", "key", ",", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ",", "z", "=", "gt_json", ":", "load_cityscapes_panoptic", "(", "x", ",", "y", ",", "z", ",", "meta", ")", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "key", ")", ".", "set", "(", "\n", "panoptic_root", "=", "gt_dir", ",", "\n", "image_root", "=", "image_dir", ",", "\n", "panoptic_json", "=", "gt_json", ",", "\n", "gt_dir", "=", "gt_dir", ".", "replace", "(", "\"cityscapes_panoptic_\"", ",", "\"\"", ")", ",", "\n", "evaluator_type", "=", "\"cityscapes_panoptic_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "label_divisor", "=", "1000", ",", "\n", "**", "meta", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_coco_json": [[347, 389], ["coco._load_coco_annotations", "coco._add_categories_metadata", "sorted", "_load_coco_annotations.loadImgs", "logging.getLogger", "logging.getLogger.info", "coco._verify_annotations_have_unique_ids", "coco._combine_images_with_annotations", "detectron2.utils.file_io.PathManager.get_local_path", "_load_coco_annotations.loadCats", "_load_coco_annotations.imgs.keys", "_load_coco_annotations.getCatIds", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._load_coco_annotations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._add_categories_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._verify_annotations_have_unique_ids", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._combine_images_with_annotations"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_sem_seg": [[225, 299], ["sorted", "sorted", "logger.info", "zip", "os.path.normpath", "len", "len", "len", "logger.warn", "list", "sorted", "logger.warn", "dataset_dicts.append", "os.path.relpath", "os.path.splitext", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "detectron2.utils.file_io.PathManager.ls", "f.endswith", "coco.load_sem_seg.file2id"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.convert_to_coco_dict": [[301, 438], ["DatasetCatalog.get", "MetadataCatalog.get", "hasattr", "logger.info", "enumerate", "logger.info", "coco_images.append", "image_dict.get", "str", "len", "reverse_id_mapper", "enumerate", "image_dict.get", "int", "int", "str", "isinstance", "detectron2.structures.BoxMode.convert", "float", "int", "int", "coco_annotations.append", "datetime.datetime.now", "MetadataCatalog.get.thing_dataset_id_to_contiguous_id.items", "bbox.tolist.tolist", "len", "ValueError", "isinstance", "enumerate", "len", "round", "annotation.get", "reverse_id_mapper", "isinstance", "len", "len", "ValueError", "len", "detectron2.structures.PolygonMasks", "[].item", "isinstance", "detectron2.structures.BoxMode.convert", "[].item", "[].item", "sum", "float", "pycocotools.area().item", "TypeError", "isinstance", "counts.decode", "detectron2.structures.PolygonMasks.area", "pycocotools.area", "detectron2.structures.Boxes().area", "detectron2.structures.RotatedBoxes().area", "type", "detectron2.structures.Boxes", "detectron2.structures.RotatedBoxes"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.convert_to_coco_json": [[440, 472], ["detectron2.utils.file_io.PathManager.mkdirs", "os.path.dirname", "iopath.common.file_io.file_lock", "detectron2.utils.file_io.PathManager.exists", "logger.warning", "logger.info", "coco.convert_to_coco_dict", "logger.info", "shutil.move", "detectron2.utils.file_io.PathManager.open", "json.dump"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.convert_to_coco_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.register_coco_instances": [[474, 501], ["isinstance", "isinstance", "isinstance", "DatasetCatalog.register", "MetadataCatalog.get().set", "coco.load_coco_json", "MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_coco_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.load_coco_panoptic_json": [[14, 64], ["len", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.isfile", "detectron2.utils.file_io.PathManager.open", "json.load", "int", "os.path.join", "os.path.join", "ret.append", "coco_panoptic.load_coco_panoptic_json._convert_category_id"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id"], ["def", "load_coco_panoptic_json", "(", "json_file", ",", "image_dir", ",", "gt_dir", ",", "meta", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): path to the raw dataset. e.g., \"~/coco/train2017\".\n        gt_dir (str): path to the raw annotations. e.g., \"~/coco/panoptic_train2017\".\n        json_file (str): path to the json file. e.g., \"~/coco/annotations/panoptic_train2017.json\".\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n    \"\"\"", "\n", "\n", "def", "_convert_category_id", "(", "segment_info", ",", "meta", ")", ":", "\n", "        ", "if", "segment_info", "[", "\"category_id\"", "]", "in", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "segment_info", "[", "\"isthing\"", "]", "=", "True", "\n", "", "else", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "segment_info", "[", "\"isthing\"", "]", "=", "False", "\n", "", "return", "segment_info", "\n", "\n", "", "with", "PathManager", ".", "open", "(", "json_file", ")", "as", "f", ":", "\n", "        ", "json_info", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "ann", "in", "json_info", "[", "\"annotations\"", "]", ":", "\n", "        ", "image_id", "=", "int", "(", "ann", "[", "\"image_id\"", "]", ")", "\n", "# TODO: currently we assume image and label has the same filename but", "\n", "# different extension, and images have extension \".jpg\" for COCO. Need", "\n", "# to make image extension a user-provided argument if we extend this", "\n", "# function to support other COCO-like datasets.", "\n", "image_file", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "os", ".", "path", ".", "splitext", "(", "ann", "[", "\"file_name\"", "]", ")", "[", "0", "]", "+", "\".jpg\"", ")", "\n", "label_file", "=", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "ann", "[", "\"file_name\"", "]", ")", "\n", "segments_info", "=", "[", "_convert_category_id", "(", "x", ",", "meta", ")", "for", "x", "in", "ann", "[", "\"segments_info\"", "]", "]", "\n", "ret", ".", "append", "(", "\n", "{", "\n", "\"file_name\"", ":", "image_file", ",", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"pan_seg_file_name\"", ":", "label_file", ",", "\n", "\"segments_info\"", ":", "segments_info", ",", "\n", "}", "\n", ")", "\n", "", "assert", "len", "(", "ret", ")", ",", "f\"No images found in {image_dir}!\"", "\n", "assert", "PathManager", ".", "isfile", "(", "ret", "[", "0", "]", "[", "\"file_name\"", "]", ")", ",", "ret", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "assert", "PathManager", ".", "isfile", "(", "ret", "[", "0", "]", "[", "\"pan_seg_file_name\"", "]", ")", ",", "ret", "[", "0", "]", "[", "\"pan_seg_file_name\"", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.register_coco_panoptic": [[66, 99], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco_panoptic.load_coco_panoptic_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.load_coco_panoptic_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "register_coco_panoptic", "(", "\n", "name", ",", "metadata", ",", "image_root", ",", "panoptic_root", ",", "panoptic_json", ",", "instances_json", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Register a \"standard\" version of COCO panoptic segmentation dataset named `name`.\n    The dictionaries in this registered dataset follows detectron2's standard format.\n    Hence it's called \"standard\".\n\n    Args:\n        name (str): the name that identifies a dataset,\n            e.g. \"coco_2017_train_panoptic\"\n        metadata (dict): extra metadata associated with this dataset.\n        image_root (str): directory which contains all the images\n        panoptic_root (str): directory which contains panoptic annotation images in COCO format\n        panoptic_json (str): path to the json panoptic annotation file in COCO format\n        sem_seg_root (none): not used, to be consistent with\n            `register_coco_panoptic_separated`.\n        instances_json (str): path to the json instance annotation file\n    \"\"\"", "\n", "panoptic_name", "=", "name", "\n", "DatasetCatalog", ".", "register", "(", "\n", "panoptic_name", ",", "\n", "lambda", ":", "load_coco_panoptic_json", "(", "panoptic_json", ",", "image_root", ",", "panoptic_root", ",", "metadata", ")", ",", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "panoptic_name", ")", ".", "set", "(", "\n", "panoptic_root", "=", "panoptic_root", ",", "\n", "image_root", "=", "image_root", ",", "\n", "panoptic_json", "=", "panoptic_json", ",", "\n", "json_file", "=", "instances_json", ",", "\n", "evaluator_type", "=", "\"coco_panoptic_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "label_divisor", "=", "1000", ",", "\n", "**", "metadata", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.register_coco_panoptic_separated": [[102, 165], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco_panoptic.merge_to_panoptic", "detectron2.data.MetadataCatalog.get", "coco.load_sem_seg", "detectron2.data.MetadataCatalog.get", "coco.load_coco_json", "coco.load_sem_seg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.merge_to_panoptic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_sem_seg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_coco_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_sem_seg"], ["", "def", "register_coco_panoptic_separated", "(", "\n", "name", ",", "metadata", ",", "image_root", ",", "panoptic_root", ",", "panoptic_json", ",", "sem_seg_root", ",", "instances_json", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Register a \"separated\" version of COCO panoptic segmentation dataset named `name`.\n    The annotations in this registered dataset will contain both instance annotations and\n    semantic annotations, each with its own contiguous ids. Hence it's called \"separated\".\n\n    It follows the setting used by the PanopticFPN paper:\n\n    1. The instance annotations directly come from polygons in the COCO\n       instances annotation task, rather than from the masks in the COCO panoptic annotations.\n\n       The two format have small differences:\n       Polygons in the instance annotations may have overlaps.\n       The mask annotations are produced by labeling the overlapped polygons\n       with depth ordering.\n\n    2. The semantic annotations are converted from panoptic annotations, where\n       all \"things\" are assigned a semantic id of 0.\n       All semantic categories will therefore have ids in contiguous\n       range [1, #stuff_categories].\n\n    This function will also register a pure semantic segmentation dataset\n    named ``name + '_stuffonly'``.\n\n    Args:\n        name (str): the name that identifies a dataset,\n            e.g. \"coco_2017_train_panoptic\"\n        metadata (dict): extra metadata associated with this dataset.\n        image_root (str): directory which contains all the images\n        panoptic_root (str): directory which contains panoptic annotation images\n        panoptic_json (str): path to the json panoptic annotation file\n        sem_seg_root (str): directory which contains all the ground truth segmentation annotations.\n        instances_json (str): path to the json instance annotation file\n    \"\"\"", "\n", "panoptic_name", "=", "name", "+", "\"_separated\"", "\n", "DatasetCatalog", ".", "register", "(", "\n", "panoptic_name", ",", "\n", "lambda", ":", "merge_to_panoptic", "(", "\n", "load_coco_json", "(", "instances_json", ",", "image_root", ",", "panoptic_name", ")", ",", "\n", "load_sem_seg", "(", "sem_seg_root", ",", "image_root", ")", ",", "\n", ")", ",", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "panoptic_name", ")", ".", "set", "(", "\n", "panoptic_root", "=", "panoptic_root", ",", "\n", "image_root", "=", "image_root", ",", "\n", "panoptic_json", "=", "panoptic_json", ",", "\n", "sem_seg_root", "=", "sem_seg_root", ",", "\n", "json_file", "=", "instances_json", ",", "# TODO rename", "\n", "evaluator_type", "=", "\"coco_panoptic_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "**", "metadata", ",", "\n", ")", "\n", "\n", "semantic_name", "=", "name", "+", "\"_stuffonly\"", "\n", "DatasetCatalog", ".", "register", "(", "semantic_name", ",", "lambda", ":", "load_sem_seg", "(", "sem_seg_root", ",", "image_root", ")", ")", "\n", "MetadataCatalog", ".", "get", "(", "semantic_name", ")", ".", "set", "(", "\n", "sem_seg_root", "=", "sem_seg_root", ",", "\n", "image_root", "=", "image_root", ",", "\n", "evaluator_type", "=", "\"sem_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "**", "metadata", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.merge_to_panoptic": [[168, 191], ["len", "copy.copy", "copy.copy.update", "results.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "def", "merge_to_panoptic", "(", "detection_dicts", ",", "sem_seg_dicts", ")", ":", "\n", "    ", "\"\"\"\n    Create dataset dicts for panoptic segmentation, by\n    merging two dicts using \"file_name\" field to match their entries.\n\n    Args:\n        detection_dicts (list[dict]): lists of dicts for object detection or instance segmentation.\n        sem_seg_dicts (list[dict]): lists of dicts for semantic segmentation.\n\n    Returns:\n        list[dict] (one per input image): Each dict contains all (key, value) pairs from dicts in\n            both detection_dicts and sem_seg_dicts that correspond to the same image.\n            The function assumes that the same key in different dicts has the same value.\n    \"\"\"", "\n", "results", "=", "[", "]", "\n", "sem_seg_file_to_entry", "=", "{", "x", "[", "\"file_name\"", "]", ":", "x", "for", "x", "in", "sem_seg_dicts", "}", "\n", "assert", "len", "(", "sem_seg_file_to_entry", ")", ">", "0", "\n", "\n", "for", "det_dict", "in", "detection_dicts", ":", "\n", "        ", "dic", "=", "copy", ".", "copy", "(", "det_dict", ")", "\n", "dic", ".", "update", "(", "sem_seg_file_to_entry", "[", "dic", "[", "\"file_name\"", "]", "]", ")", "\n", "results", ".", "append", "(", "dic", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_coco_instances_meta": [[235, 248], ["len", "len", "enumerate"], "function", ["None"], ["def", "_get_coco_instances_meta", "(", ")", ":", "\n", "    ", "thing_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "thing_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "assert", "len", "(", "thing_ids", ")", "==", "80", ",", "len", "(", "thing_ids", ")", "\n", "# Mapping from the incontiguous COCO category id to an id in [0, 79]", "\n", "thing_dataset_id_to_contiguous_id", "=", "{", "k", ":", "i", "for", "i", ",", "k", "in", "enumerate", "(", "thing_ids", ")", "}", "\n", "thing_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "1", "]", "\n", "ret", "=", "{", "\n", "\"thing_dataset_id_to_contiguous_id\"", ":", "thing_dataset_id_to_contiguous_id", ",", "\n", "\"thing_classes\"", ":", "thing_classes", ",", "\n", "\"thing_colors\"", ":", "thing_colors", ",", "\n", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_coco_panoptic_separated_meta": [[250, 281], ["len", "ret.update", "len", "builtin_meta._get_coco_instances_meta", "enumerate", "k[].replace().replace", "k[].replace"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_coco_instances_meta"], ["", "def", "_get_coco_panoptic_separated_meta", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns metadata for \"separated\" version of the panoptic segmentation dataset.\n    \"\"\"", "\n", "stuff_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "0", "]", "\n", "assert", "len", "(", "stuff_ids", ")", "==", "53", ",", "len", "(", "stuff_ids", ")", "\n", "\n", "# For semantic segmentation, this mapping maps from contiguous stuff id", "\n", "# (in [0, 53], used in models) to ids in the dataset (used for processing results)", "\n", "# The id 0 is mapped to an extra category \"thing\".", "\n", "stuff_dataset_id_to_contiguous_id", "=", "{", "k", ":", "i", "+", "1", "for", "i", ",", "k", "in", "enumerate", "(", "stuff_ids", ")", "}", "\n", "# When converting COCO panoptic annotations to semantic annotations", "\n", "# We label the \"thing\" category to 0", "\n", "stuff_dataset_id_to_contiguous_id", "[", "0", "]", "=", "0", "\n", "\n", "# 54 names for COCO stuff categories (including \"things\")", "\n", "stuff_classes", "=", "[", "\"things\"", "]", "+", "[", "\n", "k", "[", "\"name\"", "]", ".", "replace", "(", "\"-other\"", ",", "\"\"", ")", ".", "replace", "(", "\"-merged\"", ",", "\"\"", ")", "\n", "for", "k", "in", "COCO_CATEGORIES", "\n", "if", "k", "[", "\"isthing\"", "]", "==", "0", "\n", "]", "\n", "\n", "# NOTE: I randomly picked a color for things", "\n", "stuff_colors", "=", "[", "[", "82", ",", "18", ",", "128", "]", "]", "+", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "if", "k", "[", "\"isthing\"", "]", "==", "0", "]", "\n", "ret", "=", "{", "\n", "\"stuff_dataset_id_to_contiguous_id\"", ":", "stuff_dataset_id_to_contiguous_id", ",", "\n", "\"stuff_classes\"", ":", "stuff_classes", ",", "\n", "\"stuff_colors\"", ":", "stuff_colors", ",", "\n", "}", "\n", "ret", ".", "update", "(", "_get_coco_instances_meta", "(", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_builtin_metadata": [[283, 351], ["KeyError", "builtin_meta._get_coco_instances_meta", "builtin_meta._get_coco_panoptic_separated_meta", "enumerate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_coco_instances_meta", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_coco_panoptic_separated_meta"], ["", "def", "_get_builtin_metadata", "(", "dataset_name", ")", ":", "\n", "    ", "if", "dataset_name", "==", "\"coco\"", ":", "\n", "        ", "return", "_get_coco_instances_meta", "(", ")", "\n", "", "if", "dataset_name", "==", "\"coco_panoptic_separated\"", ":", "\n", "        ", "return", "_get_coco_panoptic_separated_meta", "(", ")", "\n", "", "elif", "dataset_name", "==", "\"coco_panoptic_standard\"", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "# The following metadata maps contiguous id from [0, #thing categories +", "\n", "# #stuff categories) to their names and colors. We have to replica of the", "\n", "# same name and color under \"thing_*\" and \"stuff_*\" because the current", "\n", "# visualization function in D2 handles thing and class classes differently", "\n", "# due to some heuristic used in Panoptic FPN. We keep the same naming to", "\n", "# enable reusing existing visualization functions.", "\n", "thing_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "thing_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "stuff_classes", "=", "[", "k", "[", "\"name\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "stuff_colors", "=", "[", "k", "[", "\"color\"", "]", "for", "k", "in", "COCO_CATEGORIES", "]", "\n", "\n", "meta", "[", "\"thing_classes\"", "]", "=", "thing_classes", "\n", "meta", "[", "\"thing_colors\"", "]", "=", "thing_colors", "\n", "meta", "[", "\"stuff_classes\"", "]", "=", "stuff_classes", "\n", "meta", "[", "\"stuff_colors\"", "]", "=", "stuff_colors", "\n", "\n", "# Convert category id for training:", "\n", "#   category id: like semantic segmentation, it is the class id for each", "\n", "#   pixel. Since there are some classes not used in evaluation, the category", "\n", "#   id is not always contiguous and thus we have two set of category ids:", "\n", "#       - original category id: category id in the original dataset, mainly", "\n", "#           used for evaluation.", "\n", "#       - contiguous category id: [0, #classes), in order to train the linear", "\n", "#           softmax classifier.", "\n", "thing_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "stuff_dataset_id_to_contiguous_id", "=", "{", "}", "\n", "\n", "for", "i", ",", "cat", "in", "enumerate", "(", "COCO_CATEGORIES", ")", ":", "\n", "            ", "if", "cat", "[", "\"isthing\"", "]", ":", "\n", "                ", "thing_dataset_id_to_contiguous_id", "[", "cat", "[", "\"id\"", "]", "]", "=", "i", "\n", "", "else", ":", "\n", "                ", "stuff_dataset_id_to_contiguous_id", "[", "cat", "[", "\"id\"", "]", "]", "=", "i", "\n", "\n", "", "", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "=", "thing_dataset_id_to_contiguous_id", "\n", "meta", "[", "\"stuff_dataset_id_to_contiguous_id\"", "]", "=", "stuff_dataset_id_to_contiguous_id", "\n", "\n", "return", "meta", "\n", "", "elif", "dataset_name", "==", "\"coco_person\"", ":", "\n", "        ", "return", "{", "\n", "\"thing_classes\"", ":", "[", "\"person\"", "]", ",", "\n", "\"keypoint_names\"", ":", "COCO_PERSON_KEYPOINT_NAMES", ",", "\n", "\"keypoint_flip_map\"", ":", "COCO_PERSON_KEYPOINT_FLIP_MAP", ",", "\n", "\"keypoint_connection_rules\"", ":", "KEYPOINT_CONNECTION_RULES", ",", "\n", "}", "\n", "", "elif", "dataset_name", "==", "\"cityscapes\"", ":", "\n", "# fmt: off", "\n", "        ", "CITYSCAPES_THING_CLASSES", "=", "[", "\n", "\"person\"", ",", "\"rider\"", ",", "\"car\"", ",", "\"truck\"", ",", "\n", "\"bus\"", ",", "\"train\"", ",", "\"motorcycle\"", ",", "\"bicycle\"", ",", "\n", "]", "\n", "CITYSCAPES_STUFF_CLASSES", "=", "[", "\n", "\"road\"", ",", "\"sidewalk\"", ",", "\"building\"", ",", "\"wall\"", ",", "\"fence\"", ",", "\"pole\"", ",", "\"traffic light\"", ",", "\n", "\"traffic sign\"", ",", "\"vegetation\"", ",", "\"terrain\"", ",", "\"sky\"", ",", "\"person\"", ",", "\"rider\"", ",", "\"car\"", ",", "\n", "\"truck\"", ",", "\"bus\"", ",", "\"train\"", ",", "\"motorcycle\"", ",", "\"bicycle\"", ",", "\n", "]", "\n", "# fmt: on", "\n", "return", "{", "\n", "\"thing_classes\"", ":", "CITYSCAPES_THING_CLASSES", ",", "\n", "\"stuff_classes\"", ":", "CITYSCAPES_STUFF_CLASSES", ",", "\n", "}", "\n", "", "raise", "KeyError", "(", "\"No built-in metadata for dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes._get_cityscapes_files": [[27, 51], ["detectron2.utils.file_io.PathManager.ls", "logger.info", "len", "os.path.join", "os.path.join", "detectron2.utils.file_io.PathManager.ls", "detectron2.utils.file_io.PathManager.isfile", "os.path.join", "basename.endswith", "os.path.join", "os.path.join", "os.path.join", "files.append", "len", "len"], "function", ["None"], ["min_area", "=", "0", ",", "\n", "mini", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            img_dir: /path/to/leftImg8bit/      has to contain {train,val,test}\n            ann_dir: /path/to/gtFine/           has to contain {train,val,test}\n            split: \"train\" or \"val\" or \"test\"\n            mode: \"poly\" or \"mask\", which annotation format to use\n            transforms: apply transformations to input/annotation\n            min_area: exclude intances below a specific area (bbox area)\n            mini: limit the size of the dataset, so len(dataset) == mini for\n                debugging purposes\n        \"\"\"", "\n", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "\n", "img_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "img_dir", ",", "split", ")", ")", "\n", "ann_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "split", ")", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "img_dir", ")", ",", "img_dir", "\n", "assert", "os", ".", "path", ".", "exists", "(", "ann_dir", ")", ",", "ann_dr", "\n", "\n", "self", ".", "ann_dir", "=", "ann_dir", "\n", "\n", "self", ".", "split", "=", "split", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.load_cityscapes_instances": [[53, 93], ["cityscapes._get_cityscapes_files", "logger.info", "multiprocessing.Pool", "mp.Pool.map", "logger.info", "functools.partial", "max", "len", "enumerate", "multiprocessing.cpu_count", "detectron2.utils.comm.get_world_size"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes._get_cityscapes_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["self", ".", "CLASSES", "+=", "[", "l", ".", "name", "for", "l", "in", "csHelpers", ".", "labels", "if", "l", ".", "hasInstances", "]", "\n", "\n", "# Adds name_to_id and id_to_name mapping", "\n", "self", ".", "initMaps", "(", ")", "\n", "\n", "# This is required for parsing binary masks", "\n", "self", ".", "cityscapesID_to_ind", "=", "{", "\n", "l", ".", "id", ":", "self", ".", "name_to_id", "[", "l", ".", "name", "]", "for", "l", "in", "csHelpers", ".", "labels", "if", "l", ".", "hasInstances", "\n", "}", "\n", "\n", "self", ".", "transforms", "=", "transforms", "\n", "self", ".", "min_area", "=", "int", "(", "min_area", ")", "\n", "\n", "img_pattern", "=", "os", ".", "path", ".", "join", "(", "img_dir", ",", "\"*\"", ",", "\"*_leftImg8bit.png\"", ")", "\n", "img_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "img_pattern", ")", ")", "\n", "\n", "if", "mode", "==", "\"mask\"", ":", "\n", "            ", "ann_pattern", "=", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "\"*\"", ",", "\"*_instanceIds.png\"", ")", "\n", "", "elif", "mode", "==", "\"poly\"", ":", "\n", "            ", "ann_pattern", "=", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "\"*\"", ",", "\"*_polygons.json\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Mode is not implemented yet: %s\"", "%", "mode", ")", "\n", "\n", "", "self", ".", "mode", "=", "mode", "\n", "ann_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "ann_pattern", ")", ")", "\n", "\n", "if", "mini", "is", "not", "None", ":", "\n", "# Keep the mini dataset diverse by setting the stride", "\n", "            ", "img_paths", "=", "img_paths", "[", ":", ":", "len", "(", "img_paths", ")", "//", "mini", "+", "1", "]", "\n", "ann_paths", "=", "ann_paths", "[", ":", ":", "len", "(", "ann_paths", ")", "//", "mini", "+", "1", "]", "\n", "\n", "", "assert", "len", "(", "img_paths", ")", "==", "len", "(", "ann_paths", ")", "\n", "\n", "self", ".", "img_paths", "=", "img_paths", "\n", "self", ".", "ann_paths", "=", "ann_paths", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_path", "=", "self", ".", "img_paths", "[", "idx", "]", "\n", "ann_path", "=", "self", ".", "ann_paths", "[", "idx", "]", "\n", "\n", "if", "self", ".", "mode", "==", "\"mask\"", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.load_cityscapes_semantic": [[95, 126], ["detectron2.utils.file_io.PathManager.get_local_path", "cityscapes._get_cityscapes_files", "len", "detectron2.utils.file_io.PathManager.isfile", "label_file.replace.replace", "ret.append", "detectron2.utils.file_io.PathManager.open", "json.load"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes._get_cityscapes_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["# masks are represented with tensors", "\n", "boxes", ",", "segmentations", ",", "labels", "=", "self", ".", "_processBinayMasks", "(", "ann", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "ann_path", ",", "\"r\"", ")", "as", "ann_file", ":", "\n", "                ", "ann", "=", "json", ".", "load", "(", "ann_file", ")", "\n", "# masks are represented with polygons", "\n", "", "boxes", ",", "segmentations", ",", "labels", "=", "self", ".", "_processPolygons", "(", "ann", ")", "\n", "\n", "", "boxes", ",", "segmentations", ",", "labels", "=", "self", ".", "_filterGT", "(", "boxes", ",", "segmentations", ",", "labels", ")", "\n", "\n", "if", "len", "(", "segmentations", ")", "==", "0", ":", "\n", "            ", "empty_ann_path", "=", "self", ".", "get_img_info", "(", "idx", ")", "[", "\"ann_path\"", "]", "\n", "print", "(", "\"EMPTY ENTRY:\"", ",", "empty_ann_path", ")", "\n", "# self.img_paths.pop(idx)", "\n", "# self.ann_paths.pop(idx)", "\n", "img", ",", "target", ",", "_", "=", "self", "[", "(", "idx", "+", "1", ")", "%", "len", "(", "self", ")", "]", "\n", "\n", "# just override this image with the next", "\n", "return", "img", ",", "target", ",", "idx", "\n", "\n", "", "img", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "# Compose all into a BoxList instance", "\n", "target", "=", "BoxList", "(", "boxes", ",", "img", ".", "size", ",", "mode", "=", "\"xyxy\"", ")", "\n", "target", ".", "add_field", "(", "\"labels\"", ",", "torch", ".", "tensor", "(", "labels", ")", ")", "\n", "masks", "=", "SegmentationMask", "(", "segmentations", ",", "img", ".", "size", ",", "mode", "=", "self", ".", "mode", ")", "\n", "target", ".", "add_field", "(", "\"masks\"", ",", "masks", ")", "\n", "if", "self", ".", "transforms", "is", "not", "None", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "transforms", "(", "img", ",", "target", ")", "\n", "\n", "", "return", "img", ",", "target", ",", "idx", "\n", "\n", "", "def", "_filterGT", "(", "self", ",", "boxes", ",", "segmentations", ",", "labels", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes._cityscapes_files_to_dict": [[128, 279], ["Polygon", "numpy.unique", "detectron2.utils.file_io.PathManager.open", "json.load", "os.path.basename", "Polygon().buffer", "Polygon().buffer.difference", "polygons_union.union.union", "label_name.endswith", "isinstance", "annos.append", "detectron2.utils.file_io.PathManager.open", "numpy.asarray", "os.path.basename", "numpy.asarray", "numpy.nonzero", "annos.append", "numpy.asarray", "polygons_union.union.union", "isinstance", "poly_coord.append", "PIL.Image.open", "inds[].min", "inds[].max", "inds[].min", "inds[].max", "label_name.endswith", "Polygon", "NotImplementedError", "list", "cv2.findContours", "c.reshape().tolist", "len", "pycocotools.encode", "itertools.chain", "np.asarray.copy", "c.reshape", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.cv2_util.findContours", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["filtered_segmentations", "=", "[", "]", "\n", "filtered_labels", "=", "[", "]", "\n", "assert", "len", "(", "segmentations", ")", "==", "len", "(", "labels", ")", "==", "len", "(", "boxes", ")", "\n", "\n", "for", "box", ",", "segmentation", ",", "label", "in", "zip", "(", "boxes", ",", "segmentations", ",", "labels", ")", ":", "\n", "            ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "box", "\n", "area", "=", "(", "xmax", "-", "xmin", ")", "*", "(", "ymax", "-", "ymin", ")", "\n", "if", "area", "<", "self", ".", "min_area", ":", "\n", "                ", "continue", "\n", "\n", "", "filtered_boxes", ".", "append", "(", "box", ")", "\n", "filtered_segmentations", ".", "append", "(", "segmentation", ")", "\n", "filtered_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "if", "len", "(", "filtered_boxes", ")", "<", "1", ":", "\n", "            ", "filtered_boxes", "=", "torch", ".", "empty", "(", "0", ",", "4", ")", "\n", "\n", "", "return", "filtered_boxes", ",", "filtered_segmentations", ",", "filtered_labels", "\n", "\n", "", "def", "_processPolygons", "(", "self", ",", "ann", ")", ":", "\n", "# For a single object polygon annotations are stored in CityScapes like", "\n", "# [[x1, y1], [x2, y2]...] and we need them in the following format:", "\n", "# [x1, y1, x2, y2, x3, y3 ...]", "\n", "        ", "polys", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "boxes", "=", "[", "]", "\n", "\n", "def", "poly_to_tight_box", "(", "poly", ")", ":", "\n", "            ", "xmin", "=", "int", "(", "min", "(", "poly", "[", ":", ":", "2", "]", ")", ")", "\n", "ymin", "=", "int", "(", "min", "(", "poly", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "xmax", "=", "int", "(", "max", "(", "poly", "[", ":", ":", "2", "]", ")", ")", "\n", "ymax", "=", "int", "(", "max", "(", "poly", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "bbox", "=", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "return", "bbox", "\n", "\n", "", "for", "inst", "in", "ann", "[", "\"objects\"", "]", ":", "\n", "            ", "label", "=", "inst", "[", "\"label\"", "]", "\n", "if", "label", "not", "in", "self", ".", "CLASSES", ":", "\n", "                ", "continue", "\n", "\n", "", "label", "=", "self", ".", "name_to_id", "[", "label", "]", "\n", "\n", "cityscapes_poly", "=", "inst", "[", "\"polygon\"", "]", "\n", "poly", "=", "[", "]", "\n", "for", "xy", "in", "cityscapes_poly", ":", "\n", "# Equivalent with `poly += xy` but this is more verbose", "\n", "                ", "x", "=", "xy", "[", "0", "]", "\n", "y", "=", "xy", "[", "1", "]", "\n", "poly", ".", "append", "(", "x", ")", "\n", "poly", ".", "append", "(", "y", ")", "\n", "\n", "# In CityScapes instances are described with single polygons only", "\n", "", "box", "=", "poly_to_tight_box", "(", "poly", ")", "\n", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "polys", ".", "append", "(", "[", "poly", "]", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "if", "len", "(", "boxes", ")", "<", "1", ":", "\n", "            ", "boxes", "=", "torch", ".", "empty", "(", "0", ",", "4", ")", "\n", "\n", "", "return", "boxes", ",", "polys", ",", "labels", "\n", "\n", "", "def", "_processBinayMasks", "(", "self", ",", "ann", ")", ":", "\n", "        ", "boxes", "=", "[", "]", "\n", "masks", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "def", "mask_to_tight_box", "(", "mask", ")", ":", "\n", "            ", "a", "=", "mask", ".", "nonzero", "(", ")", "\n", "bbox", "=", "[", "\n", "torch", ".", "min", "(", "a", "[", ":", ",", "1", "]", ")", ",", "\n", "torch", ".", "min", "(", "a", "[", ":", ",", "0", "]", ")", ",", "\n", "torch", ".", "max", "(", "a", "[", ":", ",", "1", "]", ")", ",", "\n", "torch", ".", "max", "(", "a", "[", ":", ",", "0", "]", ")", ",", "\n", "]", "\n", "bbox", "=", "list", "(", "map", "(", "int", ",", "bbox", ")", ")", "\n", "return", "bbox", "# xmin, ymin, xmax, ymax", "\n", "\n", "# Sort for consistent order between instances as the polygon annotation", "\n", "", "instIds", "=", "torch", ".", "sort", "(", "torch", ".", "unique", "(", "ann", ")", ")", "[", "0", "]", "\n", "for", "instId", "in", "instIds", ":", "\n", "            ", "if", "instId", "<", "1000", ":", "# group labels", "\n", "                ", "continue", "\n", "\n", "", "mask", "=", "ann", "==", "instId", "\n", "label", "=", "int", "(", "instId", "/", "1000", ")", "\n", "label", "=", "self", ".", "cityscapesID_to_ind", "[", "label", "]", "\n", "box", "=", "mask_to_tight_box", "(", "mask", ")", "\n", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "return", "boxes", ",", "masks", ",", "labels", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_paths", ")", "\n", "\n", "", "def", "get_img_info", "(", "self", ",", "index", ")", ":", "\n", "# Reverse engineered from voc.py", "\n", "# All the images have the same size", "\n", "        ", "return", "{", "\n", "\"height\"", ":", "1024", ",", "\n", "\"width\"", ":", "2048", ",", "\n", "\"idx\"", ":", "index", ",", "\n", "\"img_path\"", ":", "self", ".", "img_paths", "[", "index", "]", ",", "\n", "\"ann_path\"", ":", "self", ".", "ann_paths", "[", "index", "]", ",", "\n", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.register_lvis_instances": [[24, 37], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "lvis.load_lvis_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.load_lvis_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "register_lvis_instances", "(", "name", ",", "metadata", ",", "json_file", ",", "image_root", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in LVIS's json annotation format for instance detection and segmentation.\n\n    Args:\n        name (str): a name that identifies the dataset, e.g. \"lvis_v0.5_train\".\n        metadata (dict): extra metadata associated with this dataset. It can be an empty dict.\n        json_file (str): path to the json instance annotation file.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "DatasetCatalog", ".", "register", "(", "name", ",", "lambda", ":", "load_lvis_json", "(", "json_file", ",", "image_root", ",", "name", ")", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "json_file", "=", "json_file", ",", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"lvis\"", ",", "**", "metadata", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.load_lvis_json": [[163, 208], ["lvis._load_lvis_annotations", "lvis._add_categories_metadata", "sorted", "_load_lvis_annotations.load_imgs", "logging.getLogger", "logging.getLogger.info", "lvis._verify_annotations_have_unique_ids", "lvis._combine_images_with_annotations", "detectron2.utils.file_io.PathManager.get_local_path", "_load_lvis_annotations.imgs.keys", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._load_lvis_annotations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._add_categories_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._verify_annotations_have_unique_ids", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._combine_images_with_annotations"], ["\n", "if", "\"cocofied\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_coco_instances_meta", "(", ")", "\n", "", "if", "\"v0.5\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_lvis_instances_meta_v0_5", "(", ")", "\n", "", "elif", "\"v1\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_lvis_instances_meta_v1", "(", ")", "\n", "", "raise", "ValueError", "(", "\"No built-in metadata for dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "\n", "\n", "", "def", "_get_lvis_instances_meta_v0_5", "(", ")", ":", "\n", "    ", "assert", "len", "(", "LVIS_V0_5_CATEGORIES", ")", "==", "1230", "\n", "cat_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "LVIS_V0_5_CATEGORIES", "]", "\n", "assert", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "\n", "cat_ids", "\n", ")", ",", "\"Category ids are not in [1, #categories], as expected\"", "\n", "# Ensure that the category list is sorted by id", "\n", "lvis_categories", "=", "sorted", "(", "LVIS_V0_5_CATEGORIES", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "\n", "thing_classes", "=", "[", "k", "[", "\"synonyms\"", "]", "[", "0", "]", "for", "k", "in", "lvis_categories", "]", "\n", "meta", "=", "{", "\"thing_classes\"", ":", "thing_classes", "}", "\n", "return", "meta", "\n", "\n", "\n", "", "def", "_get_lvis_instances_meta_v1", "(", ")", ":", "\n", "    ", "assert", "len", "(", "LVIS_V1_CATEGORIES", ")", "==", "1203", "\n", "cat_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "LVIS_V1_CATEGORIES", "]", "\n", "assert", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "\n", "cat_ids", "\n", ")", ",", "\"Category ids are not in [1, #categories], as expected\"", "\n", "# Ensure that the category list is sorted by id", "\n", "lvis_categories", "=", "sorted", "(", "LVIS_V1_CATEGORIES", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "\n", "thing_classes", "=", "[", "k", "[", "\"synonyms\"", "]", "[", "0", "]", "for", "k", "in", "lvis_categories", "]", "\n", "meta", "=", "{", "\"thing_classes\"", ":", "thing_classes", "}", "\n", "return", "meta", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "\"\"\"\n    Test the LVIS json dataset loader.\n\n    Usage:\n        python -m detectron2.data.datasets.lvis \\\n            path/to/json path/to/image_root dataset_name vis_limit\n    \"\"\"", "\n", "import", "sys", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.get_lvis_instances_meta": [[155, 172], ["ValueError", "builtin_meta._get_coco_instances_meta", "lvis._get_lvis_instances_meta_v0_5", "lvis._get_lvis_instances_meta_v1"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_coco_instances_meta", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._get_lvis_instances_meta_v0_5", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._get_lvis_instances_meta_v1"], ["", "def", "get_lvis_instances_meta", "(", "dataset_name", ")", ":", "\n", "    ", "\"\"\"\n    Load LVIS metadata.\n\n    Args:\n        dataset_name (str): LVIS dataset name without the split name (e.g., \"lvis_v0.5\").\n\n    Returns:\n        dict: LVIS metadata with keys: thing_classes\n    \"\"\"", "\n", "if", "\"cocofied\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_coco_instances_meta", "(", ")", "\n", "", "if", "\"v0.5\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_lvis_instances_meta_v0_5", "(", ")", "\n", "", "elif", "\"v1\"", "in", "dataset_name", ":", "\n", "        ", "return", "_get_lvis_instances_meta_v1", "(", ")", "\n", "", "raise", "ValueError", "(", "\"No built-in metadata for dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._get_lvis_instances_meta_v0_5": [[174, 185], ["sorted", "len", "min", "max", "len"], "function", ["None"], ["", "def", "_get_lvis_instances_meta_v0_5", "(", ")", ":", "\n", "    ", "assert", "len", "(", "LVIS_V0_5_CATEGORIES", ")", "==", "1230", "\n", "cat_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "LVIS_V0_5_CATEGORIES", "]", "\n", "assert", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "\n", "cat_ids", "\n", ")", ",", "\"Category ids are not in [1, #categories], as expected\"", "\n", "# Ensure that the category list is sorted by id", "\n", "lvis_categories", "=", "sorted", "(", "LVIS_V0_5_CATEGORIES", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "\n", "thing_classes", "=", "[", "k", "[", "\"synonyms\"", "]", "[", "0", "]", "for", "k", "in", "lvis_categories", "]", "\n", "meta", "=", "{", "\"thing_classes\"", ":", "thing_classes", "}", "\n", "return", "meta", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._get_lvis_instances_meta_v1": [[187, 198], ["sorted", "len", "min", "max", "len"], "function", ["None"], ["", "def", "_get_lvis_instances_meta_v1", "(", ")", ":", "\n", "    ", "assert", "len", "(", "LVIS_V1_CATEGORIES", ")", "==", "1203", "\n", "cat_ids", "=", "[", "k", "[", "\"id\"", "]", "for", "k", "in", "LVIS_V1_CATEGORIES", "]", "\n", "assert", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "\n", "cat_ids", "\n", ")", ",", "\"Category ids are not in [1, #categories], as expected\"", "\n", "# Ensure that the category list is sorted by id", "\n", "lvis_categories", "=", "sorted", "(", "LVIS_V1_CATEGORIES", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "\n", "thing_classes", "=", "[", "k", "[", "\"synonyms\"", "]", "[", "0", "]", "for", "k", "in", "lvis_categories", "]", "\n", "meta", "=", "{", "\"thing_classes\"", ":", "thing_classes", "}", "\n", "return", "meta", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin.register_all_coco": [[106, 144], ["_PREDEFINED_SPLITS_COCO.items", "_PREDEFINED_SPLITS_COCO_PANOPTIC.items", "splits_per_dataset.items", "detectron2.data.MetadataCatalog.get", "coco_panoptic.register_coco_panoptic_separated", "coco_panoptic.register_coco_panoptic", "coco.register_coco_instances", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "os.path.join", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.register_coco_panoptic_separated", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco_panoptic.register_coco_panoptic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.register_coco_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_builtin_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_builtin_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_builtin_metadata"], ["def", "register_all_coco", "(", "root", ")", ":", "\n", "    ", "for", "dataset_name", ",", "splits_per_dataset", "in", "_PREDEFINED_SPLITS_COCO", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "(", "image_root", ",", "json_file", ")", "in", "splits_per_dataset", ".", "items", "(", ")", ":", "\n", "# Assume pre-defined datasets live in `./datasets`.", "\n", "            ", "register_coco_instances", "(", "\n", "key", ",", "\n", "_get_builtin_metadata", "(", "dataset_name", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "json_file", ")", "if", "\"://\"", "not", "in", "json_file", "else", "json_file", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "image_root", ")", ",", "\n", ")", "\n", "\n", "", "", "for", "(", "\n", "prefix", ",", "\n", "(", "panoptic_root", ",", "panoptic_json", ",", "semantic_root", ")", ",", "\n", ")", "in", "_PREDEFINED_SPLITS_COCO_PANOPTIC", ".", "items", "(", ")", ":", "\n", "        ", "prefix_instances", "=", "prefix", "[", ":", "-", "len", "(", "\"_panoptic\"", ")", "]", "\n", "instances_meta", "=", "MetadataCatalog", ".", "get", "(", "prefix_instances", ")", "\n", "image_root", ",", "instances_json", "=", "instances_meta", ".", "image_root", ",", "instances_meta", ".", "json_file", "\n", "# The \"separated\" version of COCO panoptic segmentation dataset,", "\n", "# e.g. used by Panoptic FPN", "\n", "register_coco_panoptic_separated", "(", "\n", "prefix", ",", "\n", "_get_builtin_metadata", "(", "\"coco_panoptic_separated\"", ")", ",", "\n", "image_root", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_root", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_json", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "semantic_root", ")", ",", "\n", "instances_json", ",", "\n", ")", "\n", "# The \"standard\" version of COCO panoptic segmentation dataset,", "\n", "# e.g. used by Panoptic-DeepLab", "\n", "register_coco_panoptic", "(", "\n", "prefix", ",", "\n", "_get_builtin_metadata", "(", "\"coco_panoptic_standard\"", ")", ",", "\n", "image_root", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_root", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "panoptic_json", ")", ",", "\n", "instances_json", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin.register_all_lvis": [[170, 178], ["_PREDEFINED_SPLITS_LVIS.items", "splits_per_dataset.items", "lvis.register_lvis_instances", "lvis.get_lvis_instances_meta", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.register_lvis_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.get_lvis_instances_meta"], ["def", "register_all_lvis", "(", "root", ")", ":", "\n", "    ", "for", "dataset_name", ",", "splits_per_dataset", "in", "_PREDEFINED_SPLITS_LVIS", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "(", "image_root", ",", "json_file", ")", "in", "splits_per_dataset", ".", "items", "(", ")", ":", "\n", "            ", "register_lvis_instances", "(", "\n", "key", ",", "\n", "get_lvis_instances_meta", "(", "dataset_name", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "json_file", ")", "if", "\"://\"", "not", "in", "json_file", "else", "json_file", ",", "\n", "os", ".", "path", ".", "join", "(", "root", ",", "image_root", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin.register_all_cityscapes": [[189, 216], ["_RAW_CITYSCAPES_SPLITS.items", "builtin_meta._get_builtin_metadata", "os.path.join", "os.path.join", "key.format", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "key.format", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "cityscapes.load_cityscapes_instances", "detectron2.data.MetadataCatalog.get", "cityscapes.load_cityscapes_semantic", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin_meta._get_builtin_metadata", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.load_cityscapes_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.cityscapes.load_cityscapes_semantic", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "register_all_cityscapes", "(", "root", ")", ":", "\n", "    ", "for", "key", ",", "(", "image_dir", ",", "gt_dir", ")", "in", "_RAW_CITYSCAPES_SPLITS", ".", "items", "(", ")", ":", "\n", "        ", "meta", "=", "_get_builtin_metadata", "(", "\"cityscapes\"", ")", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "image_dir", ")", "\n", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "gt_dir", ")", "\n", "\n", "inst_key", "=", "key", ".", "format", "(", "task", "=", "\"instance_seg\"", ")", "\n", "DatasetCatalog", ".", "register", "(", "\n", "inst_key", ",", "\n", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ":", "load_cityscapes_instances", "(", "\n", "x", ",", "y", ",", "from_json", "=", "True", ",", "to_polygons", "=", "True", "\n", ")", ",", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "inst_key", ")", ".", "set", "(", "\n", "image_dir", "=", "image_dir", ",", "gt_dir", "=", "gt_dir", ",", "evaluator_type", "=", "\"cityscapes_instance\"", ",", "**", "meta", "\n", ")", "\n", "\n", "sem_key", "=", "key", ".", "format", "(", "task", "=", "\"sem_seg\"", ")", "\n", "DatasetCatalog", ".", "register", "(", "\n", "sem_key", ",", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ":", "load_cityscapes_semantic", "(", "x", ",", "y", ")", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "sem_key", ")", ".", "set", "(", "\n", "image_dir", "=", "image_dir", ",", "\n", "gt_dir", "=", "gt_dir", ",", "\n", "evaluator_type", "=", "\"cityscapes_sem_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", "**", "meta", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin.register_all_pascal_voc": [[220, 234], ["pascal_voc.register_pascal_voc", "os.path.join", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.pascal_voc.register_pascal_voc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "register_all_pascal_voc", "(", "root", ")", ":", "\n", "    ", "SPLITS", "=", "[", "\n", "(", "\"voc_2007_trainval\"", ",", "\"VOC2007\"", ",", "\"trainval\"", ")", ",", "\n", "(", "\"voc_2007_train\"", ",", "\"VOC2007\"", ",", "\"train\"", ")", ",", "\n", "(", "\"voc_2007_val\"", ",", "\"VOC2007\"", ",", "\"val\"", ")", ",", "\n", "(", "\"voc_2007_test\"", ",", "\"VOC2007\"", ",", "\"test\"", ")", ",", "\n", "(", "\"voc_2012_trainval\"", ",", "\"VOC2012\"", ",", "\"trainval\"", ")", ",", "\n", "(", "\"voc_2012_train\"", ",", "\"VOC2012\"", ",", "\"train\"", ")", ",", "\n", "(", "\"voc_2012_val\"", ",", "\"VOC2012\"", ",", "\"val\"", ")", ",", "\n", "]", "\n", "for", "name", ",", "dirname", ",", "split", "in", "SPLITS", ":", "\n", "        ", "year", "=", "2007", "if", "\"2007\"", "in", "name", "else", "2012", "\n", "register_pascal_voc", "(", "name", ",", "os", ".", "path", ".", "join", "(", "root", ",", "dirname", ")", ",", "split", ",", "year", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "evaluator_type", "=", "\"pascal_voc\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.builtin.register_all_ade20k": [[236, 251], ["os.path.join", "os.path.join", "os.path.join", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco.load_sem_seg", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_sem_seg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "register_all_ade20k", "(", "root", ")", ":", "\n", "    ", "root", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"ADEChallengeData2016\"", ")", "\n", "for", "name", ",", "dirname", "in", "[", "(", "\"train\"", ",", "\"training\"", ")", ",", "(", "\"val\"", ",", "\"validation\"", ")", "]", ":", "\n", "        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"images\"", ",", "dirname", ")", "\n", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations_detectron2\"", ",", "dirname", ")", "\n", "name", "=", "f\"ade20k_sem_seg_{name}\"", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "lambda", "x", "=", "image_dir", ",", "y", "=", "gt_dir", ":", "load_sem_seg", "(", "y", ",", "x", ",", "gt_ext", "=", "\"png\"", ",", "image_ext", "=", "\"jpg\"", ")", "\n", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "stuff_classes", "=", "ADE20K_SEM_SEG_CATEGORIES", "[", ":", "]", ",", "\n", "image_root", "=", "image_dir", ",", "\n", "sem_seg_root", "=", "gt_dir", ",", "\n", "evaluator_type", "=", "\"sem_seg\"", ",", "\n", "ignore_label", "=", "255", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.pascal_voc.load_voc_instances": [[25, 76], ["detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.open", "numpy.loadtxt", "os.path.join", "os.path.join", "os.path.join", "ET.parse.findall", "dicts.append", "os.path.join", "detectron2.utils.file_io.PathManager.open", "xml.parse", "int", "int", "obj.find", "instances.append", "obj.find", "float", "class_names.index", "ET.parse.findall", "ET.parse.findall", "obj.find.find"], "function", ["None"], ["def", "load_voc_instances", "(", "dirname", ":", "str", ",", "split", ":", "str", ",", "class_names", ":", "Union", "[", "List", "[", "str", "]", ",", "Tuple", "[", "str", ",", "...", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Load Pascal VOC detection annotations to Detectron2 format.\n\n    Args:\n        dirname: Contain \"Annotations\", \"ImageSets\", \"JPEGImages\"\n        split (str): one of \"train\", \"test\", \"val\", \"trainval\"\n        class_names: list or tuple of class names\n    \"\"\"", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"ImageSets\"", ",", "\"Main\"", ",", "split", "+", "\".txt\"", ")", ")", "as", "f", ":", "\n", "        ", "fileids", "=", "np", ".", "loadtxt", "(", "f", ",", "dtype", "=", "np", ".", "str", ")", "\n", "\n", "# Needs to read many small annotation files. Makes sense at local", "\n", "", "annotation_dirname", "=", "PathManager", ".", "get_local_path", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"Annotations/\"", ")", ")", "\n", "dicts", "=", "[", "]", "\n", "for", "fileid", "in", "fileids", ":", "\n", "        ", "anno_file", "=", "os", ".", "path", ".", "join", "(", "annotation_dirname", ",", "fileid", "+", "\".xml\"", ")", "\n", "jpeg_file", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"JPEGImages\"", ",", "fileid", "+", "\".jpg\"", ")", "\n", "\n", "with", "PathManager", ".", "open", "(", "anno_file", ")", "as", "f", ":", "\n", "            ", "tree", "=", "ET", ".", "parse", "(", "f", ")", "\n", "\n", "", "r", "=", "{", "\n", "\"file_name\"", ":", "jpeg_file", ",", "\n", "\"image_id\"", ":", "fileid", ",", "\n", "\"height\"", ":", "int", "(", "tree", ".", "findall", "(", "\"./size/height\"", ")", "[", "0", "]", ".", "text", ")", ",", "\n", "\"width\"", ":", "int", "(", "tree", ".", "findall", "(", "\"./size/width\"", ")", "[", "0", "]", ".", "text", ")", ",", "\n", "}", "\n", "instances", "=", "[", "]", "\n", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "\"object\"", ")", ":", "\n", "            ", "cls", "=", "obj", ".", "find", "(", "\"name\"", ")", ".", "text", "\n", "# We include \"difficult\" samples in training.", "\n", "# Based on limited experiments, they don't hurt accuracy.", "\n", "# difficult = int(obj.find(\"difficult\").text)", "\n", "# if difficult == 1:", "\n", "# continue", "\n", "bbox", "=", "obj", ".", "find", "(", "\"bndbox\"", ")", "\n", "bbox", "=", "[", "float", "(", "bbox", ".", "find", "(", "x", ")", ".", "text", ")", "for", "x", "in", "[", "\"xmin\"", ",", "\"ymin\"", ",", "\"xmax\"", ",", "\"ymax\"", "]", "]", "\n", "# Original annotations are integers in the range [1, W or H]", "\n", "# Assuming they mean 1-based pixel indices (inclusive),", "\n", "# a box with annotation (xmin=1, xmax=W) covers the whole image.", "\n", "# In coordinate space this is represented by (xmin=0, xmax=W)", "\n", "bbox", "[", "0", "]", "-=", "1.0", "\n", "bbox", "[", "1", "]", "-=", "1.0", "\n", "instances", ".", "append", "(", "\n", "{", "\"category_id\"", ":", "class_names", ".", "index", "(", "cls", ")", ",", "\"bbox\"", ":", "bbox", ",", "\"bbox_mode\"", ":", "BoxMode", ".", "XYXY_ABS", "}", "\n", ")", "\n", "", "r", "[", "\"annotations\"", "]", "=", "instances", "\n", "dicts", ".", "append", "(", "r", ")", "\n", "", "return", "dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.pascal_voc.register_pascal_voc": [[78, 82], ["detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "pascal_voc.load_voc_instances", "detectron2.data.MetadataCatalog.get", "list"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.pascal_voc.load_voc_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "register_pascal_voc", "(", "name", ",", "dirname", ",", "split", ",", "year", ",", "class_names", "=", "CLASS_NAMES", ")", ":", "\n", "    ", "DatasetCatalog", ".", "register", "(", "name", ",", "lambda", ":", "load_voc_instances", "(", "dirname", ",", "split", ",", "class_names", ")", ")", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "thing_classes", "=", "list", "(", "class_names", ")", ",", "dirname", "=", "dirname", ",", "year", "=", "year", ",", "split", "=", "split", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.get_metadata": [[131, 152], ["utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._load_coco_annotations": [[154, 174], ["logging.getLogger", "fvcore.common.timer.Timer", "contextlib.redirect_stdout", "COCO", "fvcore.common.timer.Timer.seconds", "logging.getLogger.info", "io.StringIO", "fvcore.common.timer.Timer.seconds"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._add_categories_metadata": [[176, 181], ["detectron2.data.MetadataCatalog.get", "logging.getLogger", "logging.getLogger.info"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._verify_annotations_have_unique_ids": [[183, 192], ["len", "len", "set"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._maybe_add_bbox": [[195, 200], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._maybe_add_segm": [[202, 212], ["isinstance", "len", "len", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._maybe_add_keypoints": [[214, 226], ["enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._maybe_add_densepose": [[228, 232], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco._combine_images_with_annotations": [[234, 271], ["zip", "os.path.join", "dataset_dicts.append", "coco.create_video_frame_mapping", "img_dict.get", "coco._maybe_add_bbox", "coco._maybe_add_segm", "coco._maybe_add_keypoints", "coco._maybe_add_densepose", "objs.append", "ann_dict.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.create_video_frame_mapping", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_segm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_keypoints", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_densepose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.get_contiguous_id_to_category_id_map": [[273, 281], ["cat_id_2_cont_id.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.maybe_filter_categories_cocoapi": [[283, 310], ["detectron2.data.MetadataCatalog.get", "coco.get_contiguous_id_to_category_id_map", "coco_api.createIndex", "anns.append", "cats.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.get_contiguous_id_to_category_id_map"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.maybe_filter_and_map_categories_cocoapi": [[312, 335], ["detectron2.data.MetadataCatalog.get", "coco_api.createIndex", "cats.append", "anns.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.create_video_frame_mapping": [[337, 345], ["collections.defaultdict", "detectron2.data.MetadataCatalog.get().set", "d.get", "mapping[].update", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.register_dataset": [[391, 416], ["utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "coco.load_coco_json", "detectron2.data.MetadataCatalog.get", "coco.get_metadata"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.load_coco_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.get_metadata"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.register_datasets": [[419, 433], ["coco.register_dataset"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.register_dataset"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.chimpnsee.register_dataset": [[13, 28], ["utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "register_dataset", "(", "datasets_root", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "def", "empty_load_callback", "(", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "video_list_fpath", "=", "maybe_prepend_base_path", "(", "\n", "datasets_root", ",", "\n", "\"chimpnsee/cdna.eva.mpg.de/video_list.txt\"", ",", "\n", ")", "\n", "video_base_path", "=", "maybe_prepend_base_path", "(", "datasets_root", ",", "\"chimpnsee/cdna.eva.mpg.de\"", ")", "\n", "\n", "DatasetCatalog", ".", "register", "(", "CHIMPNSEE_DATASET_NAME", ",", "empty_load_callback", ")", "\n", "MetadataCatalog", ".", "get", "(", "CHIMPNSEE_DATASET_NAME", ")", ".", "set", "(", "\n", "dataset_type", "=", "DatasetType", ".", "VIDEO_LIST", ",", "\n", "video_list_fpath", "=", "video_list_fpath", ",", "\n", "video_base_path", "=", "video_base_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._load_lvis_annotations": [[44, 64], ["detectron2.utils.file_io.PathManager.get_local_path", "logging.getLogger", "fvcore.common.timer.Timer", "LVIS", "fvcore.common.timer.Timer.seconds", "logging.getLogger.info", "fvcore.common.timer.Timer.seconds"], "function", ["None"], ["\n", "from", "lvis", "import", "LVIS", "\n", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "lvis_api", "=", "LVIS", "(", "json_file", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._add_categories_metadata": [[66, 73], ["detectron2.data.datasets.lvis.get_lvis_instances_meta", "detectron2.data.MetadataCatalog.get", "logging.getLogger", "logging.getLogger.info", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.get_lvis_instances_meta", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["        ", "logger", ".", "info", "(", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "", "if", "dataset_name", "is", "not", "None", ":", "\n", "        ", "meta", "=", "get_lvis_instances_meta", "(", "dataset_name", ")", "\n", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", ".", "set", "(", "**", "meta", ")", "\n", "\n", "# sort indices for reproducible results", "\n", "", "img_ids", "=", "sorted", "(", "lvis_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._verify_annotations_have_unique_ids": [[75, 79], ["len", "len", "set"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["# {'license': 4,", "\n", "#  'url': 'http://farm6.staticflickr.com/5454/9413846304_881d5e5c3b_z.jpg',", "\n", "#  'file_name': 'COCO_val2014_000000001268.jpg',", "\n", "#  'height': 427,", "\n", "#  'width': 640,", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_bbox": [[82, 87], ["None"], "function", ["None"], ["imgs", "=", "lvis_api", ".", "load_imgs", "(", "img_ids", ")", "\n", "# anns is a list[list[dict]], where each dict is an annotation", "\n", "# record for an object. The inner list enumerates the objects in an image", "\n", "# and the outer list enumerates over images. Example of anns[0]:", "\n", "# [{'segmentation': [[192.81,", "\n", "#     247.09,", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_segm": [[89, 99], ["isinstance", "len", "len", "len"], "function", ["None"], ["#     219.03,", "\n", "#     249.06]],", "\n", "#   'area': 1035.749,", "\n", "#   'image_id': 1268,", "\n", "#   'bbox': [192.81, 224.8, 74.73, 33.43],", "\n", "#   'category_id': 16,", "\n", "#   'id': 42986},", "\n", "#  ...]", "\n", "anns", "=", "[", "lvis_api", ".", "img_ann_map", "[", "img_id", "]", "for", "img_id", "in", "img_ids", "]", "\n", "\n", "# Sanity check that each annotation has a unique id", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_keypoints": [[101, 113], ["enumerate"], "function", ["None"], ["assert", "len", "(", "set", "(", "ann_ids", ")", ")", "==", "len", "(", "ann_ids", ")", ",", "\"Annotation ids in '{}' are not unique\"", ".", "format", "(", "\n", "json_file", "\n", ")", "\n", "\n", "imgs_anns", "=", "list", "(", "zip", "(", "imgs", ",", "anns", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loaded {} images in the LVIS format from {}\"", ".", "format", "(", "len", "(", "imgs_anns", ")", ",", "json_file", ")", ")", "\n", "\n", "def", "get_file_name", "(", "img_root", ",", "img_dict", ")", ":", "\n", "# Determine the path including the split folder (\"train2017\", \"val2017\", \"test2017\") from", "\n", "# the coco_url field. Example:", "\n", "#   'coco_url': 'http://images.cocodataset.org/train2017/000000155379.jpg'", "\n", "        ", "split_folder", ",", "file_name", "=", "img_dict", "[", "\"coco_url\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "2", ":", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._maybe_add_densepose": [[115, 119], ["None"], "function", ["None"], ["\n", "", "dataset_dicts", "=", "[", "]", "\n", "\n", "for", "(", "img_dict", ",", "anno_dict_list", ")", "in", "imgs_anns", ":", "\n", "        ", "record", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis._combine_images_with_annotations": [[121, 161], ["zip", "os.path.join", "lvis._combine_images_with_annotations.get_file_name"], "function", ["None"], ["record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "record", "[", "\"not_exhaustive_category_ids\"", "]", "=", "img_dict", ".", "get", "(", "\"not_exhaustive_category_ids\"", ",", "[", "]", ")", "\n", "record", "[", "\"neg_category_ids\"", "]", "=", "img_dict", ".", "get", "(", "\"neg_category_ids\"", ",", "[", "]", ")", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "anno_dict_list", ":", "\n", "# Check that the image_id in this annotation is the same as", "\n", "# the image_id we're looking at.", "\n", "# This fails only when the data parsing logic or the annotation file is buggy.", "\n", "            ", "assert", "anno", "[", "\"image_id\"", "]", "==", "image_id", "\n", "obj", "=", "{", "\"bbox\"", ":", "anno", "[", "\"bbox\"", "]", ",", "\"bbox_mode\"", ":", "BoxMode", ".", "XYWH_ABS", "}", "\n", "# LVIS data loader can be used to load COCO dataset categories. In this case `meta`", "\n", "# variable will have a field with COCO-specific category mapping.", "\n", "if", "dataset_name", "is", "not", "None", "and", "\"thing_dataset_id_to_contiguous_id\"", "in", "meta", ":", "\n", "                ", "obj", "[", "\"category_id\"", "]", "=", "meta", "[", "\"thing_dataset_id_to_contiguous_id\"", "]", "[", "anno", "[", "\"category_id\"", "]", "]", "\n", "", "else", ":", "\n", "                ", "obj", "[", "\"category_id\"", "]", "=", "anno", "[", "\"category_id\"", "]", "-", "1", "# Convert 1-indexed to 0-indexed", "\n", "", "segm", "=", "anno", "[", "\"segmentation\"", "]", "# list[list[float]]", "\n", "# filter out invalid polygons (< 3 points)", "\n", "valid_segm", "=", "[", "poly", "for", "poly", "in", "segm", "if", "len", "(", "poly", ")", "%", "2", "==", "0", "and", "len", "(", "poly", ")", ">=", "6", "]", "\n", "assert", "len", "(", "segm", ")", "==", "len", "(", "\n", "valid_segm", "\n", ")", ",", "\"Annotation contains an invalid polygon with < 3 points\"", "\n", "assert", "len", "(", "segm", ")", ">", "0", "\n", "obj", "[", "\"segmentation\"", "]", "=", "segm", "\n", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "return", "dataset_dicts", "\n", "\n", "\n", "", "def", "get_lvis_instances_meta", "(", "dataset_name", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.register_dataset": [[210, 236], ["utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "lvis.load_lvis_json", "detectron2.data.MetadataCatalog.get", "coco.get_metadata"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.load_lvis_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.get_metadata"], ["from", "detectron2", ".", "utils", ".", "logger", "import", "setup_logger", "\n", "from", "PIL", "import", "Image", "\n", "import", "detectron2", ".", "data", ".", "datasets", "# noqa # add pre-defined metadata", "\n", "from", "detectron2", ".", "utils", ".", "visualizer", "import", "Visualizer", "\n", "\n", "logger", "=", "setup_logger", "(", "name", "=", "__name__", ")", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "sys", ".", "argv", "[", "3", "]", ")", "\n", "\n", "dicts", "=", "load_lvis_json", "(", "sys", ".", "argv", "[", "1", "]", ",", "sys", ".", "argv", "[", "2", "]", ",", "sys", ".", "argv", "[", "3", "]", ")", "\n", "logger", ".", "info", "(", "\"Done loading {} samples.\"", ".", "format", "(", "len", "(", "dicts", ")", ")", ")", "\n", "\n", "dirname", "=", "\"lvis-data-vis\"", "\n", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "for", "d", "in", "dicts", "[", ":", "int", "(", "sys", ".", "argv", "[", "4", "]", ")", "]", ":", "\n", "        ", "img", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "d", "[", "\"file_name\"", "]", ")", ")", "\n", "visualizer", "=", "Visualizer", "(", "img", ",", "metadata", "=", "meta", ")", "\n", "vis", "=", "visualizer", ".", "draw_dataset_dict", "(", "d", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "os", ".", "path", ".", "basename", "(", "d", "[", "\"file_name\"", "]", ")", ")", "\n", "vis", ".", "save", "(", "fpath", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.register_datasets": [[239, 253], ["lvis.register_dataset"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.lvis.register_dataset"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.__init__.evaluate": [[7, 28], ["dict", "isinstance", "coco.coco_evaluation", "isinstance", "voc.voc_evaluation", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.__init__.coco_evaluation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.__init__.voc_evaluation"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.fast_eval_api.COCOeval_opt.evaluate": [[19, 96], ["time.time", "logger.info", "list", "sorted", "fast_eval_api.COCOeval_opt._prepare", "detectron2._C.COCOevalEvaluateImages", "copy.deepcopy", "time.time", "logger.info", "numpy.unique", "list", "computeIoU", "numpy.unique", "detectron2._C.InstanceAnnotation", "instances_cpp.append", "fast_eval_api.COCOeval_opt.evaluate.convert_instances_to_cpp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._prepare", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeIoU"], ["def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run per image evaluation on given images and store results in self.evalImgs_cpp, a\n        datastructure that isn't readable from Python but is used by a c++ implementation of\n        accumulate().  Unlike the original COCO PythonAPI, we don't populate the datastructure\n        self.evalImgs because this datastructure is a computational bottleneck.\n        :return: None\n        \"\"\"", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "p", "=", "self", ".", "params", "\n", "# add backward compatibility if useSegm is specified in params", "\n", "if", "p", ".", "useSegm", "is", "not", "None", ":", "\n", "            ", "p", ".", "iouType", "=", "\"segm\"", "if", "p", ".", "useSegm", "==", "1", "else", "\"bbox\"", "\n", "", "logger", ".", "info", "(", "\"Evaluate annotation type *{}*\"", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "p", ".", "imgIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "imgIds", ")", ")", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "p", ".", "catIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "catIds", ")", ")", "\n", "", "p", ".", "maxDets", "=", "sorted", "(", "p", ".", "maxDets", ")", "\n", "self", ".", "params", "=", "p", "\n", "\n", "self", ".", "_prepare", "(", ")", "# bottleneck", "\n", "\n", "# loop through images, area range, max detection number", "\n", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "else", "[", "-", "1", "]", "\n", "\n", "if", "p", ".", "iouType", "==", "\"segm\"", "or", "p", ".", "iouType", "==", "\"bbox\"", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeIoU", "\n", "", "elif", "p", ".", "iouType", "==", "\"keypoints\"", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeOks", "\n", "", "self", ".", "ious", "=", "{", "\n", "(", "imgId", ",", "catId", ")", ":", "computeIoU", "(", "imgId", ",", "catId", ")", "for", "imgId", "in", "p", ".", "imgIds", "for", "catId", "in", "catIds", "\n", "}", "# bottleneck", "\n", "\n", "maxDet", "=", "p", ".", "maxDets", "[", "-", "1", "]", "\n", "\n", "# <<<< Beginning of code differences with original COCO API", "\n", "def", "convert_instances_to_cpp", "(", "instances", ",", "is_det", "=", "False", ")", ":", "\n", "# Convert annotations for a list of instances in an image to a format that's fast", "\n", "# to access in C++", "\n", "            ", "instances_cpp", "=", "[", "]", "\n", "for", "instance", "in", "instances", ":", "\n", "                ", "instance_cpp", "=", "_C", ".", "InstanceAnnotation", "(", "\n", "int", "(", "instance", "[", "\"id\"", "]", ")", ",", "\n", "instance", "[", "\"score\"", "]", "if", "is_det", "else", "instance", ".", "get", "(", "\"score\"", ",", "0.0", ")", ",", "\n", "instance", "[", "\"area\"", "]", ",", "\n", "bool", "(", "instance", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", ",", "\n", "bool", "(", "instance", ".", "get", "(", "\"ignore\"", ",", "0", ")", ")", ",", "\n", ")", "\n", "instances_cpp", ".", "append", "(", "instance_cpp", ")", "\n", "", "return", "instances_cpp", "\n", "\n", "# Convert GT annotations, detections, and IOUs to a format that's fast to access in C++", "\n", "", "ground_truth_instances", "=", "[", "\n", "[", "convert_instances_to_cpp", "(", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", ")", "for", "catId", "in", "p", ".", "catIds", "]", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "detected_instances", "=", "[", "\n", "[", "convert_instances_to_cpp", "(", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", ",", "is_det", "=", "True", ")", "for", "catId", "in", "p", ".", "catIds", "]", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "ious", "=", "[", "[", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "for", "catId", "in", "catIds", "]", "for", "imgId", "in", "p", ".", "imgIds", "]", "\n", "\n", "if", "not", "p", ".", "useCats", ":", "\n", "# For each image, flatten per-category lists into a single list", "\n", "            ", "ground_truth_instances", "=", "[", "[", "[", "o", "for", "c", "in", "i", "for", "o", "in", "c", "]", "]", "for", "i", "in", "ground_truth_instances", "]", "\n", "detected_instances", "=", "[", "[", "[", "o", "for", "c", "in", "i", "for", "o", "in", "c", "]", "]", "for", "i", "in", "detected_instances", "]", "\n", "\n", "# Call C++ implementation of self.evaluateImgs()", "\n", "", "self", ".", "_evalImgs_cpp", "=", "_C", ".", "COCOevalEvaluateImages", "(", "\n", "p", ".", "areaRng", ",", "maxDet", ",", "p", ".", "iouThrs", ",", "ious", ",", "ground_truth_instances", ",", "detected_instances", "\n", ")", "\n", "self", ".", "_evalImgs", "=", "None", "\n", "\n", "self", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"COCOeval_opt.evaluate() finished in {:0.2f} seconds.\"", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "# >>>> End of code differences with original COCO API", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.fast_eval_api.COCOeval_opt.accumulate": [[98, 122], ["logger.info", "time.time", "hasattr", "detectron2._C.COCOevalAccumulate", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "time.time", "logger.info", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Accumulate per image evaluation results and store the result in self.eval.  Does not\n        support changing parameter settings from those used by self.evaluate()\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Accumulating evaluation results...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "assert", "hasattr", "(", "\n", "self", ",", "\"_evalImgs_cpp\"", "\n", ")", ",", "\"evaluate() must be called before accmulate() is called.\"", "\n", "\n", "self", ".", "eval", "=", "_C", ".", "COCOevalAccumulate", "(", "self", ".", "_paramsEval", ",", "self", ".", "_evalImgs_cpp", ")", "\n", "\n", "# recall is num_iou_thresholds X num_categories X num_area_ranges X num_max_detections", "\n", "self", ".", "eval", "[", "\"recall\"", "]", "=", "np", ".", "array", "(", "self", ".", "eval", "[", "\"recall\"", "]", ")", ".", "reshape", "(", "\n", "self", ".", "eval", "[", "\"counts\"", "]", "[", ":", "1", "]", "+", "self", ".", "eval", "[", "\"counts\"", "]", "[", "2", ":", "]", "\n", ")", "\n", "\n", "# precision and scores are num_iou_thresholds X num_recall_thresholds X num_categories X", "\n", "# num_area_ranges X num_max_detections", "\n", "self", ".", "eval", "[", "\"precision\"", "]", "=", "np", ".", "array", "(", "self", ".", "eval", "[", "\"precision\"", "]", ")", ".", "reshape", "(", "self", ".", "eval", "[", "\"counts\"", "]", ")", "\n", "self", ".", "eval", "[", "\"scores\"", "]", "=", "np", ".", "array", "(", "self", ".", "eval", "[", "\"scores\"", "]", ")", ".", "reshape", "(", "self", ".", "eval", "[", "\"counts\"", "]", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"COCOeval_opt.accumulate() finished in {:0.2f} seconds.\"", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.sem_seg_evaluation.SemSegEvaluator.__init__": [[24, 73], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "len", "sem_seg_evaluation.SemSegEvaluator._logger.warn", "sem_seg_evaluation.SemSegEvaluator._logger.warn", "detectron2.data.DatasetCatalog.get", "c2d.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "None", ",", "\n", "*", ",", "\n", "num_classes", "=", "None", ",", "\n", "ignore_label", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n            distributed (bool): if True, will collect results from all ranks for evaluation.\n                Otherwise, will evaluate the results in the current process.\n            output_dir (str): an output directory to dump results.\n            num_classes, ignore_label: deprecated argument\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\n", "\"SemSegEvaluator(num_classes) is deprecated! It should be obtained from metadata.\"", "\n", ")", "\n", "", "if", "ignore_label", "is", "not", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\n", "\"SemSegEvaluator(ignore_label) is deprecated! It should be obtained from metadata.\"", "\n", ")", "\n", "", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "input_file_to_gt_file", "=", "{", "\n", "dataset_record", "[", "\"file_name\"", "]", ":", "dataset_record", "[", "\"sem_seg_file_name\"", "]", "\n", "for", "dataset_record", "in", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", "\n", "}", "\n", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "# Dict that maps contiguous training ids to COCO category ids", "\n", "try", ":", "\n", "            ", "c2d", "=", "meta", ".", "stuff_dataset_id_to_contiguous_id", "\n", "self", ".", "_contiguous_id_to_dataset_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "c2d", ".", "items", "(", ")", "}", "\n", "", "except", "AttributeError", ":", "\n", "            ", "self", ".", "_contiguous_id_to_dataset_id", "=", "None", "\n", "", "self", ".", "_class_names", "=", "meta", ".", "stuff_classes", "\n", "self", ".", "_num_classes", "=", "len", "(", "meta", ".", "stuff_classes", ")", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "_num_classes", "==", "num_classes", ",", "f\"{self._num_classes} != {num_classes}\"", "\n", "", "self", ".", "_ignore_label", "=", "ignore_label", "if", "ignore_label", "is", "not", "None", "else", "meta", ".", "ignore_label", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.sem_seg_evaluation.SemSegEvaluator.reset": [[74, 77], ["numpy.zeros"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_conf_matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "_num_classes", "+", "1", ",", "self", ".", "_num_classes", "+", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.sem_seg_evaluation.SemSegEvaluator.process": [[78, 102], ["zip", "output[].argmax().to", "numpy.array", "numpy.bincount().reshape", "sem_seg_evaluation.SemSegEvaluator._predictions.extend", "detectron2.utils.file_io.PathManager.open", "numpy.array", "sem_seg_evaluation.SemSegEvaluator.encode_json_sem_seg", "output[].argmax", "PIL.open", "numpy.bincount", "numpy.array.reshape", "numpy.array.reshape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.sem_seg_evaluation.SemSegEvaluator.encode_json_sem_seg"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a model.\n                It is a list of dicts. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\".\n            outputs: the outputs of a model. It is either list of semantic segmentation predictions\n                (Tensor [H, W]) or list of dicts with key \"sem_seg\" that contains semantic\n                segmentation prediction in the same format.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "output", "=", "output", "[", "\"sem_seg\"", "]", ".", "argmax", "(", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "pred", "=", "np", ".", "array", "(", "output", ",", "dtype", "=", "np", ".", "int", ")", "\n", "with", "PathManager", ".", "open", "(", "self", ".", "input_file_to_gt_file", "[", "input", "[", "\"file_name\"", "]", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "gt", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "f", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "", "gt", "[", "gt", "==", "self", ".", "_ignore_label", "]", "=", "self", ".", "_num_classes", "\n", "\n", "self", ".", "_conf_matrix", "+=", "np", ".", "bincount", "(", "\n", "(", "self", ".", "_num_classes", "+", "1", ")", "*", "pred", ".", "reshape", "(", "-", "1", ")", "+", "gt", ".", "reshape", "(", "-", "1", ")", ",", "\n", "minlength", "=", "self", ".", "_conf_matrix", ".", "size", ",", "\n", ")", ".", "reshape", "(", "self", ".", "_conf_matrix", ".", "shape", ")", "\n", "\n", "self", ".", "_predictions", ".", "extend", "(", "self", ".", "encode_json_sem_seg", "(", "pred", ",", "input", "[", "\"file_name\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.sem_seg_evaluation.SemSegEvaluator.evaluate": [[103, 163], ["numpy.full", "numpy.full", "[].astype", "numpy.sum().astype", "numpy.sum().astype", "numpy.sum", "enumerate", "enumerate", "collections.OrderedDict", "sem_seg_evaluation.SemSegEvaluator._logger.info", "detectron2.utils.comm.synchronize", "detectron2.utils.comm.all_gather", "detectron2.utils.comm.all_gather", "list", "numpy.zeros_like", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "os.path.join", "itertools.chain", "detectron2.utils.comm.is_main_process", "detectron2.utils.file_io.PathManager.open", "f.write", "numpy.sum", "numpy.sum", "detectron2.utils.file_io.PathManager.open", "torch.save", "json.dumps", "sem_seg_evaluation.SemSegEvaluator._conf_matrix.diagonal"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Evaluates standard semantic segmentation metrics (http://cocodataset.org/#stuff-eval):\n\n        * Mean intersection-over-union averaged across classes (mIoU)\n        * Frequency Weighted IoU (fwIoU)\n        * Mean pixel accuracy averaged across classes (mACC)\n        * Pixel Accuracy (pACC)\n        \"\"\"", "\n", "if", "self", ".", "_distributed", ":", "\n", "            ", "synchronize", "(", ")", "\n", "conf_matrix_list", "=", "all_gather", "(", "self", ".", "_conf_matrix", ")", "\n", "self", ".", "_predictions", "=", "all_gather", "(", "self", ".", "_predictions", ")", "\n", "self", ".", "_predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "self", ".", "_predictions", ")", ")", "\n", "if", "not", "is_main_process", "(", ")", ":", "\n", "                ", "return", "\n", "\n", "", "self", ".", "_conf_matrix", "=", "np", ".", "zeros_like", "(", "self", ".", "_conf_matrix", ")", "\n", "for", "conf_matrix", "in", "conf_matrix_list", ":", "\n", "                ", "self", ".", "_conf_matrix", "+=", "conf_matrix", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"sem_seg_predictions.json\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "_predictions", ")", ")", "\n", "\n", "", "", "acc", "=", "np", ".", "full", "(", "self", ".", "_num_classes", ",", "np", ".", "nan", ",", "dtype", "=", "np", ".", "float", ")", "\n", "iou", "=", "np", ".", "full", "(", "self", ".", "_num_classes", ",", "np", ".", "nan", ",", "dtype", "=", "np", ".", "float", ")", "\n", "tp", "=", "self", ".", "_conf_matrix", ".", "diagonal", "(", ")", "[", ":", "-", "1", "]", ".", "astype", "(", "np", ".", "float", ")", "\n", "pos_gt", "=", "np", ".", "sum", "(", "self", ".", "_conf_matrix", "[", ":", "-", "1", ",", ":", "-", "1", "]", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "class_weights", "=", "pos_gt", "/", "np", ".", "sum", "(", "pos_gt", ")", "\n", "pos_pred", "=", "np", ".", "sum", "(", "self", ".", "_conf_matrix", "[", ":", "-", "1", ",", ":", "-", "1", "]", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "acc_valid", "=", "pos_gt", ">", "0", "\n", "acc", "[", "acc_valid", "]", "=", "tp", "[", "acc_valid", "]", "/", "pos_gt", "[", "acc_valid", "]", "\n", "iou_valid", "=", "(", "pos_gt", "+", "pos_pred", ")", ">", "0", "\n", "union", "=", "pos_gt", "+", "pos_pred", "-", "tp", "\n", "iou", "[", "acc_valid", "]", "=", "tp", "[", "acc_valid", "]", "/", "union", "[", "acc_valid", "]", "\n", "macc", "=", "np", ".", "sum", "(", "acc", "[", "acc_valid", "]", ")", "/", "np", ".", "sum", "(", "acc_valid", ")", "\n", "miou", "=", "np", ".", "sum", "(", "iou", "[", "acc_valid", "]", ")", "/", "np", ".", "sum", "(", "iou_valid", ")", "\n", "fiou", "=", "np", ".", "sum", "(", "iou", "[", "acc_valid", "]", "*", "class_weights", "[", "acc_valid", "]", ")", "\n", "pacc", "=", "np", ".", "sum", "(", "tp", ")", "/", "np", ".", "sum", "(", "pos_gt", ")", "\n", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"mIoU\"", "]", "=", "100", "*", "miou", "\n", "res", "[", "\"fwIoU\"", "]", "=", "100", "*", "fiou", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "self", ".", "_class_names", ")", ":", "\n", "            ", "res", "[", "\"IoU-{}\"", ".", "format", "(", "name", ")", "]", "=", "100", "*", "iou", "[", "i", "]", "\n", "", "res", "[", "\"mACC\"", "]", "=", "100", "*", "macc", "\n", "res", "[", "\"pACC\"", "]", "=", "100", "*", "pacc", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "self", ".", "_class_names", ")", ":", "\n", "            ", "res", "[", "\"ACC-{}\"", ".", "format", "(", "name", ")", "]", "=", "100", "*", "acc", "[", "i", "]", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"sem_seg_evaluation.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "res", ",", "f", ")", "\n", "", "", "results", "=", "OrderedDict", "(", "{", "\"sem_seg\"", ":", "res", "}", ")", "\n", "self", ".", "_logger", ".", "info", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.sem_seg_evaluation.SemSegEvaluator.encode_json_sem_seg": [[164, 185], ["numpy.unique", "mask_rle[].decode", "json_list.append", "int", "pycocotools.encode", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["", "def", "encode_json_sem_seg", "(", "self", ",", "sem_seg", ",", "input_file_name", ")", ":", "\n", "        ", "\"\"\"\n        Convert semantic segmentation to COCO stuff format with segments encoded as RLEs.\n        See http://cocodataset.org/#format-results\n        \"\"\"", "\n", "json_list", "=", "[", "]", "\n", "for", "label", "in", "np", ".", "unique", "(", "sem_seg", ")", ":", "\n", "            ", "if", "self", ".", "_contiguous_id_to_dataset_id", "is", "not", "None", ":", "\n", "                ", "assert", "(", "\n", "label", "in", "self", ".", "_contiguous_id_to_dataset_id", "\n", ")", ",", "\"Label {} is not in the metadata info for {}\"", ".", "format", "(", "label", ",", "self", ".", "_dataset_name", ")", "\n", "dataset_id", "=", "self", ".", "_contiguous_id_to_dataset_id", "[", "label", "]", "\n", "", "else", ":", "\n", "                ", "dataset_id", "=", "int", "(", "label", ")", "\n", "", "mask", "=", "(", "sem_seg", "==", "label", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "mask_rle", "=", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", ":", ",", ":", ",", "None", "]", ",", "order", "=", "\"F\"", ")", ")", "[", "0", "]", "\n", "mask_rle", "[", "\"counts\"", "]", "=", "mask_rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "json_list", ".", "append", "(", "\n", "{", "\"file_name\"", ":", "input_file_name", ",", "\"category_id\"", ":", "dataset_id", ",", "\"segmentation\"", ":", "mask_rle", "}", "\n", ")", "\n", "", "return", "json_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator.__init__": [[28, 65], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "LVIS", "isinstance", "lvis_evaluation.LVISEvaluator._logger.warn", "len", "lvis_evaluation.LVISEvaluator._lvis_api.get_ann_ids"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "__init__", "(", "self", ",", "dataset_name", ",", "tasks", "=", "None", ",", "distributed", "=", "True", ",", "output_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n                It must have the following corresponding metadata:\n                \"json_file\": the path to the LVIS format annotation\n            tasks (tuple[str]): tasks that can be evaluated under the given\n                configuration. A task is one of \"bbox\", \"segm\".\n                By default, will infer this automatically from predictions.\n            distributed (True): if True, will collect results from all ranks for evaluation.\n                Otherwise, will evaluate the results in the current process.\n            output_dir (str): optional, an output directory to dump results.\n        \"\"\"", "\n", "from", "lvis", "import", "LVIS", "\n", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "if", "tasks", "is", "not", "None", "and", "isinstance", "(", "tasks", ",", "CfgNode", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\n", "\"COCO Evaluator instantiated using config, this is deprecated behavior.\"", "\n", "\" Please pass in explicit arguments instead.\"", "\n", ")", "\n", "self", ".", "_tasks", "=", "None", "# Infering it from predictions should be better", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tasks", "=", "tasks", "\n", "\n", "", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "json_file", ")", "\n", "self", ".", "_lvis_api", "=", "LVIS", "(", "json_file", ")", "\n", "# Test set json files do not contain annotations (evaluation must be", "\n", "# performed using the LVIS evaluation server).", "\n", "self", ".", "_do_evaluation", "=", "len", "(", "self", ".", "_lvis_api", ".", "get_ann_ids", "(", ")", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator.reset": [[66, 68], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator.process": [[69, 87], ["zip", "lvis_evaluation.LVISEvaluator._predictions.append", "output[].to", "coco_evaluation.instances_to_coco_json", "output[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.instances_to_coco_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a LVIS model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a LVIS model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "prediction", "[", "\"instances\"", "]", "=", "instances_to_coco_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator.evaluate": [[88, 116], ["collections.OrderedDict", "copy.deepcopy", "detectron2.synchronize", "detectron2.gather", "list", "len", "lvis_evaluation.LVISEvaluator._logger.warning", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "lvis_evaluation.LVISEvaluator._eval_box_proposals", "lvis_evaluation.LVISEvaluator._eval_predictions", "itertools.chain", "detectron2.is_main_process", "detectron2.utils.file_io.PathManager.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator._eval_predictions", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_distributed", ":", "\n", "            ", "comm", ".", "synchronize", "(", ")", "\n", "predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "predictions", ")", ")", "\n", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "return", "\n", "", "", "else", ":", "\n", "            ", "predictions", "=", "self", ".", "_predictions", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\"[LVISEvaluator] Did not receive valid predictions.\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"instances_predictions.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "predictions", ",", "f", ")", "\n", "\n", "", "", "self", ".", "_results", "=", "OrderedDict", "(", ")", "\n", "if", "\"proposals\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_box_proposals", "(", "predictions", ")", "\n", "", "if", "\"instances\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_predictions", "(", "predictions", ")", "\n", "# Copy so the caller can do whatever with results", "\n", "", "return", "copy", ".", "deepcopy", "(", "self", ".", "_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator._tasks_from_predictions": [[117, 122], ["None"], "methods", ["None"], ["", "def", "_tasks_from_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "for", "pred", "in", "predictions", ":", "\n", "            ", "if", "\"segmentation\"", "in", "pred", ":", "\n", "                ", "return", "(", "\"bbox\"", ",", "\"segm\"", ")", "\n", "", "", "return", "(", "\"bbox\"", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator._eval_predictions": [[123, 164], ["lvis_evaluation.LVISEvaluator._logger.info", "list", "hasattr", "lvis_evaluation.LVISEvaluator._logger.info", "sorted", "itertools.chain", "lvis_evaluation.LVISEvaluator._tasks_from_predictions", "os.path.join", "lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation._evaluate_predictions_on_lvis", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "lvis_evaluation.LVISEvaluator._metadata.thing_dataset_id_to_contiguous_id.items", "json.dumps", "lvis_evaluation.LVISEvaluator._metadata.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation._evaluate_predictions_on_lvis", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate predictions. Fill self._results with the metrics of the tasks.\n\n        Args:\n            predictions (list[dict]): list of outputs from the model\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results in the LVIS format ...\"", ")", "\n", "lvis_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "tasks", "=", "self", ".", "_tasks", "or", "self", ".", "_tasks_from_predictions", "(", "lvis_results", ")", "\n", "\n", "# LVIS evaluator can be used to evaluate results for COCO dataset categories.", "\n", "# In this case `_metadata` variable will have a field with COCO-specific category mapping.", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "reverse_id_mapping", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "for", "result", "in", "lvis_results", ":", "\n", "                ", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "result", "[", "\"category_id\"", "]", "]", "\n", "", "", "else", ":", "\n", "# unmap the category ids for LVIS (from 0-indexed to 1-indexed)", "\n", "            ", "for", "result", "in", "lvis_results", ":", "\n", "                ", "result", "[", "\"category_id\"", "]", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"lvis_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "lvis_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating predictions ...\"", ")", "\n", "for", "task", "in", "sorted", "(", "tasks", ")", ":", "\n", "            ", "res", "=", "_evaluate_predictions_on_lvis", "(", "\n", "self", ".", "_lvis_api", ",", "lvis_results", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation.LVISEvaluator._eval_box_proposals": [[165, 203], ["lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation.LVISEvaluator._logger.info", "lvis_evaluation.LVISEvaluator._logger.info", "areas.items", "ids.append", "boxes.append", "objectness_logits.append", "detectron2.utils.file_io.PathManager.open", "pickle.dump", "lvis_evaluation._evaluate_box_proposals", "float", "detectron2.utils.logger.create_small_table", "prediction[].proposal_boxes.tensor.numpy", "prediction[].objectness_logits.numpy", "os.path.join", "stats[].item"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation._evaluate_box_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.create_small_table"], ["", "", "def", "_eval_box_proposals", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the box proposals in predictions.\n        Fill self._results with the metrics for \"box_proposals\" task.\n        \"\"\"", "\n", "if", "self", ".", "_output_dir", ":", "\n", "# Saving generated box proposals to file.", "\n", "# Predicted box_proposals are in XYXY_ABS mode.", "\n", "            ", "bbox_mode", "=", "BoxMode", ".", "XYXY_ABS", ".", "value", "\n", "ids", ",", "boxes", ",", "objectness_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "                ", "ids", ".", "append", "(", "prediction", "[", "\"image_id\"", "]", ")", "\n", "boxes", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "proposal_boxes", ".", "tensor", ".", "numpy", "(", ")", ")", "\n", "objectness_logits", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "objectness_logits", ".", "numpy", "(", ")", ")", "\n", "\n", "", "proposal_data", "=", "{", "\n", "\"boxes\"", ":", "boxes", ",", "\n", "\"objectness_logits\"", ":", "objectness_logits", ",", "\n", "\"ids\"", ":", "ids", ",", "\n", "\"bbox_mode\"", ":", "bbox_mode", ",", "\n", "}", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"box_proposals.pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "proposal_data", ",", "f", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating bbox proposals ...\"", ")", "\n", "res", "=", "{", "}", "\n", "areas", "=", "{", "\"all\"", ":", "\"\"", ",", "\"small\"", ":", "\"s\"", ",", "\"medium\"", ":", "\"m\"", ",", "\"large\"", ":", "\"l\"", "}", "\n", "for", "limit", "in", "[", "100", ",", "1000", "]", ":", "\n", "            ", "for", "area", ",", "suffix", "in", "areas", ".", "items", "(", ")", ":", "\n", "                ", "stats", "=", "_evaluate_box_proposals", "(", "predictions", ",", "self", ".", "_lvis_api", ",", "area", "=", "area", ",", "limit", "=", "limit", ")", "\n", "key", "=", "\"AR{}@{:d}\"", ".", "format", "(", "suffix", ",", "limit", ")", "\n", "res", "[", "key", "]", "=", "float", "(", "stats", "[", "\"ar\"", "]", ".", "item", "(", ")", "*", "100", ")", "\n", "", "", "self", ".", "_logger", ".", "info", "(", "\"Proposal metrics: \\n\"", "+", "create_small_table", "(", "res", ")", ")", "\n", "self", ".", "_results", "[", "\"box_proposals\"", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation._evaluate_box_proposals": [[207, 313], ["torch.sort", "torch.zeros_like", "enumerate", "torch.zeros_like.mean", "lvis_api.get_ann_ids", "lvis_api.load_anns", "torch.as_tensor().reshape", "detectron2.structures.Boxes", "torch.as_tensor", "len", "detectron2.structures.pairwise_iou", "torch.zeros", "range", "gt_overlaps.append", "len", "torch.cat", "torch.zeros", "torch.arange", "predictions.objectness_logits.sort", "detectron2.structures.BoxMode.convert", "len", "len", "min", "detectron2.structures.pairwise_iou.max", "max_overlaps.max", "float", "torch.as_tensor", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "", "def", "_evaluate_box_proposals", "(", "dataset_predictions", ",", "lvis_api", ",", "thresholds", "=", "None", ",", "area", "=", "\"all\"", ",", "limit", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate detection proposal recall metrics. This function is a much\n    faster alternative to the official LVIS API recall evaluation code. However,\n    it produces slightly different results.\n    \"\"\"", "\n", "# Record max overlap value for each gt box", "\n", "# Return vector of overlap values", "\n", "areas", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"small\"", ":", "1", ",", "\n", "\"medium\"", ":", "2", ",", "\n", "\"large\"", ":", "3", ",", "\n", "\"96-128\"", ":", "4", ",", "\n", "\"128-256\"", ":", "5", ",", "\n", "\"256-512\"", ":", "6", ",", "\n", "\"512-inf\"", ":", "7", ",", "\n", "}", "\n", "area_ranges", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "# all", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "# small", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "# medium", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "# large", "\n", "[", "96", "**", "2", ",", "128", "**", "2", "]", ",", "# 96-128", "\n", "[", "128", "**", "2", ",", "256", "**", "2", "]", ",", "# 128-256", "\n", "[", "256", "**", "2", ",", "512", "**", "2", "]", ",", "# 256-512", "\n", "[", "512", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "# 512-inf", "\n", "assert", "area", "in", "areas", ",", "\"Unknown area range: {}\"", ".", "format", "(", "area", ")", "\n", "area_range", "=", "area_ranges", "[", "areas", "[", "area", "]", "]", "\n", "gt_overlaps", "=", "[", "]", "\n", "num_pos", "=", "0", "\n", "\n", "for", "prediction_dict", "in", "dataset_predictions", ":", "\n", "        ", "predictions", "=", "prediction_dict", "[", "\"proposals\"", "]", "\n", "\n", "# sort predictions in descending order", "\n", "# TODO maybe remove this and make it explicit in the documentation", "\n", "inds", "=", "predictions", ".", "objectness_logits", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "\n", "predictions", "=", "predictions", "[", "inds", "]", "\n", "\n", "ann_ids", "=", "lvis_api", ".", "get_ann_ids", "(", "img_ids", "=", "[", "prediction_dict", "[", "\"image_id\"", "]", "]", ")", "\n", "anno", "=", "lvis_api", ".", "load_anns", "(", "ann_ids", ")", "\n", "gt_boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "for", "obj", "in", "anno", "\n", "]", "\n", "gt_boxes", "=", "torch", ".", "as_tensor", "(", "gt_boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "gt_boxes", "=", "Boxes", "(", "gt_boxes", ")", "\n", "gt_areas", "=", "torch", ".", "as_tensor", "(", "[", "obj", "[", "\"area\"", "]", "for", "obj", "in", "anno", "]", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", "or", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "valid_gt_inds", "=", "(", "gt_areas", ">=", "area_range", "[", "0", "]", ")", "&", "(", "gt_areas", "<=", "area_range", "[", "1", "]", ")", "\n", "gt_boxes", "=", "gt_boxes", "[", "valid_gt_inds", "]", "\n", "\n", "num_pos", "+=", "len", "(", "gt_boxes", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "limit", "is", "not", "None", "and", "len", "(", "predictions", ")", ">", "limit", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", "limit", "]", "\n", "\n", "", "overlaps", "=", "pairwise_iou", "(", "predictions", ".", "proposal_boxes", ",", "gt_boxes", ")", "\n", "\n", "_gt_overlaps", "=", "torch", ".", "zeros", "(", "len", "(", "gt_boxes", ")", ")", "\n", "for", "j", "in", "range", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "gt_boxes", ")", ")", ")", ":", "\n", "# find which proposal box maximally covers each gt box", "\n", "# and get the iou amount of coverage for each gt box", "\n", "            ", "max_overlaps", ",", "argmax_overlaps", "=", "overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "# find which gt box is 'best' covered (i.e. 'best' = most iou)", "\n", "gt_ovr", ",", "gt_ind", "=", "max_overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "assert", "gt_ovr", ">=", "0", "\n", "# find the proposal box that covers the best covered gt box", "\n", "box_ind", "=", "argmax_overlaps", "[", "gt_ind", "]", "\n", "# record the iou coverage of this gt box", "\n", "_gt_overlaps", "[", "j", "]", "=", "overlaps", "[", "box_ind", ",", "gt_ind", "]", "\n", "assert", "_gt_overlaps", "[", "j", "]", "==", "gt_ovr", "\n", "# mark the proposal box and the gt box as used", "\n", "overlaps", "[", "box_ind", ",", ":", "]", "=", "-", "1", "\n", "overlaps", "[", ":", ",", "gt_ind", "]", "=", "-", "1", "\n", "\n", "# append recorded iou coverage level", "\n", "", "gt_overlaps", ".", "append", "(", "_gt_overlaps", ")", "\n", "", "gt_overlaps", "=", "(", "\n", "torch", ".", "cat", "(", "gt_overlaps", ",", "dim", "=", "0", ")", "if", "len", "(", "gt_overlaps", ")", "else", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", ")", "\n", "gt_overlaps", ",", "_", "=", "torch", ".", "sort", "(", "gt_overlaps", ")", "\n", "\n", "if", "thresholds", "is", "None", ":", "\n", "        ", "step", "=", "0.05", "\n", "thresholds", "=", "torch", ".", "arange", "(", "0.5", ",", "0.95", "+", "1e-5", ",", "step", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "recalls", "=", "torch", ".", "zeros_like", "(", "thresholds", ")", "\n", "# compute recall for each iou threshold", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "recalls", "[", "i", "]", "=", "(", "gt_overlaps", ">=", "t", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "float", "(", "num_pos", ")", "\n", "# ar = 2 * np.trapz(recalls, thresholds)", "\n", "", "ar", "=", "recalls", ".", "mean", "(", ")", "\n", "return", "{", "\n", "\"ar\"", ":", "ar", ",", "\n", "\"recalls\"", ":", "recalls", ",", "\n", "\"thresholds\"", ":", "thresholds", ",", "\n", "\"gt_overlaps\"", ":", "gt_overlaps", ",", "\n", "\"num_pos\"", ":", "num_pos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.lvis_evaluation._evaluate_predictions_on_lvis": [[316, 359], ["logging.getLogger", "LVISResults", "LVISEval", "LVISEval.run", "LVISEval.print_results", "LVISEval.get_results", "logging.getLogger.info", "len", "logging.getLogger.warn", "copy.deepcopy", "float", "float", "c.pop", "detectron2.utils.logger.create_small_table"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.create_small_table"], ["", "def", "_evaluate_predictions_on_lvis", "(", "lvis_gt", ",", "lvis_results", ",", "iou_type", ",", "class_names", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        iou_type (str):\n        kpt_oks_sigmas (list[float]):\n        class_names (None or list[str]): if provided, will use it to predict\n            per-category AP.\n\n    Returns:\n        a dict of {metric name: score}\n    \"\"\"", "\n", "metrics", "=", "{", "\n", "\"bbox\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", ",", "\"APr\"", ",", "\"APc\"", ",", "\"APf\"", "]", ",", "\n", "\"segm\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", ",", "\"APr\"", ",", "\"APc\"", ",", "\"APf\"", "]", ",", "\n", "}", "[", "iou_type", "]", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "if", "len", "(", "lvis_results", ")", "==", "0", ":", "# TODO: check if needed", "\n", "        ", "logger", ".", "warn", "(", "\"No predictions from the model!\"", ")", "\n", "return", "{", "metric", ":", "float", "(", "\"nan\"", ")", "for", "metric", "in", "metrics", "}", "\n", "\n", "", "if", "iou_type", "==", "\"segm\"", ":", "\n", "        ", "lvis_results", "=", "copy", ".", "deepcopy", "(", "lvis_results", ")", "\n", "# When evaluating mask AP, if the results contain bbox, LVIS API will", "\n", "# use the box area as the area of the instance, instead of the mask area.", "\n", "# This leads to a different definition of small/medium/large.", "\n", "# We remove the bbox field to let mask AP use mask area.", "\n", "for", "c", "in", "lvis_results", ":", "\n", "            ", "c", ".", "pop", "(", "\"bbox\"", ",", "None", ")", "\n", "\n", "", "", "from", "lvis", "import", "LVISEval", ",", "LVISResults", "\n", "\n", "lvis_results", "=", "LVISResults", "(", "lvis_gt", ",", "lvis_results", ")", "\n", "lvis_eval", "=", "LVISEval", "(", "lvis_gt", ",", "lvis_results", ",", "iou_type", ")", "\n", "lvis_eval", ".", "run", "(", ")", "\n", "lvis_eval", ".", "print_results", "(", ")", "\n", "\n", "# Pull the standard metrics from the LVIS results", "\n", "results", "=", "lvis_eval", ".", "get_results", "(", ")", "\n", "results", "=", "{", "metric", ":", "float", "(", "results", "[", "metric", "]", "*", "100", ")", "for", "metric", "in", "metrics", "}", "\n", "logger", ".", "info", "(", "\"Evaluation results for {}: \\n\"", ".", "format", "(", "iou_type", ")", "+", "create_small_table", "(", "results", ")", ")", "\n", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator.__init__": [[43, 122], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "isinstance", "coco_evaluation.COCOEvaluator._logger.warn", "hasattr", "coco_evaluation.COCOEvaluator._logger.info", "os.path.join", "detectron2.data.datasets.coco.convert_to_coco_json", "contextlib.redirect_stdout", "pycocotools.coco.COCO", "io.StringIO"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.convert_to_coco_json"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "tasks", "=", "None", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "None", ",", "\n", "*", ",", "\n", "use_fast_impl", "=", "True", ",", "\n", "kpt_oks_sigmas", "=", "(", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n                It must have either the following corresponding metadata:\n\n                    \"json_file\": the path to the COCO format annotation\n\n                Or it must be in detectron2's standard dataset format\n                so it can be converted to COCO format automatically.\n            tasks (tuple[str]): tasks that can be evaluated under the given\n                configuration. A task is one of \"bbox\", \"segm\", \"keypoints\".\n                By default, will infer this automatically from predictions.\n            distributed (True): if True, will collect results from all ranks and run evaluation\n                in the main process.\n                Otherwise, will only evaluate the results in the current process.\n            output_dir (str): optional, an output directory to dump all\n                results predicted on the dataset. The dump contains two files:\n\n                1. \"instances_predictions.pth\" a file that can be loaded with `torch.load` and\n                   contains all the results in the format they are produced by the model.\n                2. \"coco_instances_results.json\" a json file in COCO's result format.\n            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.\n                Although the results should be very close to the official implementation in COCO\n                API, it is still recommended to compute results with the official API for use in\n                papers. The faster implementation also uses more RAM.\n            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.\n                See http://cocodataset.org/#keypoints-eval\n                When empty, it will use the defaults in COCO.\n                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "self", ".", "_use_fast_impl", "=", "use_fast_impl", "\n", "\n", "if", "tasks", "is", "not", "None", "and", "isinstance", "(", "tasks", ",", "CfgNode", ")", ":", "\n", "            ", "kpt_oks_sigmas", "=", "(", "\n", "tasks", ".", "TEST", ".", "KEYPOINT_OKS_SIGMAS", "if", "not", "kpt_oks_sigmas", "else", "kpt_oks_sigmas", "\n", ")", "\n", "self", ".", "_logger", ".", "warn", "(", "\n", "\"COCO Evaluator instantiated using config, this is deprecated behavior.\"", "\n", "\" Please pass in explicit arguments instead.\"", "\n", ")", "\n", "self", ".", "_tasks", "=", "None", "# Infering it from predictions should be better", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tasks", "=", "tasks", "\n", "\n", "", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "if", "not", "hasattr", "(", "self", ".", "_metadata", ",", "\"json_file\"", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "f\"'{dataset_name}' is not registered by `register_coco_instances`.\"", "\n", "\" Therefore trying to convert it to COCO format ...\"", "\n", ")", "\n", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{dataset_name}_coco_format.json\"", ")", "\n", "self", ".", "_metadata", ".", "json_file", "=", "cache_path", "\n", "convert_to_coco_json", "(", "dataset_name", ",", "cache_path", ")", "\n", "\n", "", "json_file", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "            ", "self", ".", "_coco_api", "=", "COCO", "(", "json_file", ")", "\n", "\n", "# Test set json files do not contain annotations (evaluation must be", "\n", "# performed using the COCO evaluation server).", "\n", "", "self", ".", "_do_evaluation", "=", "\"annotations\"", "in", "self", ".", "_coco_api", ".", "dataset", "\n", "if", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_kpt_oks_sigmas", "=", "kpt_oks_sigmas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator.reset": [[123, 125], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator.process": [[126, 145], ["zip", "output[].to", "coco_evaluation.instances_to_coco_json", "output[].to", "len", "coco_evaluation.COCOEvaluator._predictions.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.instances_to_coco_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a COCO model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "prediction", "[", "\"instances\"", "]", "=", "instances_to_coco_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "if", "len", "(", "prediction", ")", ">", "1", ":", "\n", "                ", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator.evaluate": [[146, 178], ["collections.OrderedDict", "copy.deepcopy", "detectron2.synchronize", "detectron2.gather", "list", "len", "coco_evaluation.COCOEvaluator._logger.warning", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "coco_evaluation.COCOEvaluator._eval_box_proposals", "coco_evaluation.COCOEvaluator._eval_predictions", "itertools.chain", "detectron2.is_main_process", "detectron2.utils.file_io.PathManager.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator._eval_predictions", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["", "", "", "def", "evaluate", "(", "self", ",", "img_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset\n        \"\"\"", "\n", "if", "self", ".", "_distributed", ":", "\n", "            ", "comm", ".", "synchronize", "(", ")", "\n", "predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "predictions", ")", ")", "\n", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "return", "{", "}", "\n", "", "", "else", ":", "\n", "            ", "predictions", "=", "self", ".", "_predictions", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\"[COCOEvaluator] Did not receive valid predictions.\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"instances_predictions.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "predictions", ",", "f", ")", "\n", "\n", "", "", "self", ".", "_results", "=", "OrderedDict", "(", ")", "\n", "if", "\"proposals\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_box_proposals", "(", "predictions", ")", "\n", "", "if", "\"instances\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_predictions", "(", "predictions", ",", "img_ids", "=", "img_ids", ")", "\n", "# Copy so the caller can do whatever with results", "\n", "", "return", "copy", ".", "deepcopy", "(", "self", ".", "_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions": [[179, 190], ["sorted", "tasks.add", "tasks.add"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], ["", "def", "_tasks_from_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Get COCO API \"tasks\" (i.e. iou_type) from COCO-format predictions.\n        \"\"\"", "\n", "tasks", "=", "{", "\"bbox\"", "}", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "if", "\"segmentation\"", "in", "pred", ":", "\n", "                ", "tasks", ".", "add", "(", "\"segm\"", ")", "\n", "", "if", "\"keypoints\"", "in", "pred", ":", "\n", "                ", "tasks", ".", "add", "(", "\"keypoints\"", ")", "\n", "", "", "return", "sorted", "(", "tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._eval_predictions": [[191, 251], ["coco_evaluation.COCOEvaluator._logger.info", "list", "hasattr", "coco_evaluation.COCOEvaluator._logger.info", "sorted", "itertools.chain", "coco_evaluation.COCOEvaluator._tasks_from_predictions", "list", "len", "os.path.join", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._derive_coco_results", "dataset_id_to_contiguous_id.values", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "coco_evaluation._evaluate_predictions_on_coco", "min", "max", "dataset_id_to_contiguous_id.items", "json.dumps", "len", "coco_evaluation.COCOEvaluator._metadata.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._evaluate_predictions_on_coco", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ",", "img_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate predictions. Fill self._results with the metrics of the tasks.\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results for COCO format ...\"", ")", "\n", "coco_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "tasks", "=", "self", ".", "_tasks", "or", "self", ".", "_tasks_from_predictions", "(", "coco_results", ")", "\n", "\n", "# unmap the category ids for COCO", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "dataset_id_to_contiguous_id", "=", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", "\n", "all_contiguous_ids", "=", "list", "(", "dataset_id_to_contiguous_id", ".", "values", "(", ")", ")", "\n", "num_classes", "=", "len", "(", "all_contiguous_ids", ")", "\n", "assert", "min", "(", "all_contiguous_ids", ")", "==", "0", "and", "max", "(", "all_contiguous_ids", ")", "==", "num_classes", "-", "1", "\n", "\n", "reverse_id_mapping", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "dataset_id_to_contiguous_id", ".", "items", "(", ")", "}", "\n", "for", "result", "in", "coco_results", ":", "\n", "                ", "category_id", "=", "result", "[", "\"category_id\"", "]", "\n", "assert", "category_id", "<", "num_classes", ",", "(", "\n", "f\"A prediction has class={category_id}, \"", "\n", "f\"but the dataset only has {num_classes} classes and \"", "\n", "f\"predicted class id should be in [0, {num_classes - 1}].\"", "\n", ")", "\n", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "category_id", "]", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"coco_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "coco_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluating predictions with {} COCO API...\"", ".", "format", "(", "\n", "\"unofficial\"", "if", "self", ".", "_use_fast_impl", "else", "\"official\"", "\n", ")", "\n", ")", "\n", "for", "task", "in", "sorted", "(", "tasks", ")", ":", "\n", "            ", "assert", "task", "in", "{", "\"bbox\"", ",", "\"segm\"", ",", "\"keypoints\"", "}", ",", "f\"Got unknown task: {task}!\"", "\n", "coco_eval", "=", "(", "\n", "_evaluate_predictions_on_coco", "(", "\n", "self", ".", "_coco_api", ",", "\n", "coco_results", ",", "\n", "task", ",", "\n", "kpt_oks_sigmas", "=", "self", ".", "_kpt_oks_sigmas", ",", "\n", "use_fast_impl", "=", "self", ".", "_use_fast_impl", ",", "\n", "img_ids", "=", "img_ids", ",", "\n", ")", "\n", "if", "len", "(", "coco_results", ")", ">", "0", "\n", "else", "None", "# cocoapi does not handle empty results very well", "\n", ")", "\n", "\n", "res", "=", "self", ".", "_derive_coco_results", "(", "\n", "coco_eval", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals": [[252, 290], ["coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "areas.items", "ids.append", "boxes.append", "objectness_logits.append", "detectron2.utils.file_io.PathManager.open", "pickle.dump", "coco_evaluation._evaluate_box_proposals", "float", "detectron2.utils.logger.create_small_table", "prediction[].proposal_boxes.tensor.numpy", "prediction[].objectness_logits.numpy", "os.path.join", "stats[].item"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation._evaluate_box_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.create_small_table"], ["", "", "def", "_eval_box_proposals", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the box proposals in predictions.\n        Fill self._results with the metrics for \"box_proposals\" task.\n        \"\"\"", "\n", "if", "self", ".", "_output_dir", ":", "\n", "# Saving generated box proposals to file.", "\n", "# Predicted box_proposals are in XYXY_ABS mode.", "\n", "            ", "bbox_mode", "=", "BoxMode", ".", "XYXY_ABS", ".", "value", "\n", "ids", ",", "boxes", ",", "objectness_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "                ", "ids", ".", "append", "(", "prediction", "[", "\"image_id\"", "]", ")", "\n", "boxes", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "proposal_boxes", ".", "tensor", ".", "numpy", "(", ")", ")", "\n", "objectness_logits", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "objectness_logits", ".", "numpy", "(", ")", ")", "\n", "\n", "", "proposal_data", "=", "{", "\n", "\"boxes\"", ":", "boxes", ",", "\n", "\"objectness_logits\"", ":", "objectness_logits", ",", "\n", "\"ids\"", ":", "ids", ",", "\n", "\"bbox_mode\"", ":", "bbox_mode", ",", "\n", "}", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"box_proposals.pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "proposal_data", ",", "f", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating bbox proposals ...\"", ")", "\n", "res", "=", "{", "}", "\n", "areas", "=", "{", "\"all\"", ":", "\"\"", ",", "\"small\"", ":", "\"s\"", ",", "\"medium\"", ":", "\"m\"", ",", "\"large\"", ":", "\"l\"", "}", "\n", "for", "limit", "in", "[", "100", ",", "1000", "]", ":", "\n", "            ", "for", "area", ",", "suffix", "in", "areas", ".", "items", "(", ")", ":", "\n", "                ", "stats", "=", "_evaluate_box_proposals", "(", "predictions", ",", "self", ".", "_coco_api", ",", "area", "=", "area", ",", "limit", "=", "limit", ")", "\n", "key", "=", "\"AR{}@{:d}\"", ".", "format", "(", "suffix", ",", "limit", ")", "\n", "res", "[", "key", "]", "=", "float", "(", "stats", "[", "\"ar\"", "]", ".", "item", "(", ")", "*", "100", ")", "\n", "", "", "self", ".", "_logger", ".", "info", "(", "\"Proposal metrics: \\n\"", "+", "create_small_table", "(", "res", ")", ")", "\n", "self", ".", "_results", "[", "\"box_proposals\"", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results": [[291, 358], ["coco_evaluation.COCOEvaluator._logger.info", "enumerate", "min", "list", "itertools.zip_longest", "tabulate.tabulate.tabulate", "coco_evaluation.COCOEvaluator._logger.info", "results.update", "coco_evaluation.COCOEvaluator._logger.warn", "float", "numpy.isfinite", "coco_evaluation.COCOEvaluator._logger.info", "len", "results_per_category.append", "itertools.chain", "float", "enumerate", "detectron2.utils.logger.create_small_table", "sum", "len", "numpy.mean", "float", "len", "results.values", "float", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.create_small_table"], ["", "def", "_derive_coco_results", "(", "self", ",", "coco_eval", ",", "iou_type", ",", "class_names", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Derive the desired score numbers from summarized COCOeval.\n\n        Args:\n            coco_eval (None or COCOEval): None represents no predictions from model.\n            iou_type (str):\n            class_names (None or list[str]): if provided, will use it to predict\n                per-category AP.\n\n        Returns:\n            a dict of {metric name: score}\n        \"\"\"", "\n", "\n", "metrics", "=", "{", "\n", "\"bbox\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"segm\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"keypoints\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "}", "[", "iou_type", "]", "\n", "\n", "if", "coco_eval", "is", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\"No predictions from the model!\"", ")", "\n", "return", "{", "metric", ":", "float", "(", "\"nan\"", ")", "for", "metric", "in", "metrics", "}", "\n", "\n", "# the standard metrics", "\n", "", "results", "=", "{", "\n", "metric", ":", "float", "(", "coco_eval", ".", "stats", "[", "idx", "]", "*", "100", "if", "coco_eval", ".", "stats", "[", "idx", "]", ">=", "0", "else", "\"nan\"", ")", "\n", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "\n", "}", "\n", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluation results for {}: \\n\"", ".", "format", "(", "iou_type", ")", "+", "create_small_table", "(", "results", ")", "\n", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "sum", "(", "results", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Some metrics cannot be computed and is shown as NaN.\"", ")", "\n", "\n", "", "if", "class_names", "is", "None", "or", "len", "(", "class_names", ")", "<=", "1", ":", "\n", "            ", "return", "results", "\n", "# Compute per-category AP", "\n", "# from https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L222-L252 # noqa", "\n", "", "precisions", "=", "coco_eval", ".", "eval", "[", "\"precision\"", "]", "\n", "# precision has dims (iou, recall, cls, area range, max dets)", "\n", "assert", "len", "(", "class_names", ")", "==", "precisions", ".", "shape", "[", "2", "]", "\n", "\n", "results_per_category", "=", "[", "]", "\n", "for", "idx", ",", "name", "in", "enumerate", "(", "class_names", ")", ":", "\n", "# area range index 0: all area ranges", "\n", "# max dets index -1: typically 100 per image", "\n", "            ", "precision", "=", "precisions", "[", ":", ",", ":", ",", "idx", ",", "0", ",", "-", "1", "]", "\n", "precision", "=", "precision", "[", "precision", ">", "-", "1", "]", "\n", "ap", "=", "np", ".", "mean", "(", "precision", ")", "if", "precision", ".", "size", "else", "float", "(", "\"nan\"", ")", "\n", "results_per_category", ".", "append", "(", "(", "\"{}\"", ".", "format", "(", "name", ")", ",", "float", "(", "ap", "*", "100", ")", ")", ")", "\n", "\n", "# tabulate it", "\n", "", "N_COLS", "=", "min", "(", "6", ",", "len", "(", "results_per_category", ")", "*", "2", ")", "\n", "results_flatten", "=", "list", "(", "itertools", ".", "chain", "(", "*", "results_per_category", ")", ")", "\n", "results_2d", "=", "itertools", ".", "zip_longest", "(", "*", "[", "results_flatten", "[", "i", ":", ":", "N_COLS", "]", "for", "i", "in", "range", "(", "N_COLS", ")", "]", ")", "\n", "table", "=", "tabulate", "(", "\n", "results_2d", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "floatfmt", "=", "\".3f\"", ",", "\n", "headers", "=", "[", "\"category\"", ",", "\"AP\"", "]", "*", "(", "N_COLS", "//", "2", ")", ",", "\n", "numalign", "=", "\"left\"", ",", "\n", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Per-category {} AP: \\n\"", ".", "format", "(", "iou_type", ")", "+", "table", ")", "\n", "\n", "results", ".", "update", "(", "{", "\"AP-\"", "+", "name", ":", "ap", "for", "name", ",", "ap", "in", "results_per_category", "}", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.instances_to_coco_json": [[360, 420], ["len", "instances.pred_boxes.tensor.numpy", "detectron2.structures.BoxMode.convert", "boxes.tolist.tolist", "instances.scores.tolist", "instances.pred_classes.tolist", "instances.has", "instances.has", "range", "results.append", "rle[].decode", "keypoints[].flatten().tolist", "pycocotools.encode", "numpy.array", "keypoints[].flatten"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "", "def", "instances_to_coco_json", "(", "instances", ",", "img_id", ")", ":", "\n", "    ", "\"\"\"\n    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n\n    Args:\n        instances (Instances):\n        img_id (int): the image id\n\n    Returns:\n        list[dict]: list of json annotations in COCO format.\n    \"\"\"", "\n", "num_instance", "=", "len", "(", "instances", ")", "\n", "if", "num_instance", "==", "0", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "boxes", "=", "BoxMode", ".", "convert", "(", "boxes", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "boxes", "=", "boxes", ".", "tolist", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "\n", "has_mask", "=", "instances", ".", "has", "(", "\"pred_masks\"", ")", "\n", "if", "has_mask", ":", "\n", "# use RLE to encode the masks, because they are too large and takes memory", "\n", "# since this evaluator stores outputs of the entire dataset", "\n", "        ", "rles", "=", "[", "\n", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", ":", ",", ":", ",", "None", "]", ",", "order", "=", "\"F\"", ",", "dtype", "=", "\"uint8\"", ")", ")", "[", "0", "]", "\n", "for", "mask", "in", "instances", ".", "pred_masks", "\n", "]", "\n", "for", "rle", "in", "rles", ":", "\n", "# \"counts\" is an array encoded by mask_util as a byte-stream. Python3's", "\n", "# json writer which always produces strings cannot serialize a bytestream", "\n", "# unless you decode it. Thankfully, utf-8 works out (which is also what", "\n", "# the pycocotools/_mask.pyx does).", "\n", "            ", "rle", "[", "\"counts\"", "]", "=", "rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "", "has_keypoints", "=", "instances", ".", "has", "(", "\"pred_keypoints\"", ")", "\n", "if", "has_keypoints", ":", "\n", "        ", "keypoints", "=", "instances", ".", "pred_keypoints", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "num_instance", ")", ":", "\n", "        ", "result", "=", "{", "\n", "\"image_id\"", ":", "img_id", ",", "\n", "\"category_id\"", ":", "classes", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "boxes", "[", "k", "]", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "if", "has_mask", ":", "\n", "            ", "result", "[", "\"segmentation\"", "]", "=", "rles", "[", "k", "]", "\n", "", "if", "has_keypoints", ":", "\n", "# In COCO annotations,", "\n", "# keypoints coordinates are pixel indices.", "\n", "# However our predictions are floating point coordinates.", "\n", "# Therefore we subtract 0.5 to be consistent with the annotation format.", "\n", "# This is the inverse of data loading logic in `datasets/coco.py`.", "\n", "            ", "keypoints", "[", "k", "]", "[", ":", ",", ":", "2", "]", "-=", "0.5", "\n", "result", "[", "\"keypoints\"", "]", "=", "keypoints", "[", "k", "]", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation._evaluate_box_proposals": [[424, 532], ["torch.sort", "torch.zeros_like", "enumerate", "torch.zeros_like.mean", "coco_api.getAnnIds", "coco_api.loadAnns", "torch.as_tensor().reshape", "detectron2.structures.Boxes", "torch.as_tensor", "len", "detectron2.structures.pairwise_iou", "torch.zeros", "range", "gt_overlaps.append", "len", "torch.cat", "torch.zeros", "torch.arange", "predictions.objectness_logits.sort", "detectron2.structures.BoxMode.convert", "len", "len", "min", "detectron2.structures.pairwise_iou.max", "max_overlaps.max", "float", "torch.as_tensor", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "_evaluate_box_proposals", "(", "dataset_predictions", ",", "coco_api", ",", "thresholds", "=", "None", ",", "area", "=", "\"all\"", ",", "limit", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate detection proposal recall metrics. This function is a much\n    faster alternative to the official COCO API recall evaluation code. However,\n    it produces slightly different results.\n    \"\"\"", "\n", "# Record max overlap value for each gt box", "\n", "# Return vector of overlap values", "\n", "areas", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"small\"", ":", "1", ",", "\n", "\"medium\"", ":", "2", ",", "\n", "\"large\"", ":", "3", ",", "\n", "\"96-128\"", ":", "4", ",", "\n", "\"128-256\"", ":", "5", ",", "\n", "\"256-512\"", ":", "6", ",", "\n", "\"512-inf\"", ":", "7", ",", "\n", "}", "\n", "area_ranges", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "# all", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "# small", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "# medium", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "# large", "\n", "[", "96", "**", "2", ",", "128", "**", "2", "]", ",", "# 96-128", "\n", "[", "128", "**", "2", ",", "256", "**", "2", "]", ",", "# 128-256", "\n", "[", "256", "**", "2", ",", "512", "**", "2", "]", ",", "# 256-512", "\n", "[", "512", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "# 512-inf", "\n", "assert", "area", "in", "areas", ",", "\"Unknown area range: {}\"", ".", "format", "(", "area", ")", "\n", "area_range", "=", "area_ranges", "[", "areas", "[", "area", "]", "]", "\n", "gt_overlaps", "=", "[", "]", "\n", "num_pos", "=", "0", "\n", "\n", "for", "prediction_dict", "in", "dataset_predictions", ":", "\n", "        ", "predictions", "=", "prediction_dict", "[", "\"proposals\"", "]", "\n", "\n", "# sort predictions in descending order", "\n", "# TODO maybe remove this and make it explicit in the documentation", "\n", "inds", "=", "predictions", ".", "objectness_logits", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "\n", "predictions", "=", "predictions", "[", "inds", "]", "\n", "\n", "ann_ids", "=", "coco_api", ".", "getAnnIds", "(", "imgIds", "=", "prediction_dict", "[", "\"image_id\"", "]", ")", "\n", "anno", "=", "coco_api", ".", "loadAnns", "(", "ann_ids", ")", "\n", "gt_boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "for", "obj", "in", "anno", "\n", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "\n", "]", "\n", "gt_boxes", "=", "torch", ".", "as_tensor", "(", "gt_boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "gt_boxes", "=", "Boxes", "(", "gt_boxes", ")", "\n", "gt_areas", "=", "torch", ".", "as_tensor", "(", "[", "obj", "[", "\"area\"", "]", "for", "obj", "in", "anno", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "]", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", "or", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "valid_gt_inds", "=", "(", "gt_areas", ">=", "area_range", "[", "0", "]", ")", "&", "(", "gt_areas", "<=", "area_range", "[", "1", "]", ")", "\n", "gt_boxes", "=", "gt_boxes", "[", "valid_gt_inds", "]", "\n", "\n", "num_pos", "+=", "len", "(", "gt_boxes", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "limit", "is", "not", "None", "and", "len", "(", "predictions", ")", ">", "limit", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", "limit", "]", "\n", "\n", "", "overlaps", "=", "pairwise_iou", "(", "predictions", ".", "proposal_boxes", ",", "gt_boxes", ")", "\n", "\n", "_gt_overlaps", "=", "torch", ".", "zeros", "(", "len", "(", "gt_boxes", ")", ")", "\n", "for", "j", "in", "range", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "gt_boxes", ")", ")", ")", ":", "\n", "# find which proposal box maximally covers each gt box", "\n", "# and get the iou amount of coverage for each gt box", "\n", "            ", "max_overlaps", ",", "argmax_overlaps", "=", "overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "# find which gt box is 'best' covered (i.e. 'best' = most iou)", "\n", "gt_ovr", ",", "gt_ind", "=", "max_overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "assert", "gt_ovr", ">=", "0", "\n", "# find the proposal box that covers the best covered gt box", "\n", "box_ind", "=", "argmax_overlaps", "[", "gt_ind", "]", "\n", "# record the iou coverage of this gt box", "\n", "_gt_overlaps", "[", "j", "]", "=", "overlaps", "[", "box_ind", ",", "gt_ind", "]", "\n", "assert", "_gt_overlaps", "[", "j", "]", "==", "gt_ovr", "\n", "# mark the proposal box and the gt box as used", "\n", "overlaps", "[", "box_ind", ",", ":", "]", "=", "-", "1", "\n", "overlaps", "[", ":", ",", "gt_ind", "]", "=", "-", "1", "\n", "\n", "# append recorded iou coverage level", "\n", "", "gt_overlaps", ".", "append", "(", "_gt_overlaps", ")", "\n", "", "gt_overlaps", "=", "(", "\n", "torch", ".", "cat", "(", "gt_overlaps", ",", "dim", "=", "0", ")", "if", "len", "(", "gt_overlaps", ")", "else", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", ")", "\n", "gt_overlaps", ",", "_", "=", "torch", ".", "sort", "(", "gt_overlaps", ")", "\n", "\n", "if", "thresholds", "is", "None", ":", "\n", "        ", "step", "=", "0.05", "\n", "thresholds", "=", "torch", ".", "arange", "(", "0.5", ",", "0.95", "+", "1e-5", ",", "step", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "recalls", "=", "torch", ".", "zeros_like", "(", "thresholds", ")", "\n", "# compute recall for each iou threshold", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "recalls", "[", "i", "]", "=", "(", "gt_overlaps", ">=", "t", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "float", "(", "num_pos", ")", "\n", "# ar = 2 * np.trapz(recalls, thresholds)", "\n", "", "ar", "=", "recalls", ".", "mean", "(", ")", "\n", "return", "{", "\n", "\"ar\"", ":", "ar", ",", "\n", "\"recalls\"", ":", "recalls", ",", "\n", "\"thresholds\"", ":", "thresholds", ",", "\n", "\"gt_overlaps\"", ":", "gt_overlaps", ",", "\n", "\"num_pos\"", ":", "num_pos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation._evaluate_predictions_on_coco": [[535, 580], ["coco_gt.loadRes", "coco_eval.evaluate", "coco_eval.accumulate", "coco_eval.summarize", "len", "copy.deepcopy", "len", "c.pop", "hasattr", "numpy.array", "len", "len", "next", "iter", "coco_gt.anns.values"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "def", "_evaluate_predictions_on_coco", "(", "\n", "coco_gt", ",", "coco_results", ",", "iou_type", ",", "kpt_oks_sigmas", "=", "None", ",", "use_fast_impl", "=", "True", ",", "img_ids", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate the coco results using COCOEval API.\n    \"\"\"", "\n", "assert", "len", "(", "coco_results", ")", ">", "0", "\n", "\n", "if", "iou_type", "==", "\"segm\"", ":", "\n", "        ", "coco_results", "=", "copy", ".", "deepcopy", "(", "coco_results", ")", "\n", "# When evaluating mask AP, if the results contain bbox, cocoapi will", "\n", "# use the box area as the area of the instance, instead of the mask area.", "\n", "# This leads to a different definition of small/medium/large.", "\n", "# We remove the bbox field to let mask AP use mask area.", "\n", "for", "c", "in", "coco_results", ":", "\n", "            ", "c", ".", "pop", "(", "\"bbox\"", ",", "None", ")", "\n", "\n", "", "", "coco_dt", "=", "coco_gt", ".", "loadRes", "(", "coco_results", ")", "\n", "coco_eval", "=", "(", "COCOeval_opt", "if", "use_fast_impl", "else", "COCOeval", ")", "(", "coco_gt", ",", "coco_dt", ",", "iou_type", ")", "\n", "if", "img_ids", "is", "not", "None", ":", "\n", "        ", "coco_eval", ".", "params", ".", "imgIds", "=", "img_ids", "\n", "\n", "", "if", "iou_type", "==", "\"keypoints\"", ":", "\n", "# Use the COCO default keypoint OKS sigmas unless overrides are specified", "\n", "        ", "if", "kpt_oks_sigmas", ":", "\n", "            ", "assert", "hasattr", "(", "coco_eval", ".", "params", ",", "\"kpt_oks_sigmas\"", ")", ",", "\"pycocotools is too old!\"", "\n", "coco_eval", ".", "params", ".", "kpt_oks_sigmas", "=", "np", ".", "array", "(", "kpt_oks_sigmas", ")", "\n", "# COCOAPI requires every detection and every gt to have keypoints, so", "\n", "# we just take the first entry from both", "\n", "", "num_keypoints_dt", "=", "len", "(", "coco_results", "[", "0", "]", "[", "\"keypoints\"", "]", ")", "//", "3", "\n", "num_keypoints_gt", "=", "len", "(", "next", "(", "iter", "(", "coco_gt", ".", "anns", ".", "values", "(", ")", ")", ")", "[", "\"keypoints\"", "]", ")", "//", "3", "\n", "num_keypoints_oks", "=", "len", "(", "coco_eval", ".", "params", ".", "kpt_oks_sigmas", ")", "\n", "assert", "num_keypoints_oks", "==", "num_keypoints_dt", "==", "num_keypoints_gt", ",", "(", "\n", "f\"[COCOEvaluator] Prediction contain {num_keypoints_dt} keypoints. \"", "\n", "f\"Ground truth contains {num_keypoints_gt} keypoints. \"", "\n", "f\"The length of cfg.TEST.KEYPOINT_OKS_SIGMAS is {num_keypoints_oks}. \"", "\n", "\"They have to agree with each other. For meaning of OKS, please refer to \"", "\n", "\"http://cocodataset.org/#keypoints-eval.\"", "\n", ")", "\n", "\n", "", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "\n", "return", "coco_eval", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator.__init__": [[32, 49], ["detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.mkdirs", "panoptic_evaluation.COCOPanopticEvaluator._metadata.thing_dataset_id_to_contiguous_id.items", "panoptic_evaluation.COCOPanopticEvaluator._metadata.stuff_dataset_id_to_contiguous_id.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["def", "__init__", "(", "self", ",", "dataset_name", ":", "str", ",", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name: name of the dataset\n            output_dir: output directory to save results for evaluation.\n        \"\"\"", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "self", ".", "_thing_contiguous_id_to_dataset_id", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "_stuff_contiguous_id_to_dataset_id", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "stuff_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "if", "self", ".", "_output_dir", "is", "not", "None", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator.reset": [[50, 52], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id": [[53, 67], ["segment_info.pop"], "methods", ["None"], ["", "def", "_convert_category_id", "(", "self", ",", "segment_info", ")", ":", "\n", "        ", "isthing", "=", "segment_info", ".", "pop", "(", "\"isthing\"", ",", "None", ")", "\n", "if", "isthing", "is", "None", ":", "\n", "# the model produces panoptic category id directly. No more conversion needed", "\n", "            ", "return", "segment_info", "\n", "", "if", "isthing", "is", "True", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "self", ".", "_thing_contiguous_id_to_dataset_id", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "else", ":", "\n", "            ", "segment_info", "[", "\"category_id\"", "]", "=", "self", ".", "_stuff_contiguous_id_to_dataset_id", "[", "\n", "segment_info", "[", "\"category_id\"", "]", "\n", "]", "\n", "", "return", "segment_info", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator.process": [[68, 111], ["zip", "panoptic_img.cpu().numpy.cpu().numpy.cpu().numpy", "os.path.basename", "numpy.unique", "io.BytesIO", "PIL.Image.fromarray().save", "panoptic_evaluation.COCOPanopticEvaluator._predictions.append", "panoptic_img.cpu().numpy.cpu().numpy.cpu", "segments_info.append", "os.path.splitext", "panoptic_evaluation.COCOPanopticEvaluator._convert_category_id", "panoptic_evaluation.COCOPanopticEvaluator._metadata.thing_dataset_id_to_contiguous_id.values", "PIL.Image.fromarray", "out.getvalue", "int", "bool", "id2rgb", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator._convert_category_id"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "from", "panopticapi", ".", "utils", "import", "id2rgb", "\n", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "panoptic_img", ",", "segments_info", "=", "output", "[", "\"panoptic_seg\"", "]", "\n", "panoptic_img", "=", "panoptic_img", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "segments_info", "is", "None", ":", "\n", "# If \"segments_info\" is None, we assume \"panoptic_img\" is a", "\n", "# H*W int32 image storing the panoptic_id in the format of", "\n", "# category_id * label_divisor + instance_id. We reserve -1 for", "\n", "# VOID label, and add 1 to panoptic_img since the official", "\n", "# evaluation script uses 0 for VOID label.", "\n", "                ", "label_divisor", "=", "self", ".", "_metadata", ".", "label_divisor", "\n", "segments_info", "=", "[", "]", "\n", "for", "panoptic_label", "in", "np", ".", "unique", "(", "panoptic_img", ")", ":", "\n", "                    ", "if", "panoptic_label", "==", "-", "1", ":", "\n", "# VOID region.", "\n", "                        ", "continue", "\n", "", "pred_class", "=", "panoptic_label", "//", "label_divisor", "\n", "isthing", "=", "(", "\n", "pred_class", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", "\n", ")", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "int", "(", "panoptic_label", ")", "+", "1", ",", "\n", "\"category_id\"", ":", "int", "(", "pred_class", ")", ",", "\n", "\"isthing\"", ":", "bool", "(", "isthing", ")", ",", "\n", "}", "\n", ")", "\n", "# Official evaluation script uses 0 for VOID label.", "\n", "", "panoptic_img", "+=", "1", "\n", "\n", "", "file_name", "=", "os", ".", "path", ".", "basename", "(", "input", "[", "\"file_name\"", "]", ")", "\n", "file_name_png", "=", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "[", "0", "]", "+", "\".png\"", "\n", "with", "io", ".", "BytesIO", "(", ")", "as", "out", ":", "\n", "                ", "Image", ".", "fromarray", "(", "id2rgb", "(", "panoptic_img", ")", ")", ".", "save", "(", "out", ",", "format", "=", "\"PNG\"", ")", "\n", "segments_info", "=", "[", "self", ".", "_convert_category_id", "(", "x", ")", "for", "x", "in", "segments_info", "]", "\n", "self", ".", "_predictions", ".", "append", "(", "\n", "{", "\n", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", ",", "\n", "\"file_name\"", ":", "file_name_png", ",", "\n", "\"png_string\"", ":", "out", ".", "getvalue", "(", ")", ",", "\n", "\"segments_info\"", ":", "segments_info", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation.COCOPanopticEvaluator.evaluate": [[114, 166], ["detectron2.utils.comm.synchronize", "detectron2.utils.comm.gather", "list", "detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.get_local_path", "collections.OrderedDict", "panoptic_evaluation._print_panoptic_results", "itertools.chain", "detectron2.utils.comm.is_main_process", "tempfile.TemporaryDirectory", "logger.info", "os.path.join", "open", "json.load", "detectron2.utils.file_io.PathManager.open", "f.write", "contextlib.redirect_stdout", "pq_compute", "open", "f.write", "json.dumps", "io.StringIO", "detectron2.utils.file_io.PathManager.get_local_path", "os.path.join", "p.pop"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation._print_panoptic_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "comm", ".", "synchronize", "(", ")", "\n", "\n", "self", ".", "_predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ")", "\n", "self", ".", "_predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "self", ".", "_predictions", ")", ")", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "# PanopticApi requires local files", "\n", "", "gt_json", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "panoptic_json", ")", "\n", "gt_folder", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "panoptic_root", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"panoptic_eval\"", ")", "as", "pred_dir", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing all panoptic predictions to {} ...\"", ".", "format", "(", "pred_dir", ")", ")", "\n", "for", "p", "in", "self", ".", "_predictions", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "pred_dir", ",", "p", "[", "\"file_name\"", "]", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "p", ".", "pop", "(", "\"png_string\"", ")", ")", "\n", "\n", "", "", "with", "open", "(", "gt_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "json_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "json_data", "[", "\"annotations\"", "]", "=", "self", ".", "_predictions", "\n", "\n", "output_dir", "=", "self", ".", "_output_dir", "or", "pred_dir", "\n", "predictions_json", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"predictions.json\"", ")", "\n", "with", "PathManager", ".", "open", "(", "predictions_json", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "json_data", ")", ")", "\n", "\n", "", "from", "panopticapi", ".", "evaluation", "import", "pq_compute", "\n", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "                ", "pq_res", "=", "pq_compute", "(", "\n", "gt_json", ",", "\n", "PathManager", ".", "get_local_path", "(", "predictions_json", ")", ",", "\n", "gt_folder", "=", "gt_folder", ",", "\n", "pred_folder", "=", "pred_dir", ",", "\n", ")", "\n", "\n", "", "", "res", "=", "{", "}", "\n", "res", "[", "\"PQ\"", "]", "=", "100", "*", "pq_res", "[", "\"All\"", "]", "[", "\"pq\"", "]", "\n", "res", "[", "\"SQ\"", "]", "=", "100", "*", "pq_res", "[", "\"All\"", "]", "[", "\"sq\"", "]", "\n", "res", "[", "\"RQ\"", "]", "=", "100", "*", "pq_res", "[", "\"All\"", "]", "[", "\"rq\"", "]", "\n", "res", "[", "\"PQ_th\"", "]", "=", "100", "*", "pq_res", "[", "\"Things\"", "]", "[", "\"pq\"", "]", "\n", "res", "[", "\"SQ_th\"", "]", "=", "100", "*", "pq_res", "[", "\"Things\"", "]", "[", "\"sq\"", "]", "\n", "res", "[", "\"RQ_th\"", "]", "=", "100", "*", "pq_res", "[", "\"Things\"", "]", "[", "\"rq\"", "]", "\n", "res", "[", "\"PQ_st\"", "]", "=", "100", "*", "pq_res", "[", "\"Stuff\"", "]", "[", "\"pq\"", "]", "\n", "res", "[", "\"SQ_st\"", "]", "=", "100", "*", "pq_res", "[", "\"Stuff\"", "]", "[", "\"sq\"", "]", "\n", "res", "[", "\"RQ_st\"", "]", "=", "100", "*", "pq_res", "[", "\"Stuff\"", "]", "[", "\"rq\"", "]", "\n", "\n", "results", "=", "OrderedDict", "(", "{", "\"panoptic_seg\"", ":", "res", "}", ")", "\n", "_print_panoptic_results", "(", "pq_res", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.panoptic_evaluation._print_panoptic_results": [[168, 178], ["tabulate.tabulate", "logger.info", "data.append"], "function", ["None"], ["", "", "def", "_print_panoptic_results", "(", "pq_res", ")", ":", "\n", "    ", "headers", "=", "[", "\"\"", ",", "\"PQ\"", ",", "\"SQ\"", ",", "\"RQ\"", ",", "\"#categories\"", "]", "\n", "data", "=", "[", "]", "\n", "for", "name", "in", "[", "\"All\"", ",", "\"Things\"", ",", "\"Stuff\"", "]", ":", "\n", "        ", "row", "=", "[", "name", "]", "+", "[", "pq_res", "[", "name", "]", "[", "k", "]", "*", "100", "for", "k", "in", "[", "\"pq\"", ",", "\"sq\"", ",", "\"rq\"", "]", "]", "+", "[", "pq_res", "[", "name", "]", "[", "\"n\"", "]", "]", "\n", "data", ".", "append", "(", "row", ")", "\n", "", "table", "=", "tabulate", "(", "\n", "data", ",", "headers", "=", "headers", ",", "tablefmt", "=", "\"pipe\"", ",", "floatfmt", "=", "\".3f\"", ",", "stralign", "=", "\"center\"", ",", "numalign", "=", "\"center\"", "\n", ")", "\n", "logger", ".", "info", "(", "\"Panoptic Evaluation Results:\\n\"", "+", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.__init__": [[31, 50], ["detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "os.path.join", "os.path.join", "torch.device", "logging.getLogger", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "__init__", "(", "self", ",", "dataset_name", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset, e.g., \"voc_2007_test\"\n        \"\"\"", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "\n", "# Too many tiny files, download all to local for speed.", "\n", "annotation_dir_local", "=", "PathManager", ".", "get_local_path", "(", "\n", "os", ".", "path", ".", "join", "(", "meta", ".", "dirname", ",", "\"Annotations/\"", ")", "\n", ")", "\n", "self", ".", "_anno_file_template", "=", "os", ".", "path", ".", "join", "(", "annotation_dir_local", ",", "\"{}.xml\"", ")", "\n", "self", ".", "_image_set_path", "=", "os", ".", "path", ".", "join", "(", "meta", ".", "dirname", ",", "\"ImageSets\"", ",", "\"Main\"", ",", "meta", ".", "split", "+", "\".txt\"", ")", "\n", "self", ".", "_class_names", "=", "meta", ".", "thing_classes", "\n", "assert", "meta", ".", "year", "in", "[", "2007", ",", "2012", "]", ",", "meta", ".", "year", "\n", "self", ".", "_is_2007", "=", "meta", ".", "year", "==", "2007", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.reset": [[51, 53], ["collections.defaultdict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "defaultdict", "(", "list", ")", "# class name -> list of prediction strings", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.process": [[54, 68], ["zip", "output[].to", "output[].to.pred_boxes.tensor.numpy", "output[].to.scores.tolist", "output[].to.pred_classes.tolist", "zip", "pascal_voc_evaluation.PascalVOCDetectionEvaluator._predictions[].append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "image_id", "=", "input", "[", "\"image_id\"", "]", "\n", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "for", "box", ",", "score", ",", "cls", "in", "zip", "(", "boxes", ",", "scores", ",", "classes", ")", ":", "\n", "                ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "box", "\n", "# The inverse of data loading logic in `datasets/pascal_voc.py`", "\n", "xmin", "+=", "1", "\n", "ymin", "+=", "1", "\n", "self", ".", "_predictions", "[", "cls", "]", ".", "append", "(", "\n", "f\"{image_id} {score:.3f} {xmin:.1f} {ymin:.1f} {xmax:.1f} {ymax:.1f}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.PascalVOCDetectionEvaluator.evaluate": [[70, 116], ["detectron2.utils.comm.gather", "collections.defaultdict", "pascal_voc_evaluation.PascalVOCDetectionEvaluator._logger.info", "collections.OrderedDict", "detectron2.utils.comm.is_main_process", "predictions_per_rank.items", "tempfile.TemporaryDirectory", "os.path.join", "collections.defaultdict", "enumerate", "numpy.mean", "numpy.mean", "predictions[].extend", "collections.defaultdict.get", "range", "collections.defaultdict.items", "list", "open", "f.write", "pascal_voc_evaluation.voc_eval", "aps[].append", "mAP.values", "os.path.join.format"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.voc_eval"], ["", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict: has a key \"segm\", whose value is a dict of \"AP\", \"AP50\", and \"AP75\".\n        \"\"\"", "\n", "all_predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "return", "\n", "", "predictions", "=", "defaultdict", "(", "list", ")", "\n", "for", "predictions_per_rank", "in", "all_predictions", ":", "\n", "            ", "for", "clsid", ",", "lines", "in", "predictions_per_rank", ".", "items", "(", ")", ":", "\n", "                ", "predictions", "[", "clsid", "]", ".", "extend", "(", "lines", ")", "\n", "", "", "del", "all_predictions", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluating {} using {} metric. \"", "\n", "\"Note that results do not use the official Matlab API.\"", ".", "format", "(", "\n", "self", ".", "_dataset_name", ",", "2007", "if", "self", ".", "_is_2007", "else", "2012", "\n", ")", "\n", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"pascal_voc_eval_\"", ")", "as", "dirname", ":", "\n", "            ", "res_file_template", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"{}.txt\"", ")", "\n", "\n", "aps", "=", "defaultdict", "(", "list", ")", "# iou -> ap per class", "\n", "for", "cls_id", ",", "cls_name", "in", "enumerate", "(", "self", ".", "_class_names", ")", ":", "\n", "                ", "lines", "=", "predictions", ".", "get", "(", "cls_id", ",", "[", "\"\"", "]", ")", "\n", "\n", "with", "open", "(", "res_file_template", ".", "format", "(", "cls_name", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "lines", ")", ")", "\n", "\n", "", "for", "thresh", "in", "range", "(", "50", ",", "100", ",", "5", ")", ":", "\n", "                    ", "rec", ",", "prec", ",", "ap", "=", "voc_eval", "(", "\n", "res_file_template", ",", "\n", "self", ".", "_anno_file_template", ",", "\n", "self", ".", "_image_set_path", ",", "\n", "cls_name", ",", "\n", "ovthresh", "=", "thresh", "/", "100.0", ",", "\n", "use_07_metric", "=", "self", ".", "_is_2007", ",", "\n", ")", "\n", "aps", "[", "thresh", "]", ".", "append", "(", "ap", "*", "100", ")", "\n", "\n", "", "", "", "ret", "=", "OrderedDict", "(", ")", "\n", "mAP", "=", "{", "iou", ":", "np", ".", "mean", "(", "x", ")", "for", "iou", ",", "x", "in", "aps", ".", "items", "(", ")", "}", "\n", "ret", "[", "\"bbox\"", "]", "=", "{", "\"AP\"", ":", "np", ".", "mean", "(", "list", "(", "mAP", ".", "values", "(", ")", ")", ")", ",", "\"AP50\"", ":", "mAP", "[", "50", "]", ",", "\"AP75\"", ":", "mAP", "[", "75", "]", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.parse_rec": [[131, 153], ["functools.lru_cache", "ET.parse.findall", "detectron2.utils.file_io.PathManager.open", "xml.parse", "int", "int", "obj.find", "objects.append", "obj.find", "obj.find", "int", "int", "int", "int", "obj.find", "obj.find", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find"], "function", ["None"], ["@", "lru_cache", "(", "maxsize", "=", "None", ")", "\n", "def", "parse_rec", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Parse a PASCAL VOC xml file.\"\"\"", "\n", "with", "PathManager", ".", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "tree", "=", "ET", ".", "parse", "(", "f", ")", "\n", "", "objects", "=", "[", "]", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "\"object\"", ")", ":", "\n", "        ", "obj_struct", "=", "{", "}", "\n", "obj_struct", "[", "\"name\"", "]", "=", "obj", ".", "find", "(", "\"name\"", ")", ".", "text", "\n", "obj_struct", "[", "\"pose\"", "]", "=", "obj", ".", "find", "(", "\"pose\"", ")", ".", "text", "\n", "obj_struct", "[", "\"truncated\"", "]", "=", "int", "(", "obj", ".", "find", "(", "\"truncated\"", ")", ".", "text", ")", "\n", "obj_struct", "[", "\"difficult\"", "]", "=", "int", "(", "obj", ".", "find", "(", "\"difficult\"", ")", ".", "text", ")", "\n", "bbox", "=", "obj", ".", "find", "(", "\"bndbox\"", ")", "\n", "obj_struct", "[", "\"bbox\"", "]", "=", "[", "\n", "int", "(", "bbox", ".", "find", "(", "\"xmin\"", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "\"ymin\"", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "\"xmax\"", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "\"ymax\"", ")", ".", "text", ")", ",", "\n", "]", "\n", "objects", ".", "append", "(", "obj_struct", ")", "\n", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.voc_ap": [[155, 185], ["numpy.arange", "numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "numpy.maximum", "numpy.where", "numpy.sum", "numpy.max"], "function", ["None"], ["", "def", "voc_ap", "(", "rec", ",", "prec", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute VOC AP given precision and recall. If use_07_metric is true, uses\n    the VOC 07 11-point method (default:False).\n    \"\"\"", "\n", "if", "use_07_metric", ":", "\n", "# 11 point metric", "\n", "        ", "ap", "=", "0.0", "\n", "for", "t", "in", "np", ".", "arange", "(", "0.0", ",", "1.1", ",", "0.1", ")", ":", "\n", "            ", "if", "np", ".", "sum", "(", "rec", ">=", "t", ")", "==", "0", ":", "\n", "                ", "p", "=", "0", "\n", "", "else", ":", "\n", "                ", "p", "=", "np", ".", "max", "(", "prec", "[", "rec", ">=", "t", "]", ")", "\n", "", "ap", "=", "ap", "+", "p", "/", "11.0", "\n", "", "", "else", ":", "\n", "# correct AP calculation", "\n", "# first append sentinel values at the end", "\n", "        ", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "rec", ",", "[", "1.0", "]", ")", ")", "\n", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "prec", ",", "[", "0.0", "]", ")", ")", "\n", "\n", "# compute the precision envelope", "\n", "for", "i", "in", "range", "(", "mpre", ".", "size", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "            ", "mpre", "[", "i", "-", "1", "]", "=", "np", ".", "maximum", "(", "mpre", "[", "i", "-", "1", "]", ",", "mpre", "[", "i", "]", ")", "\n", "\n", "# to calculate area under PR curve, look for points", "\n", "# where X axis (recall) changes value", "\n", "", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# and sum (\\Delta recall) * prec", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.voc_eval": [[187, 301], ["detpath.format", "numpy.array", "numpy.array().reshape", "numpy.argsort", "len", "numpy.zeros", "numpy.zeros", "range", "numpy.cumsum", "numpy.cumsum", "pascal_voc_evaluation.voc_ap", "detectron2.utils.file_io.PathManager.open", "f.readlines", "x.strip", "pascal_voc_evaluation.parse_rec", "numpy.array", "numpy.array().astype", "open", "f.readlines", "x.strip().split", "BB[].astype", "R[].astype", "float", "numpy.maximum", "annopath.format", "len", "sum", "float", "numpy.array", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.max", "numpy.argmax", "numpy.array", "x.strip", "numpy.finfo", "float"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.voc_ap", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.pascal_voc_evaluation.parse_rec"], ["", "def", "voc_eval", "(", "detpath", ",", "annopath", ",", "imagesetfile", ",", "classname", ",", "ovthresh", "=", "0.5", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"rec, prec, ap = voc_eval(detpath,\n                                annopath,\n                                imagesetfile,\n                                classname,\n                                [ovthresh],\n                                [use_07_metric])\n\n    Top level function that does the PASCAL VOC evaluation.\n\n    detpath: Path to detections\n        detpath.format(classname) should produce the detection results file.\n    annopath: Path to annotations\n        annopath.format(imagename) should be the xml annotations file.\n    imagesetfile: Text file containing the list of images, one image per line.\n    classname: Category name (duh)\n    [ovthresh]: Overlap threshold (default = 0.5)\n    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n        (default False)\n    \"\"\"", "\n", "# assumes detections are in detpath.format(classname)", "\n", "# assumes annotations are in annopath.format(imagename)", "\n", "# assumes imagesetfile is a text file with each line an image name", "\n", "\n", "# first load gt", "\n", "# read list of images", "\n", "with", "PathManager", ".", "open", "(", "imagesetfile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "imagenames", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "lines", "]", "\n", "\n", "# load annots", "\n", "recs", "=", "{", "}", "\n", "for", "imagename", "in", "imagenames", ":", "\n", "        ", "recs", "[", "imagename", "]", "=", "parse_rec", "(", "annopath", ".", "format", "(", "imagename", ")", ")", "\n", "\n", "# extract gt objects for this class", "\n", "", "class_recs", "=", "{", "}", "\n", "npos", "=", "0", "\n", "for", "imagename", "in", "imagenames", ":", "\n", "        ", "R", "=", "[", "obj", "for", "obj", "in", "recs", "[", "imagename", "]", "if", "obj", "[", "\"name\"", "]", "==", "classname", "]", "\n", "bbox", "=", "np", ".", "array", "(", "[", "x", "[", "\"bbox\"", "]", "for", "x", "in", "R", "]", ")", "\n", "difficult", "=", "np", ".", "array", "(", "[", "x", "[", "\"difficult\"", "]", "for", "x", "in", "R", "]", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "# difficult = np.array([False for x in R]).astype(np.bool)  # treat all \"difficult\" as GT", "\n", "det", "=", "[", "False", "]", "*", "len", "(", "R", ")", "\n", "npos", "=", "npos", "+", "sum", "(", "~", "difficult", ")", "\n", "class_recs", "[", "imagename", "]", "=", "{", "\"bbox\"", ":", "bbox", ",", "\"difficult\"", ":", "difficult", ",", "\"det\"", ":", "det", "}", "\n", "\n", "# read dets", "\n", "", "detfile", "=", "detpath", ".", "format", "(", "classname", ")", "\n", "with", "open", "(", "detfile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "x", "in", "lines", "]", "\n", "image_ids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "splitlines", "]", "\n", "confidence", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "1", "]", ")", "for", "x", "in", "splitlines", "]", ")", "\n", "BB", "=", "np", ".", "array", "(", "[", "[", "float", "(", "z", ")", "for", "z", "in", "x", "[", "2", ":", "]", "]", "for", "x", "in", "splitlines", "]", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "\n", "# sort by confidence", "\n", "sorted_ind", "=", "np", ".", "argsort", "(", "-", "confidence", ")", "\n", "BB", "=", "BB", "[", "sorted_ind", ",", ":", "]", "\n", "image_ids", "=", "[", "image_ids", "[", "x", "]", "for", "x", "in", "sorted_ind", "]", "\n", "\n", "# go down dets and mark TPs and FPs", "\n", "nd", "=", "len", "(", "image_ids", ")", "\n", "tp", "=", "np", ".", "zeros", "(", "nd", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "nd", ")", "\n", "for", "d", "in", "range", "(", "nd", ")", ":", "\n", "        ", "R", "=", "class_recs", "[", "image_ids", "[", "d", "]", "]", "\n", "bb", "=", "BB", "[", "d", ",", ":", "]", ".", "astype", "(", "float", ")", "\n", "ovmax", "=", "-", "np", ".", "inf", "\n", "BBGT", "=", "R", "[", "\"bbox\"", "]", ".", "astype", "(", "float", ")", "\n", "\n", "if", "BBGT", ".", "size", ">", "0", ":", "\n", "# compute overlaps", "\n", "# intersection", "\n", "            ", "ixmin", "=", "np", ".", "maximum", "(", "BBGT", "[", ":", ",", "0", "]", ",", "bb", "[", "0", "]", ")", "\n", "iymin", "=", "np", ".", "maximum", "(", "BBGT", "[", ":", ",", "1", "]", ",", "bb", "[", "1", "]", ")", "\n", "ixmax", "=", "np", ".", "minimum", "(", "BBGT", "[", ":", ",", "2", "]", ",", "bb", "[", "2", "]", ")", "\n", "iymax", "=", "np", ".", "minimum", "(", "BBGT", "[", ":", ",", "3", "]", ",", "bb", "[", "3", "]", ")", "\n", "iw", "=", "np", ".", "maximum", "(", "ixmax", "-", "ixmin", "+", "1.0", ",", "0.0", ")", "\n", "ih", "=", "np", ".", "maximum", "(", "iymax", "-", "iymin", "+", "1.0", ",", "0.0", ")", "\n", "inters", "=", "iw", "*", "ih", "\n", "\n", "# union", "\n", "uni", "=", "(", "\n", "(", "bb", "[", "2", "]", "-", "bb", "[", "0", "]", "+", "1.0", ")", "*", "(", "bb", "[", "3", "]", "-", "bb", "[", "1", "]", "+", "1.0", ")", "\n", "+", "(", "BBGT", "[", ":", ",", "2", "]", "-", "BBGT", "[", ":", ",", "0", "]", "+", "1.0", ")", "*", "(", "BBGT", "[", ":", ",", "3", "]", "-", "BBGT", "[", ":", ",", "1", "]", "+", "1.0", ")", "\n", "-", "inters", "\n", ")", "\n", "\n", "overlaps", "=", "inters", "/", "uni", "\n", "ovmax", "=", "np", ".", "max", "(", "overlaps", ")", "\n", "jmax", "=", "np", ".", "argmax", "(", "overlaps", ")", "\n", "\n", "", "if", "ovmax", ">", "ovthresh", ":", "\n", "            ", "if", "not", "R", "[", "\"difficult\"", "]", "[", "jmax", "]", ":", "\n", "                ", "if", "not", "R", "[", "\"det\"", "]", "[", "jmax", "]", ":", "\n", "                    ", "tp", "[", "d", "]", "=", "1.0", "\n", "R", "[", "\"det\"", "]", "[", "jmax", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "fp", "[", "d", "]", "=", "1.0", "\n", "", "", "", "else", ":", "\n", "            ", "fp", "[", "d", "]", "=", "1.0", "\n", "\n", "# compute precision recall", "\n", "", "", "fp", "=", "np", ".", "cumsum", "(", "fp", ")", "\n", "tp", "=", "np", ".", "cumsum", "(", "tp", ")", "\n", "rec", "=", "tp", "/", "float", "(", "npos", ")", "\n", "# avoid divide by zero in case the first detection matches a difficult", "\n", "# ground truth", "\n", "prec", "=", "tp", "/", "np", ".", "maximum", "(", "tp", "+", "fp", ",", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", ")", "\n", "ap", "=", "voc_ap", "(", "rec", ",", "prec", ",", "use_07_metric", ")", "\n", "\n", "return", "rec", ",", "prec", ",", "ap", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.print_csv_format": [[10, 27], ["logging.getLogger", "results.items", "isinstance", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "len", "res.items"], "function", ["None"], ["from", "detectron2", ".", "structures", "import", "Boxes", ",", "Instances", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "\"\"\"\nInternal utilities for tests. Don't use except for writing tests.\n\"\"\"", "\n", "\n", "\n", "def", "get_model_no_weights", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Like model_zoo.get, but do not load any weights (even pretrained)\n    \"\"\"", "\n", "cfg", "=", "model_zoo", ".", "get_config", "(", "config_path", ")", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cpu\"", "\n", "", "return", "build_model", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.verify_results": [[29, 64], ["logging.getLogger", "len", "results[].get", "abs", "logging.getLogger.error", "logging.getLogger.error", "logging.getLogger.error", "sys.exit", "logging.getLogger.info", "numpy.isfinite", "str", "pprint.pformat"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "random_boxes", "(", "num_boxes", ",", "max_coord", "=", "100", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "\"\"\"\n    Create a random Nx4 boxes tensor, with coordinates < max_coord.\n    \"\"\"", "\n", "boxes", "=", "torch", ".", "rand", "(", "num_boxes", ",", "4", ",", "device", "=", "device", ")", "*", "(", "max_coord", "*", "0.5", ")", "\n", "boxes", ".", "clamp_", "(", "min", "=", "1.0", ")", "# tiny boxes cause numerical instability in box regression", "\n", "# Note: the implementation of this function in torchvision is:", "\n", "# boxes[:, 2:] += torch.rand(N, 2) * 100", "\n", "# but it does not guarantee non-negative widths/heights constraints:", "\n", "# boxes[:, 2] >= boxes[:, 0] and boxes[:, 3] >= boxes[:, 1]:", "\n", "boxes", "[", ":", ",", "2", ":", "]", "+=", "boxes", "[", ":", ",", ":", "2", "]", "\n", "return", "boxes", "\n", "\n", "\n", "", "def", "get_sample_coco_image", "(", "tensor", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        tensor (bool): if True, returns 3xHxW tensor.\n            else, returns a HxWx3 numpy array.\n\n    Returns:\n        an image, in BGR color.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "file_name", "=", "DatasetCatalog", ".", "get", "(", "\"coco_2017_val_100\"", ")", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "if", "not", "PathManager", ".", "exists", "(", "file_name", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# for public CI to run", "\n", "        ", "file_name", "=", "\"http://images.cocodataset.org/train2017/000000000009.jpg\"", "\n", "", "ret", "=", "read_image", "(", "file_name", ",", "format", "=", "\"BGR\"", ")", "\n", "if", "tensor", ":", "\n", "        ", "ret", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "ret", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "", "return", "ret", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.flatten_results_dict": [[66, 84], ["results.items", "isinstance", "testing.flatten_results_dict", "flatten_results_dict.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.flatten_results_dict"], ["    ", "\"\"\"\n    Convert a scripted Instances object to a regular :class:`Instances` object\n    \"\"\"", "\n", "ret", "=", "Instances", "(", "instances", ".", "image_size", ")", "\n", "for", "name", "in", "instances", ".", "_field_names", ":", "\n", "        ", "val", "=", "getattr", "(", "instances", ",", "\"_\"", "+", "name", ",", "None", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "            ", "ret", ".", "set", "(", "name", ",", "val", ")", "\n", "", "", "return", "ret", "\n", "\n", "\n", "", "def", "assert_instances_allclose", "(", "input", ",", "other", ",", "*", ",", "rtol", "=", "1e-5", ",", "msg", "=", "\"\"", ",", "size_as_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input, other (Instances):\n        size_as_tensor: compare image_size of the Instances as tensors (instead of tuples).\n             Useful for comparing outputs of tracing.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input", ",", "Instances", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluator.reset": [[25, 31], ["None"], "methods", ["None"], ["def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Preparation for a new round of evaluation.\n        Should be called before starting a round of evaluation.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluator.process": [[32, 48], ["None"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Process the pair of inputs and outputs.\n        If they contain batches, the pairs can be consumed one-by-one using `zip`:\n\n        .. code-block:: python\n\n            for input_, output in zip(inputs, outputs):\n                # do evaluation on single input/output pair\n                ...\n\n        Args:\n            inputs (list): the inputs that's used to call the model.\n            outputs (list): the return value of `model(inputs)`\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluator.evaluate": [[49, 63], ["None"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate/summarize the performance, after processing all input/output pairs.\n\n        Returns:\n            dict:\n                A new evaluator class can return a dict of arbitrary format\n                as long as the user can process the results.\n                In our train_net.py, we expect the following format:\n\n                * key: the name of the task (e.g., bbox)\n                * value: a dict of {metric name: score}, e.g.: {\"AP50\": 80}\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluators.__init__": [[73, 80], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "evaluators", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            evaluators (list): the evaluators to combine.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_evaluators", "=", "evaluators", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluators.reset": [[81, 84], ["evaluator.reset"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluators.process": [[85, 88], ["evaluator.process"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.process"], ["", "", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DatasetEvaluators.evaluate": [[89, 100], ["collections.OrderedDict", "evaluator.evaluate", "detectron2.utils.comm.is_main_process", "evaluator.evaluate.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "results", "=", "OrderedDict", "(", ")", "\n", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "result", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "if", "is_main_process", "(", ")", "and", "result", "is", "not", "None", ":", "\n", "                ", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                    ", "assert", "(", "\n", "k", "not", "in", "results", "\n", ")", ",", "\"Different evaluators produce results with the same key {}\"", ".", "format", "(", "k", ")", "\n", "results", "[", "k", "]", "=", "v", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.inference_on_dataset": [[102, 188], ["detectron2.utils.comm.get_world_size", "logging.getLogger", "logging.getLogger.info", "len", "evaluator.DatasetEvaluators.reset", "min", "time.perf_counter", "str", "logging.getLogger.info", "str", "logging.getLogger.info", "evaluator.DatasetEvaluators.evaluate", "evaluator.DatasetEvaluators", "contextlib.ExitStack", "isinstance", "stack.enter_context", "enumerate", "time.perf_counter", "datetime.timedelta", "datetime.timedelta", "len", "stack.enter_context", "torch.no_grad", "time.perf_counter", "model", "torch.cuda.is_available", "evaluator.DatasetEvaluators.process", "evaluator.inference_context", "time.perf_counter", "torch.cuda.synchronize", "time.perf_counter", "datetime.timedelta", "detectron2.utils.logger.log_every_n_seconds", "int", "int", "time.perf_counter", "int", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.inference_context", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_every_n_seconds"], ["", "", "def", "inference_on_dataset", "(", "model", ",", "data_loader", ",", "evaluator", ")", ":", "\n", "    ", "\"\"\"\n    Run model on the data_loader and evaluate the metrics with evaluator.\n    Also benchmark the inference speed of `model.__call__` accurately.\n    The model will be used in eval mode.\n\n    Args:\n        model (callable): a callable which takes an object from\n            `data_loader` and returns some outputs.\n\n            If it's an nn.Module, it will be temporarily set to `eval` mode.\n            If you wish to evaluate a model in `training` mode instead, you can\n            wrap the given model and override its behavior of `.eval()` and `.train()`.\n        data_loader: an iterable object with a length.\n            The elements it generates will be the inputs to the model.\n        evaluator (DatasetEvaluator): the evaluator to run. Use `None` if you only want\n            to benchmark, but don't want to do any evaluation.\n\n    Returns:\n        The return value of `evaluator.evaluate()`\n    \"\"\"", "\n", "num_devices", "=", "get_world_size", "(", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Start inference on {} images\"", ".", "format", "(", "len", "(", "data_loader", ")", ")", ")", "\n", "\n", "total", "=", "len", "(", "data_loader", ")", "# inference data loader must have a fixed length", "\n", "if", "evaluator", "is", "None", ":", "\n", "# create a no-op evaluator", "\n", "        ", "evaluator", "=", "DatasetEvaluators", "(", "[", "]", ")", "\n", "", "evaluator", ".", "reset", "(", ")", "\n", "\n", "num_warmup", "=", "min", "(", "5", ",", "total", "-", "1", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "stack", ".", "enter_context", "(", "inference_context", "(", "model", ")", ")", "\n", "", "stack", ".", "enter_context", "(", "torch", ".", "no_grad", "(", ")", ")", "\n", "\n", "for", "idx", ",", "inputs", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "if", "idx", "==", "num_warmup", ":", "\n", "                ", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "\n", "", "start_compute_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "total_compute_time", "+=", "time", ".", "perf_counter", "(", ")", "-", "start_compute_time", "\n", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n", "iters_after_start", "=", "idx", "+", "1", "-", "num_warmup", "*", "int", "(", "idx", ">=", "num_warmup", ")", "\n", "seconds_per_img", "=", "total_compute_time", "/", "iters_after_start", "\n", "if", "idx", ">=", "num_warmup", "*", "2", "or", "seconds_per_img", ">", "5", ":", "\n", "                ", "total_seconds_per_img", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "start_time", ")", "/", "iters_after_start", "\n", "eta", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_seconds_per_img", "*", "(", "total", "-", "idx", "-", "1", ")", ")", ")", "\n", "log_every_n_seconds", "(", "\n", "logging", ".", "INFO", ",", "\n", "\"Inference done {}/{}. {:.4f} s / img. ETA={}\"", ".", "format", "(", "\n", "idx", "+", "1", ",", "total", ",", "seconds_per_img", ",", "str", "(", "eta", ")", "\n", ")", ",", "\n", "n", "=", "5", ",", "\n", ")", "\n", "\n", "# Measure the time only for this worker (before the synchronization barrier)", "\n", "", "", "", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_time", ")", ")", "\n", "# NOTE this format is parsed by grep", "\n", "logger", ".", "info", "(", "\n", "\"Total inference time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "total_compute_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_compute_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total inference pure compute time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_compute_time_str", ",", "total_compute_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "\n", "results", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "# An evaluator may return None when not in main process.", "\n", "# Replace it by an empty dict instead to make it easier for downstream code to handle", "\n", "if", "results", "is", "None", ":", "\n", "        ", "results", "=", "{", "}", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.inference_context": [[190, 203], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train"], ["", "@", "contextmanager", "\n", "def", "inference_context", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context where the model is temporarily changed to eval mode,\n    and restored to previous mode afterwards.\n\n    Args:\n        model: a torch Module\n    \"\"\"", "\n", "training_mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "training_mode", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.is_rotated": [[16, 32], ["type", "type", "numpy.all", "numpy.array", "len", "type", "type"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "is_rotated", "(", "box_list", ")", ":", "\n", "        ", "if", "type", "(", "box_list", ")", "==", "np", ".", "ndarray", ":", "\n", "            ", "return", "box_list", ".", "shape", "[", "1", "]", "==", "5", "\n", "", "elif", "type", "(", "box_list", ")", "==", "list", ":", "\n", "            ", "if", "box_list", "==", "[", "]", ":", "# cannot decide the box_dim", "\n", "                ", "return", "False", "\n", "", "return", "np", ".", "all", "(", "\n", "np", ".", "array", "(", "\n", "[", "\n", "(", "len", "(", "obj", ")", "==", "5", ")", "and", "(", "(", "type", "(", "obj", ")", "==", "list", ")", "or", "(", "type", "(", "obj", ")", "==", "np", ".", "ndarray", ")", ")", "\n", "for", "obj", "in", "box_list", "\n", "]", "\n", ")", "\n", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor": [[33, 56], ["type", "torch.from_numpy", "type", "Exception", "detectron2.structures.BoxMode.convert", "Exception", "torch.zeros", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "@", "staticmethod", "\n", "def", "boxlist_to_tensor", "(", "boxlist", ",", "output_box_dim", ")", ":", "\n", "        ", "if", "type", "(", "boxlist", ")", "==", "np", ".", "ndarray", ":", "\n", "            ", "box_tensor", "=", "torch", ".", "from_numpy", "(", "boxlist", ")", "\n", "", "elif", "type", "(", "boxlist", ")", "==", "list", ":", "\n", "            ", "if", "boxlist", "==", "[", "]", ":", "\n", "                ", "return", "torch", ".", "zeros", "(", "(", "0", ",", "output_box_dim", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "box_tensor", "=", "torch", ".", "FloatTensor", "(", "boxlist", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Unrecognized boxlist type\"", ")", "\n", "\n", "", "input_box_dim", "=", "box_tensor", ".", "shape", "[", "1", "]", "\n", "if", "input_box_dim", "!=", "output_box_dim", ":", "\n", "            ", "if", "input_box_dim", "==", "4", "and", "output_box_dim", "==", "5", ":", "\n", "                ", "box_tensor", "=", "BoxMode", ".", "convert", "(", "box_tensor", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYWHA_ABS", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Unable to convert from {}-dim box to {}-dim box\"", ".", "format", "(", "\n", "input_box_dim", ",", "output_box_dim", "\n", ")", "\n", ")", "\n", "", "", "return", "box_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.compute_iou_dt_gt": [[57, 67], ["rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "all", "detectron2.structures.RotatedBoxes", "detectron2.structures.RotatedBoxes", "detectron2.structures.pairwise_iou_rotated", "pycocotools.cocoeval.maskUtils.iou", "rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor", "rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.is_rotated", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.rotated_boxes.pairwise_iou_rotated", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.boxlist_to_tensor"], ["", "def", "compute_iou_dt_gt", "(", "self", ",", "dt", ",", "gt", ",", "is_crowd", ")", ":", "\n", "        ", "if", "self", ".", "is_rotated", "(", "dt", ")", "or", "self", ".", "is_rotated", "(", "gt", ")", ":", "\n", "# TODO: take is_crowd into consideration", "\n", "            ", "assert", "all", "(", "c", "==", "0", "for", "c", "in", "is_crowd", ")", "\n", "dt", "=", "RotatedBoxes", "(", "self", ".", "boxlist_to_tensor", "(", "dt", ",", "output_box_dim", "=", "5", ")", ")", "\n", "gt", "=", "RotatedBoxes", "(", "self", ".", "boxlist_to_tensor", "(", "gt", ",", "output_box_dim", "=", "5", ")", ")", "\n", "return", "pairwise_iou_rotated", "(", "dt", ",", "gt", ")", "\n", "", "else", ":", "\n", "# This is the same as the classical COCO evaluation", "\n", "            ", "return", "maskUtils", ".", "iou", "(", "dt", ",", "gt", ",", "is_crowd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.computeIoU": [[68, 95], ["numpy.argsort", "rotated_coco_evaluation.RotatedCOCOeval.compute_iou_dt_gt", "len", "int", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOeval.compute_iou_dt_gt"], ["", "", "def", "computeIoU", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "\"score\"", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dt", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dt", "=", "dt", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "\n", "", "assert", "p", ".", "iouType", "==", "\"bbox\"", ",", "\"unsupported iouType for iou computation\"", "\n", "\n", "g", "=", "[", "g", "[", "\"bbox\"", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "\"bbox\"", "]", "for", "d", "in", "dt", "]", "\n", "\n", "# compute iou between each dt and gt region", "\n", "iscrowd", "=", "[", "int", "(", "o", "[", "\"iscrowd\"", "]", ")", "for", "o", "in", "gt", "]", "\n", "\n", "# Note: this function is copied from cocoeval.py in cocoapi", "\n", "# and the major difference is here.", "\n", "ious", "=", "self", ".", "compute_iou_dt_gt", "(", "d", ",", "g", ",", "iscrowd", ")", "\n", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator.process": [[104, 123], ["zip", "rotated_coco_evaluation.RotatedCOCOEvaluator._predictions.append", "output[].to", "rotated_coco_evaluation.RotatedCOCOEvaluator.instances_to_json", "output[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator.instances_to_json", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a COCO model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "\n", "prediction", "[", "\"instances\"", "]", "=", "self", ".", "instances_to_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator.instances_to_json": [[124, 147], ["len", "instances.pred_boxes.tensor.numpy", "detectron2.structures.BoxMode.convert.tolist", "instances.scores.tolist", "instances.pred_classes.tolist", "range", "detectron2.structures.BoxMode.convert", "results.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "", "def", "instances_to_json", "(", "self", ",", "instances", ",", "img_id", ")", ":", "\n", "        ", "num_instance", "=", "len", "(", "instances", ")", "\n", "if", "num_instance", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "if", "boxes", ".", "shape", "[", "1", "]", "==", "4", ":", "\n", "            ", "boxes", "=", "BoxMode", ".", "convert", "(", "boxes", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "", "boxes", "=", "boxes", ".", "tolist", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "num_instance", ")", ":", "\n", "            ", "result", "=", "{", "\n", "\"image_id\"", ":", "img_id", ",", "\n", "\"category_id\"", ":", "classes", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "boxes", "[", "k", "]", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._eval_predictions": [[148, 191], ["rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "list", "hasattr", "rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "rotated_coco_evaluation.RotatedCOCOEvaluator._derive_coco_results", "itertools.chain", "os.path.join", "rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "rotated_coco_evaluation.RotatedCOCOEvaluator._logger.info", "rotated_coco_evaluation.RotatedCOCOEvaluator._evaluate_predictions_on_coco", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "set", "len", "rotated_coco_evaluation.RotatedCOCOEvaluator._metadata.get", "rotated_coco_evaluation.RotatedCOCOEvaluator._metadata.thing_dataset_id_to_contiguous_id.items", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._evaluate_predictions_on_coco", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ",", "img_ids", "=", "None", ")", ":", "# img_ids: unused", "\n", "        ", "\"\"\"\n        Evaluate predictions on the given tasks.\n        Fill self._results with the metrics of the tasks.\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results for COCO format ...\"", ")", "\n", "coco_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "\n", "# unmap the category ids for COCO", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "reverse_id_mapping", "=", "{", "\n", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "items", "(", ")", "\n", "}", "\n", "for", "result", "in", "coco_results", ":", "\n", "                ", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "result", "[", "\"category_id\"", "]", "]", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"coco_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "coco_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating predictions ...\"", ")", "\n", "\n", "assert", "self", ".", "_tasks", "is", "None", "or", "set", "(", "self", ".", "_tasks", ")", "==", "{", "\n", "\"bbox\"", "\n", "}", ",", "\"[RotatedCOCOEvaluator] Only bbox evaluation is supported\"", "\n", "coco_eval", "=", "(", "\n", "self", ".", "_evaluate_predictions_on_coco", "(", "self", ".", "_coco_api", ",", "coco_results", ")", "\n", "if", "len", "(", "coco_results", ")", ">", "0", "\n", "else", "None", "# cocoapi does not handle empty results very well", "\n", ")", "\n", "\n", "task", "=", "\"bbox\"", "\n", "res", "=", "self", ".", "_derive_coco_results", "(", "\n", "coco_eval", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.rotated_coco_evaluation.RotatedCOCOEvaluator._evaluate_predictions_on_coco": [[192, 208], ["coco_gt.loadRes", "rotated_coco_evaluation.RotatedCOCOeval", "RotatedCOCOeval.evaluate", "RotatedCOCOeval.accumulate", "RotatedCOCOeval.summarize", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize"], ["", "def", "_evaluate_predictions_on_coco", "(", "self", ",", "coco_gt", ",", "coco_results", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the coco results using COCOEval API.\n        \"\"\"", "\n", "assert", "len", "(", "coco_results", ")", ">", "0", "\n", "\n", "coco_dt", "=", "coco_gt", ".", "loadRes", "(", "coco_results", ")", "\n", "\n", "# Only bbox is supported for now", "\n", "coco_eval", "=", "RotatedCOCOeval", "(", "coco_gt", ",", "coco_dt", ",", "iouType", "=", "\"bbox\"", ")", "\n", "\n", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "\n", "return", "coco_eval", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.cityscapes_evaluation.CityscapesEvaluator.__init__": [[23, 33], ["detectron2.data.MetadataCatalog.get", "torch.device", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "__init__", "(", "self", ",", "dataset_name", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): the name of the dataset.\n                It must have the following metadata associated with it:\n                \"thing_classes\", \"gt_dir\".\n        \"\"\"", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.cityscapes_evaluation.CityscapesEvaluator.reset": [[34, 44], ["tempfile.TemporaryDirectory", "cityscapes_evaluation.CityscapesEvaluator._logger.info", "detectron2.utils.comm.all_gather", "cityscapes_evaluation.CityscapesEvaluator._working_dir.cleanup"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.all_gather"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_working_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"cityscapes_eval_\"", ")", "\n", "self", ".", "_temp_dir", "=", "self", ".", "_working_dir", ".", "name", "\n", "# All workers will write to the same results directory", "\n", "# TODO this does not work in distributed training", "\n", "self", ".", "_temp_dir", "=", "comm", ".", "all_gather", "(", "self", ".", "_temp_dir", ")", "[", "0", "]", "\n", "if", "self", ".", "_temp_dir", "!=", "self", ".", "_working_dir", ".", "name", ":", "\n", "            ", "self", ".", "_working_dir", ".", "cleanup", "(", ")", "\n", "", "self", ".", "_logger", ".", "info", "(", "\n", "\"Writing cityscapes results to temporary directory {} ...\"", ".", "format", "(", "self", ".", "_temp_dir", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.cityscapes_evaluation.CityscapesInstanceEvaluator.process": [[57, 87], ["zip", "os.path.join", "os.path.splitext", "output[].to", "len", "os.path.basename", "open", "range", "open", "output[].to.pred_masks[].numpy().astype", "os.path.join", "PIL.Image.fromarray().save", "fout.write", "output[].to.pred_masks[].numpy", "PIL.Image.fromarray", "os.path.basename"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "from", "cityscapesscripts", ".", "helpers", ".", "labels", "import", "name2label", "\n", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "file_name", "=", "input", "[", "\"file_name\"", "]", "\n", "basename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "file_name", ")", ")", "[", "0", "]", "\n", "pred_txt", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_temp_dir", ",", "basename", "+", "\"_pred.txt\"", ")", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "output", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "num_instances", "=", "len", "(", "output", ")", "\n", "with", "open", "(", "pred_txt", ",", "\"w\"", ")", "as", "fout", ":", "\n", "                    ", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "                        ", "pred_class", "=", "output", ".", "pred_classes", "[", "i", "]", "\n", "classes", "=", "self", ".", "_metadata", ".", "thing_classes", "[", "pred_class", "]", "\n", "class_id", "=", "name2label", "[", "classes", "]", ".", "id", "\n", "score", "=", "output", ".", "scores", "[", "i", "]", "\n", "mask", "=", "output", ".", "pred_masks", "[", "i", "]", ".", "numpy", "(", ")", ".", "astype", "(", "\"uint8\"", ")", "\n", "png_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_temp_dir", ",", "basename", "+", "\"_{}_{}.png\"", ".", "format", "(", "i", ",", "classes", ")", "\n", ")", "\n", "\n", "Image", ".", "fromarray", "(", "mask", "*", "255", ")", ".", "save", "(", "png_filename", ")", "\n", "fout", ".", "write", "(", "\n", "\"{} {} {}\\n\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "png_filename", ")", ",", "class_id", ",", "score", ")", "\n", ")", "\n", "", "", "", "else", ":", "\n", "# Cityscapes requires a prediction file for every ground truth image.", "\n", "                ", "with", "open", "(", "pred_txt", ",", "\"w\"", ")", "as", "fout", ":", "\n", "                    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.cityscapes_evaluation.CityscapesInstanceEvaluator.evaluate": [[88, 127], ["detectron2.utils.comm.synchronize", "cityscapes_evaluation.CityscapesInstanceEvaluator._logger.info", "os.path.abspath", "os.path.join", "detectron2.utils.file_io.PathManager.get_local_path", "glob.glob", "len", "collections.OrderedDict", "cityscapes_evaluation.CityscapesInstanceEvaluator._working_dir.cleanup", "detectron2.utils.comm.get_rank", "os.path.join", "predictionImgList.append", "cityscapes_eval.evaluateImgLists", "cityscapes_eval.getPrediction"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict: has a key \"segm\", whose value is a dict of \"AP\" and \"AP50\".\n        \"\"\"", "\n", "comm", ".", "synchronize", "(", ")", "\n", "if", "comm", ".", "get_rank", "(", ")", ">", "0", ":", "\n", "            ", "return", "\n", "", "import", "cityscapesscripts", ".", "evaluation", ".", "evalInstanceLevelSemanticLabeling", "as", "cityscapes_eval", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Evaluating results under {} ...\"", ".", "format", "(", "self", ".", "_temp_dir", ")", ")", "\n", "\n", "# set some global states in cityscapes evaluation API, before evaluating", "\n", "cityscapes_eval", ".", "args", ".", "predictionPath", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "_temp_dir", ")", "\n", "cityscapes_eval", ".", "args", ".", "predictionWalk", "=", "None", "\n", "cityscapes_eval", ".", "args", ".", "JSONOutput", "=", "False", "\n", "cityscapes_eval", ".", "args", ".", "colorized", "=", "False", "\n", "cityscapes_eval", ".", "args", ".", "gtInstancesFile", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_temp_dir", ",", "\"gtInstances.json\"", ")", "\n", "\n", "# These lines are adopted from", "\n", "# https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/evalInstanceLevelSemanticLabeling.py # noqa", "\n", "gt_dir", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "gt_dir", ")", "\n", "groundTruthImgList", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "\"*\"", ",", "\"*_gtFine_instanceIds.png\"", ")", ")", "\n", "assert", "len", "(", "\n", "groundTruthImgList", "\n", ")", ",", "\"Cannot find any ground truth images to use for evaluation. Searched for: {}\"", ".", "format", "(", "\n", "cityscapes_eval", ".", "args", ".", "groundTruthSearch", "\n", ")", "\n", "predictionImgList", "=", "[", "]", "\n", "for", "gt", "in", "groundTruthImgList", ":", "\n", "            ", "predictionImgList", ".", "append", "(", "cityscapes_eval", ".", "getPrediction", "(", "gt", ",", "cityscapes_eval", ".", "args", ")", ")", "\n", "", "results", "=", "cityscapes_eval", ".", "evaluateImgLists", "(", "\n", "predictionImgList", ",", "groundTruthImgList", ",", "cityscapes_eval", ".", "args", "\n", ")", "[", "\"averages\"", "]", "\n", "\n", "ret", "=", "OrderedDict", "(", ")", "\n", "ret", "[", "\"segm\"", "]", "=", "{", "\"AP\"", ":", "results", "[", "\"allAp\"", "]", "*", "100", ",", "\"AP50\"", ":", "results", "[", "\"allAp50%\"", "]", "*", "100", "}", "\n", "self", ".", "_working_dir", ".", "cleanup", "(", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.cityscapes_evaluation.CityscapesSemSegEvaluator.process": [[139, 154], ["zip", "os.path.join", "output[].argmax().to().numpy", "trainId2label.items", "PIL.Image.fromarray().save", "os.path.splitext", "numpy.ones", "os.path.basename", "output[].argmax().to", "PIL.Image.fromarray", "output[].argmax"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "from", "cityscapesscripts", ".", "helpers", ".", "labels", "import", "trainId2label", "\n", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "file_name", "=", "input", "[", "\"file_name\"", "]", "\n", "basename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "file_name", ")", ")", "[", "0", "]", "\n", "pred_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_temp_dir", ",", "basename", "+", "\"_pred.png\"", ")", "\n", "\n", "output", "=", "output", "[", "\"sem_seg\"", "]", ".", "argmax", "(", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "_cpu_device", ")", ".", "numpy", "(", ")", "\n", "pred", "=", "255", "*", "np", ".", "ones", "(", "output", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "train_id", ",", "label", "in", "trainId2label", ".", "items", "(", ")", ":", "\n", "                ", "if", "label", ".", "ignoreInEval", ":", "\n", "                    ", "continue", "\n", "", "pred", "[", "output", "==", "train_id", "]", "=", "label", ".", "id", "\n", "", "Image", ".", "fromarray", "(", "pred", ")", ".", "save", "(", "pred_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.cityscapes_evaluation.CityscapesSemSegEvaluator.evaluate": [[155, 195], ["detectron2.utils.comm.synchronize", "cityscapes_evaluation.CityscapesSemSegEvaluator._logger.info", "os.path.abspath", "detectron2.utils.file_io.PathManager.get_local_path", "glob.glob", "len", "cityscapes_eval.evaluateImgLists", "collections.OrderedDict", "cityscapes_evaluation.CityscapesSemSegEvaluator._working_dir.cleanup", "detectron2.utils.comm.get_rank", "os.path.join", "predictionImgList.append", "cityscapes_eval.getPrediction"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "comm", ".", "synchronize", "(", ")", "\n", "if", "comm", ".", "get_rank", "(", ")", ">", "0", ":", "\n", "            ", "return", "\n", "# Load the Cityscapes eval script *after* setting the required env var,", "\n", "# since the script reads CITYSCAPES_DATASET into global variables at load time.", "\n", "", "import", "cityscapesscripts", ".", "evaluation", ".", "evalPixelLevelSemanticLabeling", "as", "cityscapes_eval", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Evaluating results under {} ...\"", ".", "format", "(", "self", ".", "_temp_dir", ")", ")", "\n", "\n", "# set some global states in cityscapes evaluation API, before evaluating", "\n", "cityscapes_eval", ".", "args", ".", "predictionPath", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "_temp_dir", ")", "\n", "cityscapes_eval", ".", "args", ".", "predictionWalk", "=", "None", "\n", "cityscapes_eval", ".", "args", ".", "JSONOutput", "=", "False", "\n", "cityscapes_eval", ".", "args", ".", "colorized", "=", "False", "\n", "\n", "# These lines are adopted from", "\n", "# https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/evalPixelLevelSemanticLabeling.py # noqa", "\n", "gt_dir", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "gt_dir", ")", "\n", "groundTruthImgList", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "gt_dir", ",", "\"*\"", ",", "\"*_gtFine_labelIds.png\"", ")", ")", "\n", "assert", "len", "(", "\n", "groundTruthImgList", "\n", ")", ",", "\"Cannot find any ground truth images to use for evaluation. Searched for: {}\"", ".", "format", "(", "\n", "cityscapes_eval", ".", "args", ".", "groundTruthSearch", "\n", ")", "\n", "predictionImgList", "=", "[", "]", "\n", "for", "gt", "in", "groundTruthImgList", ":", "\n", "            ", "predictionImgList", ".", "append", "(", "cityscapes_eval", ".", "getPrediction", "(", "cityscapes_eval", ".", "args", ",", "gt", ")", ")", "\n", "", "results", "=", "cityscapes_eval", ".", "evaluateImgLists", "(", "\n", "predictionImgList", ",", "groundTruthImgList", ",", "cityscapes_eval", ".", "args", "\n", ")", "\n", "ret", "=", "OrderedDict", "(", ")", "\n", "ret", "[", "\"sem_seg\"", "]", "=", "{", "\n", "\"IoU\"", ":", "100.0", "*", "results", "[", "\"averageScoreClasses\"", "]", ",", "\n", "\"iIoU\"", ":", "100.0", "*", "results", "[", "\"averageScoreInstClasses\"", "]", ",", "\n", "\"IoU_sup\"", ":", "100.0", "*", "results", "[", "\"averageScoreCategories\"", "]", ",", "\n", "\"iIoU_sup\"", ":", "100.0", "*", "results", "[", "\"averageScoreInstCategories\"", "]", ",", "\n", "}", "\n", "self", ".", "_working_dir", ".", "cleanup", "(", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.d2_evaluator_adapter.Detectron2COCOEvaluatorAdapter.__init__": [[19, 32], ["detectron2.evaluation.COCOEvaluator.__init__", "densepose.data.datasets.coco.maybe_filter_categories_cocoapi", "d2_evaluator_adapter._maybe_add_iscrowd_annotations", "hasattr", "d2_evaluator_adapter.Detectron2COCOEvaluatorAdapter._maybe_substitute_metadata"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.maybe_filter_categories_cocoapi", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.d2_evaluator_adapter._maybe_add_iscrowd_annotations", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.d2_evaluator_adapter.Detectron2COCOEvaluatorAdapter._maybe_substitute_metadata"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "output_dir", "=", "None", ",", "\n", "distributed", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset_name", ",", "output_dir", "=", "output_dir", ",", "distributed", "=", "distributed", ")", "\n", "maybe_filter_categories_cocoapi", "(", "dataset_name", ",", "self", ".", "_coco_api", ")", "\n", "_maybe_add_iscrowd_annotations", "(", "self", ".", "_coco_api", ")", "\n", "# substitute category metadata to account for categories", "\n", "# that are mapped to the same contiguous id", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "self", ".", "_maybe_substitute_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.d2_evaluator_adapter.Detectron2COCOEvaluatorAdapter._maybe_substitute_metadata": [[33, 51], ["densepose.data.datasets.coco.get_contiguous_id_to_category_id_map", "cat_id_2_cont_id.items", "detectron2.data.catalog.Metadata", "d2_evaluator_adapter.Detectron2COCOEvaluatorAdapter._metadata.__dict__.items", "len", "len", "setattr", "setattr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.get_contiguous_id_to_category_id_map"], ["", "", "def", "_maybe_substitute_metadata", "(", "self", ")", ":", "\n", "        ", "cont_id_2_cat_id", "=", "get_contiguous_id_to_category_id_map", "(", "self", ".", "_metadata", ")", "\n", "cat_id_2_cont_id", "=", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", "\n", "if", "len", "(", "cont_id_2_cat_id", ")", "==", "len", "(", "cat_id_2_cont_id", ")", ":", "\n", "            ", "return", "\n", "\n", "", "cat_id_2_cont_id_injective", "=", "{", "}", "\n", "for", "cat_id", ",", "cont_id", "in", "cat_id_2_cont_id", ".", "items", "(", ")", ":", "\n", "            ", "if", "(", "cont_id", "in", "cont_id_2_cat_id", ")", "and", "(", "cont_id_2_cat_id", "[", "cont_id", "]", "==", "cat_id", ")", ":", "\n", "                ", "cat_id_2_cont_id_injective", "[", "cat_id", "]", "=", "cont_id", "\n", "\n", "", "", "metadata_new", "=", "Metadata", "(", "name", "=", "self", ".", "_metadata", ".", "name", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "_metadata", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "\"thing_dataset_id_to_contiguous_id\"", ":", "\n", "                ", "setattr", "(", "metadata_new", ",", "key", ",", "cat_id_2_cont_id_injective", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "metadata_new", ",", "key", ",", "value", ")", "\n", "", "", "self", ".", "_metadata", "=", "metadata_new", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.d2_evaluator_adapter._maybe_add_iscrowd_annotations": [[12, 16], ["None"], "function", ["None"], ["def", "_maybe_add_iscrowd_annotations", "(", "cocoapi", ")", ":", "\n", "    ", "for", "ann", "in", "cocoapi", ".", "dataset", "[", "\"annotations\"", "]", ":", "\n", "        ", "if", "\"iscrowd\"", "not", "in", "ann", ":", "\n", "            ", "ann", "[", "\"iscrowd\"", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.SingleProcessTensorStorage.__init__": [[49, 75], ["tensor_storage._calculate_record_size_b", "tensor_storage._calculate_record_field_sizes_b"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_size_b", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_field_sizes_b"], ["def", "__init__", "(", "self", ",", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ",", "storage_impl", ":", "BinaryIO", ")", ":", "\n", "        ", "\"\"\"\n        Construct tensor storage based on information on data shape and size.\n        Internally uses numpy to interpret the type specification.\n        The storage must support operations `seek(offset, whence=os.SEEK_SET)` and\n        `read(size)` to be able to perform the `get` operation.\n        The storage must support operation `write(bytes)` to be able to perform\n        the `put` operation.\n\n        Args:\n            data_schema (dict: str -> SizeData): dictionary which maps tensor name\n                to its size data (shape and data type), e.g.\n                ```\n                {\n                  \"coarse_segm\": SizeData(dtype=\"float32\", shape=(112, 112)),\n                  \"embedding\": SizeData(dtype=\"float32\", shape=(16, 112, 112)),\n                }\n                ```\n            storage_impl (BinaryIO): io instance that handles file-like seek, read\n                and write operations, e.g. a file handle or a memory buffer like io.BytesIO\n        \"\"\"", "\n", "self", ".", "data_schema", "=", "data_schema", "\n", "self", ".", "record_size_b", "=", "_calculate_record_size_b", "(", "data_schema", ")", "\n", "self", ".", "record_field_sizes_b", "=", "_calculate_record_field_sizes_b", "(", "data_schema", ")", "\n", "self", ".", "storage_impl", "=", "storage_impl", "\n", "self", ".", "next_record_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.SingleProcessTensorStorage.get": [[76, 105], ["tensor_storage.SingleProcessTensorStorage.storage_impl.seek", "tensor_storage.SingleProcessTensorStorage.storage_impl.read", "sorted", "len", "numpy.frombuffer().reshape", "torch.from_numpy", "len", "numpy.frombuffer", "functools.reduce"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "record_id", ":", "int", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Load tensors from the storage by record ID\n\n        Args:\n            record_id (int): Record ID, for which to load the data\n\n        Return:\n            dict: str -> tensor: tensor name mapped to tensor data, recorded under the provided ID\n        \"\"\"", "\n", "self", ".", "storage_impl", ".", "seek", "(", "record_id", "*", "self", ".", "record_size_b", ",", "os", ".", "SEEK_SET", ")", "\n", "data_bytes", "=", "self", ".", "storage_impl", ".", "read", "(", "self", ".", "record_size_b", ")", "\n", "assert", "len", "(", "data_bytes", ")", "==", "self", ".", "record_size_b", ",", "(", "\n", "f\"Expected data size {self.record_size_b} B could not be read: \"", "\n", "f\"got {len(data_bytes)} B\"", "\n", ")", "\n", "record", "=", "{", "}", "\n", "cur_idx", "=", "0", "\n", "# it's important to read and write in the same order", "\n", "for", "field_name", "in", "sorted", "(", "self", ".", "data_schema", ")", ":", "\n", "            ", "schema", "=", "self", ".", "data_schema", "[", "field_name", "]", "\n", "field_size_b", "=", "self", ".", "record_field_sizes_b", "[", "field_name", "]", "\n", "chunk", "=", "data_bytes", "[", "cur_idx", ":", "cur_idx", "+", "field_size_b", "]", "\n", "data_np", "=", "np", ".", "frombuffer", "(", "\n", "chunk", ",", "dtype", "=", "schema", ".", "dtype", ",", "count", "=", "reduce", "(", "mul", ",", "schema", ".", "shape", ")", "\n", ")", ".", "reshape", "(", "schema", ".", "shape", ")", "\n", "record", "[", "field_name", "]", "=", "torch", ".", "from_numpy", "(", "data_np", ")", "\n", "cur_idx", "+=", "field_size_b", "\n", "", "return", "record", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.SingleProcessTensorStorage.put": [[106, 136], ["sorted", "value.cpu().numpy().tobytes", "tensor_storage.SingleProcessTensorStorage.storage_impl.write", "len", "data.keys", "value.cpu().numpy", "len", "value.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["", "def", "put", "(", "self", ",", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Store tensors in the storage\n\n        Args:\n            data (dict: str -> tensor): data to store, a dictionary which maps\n                tensor names into tensors; tensor shapes must match those specified\n                in data schema.\n        Return:\n            int: record ID, under which the data is stored\n        \"\"\"", "\n", "# it's important to read and write in the same order", "\n", "for", "field_name", "in", "sorted", "(", "self", ".", "data_schema", ")", ":", "\n", "            ", "assert", "(", "\n", "field_name", "in", "data", "\n", ")", ",", "f\"Field '{field_name}' not present in data: data keys are {data.keys()}\"", "\n", "value", "=", "data", "[", "field_name", "]", "\n", "assert", "value", ".", "shape", "==", "self", ".", "data_schema", "[", "field_name", "]", ".", "shape", ",", "(", "\n", "f\"Mismatched tensor shapes for field '{field_name}': \"", "\n", "f\"expected {self.data_schema[field_name].shape}, got {value.shape}\"", "\n", ")", "\n", "data_bytes", "=", "value", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "\n", "assert", "len", "(", "data_bytes", ")", "==", "self", ".", "record_field_sizes_b", "[", "field_name", "]", ",", "(", "\n", "f\"Expected field {field_name} to be of size \"", "\n", "f\"{self.record_field_sizes_b[field_name]} B, got {len(data_bytes)} B\"", "\n", ")", "\n", "self", ".", "storage_impl", ".", "write", "(", "data_bytes", ")", "\n", "", "record_id", "=", "self", ".", "next_record_id", "\n", "self", ".", "next_record_id", "+=", "1", "\n", "return", "record_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.SingleProcessFileTensorStorage.__init__": [[143, 154], ["tensor_storage.SingleProcessTensorStorage.__init__", "detectron2.utils.file_io.PathManager.open", "detectron2.utils.file_io.PathManager.get_local_path", "open", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ",", "fpath", ":", "str", ",", "mode", ":", "str", ")", ":", "\n", "        ", "self", ".", "fpath", "=", "fpath", "\n", "assert", "\"b\"", "in", "mode", ",", "f\"Tensor storage should be opened in binary mode, got '{mode}'\"", "\n", "if", "\"w\"", "in", "mode", ":", "\n", "            ", "file_h", "=", "PathManager", ".", "open", "(", "fpath", ",", "mode", ")", "\n", "", "elif", "\"r\"", "in", "mode", ":", "\n", "            ", "local_fpath", "=", "PathManager", ".", "get_local_path", "(", "fpath", ")", "\n", "file_h", "=", "open", "(", "local_fpath", ",", "mode", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unsupported file mode {mode}, supported modes: rb, wb\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "data_schema", ",", "file_h", ")", "# pyre-ignore[6]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.SingleProcessRamTensorStorage.__init__": [[161, 163], ["tensor_storage.SingleProcessTensorStorage.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ",", "buf", ":", "io", ".", "BytesIO", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "data_schema", ",", "buf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.__init__": [[174, 176], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "rank_to_storage", ":", "Dict", "[", "int", ",", "SingleProcessTensorStorage", "]", ")", ":", "\n", "        ", "self", ".", "rank_to_storage", "=", "rank_to_storage", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.get": [[177, 180], ["storage.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "get", "(", "self", ",", "rank", ":", "int", ",", "record_id", ":", "int", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "storage", "=", "self", ".", "rank_to_storage", "[", "rank", "]", "\n", "return", "storage", ".", "get", "(", "record_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put": [[181, 184], ["storage.put"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put"], ["", "def", "put", "(", "self", ",", "rank", ":", "int", ",", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "int", ":", "\n", "        ", "storage", "=", "self", ".", "rank_to_storage", "[", "rank", "]", "\n", "return", "storage", ".", "put", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessFileTensorStorage.__init__": [[187, 193], ["tensor_storage.MultiProcessTensorStorage.__init__", "tensor_storage.SingleProcessFileTensorStorage", "rank_to_fpath.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ",", "rank_to_fpath", ":", "Dict", "[", "int", ",", "str", "]", ",", "mode", ":", "str", ")", ":", "\n", "        ", "rank_to_storage", "=", "{", "\n", "rank", ":", "SingleProcessFileTensorStorage", "(", "data_schema", ",", "fpath", ",", "mode", ")", "\n", "for", "rank", ",", "fpath", "in", "rank_to_fpath", ".", "items", "(", ")", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "rank_to_storage", ")", "# pyre-ignore[6]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessRamTensorStorage.__init__": [[196, 202], ["tensor_storage.MultiProcessTensorStorage.__init__", "tensor_storage.SingleProcessRamTensorStorage", "rank_to_buffer.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ",", "rank_to_buffer", ":", "Dict", "[", "int", ",", "io", ".", "BytesIO", "]", ")", ":", "\n", "        ", "rank_to_storage", "=", "{", "\n", "rank", ":", "SingleProcessRamTensorStorage", "(", "data_schema", ",", "buf", ")", "\n", "for", "rank", ",", "buf", "in", "rank_to_buffer", ".", "items", "(", ")", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "rank_to_storage", ")", "# pyre-ignore[6]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_field_size_b": [[22, 27], ["numpy.dtype", "functools.reduce"], "function", ["None"], ["", "def", "_calculate_record_field_size_b", "(", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ",", "field_name", ":", "str", ")", "->", "int", ":", "\n", "    ", "schema", "=", "data_schema", "[", "field_name", "]", "\n", "element_size_b", "=", "np", ".", "dtype", "(", "schema", ".", "dtype", ")", ".", "itemsize", "\n", "record_field_size_b", "=", "reduce", "(", "mul", ",", "schema", ".", "shape", ")", "*", "element_size_b", "\n", "return", "record_field_size_b", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_size_b": [[29, 35], ["tensor_storage._calculate_record_field_size_b"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_field_size_b"], ["", "def", "_calculate_record_size_b", "(", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ")", "->", "int", ":", "\n", "    ", "record_size_b", "=", "0", "\n", "for", "field_name", "in", "data_schema", ":", "\n", "        ", "record_field_size_b", "=", "_calculate_record_field_size_b", "(", "data_schema", ",", "field_name", ")", "\n", "record_size_b", "+=", "record_field_size_b", "\n", "", "return", "record_size_b", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_field_sizes_b": [[37, 42], ["tensor_storage._calculate_record_field_size_b"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._calculate_record_field_size_b"], ["", "def", "_calculate_record_field_sizes_b", "(", "data_schema", ":", "Dict", "[", "str", ",", "SizeData", "]", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "    ", "field_sizes_b", "=", "{", "}", "\n", "for", "field_name", "in", "data_schema", ":", "\n", "        ", "field_sizes_b", "[", "field_name", "]", "=", "_calculate_record_field_size_b", "(", "data_schema", ",", "field_name", ")", "\n", "", "return", "field_sizes_b", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._ram_storage_gather": [[204, 216], ["storage.storage_impl.seek", "detectron2.utils.comm.gather", "tensor_storage.MultiProcessRamTensorStorage", "storage.storage_impl.read", "detectron2.utils.comm.get_rank", "io.BytesIO", "range", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "", "def", "_ram_storage_gather", "(", "\n", "storage", ":", "SingleProcessRamTensorStorage", ",", "dst_rank", ":", "int", "=", "0", "\n", ")", "->", "Optional", "[", "MultiProcessRamTensorStorage", "]", ":", "\n", "    ", "storage", ".", "storage_impl", ".", "seek", "(", "0", ",", "os", ".", "SEEK_SET", ")", "\n", "# TODO: overhead, pickling a bytes object, can just pass bytes in a tensor directly", "\n", "# see detectron2/utils.comm.py", "\n", "data_list", "=", "gather", "(", "storage", ".", "storage_impl", ".", "read", "(", ")", ",", "dst", "=", "dst_rank", ")", "\n", "if", "get_rank", "(", ")", "!=", "dst_rank", ":", "\n", "        ", "return", "None", "\n", "", "rank_to_buffer", "=", "{", "i", ":", "io", ".", "BytesIO", "(", "data_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "data_list", ")", ")", "}", "\n", "multiprocess_storage", "=", "MultiProcessRamTensorStorage", "(", "storage", ".", "data_schema", ",", "rank_to_buffer", ")", "\n", "return", "multiprocess_storage", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._file_storage_gather": [[218, 229], ["storage.storage_impl.close", "detectron2.utils.comm.gather", "tensor_storage.MultiProcessFileTensorStorage", "detectron2.utils.comm.get_rank", "range", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["", "def", "_file_storage_gather", "(", "\n", "storage", ":", "SingleProcessFileTensorStorage", ",", "\n", "dst_rank", ":", "int", "=", "0", ",", "\n", "mode", ":", "str", "=", "\"rb\"", ",", "\n", ")", "->", "Optional", "[", "MultiProcessFileTensorStorage", "]", ":", "\n", "    ", "storage", ".", "storage_impl", ".", "close", "(", ")", "\n", "fpath_list", "=", "gather", "(", "storage", ".", "fpath", ",", "dst", "=", "dst_rank", ")", "\n", "if", "get_rank", "(", ")", "!=", "dst_rank", ":", "\n", "        ", "return", "None", "\n", "", "rank_to_fpath", "=", "{", "i", ":", "fpath_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "fpath_list", ")", ")", "}", "\n", "return", "MultiProcessFileTensorStorage", "(", "storage", ".", "data_schema", ",", "rank_to_fpath", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.storage_gather": [[231, 239], ["isinstance", "Exception", "tensor_storage._ram_storage_gather", "isinstance", "tensor_storage._file_storage_gather"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._ram_storage_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage._file_storage_gather"], ["", "def", "storage_gather", "(", "\n", "storage", ":", "SingleProcessTensorStorage", ",", "dst_rank", ":", "int", "=", "0", "\n", ")", "->", "Optional", "[", "MultiProcessTensorStorage", "]", ":", "\n", "    ", "if", "isinstance", "(", "storage", ",", "SingleProcessRamTensorStorage", ")", ":", "\n", "        ", "return", "_ram_storage_gather", "(", "storage", ",", "dst_rank", ")", "\n", "", "elif", "isinstance", "(", "storage", ",", "SingleProcessFileTensorStorage", ")", ":", "\n", "        ", "return", "_file_storage_gather", "(", "storage", ",", "dst_rank", ")", "\n", "", "raise", "Exception", "(", "f\"Unsupported storage for gather operation: {storage}\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.__init__": [[45, 70], ["torch.device", "logging.getLogger", "detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "densepose.data.datasets.coco.maybe_filter_and_map_categories_cocoapi", "contextlib.redirect_stdout", "pycocotools.coco.COCO", "io.StringIO"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.coco.maybe_filter_and_map_categories_cocoapi"], ["\n", "pass", "\n", "\n", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate/summarize the performance, after processing all input/output pairs.\n\n        Returns:\n            dict:\n                A new evaluator class can return a dict of arbitrary format\n                as long as the user can process the results.\n                In our train_net.py, we expect the following format:\n\n                * key: the name of the task (e.g., bbox)\n                * value: a dict of {metric name: score}, e.g.: {\"AP50\": 80}\n        \"\"\"", "\n", "pass", "\n", "\n", "\n", "", "", "class", "DatasetEvaluators", "(", "DatasetEvaluator", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.reset": [[71, 73], ["None"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "evaluators", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.process": [[74, 106], ["zip", "output[].to", "evaluator.prediction_to_dict", "evaluator.DensePoseCOCOEvaluator._predictions.extend", "output[].to.has", "evaluator.DensePoseCOCOEvaluator._storage.put", "detectron2.utils.comm.get_rank"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.prediction_to_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["        ", "\"\"\"\n        Args:\n            evaluators (list): the evaluators to combine.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_evaluators", "=", "evaluators", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "reset", "(", ")", "\n", "\n", "", "", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "results", "=", "OrderedDict", "(", ")", "\n", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "result", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "if", "is_main_process", "(", ")", "and", "result", "is", "not", "None", ":", "\n", "                ", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                    ", "assert", "(", "\n", "k", "not", "in", "results", "\n", ")", ",", "\"Different evaluators produce results with the same key {}\"", ".", "format", "(", "k", ")", "\n", "results", "[", "k", "]", "=", "v", "\n", "", "", "", "return", "results", "\n", "\n", "\n", "", "", "def", "inference_on_dataset", "(", "model", ",", "data_loader", ",", "evaluator", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator.evaluate": [[107, 120], ["copy.deepcopy", "detectron2.utils.comm.synchronize", "detectron2.utils.comm.gather", "list", "tensor_storage.storage_gather", "detectron2.utils.comm.is_main_process", "evaluator.DensePoseCOCOEvaluator._eval_predictions", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.storage_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator._eval_predictions"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.DensePoseCOCOEvaluator._eval_predictions": [[121, 149], ["evaluator.DensePoseCOCOEvaluator._logger.info", "evaluator.DensePoseCOCOEvaluator._logger.info", "collections.OrderedDict", "evaluator._evaluate_predictions_on_coco", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "detectron2.utils.file_io.PathManager.open", "torch.save", "evaluator.DensePoseCOCOEvaluator._metadata.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._evaluate_predictions_on_coco", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "num_devices", "=", "get_world_size", "(", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Start inference on {} images\"", ".", "format", "(", "len", "(", "data_loader", ")", ")", ")", "\n", "\n", "total", "=", "len", "(", "data_loader", ")", "# inference data loader must have a fixed length", "\n", "if", "evaluator", "is", "None", ":", "\n", "# create a no-op evaluator", "\n", "        ", "evaluator", "=", "DatasetEvaluators", "(", "[", "]", ")", "\n", "", "evaluator", ".", "reset", "(", ")", "\n", "\n", "num_warmup", "=", "min", "(", "5", ",", "total", "-", "1", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "stack", ".", "enter_context", "(", "inference_context", "(", "model", ")", ")", "\n", "", "stack", ".", "enter_context", "(", "torch", ".", "no_grad", "(", ")", ")", "\n", "\n", "for", "idx", ",", "inputs", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "if", "idx", "==", "num_warmup", ":", "\n", "                ", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "\n", "", "start_compute_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.prediction_to_dict": [[151, 186], ["instances.scores.tolist", "instances.pred_classes.tolist", "detectron2.structures.BoxMode.convert", "isinstance", "range", "instances.pred_boxes.tensor.clone", "evaluator.densepose_cse_predictions_to_dict", "isinstance", "len", "results.append", "raw_boxes_xywh[].tolist", "evaluator.densepose_chart_predictions_to_dict", "evaluator.densepose_chart_predictions_to_storage_dict"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.densepose_cse_predictions_to_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.densepose_chart_predictions_to_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.densepose_chart_predictions_to_storage_dict"], ["evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n", "iters_after_start", "=", "idx", "+", "1", "-", "num_warmup", "*", "int", "(", "idx", ">=", "num_warmup", ")", "\n", "seconds_per_img", "=", "total_compute_time", "/", "iters_after_start", "\n", "if", "idx", ">=", "num_warmup", "*", "2", "or", "seconds_per_img", ">", "5", ":", "\n", "                ", "total_seconds_per_img", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "start_time", ")", "/", "iters_after_start", "\n", "eta", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_seconds_per_img", "*", "(", "total", "-", "idx", "-", "1", ")", ")", ")", "\n", "log_every_n_seconds", "(", "\n", "logging", ".", "INFO", ",", "\n", "\"Inference done {}/{}. {:.4f} s / img. ETA={}\"", ".", "format", "(", "\n", "idx", "+", "1", ",", "total", ",", "seconds_per_img", ",", "str", "(", "eta", ")", "\n", ")", ",", "\n", "n", "=", "5", ",", "\n", ")", "\n", "\n", "# Measure the time only for this worker (before the synchronization barrier)", "\n", "", "", "", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_time", ")", ")", "\n", "# NOTE this format is parsed by grep", "\n", "logger", ".", "info", "(", "\n", "\"Total inference time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "total_compute_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_compute_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total inference pure compute time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_compute_time_str", ",", "total_compute_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "\n", "results", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "# An evaluator may return None when not in main process.", "\n", "# Replace it by an empty dict instead to make it easier for downstream code to handle", "\n", "if", "results", "is", "None", ":", "\n", "        ", "results", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.densepose_chart_predictions_to_dict": [[188, 212], ["densepose.converters.ToMaskConverter.convert", "range", "len", "densepose.structures.quantize_densepose_chart_result", "densepose.structures.quantize_densepose_chart_result.labels_uv_uint8.cpu", "pycocotools.encode", "segmentation_encoded[].decode", "results.append", "densepose.converters.ToChartResultConverter.convert", "numpy.require", "segmentation.numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.quantize_densepose_chart_result", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["\n", "\n", "", "@", "contextmanager", "\n", "def", "inference_context", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context where the model is temporarily changed to eval mode,\n    and restored to previous mode afterwards.\n\n    Args:\n        model: a torch Module\n    \"\"\"", "\n", "training_mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "training_mode", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.densepose_chart_predictions_to_storage_dict": [[214, 226], ["range", "len", "results.append", "densepose_predictor_output.coarse_segm.squeeze().cpu", "densepose_predictor_output.fine_segm.squeeze().cpu", "densepose_predictor_output.u.squeeze().cpu", "densepose_predictor_output.v.squeeze().cpu", "densepose_predictor_output.coarse_segm.squeeze", "densepose_predictor_output.fine_segm.squeeze", "densepose_predictor_output.u.squeeze", "densepose_predictor_output.v.squeeze"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.densepose_cse_predictions_to_dict": [[228, 239], ["range", "len", "results.append", "cse.coarse_segm[].cpu", "cse.embedding[].cpu"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._evaluate_predictions_on_coco": [[241, 273], ["logging.getLogger", "evaluator._get_densepose_metrics", "coco_gt.loadRes", "len", "logging.getLogger.warn", "getattr", "densepose_coco_evaluation.DensePoseCocoEval", "evaluator._derive_results_from_coco_eval", "results.append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._get_densepose_metrics", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._derive_results_from_coco_eval"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._get_densepose_metrics": [[275, 285], ["metrics.extend"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator._derive_results_from_coco_eval": [[287, 337], ["numpy.linspace", "coco_eval.evaluate", "coco_eval.accumulate", "coco_eval.summarize", "logging.getLogger", "logging.getLogger.info", "enumerate", "min", "list", "itertools.zip_longest", "tabulate.tabulate", "logging.getLogger.info", "results.update", "float", "len", "results_per_category.append", "itertools.chain", "int", "enumerate", "detectron2.utils.logger.create_small_table", "len", "numpy.mean", "float", "len", "numpy.round", "float", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.create_small_table"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.evaluator.build_densepose_evaluator_storage": [[339, 375], ["tensor_storage.SingleProcessRamTensorStorage", "tensor_storage.SizeData", "tensor_storage.SizeData", "tensor_storage.SizeData", "tensor_storage.SizeData", "ValueError", "io.BytesIO", "os.path.join", "detectron2.utils.file_io.PathManager.mkdirs", "tensor_storage.SingleProcessFileTensorStorage", "ValueError", "tensor_storage.SizeData", "tensor_storage.SizeData", "detectron2.utils.comm.get_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.__init__": [[112, 147], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "densepose_coco_evaluation.Params", "sorted", "sorted", "cocoGt.getImgIds", "cocoGt.getCatIds"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cocoGt", "=", "None", ",", "\n", "cocoDt", "=", "None", ",", "\n", "iouType", ":", "str", "=", "\"densepose\"", ",", "\n", "multi_storage", "=", "None", ",", "\n", "embedder", "=", "None", ",", "\n", "dpEvalMode", ":", "DensePoseEvalMode", "=", "DensePoseEvalMode", ".", "GPS", ",", "\n", "dpDataMode", ":", "DensePoseDataMode", "=", "DensePoseDataMode", ".", "IUV_DT", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize CocoEval using coco APIs for gt and dt\n        :param cocoGt: coco object with ground truth annotations\n        :param cocoDt: coco object with detection results\n        :return: None\n        \"\"\"", "\n", "self", ".", "cocoGt", "=", "cocoGt", "# ground truth COCO API", "\n", "self", ".", "cocoDt", "=", "cocoDt", "# detections COCO API", "\n", "self", ".", "multi_storage", "=", "multi_storage", "\n", "self", ".", "embedder", "=", "embedder", "\n", "self", ".", "_dpEvalMode", "=", "dpEvalMode", "\n", "self", ".", "_dpDataMode", "=", "dpDataMode", "\n", "self", ".", "evalImgs", "=", "defaultdict", "(", "list", ")", "# per-image per-category eval results [KxAxI]", "\n", "self", ".", "eval", "=", "{", "}", "# accumulated evaluation results", "\n", "self", ".", "_gts", "=", "defaultdict", "(", "list", ")", "# gt for evaluation", "\n", "self", ".", "_dts", "=", "defaultdict", "(", "list", ")", "# dt for evaluation", "\n", "self", ".", "params", "=", "Params", "(", "iouType", "=", "iouType", ")", "# parameters", "\n", "self", ".", "_paramsEval", "=", "{", "}", "# parameters for evaluation", "\n", "self", ".", "stats", "=", "[", "]", "# result summarization", "\n", "self", ".", "ious", "=", "{", "}", "# ious between all gts and dts", "\n", "if", "cocoGt", "is", "not", "None", ":", "\n", "            ", "self", ".", "params", ".", "imgIds", "=", "sorted", "(", "cocoGt", ".", "getImgIds", "(", ")", ")", "\n", "self", ".", "params", ".", "catIds", "=", "sorted", "(", "cocoGt", ".", "getCatIds", "(", ")", ")", "\n", "", "self", ".", "ignoreThrBB", "=", "0.7", "\n", "self", ".", "ignoreThrUV", "=", "0.9", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._loadGEval": [[148, 180], ["detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.get_local_path", "detectron2.utils.file_io.PathManager.get_local_path", "scipy.io.loadmat", "scipy.io.loadmat", "densepose_coco_evaluation.DensePoseCocoEval.PDIST_transform[].squeeze", "numpy.array().squeeze", "numpy.arange", "numpy.array", "numpy.array", "numpy.array", "numpy.arange", "densepose_coco_evaluation.DensePoseCocoEval.Part_UVs.append", "densepose_coco_evaluation.DensePoseCocoEval.Part_ClosestVertInds.append", "open", "pickle.load", "SMPL_subdiv[].squeeze", "numpy.array", "SMPL_subdiv[].squeeze", "SMPL_subdiv[].squeeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "_loadGEval", "(", "self", ")", ":", "\n", "        ", "smpl_subdiv_fpath", "=", "PathManager", ".", "get_local_path", "(", "\n", "\"https://dl.fbaipublicfiles.com/densepose/data/SMPL_subdiv.mat\"", "\n", ")", "\n", "pdist_transform_fpath", "=", "PathManager", ".", "get_local_path", "(", "\n", "\"https://dl.fbaipublicfiles.com/densepose/data/SMPL_SUBDIV_TRANSFORM.mat\"", "\n", ")", "\n", "pdist_matrix_fpath", "=", "PathManager", ".", "get_local_path", "(", "\n", "\"https://dl.fbaipublicfiles.com/densepose/data/Pdist_matrix.pkl\"", ",", "timeout_sec", "=", "120", "\n", ")", "\n", "SMPL_subdiv", "=", "loadmat", "(", "smpl_subdiv_fpath", ")", "\n", "self", ".", "PDIST_transform", "=", "loadmat", "(", "pdist_transform_fpath", ")", "\n", "self", ".", "PDIST_transform", "=", "self", ".", "PDIST_transform", "[", "\"index\"", "]", ".", "squeeze", "(", ")", "\n", "UV", "=", "np", ".", "array", "(", "[", "SMPL_subdiv", "[", "\"U_subdiv\"", "]", ",", "SMPL_subdiv", "[", "\"V_subdiv\"", "]", "]", ")", ".", "squeeze", "(", ")", "\n", "ClosestVertInds", "=", "np", ".", "arange", "(", "UV", ".", "shape", "[", "1", "]", ")", "+", "1", "\n", "self", ".", "Part_UVs", "=", "[", "]", "\n", "self", ".", "Part_ClosestVertInds", "=", "[", "]", "\n", "for", "i", "in", "np", ".", "arange", "(", "24", ")", ":", "\n", "            ", "self", ".", "Part_UVs", ".", "append", "(", "UV", "[", ":", ",", "SMPL_subdiv", "[", "\"Part_ID_subdiv\"", "]", ".", "squeeze", "(", ")", "==", "(", "i", "+", "1", ")", "]", ")", "\n", "self", ".", "Part_ClosestVertInds", ".", "append", "(", "\n", "ClosestVertInds", "[", "SMPL_subdiv", "[", "\"Part_ID_subdiv\"", "]", ".", "squeeze", "(", ")", "==", "(", "i", "+", "1", ")", "]", "\n", ")", "\n", "\n", "", "with", "open", "(", "pdist_matrix_fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "            ", "arrays", "=", "pickle", ".", "load", "(", "hFile", ",", "encoding", "=", "\"latin1\"", ")", "\n", "", "self", ".", "Pdist_matrix", "=", "arrays", "[", "\"Pdist_matrix\"", "]", "\n", "self", ".", "Part_ids", "=", "np", ".", "array", "(", "SMPL_subdiv", "[", "\"Part_ID_subdiv\"", "]", ".", "squeeze", "(", ")", ")", "\n", "# Mean geodesic distances for parts.", "\n", "self", ".", "Mean_Distances", "=", "np", ".", "array", "(", "[", "0", ",", "0.351", ",", "0.107", ",", "0.126", ",", "0.237", ",", "0.173", ",", "0.142", ",", "0.128", ",", "0.150", "]", ")", "\n", "# Coarse Part labels.", "\n", "self", ".", "CoarseParts", "=", "np", ".", "array", "(", "\n", "[", "0", ",", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "4", ",", "4", ",", "4", ",", "4", ",", "5", ",", "5", ",", "5", ",", "5", ",", "6", ",", "6", ",", "6", ",", "6", ",", "7", ",", "7", ",", "7", ",", "7", ",", "8", ",", "8", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._prepare": [[182, 299], ["densepose_coco_evaluation.DensePoseCocoEval.cocoGt.loadImgs", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "pycocotools.mask.frPyObjects", "pycocotools.mask.merge", "pycocotools.mask.decode", "numpy.array().astype", "min", "min", "numpy.require", "densepose_coco_evaluation.DensePoseCocoEval._extract_mask", "numpy.require", "pycocotools.mask.encode", "pycocotools.mask.encode", "densepose_coco_evaluation.DensePoseCocoEval.cocoGt.loadAnns", "densepose_coco_evaluation.DensePoseCocoEval.cocoDt.loadAnns", "densepose_coco_evaluation.DensePoseCocoEval.cocoGt.loadAnns", "densepose_coco_evaluation.DensePoseCocoEval.cocoDt.loadAnns", "densepose_coco_evaluation.DensePoseCocoEval._loadGEval", "densepose_coco_evaluation.DensePoseCocoEval._prepare._toMask"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._extract_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._loadGEval"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Prepare ._gts and ._dts for evaluation based on params\n        :return: None\n        \"\"\"", "\n", "\n", "def", "_toMask", "(", "anns", ",", "coco", ")", ":", "\n", "# modify ann['segmentation'] by reference", "\n", "            ", "for", "ann", "in", "anns", ":", "\n", "# safeguard for invalid segmentation annotation;", "\n", "# annotations containing empty lists exist in the posetrack", "\n", "# dataset. This is not a correct segmentation annotation", "\n", "# in terms of COCO format; we need to deal with it somehow", "\n", "                ", "segm", "=", "ann", "[", "\"segmentation\"", "]", "\n", "if", "type", "(", "segm", ")", "==", "list", "and", "len", "(", "segm", ")", "==", "0", ":", "\n", "                    ", "ann", "[", "\"segmentation\"", "]", "=", "None", "\n", "continue", "\n", "", "rle", "=", "coco", ".", "annToRLE", "(", "ann", ")", "\n", "ann", "[", "\"segmentation\"", "]", "=", "rle", "\n", "\n", "", "", "def", "_getIgnoreRegion", "(", "iid", ",", "coco", ")", ":", "\n", "            ", "img", "=", "coco", ".", "imgs", "[", "iid", "]", "\n", "\n", "if", "\"ignore_regions_x\"", "not", "in", "img", ".", "keys", "(", ")", ":", "\n", "                ", "return", "None", "\n", "\n", "", "if", "len", "(", "img", "[", "\"ignore_regions_x\"", "]", ")", "==", "0", ":", "\n", "                ", "return", "None", "\n", "\n", "", "rgns_merged", "=", "[", "\n", "[", "v", "for", "xy", "in", "zip", "(", "region_x", ",", "region_y", ")", "for", "v", "in", "xy", "]", "\n", "for", "region_x", ",", "region_y", "in", "zip", "(", "img", "[", "\"ignore_regions_x\"", "]", ",", "img", "[", "\"ignore_regions_y\"", "]", ")", "\n", "]", "\n", "rles", "=", "maskUtils", ".", "frPyObjects", "(", "rgns_merged", ",", "img", "[", "\"height\"", "]", ",", "img", "[", "\"width\"", "]", ")", "\n", "rle", "=", "maskUtils", ".", "merge", "(", "rles", ")", "\n", "return", "maskUtils", ".", "decode", "(", "rle", ")", "\n", "\n", "", "def", "_checkIgnore", "(", "dt", ",", "iregion", ")", ":", "\n", "            ", "if", "iregion", "is", "None", ":", "\n", "                ", "return", "True", "\n", "\n", "", "bb", "=", "np", ".", "array", "(", "dt", "[", "\"bbox\"", "]", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "bb", "[", "0", "]", ",", "bb", "[", "1", "]", ",", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", ",", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "\n", "x2", "=", "min", "(", "[", "x2", ",", "iregion", ".", "shape", "[", "1", "]", "]", ")", "\n", "y2", "=", "min", "(", "[", "y2", ",", "iregion", ".", "shape", "[", "0", "]", "]", ")", "\n", "\n", "if", "bb", "[", "2", "]", "*", "bb", "[", "3", "]", "==", "0", ":", "\n", "                ", "return", "False", "\n", "\n", "", "crop_iregion", "=", "iregion", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "\n", "\n", "if", "crop_iregion", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "return", "True", "\n", "\n", "", "if", "\"densepose\"", "not", "in", "dt", ".", "keys", "(", ")", ":", "# filtering boxes", "\n", "                ", "return", "crop_iregion", ".", "sum", "(", ")", "/", "bb", "[", "2", "]", "/", "bb", "[", "3", "]", "<", "self", ".", "ignoreThrBB", "\n", "\n", "# filtering UVs", "\n", "", "ignoremask", "=", "np", ".", "require", "(", "crop_iregion", ",", "requirements", "=", "[", "\"F\"", "]", ")", "\n", "mask", "=", "self", ".", "_extract_mask", "(", "dt", ")", "\n", "uvmask", "=", "np", ".", "require", "(", "np", ".", "asarray", "(", "mask", ">", "0", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "requirements", "=", "[", "\"F\"", "]", ")", "\n", "uvmask_", "=", "maskUtils", ".", "encode", "(", "uvmask", ")", "\n", "ignoremask_", "=", "maskUtils", ".", "encode", "(", "ignoremask", ")", "\n", "uviou", "=", "maskUtils", ".", "iou", "(", "[", "uvmask_", "]", ",", "[", "ignoremask_", "]", ",", "[", "1", "]", ")", "[", "0", "]", "\n", "return", "uviou", "<", "self", ".", "ignoreThrUV", "\n", "\n", "", "p", "=", "self", ".", "params", "\n", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gts", "=", "self", ".", "cocoGt", ".", "loadAnns", "(", "self", ".", "cocoGt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ",", "catIds", "=", "p", ".", "catIds", ")", ")", "\n", "dts", "=", "self", ".", "cocoDt", ".", "loadAnns", "(", "self", ".", "cocoDt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ",", "catIds", "=", "p", ".", "catIds", ")", ")", "\n", "", "else", ":", "\n", "            ", "gts", "=", "self", ".", "cocoGt", ".", "loadAnns", "(", "self", ".", "cocoGt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ")", ")", "\n", "dts", "=", "self", ".", "cocoDt", ".", "loadAnns", "(", "self", ".", "cocoDt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ")", ")", "\n", "\n", "", "imns", "=", "self", ".", "cocoGt", ".", "loadImgs", "(", "p", ".", "imgIds", ")", "\n", "self", ".", "size_mapping", "=", "{", "}", "\n", "for", "im", "in", "imns", ":", "\n", "            ", "self", ".", "size_mapping", "[", "im", "[", "\"id\"", "]", "]", "=", "[", "im", "[", "\"height\"", "]", ",", "im", "[", "\"width\"", "]", "]", "\n", "\n", "# if iouType == 'uv', add point gt annotations", "\n", "", "if", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "            ", "self", ".", "_loadGEval", "(", ")", "\n", "\n", "# convert ground truth to mask if iouType == 'segm'", "\n", "", "if", "p", ".", "iouType", "==", "\"segm\"", ":", "\n", "            ", "_toMask", "(", "gts", ",", "self", ".", "cocoGt", ")", "\n", "_toMask", "(", "dts", ",", "self", ".", "cocoDt", ")", "\n", "\n", "# set ignore flag", "\n", "", "for", "gt", "in", "gts", ":", "\n", "            ", "gt", "[", "\"ignore\"", "]", "=", "gt", "[", "\"ignore\"", "]", "if", "\"ignore\"", "in", "gt", "else", "0", "\n", "gt", "[", "\"ignore\"", "]", "=", "\"iscrowd\"", "in", "gt", "and", "gt", "[", "\"iscrowd\"", "]", "\n", "if", "p", ".", "iouType", "==", "\"keypoints\"", ":", "\n", "                ", "gt", "[", "\"ignore\"", "]", "=", "(", "gt", "[", "\"num_keypoints\"", "]", "==", "0", ")", "or", "gt", "[", "\"ignore\"", "]", "\n", "", "if", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "                ", "gt", "[", "\"ignore\"", "]", "=", "(", "\"dp_x\"", "in", "gt", ")", "==", "0", "\n", "", "if", "p", ".", "iouType", "==", "\"segm\"", ":", "\n", "                ", "gt", "[", "\"ignore\"", "]", "=", "gt", "[", "\"segmentation\"", "]", "is", "None", "\n", "\n", "", "", "self", ".", "_gts", "=", "defaultdict", "(", "list", ")", "# gt for evaluation", "\n", "self", ".", "_dts", "=", "defaultdict", "(", "list", ")", "# dt for evaluation", "\n", "self", ".", "_igrgns", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "gt", "in", "gts", ":", "\n", "            ", "iid", "=", "gt", "[", "\"image_id\"", "]", "\n", "if", "iid", "not", "in", "self", ".", "_igrgns", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "_igrgns", "[", "iid", "]", "=", "_getIgnoreRegion", "(", "iid", ",", "self", ".", "cocoGt", ")", "\n", "", "if", "_checkIgnore", "(", "gt", ",", "self", ".", "_igrgns", "[", "iid", "]", ")", ":", "\n", "                ", "self", ".", "_gts", "[", "iid", ",", "gt", "[", "\"category_id\"", "]", "]", ".", "append", "(", "gt", ")", "\n", "", "", "for", "dt", "in", "dts", ":", "\n", "            ", "iid", "=", "dt", "[", "\"image_id\"", "]", "\n", "if", "(", "iid", "not", "in", "self", ".", "_igrgns", ")", "or", "_checkIgnore", "(", "dt", ",", "self", ".", "_igrgns", "[", "iid", "]", ")", ":", "\n", "                ", "self", ".", "_dts", "[", "iid", ",", "dt", "[", "\"category_id\"", "]", "]", ".", "append", "(", "dt", ")", "\n", "\n", "", "", "self", ".", "evalImgs", "=", "defaultdict", "(", "list", ")", "# per-image per-category evaluation results", "\n", "self", ".", "eval", "=", "{", "}", "# accumulated evaluation results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate": [[300, 350], ["time.time", "logger.info", "list", "sorted", "densepose_coco_evaluation.DensePoseCocoEval._prepare", "copy.deepcopy", "time.time", "logger.info", "logger.info", "numpy.unique", "list", "densepose_coco_evaluation.DensePoseCocoEval.computeIoU"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._prepare", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeIoU"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n        :return: None\n        \"\"\"", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Running per image DensePose evaluation... {}\"", ".", "format", "(", "self", ".", "params", ".", "iouType", ")", ")", "\n", "p", "=", "self", ".", "params", "\n", "# add backward compatibility if useSegm is specified in params", "\n", "if", "p", ".", "useSegm", "is", "not", "None", ":", "\n", "            ", "p", ".", "iouType", "=", "\"segm\"", "if", "p", ".", "useSegm", "==", "1", "else", "\"bbox\"", "\n", "logger", ".", "info", "(", "\"useSegm (deprecated) is not None. Running DensePose evaluation\"", ")", "\n", "", "p", ".", "imgIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "imgIds", ")", ")", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "p", ".", "catIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "catIds", ")", ")", "\n", "", "p", ".", "maxDets", "=", "sorted", "(", "p", ".", "maxDets", ")", "\n", "self", ".", "params", "=", "p", "\n", "\n", "self", ".", "_prepare", "(", ")", "\n", "# loop through images, area range, max detection number", "\n", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "else", "[", "-", "1", "]", "\n", "\n", "if", "p", ".", "iouType", "in", "[", "\"segm\"", ",", "\"bbox\"", "]", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeIoU", "\n", "", "elif", "p", ".", "iouType", "==", "\"keypoints\"", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeOks", "\n", "", "elif", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeOgps", "\n", "if", "self", ".", "_dpEvalMode", "in", "{", "DensePoseEvalMode", ".", "GPSM", ",", "DensePoseEvalMode", ".", "IOU", "}", ":", "\n", "                ", "self", ".", "real_ious", "=", "{", "\n", "(", "imgId", ",", "catId", ")", ":", "self", ".", "computeDPIoU", "(", "imgId", ",", "catId", ")", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "for", "catId", "in", "catIds", "\n", "}", "\n", "\n", "", "", "self", ".", "ious", "=", "{", "\n", "(", "imgId", ",", "catId", ")", ":", "computeIoU", "(", "imgId", ",", "catId", ")", "for", "imgId", "in", "p", ".", "imgIds", "for", "catId", "in", "catIds", "\n", "}", "\n", "\n", "evaluateImg", "=", "self", ".", "evaluateImg", "\n", "maxDet", "=", "p", ".", "maxDets", "[", "-", "1", "]", "\n", "self", ".", "evalImgs", "=", "[", "\n", "evaluateImg", "(", "imgId", ",", "catId", ",", "areaRng", ",", "maxDet", ")", "\n", "for", "catId", "in", "catIds", "\n", "for", "areaRng", "in", "p", ".", "areaRng", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "self", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"DensePose evaluation DONE (t={:0.2f}s).\"", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.getDensePoseMask": [[351, 359], ["numpy.zeros", "min", "range", "len", "pycocotools.mask.decode"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["", "def", "getDensePoseMask", "(", "self", ",", "polys", ")", ":", "\n", "        ", "maskGen", "=", "np", ".", "zeros", "(", "[", "256", ",", "256", "]", ")", "\n", "stop", "=", "min", "(", "len", "(", "polys", ")", "+", "1", ",", "15", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "stop", ")", ":", "\n", "            ", "if", "polys", "[", "i", "-", "1", "]", ":", "\n", "                ", "currentMask", "=", "maskUtils", ".", "decode", "(", "polys", "[", "i", "-", "1", "]", ")", "\n", "maskGen", "[", "currentMask", ">", "0", "]", "=", "i", "\n", "", "", "return", "maskGen", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image": [[360, 376], ["numpy.array", "numpy.zeros", "numpy.require", "max", "min", "max", "min", "int", "int", "numpy.asarray", "pycocotools.mask.encode", "int", "int", "int", "int", "numpy.array", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["", "def", "_generate_rlemask_on_image", "(", "self", ",", "mask", ",", "imgId", ",", "data", ")", ":", "\n", "        ", "bbox_xywh", "=", "np", ".", "array", "(", "data", "[", "\"bbox\"", "]", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "bbox_xywh", "\n", "im_h", ",", "im_w", "=", "self", ".", "size_mapping", "[", "imgId", "]", "\n", "im_mask", "=", "np", ".", "zeros", "(", "(", "im_h", ",", "im_w", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x0", "=", "max", "(", "int", "(", "x", ")", ",", "0", ")", "\n", "x1", "=", "min", "(", "int", "(", "x", "+", "w", ")", ",", "im_w", ",", "int", "(", "x", ")", "+", "mask", ".", "shape", "[", "1", "]", ")", "\n", "y0", "=", "max", "(", "int", "(", "y", ")", ",", "0", ")", "\n", "y1", "=", "min", "(", "int", "(", "y", "+", "h", ")", ",", "im_h", ",", "int", "(", "y", ")", "+", "mask", ".", "shape", "[", "0", "]", ")", "\n", "y", "=", "int", "(", "y", ")", "\n", "x", "=", "int", "(", "x", ")", "\n", "im_mask", "[", "y0", ":", "y1", ",", "x0", ":", "x1", "]", "=", "mask", "[", "y0", "-", "y", ":", "y1", "-", "y", ",", "x0", "-", "x", ":", "x1", "-", "x", "]", "\n", "", "im_mask", "=", "np", ".", "require", "(", "np", ".", "asarray", "(", "im_mask", ">", "0", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "requirements", "=", "[", "\"F\"", "]", ")", "\n", "rle_mask", "=", "maskUtils", ".", "encode", "(", "np", ".", "array", "(", "im_mask", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", ",", "order", "=", "\"F\"", ")", ")", "[", "0", "]", "\n", "return", "rle_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeDPIoU": [[377, 435], ["numpy.argsort", "pycocotools.mask.iou", "len", "gtmasks.append", "densepose_coco_evaluation.DensePoseCocoEval._extract_mask", "numpy.require", "densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "dtmasks.append", "int", "len", "len", "numpy.minimum", "scipy.ndimage.zoom", "numpy.array", "densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "numpy.asarray", "o.get", "densepose_coco_evaluation.DensePoseCocoEval.getDensePoseMask", "float", "float", "densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "max", "max", "isinstance", "pycocotools.mask.frPyObjects", "pycocotools.mask.merge", "isinstance", "isinstance", "densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "pycocotools.mask.frPyObjects"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._extract_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.getDensePoseMask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._generate_rlemask_on_image"], ["", "def", "computeDPIoU", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "\"score\"", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dt", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dt", "=", "dt", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "\n", "", "gtmasks", "=", "[", "]", "\n", "for", "g", "in", "gt", ":", "\n", "            ", "if", "DensePoseDataRelative", ".", "S_KEY", "in", "g", ":", "\n", "# convert DensePose mask to a binary mask", "\n", "                ", "mask", "=", "np", ".", "minimum", "(", "self", ".", "getDensePoseMask", "(", "g", "[", "DensePoseDataRelative", ".", "S_KEY", "]", ")", ",", "1.0", ")", "\n", "_", ",", "_", ",", "w", ",", "h", "=", "g", "[", "\"bbox\"", "]", "\n", "scale_x", "=", "float", "(", "max", "(", "w", ",", "1", ")", ")", "/", "mask", ".", "shape", "[", "1", "]", "\n", "scale_y", "=", "float", "(", "max", "(", "h", ",", "1", ")", ")", "/", "mask", ".", "shape", "[", "0", "]", "\n", "mask", "=", "spzoom", "(", "mask", ",", "(", "scale_y", ",", "scale_x", ")", ",", "order", "=", "1", ",", "prefilter", "=", "False", ")", "\n", "mask", "=", "np", ".", "array", "(", "mask", ">", "0.5", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "rle_mask", "=", "self", ".", "_generate_rlemask_on_image", "(", "mask", ",", "imgId", ",", "g", ")", "\n", "", "elif", "\"segmentation\"", "in", "g", ":", "\n", "                ", "segmentation", "=", "g", "[", "\"segmentation\"", "]", "\n", "if", "isinstance", "(", "segmentation", ",", "list", ")", "and", "segmentation", ":", "\n", "# polygons", "\n", "                    ", "im_h", ",", "im_w", "=", "self", ".", "size_mapping", "[", "imgId", "]", "\n", "rles", "=", "maskUtils", ".", "frPyObjects", "(", "segmentation", ",", "im_h", ",", "im_w", ")", "\n", "rle_mask", "=", "maskUtils", ".", "merge", "(", "rles", ")", "\n", "", "elif", "isinstance", "(", "segmentation", ",", "dict", ")", ":", "\n", "                    ", "if", "isinstance", "(", "segmentation", "[", "\"counts\"", "]", ",", "list", ")", ":", "\n", "# uncompressed RLE", "\n", "                        ", "im_h", ",", "im_w", "=", "self", ".", "size_mapping", "[", "imgId", "]", "\n", "rle_mask", "=", "maskUtils", ".", "frPyObjects", "(", "segmentation", ",", "im_h", ",", "im_w", ")", "\n", "", "else", ":", "\n", "# compressed RLE", "\n", "                        ", "rle_mask", "=", "segmentation", "\n", "", "", "else", ":", "\n", "                    ", "rle_mask", "=", "self", ".", "_generate_rlemask_on_image", "(", "None", ",", "imgId", ",", "g", ")", "\n", "", "", "else", ":", "\n", "                ", "rle_mask", "=", "self", ".", "_generate_rlemask_on_image", "(", "None", ",", "imgId", ",", "g", ")", "\n", "", "gtmasks", ".", "append", "(", "rle_mask", ")", "\n", "\n", "", "dtmasks", "=", "[", "]", "\n", "for", "d", "in", "dt", ":", "\n", "            ", "mask", "=", "self", ".", "_extract_mask", "(", "d", ")", "\n", "mask", "=", "np", ".", "require", "(", "np", ".", "asarray", "(", "mask", ">", "0", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "requirements", "=", "[", "\"F\"", "]", ")", "\n", "rle_mask", "=", "self", ".", "_generate_rlemask_on_image", "(", "mask", ",", "imgId", ",", "d", ")", "\n", "dtmasks", ".", "append", "(", "rle_mask", ")", "\n", "\n", "# compute iou between each dt and gt region", "\n", "", "iscrowd", "=", "[", "int", "(", "o", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", "for", "o", "in", "gt", "]", "\n", "iousDP", "=", "maskUtils", ".", "iou", "(", "dtmasks", ",", "gtmasks", ",", "iscrowd", ")", "\n", "return", "iousDP", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeIoU": [[436, 464], ["numpy.argsort", "pycocotools.mask.iou", "len", "int", "len", "len", "Exception", "o.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "computeIoU", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "\"score\"", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dt", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dt", "=", "dt", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "\n", "", "if", "p", ".", "iouType", "==", "\"segm\"", ":", "\n", "            ", "g", "=", "[", "g", "[", "\"segmentation\"", "]", "for", "g", "in", "gt", "if", "g", "[", "\"segmentation\"", "]", "is", "not", "None", "]", "\n", "d", "=", "[", "d", "[", "\"segmentation\"", "]", "for", "d", "in", "dt", "if", "d", "[", "\"segmentation\"", "]", "is", "not", "None", "]", "\n", "", "elif", "p", ".", "iouType", "==", "\"bbox\"", ":", "\n", "            ", "g", "=", "[", "g", "[", "\"bbox\"", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "\"bbox\"", "]", "for", "d", "in", "dt", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"unknown iouType for iou computation\"", ")", "\n", "\n", "# compute iou between each dt and gt region", "\n", "", "iscrowd", "=", "[", "int", "(", "o", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", "for", "o", "in", "gt", "]", "\n", "ious", "=", "maskUtils", ".", "iou", "(", "d", ",", "g", ",", "iscrowd", ")", "\n", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOks": [[465, 535], ["numpy.argsort", "numpy.zeros", "len", "enumerate", "len", "numpy.array", "numpy.array", "numpy.count_nonzero", "enumerate", "len", "len", "len", "len", "numpy.array", "numpy.zeros", "numpy.sum", "numpy.max", "numpy.max", "numpy.max", "numpy.max", "numpy.exp", "numpy.spacing"], "methods", ["None"], ["", "def", "computeOks", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "# dimension here should be Nxm", "\n", "gts", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dts", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "\"score\"", "]", "for", "d", "in", "dts", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "dts", "=", "[", "dts", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dts", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dts", "=", "dts", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "# if len(gts) == 0 and len(dts) == 0:", "\n", "", "if", "len", "(", "gts", ")", "==", "0", "or", "len", "(", "dts", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "dts", ")", ",", "len", "(", "gts", ")", ")", ")", "\n", "sigmas", "=", "(", "\n", "np", ".", "array", "(", "\n", "[", "\n", "0.26", ",", "\n", "0.25", ",", "\n", "0.25", ",", "\n", "0.35", ",", "\n", "0.35", ",", "\n", "0.79", ",", "\n", "0.79", ",", "\n", "0.72", ",", "\n", "0.72", ",", "\n", "0.62", ",", "\n", "0.62", ",", "\n", "1.07", ",", "\n", "1.07", ",", "\n", "0.87", ",", "\n", "0.87", ",", "\n", "0.89", ",", "\n", "0.89", ",", "\n", "]", "\n", ")", "\n", "/", "10.0", "\n", ")", "\n", "vars", "=", "(", "sigmas", "*", "2", ")", "**", "2", "\n", "k", "=", "len", "(", "sigmas", ")", "\n", "# compute oks between each detection and ground truth object", "\n", "for", "j", ",", "gt", "in", "enumerate", "(", "gts", ")", ":", "\n", "# create bounds for ignore regions(double the gt bbox)", "\n", "            ", "g", "=", "np", ".", "array", "(", "gt", "[", "\"keypoints\"", "]", ")", "\n", "xg", "=", "g", "[", "0", ":", ":", "3", "]", "\n", "yg", "=", "g", "[", "1", ":", ":", "3", "]", "\n", "vg", "=", "g", "[", "2", ":", ":", "3", "]", "\n", "k1", "=", "np", ".", "count_nonzero", "(", "vg", ">", "0", ")", "\n", "bb", "=", "gt", "[", "\"bbox\"", "]", "\n", "x0", "=", "bb", "[", "0", "]", "-", "bb", "[", "2", "]", "\n", "x1", "=", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", "*", "2", "\n", "y0", "=", "bb", "[", "1", "]", "-", "bb", "[", "3", "]", "\n", "y1", "=", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "*", "2", "\n", "for", "i", ",", "dt", "in", "enumerate", "(", "dts", ")", ":", "\n", "                ", "d", "=", "np", ".", "array", "(", "dt", "[", "\"keypoints\"", "]", ")", "\n", "xd", "=", "d", "[", "0", ":", ":", "3", "]", "\n", "yd", "=", "d", "[", "1", ":", ":", "3", "]", "\n", "if", "k1", ">", "0", ":", "\n", "# measure the per-keypoint distance if keypoints visible", "\n", "                    ", "dx", "=", "xd", "-", "xg", "\n", "dy", "=", "yd", "-", "yg", "\n", "", "else", ":", "\n", "# measure minimum distance to keypoints in (x0,y0) & (x1,y1)", "\n", "                    ", "z", "=", "np", ".", "zeros", "(", "k", ")", "\n", "dx", "=", "np", ".", "max", "(", "(", "z", ",", "x0", "-", "xd", ")", ",", "axis", "=", "0", ")", "+", "np", ".", "max", "(", "(", "z", ",", "xd", "-", "x1", ")", ",", "axis", "=", "0", ")", "\n", "dy", "=", "np", ".", "max", "(", "(", "z", ",", "y0", "-", "yd", ")", ",", "axis", "=", "0", ")", "+", "np", ".", "max", "(", "(", "z", ",", "yd", "-", "y1", ")", ",", "axis", "=", "0", ")", "\n", "", "e", "=", "(", "dx", "**", "2", "+", "dy", "**", "2", ")", "/", "vars", "/", "(", "gt", "[", "\"area\"", "]", "+", "np", ".", "spacing", "(", "1", ")", ")", "/", "2", "\n", "if", "k1", ">", "0", ":", "\n", "                    ", "e", "=", "e", "[", "vg", ">", "0", "]", "\n", "", "ious", "[", "i", ",", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "exp", "(", "-", "e", ")", ")", "/", "e", ".", "shape", "[", "0", "]", "\n", "", "", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._extract_mask": [[536, 574], ["ValueError", "densepose_results_quantized.labels_uv_uint8[].numpy", "max", "max", "torch.interpolate().squeeze().argmax().numpy().astype", "torch.interpolate().squeeze().argmax().numpy().astype", "int", "int", "densepose_coco_evaluation.DensePoseCocoEval.multi_storage.get", "max", "max", "torch.interpolate().squeeze().argmax().numpy().astype", "torch.interpolate().squeeze().argmax().numpy().astype", "Exception", "torch.interpolate().squeeze().argmax().numpy", "torch.interpolate().squeeze().argmax().numpy", "int", "int", "torch.interpolate().squeeze().argmax().numpy", "torch.interpolate().squeeze().argmax().numpy", "torch.interpolate().squeeze().argmax", "torch.interpolate().squeeze().argmax", "torch.interpolate().squeeze().argmax", "torch.interpolate().squeeze().argmax", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate", "torch.interpolate", "dt[].unsqueeze", "torch.interpolate", "torch.interpolate", "coarse_segm.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "_extract_mask", "(", "self", ",", "dt", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "if", "\"densepose\"", "in", "dt", ":", "\n", "            ", "densepose_results_quantized", "=", "dt", "[", "\"densepose\"", "]", "\n", "return", "densepose_results_quantized", ".", "labels_uv_uint8", "[", "0", "]", ".", "numpy", "(", ")", "\n", "", "elif", "\"cse_mask\"", "in", "dt", ":", "\n", "            ", "return", "dt", "[", "\"cse_mask\"", "]", "\n", "", "elif", "\"coarse_segm\"", "in", "dt", ":", "\n", "            ", "dy", "=", "max", "(", "int", "(", "dt", "[", "\"bbox\"", "]", "[", "3", "]", ")", ",", "1", ")", "\n", "dx", "=", "max", "(", "int", "(", "dt", "[", "\"bbox\"", "]", "[", "2", "]", ")", ",", "1", ")", "\n", "return", "(", "\n", "F", ".", "interpolate", "(", "\n", "dt", "[", "\"coarse_segm\"", "]", ".", "unsqueeze", "(", "0", ")", ",", "(", "dy", ",", "dx", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", ".", "squeeze", "(", "0", ")", "\n", ".", "argmax", "(", "0", ")", "\n", ".", "numpy", "(", ")", "\n", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "", "elif", "\"record_id\"", "in", "dt", ":", "\n", "            ", "assert", "(", "\n", "self", ".", "multi_storage", "is", "not", "None", "\n", ")", ",", "f\"Storage record id encountered in a detection {dt}, but no storage provided!\"", "\n", "record", "=", "self", ".", "multi_storage", ".", "get", "(", "dt", "[", "\"rank\"", "]", ",", "dt", "[", "\"record_id\"", "]", ")", "\n", "coarse_segm", "=", "record", "[", "\"coarse_segm\"", "]", "\n", "dy", "=", "max", "(", "int", "(", "dt", "[", "\"bbox\"", "]", "[", "3", "]", ")", ",", "1", ")", "\n", "dx", "=", "max", "(", "int", "(", "dt", "[", "\"bbox\"", "]", "[", "2", "]", ")", ",", "1", ")", "\n", "return", "(", "\n", "F", ".", "interpolate", "(", "\n", "coarse_segm", ".", "unsqueeze", "(", "0", ")", ",", "(", "dy", ",", "dx", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", ".", "squeeze", "(", "0", ")", "\n", ".", "argmax", "(", "0", ")", "\n", ".", "numpy", "(", ")", "\n", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"No mask data in the detection: {dt}\"", ")", "\n", "", "raise", "ValueError", "(", "'The prediction dict needs to contain either \"densepose\" or \"cse_mask\"'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._extract_iuv": [[575, 610], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "ValueError"], "methods", ["None"], ["", "def", "_extract_iuv", "(", "\n", "self", ",", "densepose_data", ":", "np", ".", "ndarray", ",", "py", ":", "np", ".", "ndarray", ",", "px", ":", "np", ".", "ndarray", ",", "gt", ":", "Dict", "[", "str", ",", "Any", "]", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Extract arrays of I, U and V values at given points as numpy arrays\n        given the data mode stored in self._dpDataMode\n        \"\"\"", "\n", "if", "self", ".", "_dpDataMode", "==", "DensePoseDataMode", ".", "IUV_DT", ":", "\n", "# estimated labels and UV (default)", "\n", "            ", "ipoints", "=", "densepose_data", "[", "0", ",", "py", ",", "px", "]", "\n", "upoints", "=", "densepose_data", "[", "1", ",", "py", ",", "px", "]", "/", "255.0", "# convert from uint8 by /255.", "\n", "vpoints", "=", "densepose_data", "[", "2", ",", "py", ",", "px", "]", "/", "255.0", "\n", "", "elif", "self", ".", "_dpDataMode", "==", "DensePoseDataMode", ".", "IUV_GT", ":", "\n", "# ground truth", "\n", "            ", "ipoints", "=", "np", ".", "array", "(", "gt", "[", "\"dp_I\"", "]", ")", "\n", "upoints", "=", "np", ".", "array", "(", "gt", "[", "\"dp_U\"", "]", ")", "\n", "vpoints", "=", "np", ".", "array", "(", "gt", "[", "\"dp_V\"", "]", ")", "\n", "", "elif", "self", ".", "_dpDataMode", "==", "DensePoseDataMode", ".", "I_GT_UV_0", ":", "\n", "# ground truth labels, UV = 0", "\n", "            ", "ipoints", "=", "np", ".", "array", "(", "gt", "[", "\"dp_I\"", "]", ")", "\n", "upoints", "=", "upoints", "*", "0.0", "\n", "vpoints", "=", "vpoints", "*", "0.0", "\n", "", "elif", "self", ".", "_dpDataMode", "==", "DensePoseDataMode", ".", "I_GT_UV_DT", ":", "\n", "# ground truth labels, estimated UV", "\n", "            ", "ipoints", "=", "np", ".", "array", "(", "gt", "[", "\"dp_I\"", "]", ")", "\n", "upoints", "=", "densepose_data", "[", "1", ",", "py", ",", "px", "]", "/", "255.0", "# convert from uint8 by /255.", "\n", "vpoints", "=", "densepose_data", "[", "2", ",", "py", ",", "px", "]", "/", "255.0", "\n", "", "elif", "self", ".", "_dpDataMode", "==", "DensePoseDataMode", ".", "I_DT_UV_0", ":", "\n", "# estimated labels, UV = 0", "\n", "            ", "ipoints", "=", "densepose_data", "[", "0", ",", "py", ",", "px", "]", "\n", "upoints", "=", "upoints", "*", "0.0", "\n", "vpoints", "=", "vpoints", "*", "0.0", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unknown data mode: {self._dpDataMode}\"", ")", "\n", "", "return", "ipoints", ",", "upoints", ",", "vpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair": [[611, 645], ["Exception", "densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_quantized", "densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv", "densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_raw", "densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv", "densepose_coco_evaluation.DensePoseCocoEval.multi_storage.get", "densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_raw", "densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv", "densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_cse", "densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_cse", "Exception"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_quantized", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_raw", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_raw", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_cse", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_cse"], ["", "def", "computeOgps_single_pair", "(", "self", ",", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ")", ":", "\n", "        ", "if", "\"densepose\"", "in", "dt", ":", "\n", "            ", "ipoints", ",", "upoints", ",", "vpoints", "=", "self", ".", "extract_iuv_from_quantized", "(", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ")", "\n", "return", "self", ".", "computeOgps_single_pair_iuv", "(", "dt", ",", "gt", ",", "ipoints", ",", "upoints", ",", "vpoints", ")", "\n", "", "elif", "\"u\"", "in", "dt", ":", "\n", "            ", "ipoints", ",", "upoints", ",", "vpoints", "=", "self", ".", "extract_iuv_from_raw", "(", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ")", "\n", "return", "self", ".", "computeOgps_single_pair_iuv", "(", "dt", ",", "gt", ",", "ipoints", ",", "upoints", ",", "vpoints", ")", "\n", "", "elif", "\"record_id\"", "in", "dt", ":", "\n", "            ", "assert", "(", "\n", "self", ".", "multi_storage", "is", "not", "None", "\n", ")", ",", "f\"Storage record id encountered in detection {dt}, but no storage provided!\"", "\n", "record", "=", "self", ".", "multi_storage", ".", "get", "(", "dt", "[", "\"rank\"", "]", ",", "dt", "[", "\"record_id\"", "]", ")", "\n", "record", "[", "\"bbox\"", "]", "=", "dt", "[", "\"bbox\"", "]", "\n", "if", "\"u\"", "in", "record", ":", "\n", "                ", "ipoints", ",", "upoints", ",", "vpoints", "=", "self", ".", "extract_iuv_from_raw", "(", "record", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ")", "\n", "return", "self", ".", "computeOgps_single_pair_iuv", "(", "dt", ",", "gt", ",", "ipoints", ",", "upoints", ",", "vpoints", ")", "\n", "", "elif", "\"embedding\"", "in", "record", ":", "\n", "                ", "return", "self", ".", "computeOgps_single_pair_cse", "(", "\n", "dt", ",", "\n", "gt", ",", "\n", "py", ",", "\n", "px", ",", "\n", "pt_mask", ",", "\n", "record", "[", "\"coarse_segm\"", "]", ",", "\n", "record", "[", "\"embedding\"", "]", ",", "\n", "record", "[", "\"bbox\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "f\"Unknown record format: {record}\"", ")", "\n", "", "", "elif", "\"embedding\"", "in", "dt", ":", "\n", "            ", "return", "self", ".", "computeOgps_single_pair_cse", "(", "\n", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ",", "dt", "[", "\"coarse_segm\"", "]", ",", "dt", "[", "\"embedding\"", "]", ",", "dt", "[", "\"bbox\"", "]", "\n", ")", "\n", "", "raise", "Exception", "(", "f\"Unknown detection format: {dt}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_quantized": [[646, 653], ["densepose_coco_evaluation.DensePoseCocoEval._extract_iuv", "densepose_results_quantized.labels_uv_uint8.numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._extract_iuv"], ["", "def", "extract_iuv_from_quantized", "(", "self", ",", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ")", ":", "\n", "        ", "densepose_results_quantized", "=", "dt", "[", "\"densepose\"", "]", "\n", "ipoints", ",", "upoints", ",", "vpoints", "=", "self", ".", "_extract_iuv", "(", "\n", "densepose_results_quantized", ".", "labels_uv_uint8", ".", "numpy", "(", ")", ",", "py", ",", "px", ",", "gt", "\n", ")", "\n", "ipoints", "[", "pt_mask", "==", "-", "1", "]", "=", "0", "\n", "return", "ipoints", ",", "upoints", ",", "vpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.extract_iuv_from_raw": [[654, 667], ["densepose.converters.segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox", "densepose.converters.chart_output_to_chart_result.resample_uv_tensors_to_bbox", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "densepose_coco_evaluation.DensePoseCocoEval._extract_iuv", "dt[].unsqueeze", "dt[].unsqueeze", "dt[].unsqueeze", "dt[].unsqueeze", "densepose.converters.segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox.squeeze", "torch.cat.numpy", "torch.cat.numpy", "densepose.converters.segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox.byte"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_uv_tensors_to_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval._extract_iuv"], ["", "def", "extract_iuv_from_raw", "(", "self", ",", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ")", ":", "\n", "        ", "labels_dt", "=", "resample_fine_and_coarse_segm_tensors_to_bbox", "(", "\n", "dt", "[", "\"fine_segm\"", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "dt", "[", "\"coarse_segm\"", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "dt", "[", "\"bbox\"", "]", ",", "\n", ")", "\n", "uv", "=", "resample_uv_tensors_to_bbox", "(", "\n", "dt", "[", "\"u\"", "]", ".", "unsqueeze", "(", "0", ")", ",", "dt", "[", "\"v\"", "]", ".", "unsqueeze", "(", "0", ")", ",", "labels_dt", ".", "squeeze", "(", "0", ")", ",", "dt", "[", "\"bbox\"", "]", "\n", ")", "\n", "labels_uv_uint8", "=", "torch", ".", "cat", "(", "(", "labels_dt", ".", "byte", "(", ")", ",", "(", "uv", "*", "255", ")", ".", "clamp", "(", "0", ",", "255", ")", ".", "byte", "(", ")", ")", ")", "\n", "ipoints", ",", "upoints", ",", "vpoints", "=", "self", ".", "_extract_iuv", "(", "labels_uv_uint8", ".", "numpy", "(", ")", ",", "py", ",", "px", ",", "gt", ")", "\n", "ipoints", "[", "pt_mask", "==", "-", "1", "]", "=", "0", "\n", "return", "ipoints", ",", "upoints", ",", "vpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_iuv": [[668, 680], ["densepose_coco_evaluation.DensePoseCocoEval.findAllClosestVertsGT", "densepose_coco_evaluation.DensePoseCocoEval.findAllClosestVertsUV", "densepose_coco_evaluation.DensePoseCocoEval.getDistancesUV", "cVertsGT[].astype"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.findAllClosestVertsGT", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.findAllClosestVertsUV", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.getDistancesUV"], ["", "def", "computeOgps_single_pair_iuv", "(", "self", ",", "dt", ",", "gt", ",", "ipoints", ",", "upoints", ",", "vpoints", ")", ":", "\n", "        ", "cVertsGT", ",", "ClosestVertsGTTransformed", "=", "self", ".", "findAllClosestVertsGT", "(", "gt", ")", "\n", "cVerts", "=", "self", ".", "findAllClosestVertsUV", "(", "upoints", ",", "vpoints", ",", "ipoints", ")", "\n", "# Get pairwise geodesic distances between gt and estimated mesh points.", "\n", "dist", "=", "self", ".", "getDistancesUV", "(", "ClosestVertsGTTransformed", ",", "cVerts", ")", "\n", "# Compute the Ogps measure.", "\n", "# Find the mean geodesic normalization distance for", "\n", "# each GT point, based on which part it is on.", "\n", "Current_Mean_Distances", "=", "self", ".", "Mean_Distances", "[", "\n", "self", ".", "CoarseParts", "[", "self", ".", "Part_ids", "[", "cVertsGT", "[", "cVertsGT", ">", "0", "]", ".", "astype", "(", "int", ")", "-", "1", "]", "]", "\n", "]", "\n", "return", "dist", ",", "Current_Mean_Distances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair_cse": [[681, 712], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "densepose.converters.segm_to_mask.resample_coarse_segm_tensor_to_bbox().squeeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "densepose_coco_evaluation.DensePoseCocoEval.findClosestVertsCse", "densepose_coco_evaluation.DensePoseCocoEval.getDistancesCse", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "densepose.converters.segm_to_mask.resample_coarse_segm_tensor_to_bbox", "torch.interpolate", "torch.interpolate", "coarse_segm.unsqueeze", "torch.interpolate().squeeze.unsqueeze", "int", "int", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.findClosestVertsCse", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.getDistancesCse", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_coarse_segm_tensor_to_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "computeOgps_single_pair_cse", "(", "\n", "self", ",", "dt", ",", "gt", ",", "py", ",", "px", ",", "pt_mask", ",", "coarse_segm", ",", "embedding", ",", "bbox_xywh_abs", "\n", ")", ":", "\n", "# 0-based mesh vertex indices", "\n", "        ", "cVertsGT", "=", "torch", ".", "as_tensor", "(", "gt", "[", "\"dp_vertex\"", "]", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "# label for each pixel of the bbox, [H, W] tensor of long", "\n", "labels_dt", "=", "resample_coarse_segm_tensor_to_bbox", "(", "\n", "coarse_segm", ".", "unsqueeze", "(", "0", ")", ",", "bbox_xywh_abs", "\n", ")", ".", "squeeze", "(", "0", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "bbox_xywh_abs", "\n", "# embedding for each pixel of the bbox, [D, H, W] tensor of float32", "\n", "embedding", "=", "F", ".", "interpolate", "(", "\n", "embedding", ".", "unsqueeze", "(", "0", ")", ",", "(", "int", "(", "h", ")", ",", "int", "(", "w", ")", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", ".", "squeeze", "(", "0", ")", "\n", "# valid locations py, px", "\n", "py_pt", "=", "torch", ".", "from_numpy", "(", "py", "[", "pt_mask", ">", "-", "1", "]", ")", "\n", "px_pt", "=", "torch", ".", "from_numpy", "(", "px", "[", "pt_mask", ">", "-", "1", "]", ")", "\n", "cVerts", "=", "torch", ".", "ones_like", "(", "cVertsGT", ")", "*", "-", "1", "\n", "cVerts", "[", "pt_mask", ">", "-", "1", "]", "=", "self", ".", "findClosestVertsCse", "(", "\n", "embedding", ",", "py_pt", ",", "px_pt", ",", "labels_dt", ",", "gt", "[", "\"ref_model\"", "]", "\n", ")", "\n", "# Get pairwise geodesic distances between gt and estimated mesh points.", "\n", "dist", "=", "self", ".", "getDistancesCse", "(", "cVertsGT", ",", "cVerts", ",", "gt", "[", "\"ref_model\"", "]", ")", "\n", "# normalize distances", "\n", "if", "(", "gt", "[", "\"ref_model\"", "]", "==", "\"smpl_27554\"", ")", "and", "(", "\"dp_I\"", "in", "gt", ")", ":", "\n", "            ", "Current_Mean_Distances", "=", "self", ".", "Mean_Distances", "[", "\n", "self", ".", "CoarseParts", "[", "np", ".", "array", "(", "gt", "[", "\"dp_I\"", "]", ",", "dtype", "=", "int", ")", "]", "\n", "]", "\n", "", "else", ":", "\n", "            ", "Current_Mean_Distances", "=", "0.255", "\n", "", "return", "dist", ",", "Current_Mean_Distances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps": [[713, 772], ["numpy.argsort", "numpy.zeros", "enumerate", "pycocotools.mask.iou", "len", "int", "len", "len", "len", "len", "enumerate", "o.get", "int", "int", "numpy.zeros", "len", "len", "numpy.array", "numpy.array", "numpy.max", "densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair", "numpy.exp", "numpy.mean", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.computeOgps_single_pair"], ["", "def", "computeOgps", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "# dimension here should be Nxm", "\n", "g", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "d", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d_", "[", "\"score\"", "]", "for", "d_", "in", "d", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "d", "=", "[", "d", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "d", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "d", "=", "d", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "# if len(gts) == 0 and len(dts) == 0:", "\n", "", "if", "len", "(", "g", ")", "==", "0", "or", "len", "(", "d", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "d", ")", ",", "len", "(", "g", ")", ")", ")", "\n", "# compute opgs between each detection and ground truth object", "\n", "# sigma = self.sigma #0.255 # dist = 0.3m corresponds to ogps = 0.5", "\n", "# 1 # dist = 0.3m corresponds to ogps = 0.96", "\n", "# 1.45 # dist = 1.7m (person height) corresponds to ogps = 0.5)", "\n", "for", "j", ",", "gt", "in", "enumerate", "(", "g", ")", ":", "\n", "            ", "if", "not", "gt", "[", "\"ignore\"", "]", ":", "\n", "                ", "g_", "=", "gt", "[", "\"bbox\"", "]", "\n", "for", "i", ",", "dt", "in", "enumerate", "(", "d", ")", ":", "\n", "#", "\n", "                    ", "dy", "=", "int", "(", "dt", "[", "\"bbox\"", "]", "[", "3", "]", ")", "\n", "dx", "=", "int", "(", "dt", "[", "\"bbox\"", "]", "[", "2", "]", ")", "\n", "dp_x", "=", "np", ".", "array", "(", "gt", "[", "\"dp_x\"", "]", ")", "*", "g_", "[", "2", "]", "/", "255.0", "\n", "dp_y", "=", "np", ".", "array", "(", "gt", "[", "\"dp_y\"", "]", ")", "*", "g_", "[", "3", "]", "/", "255.0", "\n", "py", "=", "(", "dp_y", "+", "g_", "[", "1", "]", "-", "dt", "[", "\"bbox\"", "]", "[", "1", "]", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "px", "=", "(", "dp_x", "+", "g_", "[", "0", "]", "-", "dt", "[", "\"bbox\"", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "#", "\n", "pts", "=", "np", ".", "zeros", "(", "len", "(", "px", ")", ")", "\n", "pts", "[", "px", ">=", "dx", "]", "=", "-", "1", "\n", "pts", "[", "py", ">=", "dy", "]", "=", "-", "1", "\n", "pts", "[", "px", "<", "0", "]", "=", "-", "1", "\n", "pts", "[", "py", "<", "0", "]", "=", "-", "1", "\n", "if", "len", "(", "pts", ")", "<", "1", ":", "\n", "                        ", "ogps", "=", "0.0", "\n", "", "elif", "np", ".", "max", "(", "pts", ")", "==", "-", "1", ":", "\n", "                        ", "ogps", "=", "0.0", "\n", "", "else", ":", "\n", "                        ", "px", "[", "pts", "==", "-", "1", "]", "=", "0", "\n", "py", "[", "pts", "==", "-", "1", "]", "=", "0", "\n", "dists_between_matches", ",", "dist_norm_coeffs", "=", "self", ".", "computeOgps_single_pair", "(", "\n", "dt", ",", "gt", ",", "py", ",", "px", ",", "pts", "\n", ")", "\n", "# Compute gps", "\n", "ogps_values", "=", "np", ".", "exp", "(", "\n", "-", "(", "dists_between_matches", "**", "2", ")", "/", "(", "2", "*", "(", "dist_norm_coeffs", "**", "2", ")", ")", "\n", ")", "\n", "#", "\n", "ogps", "=", "np", ".", "mean", "(", "ogps_values", ")", "if", "len", "(", "ogps_values", ")", ">", "0", "else", "0.0", "\n", "", "ious", "[", "i", ",", "j", "]", "=", "ogps", "\n", "\n", "", "", "", "gbb", "=", "[", "gt", "[", "\"bbox\"", "]", "for", "gt", "in", "g", "]", "\n", "dbb", "=", "[", "dt", "[", "\"bbox\"", "]", "for", "dt", "in", "d", "]", "\n", "\n", "# compute iou between each dt and gt region", "\n", "iscrowd", "=", "[", "int", "(", "o", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", "for", "o", "in", "g", "]", "\n", "ious_bb", "=", "maskUtils", ".", "iou", "(", "dbb", ",", "gbb", ",", "iscrowd", ")", "\n", "return", "ious", ",", "ious_bb", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluateImg": [[773, 916], ["numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.array", "numpy.zeros", "numpy.array().reshape", "numpy.logical_or", "int", "numpy.all", "numpy.logical_or", "len", "enumerate", "numpy.logical_and", "len", "len", "o.get", "enumerate", "enumerate", "numpy.array", "len", "numpy.repeat", "len", "len", "len", "min", "enumerate", "len", "len", "enumerate", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "evaluateImg", "(", "self", ",", "imgId", ",", "catId", ",", "aRng", ",", "maxDet", ")", ":", "\n", "        ", "\"\"\"\n        perform evaluation for single category and image\n        :return: dict (single image results)\n        \"\"\"", "\n", "\n", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "for", "g", "in", "gt", ":", "\n", "# g['_ignore'] = g['ignore']", "\n", "            ", "if", "g", "[", "\"ignore\"", "]", "or", "(", "g", "[", "\"area\"", "]", "<", "aRng", "[", "0", "]", "or", "g", "[", "\"area\"", "]", ">", "aRng", "[", "1", "]", ")", ":", "\n", "                ", "g", "[", "\"_ignore\"", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "g", "[", "\"_ignore\"", "]", "=", "False", "\n", "\n", "# sort dt highest score first, sort gt ignore last", "\n", "", "", "gtind", "=", "np", ".", "argsort", "(", "[", "g", "[", "\"_ignore\"", "]", "for", "g", "in", "gt", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "gt", "=", "[", "gt", "[", "i", "]", "for", "i", "in", "gtind", "]", "\n", "dtind", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "\"score\"", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "dtind", "[", "0", ":", "maxDet", "]", "]", "\n", "iscrowd", "=", "[", "int", "(", "o", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", ")", "for", "o", "in", "gt", "]", "\n", "# load computed ious", "\n", "if", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "# print('Checking the length', len(self.ious[imgId, catId]))", "\n", "# if len(self.ious[imgId, catId]) == 0:", "\n", "#    print(self.ious[imgId, catId])", "\n", "            ", "ious", "=", "(", "\n", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "[", "0", "]", "[", ":", ",", "gtind", "]", "\n", "if", "len", "(", "self", ".", "ious", "[", "imgId", ",", "catId", "]", ")", ">", "0", "\n", "else", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "\n", ")", "\n", "ioubs", "=", "(", "\n", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "[", "1", "]", "[", ":", ",", "gtind", "]", "\n", "if", "len", "(", "self", ".", "ious", "[", "imgId", ",", "catId", "]", ")", ">", "0", "\n", "else", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "\n", ")", "\n", "if", "self", ".", "_dpEvalMode", "in", "{", "DensePoseEvalMode", ".", "GPSM", ",", "DensePoseEvalMode", ".", "IOU", "}", ":", "\n", "                ", "iousM", "=", "(", "\n", "self", ".", "real_ious", "[", "imgId", ",", "catId", "]", "[", ":", ",", "gtind", "]", "\n", "if", "len", "(", "self", ".", "real_ious", "[", "imgId", ",", "catId", "]", ")", ">", "0", "\n", "else", "self", ".", "real_ious", "[", "imgId", ",", "catId", "]", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "ious", "=", "(", "\n", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "[", ":", ",", "gtind", "]", "\n", "if", "len", "(", "self", ".", "ious", "[", "imgId", ",", "catId", "]", ")", ">", "0", "\n", "else", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "\n", ")", "\n", "\n", "", "T", "=", "len", "(", "p", ".", "iouThrs", ")", "\n", "G", "=", "len", "(", "gt", ")", "\n", "D", "=", "len", "(", "dt", ")", "\n", "gtm", "=", "np", ".", "zeros", "(", "(", "T", ",", "G", ")", ")", "\n", "dtm", "=", "np", ".", "zeros", "(", "(", "T", ",", "D", ")", ")", "\n", "gtIg", "=", "np", ".", "array", "(", "[", "g", "[", "\"_ignore\"", "]", "for", "g", "in", "gt", "]", ")", "\n", "dtIg", "=", "np", ".", "zeros", "(", "(", "T", ",", "D", ")", ")", "\n", "if", "np", ".", "all", "(", "gtIg", ")", "and", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "            ", "dtIg", "=", "np", ".", "logical_or", "(", "dtIg", ",", "True", ")", "\n", "\n", "", "if", "len", "(", "ious", ")", ">", "0", ":", "# and not p.iouType == 'densepose':", "\n", "            ", "for", "tind", ",", "t", "in", "enumerate", "(", "p", ".", "iouThrs", ")", ":", "\n", "                ", "for", "dind", ",", "d", "in", "enumerate", "(", "dt", ")", ":", "\n", "# information about best match so far (m=-1 -> unmatched)", "\n", "                    ", "iou", "=", "min", "(", "[", "t", ",", "1", "-", "1e-10", "]", ")", "\n", "m", "=", "-", "1", "\n", "for", "gind", ",", "_g", "in", "enumerate", "(", "gt", ")", ":", "\n", "# if this gt already matched, and not a crowd, continue", "\n", "                        ", "if", "gtm", "[", "tind", ",", "gind", "]", ">", "0", "and", "not", "iscrowd", "[", "gind", "]", ":", "\n", "                            ", "continue", "\n", "# if dt matched to reg gt, and on ignore gt, stop", "\n", "", "if", "m", ">", "-", "1", "and", "gtIg", "[", "m", "]", "==", "0", "and", "gtIg", "[", "gind", "]", "==", "1", ":", "\n", "                            ", "break", "\n", "", "if", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "                            ", "if", "self", ".", "_dpEvalMode", "==", "DensePoseEvalMode", ".", "GPSM", ":", "\n", "                                ", "new_iou", "=", "np", ".", "sqrt", "(", "iousM", "[", "dind", ",", "gind", "]", "*", "ious", "[", "dind", ",", "gind", "]", ")", "\n", "", "elif", "self", ".", "_dpEvalMode", "==", "DensePoseEvalMode", ".", "IOU", ":", "\n", "                                ", "new_iou", "=", "iousM", "[", "dind", ",", "gind", "]", "\n", "", "elif", "self", ".", "_dpEvalMode", "==", "DensePoseEvalMode", ".", "GPS", ":", "\n", "                                ", "new_iou", "=", "ious", "[", "dind", ",", "gind", "]", "\n", "", "", "else", ":", "\n", "                            ", "new_iou", "=", "ious", "[", "dind", ",", "gind", "]", "\n", "", "if", "new_iou", "<", "iou", ":", "\n", "                            ", "continue", "\n", "", "if", "new_iou", "==", "0.0", ":", "\n", "                            ", "continue", "\n", "# if match successful and best so far, store appropriately", "\n", "", "iou", "=", "new_iou", "\n", "m", "=", "gind", "\n", "# if match made store id of match for both dt and gt", "\n", "", "if", "m", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "dtIg", "[", "tind", ",", "dind", "]", "=", "gtIg", "[", "m", "]", "\n", "dtm", "[", "tind", ",", "dind", "]", "=", "gt", "[", "m", "]", "[", "\"id\"", "]", "\n", "gtm", "[", "tind", ",", "m", "]", "=", "d", "[", "\"id\"", "]", "\n", "\n", "", "", "", "if", "p", ".", "iouType", "==", "\"densepose\"", ":", "\n", "            ", "if", "not", "len", "(", "ioubs", ")", "==", "0", ":", "\n", "                ", "for", "dind", ",", "d", "in", "enumerate", "(", "dt", ")", ":", "\n", "# information about best match so far (m=-1 -> unmatched)", "\n", "                    ", "if", "dtm", "[", "tind", ",", "dind", "]", "==", "0", ":", "\n", "                        ", "ioub", "=", "0.8", "\n", "m", "=", "-", "1", "\n", "for", "gind", ",", "_g", "in", "enumerate", "(", "gt", ")", ":", "\n", "# if this gt already matched, and not a crowd, continue", "\n", "                            ", "if", "gtm", "[", "tind", ",", "gind", "]", ">", "0", "and", "not", "iscrowd", "[", "gind", "]", ":", "\n", "                                ", "continue", "\n", "# continue to next gt unless better match made", "\n", "", "if", "ioubs", "[", "dind", ",", "gind", "]", "<", "ioub", ":", "\n", "                                ", "continue", "\n", "# if match successful and best so far, store appropriately", "\n", "", "ioub", "=", "ioubs", "[", "dind", ",", "gind", "]", "\n", "m", "=", "gind", "\n", "# if match made store id of match for both dt and gt", "\n", "", "if", "m", ">", "-", "1", ":", "\n", "                            ", "dtIg", "[", ":", ",", "dind", "]", "=", "gtIg", "[", "m", "]", "\n", "if", "gtIg", "[", "m", "]", ":", "\n", "                                ", "dtm", "[", "tind", ",", "dind", "]", "=", "gt", "[", "m", "]", "[", "\"id\"", "]", "\n", "gtm", "[", "tind", ",", "m", "]", "=", "d", "[", "\"id\"", "]", "\n", "# set unmatched detections outside of area range to ignore", "\n", "", "", "", "", "", "", "a", "=", "np", ".", "array", "(", "[", "d", "[", "\"area\"", "]", "<", "aRng", "[", "0", "]", "or", "d", "[", "\"area\"", "]", ">", "aRng", "[", "1", "]", "for", "d", "in", "dt", "]", ")", ".", "reshape", "(", "(", "1", ",", "len", "(", "dt", ")", ")", ")", "\n", "dtIg", "=", "np", ".", "logical_or", "(", "dtIg", ",", "np", ".", "logical_and", "(", "dtm", "==", "0", ",", "np", ".", "repeat", "(", "a", ",", "T", ",", "0", ")", ")", ")", "\n", "# store results for given image and category", "\n", "# print('Done with the function', len(self.ious[imgId, catId]))", "\n", "return", "{", "\n", "\"image_id\"", ":", "imgId", ",", "\n", "\"category_id\"", ":", "catId", ",", "\n", "\"aRng\"", ":", "aRng", ",", "\n", "\"maxDet\"", ":", "maxDet", ",", "\n", "\"dtIds\"", ":", "[", "d", "[", "\"id\"", "]", "for", "d", "in", "dt", "]", ",", "\n", "\"gtIds\"", ":", "[", "g", "[", "\"id\"", "]", "for", "g", "in", "gt", "]", ",", "\n", "\"dtMatches\"", ":", "dtm", ",", "\n", "\"gtMatches\"", ":", "gtm", ",", "\n", "\"dtScores\"", ":", "[", "d", "[", "\"score\"", "]", "for", "d", "in", "dt", "]", ",", "\n", "\"gtIgnore\"", ":", "gtIg", ",", "\n", "\"dtIgnore\"", ":", "dtIg", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.accumulate": [[918, 1022], ["logger.info", "time.time", "len", "len", "len", "len", "logger.info", "set", "set", "set", "set", "len", "len", "enumerate", "logger.info", "time.time", "logger.info", "logger.info", "len", "numpy.ones", "numpy.ones", "map", "enumerate", "datetime.datetime.now().strftime", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.max", "numpy.min", "map", "numpy.concatenate", "numpy.argsort", "numpy.concatenate", "numpy.count_nonzero", "numpy.logical_and", "numpy.logical_and", "numpy.cumsum().astype", "numpy.cumsum().astype", "enumerate", "datetime.datetime.now", "len", "numpy.concatenate", "numpy.concatenate", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "zip", "numpy.array", "numpy.array", "len", "numpy.zeros", "pr.tolist.tolist.tolist", "q.tolist.tolist.tolist", "range", "numpy.searchsorted", "numpy.array", "tuple", "numpy.cumsum", "numpy.cumsum", "enumerate", "numpy.spacing"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "def", "accumulate", "(", "self", ",", "p", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Accumulate per image evaluation results and store the result in self.eval\n        :param p: input params for evaluation\n        :return: None\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Accumulating evaluation results...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "self", ".", "evalImgs", ":", "\n", "            ", "logger", ".", "info", "(", "\"Please run evaluate() first\"", ")", "\n", "# allows input customized parameters", "\n", "", "if", "p", "is", "None", ":", "\n", "            ", "p", "=", "self", ".", "params", "\n", "", "p", ".", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "==", "1", "else", "[", "-", "1", "]", "\n", "T", "=", "len", "(", "p", ".", "iouThrs", ")", "\n", "R", "=", "len", "(", "p", ".", "recThrs", ")", "\n", "K", "=", "len", "(", "p", ".", "catIds", ")", "if", "p", ".", "useCats", "else", "1", "\n", "A", "=", "len", "(", "p", ".", "areaRng", ")", "\n", "M", "=", "len", "(", "p", ".", "maxDets", ")", "\n", "precision", "=", "-", "(", "np", ".", "ones", "(", "(", "T", ",", "R", ",", "K", ",", "A", ",", "M", ")", ")", ")", "# -1 for the precision of absent categories", "\n", "recall", "=", "-", "(", "np", ".", "ones", "(", "(", "T", ",", "K", ",", "A", ",", "M", ")", ")", ")", "\n", "\n", "# create dictionary for future indexing", "\n", "logger", ".", "info", "(", "\"Categories: {}\"", ".", "format", "(", "p", ".", "catIds", ")", ")", "\n", "_pe", "=", "self", ".", "_paramsEval", "\n", "catIds", "=", "_pe", ".", "catIds", "if", "_pe", ".", "useCats", "else", "[", "-", "1", "]", "\n", "setK", "=", "set", "(", "catIds", ")", "\n", "setA", "=", "set", "(", "map", "(", "tuple", ",", "_pe", ".", "areaRng", ")", ")", "\n", "setM", "=", "set", "(", "_pe", ".", "maxDets", ")", "\n", "setI", "=", "set", "(", "_pe", ".", "imgIds", ")", "\n", "# get inds to evaluate", "\n", "k_list", "=", "[", "n", "for", "n", ",", "k", "in", "enumerate", "(", "p", ".", "catIds", ")", "if", "k", "in", "setK", "]", "\n", "m_list", "=", "[", "m", "for", "n", ",", "m", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "m", "in", "setM", "]", "\n", "a_list", "=", "[", "n", "for", "n", ",", "a", "in", "enumerate", "(", "map", "(", "lambda", "x", ":", "tuple", "(", "x", ")", ",", "p", ".", "areaRng", ")", ")", "if", "a", "in", "setA", "]", "\n", "i_list", "=", "[", "n", "for", "n", ",", "i", "in", "enumerate", "(", "p", ".", "imgIds", ")", "if", "i", "in", "setI", "]", "\n", "I0", "=", "len", "(", "_pe", ".", "imgIds", ")", "\n", "A0", "=", "len", "(", "_pe", ".", "areaRng", ")", "\n", "# retrieve E at each category, area range, and max number of detections", "\n", "for", "k", ",", "k0", "in", "enumerate", "(", "k_list", ")", ":", "\n", "            ", "Nk", "=", "k0", "*", "A0", "*", "I0", "\n", "for", "a", ",", "a0", "in", "enumerate", "(", "a_list", ")", ":", "\n", "                ", "Na", "=", "a0", "*", "I0", "\n", "for", "m", ",", "maxDet", "in", "enumerate", "(", "m_list", ")", ":", "\n", "                    ", "E", "=", "[", "self", ".", "evalImgs", "[", "Nk", "+", "Na", "+", "i", "]", "for", "i", "in", "i_list", "]", "\n", "E", "=", "[", "e", "for", "e", "in", "E", "if", "e", "is", "not", "None", "]", "\n", "if", "len", "(", "E", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "dtScores", "=", "np", ".", "concatenate", "(", "[", "e", "[", "\"dtScores\"", "]", "[", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ")", "\n", "\n", "# different sorting method generates slightly different results.", "\n", "# mergesort is used to be consistent as Matlab implementation.", "\n", "inds", "=", "np", ".", "argsort", "(", "-", "dtScores", ",", "kind", "=", "\"mergesort\"", ")", "\n", "\n", "dtm", "=", "np", ".", "concatenate", "(", "[", "e", "[", "\"dtMatches\"", "]", "[", ":", ",", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ",", "axis", "=", "1", ")", "[", ":", ",", "inds", "]", "\n", "dtIg", "=", "np", ".", "concatenate", "(", "[", "e", "[", "\"dtIgnore\"", "]", "[", ":", ",", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ",", "axis", "=", "1", ")", "[", ":", ",", "inds", "]", "\n", "gtIg", "=", "np", ".", "concatenate", "(", "[", "e", "[", "\"gtIgnore\"", "]", "for", "e", "in", "E", "]", ")", "\n", "npig", "=", "np", ".", "count_nonzero", "(", "gtIg", "==", "0", ")", "\n", "if", "npig", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "tps", "=", "np", ".", "logical_and", "(", "dtm", ",", "np", ".", "logical_not", "(", "dtIg", ")", ")", "\n", "fps", "=", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "dtm", ")", ",", "np", ".", "logical_not", "(", "dtIg", ")", ")", "\n", "tp_sum", "=", "np", ".", "cumsum", "(", "tps", ",", "axis", "=", "1", ")", ".", "astype", "(", "dtype", "=", "np", ".", "float", ")", "\n", "fp_sum", "=", "np", ".", "cumsum", "(", "fps", ",", "axis", "=", "1", ")", ".", "astype", "(", "dtype", "=", "np", ".", "float", ")", "\n", "for", "t", ",", "(", "tp", ",", "fp", ")", "in", "enumerate", "(", "zip", "(", "tp_sum", ",", "fp_sum", ")", ")", ":", "\n", "                        ", "tp", "=", "np", ".", "array", "(", "tp", ")", "\n", "fp", "=", "np", ".", "array", "(", "fp", ")", "\n", "nd", "=", "len", "(", "tp", ")", "\n", "rc", "=", "tp", "/", "npig", "\n", "pr", "=", "tp", "/", "(", "fp", "+", "tp", "+", "np", ".", "spacing", "(", "1", ")", ")", "\n", "q", "=", "np", ".", "zeros", "(", "(", "R", ",", ")", ")", "\n", "\n", "if", "nd", ":", "\n", "                            ", "recall", "[", "t", ",", "k", ",", "a", ",", "m", "]", "=", "rc", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                            ", "recall", "[", "t", ",", "k", ",", "a", ",", "m", "]", "=", "0", "\n", "\n", "# numpy is slow without cython optimization for accessing elements", "\n", "# use python array gets significant speed improvement", "\n", "", "pr", "=", "pr", ".", "tolist", "(", ")", "\n", "q", "=", "q", ".", "tolist", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "nd", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "                            ", "if", "pr", "[", "i", "]", ">", "pr", "[", "i", "-", "1", "]", ":", "\n", "                                ", "pr", "[", "i", "-", "1", "]", "=", "pr", "[", "i", "]", "\n", "\n", "", "", "inds", "=", "np", ".", "searchsorted", "(", "rc", ",", "p", ".", "recThrs", ",", "side", "=", "\"left\"", ")", "\n", "try", ":", "\n", "                            ", "for", "ri", ",", "pi", "in", "enumerate", "(", "inds", ")", ":", "\n", "                                ", "q", "[", "ri", "]", "=", "pr", "[", "pi", "]", "\n", "", "", "except", "Exception", ":", "\n", "                            ", "pass", "\n", "", "precision", "[", "t", ",", ":", ",", "k", ",", "a", ",", "m", "]", "=", "np", ".", "array", "(", "q", ")", "\n", "", "", "", "", "logger", ".", "info", "(", "\n", "\"Final: max precision {}, min precision {}\"", ".", "format", "(", "np", ".", "max", "(", "precision", ")", ",", "np", ".", "min", "(", "precision", ")", ")", "\n", ")", "\n", "self", ".", "eval", "=", "{", "\n", "\"params\"", ":", "p", ",", "\n", "\"counts\"", ":", "[", "T", ",", "R", ",", "K", ",", "A", ",", "M", "]", ",", "\n", "\"date\"", ":", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", ",", "\n", "\"precision\"", ":", "precision", ",", "\n", "\"recall\"", ":", "recall", ",", "\n", "}", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"DONE (t={:0.2f}s).\"", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize": [[1023, 1153], ["densepose_coco_evaluation.DensePoseCocoEval.summarize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize"], ["", "def", "summarize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Compute and display summary metrics for evaluation results.\n        Note this function can *only* be applied on the default parameter setting\n        \"\"\"", "\n", "\n", "def", "_summarize", "(", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"all\"", ",", "maxDets", "=", "100", ")", ":", "\n", "            ", "p", "=", "self", ".", "params", "\n", "iStr", "=", "\" {:<18} {} @[ {}={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}\"", "\n", "titleStr", "=", "\"Average Precision\"", "if", "ap", "==", "1", "else", "\"Average Recall\"", "\n", "typeStr", "=", "\"(AP)\"", "if", "ap", "==", "1", "else", "\"(AR)\"", "\n", "measure", "=", "\"IoU\"", "\n", "if", "self", ".", "params", ".", "iouType", "==", "\"keypoints\"", ":", "\n", "                ", "measure", "=", "\"OKS\"", "\n", "", "elif", "self", ".", "params", ".", "iouType", "==", "\"densepose\"", ":", "\n", "                ", "measure", "=", "\"OGPS\"", "\n", "", "iouStr", "=", "(", "\n", "\"{:0.2f}:{:0.2f}\"", ".", "format", "(", "p", ".", "iouThrs", "[", "0", "]", ",", "p", ".", "iouThrs", "[", "-", "1", "]", ")", "\n", "if", "iouThr", "is", "None", "\n", "else", "\"{:0.2f}\"", ".", "format", "(", "iouThr", ")", "\n", ")", "\n", "\n", "aind", "=", "[", "i", "for", "i", ",", "aRng", "in", "enumerate", "(", "p", ".", "areaRngLbl", ")", "if", "aRng", "==", "areaRng", "]", "\n", "mind", "=", "[", "i", "for", "i", ",", "mDet", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "mDet", "==", "maxDets", "]", "\n", "if", "ap", "==", "1", ":", "\n", "# dimension of precision: [TxRxKxAxM]", "\n", "                ", "s", "=", "self", ".", "eval", "[", "\"precision\"", "]", "\n", "# IoU", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "                    ", "t", "=", "np", ".", "where", "(", "np", ".", "abs", "(", "iouThr", "-", "p", ".", "iouThrs", ")", "<", "0.001", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "s", "=", "s", "[", ":", ",", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "else", ":", "\n", "# dimension of recall: [TxKxAxM]", "\n", "                ", "s", "=", "self", ".", "eval", "[", "\"recall\"", "]", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "                    ", "t", "=", "np", ".", "where", "(", "np", ".", "abs", "(", "iouThr", "-", "p", ".", "iouThrs", ")", "<", "0.001", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "s", "=", "s", "[", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "if", "len", "(", "s", "[", "s", ">", "-", "1", "]", ")", "==", "0", ":", "\n", "                ", "mean_s", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "mean_s", "=", "np", ".", "mean", "(", "s", "[", "s", ">", "-", "1", "]", ")", "\n", "", "logger", ".", "info", "(", "iStr", ".", "format", "(", "titleStr", ",", "typeStr", ",", "measure", ",", "iouStr", ",", "areaRng", ",", "maxDets", ",", "mean_s", ")", ")", "\n", "return", "mean_s", "\n", "\n", "", "def", "_summarizeDets", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "iouThr", "=", "0.5", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "iouThr", "=", "0.75", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "\"small\"", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "\"medium\"", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "\"large\"", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "1", "]", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "\"small\"", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "10", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "\"medium\"", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "11", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "\"large\"", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "return", "stats", "\n", "\n", "", "def", "_summarizeKps", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "10", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "iouThr", "=", "0.5", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "iouThr", "=", "0.75", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "areaRng", "=", "\"medium\"", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "areaRng", "=", "\"large\"", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "iouThr", "=", "0.5", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "iouThr", "=", "0.75", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "areaRng", "=", "\"medium\"", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "areaRng", "=", "\"large\"", ")", "\n", "return", "stats", "\n", "\n", "", "def", "_summarizeUvs", "(", ")", ":", "\n", "            ", "stats", "=", "[", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", "]", "\n", "min_threshold", "=", "self", ".", "params", ".", "iouThrs", ".", "min", "(", ")", "\n", "if", "min_threshold", "<=", "0.201", ":", "\n", "                ", "stats", "+=", "[", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.2", ")", "]", "\n", "", "if", "min_threshold", "<=", "0.301", ":", "\n", "                ", "stats", "+=", "[", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.3", ")", "]", "\n", "", "if", "min_threshold", "<=", "0.401", ":", "\n", "                ", "stats", "+=", "[", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.4", ")", "]", "\n", "", "stats", "+=", "[", "\n", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.5", ")", ",", "\n", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.75", ")", ",", "\n", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"medium\"", ")", ",", "\n", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"large\"", ")", ",", "\n", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", ",", "\n", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.5", ")", ",", "\n", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.75", ")", ",", "\n", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"medium\"", ")", ",", "\n", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"large\"", ")", ",", "\n", "]", "\n", "return", "np", ".", "array", "(", "stats", ")", "\n", "\n", "", "def", "_summarizeUvsOld", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "18", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.5", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.55", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.60", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.65", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.70", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.75", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.80", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.85", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.90", ")", "\n", "stats", "[", "10", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.95", ")", "\n", "stats", "[", "11", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"medium\"", ")", "\n", "stats", "[", "12", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"large\"", ")", "\n", "stats", "[", "13", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", "\n", "stats", "[", "14", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.5", ")", "\n", "stats", "[", "15", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "iouThr", "=", "0.75", ")", "\n", "stats", "[", "16", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"medium\"", ")", "\n", "stats", "[", "17", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ",", "areaRng", "=", "\"large\"", ")", "\n", "return", "stats", "\n", "\n", "", "if", "not", "self", ".", "eval", ":", "\n", "            ", "raise", "Exception", "(", "\"Please run accumulate() first\"", ")", "\n", "", "iouType", "=", "self", ".", "params", ".", "iouType", "\n", "if", "iouType", "in", "[", "\"segm\"", ",", "\"bbox\"", "]", ":", "\n", "            ", "summarize", "=", "_summarizeDets", "\n", "", "elif", "iouType", "in", "[", "\"keypoints\"", "]", ":", "\n", "            ", "summarize", "=", "_summarizeKps", "\n", "", "elif", "iouType", "in", "[", "\"densepose\"", "]", ":", "\n", "            ", "summarize", "=", "_summarizeUvs", "\n", "", "self", ".", "stats", "=", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.__str__": [[1154, 1156], ["densepose_coco_evaluation.DensePoseCocoEval.summarize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "self", ".", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.findAllClosestVertsUV": [[1158, 1175], ["numpy.arange", "numpy.ones", "numpy.array", "scipy.cdist().squeeze", "ClosestVerts.astype", "scipy.cdist", "numpy.argmin", "Current_Part_UVs.transpose", "numpy.array.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "findAllClosestVertsUV", "(", "self", ",", "U_points", ",", "V_points", ",", "Index_points", ")", ":", "\n", "        ", "ClosestVerts", "=", "np", ".", "ones", "(", "Index_points", ".", "shape", ")", "*", "-", "1", "\n", "for", "i", "in", "np", ".", "arange", "(", "24", ")", ":", "\n", "#", "\n", "            ", "if", "(", "i", "+", "1", ")", "in", "Index_points", ":", "\n", "                ", "UVs", "=", "np", ".", "array", "(", "\n", "[", "U_points", "[", "Index_points", "==", "(", "i", "+", "1", ")", "]", ",", "V_points", "[", "Index_points", "==", "(", "i", "+", "1", ")", "]", "]", "\n", ")", "\n", "Current_Part_UVs", "=", "self", ".", "Part_UVs", "[", "i", "]", "\n", "Current_Part_ClosestVertInds", "=", "self", ".", "Part_ClosestVertInds", "[", "i", "]", "\n", "D", "=", "ssd", ".", "cdist", "(", "Current_Part_UVs", ".", "transpose", "(", ")", ",", "UVs", ".", "transpose", "(", ")", ")", ".", "squeeze", "(", ")", "\n", "ClosestVerts", "[", "Index_points", "==", "(", "i", "+", "1", ")", "]", "=", "Current_Part_ClosestVertInds", "[", "\n", "np", ".", "argmin", "(", "D", ",", "axis", "=", "0", ")", "\n", "]", "\n", "", "", "ClosestVertsTransformed", "=", "self", ".", "PDIST_transform", "[", "ClosestVerts", ".", "astype", "(", "int", ")", "-", "1", "]", "\n", "ClosestVertsTransformed", "[", "ClosestVerts", "<", "0", "]", "=", "0", "\n", "return", "ClosestVertsTransformed", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.findClosestVertsCse": [[1176, 1184], ["densepose_coco_evaluation.DensePoseCocoEval.embedder", "embedding[].t().to", "densepose.modeling.cse.utils.squared_euclidean_distance_matrix", "densepose.modeling.cse.utils.squared_euclidean_distance_matrix.argmin().cpu", "embedding[].t", "densepose.modeling.cse.utils.squared_euclidean_distance_matrix.argmin"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.squared_euclidean_distance_matrix"], ["", "def", "findClosestVertsCse", "(", "self", ",", "embedding", ",", "py", ",", "px", ",", "mask", ",", "mesh_name", ")", ":", "\n", "        ", "mesh_vertex_embeddings", "=", "self", ".", "embedder", "(", "mesh_name", ")", "\n", "pixel_embeddings", "=", "embedding", "[", ":", ",", "py", ",", "px", "]", ".", "t", "(", ")", ".", "to", "(", "device", "=", "\"cuda\"", ")", "\n", "mask_vals", "=", "mask", "[", "py", ",", "px", "]", "\n", "edm", "=", "squared_euclidean_distance_matrix", "(", "pixel_embeddings", ",", "mesh_vertex_embeddings", ")", "\n", "vertex_indices", "=", "edm", ".", "argmin", "(", "dim", "=", "1", ")", ".", "cpu", "(", ")", "\n", "vertex_indices", "[", "mask_vals", "<=", "0", "]", "=", "-", "1", "\n", "return", "vertex_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.findAllClosestVertsGT": [[1185, 1205], ["numpy.array", "numpy.array", "numpy.array", "numpy.arange", "numpy.ones", "numpy.array", "scipy.cdist().squeeze", "ClosestVertsGT.astype", "scipy.cdist", "numpy.argmin", "Current_Part_UVs.transpose", "numpy.array.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "findAllClosestVertsGT", "(", "self", ",", "gt", ")", ":", "\n", "#", "\n", "        ", "I_gt", "=", "np", ".", "array", "(", "gt", "[", "\"dp_I\"", "]", ")", "\n", "U_gt", "=", "np", ".", "array", "(", "gt", "[", "\"dp_U\"", "]", ")", "\n", "V_gt", "=", "np", ".", "array", "(", "gt", "[", "\"dp_V\"", "]", ")", "\n", "#", "\n", "# print(I_gt)", "\n", "#", "\n", "ClosestVertsGT", "=", "np", ".", "ones", "(", "I_gt", ".", "shape", ")", "*", "-", "1", "\n", "for", "i", "in", "np", ".", "arange", "(", "24", ")", ":", "\n", "            ", "if", "(", "i", "+", "1", ")", "in", "I_gt", ":", "\n", "                ", "UVs", "=", "np", ".", "array", "(", "[", "U_gt", "[", "I_gt", "==", "(", "i", "+", "1", ")", "]", ",", "V_gt", "[", "I_gt", "==", "(", "i", "+", "1", ")", "]", "]", ")", "\n", "Current_Part_UVs", "=", "self", ".", "Part_UVs", "[", "i", "]", "\n", "Current_Part_ClosestVertInds", "=", "self", ".", "Part_ClosestVertInds", "[", "i", "]", "\n", "D", "=", "ssd", ".", "cdist", "(", "Current_Part_UVs", ".", "transpose", "(", ")", ",", "UVs", ".", "transpose", "(", ")", ")", ".", "squeeze", "(", ")", "\n", "ClosestVertsGT", "[", "I_gt", "==", "(", "i", "+", "1", ")", "]", "=", "Current_Part_ClosestVertInds", "[", "np", ".", "argmin", "(", "D", ",", "axis", "=", "0", ")", "]", "\n", "#", "\n", "", "", "ClosestVertsGTTransformed", "=", "self", ".", "PDIST_transform", "[", "ClosestVertsGT", ".", "astype", "(", "int", ")", "-", "1", "]", "\n", "ClosestVertsGTTransformed", "[", "ClosestVertsGT", "<", "0", "]", "=", "0", "\n", "return", "ClosestVertsGT", ",", "ClosestVertsGTTransformed", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.getDistancesCse": [[1206, 1212], ["densepose.structures.mesh.create_mesh", "geodists_vertices.numpy", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "float"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.create_mesh"], ["", "def", "getDistancesCse", "(", "self", ",", "cVertsGT", ",", "cVerts", ",", "mesh_name", ")", ":", "\n", "        ", "geodists_vertices", "=", "torch", ".", "ones_like", "(", "cVertsGT", ")", "*", "float", "(", "\"inf\"", ")", "\n", "selected", "=", "(", "cVertsGT", ">=", "0", ")", "*", "(", "cVerts", ">=", "0", ")", "\n", "mesh", "=", "create_mesh", "(", "mesh_name", ",", "\"cpu\"", ")", "\n", "geodists_vertices", "[", "selected", "]", "=", "mesh", ".", "geodists", "[", "cVertsGT", "[", "selected", "]", ",", "cVerts", "[", "selected", "]", "]", "\n", "return", "geodists_vertices", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.getDistancesUV": [[1213, 1242], ["range", "numpy.atleast_1d", "len", "numpy.array().squeeze", "dists.append", "numpy.array", "dists.append", "dists.append", "dists.append", "int", "int"], "methods", ["None"], ["", "def", "getDistancesUV", "(", "self", ",", "cVertsGT", ",", "cVerts", ")", ":", "\n", "#", "\n", "        ", "n", "=", "27554", "\n", "dists", "=", "[", "]", "\n", "for", "d", "in", "range", "(", "len", "(", "cVertsGT", ")", ")", ":", "\n", "            ", "if", "cVertsGT", "[", "d", "]", ">", "0", ":", "\n", "                ", "if", "cVerts", "[", "d", "]", ">", "0", ":", "\n", "                    ", "i", "=", "cVertsGT", "[", "d", "]", "-", "1", "\n", "j", "=", "cVerts", "[", "d", "]", "-", "1", "\n", "if", "j", "==", "i", ":", "\n", "                        ", "dists", ".", "append", "(", "0", ")", "\n", "", "elif", "j", ">", "i", ":", "\n", "                        ", "ccc", "=", "i", "\n", "i", "=", "j", "\n", "j", "=", "ccc", "\n", "i", "=", "n", "-", "i", "-", "1", "\n", "j", "=", "n", "-", "j", "-", "1", "\n", "k", "=", "(", "n", "*", "(", "n", "-", "1", ")", "/", "2", ")", "-", "(", "n", "-", "i", ")", "*", "(", "(", "n", "-", "i", ")", "-", "1", ")", "/", "2", "+", "j", "-", "i", "-", "1", "\n", "k", "=", "(", "n", "*", "n", "-", "n", ")", "/", "2", "-", "k", "-", "1", "\n", "dists", ".", "append", "(", "self", ".", "Pdist_matrix", "[", "int", "(", "k", ")", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                        ", "i", "=", "n", "-", "i", "-", "1", "\n", "j", "=", "n", "-", "j", "-", "1", "\n", "k", "=", "(", "n", "*", "(", "n", "-", "1", ")", "/", "2", ")", "-", "(", "n", "-", "i", ")", "*", "(", "(", "n", "-", "i", ")", "-", "1", ")", "/", "2", "+", "j", "-", "i", "-", "1", "\n", "k", "=", "(", "n", "*", "n", "-", "n", ")", "/", "2", "-", "k", "-", "1", "\n", "dists", ".", "append", "(", "self", ".", "Pdist_matrix", "[", "int", "(", "k", ")", "]", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "dists", ".", "append", "(", "np", ".", "inf", ")", "\n", "", "", "", "return", "np", ".", "atleast_1d", "(", "np", ".", "array", "(", "dists", ")", ".", "squeeze", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.setDetParams": [[1249, 1264], ["numpy.linspace", "numpy.linspace", "int", "int", "numpy.round", "numpy.round"], "methods", ["None"], ["def", "setDetParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "# np.arange causes trouble.  the data point on arange is slightly larger than the true value", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "int", "(", "np", ".", "round", "(", "(", "0.95", "-", "0.5", ")", "/", "0.05", ")", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", "0.0", ",", "1.00", ",", "int", "(", "np", ".", "round", "(", "(", "1.00", "-", "0.0", ")", "/", "0.01", ")", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "1", ",", "10", ",", "100", "]", "\n", "self", ".", "areaRng", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "\"all\"", ",", "\"small\"", ",", "\"medium\"", ",", "\"large\"", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.setKpParams": [[1265, 1275], ["numpy.linspace", "numpy.linspace", "numpy.round", "numpy.round"], "methods", ["None"], ["", "def", "setKpParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "# np.arange causes trouble.  the data point on arange is slightly larger than the true value", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "np", ".", "round", "(", "(", "0.95", "-", "0.5", ")", "/", "0.05", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", "0.0", ",", "1.00", ",", "np", ".", "round", "(", "(", "1.00", "-", "0.0", ")", "/", "0.01", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "20", "]", "\n", "self", ".", "areaRng", "=", "[", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "\"all\"", ",", "\"medium\"", ",", "\"large\"", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.setUvParams": [[1276, 1285], ["numpy.linspace", "numpy.linspace", "int", "int", "numpy.round", "numpy.round"], "methods", ["None"], ["", "def", "setUvParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "int", "(", "np", ".", "round", "(", "(", "0.95", "-", "0.5", ")", "/", "0.05", ")", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", "0.0", ",", "1.00", ",", "int", "(", "np", ".", "round", "(", "(", "1.00", "-", "0.0", ")", "/", "0.01", ")", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "20", "]", "\n", "self", ".", "areaRng", "=", "[", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "\"all\"", ",", "\"medium\"", ",", "\"large\"", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.__init__": [[1286, 1298], ["densepose_coco_evaluation.Params.setDetParams", "densepose_coco_evaluation.Params.setKpParams", "densepose_coco_evaluation.Params.setUvParams", "Exception"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.setDetParams", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.setKpParams", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.Params.setUvParams"], ["", "def", "__init__", "(", "self", ",", "iouType", "=", "\"segm\"", ")", ":", "\n", "        ", "if", "iouType", "==", "\"segm\"", "or", "iouType", "==", "\"bbox\"", ":", "\n", "            ", "self", ".", "setDetParams", "(", ")", "\n", "", "elif", "iouType", "==", "\"keypoints\"", ":", "\n", "            ", "self", ".", "setKpParams", "(", ")", "\n", "", "elif", "iouType", "==", "\"densepose\"", ":", "\n", "            ", "self", ".", "setUvParams", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"iouType not supported\"", ")", "\n", "", "self", ".", "iouType", "=", "iouType", "\n", "# useSegm is deprecated", "\n", "self", ".", "useSegm", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.__init__": [[375, 384], ["all", "collections.OrderedDict", "collections.OrderedDict"], "methods", ["None"], ["\n", "\n", "", "", "def", "check_expected_results", "(", "results", ",", "expected_results", ",", "sigma_tol", ")", ":", "\n", "    ", "if", "not", "expected_results", ":", "\n", "        ", "return", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.inference\"", ")", "\n", "for", "task", ",", "metric", ",", "(", "mean", ",", "std", ")", "in", "expected_results", ":", "\n", "        ", "actual_val", "=", "results", ".", "results", "[", "task", "]", "[", "metric", "]", "\n", "lo", "=", "mean", "-", "sigma_tol", "*", "std", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update": [[385, 397], ["isinstance", "enumerate"], "methods", ["None"], ["hi", "=", "mean", "+", "sigma_tol", "*", "std", "\n", "ok", "=", "(", "lo", "<", "actual_val", ")", "and", "(", "actual_val", "<", "hi", ")", "\n", "msg", "=", "(", "\n", "\"{} > {} sanity check (actual vs. expected): \"", "\n", "\"{:.3f} vs. mean={:.4f}, std={:.4}, range=({:.4f}, {:.4f})\"", "\n", ")", ".", "format", "(", "task", ",", "metric", ",", "actual_val", ",", "mean", ",", "std", ",", "lo", ",", "hi", ")", "\n", "if", "not", "ok", ":", "\n", "            ", "msg", "=", "\"FAIL: \"", "+", "msg", "\n", "logger", ".", "error", "(", "msg", ")", "\n", "", "else", ":", "\n", "            ", "msg", "=", "\"PASS: \"", "+", "msg", "\n", "logger", ".", "info", "(", "msg", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.__repr__": [[398, 401], ["repr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.do_coco_evaluation": [[13, 68], ["logging.getLogger", "logging.getLogger.info", "coco_eval.COCOResults", "logging.getLogger.info", "logging.getLogger.info", "coco_eval.check_expected_results", "logging.getLogger.info", "coco_eval.COCOResults", "logging.getLogger.info", "coco_eval.check_expected_results", "logging.getLogger.info", "coco_eval.prepare_for_coco_detection", "logging.getLogger.info", "coco_eval.prepare_for_coco_segmentation", "logging.getLogger.info", "coco_eval.prepare_for_coco_keypoint", "torch.save", "areas.items", "torch.save", "tempfile.NamedTemporaryFile", "coco_eval.evaluate_predictions_on_coco", "coco_eval.COCOResults.update", "os.path.join", "coco_eval.evaluate_box_proposals", "stats[].item", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.check_expected_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.check_expected_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.prepare_for_coco_detection", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.prepare_for_coco_segmentation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.prepare_for_coco_keypoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.evaluate_predictions_on_coco", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.evaluate_box_proposals"], ["def", "do_coco_evaluation", "(", "\n", "dataset", ",", "\n", "predictions", ",", "\n", "box_only", ",", "\n", "output_folder", ",", "\n", "iou_types", ",", "\n", "expected_results", ",", "\n", "expected_results_sigma_tol", ",", "\n", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.inference\"", ")", "\n", "\n", "if", "box_only", ":", "\n", "        ", "logger", ".", "info", "(", "\"Evaluating bbox proposals\"", ")", "\n", "areas", "=", "{", "\"all\"", ":", "\"\"", ",", "\"small\"", ":", "\"s\"", ",", "\"medium\"", ":", "\"m\"", ",", "\"large\"", ":", "\"l\"", "}", "\n", "res", "=", "COCOResults", "(", "\"box_proposal\"", ")", "\n", "for", "limit", "in", "[", "100", ",", "1000", "]", ":", "\n", "            ", "for", "area", ",", "suffix", "in", "areas", ".", "items", "(", ")", ":", "\n", "                ", "stats", "=", "evaluate_box_proposals", "(", "\n", "predictions", ",", "dataset", ",", "area", "=", "area", ",", "limit", "=", "limit", "\n", ")", "\n", "key", "=", "\"AR{}@{:d}\"", ".", "format", "(", "suffix", ",", "limit", ")", "\n", "res", ".", "results", "[", "\"box_proposal\"", "]", "[", "key", "]", "=", "stats", "[", "\"ar\"", "]", ".", "item", "(", ")", "\n", "", "", "logger", ".", "info", "(", "res", ")", "\n", "check_expected_results", "(", "res", ",", "expected_results", ",", "expected_results_sigma_tol", ")", "\n", "if", "output_folder", ":", "\n", "            ", "torch", ".", "save", "(", "res", ",", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"box_proposals.pth\"", ")", ")", "\n", "", "return", "\n", "", "logger", ".", "info", "(", "\"Preparing results for COCO format\"", ")", "\n", "coco_results", "=", "{", "}", "\n", "if", "\"bbox\"", "in", "iou_types", ":", "\n", "        ", "logger", ".", "info", "(", "\"Preparing bbox results\"", ")", "\n", "coco_results", "[", "\"bbox\"", "]", "=", "prepare_for_coco_detection", "(", "predictions", ",", "dataset", ")", "\n", "", "if", "\"segm\"", "in", "iou_types", ":", "\n", "        ", "logger", ".", "info", "(", "\"Preparing segm results\"", ")", "\n", "coco_results", "[", "\"segm\"", "]", "=", "prepare_for_coco_segmentation", "(", "predictions", ",", "dataset", ")", "\n", "", "if", "'keypoints'", "in", "iou_types", ":", "\n", "        ", "logger", ".", "info", "(", "'Preparing keypoints results'", ")", "\n", "coco_results", "[", "'keypoints'", "]", "=", "prepare_for_coco_keypoint", "(", "predictions", ",", "dataset", ")", "\n", "\n", "", "results", "=", "COCOResults", "(", "*", "iou_types", ")", "\n", "logger", ".", "info", "(", "\"Evaluating predictions\"", ")", "\n", "for", "iou_type", "in", "iou_types", ":", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "f", ":", "\n", "            ", "file_path", "=", "f", ".", "name", "\n", "if", "output_folder", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "iou_type", "+", "\".json\"", ")", "\n", "", "res", "=", "evaluate_predictions_on_coco", "(", "\n", "dataset", ".", "coco", ",", "coco_results", "[", "iou_type", "]", ",", "file_path", ",", "iou_type", "\n", ")", "\n", "results", ".", "update", "(", "res", ")", "\n", "", "", "logger", ".", "info", "(", "results", ")", "\n", "check_expected_results", "(", "results", ",", "expected_results", ",", "expected_results_sigma_tol", ")", "\n", "if", "output_folder", ":", "\n", "        ", "torch", ".", "save", "(", "results", ",", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"coco_results.pth\"", ")", ")", "\n", "", "return", "results", ",", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.prepare_for_coco_detection": [[70, 102], ["enumerate", "dataset.get_img_info", "prediction.convert.resize", "prediction.convert.convert", "prediction.convert.bbox.tolist", "prediction.convert.get_field().tolist", "prediction.convert.get_field().tolist", "coco_results.extend", "len", "prediction.convert.get_field", "prediction.convert.get_field", "enumerate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "prepare_for_coco_detection", "(", "predictions", ",", "dataset", ")", ":", "\n", "# assert isinstance(dataset, COCODataset)", "\n", "    ", "coco_results", "=", "[", "]", "\n", "for", "image_id", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "original_id", "=", "dataset", ".", "id_to_img_map", "[", "image_id", "]", "\n", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "img_info", "=", "dataset", ".", "get_img_info", "(", "image_id", ")", "\n", "image_width", "=", "img_info", "[", "\"width\"", "]", "\n", "image_height", "=", "img_info", "[", "\"height\"", "]", "\n", "prediction", "=", "prediction", ".", "resize", "(", "(", "image_width", ",", "image_height", ")", ")", "\n", "prediction", "=", "prediction", ".", "convert", "(", "\"xywh\"", ")", "\n", "\n", "boxes", "=", "prediction", ".", "bbox", ".", "tolist", "(", ")", "\n", "scores", "=", "prediction", ".", "get_field", "(", "\"scores\"", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "prediction", ".", "get_field", "(", "\"labels\"", ")", ".", "tolist", "(", ")", "\n", "\n", "mapped_labels", "=", "[", "dataset", ".", "contiguous_category_id_to_json_id", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "\n", "coco_results", ".", "extend", "(", "\n", "[", "\n", "{", "\n", "\"image_id\"", ":", "original_id", ",", "\n", "\"category_id\"", ":", "mapped_labels", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "box", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "for", "k", ",", "box", "in", "enumerate", "(", "boxes", ")", "\n", "]", "\n", ")", "\n", "", "return", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.prepare_for_coco_segmentation": [[104, 156], ["fcos_core.modeling.roi_heads.mask_head.inference.Masker", "tqdm.tqdm", "enumerate", "dataset.get_img_info", "prediction.resize.resize", "prediction.resize.get_field", "prediction.resize.get_field().tolist", "prediction.resize.get_field().tolist", "coco_results.extend", "len", "list", "fcos_core.modeling.roi_heads.mask_head.inference.Masker.", "rle[].decode", "masker.expand", "prediction.resize.get_field", "prediction.resize.get_field", "mask_util.encode", "np.array", "enumerate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["", "def", "prepare_for_coco_segmentation", "(", "predictions", ",", "dataset", ")", ":", "\n", "    ", "import", "pycocotools", ".", "mask", "as", "mask_util", "\n", "import", "numpy", "as", "np", "\n", "\n", "masker", "=", "Masker", "(", "threshold", "=", "0.5", ",", "padding", "=", "1", ")", "\n", "# assert isinstance(dataset, COCODataset)", "\n", "coco_results", "=", "[", "]", "\n", "for", "image_id", ",", "prediction", "in", "tqdm", "(", "enumerate", "(", "predictions", ")", ")", ":", "\n", "        ", "original_id", "=", "dataset", ".", "id_to_img_map", "[", "image_id", "]", "\n", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "img_info", "=", "dataset", ".", "get_img_info", "(", "image_id", ")", "\n", "image_width", "=", "img_info", "[", "\"width\"", "]", "\n", "image_height", "=", "img_info", "[", "\"height\"", "]", "\n", "prediction", "=", "prediction", ".", "resize", "(", "(", "image_width", ",", "image_height", ")", ")", "\n", "masks", "=", "prediction", ".", "get_field", "(", "\"mask\"", ")", "\n", "# t = time.time()", "\n", "# Masker is necessary only if masks haven't been already resized.", "\n", "if", "list", "(", "masks", ".", "shape", "[", "-", "2", ":", "]", ")", "!=", "[", "image_height", ",", "image_width", "]", ":", "\n", "            ", "masks", "=", "masker", "(", "masks", ".", "expand", "(", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "prediction", ")", "\n", "masks", "=", "masks", "[", "0", "]", "\n", "# logger.info('Time mask: {}'.format(time.time() - t))", "\n", "# prediction = prediction.convert('xywh')", "\n", "\n", "# boxes = prediction.bbox.tolist()", "\n", "", "scores", "=", "prediction", ".", "get_field", "(", "\"scores\"", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "prediction", ".", "get_field", "(", "\"labels\"", ")", ".", "tolist", "(", ")", "\n", "\n", "# rles = prediction.get_field('mask')", "\n", "\n", "rles", "=", "[", "\n", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", "0", ",", ":", ",", ":", ",", "np", ".", "newaxis", "]", ",", "order", "=", "\"F\"", ")", ")", "[", "0", "]", "\n", "for", "mask", "in", "masks", "\n", "]", "\n", "for", "rle", "in", "rles", ":", "\n", "            ", "rle", "[", "\"counts\"", "]", "=", "rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "mapped_labels", "=", "[", "dataset", ".", "contiguous_category_id_to_json_id", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "\n", "coco_results", ".", "extend", "(", "\n", "[", "\n", "{", "\n", "\"image_id\"", ":", "original_id", ",", "\n", "\"category_id\"", ":", "mapped_labels", "[", "k", "]", ",", "\n", "\"segmentation\"", ":", "rle", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "for", "k", ",", "rle", "in", "enumerate", "(", "rles", ")", "\n", "]", "\n", ")", "\n", "", "return", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.prepare_for_coco_keypoint": [[158, 187], ["enumerate", "prediction.convert.resize", "prediction.convert.convert", "prediction.convert.bbox.tolist", "prediction.convert.get_field().tolist", "prediction.convert.get_field().tolist", "prediction.convert.get_field", "keypoints.keypoints.view().tolist.resize", "keypoints.keypoints.view().tolist.keypoints.view().tolist", "coco_results.extend", "len", "prediction.convert.get_field", "prediction.convert.get_field", "keypoints.keypoints.view().tolist.keypoints.view", "enumerate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "prepare_for_coco_keypoint", "(", "predictions", ",", "dataset", ")", ":", "\n", "# assert isinstance(dataset, COCODataset)", "\n", "    ", "coco_results", "=", "[", "]", "\n", "for", "image_id", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "original_id", "=", "dataset", ".", "id_to_img_map", "[", "image_id", "]", "\n", "if", "len", "(", "prediction", ".", "bbox", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "# TODO replace with get_img_info?", "\n", "", "image_width", "=", "dataset", ".", "coco", ".", "imgs", "[", "original_id", "]", "[", "'width'", "]", "\n", "image_height", "=", "dataset", ".", "coco", ".", "imgs", "[", "original_id", "]", "[", "'height'", "]", "\n", "prediction", "=", "prediction", ".", "resize", "(", "(", "image_width", ",", "image_height", ")", ")", "\n", "prediction", "=", "prediction", ".", "convert", "(", "'xywh'", ")", "\n", "\n", "boxes", "=", "prediction", ".", "bbox", ".", "tolist", "(", ")", "\n", "scores", "=", "prediction", ".", "get_field", "(", "'scores'", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "prediction", ".", "get_field", "(", "'labels'", ")", ".", "tolist", "(", ")", "\n", "keypoints", "=", "prediction", ".", "get_field", "(", "'keypoints'", ")", "\n", "keypoints", "=", "keypoints", ".", "resize", "(", "(", "image_width", ",", "image_height", ")", ")", "\n", "keypoints", "=", "keypoints", ".", "keypoints", ".", "view", "(", "keypoints", ".", "keypoints", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "mapped_labels", "=", "[", "dataset", ".", "contiguous_category_id_to_json_id", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "\n", "coco_results", ".", "extend", "(", "[", "{", "\n", "'image_id'", ":", "original_id", ",", "\n", "'category_id'", ":", "mapped_labels", "[", "k", "]", ",", "\n", "'keypoints'", ":", "keypoint", ",", "\n", "'score'", ":", "scores", "[", "k", "]", "}", "for", "k", ",", "keypoint", "in", "enumerate", "(", "keypoints", ")", "]", ")", "\n", "", "return", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.evaluate_box_proposals": [[189, 302], ["enumerate", "torch.cat", "torch.sort", "torch.zeros_like", "enumerate", "torch.zeros_like.mean", "dataset.get_img_info", "prediction.resize.resize", "dataset.coco.getAnnIds", "dataset.coco.loadAnns", "torch.as_tensor().reshape", "fcos_core.structures.bounding_box.BoxList().convert", "torch.as_tensor", "len", "fcos_core.structures.boxlist_ops.boxlist_iou", "torch.zeros", "range", "torch.cat.append", "torch.arange", "prediction.resize.get_field().sort", "len", "len", "len", "len", "min", "fcos_core.structures.boxlist_ops.boxlist_iou.max", "max_overlaps.max", "float", "torch.as_tensor", "fcos_core.structures.bounding_box.BoxList", "len", "len", "len", "prediction.resize.get_field"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "evaluate_box_proposals", "(", "\n", "predictions", ",", "dataset", ",", "thresholds", "=", "None", ",", "area", "=", "\"all\"", ",", "limit", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"Evaluate detection proposal recall metrics. This function is a much\n    faster alternative to the official COCO API recall evaluation code. However,\n    it produces slightly different results.\n    \"\"\"", "\n", "# Record max overlap value for each gt box", "\n", "# Return vector of overlap values", "\n", "areas", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"small\"", ":", "1", ",", "\n", "\"medium\"", ":", "2", ",", "\n", "\"large\"", ":", "3", ",", "\n", "\"96-128\"", ":", "4", ",", "\n", "\"128-256\"", ":", "5", ",", "\n", "\"256-512\"", ":", "6", ",", "\n", "\"512-inf\"", ":", "7", ",", "\n", "}", "\n", "area_ranges", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "# all", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "# small", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "# medium", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "# large", "\n", "[", "96", "**", "2", ",", "128", "**", "2", "]", ",", "# 96-128", "\n", "[", "128", "**", "2", ",", "256", "**", "2", "]", ",", "# 128-256", "\n", "[", "256", "**", "2", ",", "512", "**", "2", "]", ",", "# 256-512", "\n", "[", "512", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "# 512-inf", "\n", "assert", "area", "in", "areas", ",", "\"Unknown area range: {}\"", ".", "format", "(", "area", ")", "\n", "area_range", "=", "area_ranges", "[", "areas", "[", "area", "]", "]", "\n", "gt_overlaps", "=", "[", "]", "\n", "num_pos", "=", "0", "\n", "\n", "for", "image_id", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "original_id", "=", "dataset", ".", "id_to_img_map", "[", "image_id", "]", "\n", "\n", "img_info", "=", "dataset", ".", "get_img_info", "(", "image_id", ")", "\n", "image_width", "=", "img_info", "[", "\"width\"", "]", "\n", "image_height", "=", "img_info", "[", "\"height\"", "]", "\n", "prediction", "=", "prediction", ".", "resize", "(", "(", "image_width", ",", "image_height", ")", ")", "\n", "\n", "# sort predictions in descending order", "\n", "# TODO maybe remove this and make it explicit in the documentation", "\n", "inds", "=", "prediction", ".", "get_field", "(", "\"objectness\"", ")", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "\n", "prediction", "=", "prediction", "[", "inds", "]", "\n", "\n", "ann_ids", "=", "dataset", ".", "coco", ".", "getAnnIds", "(", "imgIds", "=", "original_id", ")", "\n", "anno", "=", "dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "gt_boxes", "=", "[", "obj", "[", "\"bbox\"", "]", "for", "obj", "in", "anno", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "]", "\n", "gt_boxes", "=", "torch", ".", "as_tensor", "(", "gt_boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "gt_boxes", "=", "BoxList", "(", "gt_boxes", ",", "(", "image_width", ",", "image_height", ")", ",", "mode", "=", "\"xywh\"", ")", ".", "convert", "(", "\n", "\"xyxy\"", "\n", ")", "\n", "gt_areas", "=", "torch", ".", "as_tensor", "(", "[", "obj", "[", "\"area\"", "]", "for", "obj", "in", "anno", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "]", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "valid_gt_inds", "=", "(", "gt_areas", ">=", "area_range", "[", "0", "]", ")", "&", "(", "gt_areas", "<=", "area_range", "[", "1", "]", ")", "\n", "gt_boxes", "=", "gt_boxes", "[", "valid_gt_inds", "]", "\n", "\n", "num_pos", "+=", "len", "(", "gt_boxes", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "limit", "is", "not", "None", "and", "len", "(", "prediction", ")", ">", "limit", ":", "\n", "            ", "prediction", "=", "prediction", "[", ":", "limit", "]", "\n", "\n", "", "overlaps", "=", "boxlist_iou", "(", "prediction", ",", "gt_boxes", ")", "\n", "\n", "_gt_overlaps", "=", "torch", ".", "zeros", "(", "len", "(", "gt_boxes", ")", ")", "\n", "for", "j", "in", "range", "(", "min", "(", "len", "(", "prediction", ")", ",", "len", "(", "gt_boxes", ")", ")", ")", ":", "\n", "# find which proposal box maximally covers each gt box", "\n", "# and get the iou amount of coverage for each gt box", "\n", "            ", "max_overlaps", ",", "argmax_overlaps", "=", "overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "# find which gt box is 'best' covered (i.e. 'best' = most iou)", "\n", "gt_ovr", ",", "gt_ind", "=", "max_overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "assert", "gt_ovr", ">=", "0", "\n", "# find the proposal box that covers the best covered gt box", "\n", "box_ind", "=", "argmax_overlaps", "[", "gt_ind", "]", "\n", "# record the iou coverage of this gt box", "\n", "_gt_overlaps", "[", "j", "]", "=", "overlaps", "[", "box_ind", ",", "gt_ind", "]", "\n", "assert", "_gt_overlaps", "[", "j", "]", "==", "gt_ovr", "\n", "# mark the proposal box and the gt box as used", "\n", "overlaps", "[", "box_ind", ",", ":", "]", "=", "-", "1", "\n", "overlaps", "[", ":", ",", "gt_ind", "]", "=", "-", "1", "\n", "\n", "# append recorded iou coverage level", "\n", "", "gt_overlaps", ".", "append", "(", "_gt_overlaps", ")", "\n", "", "gt_overlaps", "=", "torch", ".", "cat", "(", "gt_overlaps", ",", "dim", "=", "0", ")", "\n", "gt_overlaps", ",", "_", "=", "torch", ".", "sort", "(", "gt_overlaps", ")", "\n", "\n", "if", "thresholds", "is", "None", ":", "\n", "        ", "step", "=", "0.05", "\n", "thresholds", "=", "torch", ".", "arange", "(", "0.5", ",", "0.95", "+", "1e-5", ",", "step", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "recalls", "=", "torch", ".", "zeros_like", "(", "thresholds", ")", "\n", "# compute recall for each iou threshold", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "recalls", "[", "i", "]", "=", "(", "gt_overlaps", ">=", "t", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "float", "(", "num_pos", ")", "\n", "# ar = 2 * np.trapz(recalls, thresholds)", "\n", "", "ar", "=", "recalls", ".", "mean", "(", ")", "\n", "return", "{", "\n", "\"ar\"", ":", "ar", ",", "\n", "\"recalls\"", ":", "recalls", ",", "\n", "\"thresholds\"", ":", "thresholds", ",", "\n", "\"gt_overlaps\"", ":", "gt_overlaps", ",", "\n", "\"num_pos\"", ":", "num_pos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.evaluate_predictions_on_coco": [[305, 327], ["COCOeval", "COCOeval.evaluate", "COCOeval.accumulate", "COCOeval.summarize", "coco_eval.compute_thresholds_for_classes", "open", "json.dump", "coco_gt.loadRes", "COCO", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.evaluate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.densepose_coco_evaluation.DensePoseCocoEval.summarize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.compute_thresholds_for_classes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["", "def", "evaluate_predictions_on_coco", "(", "\n", "coco_gt", ",", "coco_results", ",", "json_result_file", ",", "iou_type", "=", "\"bbox\"", "\n", ")", ":", "\n", "    ", "import", "json", "\n", "\n", "with", "open", "(", "json_result_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "coco_results", ",", "f", ")", "\n", "\n", "", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocotools", ".", "cocoeval", "import", "COCOeval", "\n", "\n", "coco_dt", "=", "coco_gt", ".", "loadRes", "(", "str", "(", "json_result_file", ")", ")", "if", "coco_results", "else", "COCO", "(", ")", "\n", "\n", "# coco_dt = coco_gt.loadRes(coco_results)", "\n", "coco_eval", "=", "COCOeval", "(", "coco_gt", ",", "coco_dt", ",", "iou_type", ")", "\n", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "return", "coco_eval", "\n", "\n", "\n", "", "class", "COCOResults", "(", "object", ")", ":", "\n", "    ", "METRICS", "=", "{", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.check_expected_results": [[403, 423], ["logging.getLogger", "logging.getLogger.error", "logging.getLogger.info"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval_wrapper.do_coco_evaluation": [[13, 49], ["logging.getLogger", "logging.getLogger.info", "abs_to_coco.convert_abstract_to_coco", "os.path.join", "logging.getLogger.info", "logging.getLogger.info", "maskrcnn_benchmark.data.datasets.coco.COCODataset", "coco_eval.do_coco_evaluation", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.abs_to_coco.convert_abstract_to_coco", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval_wrapper.do_coco_evaluation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["def", "do_coco_evaluation", "(", "\n", "dataset", ",", "\n", "predictions", ",", "\n", "box_only", ",", "\n", "output_folder", ",", "\n", "iou_types", ",", "\n", "expected_results", ",", "\n", "expected_results_sigma_tol", ",", "\n", ")", ":", "\n", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.inference\"", ")", "\n", "logger", ".", "info", "(", "\"Converting annotations to COCO format...\"", ")", "\n", "coco_annotation_dict", "=", "convert_abstract_to_coco", "(", "dataset", ")", "\n", "\n", "dataset_name", "=", "dataset", ".", "__class__", ".", "__name__", "\n", "coco_annotation_path", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "dataset_name", "+", "\".json\"", ")", "\n", "logger", ".", "info", "(", "\"Saving annotations to %s\"", "%", "coco_annotation_path", ")", "\n", "with", "open", "(", "coco_annotation_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "coco_annotation_dict", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Loading annotations as COCODataset\"", ")", "\n", "coco_dataset", "=", "COCODataset", "(", "\n", "ann_file", "=", "coco_annotation_path", ",", "\n", "root", "=", "\"\"", ",", "\n", "remove_images_without_annotations", "=", "False", ",", "\n", "transforms", "=", "None", ",", "# transformations should be already saved to the json", "\n", ")", "\n", "\n", "return", "orig_evaluation", "(", "\n", "dataset", "=", "coco_dataset", ",", "\n", "predictions", "=", "predictions", ",", "\n", "box_only", "=", "box_only", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "expected_results", "=", "expected_results", ",", "\n", "expected_results_sigma_tol", "=", "expected_results", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.__init__.coco_evaluation": [[4, 21], ["coco_eval.do_coco_evaluation"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval_wrapper.do_coco_evaluation"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.abs_to_coco.convert_abstract_to_coco": [[18, 102], ["logging.getLogger", "isinstance", "len", "logging.getLogger.info", "enumerate", "logging.getLogger.info", "torch.multiprocessing.cpu_count", "min", "torch.multiprocessing.Pool", "logging.getLogger.info", "datetime.datetime.now", "torch.multiprocessing.cpu_count", "tqdm.tqdm", "pool.imap", "dataset.id_to_name.items", "str", "images.append", "annotations.extend", "progress_bar.update", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["def", "convert_abstract_to_coco", "(", "dataset", ",", "num_workers", "=", "None", ",", "chunksize", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    Convert any dataset derived from AbstractDataset to COCO style\n    for evaluating with the pycocotools lib\n\n    Conversion imitates required fields of COCO instance segmentation\n    ground truth files like: \".../annotations/instances_train2014.json\"\n\n    After th conversion is done a dict is returned that follows the same\n    format as COCO json files.\n\n    By default .coco_eval_wrapper.py saves it to the hard-drive in json format\n    and loads it with the maskrcnn_benchmark's default COCODataset\n\n    Args:\n        dataset: any dataset derived from AbstractDataset\n        num_workers (optional): number of worker threads to parallelize the\n            conversion (default is to use all cores for conversion)\n        chunk_size (optional): how many entries one thread processes before\n            requesting new task. The larger the less overhead there is.\n    \"\"\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"maskrcnn_benchmark.inference\"", ")", "\n", "assert", "isinstance", "(", "dataset", ",", "AbstractDataset", ")", "\n", "# Official COCO annotations have these fields", "\n", "# 'info', 'licenses', 'images', 'type', 'annotations', 'categories'", "\n", "coco_dict", "=", "{", "}", "\n", "coco_dict", "[", "\"info\"", "]", "=", "{", "\n", "\"description\"", ":", "(", "\n", "\"This is an automatically generated COCO annotation\"", "\n", "\" file using maskrcnn_benchmark\"", "\n", ")", ",", "\n", "\"date_created\"", ":", "\"%s\"", "%", "datetime", ".", "now", "(", ")", ",", "\n", "}", "\n", "coco_dict", "[", "\"type\"", "]", "=", "\"instances\"", "\n", "\n", "images", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "\n", "if", "num_workers", "is", "None", ":", "\n", "        ", "num_workers", "=", "torch", ".", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "num_workers", "=", "min", "(", "num_workers", ",", "torch", ".", "multiprocessing", ".", "cpu_count", "(", ")", ")", "\n", "\n", "", "dataset_name", "=", "dataset", ".", "__class__", ".", "__name__", "\n", "num_images", "=", "len", "(", "dataset", ")", "\n", "logger", ".", "info", "(", "\n", "(", "\n", "\"Parsing each entry in \"", "\n", "\"%s, total=%d. \"", "\n", "\"Using N=%d workers and chunksize=%d\"", "\n", ")", "\n", "%", "(", "dataset_name", ",", "num_images", ",", "num_workers", ",", "chunksize", ")", "\n", ")", "\n", "\n", "with", "torch", ".", "multiprocessing", ".", "Pool", "(", "num_workers", ")", "as", "pool", ":", "\n", "        ", "with", "tqdm", "(", "total", "=", "num_images", ")", "as", "progress_bar", ":", "\n", "            ", "args", "=", "[", "(", "dataset", ",", "idx", ")", "for", "idx", "in", "range", "(", "num_images", ")", "]", "\n", "iterator", "=", "pool", ".", "imap", "(", "process_single_image", ",", "args", ",", "chunksize", "=", "100", ")", "\n", "for", "img_annots_pair", "in", "iterator", ":", "\n", "                ", "image", ",", "per_img_annotations", "=", "img_annots_pair", "\n", "\n", "images", ".", "append", "(", "image", ")", "\n", "annotations", ".", "extend", "(", "per_img_annotations", ")", "\n", "progress_bar", ".", "update", "(", ")", "\n", "\n", "", "", "", "for", "ann_id", ",", "ann", "in", "enumerate", "(", "annotations", ",", "1", ")", ":", "\n", "        ", "ann", "[", "\"id\"", "]", "=", "ann_id", "\n", "\n", "", "logger", ".", "info", "(", "\"Parsing categories:\"", ")", "\n", "# CATEGORY DATA", "\n", "categories", "=", "[", "\n", "{", "\"id\"", ":", "category_id", ",", "\"name\"", ":", "name", "}", "\n", "for", "category_id", ",", "name", "in", "dataset", ".", "id_to_name", ".", "items", "(", ")", "\n", "if", "name", "!=", "\"__background__\"", "\n", "]", "\n", "# Logging categories", "\n", "for", "cat", "in", "categories", ":", "\n", "        ", "logger", ".", "info", "(", "str", "(", "cat", ")", ")", "\n", "\n", "", "coco_dict", "[", "\"images\"", "]", "=", "images", "\n", "coco_dict", "[", "\"annotations\"", "]", "=", "annotations", "\n", "coco_dict", "[", "\"categories\"", "]", "=", "categories", "\n", "return", "coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.abs_to_coco.process_single_image": [[104, 187], ["dataset.get_img_info", "isinstance", "image.update", "isinstance", "target.convert().bbox.tolist", "target.get_field().long().tolist", "len", "range", "image.keys", "target.fields", "target.get_field().get_mask_tensor", "abs_to_coco.masks_to_rles", "target.area().tolist", "len", "len", "len", "per_img_annotations.append", "masks.unsqueeze.dim", "masks.unsqueeze.unsqueeze", "target.get_field().long", "target.convert", "target.get_field", "target.area", "target.get_field"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.segmentation_mask.SegmentationMask.get_mask_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.abs_to_coco.masks_to_rles", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.area", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field"], ["", "def", "process_single_image", "(", "args", ")", ":", "\n", "    ", "dataset", ",", "idx", "=", "args", "\n", "# IMAGE DATA", "\n", "img_id", "=", "idx", "+", "1", "\n", "image", "=", "{", "}", "\n", "# Official COCO \"images\" entries have these fields", "\n", "# 'license', 'url', 'file_name', 'height', 'width', 'date_captured', 'id'", "\n", "\n", "img", ",", "target", ",", "ret_idx", "=", "dataset", "[", "idx", "]", "\n", "img_info", "=", "dataset", ".", "get_img_info", "(", "idx", ")", "\n", "assert", "isinstance", "(", "img_info", ",", "dict", ")", "\n", "image", ".", "update", "(", "img_info", ")", "\n", "image", "[", "\"width\"", "]", ",", "image", "[", "\"height\"", "]", "=", "target", ".", "size", "\n", "\n", "if", "\"id\"", "not", "in", "image", ".", "keys", "(", ")", ":", "\n", "# Start indexing from 1 if \"id\" field is not present", "\n", "        ", "image", "[", "\"id\"", "]", "=", "img_id", "\n", "", "else", ":", "\n", "        ", "img_id", "=", "image", "[", "\"id\"", "]", "\n", "\n", "# ANNOTATION DATA", "\n", "", "per_img_annotations", "=", "[", "]", "\n", "# Official COCO \"annotations\" entries have these fields", "\n", "# 'segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'", "\n", "\n", "#", "\n", "\n", "assert", "ret_idx", "==", "idx", ",", "(", "ret_idx", ",", "idx", ")", "\n", "assert", "isinstance", "(", "target", ",", "BoxList", ")", "\n", "\n", "bboxes", "=", "target", ".", "convert", "(", "\"xywh\"", ")", ".", "bbox", ".", "tolist", "(", ")", "\n", "segm_available", "=", "\"masks\"", "in", "target", ".", "fields", "(", ")", "\n", "if", "segm_available", ":", "\n", "        ", "masks", "=", "target", ".", "get_field", "(", "\"masks\"", ")", ".", "get_mask_tensor", "(", ")", "# [N, H, W]", "\n", "if", "masks", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "masks", "=", "masks", ".", "unsqueeze", "(", "0", ")", "\n", "", "rles", "=", "masks_to_rles", "(", "masks", ")", "\n", "\"\"\"\n        !!!WARNING!!!\n        At this point the area value differs from the precomputed\n        original COCO area values, because we compute the area\n        by counting the nonzero entries of the binary mask\n        while COCO areas are computed directly from the polygons\n\n        Example:\n        Reference image data\n        {'license': 2,\n         'url': 'http://farm9.staticflickr.com/8035/8024364858_9c41dc1666_z.jpg',\n         'file_name': 'COCO_val2014_000000000139.jpg',\n         'height': 426,\n         'width': 640,\n         'date_captured': '2013-11-21 01:34:01',\n         'id': 139}\n\n        Original COCO area values\n        [  531.8071, 13244.6572,  5833.1182,  2245.3435,  1833.7841,  1289.3734,\n           210.1482,  2913.1104,   435.1450,   217.7192,  2089.9749,   338.6089,\n           322.5936,   225.6642,  2171.6189,   178.1851,    90.9873,   189.5601,\n           120.2320,  2362.4897]\n\n        Area values using the binary masks\n        [  531, 13247,  5846,  2251,  1850,  1292,   212,  2922,   439,   224,\n           2060,   342,   324,   226,  2171,   178,    90,   187,   120,  2372]\n        \"\"\"", "\n", "areas", "=", "(", "masks", "!=", "0", ")", ".", "sum", "(", "[", "1", ",", "2", "]", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "        ", "areas", "=", "target", ".", "area", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "", "cat_ids", "=", "target", ".", "get_field", "(", "\"labels\"", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "assert", "len", "(", "bboxes", ")", "==", "len", "(", "areas", ")", "==", "len", "(", "cat_ids", ")", "\n", "num_instances", "=", "len", "(", "target", ")", "\n", "for", "ann_idx", "in", "range", "(", "num_instances", ")", ":", "\n", "        ", "annotation", "=", "{", "}", "\n", "if", "segm_available", ":", "\n", "            ", "annotation", "[", "\"segmentation\"", "]", "=", "rles", "[", "ann_idx", "]", "\n", "", "annotation", "[", "\"area\"", "]", "=", "areas", "[", "ann_idx", "]", "\n", "annotation", "[", "\"iscrowd\"", "]", "=", "0", "\n", "annotation", "[", "\"image_id\"", "]", "=", "img_id", "\n", "annotation", "[", "\"bbox\"", "]", "=", "bboxes", "[", "ann_idx", "]", "\n", "annotation", "[", "\"category_id\"", "]", "=", "cat_ids", "[", "ann_idx", "]", "\n", "per_img_annotations", ".", "append", "(", "annotation", ")", "\n", "\n", "", "return", "image", ",", "per_img_annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.abs_to_coco.masks_to_rles": [[189, 199], ["numpy.array", "rle[].decode", "rles.append", "pycocotools.encode"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["", "def", "masks_to_rles", "(", "masks_tensor", ")", ":", "\n", "# TODO: parallelize", "\n", "    ", "rles", "=", "[", "]", "\n", "for", "instance_mask", "in", "masks_tensor", ":", "\n", "        ", "np_mask", "=", "np", ".", "array", "(", "instance_mask", "[", ":", ",", ":", ",", "None", "]", ",", "order", "=", "\"F\"", ")", "\n", "rle", "=", "mask_util", ".", "encode", "(", "np_mask", ")", "[", "0", "]", "\n", "rle", "[", "\"counts\"", "]", "=", "rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "rles", ".", "append", "(", "rle", ")", "\n", "\n", "", "return", "rles", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.compute_thresholds_for_classes": [[329, 356], ["np.linspace", "f_measure.max", "f_measure.argmax", "print", "print", "print", "print", "np.maximum", "list", "list", "range", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["\"segm\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"box_proposal\"", ":", "[", "\n", "\"AR@100\"", ",", "\n", "\"ARs@100\"", ",", "\n", "\"ARm@100\"", ",", "\n", "\"ARl@100\"", ",", "\n", "\"AR@1000\"", ",", "\n", "\"ARs@1000\"", ",", "\n", "\"ARm@1000\"", ",", "\n", "\"ARl@1000\"", ",", "\n", "]", ",", "\n", "\"keypoints\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "}", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "iou_types", ")", ":", "\n", "        ", "allowed_types", "=", "(", "\"box_proposal\"", ",", "\"bbox\"", ",", "\"segm\"", ",", "\"keypoints\"", ")", "\n", "assert", "all", "(", "iou_type", "in", "allowed_types", "for", "iou_type", "in", "iou_types", ")", "\n", "results", "=", "OrderedDict", "(", ")", "\n", "for", "iou_type", "in", "iou_types", ":", "\n", "            ", "results", "[", "iou_type", "]", "=", "OrderedDict", "(", "\n", "[", "(", "metric", ",", "-", "1", ")", "for", "metric", "in", "COCOResults", ".", "METRICS", "[", "iou_type", "]", "]", "\n", ")", "\n", "", "self", ".", "results", "=", "results", "\n", "\n", "", "def", "update", "(", "self", ",", "coco_eval", ")", ":", "\n", "        ", "if", "coco_eval", "is", "None", ":", "\n", "            ", "return", "\n", "", "from", "pycocotools", ".", "cocoeval", "import", "COCOeval", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.do_voc_evaluation": [[12, 44], ["enumerate", "voc_eval.eval_detection_voc", "enumerate", "logger.info", "dataset.get_img_info", "prediction.resize.resize", "pred_boxlists.append", "dataset.get_groundtruth", "gt_boxlists.append", "dataset.map_class_id_to_class_name", "open", "fid.write", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.eval_detection_voc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_img_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.get_groundtruth", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.datasets.voc.PascalVOCDataset.map_class_id_to_class_name", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["def", "do_voc_evaluation", "(", "dataset", ",", "predictions", ",", "output_folder", ",", "logger", ")", ":", "\n", "# TODO need to make the use_07_metric format available", "\n", "# for the user to choose", "\n", "    ", "pred_boxlists", "=", "[", "]", "\n", "gt_boxlists", "=", "[", "]", "\n", "for", "image_id", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "img_info", "=", "dataset", ".", "get_img_info", "(", "image_id", ")", "\n", "image_width", "=", "img_info", "[", "\"width\"", "]", "\n", "image_height", "=", "img_info", "[", "\"height\"", "]", "\n", "prediction", "=", "prediction", ".", "resize", "(", "(", "image_width", ",", "image_height", ")", ")", "\n", "pred_boxlists", ".", "append", "(", "prediction", ")", "\n", "\n", "gt_boxlist", "=", "dataset", ".", "get_groundtruth", "(", "image_id", ")", "\n", "gt_boxlists", ".", "append", "(", "gt_boxlist", ")", "\n", "", "result", "=", "eval_detection_voc", "(", "\n", "pred_boxlists", "=", "pred_boxlists", ",", "\n", "gt_boxlists", "=", "gt_boxlists", ",", "\n", "iou_thresh", "=", "0.5", ",", "\n", "use_07_metric", "=", "True", ",", "\n", ")", "\n", "result_str", "=", "\"mAP: {:.4f}\\n\"", ".", "format", "(", "result", "[", "\"map\"", "]", ")", "\n", "for", "i", ",", "ap", "in", "enumerate", "(", "result", "[", "\"ap\"", "]", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "# skip background", "\n", "            ", "continue", "\n", "", "result_str", "+=", "\"{:<16}: {:.4f}\\n\"", ".", "format", "(", "\n", "dataset", ".", "map_class_id_to_class_name", "(", "i", ")", ",", "ap", "\n", ")", "\n", "", "logger", ".", "info", "(", "result_str", ")", "\n", "if", "output_folder", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"result.txt\"", ")", ",", "\"w\"", ")", "as", "fid", ":", "\n", "            ", "fid", ".", "write", "(", "result_str", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.eval_detection_voc": [[46, 64], ["voc_eval.calc_detection_voc_prec_rec", "voc_eval.calc_detection_voc_ap", "len", "len", "numpy.nanmean"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.calc_detection_voc_prec_rec", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.calc_detection_voc_ap"], ["", "def", "eval_detection_voc", "(", "pred_boxlists", ",", "gt_boxlists", ",", "iou_thresh", "=", "0.5", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"Evaluate on voc dataset.\n    Args:\n        pred_boxlists(list[BoxList]): pred boxlist, has labels and scores fields.\n        gt_boxlists(list[BoxList]): ground truth boxlist, has labels field.\n        iou_thresh: iou thresh\n        use_07_metric: boolean\n    Returns:\n        dict represents the results\n    \"\"\"", "\n", "assert", "len", "(", "gt_boxlists", ")", "==", "len", "(", "\n", "pred_boxlists", "\n", ")", ",", "\"Length of gt and pred lists need to be same.\"", "\n", "prec", ",", "rec", "=", "calc_detection_voc_prec_rec", "(", "\n", "pred_boxlists", "=", "pred_boxlists", ",", "gt_boxlists", "=", "gt_boxlists", ",", "iou_thresh", "=", "iou_thresh", "\n", ")", "\n", "ap", "=", "calc_detection_voc_ap", "(", "prec", ",", "rec", ",", "use_07_metric", "=", "use_07_metric", ")", "\n", "return", "{", "\"ap\"", ":", "ap", ",", "\"map\"", ":", "np", ".", "nanmean", "(", "ap", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.calc_detection_voc_prec_rec": [[66, 156], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "zip", "collections.defaultdict.keys", "pred_boxlist.bbox.numpy", "pred_boxlist.get_field().numpy", "pred_boxlist.get_field().numpy", "gt_boxlist.bbox.numpy", "gt_boxlist.get_field().numpy", "gt_boxlist.get_field().numpy", "numpy.unique", "max", "numpy.array", "numpy.array", "numpy.cumsum", "numpy.cumsum", "numpy.concatenate().astype", "numpy.logical_not().sum", "score[].extend", "pred_bbox_l.copy.copy", "gt_bbox_l.copy.copy", "fcos_core.structures.boxlist_ops.boxlist_iou().numpy", "boxlist_iou().numpy.argmax", "numpy.zeros", "collections.defaultdict.keys", "np.array.argsort", "pred_boxlist.get_field", "pred_boxlist.get_field", "gt_boxlist.get_field", "gt_boxlist.get_field", "pred_score_l.argsort", "len", "len", "match[].extend", "numpy.concatenate", "numpy.logical_not", "fcos_core.structures.boxlist_ops.boxlist_iou", "match[].append", "fcos_core.structures.bounding_box.BoxList", "fcos_core.structures.bounding_box.BoxList", "boxlist_iou().numpy.max", "match[].append", "match[].append", "match[].append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.get_field", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxlist_ops.boxlist_iou"], ["", "def", "calc_detection_voc_prec_rec", "(", "gt_boxlists", ",", "pred_boxlists", ",", "iou_thresh", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"Calculate precision and recall based on evaluation code of PASCAL VOC.\n    This function calculates precision and recall of\n    predicted bounding boxes obtained from a dataset which has :math:`N`\n    images.\n    The code is based on the evaluation code used in PASCAL VOC Challenge.\n   \"\"\"", "\n", "n_pos", "=", "defaultdict", "(", "int", ")", "\n", "score", "=", "defaultdict", "(", "list", ")", "\n", "match", "=", "defaultdict", "(", "list", ")", "\n", "for", "gt_boxlist", ",", "pred_boxlist", "in", "zip", "(", "gt_boxlists", ",", "pred_boxlists", ")", ":", "\n", "        ", "pred_bbox", "=", "pred_boxlist", ".", "bbox", ".", "numpy", "(", ")", "\n", "pred_label", "=", "pred_boxlist", ".", "get_field", "(", "\"labels\"", ")", ".", "numpy", "(", ")", "\n", "pred_score", "=", "pred_boxlist", ".", "get_field", "(", "\"scores\"", ")", ".", "numpy", "(", ")", "\n", "gt_bbox", "=", "gt_boxlist", ".", "bbox", ".", "numpy", "(", ")", "\n", "gt_label", "=", "gt_boxlist", ".", "get_field", "(", "\"labels\"", ")", ".", "numpy", "(", ")", "\n", "gt_difficult", "=", "gt_boxlist", ".", "get_field", "(", "\"difficult\"", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "l", "in", "np", ".", "unique", "(", "np", ".", "concatenate", "(", "(", "pred_label", ",", "gt_label", ")", ")", ".", "astype", "(", "int", ")", ")", ":", "\n", "            ", "pred_mask_l", "=", "pred_label", "==", "l", "\n", "pred_bbox_l", "=", "pred_bbox", "[", "pred_mask_l", "]", "\n", "pred_score_l", "=", "pred_score", "[", "pred_mask_l", "]", "\n", "# sort by score", "\n", "order", "=", "pred_score_l", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "pred_bbox_l", "=", "pred_bbox_l", "[", "order", "]", "\n", "pred_score_l", "=", "pred_score_l", "[", "order", "]", "\n", "\n", "gt_mask_l", "=", "gt_label", "==", "l", "\n", "gt_bbox_l", "=", "gt_bbox", "[", "gt_mask_l", "]", "\n", "gt_difficult_l", "=", "gt_difficult", "[", "gt_mask_l", "]", "\n", "\n", "n_pos", "[", "l", "]", "+=", "np", ".", "logical_not", "(", "gt_difficult_l", ")", ".", "sum", "(", ")", "\n", "score", "[", "l", "]", ".", "extend", "(", "pred_score_l", ")", "\n", "\n", "if", "len", "(", "pred_bbox_l", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "if", "len", "(", "gt_bbox_l", ")", "==", "0", ":", "\n", "                ", "match", "[", "l", "]", ".", "extend", "(", "(", "0", ",", ")", "*", "pred_bbox_l", ".", "shape", "[", "0", "]", ")", "\n", "continue", "\n", "\n", "# VOC evaluation follows integer typed bounding boxes.", "\n", "", "pred_bbox_l", "=", "pred_bbox_l", ".", "copy", "(", ")", "\n", "pred_bbox_l", "[", ":", ",", "2", ":", "]", "+=", "1", "\n", "gt_bbox_l", "=", "gt_bbox_l", ".", "copy", "(", ")", "\n", "gt_bbox_l", "[", ":", ",", "2", ":", "]", "+=", "1", "\n", "iou", "=", "boxlist_iou", "(", "\n", "BoxList", "(", "pred_bbox_l", ",", "gt_boxlist", ".", "size", ")", ",", "\n", "BoxList", "(", "gt_bbox_l", ",", "gt_boxlist", ".", "size", ")", ",", "\n", ")", ".", "numpy", "(", ")", "\n", "gt_index", "=", "iou", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "# set -1 if there is no matching ground truth", "\n", "gt_index", "[", "iou", ".", "max", "(", "axis", "=", "1", ")", "<", "iou_thresh", "]", "=", "-", "1", "\n", "del", "iou", "\n", "\n", "selec", "=", "np", ".", "zeros", "(", "gt_bbox_l", ".", "shape", "[", "0", "]", ",", "dtype", "=", "bool", ")", "\n", "for", "gt_idx", "in", "gt_index", ":", "\n", "                ", "if", "gt_idx", ">=", "0", ":", "\n", "                    ", "if", "gt_difficult_l", "[", "gt_idx", "]", ":", "\n", "                        ", "match", "[", "l", "]", ".", "append", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                        ", "if", "not", "selec", "[", "gt_idx", "]", ":", "\n", "                            ", "match", "[", "l", "]", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                            ", "match", "[", "l", "]", ".", "append", "(", "0", ")", "\n", "", "", "selec", "[", "gt_idx", "]", "=", "True", "\n", "", "else", ":", "\n", "                    ", "match", "[", "l", "]", ".", "append", "(", "0", ")", "\n", "\n", "", "", "", "", "n_fg_class", "=", "max", "(", "n_pos", ".", "keys", "(", ")", ")", "+", "1", "\n", "prec", "=", "[", "None", "]", "*", "n_fg_class", "\n", "rec", "=", "[", "None", "]", "*", "n_fg_class", "\n", "\n", "for", "l", "in", "n_pos", ".", "keys", "(", ")", ":", "\n", "        ", "score_l", "=", "np", ".", "array", "(", "score", "[", "l", "]", ")", "\n", "match_l", "=", "np", ".", "array", "(", "match", "[", "l", "]", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "\n", "order", "=", "score_l", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "match_l", "=", "match_l", "[", "order", "]", "\n", "\n", "tp", "=", "np", ".", "cumsum", "(", "match_l", "==", "1", ")", "\n", "fp", "=", "np", ".", "cumsum", "(", "match_l", "==", "0", ")", "\n", "\n", "# If an element of fp + tp is 0,", "\n", "# the corresponding element of prec[l] is nan.", "\n", "prec", "[", "l", "]", "=", "tp", "/", "(", "fp", "+", "tp", ")", "\n", "# If n_pos[l] is 0, rec[l] is None.", "\n", "if", "n_pos", "[", "l", "]", ">", "0", ":", "\n", "            ", "rec", "[", "l", "]", "=", "tp", "/", "n_pos", "[", "l", "]", "\n", "\n", "", "", "return", "prec", ",", "rec", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.calc_detection_voc_ap": [[158, 215], ["len", "numpy.empty", "range", "numpy.arange", "numpy.concatenate", "numpy.concatenate", "numpy.sum", "numpy.maximum.accumulate", "numpy.where", "numpy.sum", "numpy.max", "numpy.nan_to_num", "numpy.nan_to_num"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate"], ["", "def", "calc_detection_voc_ap", "(", "prec", ",", "rec", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate average precisions based on evaluation code of PASCAL VOC.\n    This function calculates average precisions\n    from given precisions and recalls.\n    The code is based on the evaluation code used in PASCAL VOC Challenge.\n    Args:\n        prec (list of numpy.array): A list of arrays.\n            :obj:`prec[l]` indicates precision for class :math:`l`.\n            If :obj:`prec[l]` is :obj:`None`, this function returns\n            :obj:`numpy.nan` for class :math:`l`.\n        rec (list of numpy.array): A list of arrays.\n            :obj:`rec[l]` indicates recall for class :math:`l`.\n            If :obj:`rec[l]` is :obj:`None`, this function returns\n            :obj:`numpy.nan` for class :math:`l`.\n        use_07_metric (bool): Whether to use PASCAL VOC 2007 evaluation metric\n            for calculating average precision. The default value is\n            :obj:`False`.\n    Returns:\n        ~numpy.ndarray:\n        This function returns an array of average precisions.\n        The :math:`l`-th value corresponds to the average precision\n        for class :math:`l`. If :obj:`prec[l]` or :obj:`rec[l]` is\n        :obj:`None`, the corresponding value is set to :obj:`numpy.nan`.\n    \"\"\"", "\n", "\n", "n_fg_class", "=", "len", "(", "prec", ")", "\n", "ap", "=", "np", ".", "empty", "(", "n_fg_class", ")", "\n", "for", "l", "in", "range", "(", "n_fg_class", ")", ":", "\n", "        ", "if", "prec", "[", "l", "]", "is", "None", "or", "rec", "[", "l", "]", "is", "None", ":", "\n", "            ", "ap", "[", "l", "]", "=", "np", ".", "nan", "\n", "continue", "\n", "\n", "", "if", "use_07_metric", ":", "\n", "# 11 point metric", "\n", "            ", "ap", "[", "l", "]", "=", "0", "\n", "for", "t", "in", "np", ".", "arange", "(", "0.0", ",", "1.1", ",", "0.1", ")", ":", "\n", "                ", "if", "np", ".", "sum", "(", "rec", "[", "l", "]", ">=", "t", ")", "==", "0", ":", "\n", "                    ", "p", "=", "0", "\n", "", "else", ":", "\n", "                    ", "p", "=", "np", ".", "max", "(", "np", ".", "nan_to_num", "(", "prec", "[", "l", "]", ")", "[", "rec", "[", "l", "]", ">=", "t", "]", ")", "\n", "", "ap", "[", "l", "]", "+=", "p", "/", "11", "\n", "", "", "else", ":", "\n", "# correct AP calculation", "\n", "# first append sentinel values at the end", "\n", "            ", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "0", "]", ",", "np", ".", "nan_to_num", "(", "prec", "[", "l", "]", ")", ",", "[", "0", "]", ")", ")", "\n", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0", "]", ",", "rec", "[", "l", "]", ",", "[", "1", "]", ")", ")", "\n", "\n", "mpre", "=", "np", ".", "maximum", ".", "accumulate", "(", "mpre", "[", ":", ":", "-", "1", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "# to calculate area under PR curve, look for points", "\n", "# where X axis (recall) changes value", "\n", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# and sum (\\Delta recall) * prec", "\n", "ap", "[", "l", "]", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "\n", "\n", "", "", "return", "ap", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.__init__.voc_evaluation": [[6, 16], ["logging.getLogger", "logging.getLogger.info", "voc_eval.do_voc_evaluation", "logging.getLogger.warning"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.voc.voc_eval.do_voc_evaluation"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed.DistributedSampler.__init__": [[25, 41], ["int", "torch.get_world_size", "torch.get_world_size", "torch.get_rank", "torch.get_rank", "math.ceil", "torch.is_available", "torch.is_available", "RuntimeError", "torch.is_available", "torch.is_available", "RuntimeError", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["def", "__init__", "(", "self", ",", "dataset", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "num_replicas", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "num_replicas", "=", "dist", ".", "get_world_size", "(", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "num_samples", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "dataset", ")", "*", "1.0", "/", "self", ".", "num_replicas", ")", ")", "\n", "self", ".", "total_size", "=", "self", ".", "num_samples", "*", "self", ".", "num_replicas", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed.DistributedSampler.__iter__": [[42, 61], ["iter", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator.manual_seed", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.arange().tolist", "torch.arange().tolist", "torch.arange().tolist", "torch.arange().tolist", "len", "len", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "# deterministically shuffle based on epoch", "\n", "            ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "epoch", ")", "\n", "indices", "=", "torch", ".", "randperm", "(", "len", "(", "self", ".", "dataset", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "indices", "=", "torch", ".", "arange", "(", "len", "(", "self", ".", "dataset", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "# add extra samples to make it evenly divisible", "\n", "", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "\n", "# subsample", "\n", "offset", "=", "self", ".", "num_samples", "*", "self", ".", "rank", "\n", "indices", "=", "indices", "[", "offset", ":", "offset", "+", "self", ".", "num_samples", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "\n", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed.DistributedSampler.__len__": [[62, 64], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed.DistributedSampler.set_epoch": [[65, 67], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.grouped_batch_sampler.GroupedBatchSampler.__init__": [[24, 39], ["torch.as_tensor", "isinstance", "ValueError", "grouped_batch_sampler.GroupedBatchSampler.group_ids.dim", "torch.unique().sort", "torch.unique"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sampler", ",", "group_ids", ",", "batch_size", ",", "drop_uneven", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "sampler", ",", "Sampler", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"sampler should be an instance of \"", "\n", "\"torch.utils.data.Sampler, but got sampler={}\"", ".", "format", "(", "sampler", ")", "\n", ")", "\n", "", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "group_ids", "=", "torch", ".", "as_tensor", "(", "group_ids", ")", "\n", "assert", "self", ".", "group_ids", ".", "dim", "(", ")", "==", "1", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "drop_uneven", "=", "drop_uneven", "\n", "\n", "self", ".", "groups", "=", "torch", ".", "unique", "(", "self", ".", "group_ids", ")", ".", "sort", "(", "0", ")", "[", "0", "]", "\n", "\n", "self", ".", "_can_reuse_batches", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.grouped_batch_sampler.GroupedBatchSampler._prepare_batches": [[40, 101], ["len", "torch.as_tensor", "torch.full", "torch.arange", "tuple", "torch.as_tensor", "[].tolist", "list", "len", "c.split", "itertools.chain.from_iterable", "t[].item", "merged[].tolist", "enumerate", "torch.as_tensor.tolist", "torch.as_tensor.sort", "len", "kept.append", "s.sort"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "_prepare_batches", "(", "self", ")", ":", "\n", "        ", "dataset_size", "=", "len", "(", "self", ".", "group_ids", ")", "\n", "# get the sampled indices from the sampler", "\n", "sampled_ids", "=", "torch", ".", "as_tensor", "(", "list", "(", "self", ".", "sampler", ")", ")", "\n", "# potentially not all elements of the dataset were sampled", "\n", "# by the sampler (e.g., DistributedSampler).", "\n", "# construct a tensor which contains -1 if the element was", "\n", "# not sampled, and a non-negative number indicating the", "\n", "# order where the element was sampled.", "\n", "# for example. if sampled_ids = [3, 1] and dataset_size = 5,", "\n", "# the order is [-1, 1, -1, 0, -1]", "\n", "order", "=", "torch", ".", "full", "(", "(", "dataset_size", ",", ")", ",", "-", "1", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "order", "[", "sampled_ids", "]", "=", "torch", ".", "arange", "(", "len", "(", "sampled_ids", ")", ")", "\n", "\n", "# get a mask with the elements that were sampled", "\n", "mask", "=", "order", ">=", "0", "\n", "\n", "# find the elements that belong to each individual cluster", "\n", "clusters", "=", "[", "(", "self", ".", "group_ids", "==", "i", ")", "&", "mask", "for", "i", "in", "self", ".", "groups", "]", "\n", "# get relative order of the elements inside each cluster", "\n", "# that follows the order from the sampler", "\n", "relative_order", "=", "[", "order", "[", "cluster", "]", "for", "cluster", "in", "clusters", "]", "\n", "# with the relative order, find the absolute order in the", "\n", "# sampled space", "\n", "permutation_ids", "=", "[", "s", "[", "s", ".", "sort", "(", ")", "[", "1", "]", "]", "for", "s", "in", "relative_order", "]", "\n", "# permute each cluster so that they follow the order from", "\n", "# the sampler", "\n", "permuted_clusters", "=", "[", "sampled_ids", "[", "idx", "]", "for", "idx", "in", "permutation_ids", "]", "\n", "\n", "# splits each cluster in batch_size, and merge as a list of tensors", "\n", "splits", "=", "[", "c", ".", "split", "(", "self", ".", "batch_size", ")", "for", "c", "in", "permuted_clusters", "]", "\n", "merged", "=", "tuple", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "splits", ")", ")", "\n", "\n", "# now each batch internally has the right order, but", "\n", "# they are grouped by clusters. Find the permutation between", "\n", "# different batches that brings them as close as possible to", "\n", "# the order that we have in the sampler. For that, we will consider the", "\n", "# ordering as coming from the first element of each batch, and sort", "\n", "# correspondingly", "\n", "first_element_of_batch", "=", "[", "t", "[", "0", "]", ".", "item", "(", ")", "for", "t", "in", "merged", "]", "\n", "# get and inverse mapping from sampled indices and the position where", "\n", "# they occur (as returned by the sampler)", "\n", "inv_sampled_ids_map", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "enumerate", "(", "sampled_ids", ".", "tolist", "(", ")", ")", "}", "\n", "# from the first element in each batch, get a relative ordering", "\n", "first_index_of_batch", "=", "torch", ".", "as_tensor", "(", "\n", "[", "inv_sampled_ids_map", "[", "s", "]", "for", "s", "in", "first_element_of_batch", "]", "\n", ")", "\n", "\n", "# permute the batches so that they approximately follow the order", "\n", "# from the sampler", "\n", "permutation_order", "=", "first_index_of_batch", ".", "sort", "(", "0", ")", "[", "1", "]", ".", "tolist", "(", ")", "\n", "# finally, permute the batches", "\n", "batches", "=", "[", "merged", "[", "i", "]", ".", "tolist", "(", ")", "for", "i", "in", "permutation_order", "]", "\n", "\n", "if", "self", ".", "drop_uneven", ":", "\n", "            ", "kept", "=", "[", "]", "\n", "for", "batch", "in", "batches", ":", "\n", "                ", "if", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                    ", "kept", ".", "append", "(", "batch", ")", "\n", "", "", "batches", "=", "kept", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.grouped_batch_sampler.GroupedBatchSampler.__iter__": [[102, 110], ["iter", "grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_can_reuse_batches", ":", "\n", "            ", "batches", "=", "self", ".", "_batches", "\n", "self", ".", "_can_reuse_batches", "=", "False", "\n", "", "else", ":", "\n", "            ", "batches", "=", "self", ".", "_prepare_batches", "(", ")", "\n", "", "self", ".", "_batches", "=", "batches", "\n", "return", "iter", "(", "batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.grouped_batch_sampler.GroupedBatchSampler.__len__": [[111, 116], ["len", "hasattr", "grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"_batches\"", ")", ":", "\n", "            ", "self", ".", "_batches", "=", "self", ".", "_prepare_batches", "(", ")", "\n", "self", ".", "_can_reuse_batches", "=", "True", "\n", "", "return", "len", "(", "self", ".", "_batches", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.iteration_based_batch_sampler.IterationBasedBatchSampler.__init__": [[11, 15], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_sampler", ",", "num_iterations", ",", "start_iter", "=", "0", ")", ":", "\n", "        ", "self", ".", "batch_sampler", "=", "batch_sampler", "\n", "self", ".", "num_iterations", "=", "num_iterations", "\n", "self", ".", "start_iter", "=", "start_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.iteration_based_batch_sampler.IterationBasedBatchSampler.__iter__": [[16, 29], ["hasattr", "iteration_based_batch_sampler.IterationBasedBatchSampler.batch_sampler.sampler.set_epoch"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed.DistributedSampler.set_epoch"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "iteration", "=", "self", ".", "start_iter", "\n", "while", "iteration", "<=", "self", ".", "num_iterations", ":", "\n", "# if the underlying sampler has a set_epoch method, like", "\n", "# DistributedSampler, used for making each process see", "\n", "# a different split of the dataset, then set it", "\n", "            ", "if", "hasattr", "(", "self", ".", "batch_sampler", ".", "sampler", ",", "\"set_epoch\"", ")", ":", "\n", "                ", "self", ".", "batch_sampler", ".", "sampler", ".", "set_epoch", "(", "iteration", ")", "\n", "", "for", "batch", "in", "self", ".", "batch_sampler", ":", "\n", "                ", "iteration", "+=", "1", "\n", "if", "iteration", ">", "self", ".", "num_iterations", ":", "\n", "                    ", "break", "\n", "", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.iteration_based_batch_sampler.IterationBasedBatchSampler.__len__": [[30, 32], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_iterations", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.TrainingSampler.__init__": [[24, 42], ["int", "detectron2.utils.comm.get_rank", "detectron2.utils.comm.get_world_size", "detectron2.utils.comm.shared_random_seed"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.shared_random_seed"], ["def", "__init__", "(", "self", ",", "size", ":", "int", ",", "shuffle", ":", "bool", "=", "True", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            size (int): the total number of data of the underlying dataset to sample from\n            shuffle (bool): whether to shuffle the indices or not\n            seed (int): the initial seed of the shuffle. Must be the same\n                across all workers. If None, will use a random seed shared\n                among workers (require synchronization among all workers).\n        \"\"\"", "\n", "self", ".", "_size", "=", "size", "\n", "assert", "size", ">", "0", "\n", "self", ".", "_shuffle", "=", "shuffle", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "comm", ".", "shared_random_seed", "(", ")", "\n", "", "self", ".", "_seed", "=", "int", "(", "seed", ")", "\n", "\n", "self", ".", "_rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.TrainingSampler.__iter__": [[43, 46], ["itertools.islice", "distributed_sampler.TrainingSampler._infinite_indices"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler._infinite_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "start", "=", "self", ".", "_rank", "\n", "yield", "from", "itertools", ".", "islice", "(", "self", ".", "_infinite_indices", "(", ")", ",", "start", ",", "None", ",", "self", ".", "_world_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.TrainingSampler._infinite_indices": [[47, 55], ["torch.Generator", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.arange().tolist", "torch.randperm", "torch.arange"], "methods", ["None"], ["", "def", "_infinite_indices", "(", "self", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "_seed", ")", "\n", "while", "True", ":", "\n", "            ", "if", "self", ".", "_shuffle", ":", "\n", "                ", "yield", "from", "torch", ".", "randperm", "(", "self", ".", "_size", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "yield", "from", "torch", ".", "arange", "(", "self", ".", "_size", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler.__init__": [[63, 84], ["int", "detectron2.utils.comm.get_rank", "detectron2.utils.comm.get_world_size", "torch.trunc", "detectron2.utils.comm.shared_random_seed"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.shared_random_seed"], ["def", "__init__", "(", "self", ",", "repeat_factors", ",", "*", ",", "shuffle", "=", "True", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            repeat_factors (Tensor): a float vector, the repeat factor for each indice. When it's\n                full of ones, it is equivalent to ``TrainingSampler(len(repeat_factors), ...)``.\n            shuffle (bool): whether to shuffle the indices or not\n            seed (int): the initial seed of the shuffle. Must be the same\n                across all workers. If None, will use a random seed shared\n                among workers (require synchronization among all workers).\n        \"\"\"", "\n", "self", ".", "_shuffle", "=", "shuffle", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "comm", ".", "shared_random_seed", "(", ")", "\n", "", "self", ".", "_seed", "=", "int", "(", "seed", ")", "\n", "\n", "self", ".", "_rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "\n", "# Split into whole number (_int_part) and fractional (_frac_part) parts.", "\n", "self", ".", "_int_part", "=", "torch", ".", "trunc", "(", "repeat_factors", ")", "\n", "self", ".", "_frac_part", "=", "repeat_factors", "-", "self", ".", "_int_part", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency": [[85, 131], ["collections.defaultdict", "len", "collections.defaultdict.items", "torch.tensor", "max", "max", "rep_factors.append", "math.sqrt", "collections.defaultdict.items"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "repeat_factors_from_category_frequency", "(", "dataset_dicts", ",", "repeat_thresh", ")", ":", "\n", "        ", "\"\"\"\n        Compute (fractional) per-image repeat factors based on category frequency.\n        The repeat factor for an image is a function of the frequency of the rarest\n        category labeled in that image. The \"frequency of category c\" in [0, 1] is defined\n        as the fraction of images in the training set (without repeats) in which category c\n        appears.\n        See :paper:`lvis` (>= v2) Appendix B.2.\n\n        Args:\n            dataset_dicts (list[dict]): annotations in Detectron2 dataset format.\n            repeat_thresh (float): frequency threshold below which data is repeated.\n                If the frequency is half of `repeat_thresh`, the image will be\n                repeated twice.\n\n        Returns:\n            torch.Tensor:\n                the i-th element is the repeat factor for the dataset image at index i.\n        \"\"\"", "\n", "# 1. For each category c, compute the fraction of images that contain it: f(c)", "\n", "category_freq", "=", "defaultdict", "(", "int", ")", "\n", "for", "dataset_dict", "in", "dataset_dicts", ":", "# For each image (without repeats)", "\n", "            ", "cat_ids", "=", "{", "ann", "[", "\"category_id\"", "]", "for", "ann", "in", "dataset_dict", "[", "\"annotations\"", "]", "}", "\n", "for", "cat_id", "in", "cat_ids", ":", "\n", "                ", "category_freq", "[", "cat_id", "]", "+=", "1", "\n", "", "", "num_images", "=", "len", "(", "dataset_dicts", ")", "\n", "for", "k", ",", "v", "in", "category_freq", ".", "items", "(", ")", ":", "\n", "            ", "category_freq", "[", "k", "]", "=", "v", "/", "num_images", "\n", "\n", "# 2. For each category c, compute the category-level repeat factor:", "\n", "#    r(c) = max(1, sqrt(t / f(c)))", "\n", "", "category_rep", "=", "{", "\n", "cat_id", ":", "max", "(", "1.0", ",", "math", ".", "sqrt", "(", "repeat_thresh", "/", "cat_freq", ")", ")", "\n", "for", "cat_id", ",", "cat_freq", "in", "category_freq", ".", "items", "(", ")", "\n", "}", "\n", "\n", "# 3. For each image I, compute the image-level repeat factor:", "\n", "#    r(I) = max_{c in I} r(c)", "\n", "rep_factors", "=", "[", "]", "\n", "for", "dataset_dict", "in", "dataset_dicts", ":", "\n", "            ", "cat_ids", "=", "{", "ann", "[", "\"category_id\"", "]", "for", "ann", "in", "dataset_dict", "[", "\"annotations\"", "]", "}", "\n", "rep_factor", "=", "max", "(", "{", "category_rep", "[", "cat_id", "]", "for", "cat_id", "in", "cat_ids", "}", ",", "default", "=", "1.0", ")", "\n", "rep_factors", ".", "append", "(", "rep_factor", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "rep_factors", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler._get_epoch_indices": [[132, 154], ["torch.rand", "enumerate", "torch.tensor", "len", "indices.extend", "int", "rep_factor.item"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "_get_epoch_indices", "(", "self", ",", "generator", ")", ":", "\n", "        ", "\"\"\"\n        Create a list of dataset indices (with repeats) to use for one epoch.\n\n        Args:\n            generator (torch.Generator): pseudo random number generator used for\n                stochastic rounding.\n\n        Returns:\n            torch.Tensor: list of dataset indices to use in one epoch. Each index\n                is repeated based on its calculated repeat factor.\n        \"\"\"", "\n", "# Since repeat factors are fractional, we use stochastic rounding so", "\n", "# that the target repeat factor is achieved in expectation over the", "\n", "# course of training", "\n", "rands", "=", "torch", ".", "rand", "(", "len", "(", "self", ".", "_frac_part", ")", ",", "generator", "=", "generator", ")", "\n", "rep_factors", "=", "self", ".", "_int_part", "+", "(", "rands", "<", "self", ".", "_frac_part", ")", ".", "float", "(", ")", "\n", "# Construct a list of indices in which we repeat images as specified", "\n", "indices", "=", "[", "]", "\n", "for", "dataset_index", ",", "rep_factor", "in", "enumerate", "(", "rep_factors", ")", ":", "\n", "            ", "indices", ".", "extend", "(", "[", "dataset_index", "]", "*", "int", "(", "rep_factor", ".", "item", "(", ")", ")", ")", "\n", "", "return", "torch", ".", "tensor", "(", "indices", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler.__iter__": [[155, 158], ["itertools.islice", "distributed_sampler.RepeatFactorTrainingSampler._infinite_indices"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler._infinite_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "start", "=", "self", ".", "_rank", "\n", "yield", "from", "itertools", ".", "islice", "(", "self", ".", "_infinite_indices", "(", ")", ",", "start", ",", "None", ",", "self", ".", "_world_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler._infinite_indices": [[159, 171], ["torch.Generator", "torch.Generator.manual_seed", "distributed_sampler.RepeatFactorTrainingSampler._get_epoch_indices", "torch.randperm", "len", "indices[].tolist", "distributed_sampler.RepeatFactorTrainingSampler.tolist"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.RepeatFactorTrainingSampler._get_epoch_indices"], ["", "def", "_infinite_indices", "(", "self", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "_seed", ")", "\n", "while", "True", ":", "\n", "# Sample indices with repeats determined by stochastic rounding; each", "\n", "# \"epoch\" may have a slightly different size due to the rounding.", "\n", "            ", "indices", "=", "self", ".", "_get_epoch_indices", "(", "g", ")", "\n", "if", "self", ".", "_shuffle", ":", "\n", "                ", "randperm", "=", "torch", ".", "randperm", "(", "len", "(", "indices", ")", ",", "generator", "=", "g", ")", "\n", "yield", "from", "indices", "[", "randperm", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "yield", "from", "indices", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.InferenceSampler.__init__": [[181, 195], ["detectron2.utils.comm.get_rank", "detectron2.utils.comm.get_world_size", "min", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size"], ["def", "__init__", "(", "self", ",", "size", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            size (int): the total number of data of the underlying dataset to sample from\n        \"\"\"", "\n", "self", ".", "_size", "=", "size", "\n", "assert", "size", ">", "0", "\n", "self", ".", "_rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "\n", "shard_size", "=", "(", "self", ".", "_size", "-", "1", ")", "//", "self", ".", "_world_size", "+", "1", "\n", "begin", "=", "shard_size", "*", "self", ".", "_rank", "\n", "end", "=", "min", "(", "shard_size", "*", "(", "self", ".", "_rank", "+", "1", ")", ",", "self", ".", "_size", ")", "\n", "self", ".", "_local_indices", "=", "range", "(", "begin", ",", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.InferenceSampler.__iter__": [[196, 198], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "_local_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.distributed_sampler.InferenceSampler.__len__": [[199, 201], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_local_indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_confidence_based.DensePoseConfidenceBasedSampler.__init__": [[18, 54], ["densepose_base.DensePoseBaseSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "confidence_channel", ":", "str", ",", "\n", "count_per_class", ":", "int", "=", "8", ",", "\n", "search_count_multiplier", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "search_proportion", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Constructor\n\n        Args:\n          confidence_channel (str): confidence channel to use for sampling;\n            possible values:\n              \"sigma_2\": confidences for UV values\n              \"fine_segm_confidence\": confidences for fine segmentation\n              \"coarse_segm_confidence\": confidences for coarse segmentation\n            (default: \"sigma_2\")\n          count_per_class (int): the sampler produces at most `count_per_class`\n              samples for each category (default: 8)\n          search_count_multiplier (float or None): if not None, the total number\n              of the most confident estimates of a given class to consider is\n              defined as `min(search_count_multiplier * count_per_class, N)`,\n              where `N` is the total number of estimates of the class; cannot be\n              specified together with `search_proportion` (default: None)\n          search_proportion (float or None): if not None, the total number of the\n              of the most confident estimates of a given class to consider is\n              defined as `min(max(search_proportion * N, count_per_class), N)`,\n              where `N` is the total number of estimates of the class; cannot be\n              specified together with `search_count_multiplier` (default: None)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "count_per_class", ")", "\n", "self", ".", "confidence_channel", "=", "confidence_channel", "\n", "self", ".", "search_count_multiplier", "=", "search_count_multiplier", "\n", "self", ".", "search_proportion", "=", "search_proportion", "\n", "assert", "(", "search_count_multiplier", "is", "None", ")", "or", "(", "search_proportion", "is", "None", ")", ",", "(", "\n", "f\"Cannot specify both search_count_multiplier (={search_count_multiplier})\"", "\n", "f\"and search_proportion (={search_proportion})\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_confidence_based.DensePoseConfidenceBasedSampler._produce_index_sample": [[57, 88], ["list", "torch.sort", "random.sample", "range", "min", "range", "int", "min", "min", "max", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "_produce_index_sample", "(", "self", ",", "values", ":", "torch", ".", "Tensor", ",", "count", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Produce a sample of indices to select data based on confidences\n\n        Args:\n            values (torch.Tensor): an array of size [n, k] that contains\n                estimated values (U, V, confidences);\n                n: number of channels (U, V, confidences)\n                k: number of points labeled with part_id\n            count (int): number of samples to produce, should be positive and <= k\n\n        Return:\n            list(int): indices of values (along axis 1) selected as a sample\n        \"\"\"", "\n", "k", "=", "values", ".", "shape", "[", "1", "]", "\n", "if", "k", "==", "count", ":", "\n", "            ", "index_sample", "=", "list", "(", "range", "(", "k", ")", ")", "\n", "", "else", ":", "\n", "# take the best count * search_count_multiplier pixels,", "\n", "# sample from them uniformly", "\n", "# (here best = smallest variance)", "\n", "            ", "_", ",", "sorted_confidence_indices", "=", "torch", ".", "sort", "(", "values", "[", "2", "]", ")", "\n", "if", "self", ".", "search_count_multiplier", "is", "not", "None", ":", "\n", "                ", "search_count", "=", "min", "(", "int", "(", "count", "*", "self", ".", "search_count_multiplier", ")", ",", "k", ")", "# pyre-ignore[58]", "\n", "", "elif", "self", ".", "search_proportion", "is", "not", "None", ":", "\n", "                ", "search_count", "=", "min", "(", "max", "(", "int", "(", "k", "*", "self", ".", "search_proportion", ")", ",", "count", ")", ",", "k", ")", "\n", "", "else", ":", "\n", "                ", "search_count", "=", "min", "(", "count", ",", "k", ")", "\n", "", "sample_from_top", "=", "random", ".", "sample", "(", "range", "(", "search_count", ")", ",", "count", ")", "\n", "index_sample", "=", "sorted_confidence_indices", "[", ":", "search_count", "]", "[", "sample_from_top", "]", "\n", "", "return", "index_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_confidence_based.DensePoseConfidenceBasedSampler._produce_labels_and_results": [[89, 109], ["converter.convert", "torch.cat", "converter.convert.labels.cpu", "converter.convert.uv.cpu", "[].cpu", "getattr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "_produce_labels_and_results", "(", "self", ",", "instance", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Method to get labels and DensePose results from an instance, with confidences\n\n        Args:\n            instance (Instances): an instance of `DensePoseChartPredictorOutputWithConfidences`\n\n        Return:\n            labels (torch.Tensor): shape [H, W], DensePose segmentation labels\n            dp_result (torch.Tensor): shape [3, H, W], DensePose results u and v\n                stacked with the confidence channel\n        \"\"\"", "\n", "converter", "=", "ToChartResultConverterWithConfidences", "\n", "chart_result", "=", "converter", ".", "convert", "(", "instance", ".", "pred_densepose", ",", "instance", ".", "pred_boxes", ")", "\n", "labels", ",", "dp_result", "=", "chart_result", ".", "labels", ".", "cpu", "(", ")", ",", "chart_result", ".", "uv", ".", "cpu", "(", ")", "\n", "dp_result", "=", "torch", ".", "cat", "(", "\n", "(", "dp_result", ",", "getattr", "(", "chart_result", ",", "self", ".", "confidence_channel", ")", "[", "None", "]", ".", "cpu", "(", ")", ")", "\n", ")", "\n", "\n", "return", "labels", ",", "dp_result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.mask_from_densepose.MaskFromDensePoseSampler.__call__": [[15, 28], ["densepose.converters.ToMaskConverter.convert"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["def", "__call__", "(", "self", ",", "instances", ":", "Instances", ")", "->", "BitMasks", ":", "\n", "        ", "\"\"\"\n        Converts predicted data from `instances` into the GT mask data\n\n        Args:\n            instances (Instances): predicted results, expected to have `pred_densepose` field\n\n        Returns:\n            Boolean Tensor of the size of the input image that has non-zero\n            values at pixels that are estimated to belong to the detected object\n        \"\"\"", "\n", "return", "ToMaskConverter", ".", "convert", "(", "\n", "instances", ".", "pred_densepose", ",", "instances", ".", "pred_boxes", ",", "instances", ".", "image_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler.__init__": [[21, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "count_per_class", ":", "int", "=", "8", ")", ":", "\n", "        ", "\"\"\"\n        Constructor\n\n        Args:\n          count_per_class (int): the sampler produces at most `count_per_class`\n              samples for each category\n        \"\"\"", "\n", "self", ".", "count_per_class", "=", "count_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler.__call__": [[31, 48], ["instances.pred_boxes.tensor.clone().cpu", "detectron2.structures.BoxMode.convert", "range", "densepose.structures.DensePoseList", "len", "densepose_base.DensePoseBaseSampler._sample", "densepose_base.DensePoseBaseSampler._resample_mask", "dp_datas.append", "instances.pred_boxes.tensor.clone", "densepose.converters.base.make_int_box", "densepose.structures.DensePoseDataRelative"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._resample_mask", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.make_int_box"], ["", "def", "__call__", "(", "self", ",", "instances", ":", "Instances", ")", "->", "DensePoseList", ":", "\n", "        ", "\"\"\"\n        Convert DensePose predictions (an instance of `DensePoseChartPredictorOutput`)\n        into DensePose annotations data (an instance of `DensePoseList`)\n        \"\"\"", "\n", "boxes_xyxy_abs", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "clone", "(", ")", ".", "cpu", "(", ")", "\n", "boxes_xywh_abs", "=", "BoxMode", ".", "convert", "(", "boxes_xyxy_abs", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "dp_datas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "boxes_xywh_abs", ")", ")", ":", "\n", "            ", "annotation_i", "=", "self", ".", "_sample", "(", "instances", "[", "i", "]", ",", "make_int_box", "(", "boxes_xywh_abs", "[", "i", "]", ")", ")", "\n", "annotation_i", "[", "DensePoseDataRelative", ".", "S_KEY", "]", "=", "self", ".", "_resample_mask", "(", "# pyre-ignore[6]", "\n", "instances", "[", "i", "]", ".", "pred_densepose", "\n", ")", "\n", "dp_datas", ".", "append", "(", "DensePoseDataRelative", "(", "annotation_i", ")", ")", "\n", "# create densepose annotations on CPU", "\n", "", "dp_list", "=", "DensePoseList", "(", "dp_datas", ",", "boxes_xyxy_abs", ",", "instances", ".", "image_size", ")", "\n", "return", "dp_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._sample": [[49, 94], ["densepose_base.DensePoseBaseSampler._produce_labels_and_results", "range", "torch.nonzero", "dp_result[].view", "min", "densepose_base.DensePoseBaseSampler._produce_index_sample", "sampled_values[].clamp().cpu().tolist", "sampled_values[].clamp().cpu().tolist", "annotation[].extend", "annotation[].extend", "annotation[].extend", "annotation[].extend", "annotation[].extend", "labels.expand", "sampled_values[].clamp().cpu", "sampled_values[].clamp().cpu", "sampled_values[].clamp", "sampled_values[].clamp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._produce_labels_and_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_uniform.DensePoseUniformSampler._produce_index_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "_sample", "(", "self", ",", "instance", ":", "Instances", ",", "bbox_xywh", ":", "IntTupleBox", ")", "->", "Dict", "[", "str", ",", "List", "[", "Any", "]", "]", ":", "\n", "        ", "\"\"\"\n        Sample DensPoseDataRelative from estimation results\n        \"\"\"", "\n", "labels", ",", "dp_result", "=", "self", ".", "_produce_labels_and_results", "(", "instance", ")", "\n", "annotation", "=", "{", "\n", "DensePoseDataRelative", ".", "X_KEY", ":", "[", "]", ",", "\n", "DensePoseDataRelative", ".", "Y_KEY", ":", "[", "]", ",", "\n", "DensePoseDataRelative", ".", "U_KEY", ":", "[", "]", ",", "\n", "DensePoseDataRelative", ".", "V_KEY", ":", "[", "]", ",", "\n", "DensePoseDataRelative", ".", "I_KEY", ":", "[", "]", ",", "\n", "}", "\n", "x0", ",", "y0", ",", "_", ",", "_", "=", "bbox_xywh", "\n", "n", ",", "h", ",", "w", "=", "dp_result", ".", "shape", "\n", "for", "part_id", "in", "range", "(", "1", ",", "DensePoseDataRelative", ".", "N_PART_LABELS", "+", "1", ")", ":", "\n", "# indices - tuple of 3 1D tensors of size k", "\n", "# 0: index along the first dimension N", "\n", "# 1: index along H dimension", "\n", "# 2: index along W dimension", "\n", "            ", "indices", "=", "torch", ".", "nonzero", "(", "labels", ".", "expand", "(", "n", ",", "h", ",", "w", ")", "==", "part_id", ",", "as_tuple", "=", "True", ")", "\n", "# values - an array of size [n, k]", "\n", "# n: number of channels (U, V, confidences)", "\n", "# k: number of points labeled with part_id", "\n", "values", "=", "dp_result", "[", "indices", "]", ".", "view", "(", "n", ",", "-", "1", ")", "\n", "k", "=", "values", ".", "shape", "[", "1", "]", "\n", "count", "=", "min", "(", "self", ".", "count_per_class", ",", "k", ")", "\n", "if", "count", "<=", "0", ":", "\n", "                ", "continue", "\n", "", "index_sample", "=", "self", ".", "_produce_index_sample", "(", "values", ",", "count", ")", "\n", "sampled_values", "=", "values", "[", ":", ",", "index_sample", "]", "\n", "sampled_y", "=", "indices", "[", "1", "]", "[", "index_sample", "]", "+", "0.5", "\n", "sampled_x", "=", "indices", "[", "2", "]", "[", "index_sample", "]", "+", "0.5", "\n", "# prepare / normalize data", "\n", "x", "=", "(", "sampled_x", "/", "w", "*", "256.0", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "y", "=", "(", "sampled_y", "/", "h", "*", "256.0", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "u", "=", "sampled_values", "[", "0", "]", ".", "clamp", "(", "0", ",", "1", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "v", "=", "sampled_values", "[", "1", "]", ".", "clamp", "(", "0", ",", "1", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "fine_segm_labels", "=", "[", "part_id", "]", "*", "count", "\n", "# extend annotations", "\n", "annotation", "[", "DensePoseDataRelative", ".", "X_KEY", "]", ".", "extend", "(", "x", ")", "\n", "annotation", "[", "DensePoseDataRelative", ".", "Y_KEY", "]", ".", "extend", "(", "y", ")", "\n", "annotation", "[", "DensePoseDataRelative", ".", "U_KEY", "]", ".", "extend", "(", "u", ")", "\n", "annotation", "[", "DensePoseDataRelative", ".", "V_KEY", "]", ".", "extend", "(", "v", ")", "\n", "annotation", "[", "DensePoseDataRelative", ".", "I_KEY", "]", ".", "extend", "(", "fine_segm_labels", ")", "\n", "", "return", "annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._produce_index_sample": [[95, 111], ["None"], "methods", ["None"], ["", "def", "_produce_index_sample", "(", "self", ",", "values", ":", "torch", ".", "Tensor", ",", "count", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Abstract method to produce a sample of indices to select data\n        To be implemented in descendants\n\n        Args:\n            values (torch.Tensor): an array of size [n, k] that contains\n                estimated values (U, V, confidences);\n                n: number of channels (U, V, confidences)\n                k: number of points labeled with part_id\n            count (int): number of samples to produce, should be positive and <= k\n\n        Return:\n            list(int): indices of values (along axis 1) selected as a sample\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._produce_labels_and_results": [[112, 127], ["converter.convert", "converter.convert.labels.cpu", "converter.convert.uv.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "_produce_labels_and_results", "(", "self", ",", "instance", ":", "Instances", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Method to get labels and DensePose results from an instance\n\n        Args:\n            instance (Instances): an instance of `DensePoseChartPredictorOutput`\n\n        Return:\n            labels (torch.Tensor): shape [H, W], DensePose segmentation labels\n            dp_result (torch.Tensor): shape [2, H, W], stacked DensePose results u and v\n        \"\"\"", "\n", "converter", "=", "ToChartResultConverter", "\n", "chart_result", "=", "converter", ".", "convert", "(", "instance", ".", "pred_densepose", ",", "instance", ".", "pred_boxes", ")", "\n", "labels", ",", "dp_result", "=", "chart_result", ".", "labels", ".", "cpu", "(", ")", ",", "chart_result", ".", "uv", ".", "cpu", "(", ")", "\n", "return", "labels", ",", "dp_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_base.DensePoseBaseSampler._resample_mask": [[128, 202], ["torch.nn.functional.interpolate().argmax().long", "torch.zeros", "range", "torch.nn.functional.interpolate().argmax", "torch.device", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate().argmax", "torch.nn.functional.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "_resample_mask", "(", "self", ",", "output", ":", "Any", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Convert DensePose predictor output to segmentation annotation - tensors of size\n        (256, 256) and type `int64`.\n\n        Args:\n            output: DensePose predictor output with the following attributes:\n             - coarse_segm: tensor of size [N, D, H, W] with unnormalized coarse\n               segmentation scores\n             - fine_segm: tensor of size [N, C, H, W] with unnormalized fine\n               segmentation scores\n        Return:\n            Tensor of size (S, S) and type `int64` with coarse segmentation annotations,\n            where S = DensePoseDataRelative.MASK_SIZE\n        \"\"\"", "\n", "sz", "=", "DensePoseDataRelative", ".", "MASK_SIZE", "\n", "S", "=", "(", "\n", "F", ".", "interpolate", "(", "output", ".", "coarse_segm", ",", "(", "sz", ",", "sz", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", ".", "argmax", "(", "dim", "=", "1", ")", "\n", ".", "long", "(", ")", "\n", ")", "\n", "I", "=", "(", "\n", "(", "\n", "F", ".", "interpolate", "(", "\n", "output", ".", "fine_segm", ",", "(", "sz", ",", "sz", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "*", "(", "S", ">", "0", ")", ".", "long", "(", ")", "\n", ")", "\n", ".", "squeeze", "(", ")", "\n", ".", "cpu", "(", ")", "\n", ")", "\n", "# Map fine segmentation results to coarse segmentation ground truth", "\n", "# TODO: extract this into separate classes", "\n", "# coarse segmentation: 1 = Torso, 2 = Right Hand, 3 = Left Hand,", "\n", "# 4 = Left Foot, 5 = Right Foot, 6 = Upper Leg Right, 7 = Upper Leg Left,", "\n", "# 8 = Lower Leg Right, 9 = Lower Leg Left, 10 = Upper Arm Left,", "\n", "# 11 = Upper Arm Right, 12 = Lower Arm Left, 13 = Lower Arm Right,", "\n", "# 14 = Head", "\n", "# fine segmentation: 1, 2 = Torso, 3 = Right Hand, 4 = Left Hand,", "\n", "# 5 = Left Foot, 6 = Right Foot, 7, 9 = Upper Leg Right,", "\n", "# 8, 10 = Upper Leg Left, 11, 13 = Lower Leg Right,", "\n", "# 12, 14 = Lower Leg Left, 15, 17 = Upper Arm Left,", "\n", "# 16, 18 = Upper Arm Right, 19, 21 = Lower Arm Left,", "\n", "# 20, 22 = Lower Arm Right, 23, 24 = Head", "\n", "FINE_TO_COARSE_SEGMENTATION", "=", "{", "\n", "1", ":", "1", ",", "\n", "2", ":", "1", ",", "\n", "3", ":", "2", ",", "\n", "4", ":", "3", ",", "\n", "5", ":", "4", ",", "\n", "6", ":", "5", ",", "\n", "7", ":", "6", ",", "\n", "8", ":", "7", ",", "\n", "9", ":", "6", ",", "\n", "10", ":", "7", ",", "\n", "11", ":", "8", ",", "\n", "12", ":", "9", ",", "\n", "13", ":", "8", ",", "\n", "14", ":", "9", ",", "\n", "15", ":", "10", ",", "\n", "16", ":", "11", ",", "\n", "17", ":", "10", ",", "\n", "18", ":", "11", ",", "\n", "19", ":", "12", ",", "\n", "20", ":", "13", ",", "\n", "21", ":", "12", ",", "\n", "22", ":", "13", ",", "\n", "23", ":", "14", ",", "\n", "24", ":", "14", ",", "\n", "}", "\n", "mask", "=", "torch", ".", "zeros", "(", "(", "sz", ",", "sz", ")", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "for", "i", "in", "range", "(", "DensePoseDataRelative", ".", "N_PART_LABELS", ")", ":", "\n", "            ", "mask", "[", "I", "==", "i", "+", "1", "]", "=", "FINE_TO_COARSE_SEGMENTATION", "[", "i", "+", "1", "]", "\n", "", "return", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.__init__": [[33, 40], ["prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "prediction_to_gt.PredictionToGroundTruthSampler.register_sampler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler"], ["def", "__init__", "(", "self", ",", "dataset_name", ":", "str", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "_samplers", "=", "{", "}", "\n", "self", ".", "register_sampler", "(", "\"pred_boxes\"", ",", "\"gt_boxes\"", ",", "None", ")", "\n", "self", ".", "register_sampler", "(", "\"pred_classes\"", ",", "\"gt_classes\"", ",", "None", ")", "\n", "# delete scores", "\n", "self", ".", "register_sampler", "(", "\"scores\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.__call__": [[41, 66], ["prediction_to_gt.PredictionToGroundTruthSampler._samplers.items", "prediction_to_gt.PredictionToGroundTruthSampler._samplers.items", "instances.set", "instances.set", "instances.has", "instances.remove", "instances.has", "instances.get", "sampler.func"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "__call__", "(", "self", ",", "model_output", ":", "List", "[", "ModelOutput", "]", ")", "->", "List", "[", "SampledData", "]", ":", "\n", "        ", "\"\"\"\n        Transform model output into ground truth data through sampling\n\n        Args:\n          model_output (Dict[str, Any]): model output\n        Returns:\n          Dict[str, Any]: sampled data\n        \"\"\"", "\n", "for", "model_output_i", "in", "model_output", ":", "\n", "            ", "instances", ":", "Instances", "=", "model_output_i", "[", "\"instances\"", "]", "\n", "# transform data in each field", "\n", "for", "_", ",", "sampler", "in", "self", ".", "_samplers", ".", "items", "(", ")", ":", "\n", "                ", "if", "not", "instances", ".", "has", "(", "sampler", ".", "src", ")", "or", "sampler", ".", "dst", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "if", "sampler", ".", "func", "is", "None", ":", "\n", "                    ", "instances", ".", "set", "(", "sampler", ".", "dst", ",", "instances", ".", "get", "(", "sampler", ".", "src", ")", ")", "\n", "", "else", ":", "\n", "                    ", "instances", ".", "set", "(", "sampler", ".", "dst", ",", "sampler", ".", "func", "(", "instances", ")", ")", "\n", "# delete model output data that was transformed", "\n", "", "", "for", "_", ",", "sampler", "in", "self", ".", "_samplers", ".", "items", "(", ")", ":", "\n", "                ", "if", "sampler", ".", "src", "!=", "sampler", ".", "dst", "and", "instances", ".", "has", "(", "sampler", ".", "src", ")", ":", "\n", "                    ", "instances", ".", "remove", "(", "sampler", ".", "src", ")", "\n", "", "", "model_output_i", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.prediction_to_gt.PredictionToGroundTruthSampler.register_sampler": [[67, 83], ["prediction_to_gt._Sampler"], "methods", ["None"], ["", "def", "register_sampler", "(", "\n", "self", ",", "\n", "prediction_attr", ":", "str", ",", "\n", "gt_attr", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "func", ":", "Optional", "[", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Register sampler for a field\n\n        Args:\n          prediction_attr (str): field to replace with a sampled value\n          gt_attr (Optional[str]): field to store the sampled value to, if not None\n          func (Optional[Callable: Any -> Any]): sampler function\n        \"\"\"", "\n", "self", ".", "_samplers", "[", "(", "prediction_attr", ",", "gt_attr", ")", "]", "=", "_Sampler", "(", "\n", "src", "=", "prediction_attr", ",", "dst", "=", "gt_attr", ",", "func", "=", "func", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_uniform.DensePoseUniformSampler.__init__": [[16, 25], ["densepose_base.DensePoseBaseSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "count_per_class", ":", "int", "=", "8", ")", ":", "\n", "        ", "\"\"\"\n        Constructor\n\n        Args:\n          count_per_class (int): the sampler produces at most `count_per_class`\n              samples for each category\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "count_per_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.samplers.densepose_uniform.DensePoseUniformSampler._produce_index_sample": [[26, 42], ["random.sample", "range"], "methods", ["None"], ["", "def", "_produce_index_sample", "(", "self", ",", "values", ":", "torch", ".", "Tensor", ",", "count", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Produce a uniform sample of indices to select data\n\n        Args:\n            values (torch.Tensor): an array of size [n, k] that contains\n                estimated values (U, V, confidences);\n                n: number of channels (U, V, confidences)\n                k: number of points labeled with part_id\n            count (int): number of samples to produce, should be positive and <= k\n\n        Return:\n            list(int): indices of values (along axis 1) selected as a sample\n        \"\"\"", "\n", "k", "=", "values", ".", "shape", "[", "1", "]", "\n", "return", "random", ".", "sample", "(", "range", "(", "k", ")", ",", "count", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Compose.__init__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Compose.__call__": [[13, 17], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "target", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "image", ",", "target", "=", "t", "(", "image", ",", "target", ")", "\n", "", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Compose.__repr__": [[18, 25], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "\"\\n\"", "\n", "format_string", "+=", "\"    {0}\"", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "\"\\n)\"", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Resize.__init__": [[28, 33], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "min_size", ",", "max_size", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "min_size", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "min_size", "=", "(", "min_size", ",", ")", "\n", "", "self", ".", "min_size", "=", "min_size", "\n", "self", ".", "max_size", "=", "max_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Resize.get_size": [[35, 56], ["random.choice", "float", "float", "int", "int", "min", "max", "int", "round"], "methods", ["None"], ["", "def", "get_size", "(", "self", ",", "image_size", ")", ":", "\n", "        ", "w", ",", "h", "=", "image_size", "\n", "size", "=", "random", ".", "choice", "(", "self", ".", "min_size", ")", "\n", "max_size", "=", "self", ".", "max_size", "\n", "if", "max_size", "is", "not", "None", ":", "\n", "            ", "min_original_size", "=", "float", "(", "min", "(", "(", "w", ",", "h", ")", ")", ")", "\n", "max_original_size", "=", "float", "(", "max", "(", "(", "w", ",", "h", ")", ")", ")", "\n", "if", "max_original_size", "/", "min_original_size", "*", "size", ">", "max_size", ":", "\n", "                ", "size", "=", "int", "(", "round", "(", "max_size", "*", "min_original_size", "/", "max_original_size", ")", ")", "\n", "\n", "", "", "if", "(", "w", "<=", "h", "and", "w", "==", "size", ")", "or", "(", "h", "<=", "w", "and", "h", "==", "size", ")", ":", "\n", "            ", "return", "(", "h", ",", "w", ")", "\n", "\n", "", "if", "w", "<", "h", ":", "\n", "            ", "ow", "=", "size", "\n", "oh", "=", "int", "(", "size", "*", "h", "/", "w", ")", "\n", "", "else", ":", "\n", "            ", "oh", "=", "size", "\n", "ow", "=", "int", "(", "size", "*", "w", "/", "h", ")", "\n", "\n", "", "return", "(", "oh", ",", "ow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Resize.__call__": [[57, 67], ["transforms.Resize.get_size", "torchvision.transforms.functional.resize", "isinstance", "t.resize", "target.resize.resize.resize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Resize.get_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize"], ["", "def", "__call__", "(", "self", ",", "image", ",", "target", "=", "None", ")", ":", "\n", "        ", "size", "=", "self", ".", "get_size", "(", "image", ".", "size", ")", "\n", "image", "=", "F", ".", "resize", "(", "image", ",", "size", ")", "\n", "if", "target", "is", "None", ":", "\n", "            ", "return", "image", "\n", "", "target", "=", "target", ".", "resize", "(", "image", ".", "size", ")", "\n", "return", "image", ",", "target", "\n", "\n", "\n", "", "", "class", "RandomHorizontalFlip", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "prob", "=", "0.5", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.RandomHorizontalFlip.__init__": [[70, 72], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "target", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "prob", ":", "\n", "            ", "image", "=", "F", ".", "hflip", "(", "image", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.RandomHorizontalFlip.__call__": [[73, 78], ["random.random", "torchvision.transforms.functional.hflip", "target.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["target", "=", "target", ".", "transpose", "(", "0", ")", "\n", "", "return", "image", ",", "target", "\n", "\n", "", "", "class", "RandomVerticalFlip", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "prob", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.RandomVerticalFlip.__init__": [[77, 79], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.RandomVerticalFlip.__call__": [[80, 85], ["random.random", "torchvision.transforms.functional.vflip", "target.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["", "def", "__call__", "(", "self", ",", "image", ",", "target", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "prob", ":", "\n", "            ", "image", "=", "F", ".", "vflip", "(", "image", ")", "\n", "target", "=", "target", ".", "transpose", "(", "1", ")", "\n", "", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.ColorJitter.__init__": [[87, 98], ["torchvision.transforms.ColorJitter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "brightness", "=", "None", ",", "\n", "contrast", "=", "None", ",", "\n", "saturation", "=", "None", ",", "\n", "hue", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "color_jitter", "=", "torchvision", ".", "transforms", ".", "ColorJitter", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.ColorJitter.__call__": [[99, 102], ["transforms.ColorJitter.color_jitter"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "target", ")", ":", "\n", "        ", "image", "=", "self", ".", "color_jitter", "(", "image", ")", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.ToTensor.__call__": [[81, 83], ["torchvision.transforms.functional.to_tensor"], "methods", ["None"], ["        ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "prob", ":", "\n", "            ", "image", "=", "F", ".", "vflip", "(", "image", ")", "\n", "target", "=", "target", ".", "transpose", "(", "1", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Normalize.__init__": [[86, 90], ["None"], "methods", ["None"], ["", "", "class", "ColorJitter", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "\n", "brightness", "=", "None", ",", "\n", "contrast", "=", "None", ",", "\n", "saturation", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transforms.Normalize.__call__": [[91, 98], ["torchvision.transforms.functional.normalize"], "methods", ["None"], ["hue", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "color_jitter", "=", "torchvision", ".", "transforms", ".", "ColorJitter", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.build.build_transforms": [[6, 42], ["transforms.Normalize", "transforms.Compose", "transforms.Resize", "transforms.RandomHorizontalFlip", "transforms.ToTensor", "list", "fcos_core.augmentations.scale_aware_aug.SA_Aug", "len", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["import", "torch", ".", "utils", ".", "data", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "comm", "import", "get_world_size", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "imports", "import", "import_file", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "miscellaneous", "import", "save_labels", "\n", "\n", "from", ".", "import", "datasets", "as", "D", "\n", "from", ".", "import", "samplers", "\n", "\n", "from", ".", "collate_batch", "import", "BatchCollator", ",", "BBoxAugCollator", "\n", "from", ".", "transforms", "import", "build_transforms", "\n", "\n", "\n", "def", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "dataset_catalog", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        dataset_list (list[str]): Contains the names of the datasets, i.e.,\n            coco_2014_train, coco_2014_val, etc\n        transforms (callable): transforms to apply to each (image, target) sample\n        dataset_catalog (DatasetCatalog): contains the information on how to\n            construct a dataset.\n        is_train (bool): whether to setup the dataset for training or testing\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "dataset_list", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"dataset_list should be a list of strings, got {}\"", ".", "format", "(", "dataset_list", ")", "\n", ")", "\n", "", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "dataset_list", ":", "\n", "        ", "data", "=", "dataset_catalog", ".", "get", "(", "dataset_name", ")", "\n", "factory", "=", "getattr", "(", "D", ",", "data", "[", "\"factory\"", "]", ")", "\n", "args", "=", "data", "[", "\"args\"", "]", "\n", "# for COCODataset, we want to remove images without annotations", "\n", "# during training", "\n", "if", "data", "[", "\"factory\"", "]", "==", "\"COCODataset\"", ":", "\n", "            ", "args", "[", "\"remove_images_without_annotations\"", "]", "=", "is_train", "\n", "", "if", "data", "[", "\"factory\"", "]", "==", "\"PascalVOCDataset\"", ":", "\n", "            ", "args", "[", "\"use_difficult\"", "]", "=", "not", "is_train", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomApply.__init__": [[41, 54], ["augmentation.Augmentation.__init__", "augmentation._transform_to_aug"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._transform_to_aug"], ["def", "__init__", "(", "self", ",", "tfm_or_aug", ",", "prob", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tfm_or_aug (Transform, Augmentation): the transform or augmentation\n                to be applied. It can either be a `Transform` or `Augmentation`\n                instance.\n            prob (float): probability between 0.0 and 1.0 that\n                the wrapper transformation is applied\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "aug", "=", "_transform_to_aug", "(", "tfm_or_aug", ")", "\n", "assert", "0.0", "<=", "prob", "<=", "1.0", ",", "f\"Probablity must be between 0.0 and 1.0 (given: {prob})\"", "\n", "self", ".", "prob", "=", "prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomApply.get_transform": [[55, 61], ["augmentation_impl.RandomApply._rand_range", "augmentation_impl.RandomApply.aug.get_transform", "fvcore.transforms.transform.NoOpTransform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._rand_range", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.get_transform"], ["", "def", "get_transform", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "do", "=", "self", ".", "_rand_range", "(", ")", "<", "self", ".", "prob", "\n", "if", "do", ":", "\n", "            ", "return", "self", ".", "aug", ".", "get_transform", "(", "*", "args", ")", "\n", "", "else", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomApply.__call__": [[62, 68], ["augmentation_impl.RandomApply._rand_range", "augmentation_impl.RandomApply.aug", "fvcore.transforms.transform.NoOpTransform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._rand_range"], ["", "", "def", "__call__", "(", "self", ",", "aug_input", ")", ":", "\n", "        ", "do", "=", "self", ".", "_rand_range", "(", ")", "<", "self", ".", "prob", "\n", "if", "do", ":", "\n", "            ", "return", "self", ".", "aug", "(", "aug_input", ")", "\n", "", "else", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomFlip.__init__": [[75, 89], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomFlip._init", "ValueError", "ValueError", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "prob", "=", "0.5", ",", "*", ",", "horizontal", "=", "True", ",", "vertical", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prob (float): probability of flip.\n            horizontal (boolean): whether to apply horizontal flipping\n            vertical (boolean): whether to apply vertical flipping\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "horizontal", "and", "vertical", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot do both horiz and vert. Please use two Flip instead.\"", ")", "\n", "", "if", "not", "horizontal", "and", "not", "vertical", ":", "\n", "            ", "raise", "ValueError", "(", "\"At least one of horiz or vert has to be True!\"", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomFlip.get_transform": [[90, 100], ["augmentation_impl.RandomFlip._rand_range", "fvcore.transforms.transform.NoOpTransform", "fvcore.transforms.transform.HFlipTransform", "fvcore.transforms.transform.VFlipTransform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._rand_range"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "do", "=", "self", ".", "_rand_range", "(", ")", "<", "self", ".", "prob", "\n", "if", "do", ":", "\n", "            ", "if", "self", ".", "horizontal", ":", "\n", "                ", "return", "HFlipTransform", "(", "w", ")", "\n", "", "elif", "self", ".", "vertical", ":", "\n", "                ", "return", "VFlipTransform", "(", "h", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.Resize.__init__": [[105, 115], ["isinstance", "tuple", "augmentation_impl.Resize._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "shape", ",", "interp", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            shape: (h, w) tuple or a int\n            interp: PIL interpolation method\n        \"\"\"", "\n", "if", "isinstance", "(", "shape", ",", "int", ")", ":", "\n", "            ", "shape", "=", "(", "shape", ",", "shape", ")", "\n", "", "shape", "=", "tuple", "(", "shape", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.Resize.get_transform": [[116, 119], ["transform.ResizeTransform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "return", "ResizeTransform", "(", "\n", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "self", ".", "shape", "[", "0", "]", ",", "self", ".", "shape", "[", "1", "]", ",", "self", ".", "interp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.ResizeShortestEdge.__init__": [[128, 151], ["augmentation.Augmentation.__init__", "isinstance", "augmentation_impl.ResizeShortestEdge._init", "locals", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "\n", "self", ",", "short_edge_length", ",", "max_size", "=", "sys", ".", "maxsize", ",", "sample_style", "=", "\"range\"", ",", "interp", "=", "Image", ".", "BILINEAR", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            short_edge_length (list[int]): If ``sample_style==\"range\"``,\n                a [min, max] interval from which to sample the shortest edge length.\n                If ``sample_style==\"choice\"``, a list of shortest edge lengths to sample from.\n            max_size (int): maximum allowed longest edge length.\n            sample_style (str): either \"range\" or \"choice\".\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "sample_style", "in", "[", "\"range\"", ",", "\"choice\"", "]", ",", "sample_style", "\n", "\n", "self", ".", "is_range", "=", "sample_style", "==", "\"range\"", "\n", "if", "isinstance", "(", "short_edge_length", ",", "int", ")", ":", "\n", "            ", "short_edge_length", "=", "(", "short_edge_length", ",", "short_edge_length", ")", "\n", "", "if", "self", ".", "is_range", ":", "\n", "            ", "assert", "len", "(", "short_edge_length", ")", "==", "2", ",", "(", "\n", "\"short_edge_length must be two values using 'range' sample style.\"", "\n", "f\" Got {short_edge_length}!\"", "\n", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.ResizeShortestEdge.get_transform": [[152, 173], ["int", "int", "transform.ResizeTransform", "numpy.random.randint", "numpy.random.choice", "fvcore.transforms.transform.NoOpTransform", "min", "max", "max"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "if", "self", ".", "is_range", ":", "\n", "            ", "size", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "short_edge_length", "[", "0", "]", ",", "self", ".", "short_edge_length", "[", "1", "]", "+", "1", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "short_edge_length", ")", "\n", "", "if", "size", "==", "0", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n", "", "scale", "=", "size", "*", "1.0", "/", "min", "(", "h", ",", "w", ")", "\n", "if", "h", "<", "w", ":", "\n", "            ", "newh", ",", "neww", "=", "size", ",", "scale", "*", "w", "\n", "", "else", ":", "\n", "            ", "newh", ",", "neww", "=", "scale", "*", "h", ",", "size", "\n", "", "if", "max", "(", "newh", ",", "neww", ")", ">", "self", ".", "max_size", ":", "\n", "            ", "scale", "=", "self", ".", "max_size", "*", "1.0", "/", "max", "(", "newh", ",", "neww", ")", "\n", "newh", "=", "newh", "*", "scale", "\n", "neww", "=", "neww", "*", "scale", "\n", "", "neww", "=", "int", "(", "neww", "+", "0.5", ")", "\n", "newh", "=", "int", "(", "newh", "+", "0.5", ")", "\n", "return", "ResizeTransform", "(", "h", ",", "w", ",", "newh", ",", "neww", ",", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomRotation.__init__": [[181, 204], ["augmentation.Augmentation.__init__", "isinstance", "augmentation_impl.RandomRotation._init", "isinstance", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "angle", ",", "expand", "=", "True", ",", "center", "=", "None", ",", "sample_style", "=", "\"range\"", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            angle (list[float]): If ``sample_style==\"range\"``,\n                a [min, max] interval from which to sample the angle (in degrees).\n                If ``sample_style==\"choice\"``, a list of angles to sample from\n            expand (bool): choose if the image should be resized to fit the whole\n                rotated image (default), or simply cropped\n            center (list[[float, float]]):  If ``sample_style==\"range\"``,\n                a [[minx, miny], [maxx, maxy]] relative interval from which to sample the center,\n                [0, 0] being the top left of the image and [1, 1] the bottom right.\n                If ``sample_style==\"choice\"``, a list of centers to sample from\n                Default: None, which means that the center of rotation is the center of the image\n                center has no effect if expand=True because it only affects shifting\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "sample_style", "in", "[", "\"range\"", ",", "\"choice\"", "]", ",", "sample_style", "\n", "self", ".", "is_range", "=", "sample_style", "==", "\"range\"", "\n", "if", "isinstance", "(", "angle", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "angle", "=", "(", "angle", ",", "angle", ")", "\n", "", "if", "center", "is", "not", "None", "and", "isinstance", "(", "center", "[", "0", "]", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "center", "=", "(", "center", ",", "center", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomRotation.get_transform": [[205, 227], ["transform.RotationTransform", "numpy.random.uniform", "numpy.random.choice", "fvcore.transforms.transform.NoOpTransform", "numpy.random.choice", "numpy.random.uniform", "numpy.random.uniform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "center", "=", "None", "\n", "if", "self", ".", "is_range", ":", "\n", "            ", "angle", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "angle", "[", "0", "]", ",", "self", ".", "angle", "[", "1", "]", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "                ", "center", "=", "(", "\n", "np", ".", "random", ".", "uniform", "(", "self", ".", "center", "[", "0", "]", "[", "0", "]", ",", "self", ".", "center", "[", "1", "]", "[", "0", "]", ")", ",", "\n", "np", ".", "random", ".", "uniform", "(", "self", ".", "center", "[", "0", "]", "[", "1", "]", ",", "self", ".", "center", "[", "1", "]", "[", "1", "]", ")", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "angle", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "angle", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "                ", "center", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "center", ")", "\n", "\n", "", "", "if", "center", "is", "not", "None", ":", "\n", "            ", "center", "=", "(", "w", "*", "center", "[", "0", "]", ",", "h", "*", "center", "[", "1", "]", ")", "# Convert to absolute coordinates", "\n", "\n", "", "if", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n", "", "return", "RotationTransform", "(", "h", ",", "w", ",", "angle", ",", "expand", "=", "self", ".", "expand", ",", "center", "=", "center", ",", "interp", "=", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop.__init__": [[234, 255], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomCrop._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "crop_type", ":", "str", ",", "crop_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            crop_type (str): one of \"relative_range\", \"relative\", \"absolute\", \"absolute_range\".\n            crop_size (tuple[float, float]): two floats, explained below.\n\n        - \"relative\": crop a (H * crop_size[0], W * crop_size[1]) region from an input image of\n          size (H, W). crop size should be in (0, 1]\n        - \"relative_range\": uniformly sample two values from [crop_size[0], 1]\n          and [crop_size[1]], 1], and use them as in \"relative\" crop type.\n        - \"absolute\" crop a (crop_size[0], crop_size[1]) region from input image.\n          crop_size must be smaller than the input image size.\n        - \"absolute_range\", for an input of size (H, W), uniformly sample H_crop in\n          [crop_size[0], min(H, crop_size[1])] and W_crop in [crop_size[0], min(W, crop_size[1])].\n          Then crop a region (H_crop, W_crop).\n        \"\"\"", "\n", "# TODO style of relative_range and absolute_range are not consistent:", "\n", "# one takes (h, w) but another takes (min, max)", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "crop_type", "in", "[", "\"relative_range\"", ",", "\"relative\"", ",", "\"absolute\"", ",", "\"absolute_range\"", "]", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop.get_transform": [[256, 263], ["augmentation_impl.RandomCrop.get_crop_size", "numpy.random.randint", "numpy.random.randint", "fvcore.transforms.transform.CropTransform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop.get_crop_size"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "croph", ",", "cropw", "=", "self", ".", "get_crop_size", "(", "(", "h", ",", "w", ")", ")", "\n", "assert", "h", ">=", "croph", "and", "w", ">=", "cropw", ",", "\"Shape computation in {} has bugs.\"", ".", "format", "(", "self", ")", "\n", "h0", "=", "np", ".", "random", ".", "randint", "(", "h", "-", "croph", "+", "1", ")", "\n", "w0", "=", "np", ".", "random", ".", "randint", "(", "w", "-", "cropw", "+", "1", ")", "\n", "return", "CropTransform", "(", "w0", ",", "h0", ",", "cropw", ",", "croph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop.get_crop_size": [[264, 289], ["int", "int", "numpy.asarray", "int", "int", "numpy.random.rand", "min", "min", "numpy.random.randint", "numpy.random.randint", "NotImplementedError", "min", "min", "min", "min"], "methods", ["None"], ["", "def", "get_crop_size", "(", "self", ",", "image_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_size (tuple): height, width\n\n        Returns:\n            crop_size (tuple): height, width in absolute pixels\n        \"\"\"", "\n", "h", ",", "w", "=", "image_size", "\n", "if", "self", ".", "crop_type", "==", "\"relative\"", ":", "\n", "            ", "ch", ",", "cw", "=", "self", ".", "crop_size", "\n", "return", "int", "(", "h", "*", "ch", "+", "0.5", ")", ",", "int", "(", "w", "*", "cw", "+", "0.5", ")", "\n", "", "elif", "self", ".", "crop_type", "==", "\"relative_range\"", ":", "\n", "            ", "crop_size", "=", "np", ".", "asarray", "(", "self", ".", "crop_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ch", ",", "cw", "=", "crop_size", "+", "np", ".", "random", ".", "rand", "(", "2", ")", "*", "(", "1", "-", "crop_size", ")", "\n", "return", "int", "(", "h", "*", "ch", "+", "0.5", ")", ",", "int", "(", "w", "*", "cw", "+", "0.5", ")", "\n", "", "elif", "self", ".", "crop_type", "==", "\"absolute\"", ":", "\n", "            ", "return", "(", "min", "(", "self", ".", "crop_size", "[", "0", "]", ",", "h", ")", ",", "min", "(", "self", ".", "crop_size", "[", "1", "]", ",", "w", ")", ")", "\n", "", "elif", "self", ".", "crop_type", "==", "\"absolute_range\"", ":", "\n", "            ", "assert", "self", ".", "crop_size", "[", "0", "]", "<=", "self", ".", "crop_size", "[", "1", "]", "\n", "ch", "=", "np", ".", "random", ".", "randint", "(", "min", "(", "h", ",", "self", ".", "crop_size", "[", "0", "]", ")", ",", "min", "(", "h", ",", "self", ".", "crop_size", "[", "1", "]", ")", "+", "1", ")", "\n", "cw", "=", "np", ".", "random", ".", "randint", "(", "min", "(", "w", ",", "self", ".", "crop_size", "[", "0", "]", ")", ",", "min", "(", "w", ",", "self", ".", "crop_size", "[", "1", "]", ")", "+", "1", ")", "\n", "return", "ch", ",", "cw", "\n", "", "else", ":", "\n", "            ", "NotImplementedError", "(", "\"Unknown crop type {}\"", ".", "format", "(", "self", ".", "crop_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop_CategoryAreaConstraint.__init__": [[299, 317], ["augmentation_impl.RandomCrop", "augmentation_impl.RandomCrop_CategoryAreaConstraint._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "\n", "self", ",", "\n", "crop_type", ":", "str", ",", "\n", "crop_size", ",", "\n", "single_category_max_area", ":", "float", "=", "1.0", ",", "\n", "ignored_category", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            crop_type, crop_size: same as in :class:`RandomCrop`\n            single_category_max_area: the maximum allowed area ratio of a\n                category. Set to 1.0 to disable\n            ignored_category: allow this category in the semantic segmentation\n                ground truth to exceed the area ratio. Usually set to the category\n                that's ignored in training.\n        \"\"\"", "\n", "self", ".", "crop_aug", "=", "RandomCrop", "(", "crop_type", ",", "crop_size", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop_CategoryAreaConstraint.get_transform": [[318, 335], ["augmentation_impl.RandomCrop_CategoryAreaConstraint.crop_aug.get_transform", "range", "fvcore.transforms.transform.CropTransform", "augmentation_impl.RandomCrop_CategoryAreaConstraint.crop_aug.get_crop_size", "numpy.random.randint", "numpy.random.randint", "numpy.unique", "len", "numpy.max", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.get_transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomCrop.get_crop_size"], ["", "def", "get_transform", "(", "self", ",", "image", ",", "sem_seg", ")", ":", "\n", "        ", "if", "self", ".", "single_category_max_area", ">=", "1.0", ":", "\n", "            ", "return", "self", ".", "crop_aug", ".", "get_transform", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "w", "=", "sem_seg", ".", "shape", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "crop_size", "=", "self", ".", "crop_aug", ".", "get_crop_size", "(", "(", "h", ",", "w", ")", ")", "\n", "y0", "=", "np", ".", "random", ".", "randint", "(", "h", "-", "crop_size", "[", "0", "]", "+", "1", ")", "\n", "x0", "=", "np", ".", "random", ".", "randint", "(", "w", "-", "crop_size", "[", "1", "]", "+", "1", ")", "\n", "sem_seg_temp", "=", "sem_seg", "[", "y0", ":", "y0", "+", "crop_size", "[", "0", "]", ",", "x0", ":", "x0", "+", "crop_size", "[", "1", "]", "]", "\n", "labels", ",", "cnt", "=", "np", ".", "unique", "(", "sem_seg_temp", ",", "return_counts", "=", "True", ")", "\n", "if", "self", ".", "ignored_category", "is", "not", "None", ":", "\n", "                    ", "cnt", "=", "cnt", "[", "labels", "!=", "self", ".", "ignored_category", "]", "\n", "", "if", "len", "(", "cnt", ")", ">", "1", "and", "np", ".", "max", "(", "cnt", ")", "<", "np", ".", "sum", "(", "cnt", ")", "*", "self", ".", "single_category_max_area", ":", "\n", "                    ", "break", "\n", "", "", "crop_tfm", "=", "CropTransform", "(", "x0", ",", "y0", ",", "crop_size", "[", "1", "]", ",", "crop_size", "[", "0", "]", ")", "\n", "return", "crop_tfm", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomExtent.__init__": [[346, 358], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomExtent._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "scale_range", ",", "shift_range", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (h, w): Dimensions of output image\n            scale_range (l, h): Range of input-to-output size scaling factor\n            shift_range (x, y): Range of shifts of the cropped subrect. The rect\n                is shifted by [w / 2 * Uniform(-x, x), h / 2 * Uniform(-y, y)],\n                where (w, h) is the (width, height) of the input image. Set each\n                component to zero to crop at the image's center.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomExtent.get_transform": [[359, 379], ["numpy.array", "numpy.random.uniform", "transform.ExtentTransform", "numpy.random.rand", "numpy.random.rand", "int", "int"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "img_h", ",", "img_w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Initialize src_rect to fit the input image.", "\n", "src_rect", "=", "np", ".", "array", "(", "[", "-", "0.5", "*", "img_w", ",", "-", "0.5", "*", "img_h", ",", "0.5", "*", "img_w", ",", "0.5", "*", "img_h", "]", ")", "\n", "\n", "# Apply a random scaling to the src_rect.", "\n", "src_rect", "*=", "np", ".", "random", ".", "uniform", "(", "self", ".", "scale_range", "[", "0", "]", ",", "self", ".", "scale_range", "[", "1", "]", ")", "\n", "\n", "# Apply a random shift to the coordinates origin.", "\n", "src_rect", "[", "0", ":", ":", "2", "]", "+=", "self", ".", "shift_range", "[", "0", "]", "*", "img_w", "*", "(", "np", ".", "random", ".", "rand", "(", ")", "-", "0.5", ")", "\n", "src_rect", "[", "1", ":", ":", "2", "]", "+=", "self", ".", "shift_range", "[", "1", "]", "*", "img_h", "*", "(", "np", ".", "random", ".", "rand", "(", ")", "-", "0.5", ")", "\n", "\n", "# Map src_rect coordinates into image coordinates (center at corner).", "\n", "src_rect", "[", "0", ":", ":", "2", "]", "+=", "0.5", "*", "img_w", "\n", "src_rect", "[", "1", ":", ":", "2", "]", "+=", "0.5", "*", "img_h", "\n", "\n", "return", "ExtentTransform", "(", "\n", "src_rect", "=", "(", "src_rect", "[", "0", "]", ",", "src_rect", "[", "1", "]", ",", "src_rect", "[", "2", "]", ",", "src_rect", "[", "3", "]", ")", ",", "\n", "output_size", "=", "(", "int", "(", "src_rect", "[", "3", "]", "-", "src_rect", "[", "1", "]", ")", ",", "int", "(", "src_rect", "[", "2", "]", "-", "src_rect", "[", "0", "]", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomContrast.__init__": [[394, 402], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomContrast._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "intensity_min", ",", "intensity_max", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            intensity_min (float): Minimum augmentation\n            intensity_max (float): Maximum augmentation\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomContrast.get_transform": [[403, 406], ["numpy.random.uniform", "fvcore.transforms.transform.BlendTransform", "image.mean"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "w", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "intensity_min", ",", "self", ".", "intensity_max", ")", "\n", "return", "BlendTransform", "(", "src_image", "=", "image", ".", "mean", "(", ")", ",", "src_weight", "=", "1", "-", "w", ",", "dst_weight", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomBrightness.__init__": [[420, 428], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomBrightness._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "intensity_min", ",", "intensity_max", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            intensity_min (float): Minimum augmentation\n            intensity_max (float): Maximum augmentation\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomBrightness.get_transform": [[429, 432], ["numpy.random.uniform", "fvcore.transforms.transform.BlendTransform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "w", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "intensity_min", ",", "self", ".", "intensity_max", ")", "\n", "return", "BlendTransform", "(", "src_image", "=", "0", ",", "src_weight", "=", "1", "-", "w", ",", "dst_weight", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomSaturation.__init__": [[447, 455], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomSaturation._init", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "intensity_min", ",", "intensity_max", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            intensity_min (float): Minimum augmentation (1 preserves input).\n            intensity_max (float): Maximum augmentation (1 preserves input).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomSaturation.get_transform": [[456, 461], ["numpy.random.uniform", "fvcore.transforms.transform.BlendTransform", "image.dot"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "assert", "image", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "\"RandomSaturation only works on RGB images\"", "\n", "w", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "intensity_min", ",", "self", ".", "intensity_max", ")", "\n", "grayscale", "=", "image", ".", "dot", "(", "[", "0.299", ",", "0.587", ",", "0.114", "]", ")", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "return", "BlendTransform", "(", "src_image", "=", "grayscale", ",", "src_weight", "=", "1", "-", "w", ",", "dst_weight", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomLighting.__init__": [[472, 483], ["augmentation.Augmentation.__init__", "augmentation_impl.RandomLighting._init", "numpy.array", "numpy.array", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init"], ["def", "__init__", "(", "self", ",", "scale", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            scale (float): Standard deviation of principal component weighting.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "self", ".", "eigen_vecs", "=", "np", ".", "array", "(", "\n", "[", "[", "-", "0.5675", ",", "0.7192", ",", "0.4009", "]", ",", "[", "-", "0.5808", ",", "-", "0.0045", ",", "-", "0.8140", "]", ",", "[", "-", "0.5836", ",", "-", "0.6948", ",", "0.4203", "]", "]", "\n", ")", "\n", "self", ".", "eigen_vals", "=", "np", ".", "array", "(", "[", "0.2175", ",", "0.0188", ",", "0.0045", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation_impl.RandomLighting.get_transform": [[484, 489], ["numpy.random.normal", "fvcore.transforms.transform.BlendTransform", "augmentation_impl.RandomLighting.eigen_vecs.dot"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "assert", "image", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "\"RandomLighting only works on RGB images\"", "\n", "weights", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "self", ".", "scale", ",", "size", "=", "3", ")", "\n", "return", "BlendTransform", "(", "\n", "src_image", "=", "self", ".", "eigen_vecs", ".", "dot", "(", "weights", "*", "self", ".", "eigen_vals", ")", ",", "src_weight", "=", "1.0", ",", "dst_weight", "=", "1.0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ExtentTransform.__init__": [[46, 56], ["fvcore.transforms.transform.Transform.__init__", "transform.ExtentTransform._set_attributes", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "src_rect", ",", "output_size", ",", "interp", "=", "Image", ".", "LINEAR", ",", "fill", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_rect (x0, y0, x1, y1): src coordinates\n            output_size (h, w): dst image size\n            interp: PIL interpolation methods\n            fill: Fill color used when src_rect extends outside image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ExtentTransform.apply_image": [[57, 74], ["PIL.Image.fromarray.transform", "numpy.asarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "numpy.expand_dims", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "h", ",", "w", "=", "self", ".", "output_size", "\n", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "            ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", "[", ":", ",", ":", ",", "0", "]", ",", "mode", "=", "\"L\"", ")", "\n", "", "else", ":", "\n", "            ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "", "pil_image", "=", "pil_image", ".", "transform", "(", "\n", "size", "=", "(", "w", ",", "h", ")", ",", "\n", "method", "=", "Image", ".", "EXTENT", ",", "\n", "data", "=", "self", ".", "src_rect", ",", "\n", "resample", "=", "interp", "if", "interp", "else", "self", ".", "interp", ",", "\n", "fill", "=", "self", ".", "fill", ",", "\n", ")", "\n", "ret", "=", "np", ".", "asarray", "(", "pil_image", ")", "\n", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "            ", "ret", "=", "np", ".", "expand_dims", "(", "ret", ",", "-", "1", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ExtentTransform.apply_coords": [[75, 88], ["coords.astype"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "# Transform image center from source coordinates into output coordinates", "\n", "# and then map the new origin to the corner of the output image.", "\n", "        ", "h", ",", "w", "=", "self", ".", "output_size", "\n", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "self", ".", "src_rect", "\n", "new_coords", "=", "coords", ".", "astype", "(", "np", ".", "float32", ")", "\n", "new_coords", "[", ":", ",", "0", "]", "-=", "0.5", "*", "(", "x0", "+", "x1", ")", "\n", "new_coords", "[", ":", ",", "1", "]", "-=", "0.5", "*", "(", "y0", "+", "y1", ")", "\n", "new_coords", "[", ":", ",", "0", "]", "*=", "w", "/", "(", "x1", "-", "x0", ")", "\n", "new_coords", "[", ":", ",", "1", "]", "*=", "h", "/", "(", "y1", "-", "y0", ")", "\n", "new_coords", "[", ":", ",", "0", "]", "+=", "0.5", "*", "w", "\n", "new_coords", "[", ":", ",", "1", "]", "+=", "0.5", "*", "h", "\n", "return", "new_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ExtentTransform.apply_segmentation": [[89, 92], ["transform.ExtentTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "Image", ".", "NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ResizeTransform.__init__": [[99, 111], ["fvcore.transforms.transform.Transform.__init__", "transform.ResizeTransform._set_attributes", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "h", ",", "w", ",", "new_h", ",", "new_w", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            h, w (int): original image size\n            new_h, new_w (int): new image size\n            interp: PIL interpolation methods, defaults to bilinear.\n        \"\"\"", "\n", "# TODO decide on PIL vs opencv", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "interp", "is", "None", ":", "\n", "            ", "interp", "=", "Image", ".", "BILINEAR", "\n", "", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ResizeTransform.apply_image": [[112, 148], ["len", "PIL.Image.fromarray.resize", "numpy.asarray", "any", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "list", "numpy.ascontiguousarray.view().permute", "torch.interpolate", "torch.interpolate", "numpy.ascontiguousarray.permute().view().numpy", "PIL.Image.fromarray", "PIL.Image.fromarray", "numpy.expand_dims", "numpy.ascontiguousarray", "len", "len", "numpy.ascontiguousarray.view", "numpy.ascontiguousarray.permute().view", "len", "numpy.ascontiguousarray.permute"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "assert", "img", ".", "shape", "[", ":", "2", "]", "==", "(", "self", ".", "h", ",", "self", ".", "w", ")", "\n", "assert", "len", "(", "img", ".", "shape", ")", "<=", "4", "\n", "interp_method", "=", "interp", "if", "interp", "is", "not", "None", "else", "self", ".", "interp", "\n", "\n", "if", "img", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "            ", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "                ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", "[", ":", ",", ":", ",", "0", "]", ",", "mode", "=", "\"L\"", ")", "\n", "", "else", ":", "\n", "                ", "pil_image", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "", "pil_image", "=", "pil_image", ".", "resize", "(", "(", "self", ".", "new_w", ",", "self", ".", "new_h", ")", ",", "interp_method", ")", "\n", "ret", "=", "np", ".", "asarray", "(", "pil_image", ")", "\n", "if", "len", "(", "img", ".", "shape", ")", ">", "2", "and", "img", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "                ", "ret", "=", "np", ".", "expand_dims", "(", "ret", ",", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# PIL only supports uint8", "\n", "            ", "if", "any", "(", "x", "<", "0", "for", "x", "in", "img", ".", "strides", ")", ":", "\n", "                ", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "", "img", "=", "torch", ".", "from_numpy", "(", "img", ")", "\n", "shape", "=", "list", "(", "img", ".", "shape", ")", "\n", "shape_4d", "=", "shape", "[", ":", "2", "]", "+", "[", "1", "]", "*", "(", "4", "-", "len", "(", "shape", ")", ")", "+", "shape", "[", "2", ":", "]", "\n", "img", "=", "img", ".", "view", "(", "shape_4d", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "# hw(c) -> nchw", "\n", "_PIL_RESIZE_TO_INTERPOLATE_MODE", "=", "{", "\n", "Image", ".", "NEAREST", ":", "\"nearest\"", ",", "\n", "Image", ".", "BILINEAR", ":", "\"bilinear\"", ",", "\n", "Image", ".", "BICUBIC", ":", "\"bicubic\"", ",", "\n", "}", "\n", "mode", "=", "_PIL_RESIZE_TO_INTERPOLATE_MODE", "[", "interp_method", "]", "\n", "align_corners", "=", "None", "if", "mode", "==", "\"nearest\"", "else", "False", "\n", "img", "=", "F", ".", "interpolate", "(", "\n", "img", ",", "(", "self", ".", "new_h", ",", "self", ".", "new_w", ")", ",", "mode", "=", "mode", ",", "align_corners", "=", "align_corners", "\n", ")", "\n", "shape", "[", ":", "2", "]", "=", "(", "self", ".", "new_h", ",", "self", ".", "new_w", ")", "\n", "ret", "=", "img", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "view", "(", "shape", ")", ".", "numpy", "(", ")", "# nchw -> hw(c)", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ResizeTransform.apply_coords": [[149, 153], ["None"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "coords", "[", ":", ",", "0", "]", "=", "coords", "[", ":", ",", "0", "]", "*", "(", "self", ".", "new_w", "*", "1.0", "/", "self", ".", "w", ")", "\n", "coords", "[", ":", ",", "1", "]", "=", "coords", "[", ":", ",", "1", "]", "*", "(", "self", ".", "new_h", "*", "1.0", "/", "self", ".", "h", ")", "\n", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ResizeTransform.apply_segmentation": [[154, 157], ["transform.ResizeTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "Image", ".", "NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ResizeTransform.inverse": [[158, 160], ["transform.ResizeTransform"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "return", "ResizeTransform", "(", "self", ".", "new_h", ",", "self", ".", "new_w", ",", "self", ".", "h", ",", "self", ".", "w", ",", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.__init__": [[168, 199], ["fvcore.transforms.transform.Transform.__init__", "numpy.array", "transform.RotationTransform._set_attributes", "transform.RotationTransform.create_rotation_matrix", "transform.RotationTransform.create_rotation_matrix", "abs", "abs", "numpy.rint().astype", "locals", "numpy.cos", "numpy.sin", "numpy.deg2rad", "numpy.deg2rad", "numpy.rint"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.create_rotation_matrix", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.create_rotation_matrix"], ["def", "__init__", "(", "self", ",", "h", ",", "w", ",", "angle", ",", "expand", "=", "True", ",", "center", "=", "None", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            h, w (int): original image size\n            angle (float): degrees for rotation\n            expand (bool): choose if the image should be resized to fit the whole\n                rotated image (default), or simply cropped\n            center (tuple (width, height)): coordinates of the rotation center\n                if left to None, the center will be fit to the center of each image\n                center has no effect if expand=True because it only affects shifting\n            interp: cv2 interpolation method, default cv2.INTER_LINEAR\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "image_center", "=", "np", ".", "array", "(", "(", "w", "/", "2", ",", "h", "/", "2", ")", ")", "\n", "if", "center", "is", "None", ":", "\n", "            ", "center", "=", "image_center", "\n", "", "if", "interp", "is", "None", ":", "\n", "            ", "interp", "=", "cv2", ".", "INTER_LINEAR", "\n", "", "abs_cos", ",", "abs_sin", "=", "(", "abs", "(", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "angle", ")", ")", ")", ",", "abs", "(", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "angle", ")", ")", ")", ")", "\n", "if", "expand", ":", "\n", "# find the new width and height bounds", "\n", "            ", "bound_w", ",", "bound_h", "=", "np", ".", "rint", "(", "\n", "[", "h", "*", "abs_sin", "+", "w", "*", "abs_cos", ",", "h", "*", "abs_cos", "+", "w", "*", "abs_sin", "]", "\n", ")", ".", "astype", "(", "int", ")", "\n", "", "else", ":", "\n", "            ", "bound_w", ",", "bound_h", "=", "w", ",", "h", "\n", "\n", "", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "self", ".", "rm_coords", "=", "self", ".", "create_rotation_matrix", "(", ")", "\n", "# Needed because of this problem https://github.com/opencv/opencv/issues/11784", "\n", "self", ".", "rm_image", "=", "self", ".", "create_rotation_matrix", "(", "offset", "=", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.apply_image": [[200, 209], ["cv2.warpAffine", "len"], "methods", ["None"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        img should be a numpy array, formatted as Height * Width * Nchannels\n        \"\"\"", "\n", "if", "len", "(", "img", ")", "==", "0", "or", "self", ".", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "img", "\n", "", "assert", "img", ".", "shape", "[", ":", "2", "]", "==", "(", "self", ".", "h", ",", "self", ".", "w", ")", "\n", "interp", "=", "interp", "if", "interp", "is", "not", "None", "else", "self", ".", "interp", "\n", "return", "cv2", ".", "warpAffine", "(", "img", ",", "self", ".", "rm_image", ",", "(", "self", ".", "bound_w", ",", "self", ".", "bound_h", ")", ",", "flags", "=", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.apply_coords": [[210, 218], ["numpy.asarray", "cv2.transform", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "\"\"\"\n        coords should be a N * 2 array-like, containing N couples of (x, y) points\n        \"\"\"", "\n", "coords", "=", "np", ".", "asarray", "(", "coords", ",", "dtype", "=", "float", ")", "\n", "if", "len", "(", "coords", ")", "==", "0", "or", "self", ".", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "coords", "\n", "", "return", "cv2", ".", "transform", "(", "coords", "[", ":", ",", "np", ".", "newaxis", ",", ":", "]", ",", "self", ".", "rm_coords", ")", "[", ":", ",", "0", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.apply_segmentation": [[219, 222], ["transform.RotationTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "cv2", ".", "INTER_NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.create_rotation_matrix": [[223, 234], ["cv2.getRotationMatrix2D", "tuple", "cv2.transform", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform"], ["", "def", "create_rotation_matrix", "(", "self", ",", "offset", "=", "0", ")", ":", "\n", "        ", "center", "=", "(", "self", ".", "center", "[", "0", "]", "+", "offset", ",", "self", ".", "center", "[", "1", "]", "+", "offset", ")", "\n", "rm", "=", "cv2", ".", "getRotationMatrix2D", "(", "tuple", "(", "center", ")", ",", "self", ".", "angle", ",", "1", ")", "\n", "if", "self", ".", "expand", ":", "\n", "# Find the coordinates of the center of rotation in the new image", "\n", "# The only point for which we know the future coordinates is the center of the image", "\n", "            ", "rot_im_center", "=", "cv2", ".", "transform", "(", "self", ".", "image_center", "[", "None", ",", "None", ",", ":", "]", "+", "offset", ",", "rm", ")", "[", "0", ",", "0", ",", ":", "]", "\n", "new_center", "=", "np", ".", "array", "(", "[", "self", ".", "bound_w", "/", "2", ",", "self", ".", "bound_h", "/", "2", "]", ")", "+", "offset", "-", "rot_im_center", "\n", "# shift the rotation center to the new coordinates", "\n", "rm", "[", ":", ",", "2", "]", "+=", "new_center", "\n", "", "return", "rm", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.RotationTransform.inverse": [[235, 248], ["transform.RotationTransform", "fvcore.transforms.transform.CropTransform", "fvcore.transforms.transform.TransformList", "NotImplementedError"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The inverse is to rotate it back with expand, and crop to get the original shape.\n        \"\"\"", "\n", "if", "not", "self", ".", "expand", ":", "# Not possible to inverse if a part of the image is lost", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "rotation", "=", "RotationTransform", "(", "\n", "self", ".", "bound_h", ",", "self", ".", "bound_w", ",", "-", "self", ".", "angle", ",", "True", ",", "None", ",", "self", ".", "interp", "\n", ")", "\n", "crop", "=", "CropTransform", "(", "\n", "(", "rotation", ".", "bound_w", "-", "self", ".", "w", ")", "//", "2", ",", "(", "rotation", ".", "bound_h", "-", "self", ".", "h", ")", "//", "2", ",", "self", ".", "w", ",", "self", ".", "h", "\n", ")", "\n", "return", "TransformList", "(", "[", "rotation", ",", "crop", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.__init__": [[258, 268], ["fvcore.transforms.transform.Transform.__init__", "transform.ColorTransform._set_attributes", "callable", "ValueError", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            op (Callable): operation to be applied to the image,\n                which takes in an ndarray and returns an ndarray.\n        \"\"\"", "\n", "if", "not", "callable", "(", "op", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"op parameter should be callable\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.apply_image": [[269, 271], ["transform.ColorTransform.op"], "methods", ["None"], ["", "def", "apply_image", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "self", ".", "op", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.apply_coords": [[272, 274], ["None"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.inverse": [[275, 277], ["fvcore.transforms.transform.NoOpTransform"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "return", "NoOpTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.ColorTransform.apply_segmentation": [[278, 280], ["None"], "methods", ["None"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.PILColorTransform.__init__": [[289, 301], ["transform.ColorTransform.__init__", "callable", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            op (Callable): operation to be applied to the image,\n                which takes in a PIL Image and returns a transformed\n                PIL Image.\n                For reference on possible operations see:\n                - https://pillow.readthedocs.io/en/stable/\n        \"\"\"", "\n", "if", "not", "callable", "(", "op", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"op parameter should be callable\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.PILColorTransform.apply_image": [[302, 305], ["PIL.Image.fromarray", "numpy.asarray", "transform.ColorTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image"], ["", "def", "apply_image", "(", "self", ",", "img", ")", ":", "\n", "        ", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "return", "np", ".", "asarray", "(", "super", "(", ")", ".", "apply_image", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.HFlip_rotated_box": [[307, 321], ["None"], "function", ["None"], ["", "", "def", "HFlip_rotated_box", "(", "transform", ",", "rotated_boxes", ")", ":", "\n", "    ", "\"\"\"\n    Apply the horizontal flip transform on rotated boxes.\n\n    Args:\n        rotated_boxes (ndarray): Nx5 floating point array of\n            (x_center, y_center, width, height, angle_degrees) format\n            in absolute coordinates.\n    \"\"\"", "\n", "# Transform x_center", "\n", "rotated_boxes", "[", ":", ",", "0", "]", "=", "transform", ".", "width", "-", "rotated_boxes", "[", ":", ",", "0", "]", "\n", "# Transform angle", "\n", "rotated_boxes", "[", ":", ",", "4", "]", "=", "-", "rotated_boxes", "[", ":", ",", "4", "]", "\n", "return", "rotated_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.transform.Resize_rotated_box": [[323, 345], ["numpy.cos", "numpy.sin", "numpy.sqrt", "numpy.sqrt", "numpy.square", "numpy.square", "numpy.square", "numpy.square", "numpy.arctan2"], "function", ["None"], ["", "def", "Resize_rotated_box", "(", "transform", ",", "rotated_boxes", ")", ":", "\n", "    ", "\"\"\"\n    Apply the resizing transform on rotated boxes. For details of how these (approximation)\n    formulas are derived, please refer to :meth:`RotatedBoxes.scale`.\n\n    Args:\n        rotated_boxes (ndarray): Nx5 floating point array of\n            (x_center, y_center, width, height, angle_degrees) format\n            in absolute coordinates.\n    \"\"\"", "\n", "scale_factor_x", "=", "transform", ".", "new_w", "*", "1.0", "/", "transform", ".", "w", "\n", "scale_factor_y", "=", "transform", ".", "new_h", "*", "1.0", "/", "transform", ".", "h", "\n", "rotated_boxes", "[", ":", ",", "0", "]", "*=", "scale_factor_x", "\n", "rotated_boxes", "[", ":", ",", "1", "]", "*=", "scale_factor_y", "\n", "theta", "=", "rotated_boxes", "[", ":", ",", "4", "]", "*", "np", ".", "pi", "/", "180.0", "\n", "c", "=", "np", ".", "cos", "(", "theta", ")", "\n", "s", "=", "np", ".", "sin", "(", "theta", ")", "\n", "rotated_boxes", "[", ":", ",", "2", "]", "*=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "scale_factor_x", "*", "c", ")", "+", "np", ".", "square", "(", "scale_factor_y", "*", "s", ")", ")", "\n", "rotated_boxes", "[", ":", ",", "3", "]", "*=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "scale_factor_x", "*", "s", ")", "+", "np", ".", "square", "(", "scale_factor_y", "*", "c", ")", ")", "\n", "rotated_boxes", "[", ":", ",", "4", "]", "=", "np", ".", "arctan2", "(", "scale_factor_x", "*", "s", ",", "scale_factor_y", "*", "c", ")", "*", "180", "/", "np", ".", "pi", "\n", "\n", "return", "rotated_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._init": [[106, 111], ["params.items", "setattr", "k.startswith"], "methods", ["None"], ["def", "_init", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "        ", "if", "params", ":", "\n", "            ", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "!=", "\"self\"", "and", "not", "k", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                    ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.get_transform": [[112, 147], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_transform", "(", "self", ",", "*", "args", ")", "->", "Transform", ":", "\n", "        ", "\"\"\"\n        Execute the policy based on input data, and decide what transform to apply to inputs.\n\n        Args:\n            args: Any fixed-length positional arguments. By default, the name of the arguments\n                should exist in the :class:`AugInput` to be used.\n\n        Returns:\n            Transform: Returns the deterministic transform to apply to the input.\n\n        Examples:\n        ::\n            class MyAug:\n                # if a policy needs to know both image and semantic segmentation\n                def get_transform(image, sem_seg) -> T.Transform:\n                    pass\n            tfm: Transform = MyAug().get_transform(image, sem_seg)\n            new_image = tfm.apply_image(image)\n\n        Notes:\n            Users can freely use arbitrary new argument names in custom\n            :meth:`get_transform` method, as long as they are available in the\n            input data. In detectron2 we use the following convention:\n\n            * image: (H,W) or (H,W,C) ndarray of type uint8 in range [0, 255], or\n              floating point in range [0, 1] or [0, 255].\n            * boxes: (N,4) ndarray of float32. It represents the instance bounding boxes\n              of N instances. Each is in XYXY format in unit of absolute coordinates.\n            * sem_seg: (H,W) ndarray of type uint8. Each element is an integer label of pixel.\n\n            We do not specify convention for other types and do not include builtin\n            :class:`Augmentation` that uses other types in detectron2.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.__call__": [[148, 172], ["augmentation._get_aug_input_args", "augmentation.Augmentation.get_transform", "isinstance", "aug_input.transform", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._get_aug_input_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.get_transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform"], ["", "def", "__call__", "(", "self", ",", "aug_input", ")", "->", "Transform", ":", "\n", "        ", "\"\"\"\n        Augment the given `aug_input` **in-place**, and return the transform that's used.\n\n        This method will be called to apply the augmentation. In most augmentation, it\n        is enough to use the default implementation, which calls :meth:`get_transform`\n        using the inputs. But a subclass can overwrite it to have more complicated logic.\n\n        Args:\n            aug_input (AugInput): an object that has attributes needed by this augmentation\n                (defined by ``self.get_transform``). Its ``transform`` method will be called\n                to in-place transform it.\n\n        Returns:\n            Transform: the transform that is applied on the input.\n        \"\"\"", "\n", "args", "=", "_get_aug_input_args", "(", "self", ",", "aug_input", ")", "\n", "tfm", "=", "self", ".", "get_transform", "(", "*", "args", ")", "\n", "assert", "isinstance", "(", "tfm", ",", "(", "Transform", ",", "TransformList", ")", ")", ",", "(", "\n", "f\"{type(self)}.get_transform must return an instance of Transform! \"", "\n", "\"Got {type(tfm)} instead.\"", "\n", ")", "\n", "aug_input", ".", "transform", "(", "tfm", ")", "\n", "return", "tfm", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation._rand_range": [[173, 182], ["numpy.random.uniform"], "methods", ["None"], ["", "def", "_rand_range", "(", "self", ",", "low", "=", "1.0", ",", "high", "=", "None", ",", "size", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Uniform float random number between low and high.\n        \"\"\"", "\n", "if", "high", "is", "None", ":", "\n", "            ", "low", ",", "high", "=", "0", ",", "low", "\n", "", "if", "size", "is", "None", ":", "\n", "            ", "size", "=", "[", "]", "\n", "", "return", "np", ".", "random", ".", "uniform", "(", "low", ",", "high", ",", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.Augmentation.__repr__": [[183, 212], ["inspect.signature", "inspect.signature.parameters.items", "type", "hasattr", "getattr", "pprint.pformat", "argstr.append", "super().__repr__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugmentationList.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Produce something like:\n        \"MyAugmentation(field1={self.field1}, field2={self.field2})\"\n        \"\"\"", "\n", "try", ":", "\n", "            ", "sig", "=", "inspect", ".", "signature", "(", "self", ".", "__init__", ")", "\n", "classname", "=", "type", "(", "self", ")", ".", "__name__", "\n", "argstr", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "sig", ".", "parameters", ".", "items", "(", ")", ":", "\n", "                ", "assert", "(", "\n", "param", ".", "kind", "!=", "param", ".", "VAR_POSITIONAL", "and", "param", ".", "kind", "!=", "param", ".", "VAR_KEYWORD", "\n", ")", ",", "\"The default __repr__ doesn't support *args or **kwargs\"", "\n", "assert", "hasattr", "(", "self", ",", "name", ")", ",", "(", "\n", "\"Attribute {} not found! \"", "\n", "\"Default __repr__ only works if attributes match the constructor.\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "attr", "=", "getattr", "(", "self", ",", "name", ")", "\n", "default", "=", "param", ".", "default", "\n", "if", "default", "is", "attr", ":", "\n", "                    ", "continue", "\n", "", "attr_str", "=", "pprint", ".", "pformat", "(", "attr", ")", "\n", "if", "\"\\n\"", "in", "attr_str", ":", "\n", "# don't show it if pformat decides to use >1 lines", "\n", "                    ", "attr_str", "=", "\"...\"", "\n", "", "argstr", ".", "append", "(", "\"{}={}\"", ".", "format", "(", "name", ",", "attr_str", ")", ")", "\n", "", "return", "\"{}({})\"", ".", "format", "(", "classname", ",", "\", \"", ".", "join", "(", "argstr", ")", ")", "\n", "", "except", "AssertionError", ":", "\n", "            ", "return", "super", "(", ")", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugmentationList.__init__": [[253, 260], ["super().__init__", "augmentation._transform_to_aug"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._transform_to_aug"], ["def", "__init__", "(", "self", ",", "augs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            augs (list[Augmentation or Transform]):\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "augs", "=", "[", "_transform_to_aug", "(", "x", ")", "for", "x", "in", "augs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugmentationList.__call__": [[261, 267], ["fvcore.transforms.transform.TransformList", "x", "tfms.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "aug_input", ")", "->", "Transform", ":", "\n", "        ", "tfms", "=", "[", "]", "\n", "for", "x", "in", "self", ".", "augs", ":", "\n", "            ", "tfm", "=", "x", "(", "aug_input", ")", "\n", "tfms", ".", "append", "(", "tfm", ")", "\n", "", "return", "TransformList", "(", "tfms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugmentationList.__repr__": [[268, 271], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msgs", "=", "[", "str", "(", "x", ")", "for", "x", "in", "self", ".", "augs", "]", "\n", "return", "\"AugmentationList[{}]\"", ".", "format", "(", "\", \"", ".", "join", "(", "msgs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.__init__": [[307, 327], ["augmentation._check_img_dtype"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._check_img_dtype"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image", ":", "np", ".", "ndarray", ",", "\n", "*", ",", "\n", "boxes", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "sem_seg", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image (ndarray): (H,W) or (H,W,C) ndarray of type uint8 in range [0, 255], or\n                floating point in range [0, 1] or [0, 255]. The meaning of C is up\n                to users.\n            boxes (ndarray or None): Nx4 float32 boxes in XYXY_ABS mode\n            sem_seg (ndarray or None): HxW uint8 semantic segmentation mask. Each element\n                is an integer label of pixel.\n        \"\"\"", "\n", "_check_img_dtype", "(", "image", ")", "\n", "self", ".", "image", "=", "image", "\n", "self", ".", "boxes", "=", "boxes", "\n", "self", ".", "sem_seg", "=", "sem_seg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform": [[328, 340], ["tfm.apply_image", "tfm.apply_box", "tfm.apply_segmentation"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_segmentation"], ["", "def", "transform", "(", "self", ",", "tfm", ":", "Transform", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        In-place transform all attributes of this class.\n\n        By \"in-place\", it means after calling this method, accessing an attribute such\n        as ``self.image`` will return transformed data.\n        \"\"\"", "\n", "self", ".", "image", "=", "tfm", ".", "apply_image", "(", "self", ".", "image", ")", "\n", "if", "self", ".", "boxes", "is", "not", "None", ":", "\n", "            ", "self", ".", "boxes", "=", "tfm", ".", "apply_box", "(", "self", ".", "boxes", ")", "\n", "", "if", "self", ".", "sem_seg", "is", "not", "None", ":", "\n", "            ", "self", ".", "sem_seg", "=", "tfm", ".", "apply_segmentation", "(", "self", ".", "sem_seg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.apply_augmentations": [[341, 348], ["augmentation.AugmentationList"], "methods", ["None"], ["", "", "def", "apply_augmentations", "(", "\n", "self", ",", "augmentations", ":", "List", "[", "Union", "[", "Augmentation", ",", "Transform", "]", "]", "\n", ")", "->", "TransformList", ":", "\n", "        ", "\"\"\"\n        Equivalent of ``AugmentationList(augmentations)(self)``\n        \"\"\"", "\n", "return", "AugmentationList", "(", "augmentations", ")", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._check_img_dtype": [[27, 37], ["isinstance", "type", "isinstance"], "function", ["None"], ["def", "_check_img_dtype", "(", "img", ")", ":", "\n", "    ", "assert", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ",", "\"[Augmentation] Needs an numpy array, but got a {}!\"", ".", "format", "(", "\n", "type", "(", "img", ")", "\n", ")", "\n", "assert", "not", "isinstance", "(", "img", ".", "dtype", ",", "np", ".", "integer", ")", "or", "(", "\n", "img", ".", "dtype", "==", "np", ".", "uint8", "\n", ")", ",", "\"[Augmentation] Got image of type {}, use uint8 or floating points instead!\"", ".", "format", "(", "\n", "img", ".", "dtype", "\n", ")", "\n", "assert", "img", ".", "ndim", "in", "[", "2", ",", "3", "]", ",", "img", ".", "ndim", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._get_aug_input_args": [[39, 75], ["list", "tuple", "inspect.signature().parameters.items", "len", "args.append", "names.append", "getattr", "AttributeError", "TypeError", "inspect.signature", "type", "type", "type", "type"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "_get_aug_input_args", "(", "aug", ",", "aug_input", ")", "->", "List", "[", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Get the arguments to be passed to ``aug.get_transform`` from the input ``aug_input``.\n    \"\"\"", "\n", "if", "aug", ".", "input_args", "is", "None", ":", "\n", "# Decide what attributes are needed automatically", "\n", "        ", "prms", "=", "list", "(", "inspect", ".", "signature", "(", "aug", ".", "get_transform", ")", ".", "parameters", ".", "items", "(", ")", ")", "\n", "# The default behavior is: if there is one parameter, then its \"image\"", "\n", "# (work automatically for majority of use cases, and also avoid BC breaking),", "\n", "# Otherwise, use the argument names.", "\n", "if", "len", "(", "prms", ")", "==", "1", ":", "\n", "            ", "names", "=", "(", "\"image\"", ",", ")", "\n", "", "else", ":", "\n", "            ", "names", "=", "[", "]", "\n", "for", "name", ",", "prm", "in", "prms", ":", "\n", "                ", "if", "prm", ".", "kind", "in", "(", "inspect", ".", "Parameter", ".", "VAR_POSITIONAL", ",", "inspect", ".", "Parameter", ".", "VAR_KEYWORD", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "\n", "f\"\"\" \\\nThe default implementation of `{type(aug)}.__call__` does not allow \\\n`{type(aug)}.get_transform` to use variable-length arguments (*args, **kwargs)! \\\nIf arguments are unknown, reimplement `__call__` instead. \\\n\"\"\"", "\n", ")", "\n", "", "names", ".", "append", "(", "name", ")", "\n", "", "", "aug", ".", "input_args", "=", "tuple", "(", "names", ")", "\n", "\n", "", "args", "=", "[", "]", "\n", "for", "f", "in", "aug", ".", "input_args", ":", "\n", "        ", "try", ":", "\n", "            ", "args", ".", "append", "(", "getattr", "(", "aug_input", ",", "f", ")", ")", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "f\"{type(aug)}.get_transform needs input attribute '{f}', \"", "\n", "f\"but it is not an attribute of {type(aug_input)}!\"", "\n", ")", "from", "e", "\n", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation._transform_to_aug": [[216, 239], ["isinstance", "isinstance", "_TransformToAug", "repr"], "function", ["None"], ["", "def", "_transform_to_aug", "(", "tfm_or_aug", ")", ":", "\n", "    ", "\"\"\"\n    Wrap Transform into Augmentation.\n    Private, used internally to implement augmentations.\n    \"\"\"", "\n", "assert", "isinstance", "(", "tfm_or_aug", ",", "(", "Transform", ",", "Augmentation", ")", ")", ",", "tfm_or_aug", "\n", "if", "isinstance", "(", "tfm_or_aug", ",", "Augmentation", ")", ":", "\n", "        ", "return", "tfm_or_aug", "\n", "", "else", ":", "\n", "\n", "        ", "class", "_TransformToAug", "(", "Augmentation", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "tfm", ":", "Transform", ")", ":", "\n", "                ", "self", ".", "tfm", "=", "tfm", "\n", "\n", "", "def", "get_transform", "(", "self", ",", "*", "args", ")", ":", "\n", "                ", "return", "self", ".", "tfm", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "                ", "return", "repr", "(", "self", ".", "tfm", ")", "\n", "\n", "", "__str__", "=", "__repr__", "\n", "\n", "", "return", "_TransformToAug", "(", "tfm_or_aug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.apply_augmentations": [[350, 362], ["isinstance", "AugInput.apply_augmentations", "augmentation.AugInput"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.apply_augmentations"], ["", "", "def", "apply_augmentations", "(", "augmentations", ":", "List", "[", "Union", "[", "Transform", ",", "Augmentation", "]", "]", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Use ``T.AugmentationList(augmentations)(inputs)`` instead.\n    \"\"\"", "\n", "if", "isinstance", "(", "inputs", ",", "np", ".", "ndarray", ")", ":", "\n", "# handle the common case of image-only Augmentation, also for backward compatibility", "\n", "        ", "image_only", "=", "True", "\n", "inputs", "=", "AugInput", "(", "inputs", ")", "\n", "", "else", ":", "\n", "        ", "image_only", "=", "False", "\n", "", "tfms", "=", "inputs", ".", "apply_augmentations", "(", "augmentations", ")", "\n", "return", "inputs", ".", "image", "if", "image_only", "else", "inputs", ",", "tfms", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.make_optimizer": [[7, 27], ["logging.getLogger", "model.named_parameters", "torch.optim.SGD", "key.endswith", "key.endswith", "logging.getLogger.info"], "function", ["None"], ["from", "maskrcnn_benchmark", ".", "utils", ".", "comm", "import", "get_world_size", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "imports", "import", "import_file", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "miscellaneous", "import", "save_labels", "\n", "\n", "from", ".", "import", "datasets", "as", "D", "\n", "from", ".", "import", "samplers", "\n", "\n", "from", ".", "collate_batch", "import", "BatchCollator", ",", "BBoxAugCollator", "\n", "from", ".", "transforms", "import", "build_transforms", "\n", "\n", "\n", "def", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "dataset_catalog", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        dataset_list (list[str]): Contains the names of the datasets, i.e.,\n            coco_2014_train, coco_2014_val, etc\n        transforms (callable): transforms to apply to each (image, target) sample\n        dataset_catalog (DatasetCatalog): contains the information on how to\n            construct a dataset.\n        is_train (bool): whether to setup the dataset for training or testing\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.make_lr_scheduler": [[29, 37], ["lr_scheduler.WarmupMultiStepLR"], "function", ["None"], ["        ", "raise", "RuntimeError", "(", "\n", "\"dataset_list should be a list of strings, got {}\"", ".", "format", "(", "dataset_list", ")", "\n", ")", "\n", "", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "dataset_list", ":", "\n", "        ", "data", "=", "dataset_catalog", ".", "get", "(", "dataset_name", ")", "\n", "factory", "=", "getattr", "(", "D", ",", "data", "[", "\"factory\"", "]", ")", "\n", "args", "=", "data", "[", "\"args\"", "]", "\n", "# for COCODataset, we want to remove images without annotations", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupMultiStepLR.__init__": [[11, 38], ["super().__init__", "ValueError", "ValueError", "list", "sorted"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "milestones", ",", "\n", "gamma", "=", "0.1", ",", "\n", "warmup_factor", "=", "1.0", "/", "3", ",", "\n", "warmup_iters", "=", "500", ",", "\n", "warmup_method", "=", "\"linear\"", ",", "\n", "last_epoch", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "if", "not", "list", "(", "milestones", ")", "==", "sorted", "(", "milestones", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {}\"", ",", "\n", "milestones", ",", "\n", ")", "\n", "\n", "", "if", "warmup_method", "not", "in", "(", "\"constant\"", ",", "\"linear\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only 'constant' or 'linear' warmup_method accepted\"", "\n", "\"got {}\"", ".", "format", "(", "warmup_method", ")", "\n", ")", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", "WarmupMultiStepLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupMultiStepLR.get_lr": [[39, 52], ["bisect.bisect_right", "float"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "warmup_factor", "=", "1", "\n", "if", "self", ".", "last_epoch", "<", "self", ".", "warmup_iters", ":", "\n", "            ", "if", "self", ".", "warmup_method", "==", "\"constant\"", ":", "\n", "                ", "warmup_factor", "=", "self", ".", "warmup_factor", "\n", "", "elif", "self", ".", "warmup_method", "==", "\"linear\"", ":", "\n", "                ", "alpha", "=", "float", "(", "self", ".", "last_epoch", ")", "/", "self", ".", "warmup_iters", "\n", "warmup_factor", "=", "self", ".", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "", "", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n", "*", "self", ".", "gamma", "**", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build._create_gradient_clipper": [[23, 41], ["copy.deepcopy", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "build.GradientClipType"], "function", ["None"], ["\n", "if", "not", "isinstance", "(", "dataset_list", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"dataset_list should be a list of strings, got {}\"", ".", "format", "(", "dataset_list", ")", "\n", ")", "\n", "", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "dataset_list", ":", "\n", "        ", "data", "=", "dataset_catalog", ".", "get", "(", "dataset_name", ")", "\n", "factory", "=", "getattr", "(", "D", ",", "data", "[", "\"factory\"", "]", ")", "\n", "args", "=", "data", "[", "\"args\"", "]", "\n", "# for COCODataset, we want to remove images without annotations", "\n", "# during training", "\n", "if", "data", "[", "\"factory\"", "]", "==", "\"COCODataset\"", ":", "\n", "            ", "args", "[", "\"remove_images_without_annotations\"", "]", "=", "is_train", "\n", "", "if", "data", "[", "\"factory\"", "]", "==", "\"PascalVOCDataset\"", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build._generate_optimizer_class_with_gradient_clipping": [[43, 75], ["type", "super().step", "itertools.chain", "global_clipper", "per_param_clipper", "type"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.step"], ["", "args", "[", "\"transforms\"", "]", "=", "transforms", "\n", "# make dataset from factory", "\n", "dataset", "=", "factory", "(", "**", "args", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "# for testing, return a list of datasets", "\n", "", "if", "not", "is_train", ":", "\n", "        ", "return", "datasets", "\n", "\n", "# for training, concatenate all datasets into a single one", "\n", "", "dataset", "=", "datasets", "[", "0", "]", "\n", "if", "len", "(", "datasets", ")", ">", "1", ":", "\n", "        ", "dataset", "=", "D", ".", "ConcatDataset", "(", "datasets", ")", "\n", "\n", "", "return", "[", "dataset", "]", "\n", "\n", "\n", "", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n", "\n", "", "def", "_quantize", "(", "x", ",", "bins", ")", ":", "\n", "    ", "bins", "=", "copy", ".", "copy", "(", "bins", ")", "\n", "bins", "=", "sorted", "(", "bins", ")", "\n", "quantized", "=", "list", "(", "map", "(", "lambda", "y", ":", "bisect", ".", "bisect_right", "(", "bins", ",", "y", ")", ",", "x", ")", ")", "\n", "return", "quantized", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping": [[77, 111], ["isinstance", "build._create_gradient_clipper", "build._generate_optimizer_class_with_gradient_clipping", "isinstance", "type", "issubclass", "torch.optim.SGD"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build._create_gradient_clipper", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build._generate_optimizer_class_with_gradient_clipping"], ["", "def", "_compute_aspect_ratios", "(", "dataset", ")", ":", "\n", "    ", "aspect_ratios", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "img_info", "=", "dataset", ".", "get_img_info", "(", "i", ")", "\n", "aspect_ratio", "=", "float", "(", "img_info", "[", "\"height\"", "]", ")", "/", "float", "(", "img_info", "[", "\"width\"", "]", ")", "\n", "aspect_ratios", ".", "append", "(", "aspect_ratio", ")", "\n", "", "return", "aspect_ratios", "\n", "\n", "\n", "", "def", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_batch", ",", "num_iters", "=", "None", ",", "start_iter", "=", "0", "\n", ")", ":", "\n", "    ", "if", "aspect_grouping", ":", "\n", "        ", "if", "not", "isinstance", "(", "aspect_grouping", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "aspect_grouping", "=", "[", "aspect_grouping", "]", "\n", "", "aspect_ratios", "=", "_compute_aspect_ratios", "(", "dataset", ")", "\n", "group_ids", "=", "_quantize", "(", "aspect_ratios", ",", "aspect_grouping", ")", "\n", "batch_sampler", "=", "samplers", ".", "GroupedBatchSampler", "(", "\n", "sampler", ",", "group_ids", ",", "images_per_batch", ",", "drop_uneven", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "BatchSampler", "(", "\n", "sampler", ",", "images_per_batch", ",", "drop_last", "=", "False", "\n", ")", "\n", "", "if", "num_iters", "is", "not", "None", ":", "\n", "        ", "batch_sampler", "=", "samplers", ".", "IterationBasedBatchSampler", "(", "\n", "batch_sampler", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "", "return", "batch_sampler", "\n", "\n", "\n", "", "def", "make_data_loader", "(", "cfg", ",", "is_train", "=", "True", ",", "is_distributed", "=", "False", ",", "start_iter", "=", "0", ",", "is_for_period", "=", "False", ")", ":", "\n", "    ", "num_gpus", "=", "get_world_size", "(", ")", "\n", "if", "is_train", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.build_optimizer": [[113, 130], ["build.get_default_optimizer_params", "build.maybe_add_gradient_clipping"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.get_default_optimizer_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping"], ["images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "True", "\n", "num_iters", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "", "else", ":", "\n", "        ", "images_per_batch", "=", "cfg", ".", "TEST", ".", "IMS_PER_BATCH", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\"", ".", "format", "(", "\n", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "shuffle", "=", "False", "if", "not", "is_distributed", "else", "True", "\n", "num_iters", "=", "None", "\n", "start_iter", "=", "0", "\n", "\n", "", "if", "images_per_gpu", ">", "1", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.get_default_optimizer_params": [[133, 218], ["len", "set", "model.modules", "module.named_parameters", "ValueError", "ValueError", "memo.add", "copy.copy", "copy.copy.update", "params.append", "isinstance", "overrides.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\"When using more than one image per GPU you may encounter \"", "\n", "\"an out-of-memory (OOM) error if your GPU does not have \"", "\n", "\"sufficient memory. If this happens, you can reduce \"", "\n", "\"SOLVER.IMS_PER_BATCH (for training) or \"", "\n", "\"TEST.IMS_PER_BATCH (for inference). For training, you must \"", "\n", "\"also adjust the learning rate and schedule length according \"", "\n", "\"to the linear scaling rule. See for example: \"", "\n", "\"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"", "\n", ")", "\n", "\n", "# group images which have similar aspect ratio. In this case, we only", "\n", "# group in two cases: those with width / height > 1, and the other way around,", "\n", "# but the code supports more general grouping strategy", "\n", "", "aspect_grouping", "=", "[", "1", "]", "if", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", "else", "[", "]", "\n", "\n", "paths_catalog", "=", "import_file", "(", "\n", "\"maskrcnn_benchmark.config.paths_catalog\"", ",", "cfg", ".", "PATHS_CATALOG", ",", "True", "\n", ")", "\n", "DatasetCatalog", "=", "paths_catalog", ".", "DatasetCatalog", "\n", "dataset_list", "=", "cfg", ".", "DATASETS", ".", "TRAIN", "if", "is_train", "else", "cfg", ".", "DATASETS", ".", "TEST", "\n", "\n", "# If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later", "\n", "transforms", "=", "None", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "build_transforms", "(", "cfg", ",", "is_train", ")", "\n", "datasets", "=", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "DatasetCatalog", ",", "is_train", "or", "is_for_period", ")", "\n", "\n", "if", "is_train", ":", "\n", "# save category_id to label name mapping", "\n", "        ", "save_labels", "(", "datasets", ",", "cfg", ".", "OUTPUT_DIR", ")", "\n", "\n", "", "data_loaders", "=", "[", "]", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "sampler", "=", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "is_distributed", ")", "\n", "batch_sampler", "=", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "images_per_gpu", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "collator", "=", "BBoxAugCollator", "(", ")", "if", "not", "is_train", "and", "cfg", ".", "TEST", ".", "BBOX_AUG", ".", "ENABLED", "else", "BatchCollator", "(", "cfg", ".", "DATALOADER", ".", "SIZE_DIVISIBILITY", ")", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "collator", ",", "\n", ")", "\n", "data_loaders", ".", "append", "(", "data_loader", ")", "\n", "", "if", "is_train", "or", "is_for_period", ":", "\n", "# during training, a single (possibly concatenated) data_loader is returned", "\n", "        ", "assert", "len", "(", "data_loaders", ")", "==", "1", "\n", "return", "data_loaders", "[", "0", "]", "\n", "", "return", "data_loaders", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.build_lr_scheduler": [[220, 253], ["lr_scheduler.WarmupParamScheduler", "lr_scheduler.LRMultiplier", "fvcore.common.param_scheduler.MultiStepParamScheduler", "len", "len", "logging.getLogger", "logging.getLogger.warning", "fvcore.common.param_scheduler.CosineParamScheduler", "ValueError", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupParamScheduler.__init__": [[22, 49], ["scheduler", "fvcore.common.param_scheduler.CompositeParamScheduler.__init__", "scheduler", "fvcore.common.param_scheduler.ConstantParamScheduler", "fvcore.common.param_scheduler.LinearParamScheduler", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {}\"", ",", "\n", "milestones", ",", "\n", ")", "\n", "\n", "", "if", "warmup_method", "not", "in", "(", "\"constant\"", ",", "\"linear\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only 'constant' or 'linear' warmup_method accepted\"", "\n", "\"got {}\"", ".", "format", "(", "warmup_method", ")", "\n", ")", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", "WarmupMultiStepLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n", "", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "warmup_factor", "=", "1", "\n", "if", "self", ".", "last_epoch", "<", "self", ".", "warmup_iters", ":", "\n", "            ", "if", "self", ".", "warmup_method", "==", "\"constant\"", ":", "\n", "                ", "warmup_factor", "=", "self", ".", "warmup_factor", "\n", "", "elif", "self", ".", "warmup_method", "==", "\"linear\"", ":", "\n", "                ", "alpha", "=", "float", "(", "self", ".", "last_epoch", ")", "/", "self", ".", "warmup_iters", "\n", "warmup_factor", "=", "self", ".", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "", "", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.__init__": [[86, 109], ["super().__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.state_dict": [[110, 113], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.get_lr": [[114, 117], ["lr_scheduler.LRMultiplier._multiplier"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupMultiStepLR._compute_values": [[166, 169], ["lr_scheduler.WarmupMultiStepLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.lr_scheduler.WarmupPolyLR.get_lr"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupCosineLR.__init__": [[172, 189], ["logger.warning", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupCosineLR.get_lr": [[190, 205], ["lr_scheduler._get_warmup_factor_at_iter", "math.cos"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler._get_warmup_factor_at_iter"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.WarmupCosineLR._compute_values": [[207, 210], ["lr_scheduler.WarmupCosineLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.lr_scheduler.WarmupPolyLR.get_lr"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler._get_warmup_factor_at_iter": [[212, 239], ["ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detectron2.setup.get_version": [[18, 39], ["os.path.join", "open().readlines", "[].strip().strip", "os.getenv", "os.path.abspath", "os.getenv", "datetime.today().strftime", "new_init_py.append", "os.path.dirname", "open", "l.strip", "[].strip", "open", "f.write", "l.startswith", "datetime.today", "l.startswith", "version_line.split"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["    ", "this_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "extensions_dir", "=", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"maskrcnn_benchmark\"", ",", "\"csrc\"", ")", "\n", "\n", "main_file", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"*.cpp\"", ")", ")", "\n", "source_cpu", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"cpu\"", ",", "\"*.cpp\"", ")", ")", "\n", "source_cuda", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"cuda\"", ",", "\"*.cu\"", ")", ")", "\n", "\n", "sources", "=", "main_file", "+", "source_cpu", "\n", "extension", "=", "CppExtension", "\n", "\n", "extra_compile_args", "=", "{", "\"cxx\"", ":", "[", "]", "}", "\n", "define_macros", "=", "[", "]", "\n", "\n", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "CUDA_HOME", "is", "not", "None", ")", "or", "os", ".", "getenv", "(", "\"FORCE_CUDA\"", ",", "\"0\"", ")", "==", "\"1\"", ":", "\n", "        ", "extension", "=", "CUDAExtension", "\n", "sources", "+=", "source_cuda", "\n", "define_macros", "+=", "[", "(", "\"WITH_CUDA\"", ",", "None", ")", "]", "\n", "extra_compile_args", "[", "\"nvcc\"", "]", "=", "[", "\n", "\"-DCUDA_HAS_FP16=1\"", ",", "\n", "\"-D__CUDA_NO_HALF_OPERATORS__\"", ",", "\n", "\"-D__CUDA_NO_HALF_CONVERSIONS__\"", ",", "\n", "\"-D__CUDA_NO_HALF2_OPERATORS__\"", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detectron2.setup.get_extensions": [[41, 150], ["os.path.dirname", "os.path.join", "os.path.join", "glob.glob", "os.path.abspath", "os.path.join", "hasattr", "torch.utils.hipify.hipify_python.hipify", "shutil.copy", "shutil.copy", "extension", "int", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "torch.cuda.is_available", "os.getenv", "os.environ.get", "torch.utils.hipify.__version__.split", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "extra_compile_args[].append", "s.endswith"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["\n", "", "sources", "=", "[", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "s", ")", "for", "s", "in", "sources", "]", "\n", "\n", "include_dirs", "=", "[", "extensions_dir", "]", "\n", "\n", "ext_modules", "=", "[", "\n", "extension", "(", "\n", "\"maskrcnn_benchmark._C\"", ",", "\n", "sources", ",", "\n", "include_dirs", "=", "include_dirs", ",", "\n", "define_macros", "=", "define_macros", ",", "\n", "extra_compile_args", "=", "extra_compile_args", ",", "\n", ")", "\n", "]", "\n", "\n", "return", "ext_modules", "\n", "\n", "\n", "", "setup", "(", "\n", "name", "=", "\"maskrcnn_benchmark\"", ",", "\n", "version", "=", "\"0.1\"", ",", "\n", "author", "=", "\"fmassa\"", ",", "\n", "url", "=", "\"https://github.com/facebookresearch/maskrcnn-benchmark\"", ",", "\n", "description", "=", "\"object detection in pytorch\"", ",", "\n", "packages", "=", "find_packages", "(", "exclude", "=", "(", "\"configs\"", ",", "\"tests\"", ",", ")", ")", ",", "\n", "# install_requires=requirements,", "\n", "ext_modules", "=", "get_extensions", "(", ")", ",", "\n", "cmdclass", "=", "{", "\"build_ext\"", ":", "torch", ".", "utils", ".", "cpp_extension", ".", "BuildExtension", "}", ",", "\n", ")", "\n", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.detectron2.setup.get_model_zoo_configs": [[152, 181], ["os.path.join", "os.path.join", "os.path.exists", "glob.glob", "os.path.dirname", "os.path.dirname", "os.path.islink", "os.path.exists", "os.path.realpath", "os.path.realpath", "os.unlink", "os.path.isdir", "os.symlink", "shutil.rmtree", "shutil.copytree"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deploy.export_model.setup_cfg": [[30, 40], ["detectron2.config.get_cfg", "detectron2.export.add_export_config", "detectron2.projects.point_rend.add_pointrend_config", "detectron2.export.add_export_config.merge_from_file", "detectron2.export.add_export_config.merge_from_list", "detectron2.export.add_export_config.freeze"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.add_export_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.config.add_pointrend_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], ["def", "setup_cfg", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "# cuda context is initialized before creating dataloader, so we don't fork anymore", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "cfg", "=", "add_export_config", "(", "cfg", ")", "\n", "add_pointrend_config", "(", "cfg", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deploy.export_model.export_caffe2_tracing": [[42, 58], ["detectron2.export.Caffe2Tracer", "detectron2.export.Caffe2Tracer.export_caffe2", "tracer.export_caffe2.save_protobuf", "tracer.export_caffe2.save_graph", "os.path.join", "detectron2.export.Caffe2Tracer.export_onnx", "onnx.save", "os.path.join", "detectron2.export.Caffe2Tracer.export_torchscript", "detectron2.export.dump_torchscript_IR", "detectron2.utils.file_io.PathManager.open", "torch.jit.save", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_caffe2", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_protobuf", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_graph", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_onnx", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_torchscript", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript.dump_torchscript_IR", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save"], ["", "def", "export_caffe2_tracing", "(", "cfg", ",", "torch_model", ",", "inputs", ")", ":", "\n", "    ", "tracer", "=", "Caffe2Tracer", "(", "cfg", ",", "torch_model", ",", "inputs", ")", "\n", "if", "args", ".", "format", "==", "\"caffe2\"", ":", "\n", "        ", "caffe2_model", "=", "tracer", ".", "export_caffe2", "(", ")", "\n", "caffe2_model", ".", "save_protobuf", "(", "args", ".", "output", ")", "\n", "# draw the caffe2 graph", "\n", "caffe2_model", ".", "save_graph", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"model.svg\"", ")", ",", "inputs", "=", "inputs", ")", "\n", "return", "caffe2_model", "\n", "", "elif", "args", ".", "format", "==", "\"onnx\"", ":", "\n", "        ", "onnx_model", "=", "tracer", ".", "export_onnx", "(", ")", "\n", "onnx", ".", "save", "(", "onnx_model", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"model.onnx\"", ")", ")", "\n", "", "elif", "args", ".", "format", "==", "\"torchscript\"", ":", "\n", "        ", "ts_model", "=", "tracer", ".", "export_torchscript", "(", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"model.ts\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch", ".", "jit", ".", "save", "(", "ts_model", ",", "f", ")", "\n", "", "dump_torchscript_IR", "(", "ts_model", ",", "args", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deploy.export_model.export_scripting": [[61, 103], ["isinstance", "detectron2.export.scripting_with_instances", "detectron2.export.dump_torchscript_IR", "ScriptableAdapter", "detectron2.utils.file_io.PathManager.open", "torch.jit.save", "super().__init__", "export_model..eval", "os.path.join", "export_model..model.inference", "export_model..model", "i.get_fields", "i.get_fields"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript.scripting_with_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript.dump_torchscript_IR", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields"], ["", "", "def", "export_scripting", "(", "torch_model", ")", ":", "\n", "    ", "assert", "TORCH_VERSION", ">=", "(", "1", ",", "8", ")", "\n", "fields", "=", "{", "\n", "\"proposal_boxes\"", ":", "Boxes", ",", "\n", "\"objectness_logits\"", ":", "Tensor", ",", "\n", "\"pred_boxes\"", ":", "Boxes", ",", "\n", "\"scores\"", ":", "Tensor", ",", "\n", "\"pred_classes\"", ":", "Tensor", ",", "\n", "\"pred_masks\"", ":", "Tensor", ",", "\n", "\"pred_keypoints\"", ":", "torch", ".", "Tensor", ",", "\n", "\"pred_keypoint_heatmaps\"", ":", "torch", ".", "Tensor", ",", "\n", "}", "\n", "assert", "args", ".", "format", "==", "\"torchscript\"", ",", "\"Scripting only supports torchscript format.\"", "\n", "\n", "class", "ScriptableAdapterBase", "(", "nn", ".", "Module", ")", ":", "\n", "# Use this adapter to workaround https://github.com/pytorch/pytorch/issues/46944", "\n", "# by not retuning instances but dicts. Otherwise the exported model is not deployable", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "torch_model", "\n", "self", ".", "eval", "(", ")", "\n", "\n", "", "", "if", "isinstance", "(", "torch_model", ",", "GeneralizedRCNN", ")", ":", "\n", "\n", "        ", "class", "ScriptableAdapter", "(", "ScriptableAdapterBase", ")", ":", "\n", "            ", "def", "forward", "(", "self", ",", "inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ":", "\n", "                ", "instances", "=", "self", ".", "model", ".", "inference", "(", "inputs", ",", "do_postprocess", "=", "False", ")", "\n", "return", "[", "i", ".", "get_fields", "(", ")", "for", "i", "in", "instances", "]", "\n", "\n", "", "", "", "else", ":", "\n", "\n", "        ", "class", "ScriptableAdapter", "(", "ScriptableAdapterBase", ")", ":", "\n", "            ", "def", "forward", "(", "self", ",", "inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ":", "\n", "                ", "instances", "=", "self", ".", "model", "(", "inputs", ")", "\n", "return", "[", "i", ".", "get_fields", "(", ")", "for", "i", "in", "instances", "]", "\n", "\n", "", "", "", "ts_model", "=", "scripting_with_instances", "(", "ScriptableAdapter", "(", ")", ",", "fields", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"model.ts\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "torch", ".", "jit", ".", "save", "(", "ts_model", ",", "f", ")", "\n", "", "dump_torchscript_IR", "(", "ts_model", ",", "args", ".", "output", ")", "\n", "# TODO inference in Python now missing postprocessing glue code", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deploy.export_model.export_tracing": [[106, 151], ["isinstance", "detectron2.export.TracingAdapter", "logger.info", "logger.info", "torch.jit.trace", "detectron2.export.dump_torchscript_IR", "isinstance", "detectron2.modeling.postprocessing.detector_postprocess", "detectron2.utils.file_io.PathManager.open", "torch.jit.save", "str", "str", "model.inference", "os.path.join", "detectron2.utils.file_io.PathManager.open", "torch.onnx.export", "detectron2.export.TracingAdapter.outputs_schema", "os.path.join", "torch.jit.trace."], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript.dump_torchscript_IR", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference"], ["", "def", "export_tracing", "(", "torch_model", ",", "inputs", ")", ":", "\n", "    ", "assert", "TORCH_VERSION", ">=", "(", "1", ",", "8", ")", "\n", "image", "=", "inputs", "[", "0", "]", "[", "\"image\"", "]", "\n", "inputs", "=", "[", "{", "\"image\"", ":", "image", "}", "]", "# remove other unused keys", "\n", "\n", "if", "isinstance", "(", "torch_model", ",", "GeneralizedRCNN", ")", ":", "\n", "\n", "        ", "def", "inference", "(", "model", ",", "inputs", ")", ":", "\n", "# use do_postprocess=False so it returns ROI mask", "\n", "            ", "inst", "=", "model", ".", "inference", "(", "inputs", ",", "do_postprocess", "=", "False", ")", "[", "0", "]", "\n", "return", "[", "{", "\"instances\"", ":", "inst", "}", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "inference", "=", "None", "# assume that we just call the model directly", "\n", "\n", "", "traceable_model", "=", "TracingAdapter", "(", "torch_model", ",", "inputs", ",", "inference", ")", "\n", "\n", "if", "args", ".", "format", "==", "\"torchscript\"", ":", "\n", "        ", "ts_model", "=", "torch", ".", "jit", ".", "trace", "(", "traceable_model", ",", "(", "image", ",", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"model.ts\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch", ".", "jit", ".", "save", "(", "ts_model", ",", "f", ")", "\n", "", "dump_torchscript_IR", "(", "ts_model", ",", "args", ".", "output", ")", "\n", "", "elif", "args", ".", "format", "==", "\"onnx\"", ":", "\n", "# NOTE onnx export currently failing in pytorch", "\n", "        ", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"model.onnx\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch", ".", "onnx", ".", "export", "(", "traceable_model", ",", "(", "image", ",", ")", ",", "f", ")", "\n", "", "", "logger", ".", "info", "(", "\"Inputs schema: \"", "+", "str", "(", "traceable_model", ".", "inputs_schema", ")", ")", "\n", "logger", ".", "info", "(", "\"Outputs schema: \"", "+", "str", "(", "traceable_model", ".", "outputs_schema", ")", ")", "\n", "\n", "if", "args", ".", "format", "!=", "\"torchscript\"", ":", "\n", "        ", "return", "None", "\n", "", "if", "not", "isinstance", "(", "torch_model", ",", "(", "GeneralizedRCNN", ",", "RetinaNet", ")", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "", "def", "eval_wrapper", "(", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        The exported model does not contain the final resize step, which is typically\n        unused in deployment but needed for evaluation. We add it manually here.\n        \"\"\"", "\n", "input", "=", "inputs", "[", "0", "]", "\n", "instances", "=", "traceable_model", ".", "outputs_schema", "(", "ts_model", "(", "input", "[", "\"image\"", "]", ")", ")", "[", "0", "]", "[", "\"instances\"", "]", "\n", "postprocessed", "=", "detector_postprocess", "(", "instances", ",", "input", "[", "\"height\"", "]", ",", "input", "[", "\"width\"", "]", ")", "\n", "return", "[", "{", "\"instances\"", ":", "postprocessed", "}", "]", "\n", "\n", "", "return", "eval_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.__init__": [[32, 69], ["torch.nn.Module.__init__", "rcnn.GeneralizedRCNN.register_buffer", "rcnn.GeneralizedRCNN.register_buffer", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "proposal_generator", ":", "nn", ".", "Module", ",", "\n", "roi_heads", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", ",", "\n", "input_format", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "vis_period", ":", "int", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            proposal_generator: a module that generates proposals using backbone features\n            roi_heads: a ROI head that performs per-region computation\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n            input_format: describe the meaning of channels of input. Needed by visualization\n            vis_period: the period to run visualization. Set to 0 to disable.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "proposal_generator", "=", "proposal_generator", "\n", "self", ".", "roi_heads", "=", "roi_heads", "\n", "\n", "self", ".", "input_format", "=", "input_format", "\n", "self", ".", "vis_period", "=", "vis_period", "\n", "if", "vis_period", ">", "0", ":", "\n", "            ", "assert", "input_format", "is", "not", "None", ",", "\"input_format is required for visualization!\"", "\n", "\n", "", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "assert", "(", "\n", "self", ".", "pixel_mean", ".", "shape", "==", "self", ".", "pixel_std", ".", "shape", "\n", ")", ",", "f\"{self.pixel_mean} and {self.pixel_std} have different shapes!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.from_config": [[70, 81], ["backbone.build_backbone.build_backbone", "proposal_generator.build_proposal_generator", "roi_heads.build_roi_heads", "backbone.build_backbone.build_backbone.output_shape", "backbone.build_backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.build.build_proposal_generator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_heads.build_roi_heads", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"proposal_generator\"", ":", "build_proposal_generator", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"roi_heads\"", ":", "build_roi_heads", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"input_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"vis_period\"", ":", "cfg", ".", "VIS_PERIOD", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.device": [[83, 86], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.visualize_training": [[87, 121], ["detectron2.utils.events.get_event_storage", "zip", "detectron2.data.detection_utils.convert_image_to_rgb", "Visualizer", "v_gt.overlay_instances.overlay_instances.overlay_instances", "v_gt.overlay_instances.overlay_instances.get_image", "min", "Visualizer", "v_pred.overlay_instances.overlay_instances.overlay_instances", "v_pred.overlay_instances.overlay_instances.get_image", "numpy.concatenate", "vis_img.transpose.transpose.transpose", "detectron2.utils.events.get_event_storage.put_image", "detectron2.data.detection_utils.convert_image_to_rgb.permute", "len", "prop.proposal_boxes[].tensor.cpu().numpy", "prop.proposal_boxes[].tensor.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.convert_image_to_rgb", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_image"], ["", "def", "visualize_training", "(", "self", ",", "batched_inputs", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        A function used to visualize images and proposals. It shows ground truth\n        bounding boxes on the original image and up to 20 top-scoring predicted\n        object proposals on the original image. Users can implement different\n        visualization functions for different models.\n\n        Args:\n            batched_inputs (list): a list that contains input to the model.\n            proposals (list): a list that contains predicted proposals. Both\n                batched_inputs and proposals should have the same length.\n        \"\"\"", "\n", "from", "detectron2", ".", "utils", ".", "visualizer", "import", "Visualizer", "\n", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "max_vis_prop", "=", "20", "\n", "\n", "for", "input", ",", "prop", "in", "zip", "(", "batched_inputs", ",", "proposals", ")", ":", "\n", "            ", "img", "=", "input", "[", "\"image\"", "]", "\n", "img", "=", "convert_image_to_rgb", "(", "img", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "self", ".", "input_format", ")", "\n", "v_gt", "=", "Visualizer", "(", "img", ",", "None", ")", "\n", "v_gt", "=", "v_gt", ".", "overlay_instances", "(", "boxes", "=", "input", "[", "\"instances\"", "]", ".", "gt_boxes", ")", "\n", "anno_img", "=", "v_gt", ".", "get_image", "(", ")", "\n", "box_size", "=", "min", "(", "len", "(", "prop", ".", "proposal_boxes", ")", ",", "max_vis_prop", ")", "\n", "v_pred", "=", "Visualizer", "(", "img", ",", "None", ")", "\n", "v_pred", "=", "v_pred", ".", "overlay_instances", "(", "\n", "boxes", "=", "prop", ".", "proposal_boxes", "[", "0", ":", "box_size", "]", ".", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "prop_img", "=", "v_pred", ".", "get_image", "(", ")", "\n", "vis_img", "=", "np", ".", "concatenate", "(", "(", "anno_img", ",", "prop_img", ")", ",", "axis", "=", "1", ")", "\n", "vis_img", "=", "vis_img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "vis_name", "=", "\"Left: GT bounding boxes;  Right: Predicted proposals\"", "\n", "storage", ".", "put_image", "(", "vis_name", ",", "vis_img", ")", "\n", "break", "# only visualize one image in a batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.forward": [[122, 173], ["rcnn.GeneralizedRCNN.preprocess_image", "rcnn.GeneralizedRCNN.backbone", "rcnn.GeneralizedRCNN.roi_heads", "losses.update", "losses.update", "rcnn.GeneralizedRCNN.inference", "rcnn.GeneralizedRCNN.proposal_generator", "detectron2.utils.events.get_event_storage", "x[].to", "x[].to", "rcnn.GeneralizedRCNN.visualize_training"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.visualize_training"], ["", "", "def", "forward", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\n                Each item in the list contains the inputs for one image.\n                For now, each item in the list is a dict that contains:\n\n                * image: Tensor, image in (C, H, W) format.\n                * instances (optional): groundtruth :class:`Instances`\n                * proposals (optional): :class:`Instances`, precomputed proposals.\n\n                Other information that's included in the original dicts, such as:\n\n                * \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n\n        Returns:\n            list[dict]:\n                Each dict is the output for one input image.\n                The dict contains one key \"instances\" whose value is a :class:`Instances`.\n                The :class:`Instances` object has the following keys:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "self", ".", "proposal_generator", "is", "not", "None", ":", "\n", "            ", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances", ")", "\n", "", "else", ":", "\n", "            ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "proposal_losses", "=", "{", "}", "\n", "\n", "", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "gt_instances", ")", "\n", "if", "self", ".", "vis_period", ">", "0", ":", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "if", "storage", ".", "iter", "%", "self", ".", "vis_period", "==", "0", ":", "\n", "                ", "self", ".", "visualize_training", "(", "batched_inputs", ",", "proposals", ")", "\n", "\n", "", "", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.inference": [[174, 219], ["rcnn.GeneralizedRCNN.preprocess_image", "rcnn.GeneralizedRCNN.backbone", "rcnn.GeneralizedRCNN.roi_heads", "rcnn.GeneralizedRCNN.roi_heads.forward_with_given_boxes", "rcnn.GeneralizedRCNN._postprocess", "rcnn.GeneralizedRCNN.proposal_generator", "x.to", "torch.jit.is_scripting", "x[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.roi_head.DensePoseROIHeads.forward_with_given_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "inference", "(", "\n", "self", ",", "\n", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "detected_instances", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", "do_postprocess", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            detected_instances (None or list[Instances]): if not None, it\n                contains an `Instances` object per image. The `Instances`\n                object contains \"pred_boxes\" and \"pred_classes\" which are\n                known boxes in the image.\n                The inference will then skip the detection of bounding boxes,\n                and only predict other per-ROI outputs.\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            When do_postprocess=True, same as in :meth:`forward`.\n            Otherwise, a list[Instances] containing raw network outputs.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "if", "self", ".", "proposal_generator", "is", "not", "None", ":", "\n", "                ", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "results", ",", "_", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "detected_instances", "=", "[", "x", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "detected_instances", "]", "\n", "results", "=", "self", ".", "roi_heads", ".", "forward_with_given_boxes", "(", "features", ",", "detected_instances", ")", "\n", "\n", "", "if", "do_postprocess", ":", "\n", "            ", "assert", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ",", "\"Scripting is not supported for postprocess.\"", "\n", "return", "GeneralizedRCNN", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", "\n", "", "else", ":", "\n", "            ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN.preprocess_image": [[220, 228], ["detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "def", "preprocess_image", "(", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Normalize, pad and batch the input images.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.GeneralizedRCNN._postprocess": [[229, 244], ["zip", "input_per_image.get", "input_per_image.get", "postprocessing.detector_postprocess", "processed_results.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess"], ["", "@", "staticmethod", "\n", "def", "_postprocess", "(", "instances", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Rescale the output instances to the target size.\n        \"\"\"", "\n", "# note: private function; subject to changes", "\n", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "instances", ",", "batched_inputs", ",", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.ProposalNetwork.__init__": [[252, 273], ["torch.nn.Module.__init__", "rcnn.ProposalNetwork.register_buffer", "rcnn.ProposalNetwork.register_buffer", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "proposal_generator", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            proposal_generator: a module that generates proposals using backbone features\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "proposal_generator", "=", "proposal_generator", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.ProposalNetwork.from_config": [[274, 282], ["backbone.build_backbone.build_backbone", "proposal_generator.build_proposal_generator", "backbone.build_backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.build.build_proposal_generator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"proposal_generator\"", ":", "build_proposal_generator", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.ProposalNetwork.device": [[284, 287], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.rcnn.ProposalNetwork.forward": [[288, 328], ["detectron2.structures.ImageList.from_tensors", "rcnn.ProposalNetwork.backbone", "rcnn.ProposalNetwork.proposal_generator", "zip", "x[].to", "input_per_image.get", "input_per_image.get", "postprocessing.detector_postprocess", "processed_results.append", "x[].to", "detectron2.utils.logger.log_first_n", "x[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.log_first_n", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            Same as in :class:`GeneralizedRCNN.forward`\n\n        Returns:\n            list[dict]:\n                Each dict is the output for one input image.\n                The dict contains one key \"proposals\" whose value is a\n                :class:`Instances` with keys \"proposal_boxes\" and \"objectness_logits\".\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "elif", "\"targets\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "log_first_n", "(", "\n", "logging", ".", "WARN", ",", "\"'targets' in the model inputs is now renamed to 'instances'!\"", ",", "n", "=", "10", "\n", ")", "\n", "gt_instances", "=", "[", "x", "[", "\"targets\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances", ")", "\n", "# In training, the proposals are not useful at all but we generate them anyway.", "\n", "# This makes RPN-only models about 5% slower.", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "proposal_losses", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "proposals", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"proposals\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.__init__": [[48, 156], ["torch.nn.Module.__init__", "retinanet.RetinaNet.register_buffer", "retinanet.RetinaNet.register_buffer", "len", "len", "logger.warning", "torch.Tensor().view", "torch.Tensor().view", "retinanet.RetinaNet.backbone.output_shape", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", ")", "\n", "bbox_tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "'cls_tower'", ",", "nn", ".", "Sequential", "(", "*", "cls_tower", ")", ")", "\n", "self", ".", "add_module", "(", "'bbox_tower'", ",", "nn", ".", "Sequential", "(", "*", "bbox_tower", ")", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n", "\n", "# Initialization", "\n", "for", "modules", "in", "[", "self", ".", "cls_tower", ",", "self", ".", "bbox_tower", ",", "self", ".", "cls_logits", ",", "\n", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "\n", "# retinanet_bias_init", "\n", "", "", "", "prior_prob", "=", "cfg", ".", "MODEL", ".", "RETINANET", ".", "PRIOR_PROB", "\n", "bias_value", "=", "-", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_logits", ".", "bias", ",", "bias_value", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "for", "feature", "in", "x", ":", "\n", "            ", "logits", ".", "append", "(", "self", ".", "cls_logits", "(", "self", ".", "cls_tower", "(", "feature", ")", ")", ")", "\n", "bbox_reg", ".", "append", "(", "self", ".", "bbox_pred", "(", "self", ".", "bbox_tower", "(", "feature", ")", ")", ")", "\n", "", "return", "logits", ",", "bbox_reg", "\n", "\n", "\n", "", "", "class", "RetinaNetModule", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Module for RetinaNet computation. Takes feature maps from the backbone and\n    RetinaNet outputs and losses. Only Test on FPN now.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "RetinaNetModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "\n", "anchor_generator", "=", "make_anchor_generator_retinanet", "(", "cfg", ")", "\n", "head", "=", "RetinaNetHead", "(", "cfg", ",", "in_channels", ")", "\n", "box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "10.", ",", "10.", ",", "5.", ",", "5.", ")", ")", "\n", "\n", "box_selector_test", "=", "make_retinanet_postprocessor", "(", "cfg", ",", "box_coder", ",", "is_train", "=", "False", ")", "\n", "\n", "loss_evaluator", "=", "make_retinanet_loss_evaluator", "(", "cfg", ",", "box_coder", ")", "\n", "\n", "self", ".", "anchor_generator", "=", "anchor_generator", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "box_selector_test", "=", "box_selector_test", "\n", "self", ".", "loss_evaluator", "=", "loss_evaluator", "\n", "\n", "", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "targets", "=", "None", ",", "search", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (ImageList): images for which we want to compute the predictions\n            features (list[Tensor]): features computed from the images that are\n                used for computing the predictions. Each tensor in the list\n                correspond to different feature levels\n            targets (list[BoxList): ground-truth boxes present in the image (optional)\n\n        Returns:\n            boxes (list[BoxList]): the predicted boxes from the RPN, one BoxList per\n                image.\n            losses (dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"", "\n", "box_cls", ",", "box_regression", "=", "self", ".", "head", "(", "features", ")", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "images", ",", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_train", "(", "anchors", ",", "box_cls", ",", "box_regression", ",", "targets", ",", "search", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_test", "(", "anchors", ",", "box_cls", ",", "box_regression", ")", "\n", "\n", "", "", "def", "_forward_train", "(", "self", ",", "anchors", ",", "box_cls", ",", "box_regression", ",", "targets", ",", "search", "=", "False", ")", ":", "\n", "\n", "        ", "loss_box_cls", ",", "loss_box_reg", ",", "loss_scale", "=", "self", ".", "loss_evaluator", "(", "\n", "anchors", ",", "box_cls", ",", "box_regression", ",", "targets", ",", "search", "\n", ")", "\n", "losses", "=", "{", "\n", "\"loss_retina_cls\"", ":", "loss_box_cls", ",", "\n", "\"loss_retina_reg\"", ":", "loss_box_reg", ",", "\n", "}", "\n", "if", "search", ":", "\n", "            ", "return", "anchors", ",", "losses", ",", "loss_scale", "\n", "", "else", ":", "\n", "            ", "return", "anchors", ",", "losses", "\n", "\n", "", "", "def", "_forward_test", "(", "self", ",", "anchors", ",", "box_cls", ",", "box_regression", ")", ":", "\n", "        ", "boxes", "=", "self", ".", "box_selector_test", "(", "anchors", ",", "box_cls", ",", "box_regression", ")", "\n", "return", "boxes", ",", "{", "}", "\n", "\n", "\n", "", "", "def", "build_retinanet", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "RetinaNetModule", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.from_config": [[157, 191], ["backbone.build_backbone.build_backbone", "backbone.build_backbone.build_backbone.output_shape", "retinanet.RetinaNetHead", "anchor_generator.build_anchor_generator.build_anchor_generator", "box_regression.Box2BoxTransform", "matcher.Matcher"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.build_anchor_generator"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.device": [[193, 196], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.visualize_training": [[197, 231], ["detectron2.utils.events.get_event_storage", "detectron2.data.detection_utils.convert_image_to_rgb", "Visualizer", "v_gt.overlay_instances.overlay_instances.overlay_instances", "v_gt.overlay_instances.overlay_instances.get_image", "postprocessing.detector_postprocess", "postprocessing.detector_postprocess.pred_boxes.tensor.detach().cpu().numpy", "Visualizer", "v_pred.overlay_instances.overlay_instances.overlay_instances", "v_pred.overlay_instances.overlay_instances.get_image", "numpy.vstack", "vis_img.transpose.transpose.transpose", "detectron2.utils.events.get_event_storage.put_image", "len", "len", "detectron2.data.detection_utils.convert_image_to_rgb.permute", "postprocessing.detector_postprocess.pred_boxes.tensor.detach().cpu", "postprocessing.detector_postprocess.pred_boxes.tensor.detach"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.convert_image_to_rgb", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.get_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_image"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.forward": [[232, 291], ["retinanet.RetinaNet.preprocess_image", "retinanet.RetinaNet.backbone", "retinanet.RetinaNet.anchor_generator", "retinanet.RetinaNet.head", "retinanet.permute_to_N_HWA_K", "retinanet.permute_to_N_HWA_K", "retinanet.RetinaNet.label_anchors", "retinanet.RetinaNet.losses", "retinanet.RetinaNet.inference", "torch.jit.is_scripting", "zip", "torch.jit.is_scripting", "x[].to", "detectron2.utils.events.get_event_storage", "input_per_image.get", "input_per_image.get", "postprocessing.detector_postprocess", "processed_results.append", "retinanet.RetinaNet.inference", "retinanet.RetinaNet.visualize_training"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.label_anchors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.visualize_training"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.losses": [[292, 345], ["len", "torch.stack", "pos_mask.sum().item", "detectron2.utils.events.get_event_storage().put_scalar", "fvcore.nn.sigmoid_focal_loss_jit", "box_regression._dense_box_regression_loss", "torch.nn.functional.one_hot", "gt_labels_target.to", "pos_mask.sum", "detectron2.utils.events.get_event_storage", "max", "detectron2.layers.cat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression._dense_box_regression_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.label_anchors": [[347, 391], ["torch.no_grad", "detectron2.structures.Boxes.cat", "detectron2.structures.pairwise_iou", "retinanet.RetinaNet.anchor_matcher", "gt_labels.append", "matched_gt_boxes.append", "len", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.pairwise_iou"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.inference": [[392, 419], ["enumerate", "retinanet.RetinaNet.inference_single_image", "results.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference_single_image"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.inference_single_image": [[420, 487], ["zip", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "box_cls_i.flatten().sigmoid_", "min", "box_cls_i.flatten().sigmoid_.sort", "retinanet.RetinaNet.box2box_transform.apply_deltas", "boxes_all.append", "scores_all.append", "class_idxs_all.append", "detectron2.layers.cat", "detectron2.layers.nonzero_tuple", "topk_idxs.size", "box_cls_i.flatten"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.nonzero_tuple", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNet.preprocess_image": [[488, 496], ["detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNetHead.__init__": [[504, 570], ["torch.nn.Module.__init__", "zip", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "logger.warning", "cls_subnet.append", "cls_subnet.append", "bbox_subnet.append", "bbox_subnet.append", "modules.modules", "math.log", "list", "torch.nn.Conv2d", "cls_subnet.append", "torch.nn.ReLU", "torch.nn.Conv2d", "bbox_subnet.append", "torch.nn.ReLU", "isinstance", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "torch.nn.init.normal_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNetHead.from_config": [[571, 586], ["anchor_generator.build_anchor_generator", "len", "set"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.build_anchor_generator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.RetinaNetHead.forward": [[588, 610], ["logits.append", "bbox_reg.append", "retinanet.RetinaNetHead.cls_score", "retinanet.RetinaNetHead.bbox_pred", "retinanet.RetinaNetHead.cls_subnet", "retinanet.RetinaNetHead.bbox_subnet"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K": [[30, 40], ["tensor.reshape.view", "tensor.reshape.permute", "tensor.reshape.reshape", "tensor.reshape.dim"], "function", ["None"], ["cls_tower", "=", "[", "]", "\n", "bbox_tower", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CONVS", ")", ":", "\n", "            ", "cls_tower", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model": [[16, 26], ["model.to", "detectron2.utils.logger._log_api_usage", "META_ARCH_REGISTRY.get", "torch.device"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger._log_api_usage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["\n", "\n", "def", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "dataset_catalog", ",", "is_train", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.PanopticFPN.__init__": [[26, 55], ["rcnn.GeneralizedRCNN.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "sem_seg_head", ":", "nn", ".", "Module", ",", "\n", "combine_overlap_thresh", ":", "float", "=", "0.5", ",", "\n", "combine_stuff_area_thresh", ":", "float", "=", "4096", ",", "\n", "combine_instances_score_thresh", ":", "float", "=", "0.5", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            sem_seg_head: a module for the semantic segmentation head.\n            combine_overlap_thresh: combine masks into one instances if\n                they have enough overlap\n            combine_stuff_area_thresh: ignore stuff areas smaller than this threshold\n            combine_instances_score_thresh: ignore instances whose score is\n                smaller than this threshold\n\n        Other arguments are the same as :class:`GeneralizedRCNN`.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "sem_seg_head", "=", "sem_seg_head", "\n", "# options when combining instance & semantic outputs", "\n", "self", ".", "combine_overlap_thresh", "=", "combine_overlap_thresh", "\n", "self", ".", "combine_stuff_area_thresh", "=", "combine_stuff_area_thresh", "\n", "self", ".", "combine_instances_score_thresh", "=", "combine_instances_score_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.PanopticFPN.from_config": [[56, 89], ["super().from_config", "super().from_config.update", "semantic_seg.build_sem_seg_head", "logging.getLogger", "ret[].output_shape", "logging.getLogger.warning", "logging.getLogger.warning", "panoptic_fpn.PanopticFPN.from_config.update_weight"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.build_sem_seg_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ")", "\n", "ret", ".", "update", "(", "\n", "{", "\n", "\"combine_overlap_thresh\"", ":", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "OVERLAP_THRESH", ",", "\n", "\"combine_stuff_area_thresh\"", ":", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "STUFF_AREA_LIMIT", ",", "\n", "\"combine_instances_score_thresh\"", ":", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "INSTANCES_CONFIDENCE_THRESH", ",", "# noqa", "\n", "}", "\n", ")", "\n", "ret", "[", "\"sem_seg_head\"", "]", "=", "build_sem_seg_head", "(", "cfg", ",", "ret", "[", "\"backbone\"", "]", ".", "output_shape", "(", ")", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "not", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "COMBINE", ".", "ENABLED", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"PANOPTIC_FPN.COMBINED.ENABLED is no longer used. \"", "\n", "\" model.inference(do_postprocess=) should be used to toggle postprocessing.\"", "\n", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "INSTANCE_LOSS_WEIGHT", "!=", "1.0", ":", "\n", "            ", "w", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_FPN", ".", "INSTANCE_LOSS_WEIGHT", "\n", "logger", ".", "warning", "(", "\n", "\"PANOPTIC_FPN.INSTANCE_LOSS_WEIGHT should be replaced by weights on each ROI head.\"", "\n", ")", "\n", "\n", "def", "update_weight", "(", "x", ")", ":", "\n", "                ", "if", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "                    ", "return", "{", "k", ":", "v", "*", "w", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "                    ", "return", "x", "*", "w", "\n", "\n", "", "", "roi_heads", "=", "ret", "[", "\"roi_heads\"", "]", "\n", "roi_heads", ".", "box_predictor", ".", "loss_weight", "=", "update_weight", "(", "roi_heads", ".", "box_predictor", ".", "loss_weight", ")", "\n", "roi_heads", ".", "mask_head", ".", "loss_weight", "=", "update_weight", "(", "roi_heads", ".", "mask_head", ".", "loss_weight", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.PanopticFPN.forward": [[90, 136], ["panoptic_fpn.PanopticFPN.preprocess_image", "panoptic_fpn.PanopticFPN.backbone", "panoptic_fpn.PanopticFPN.sem_seg_head", "panoptic_fpn.PanopticFPN.proposal_generator", "panoptic_fpn.PanopticFPN.roi_heads", "losses.update", "losses.update", "panoptic_fpn.PanopticFPN.inference", "x[].to", "detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n\n                For now, each item in the list is a dict that contains:\n\n                * \"image\": Tensor, image in (C, H, W) format.\n                * \"instances\": Instances\n                * \"sem_seg\": semantic segmentation ground truth.\n                * Other information that's included in the original dicts, such as:\n                  \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n\n        Returns:\n            list[dict]:\n                each dict has the results for one image. The dict contains the following keys:\n\n                * \"instances\": see :meth:`GeneralizedRCNN.forward` for its format.\n                * \"sem_seg\": see :meth:`SemanticSegmentor.forward` for its format.\n                * \"panoptic_seg\": See the return value of\n                  :func:`combine_semantic_and_instance_outputs` for its format.\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "assert", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", "\n", "gt_sem_seg", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "gt_sem_seg", "=", "ImageList", ".", "from_tensors", "(", "\n", "gt_sem_seg", ",", "self", ".", "backbone", ".", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "sem_seg_results", ",", "sem_seg_losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "gt_sem_seg", ")", "\n", "\n", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances", ")", "\n", "detector_results", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "features", ",", "proposals", ",", "gt_instances", "\n", ")", "\n", "\n", "losses", "=", "sem_seg_losses", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.PanopticFPN.inference": [[137, 181], ["panoptic_fpn.PanopticFPN.preprocess_image", "panoptic_fpn.PanopticFPN.backbone", "panoptic_fpn.PanopticFPN.sem_seg_head", "panoptic_fpn.PanopticFPN.proposal_generator", "panoptic_fpn.PanopticFPN.roi_heads", "zip", "input_per_image.get", "input_per_image.get", "postprocessing.sem_seg_postprocess", "postprocessing.detector_postprocess", "processed_results.append", "panoptic_fpn.combine_semantic_and_instance_outputs", "postprocessing.sem_seg_postprocess.argmax"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs"], ["", "def", "inference", "(", "\n", "self", ",", "batched_inputs", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "do_postprocess", ":", "bool", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            When do_postprocess=True, see docs in :meth:`forward`.\n            Otherwise, returns a (list[Instances], list[Tensor]) that contains\n            the raw detector outputs, and raw semantic segmentation outputs.\n        \"\"\"", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "sem_seg_results", ",", "sem_seg_losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "None", ")", "\n", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "None", ")", "\n", "detector_results", ",", "_", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "\n", "if", "do_postprocess", ":", "\n", "            ", "processed_results", "=", "[", "]", "\n", "for", "sem_seg_result", ",", "detector_result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "sem_seg_results", ",", "detector_results", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "                ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "sem_seg_r", "=", "sem_seg_postprocess", "(", "sem_seg_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "detector_r", "=", "detector_postprocess", "(", "detector_result", ",", "height", ",", "width", ")", "\n", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "sem_seg_r", ",", "\"instances\"", ":", "detector_r", "}", ")", "\n", "\n", "panoptic_r", "=", "combine_semantic_and_instance_outputs", "(", "\n", "detector_r", ",", "\n", "sem_seg_r", ".", "argmax", "(", "dim", "=", "0", ")", ",", "\n", "self", ".", "combine_overlap_thresh", ",", "\n", "self", ".", "combine_stuff_area_thresh", ",", "\n", "self", ".", "combine_instances_score_thresh", ",", "\n", ")", "\n", "processed_results", "[", "-", "1", "]", "[", "\"panoptic_seg\"", "]", "=", "panoptic_r", "\n", "", "return", "processed_results", "\n", "", "else", ":", "\n", "            ", "return", "detector_results", ",", "sem_seg_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs": [[183, 269], ["torch.zeros_like", "torch.argsort", "instance_results.pred_masks.to", "torch.unique().cpu().tolist", "instance_results.scores[].item", "mask.sum().item", "intersect.sum().item", "segments_info.append", "mask.sum().item", "segments_info.append", "torch.unique().cpu", "mask.sum", "intersect.sum", "instance_results.pred_classes[].item", "inst_id.item", "mask.sum", "torch.unique"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "", "def", "combine_semantic_and_instance_outputs", "(", "\n", "instance_results", ",", "\n", "semantic_results", ",", "\n", "overlap_threshold", ",", "\n", "stuff_area_thresh", ",", "\n", "instances_score_thresh", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Implement a simple combining logic following\n    \"combine_semantic_and_instance_predictions.py\" in panopticapi\n    to produce panoptic segmentation outputs.\n\n    Args:\n        instance_results: output of :func:`detector_postprocess`.\n        semantic_results: an (H, W) tensor, each element is the contiguous semantic\n            category id\n\n    Returns:\n        panoptic_seg (Tensor): of shape (height, width) where the values are ids for each segment.\n        segments_info (list[dict]): Describe each segment in `panoptic_seg`.\n            Each dict contains keys \"id\", \"category_id\", \"isthing\".\n    \"\"\"", "\n", "panoptic_seg", "=", "torch", ".", "zeros_like", "(", "semantic_results", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "\n", "# sort instance outputs by scores", "\n", "sorted_inds", "=", "torch", ".", "argsort", "(", "-", "instance_results", ".", "scores", ")", "\n", "\n", "current_segment_id", "=", "0", "\n", "segments_info", "=", "[", "]", "\n", "\n", "instance_masks", "=", "instance_results", ".", "pred_masks", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "panoptic_seg", ".", "device", ")", "\n", "\n", "# Add instances one-by-one, check for overlaps with existing ones", "\n", "for", "inst_id", "in", "sorted_inds", ":", "\n", "        ", "score", "=", "instance_results", ".", "scores", "[", "inst_id", "]", ".", "item", "(", ")", "\n", "if", "score", "<", "instances_score_thresh", ":", "\n", "            ", "break", "\n", "", "mask", "=", "instance_masks", "[", "inst_id", "]", "# H,W", "\n", "mask_area", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "mask_area", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "intersect", "=", "(", "mask", ">", "0", ")", "&", "(", "panoptic_seg", ">", "0", ")", "\n", "intersect_area", "=", "intersect", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "intersect_area", "*", "1.0", "/", "mask_area", ">", "overlap_threshold", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "intersect_area", ">", "0", ":", "\n", "            ", "mask", "=", "mask", "&", "(", "panoptic_seg", "==", "0", ")", "\n", "\n", "", "current_segment_id", "+=", "1", "\n", "panoptic_seg", "[", "mask", "]", "=", "current_segment_id", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "current_segment_id", ",", "\n", "\"isthing\"", ":", "True", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"category_id\"", ":", "instance_results", ".", "pred_classes", "[", "inst_id", "]", ".", "item", "(", ")", ",", "\n", "\"instance_id\"", ":", "inst_id", ".", "item", "(", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# Add semantic results to remaining empty areas", "\n", "", "semantic_labels", "=", "torch", ".", "unique", "(", "semantic_results", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "for", "semantic_label", "in", "semantic_labels", ":", "\n", "        ", "if", "semantic_label", "==", "0", ":", "# 0 is a special \"thing\" class", "\n", "            ", "continue", "\n", "", "mask", "=", "(", "semantic_results", "==", "semantic_label", ")", "&", "(", "panoptic_seg", "==", "0", ")", "\n", "mask_area", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "mask_area", "<", "stuff_area_thresh", ":", "\n", "            ", "continue", "\n", "\n", "", "current_segment_id", "+=", "1", "\n", "panoptic_seg", "[", "mask", "]", "=", "current_segment_id", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "current_segment_id", ",", "\n", "\"isthing\"", ":", "False", ",", "\n", "\"category_id\"", ":", "semantic_label", ",", "\n", "\"area\"", ":", "mask_area", ",", "\n", "}", "\n", ")", "\n", "\n", "", "return", "panoptic_seg", ",", "segments_info", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemanticSegmentor.__init__": [[34, 55], ["torch.nn.Module.__init__", "semantic_seg.SemanticSegmentor.register_buffer", "semantic_seg.SemanticSegmentor.register_buffer", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "sem_seg_head", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            sem_seg_head: a module that predicts semantic segmentation from backbone features\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "sem_seg_head", "=", "sem_seg_head", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemanticSegmentor.from_config": [[56, 65], ["backbone.build_backbone.build_backbone", "semantic_seg.build_sem_seg_head", "backbone.build_backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.build_sem_seg_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "sem_seg_head", "=", "build_sem_seg_head", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"sem_seg_head\"", ":", "sem_seg_head", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemanticSegmentor.device": [[67, 70], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemanticSegmentor.forward": [[71, 120], ["detectron2.structures.ImageList.from_tensors", "semantic_seg.SemanticSegmentor.backbone", "semantic_seg.SemanticSegmentor.sem_seg_head", "zip", "x[].to", "input_per_image.get", "input_per_image.get", "postprocessing.sem_seg_postprocess", "processed_results.append", "x[].to", "detectron2.structures.ImageList.from_tensors"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n\n                For now, each item in the list is a dict that contains:\n\n                   * \"image\": Tensor, image in (C, H, W) format.\n                   * \"sem_seg\": semantic segmentation ground truth\n                   * Other information that's included in the original dicts, such as:\n                     \"height\", \"width\" (int): the output resolution of the model (may be different\n                     from input resolution), used in inference.\n\n\n        Returns:\n            list[dict]:\n              Each dict is the output for one input image.\n              The dict contains one key \"sem_seg\" whose value is a\n              Tensor that represents the\n              per-pixel segmentation prediced by the head.\n              The prediction has shape KxHxW that represents the logits of\n              each class for each pixel.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "targets", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "targets", "=", "ImageList", ".", "from_tensors", "(", "\n", "targets", ",", "self", ".", "backbone", ".", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "targets", "=", "None", "\n", "", "results", ",", "losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "targets", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "losses", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ")", "\n", "r", "=", "sem_seg_postprocess", "(", "result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemSegFPNHead.__init__": [[140, 202], ["torch.nn.Module.__init__", "sorted", "zip", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "sorted.items", "max", "range", "semantic_seg.SemSegFPNHead.scale_heads.append", "semantic_seg.SemSegFPNHead.add_module", "int", "detectron2.layers.get_norm", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "head_ops.append", "torch.nn.Sequential", "head_ops.append", "numpy.log2", "numpy.log2", "torch.nn.Upsample"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ",", "\n", "*", ",", "\n", "num_classes", ":", "int", ",", "\n", "conv_dims", ":", "int", ",", "\n", "common_stride", ":", "int", ",", "\n", "loss_weight", ":", "float", "=", "1.0", ",", "\n", "norm", ":", "Optional", "[", "Union", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "ignore_value", ":", "int", "=", "-", "1", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape: shapes (channels and stride) of the input features\n            num_classes: number of classes to predict\n            conv_dims: number of output channels for the intermediate conv layers.\n            common_stride: the common stride that all features will be upscaled to\n            loss_weight: loss weight\n            norm (str or callable): normalization for all conv layers\n            ignore_value: category id to be ignored during training.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "input_shape", "=", "sorted", "(", "input_shape", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ".", "stride", ")", "\n", "self", ".", "in_features", "=", "[", "k", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "feature_strides", "=", "[", "v", ".", "stride", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "feature_channels", "=", "[", "v", ".", "channels", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "\n", "self", ".", "ignore_value", "=", "ignore_value", "\n", "self", ".", "common_stride", "=", "common_stride", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n", "self", ".", "scale_heads", "=", "[", "]", "\n", "for", "in_feature", ",", "stride", ",", "channels", "in", "zip", "(", "\n", "self", ".", "in_features", ",", "feature_strides", ",", "feature_channels", "\n", ")", ":", "\n", "            ", "head_ops", "=", "[", "]", "\n", "head_length", "=", "max", "(", "1", ",", "int", "(", "np", ".", "log2", "(", "stride", ")", "-", "np", ".", "log2", "(", "self", ".", "common_stride", ")", ")", ")", "\n", "for", "k", "in", "range", "(", "head_length", ")", ":", "\n", "                ", "norm_module", "=", "get_norm", "(", "norm", ",", "conv_dims", ")", "\n", "conv", "=", "Conv2d", "(", "\n", "channels", "if", "k", "==", "0", "else", "conv_dims", ",", "\n", "conv_dims", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "norm", ",", "\n", "norm", "=", "norm_module", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "conv", ")", "\n", "head_ops", ".", "append", "(", "conv", ")", "\n", "if", "stride", "!=", "self", ".", "common_stride", ":", "\n", "                    ", "head_ops", ".", "append", "(", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", ")", "\n", "", "", "self", ".", "scale_heads", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "head_ops", ")", ")", "\n", "self", ".", "add_module", "(", "in_feature", ",", "self", ".", "scale_heads", "[", "-", "1", "]", ")", "\n", "", "self", ".", "predictor", "=", "Conv2d", "(", "conv_dims", ",", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "predictor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemSegFPNHead.from_config": [[203, 215], ["input_shape.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "return", "{", "\n", "\"input_shape\"", ":", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input_shape", ".", "items", "(", ")", "if", "k", "in", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IN_FEATURES", "\n", "}", ",", "\n", "\"ignore_value\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IGNORE_VALUE", ",", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NUM_CLASSES", ",", "\n", "\"conv_dims\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "CONVS_DIM", ",", "\n", "\"common_stride\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "COMMON_STRIDE", ",", "\n", "\"norm\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NORM", ",", "\n", "\"loss_weight\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "LOSS_WEIGHT", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemSegFPNHead.forward": [[217, 231], ["semantic_seg.SemSegFPNHead.layers", "torch.nn.functional.interpolate", "semantic_seg.SemSegFPNHead.losses"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses"], ["", "def", "forward", "(", "self", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            In training, returns (None, dict of losses)\n            In inference, returns (CxHxW logits, {})\n        \"\"\"", "\n", "x", "=", "self", ".", "layers", "(", "features", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "None", ",", "self", ".", "losses", "(", "x", ",", "targets", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "\n", "x", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "return", "x", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemSegFPNHead.layers": [[232, 240], ["enumerate", "semantic_seg.SemSegFPNHead.predictor"], "methods", ["None"], ["", "", "def", "layers", "(", "self", ",", "features", ")", ":", "\n", "        ", "for", "i", ",", "f", "in", "enumerate", "(", "self", ".", "in_features", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "x", "=", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "f", "]", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "+", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "f", "]", ")", "\n", "", "", "x", "=", "self", ".", "predictor", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.SemSegFPNHead.losses": [[241, 251], ["torch.nn.functional.interpolate.float", "torch.nn.functional.interpolate", "torch.nn.functional.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy"], ["", "def", "losses", "(", "self", ",", "predictions", ",", "targets", ")", ":", "\n", "        ", "predictions", "=", "predictions", ".", "float", "(", ")", "# https://github.com/pytorch/pytorch/issues/48163", "\n", "predictions", "=", "F", ".", "interpolate", "(", "\n", "predictions", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "predictions", ",", "targets", ",", "reduction", "=", "\"mean\"", ",", "ignore_index", "=", "self", ".", "ignore_value", "\n", ")", "\n", "losses", "=", "{", "\"loss_sem_seg\"", ":", "loss", "*", "self", ".", "loss_weight", "}", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.build_sem_seg_head": [[122, 128], ["SEM_SEG_HEADS_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "build_sem_seg_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a semantic segmentation head from `cfg.MODEL.SEM_SEG_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NAME", "\n", "return", "SEM_SEG_HEADS_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils._is_tracing": [[14, 20], ["torch.jit.is_scripting", "torch.jit.is_tracing"], "function", ["None"], ["def", "_is_tracing", "(", ")", ":", "\n", "    ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "# https://github.com/pytorch/pytorch/issues/47379", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "TORCH_VERSION", ">=", "(", "1", ",", "7", ")", "and", "torch", ".", "jit", ".", "is_tracing", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.find_top_rpn_proposals": [[22, 131], ["len", "torch.arange", "enumerate", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "enumerate", "zip", "isinstance", "logits_i.sort", "logits_i.narrow", "idx.narrow", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.structures.Boxes", "detectron2.structures.Boxes.clip", "detectron2.structures.Boxes.nonempty", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "results.append", "torch.clamp", "min", "torch.full", "torch.isfinite().all", "torch.isfinite", "valid_mask.all", "proposal_utils._is_tracing", "FloatingPointError", "detectron2.layers.batched_nms.sum().item", "len", "torch.isfinite", "detectron2.layers.batched_nms.sum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils._is_tracing"], ["", "", "def", "find_top_rpn_proposals", "(", "\n", "proposals", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "pred_objectness_logits", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "image_sizes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "nms_thresh", ":", "float", ",", "\n", "pre_nms_topk", ":", "int", ",", "\n", "post_nms_topk", ":", "int", ",", "\n", "min_box_size", ":", "float", ",", "\n", "training", ":", "bool", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    For each feature map, select the `pre_nms_topk` highest scoring proposals,\n    apply NMS, clip proposals, and remove small boxes. Return the `post_nms_topk`\n    highest scoring proposals among all the feature maps for each image.\n\n    Args:\n        proposals (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A, 4).\n            All proposal predictions on the feature maps.\n        pred_objectness_logits (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A).\n        image_sizes (list[tuple]): sizes (h, w) for each image\n        nms_thresh (float): IoU threshold to use for NMS\n        pre_nms_topk (int): number of top k scoring proposals to keep before applying NMS.\n            When RPN is run on multiple feature maps (as in FPN) this number is per\n            feature map.\n        post_nms_topk (int): number of top k scoring proposals to keep after applying NMS.\n            When RPN is run on multiple feature maps (as in FPN) this number is total,\n            over all feature maps.\n        min_box_size (float): minimum proposal box side length in pixels (absolute units\n            wrt input images).\n        training (bool): True if proposals are to be used in training, otherwise False.\n            This arg exists only to support a legacy bug; look for the \"NB: Legacy bug ...\"\n            comment.\n\n    Returns:\n        list[Instances]: list of N Instances. The i-th Instances\n            stores post_nms_topk object proposals for image i, sorted by their\n            objectness score in descending order.\n    \"\"\"", "\n", "num_images", "=", "len", "(", "image_sizes", ")", "\n", "device", "=", "proposals", "[", "0", "]", ".", "device", "\n", "\n", "# 1. Select top-k anchor for every level and every image", "\n", "topk_scores", "=", "[", "]", "# #lvl Tensor, each of shape N x topk", "\n", "topk_proposals", "=", "[", "]", "\n", "level_ids", "=", "[", "]", "# #lvl Tensor, each of shape (topk,)", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "num_images", ",", "device", "=", "device", ")", "\n", "for", "level_id", ",", "(", "proposals_i", ",", "logits_i", ")", "in", "enumerate", "(", "zip", "(", "proposals", ",", "pred_objectness_logits", ")", ")", ":", "\n", "        ", "Hi_Wi_A", "=", "logits_i", ".", "shape", "[", "1", "]", "\n", "if", "isinstance", "(", "Hi_Wi_A", ",", "torch", ".", "Tensor", ")", ":", "# it's a tensor in tracing", "\n", "            ", "num_proposals_i", "=", "torch", ".", "clamp", "(", "Hi_Wi_A", ",", "max", "=", "pre_nms_topk", ")", "\n", "", "else", ":", "\n", "            ", "num_proposals_i", "=", "min", "(", "Hi_Wi_A", ",", "pre_nms_topk", ")", "\n", "\n", "# sort is faster than topk: https://github.com/pytorch/pytorch/issues/22812", "\n", "# topk_scores_i, topk_idx = logits_i.topk(num_proposals_i, dim=1)", "\n", "", "logits_i", ",", "idx", "=", "logits_i", ".", "sort", "(", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "topk_scores_i", "=", "logits_i", ".", "narrow", "(", "1", ",", "0", ",", "num_proposals_i", ")", "\n", "topk_idx", "=", "idx", ".", "narrow", "(", "1", ",", "0", ",", "num_proposals_i", ")", "\n", "\n", "# each is N x topk", "\n", "topk_proposals_i", "=", "proposals_i", "[", "batch_idx", "[", ":", ",", "None", "]", ",", "topk_idx", "]", "# N x topk x 4", "\n", "\n", "topk_proposals", ".", "append", "(", "topk_proposals_i", ")", "\n", "topk_scores", ".", "append", "(", "topk_scores_i", ")", "\n", "level_ids", ".", "append", "(", "torch", ".", "full", "(", "(", "num_proposals_i", ",", ")", ",", "level_id", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", ")", "\n", "\n", "# 2. Concat all levels together", "\n", "", "topk_scores", "=", "cat", "(", "topk_scores", ",", "dim", "=", "1", ")", "\n", "topk_proposals", "=", "cat", "(", "topk_proposals", ",", "dim", "=", "1", ")", "\n", "level_ids", "=", "cat", "(", "level_ids", ",", "dim", "=", "0", ")", "\n", "\n", "# 3. For each image, run a per-level NMS, and choose topk results.", "\n", "results", ":", "List", "[", "Instances", "]", "=", "[", "]", "\n", "for", "n", ",", "image_size", "in", "enumerate", "(", "image_sizes", ")", ":", "\n", "        ", "boxes", "=", "Boxes", "(", "topk_proposals", "[", "n", "]", ")", "\n", "scores_per_img", "=", "topk_scores", "[", "n", "]", "\n", "lvl", "=", "level_ids", "\n", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ".", "tensor", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores_per_img", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "            ", "if", "training", ":", "\n", "                ", "raise", "FloatingPointError", "(", "\n", "\"Predicted boxes or scores contain Inf/NaN. Training has diverged.\"", "\n", ")", "\n", "", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores_per_img", "=", "scores_per_img", "[", "valid_mask", "]", "\n", "lvl", "=", "lvl", "[", "valid_mask", "]", "\n", "", "boxes", ".", "clip", "(", "image_size", ")", "\n", "\n", "# filter empty boxes", "\n", "keep", "=", "boxes", ".", "nonempty", "(", "threshold", "=", "min_box_size", ")", "\n", "if", "_is_tracing", "(", ")", "or", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "len", "(", "boxes", ")", ":", "\n", "            ", "boxes", ",", "scores_per_img", ",", "lvl", "=", "boxes", "[", "keep", "]", ",", "scores_per_img", "[", "keep", "]", ",", "lvl", "[", "keep", "]", "\n", "\n", "", "keep", "=", "batched_nms", "(", "boxes", ".", "tensor", ",", "scores_per_img", ",", "lvl", ",", "nms_thresh", ")", "\n", "# In Detectron1, there was different behavior during training vs. testing.", "\n", "# (https://github.com/facebookresearch/Detectron/issues/459)", "\n", "# During training, topk is over the proposals from *all* images in the training batch.", "\n", "# During testing, it is over the proposals for each image separately.", "\n", "# As a result, the training behavior becomes batch-dependent,", "\n", "# and the configuration \"POST_NMS_TOPK_TRAIN\" end up relying on the batch size.", "\n", "# This bug is addressed in Detectron2 to make the behavior independent of batch size.", "\n", "keep", "=", "keep", "[", ":", "post_nms_topk", "]", "# keep is already sorted", "\n", "\n", "res", "=", "Instances", "(", "image_size", ")", "\n", "res", ".", "proposal_boxes", "=", "boxes", "[", "keep", "]", "\n", "res", ".", "objectness_logits", "=", "scores_per_img", "[", "keep", "]", "\n", "results", ".", "append", "(", "res", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.add_ground_truth_to_proposals": [[133, 156], ["len", "len", "len", "proposal_utils.add_ground_truth_to_proposals_single_image", "zip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.add_ground_truth_to_proposals_single_image"], ["", "def", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", ":", "\n", "    ", "\"\"\"\n    Call `add_ground_truth_to_proposals_single_image` for all images.\n\n    Args:\n        gt_boxes(list[Boxes]): list of N elements. Element i is a Boxes\n            representing the gound-truth for image i.\n        proposals (list[Instances]): list of N elements. Element i is a Instances\n            representing the proposals for image i.\n\n    Returns:\n        list[Instances]: list of N Instances. Each is the proposals for the image,\n            with field \"proposal_boxes\" and \"objectness_logits\".\n    \"\"\"", "\n", "assert", "gt_boxes", "is", "not", "None", "\n", "\n", "assert", "len", "(", "proposals", ")", "==", "len", "(", "gt_boxes", ")", "\n", "if", "len", "(", "proposals", ")", "==", "0", ":", "\n", "        ", "return", "proposals", "\n", "\n", "", "return", "[", "\n", "add_ground_truth_to_proposals_single_image", "(", "gt_boxes_i", ",", "proposals_i", ")", "\n", "for", "gt_boxes_i", ",", "proposals_i", "in", "zip", "(", "gt_boxes", ",", "proposals", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.add_ground_truth_to_proposals_single_image": [[159, 183], ["math.log", "detectron2.structures.Instances", "detectron2.structures.Instances.cat", "torch.ones", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "add_ground_truth_to_proposals_single_image", "(", "gt_boxes", ",", "proposals", ")", ":", "\n", "    ", "\"\"\"\n    Augment `proposals` with ground-truth boxes from `gt_boxes`.\n\n    Args:\n        Same as `add_ground_truth_to_proposals`, but with gt_boxes and proposals\n        per image.\n\n    Returns:\n        Same as `add_ground_truth_to_proposals`, but for only one image.\n    \"\"\"", "\n", "device", "=", "proposals", ".", "objectness_logits", ".", "device", "\n", "# Assign all ground-truth boxes an objectness logit corresponding to", "\n", "# P(object) = sigmoid(logit) =~ 1.", "\n", "gt_logit_value", "=", "math", ".", "log", "(", "(", "1.0", "-", "1e-10", ")", "/", "(", "1", "-", "(", "1.0", "-", "1e-10", ")", ")", ")", "\n", "gt_logits", "=", "gt_logit_value", "*", "torch", ".", "ones", "(", "len", "(", "gt_boxes", ")", ",", "device", "=", "device", ")", "\n", "\n", "# Concatenating gt_boxes with proposals requires them to have the same fields", "\n", "gt_proposal", "=", "Instances", "(", "proposals", ".", "image_size", ")", "\n", "gt_proposal", ".", "proposal_boxes", "=", "gt_boxes", "\n", "gt_proposal", ".", "objectness_logits", "=", "gt_logits", "\n", "new_proposals", "=", "Instances", ".", "cat", "(", "[", "proposals", ",", "gt_proposal", "]", ")", "\n", "\n", "return", "new_proposals", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.StandardRPNHead.__init__": [[75, 125], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "rpn.StandardRPNHead.modules", "len", "rpn.StandardRPNHead._get_rpn_conv", "torch.nn.Sequential", "torch.nn.Sequential", "enumerate", "isinstance", "rpn.StandardRPNHead._get_rpn_conv", "rpn.StandardRPNHead.conv.add_module", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.StandardRPNHead._get_rpn_conv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.StandardRPNHead._get_rpn_conv"], ["", "", "@", "registry", ".", "RPN_HEADS", ".", "register", "(", "\"SingleConvRPNHead\"", ")", "\n", "class", "RPNHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Adds a simple RPN Head with classification and regression heads\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ",", "num_anchors", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            cfg              : config\n            in_channels (int): number of channels of the input feature\n            num_anchors (int): number of anchors to be predicted\n        \"\"\"", "\n", "super", "(", "RPNHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "num_anchors", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", "\n", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv", ",", "self", ".", "cls_logits", ",", "self", ".", "bbox_pred", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "bbox_reg", "=", "[", "]", "\n", "for", "feature", "in", "x", ":", "\n", "            ", "t", "=", "F", ".", "relu", "(", "self", ".", "conv", "(", "feature", ")", ")", "\n", "logits", ".", "append", "(", "self", ".", "cls_logits", "(", "t", ")", ")", "\n", "bbox_reg", ".", "append", "(", "self", ".", "bbox_pred", "(", "t", ")", ")", "\n", "", "return", "logits", ",", "bbox_reg", "\n", "\n", "\n", "", "", "class", "RPNModule", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Module for RPN computation. Takes feature maps from the backbone and outputs \n    RPN proposals and losses. Works for both FPN and non-FPN.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "RPNModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "\n", "anchor_generator", "=", "make_anchor_generator", "(", "cfg", ")", "\n", "\n", "rpn_head", "=", "registry", ".", "RPN_HEADS", "[", "cfg", ".", "MODEL", ".", "RPN", ".", "RPN_HEAD", "]", "\n", "head", "=", "rpn_head", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.StandardRPNHead._get_rpn_conv": [[126, 134], ["detectron2.layers.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["None"], ["cfg", ",", "in_channels", ",", "anchor_generator", ".", "num_anchors_per_location", "(", ")", "[", "0", "]", "\n", ")", "\n", "\n", "rpn_box_coder", "=", "BoxCoder", "(", "weights", "=", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "\n", "box_selector_train", "=", "make_rpn_postprocessor", "(", "cfg", ",", "rpn_box_coder", ",", "is_train", "=", "True", ")", "\n", "box_selector_test", "=", "make_rpn_postprocessor", "(", "cfg", ",", "rpn_box_coder", ",", "is_train", "=", "False", ")", "\n", "\n", "loss_evaluator", "=", "make_rpn_loss_evaluator", "(", "cfg", ",", "rpn_box_coder", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.StandardRPNHead.from_config": [[136, 156], ["anchor_generator.build_anchor_generator.build_anchor_generator", "len", "len", "set", "set"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.build_anchor_generator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["self", ".", "anchor_generator", "=", "anchor_generator", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "box_selector_train", "=", "box_selector_train", "\n", "self", ".", "box_selector_test", "=", "box_selector_test", "\n", "self", ".", "loss_evaluator", "=", "loss_evaluator", "\n", "\n", "", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (ImageList): images for which we want to compute the predictions\n            features (list[Tensor]): features computed from the images that are\n                used for computing the predictions. Each tensor in the list\n                correspond to different feature levels\n            targets (list[BoxList): ground-truth boxes present in the image (optional)\n\n        Returns:\n            boxes (list[BoxList]): the predicted boxes from the RPN, one BoxList per\n                image.\n            losses (dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.StandardRPNHead.forward": [[158, 178], ["rpn.StandardRPNHead.conv", "pred_objectness_logits.append", "pred_anchor_deltas.append", "rpn.StandardRPNHead.objectness_logits", "rpn.StandardRPNHead.anchor_deltas"], "methods", ["None"], ["anchors", "=", "self", ".", "anchor_generator", "(", "images", ",", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_train", "(", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_test", "(", "anchors", ",", "objectness", ",", "rpn_box_regression", ")", "\n", "\n", "", "", "def", "_forward_train", "(", "self", ",", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "MODEL", ".", "RPN_ONLY", ":", "\n", "# When training an RPN-only model, the loss is determined by the", "\n", "# predicted objectness and rpn_box_regression values and there is", "\n", "# no need to transform the anchors into predicted boxes; this is an", "\n", "# optimization that avoids the unnecessary transformation.", "\n", "            ", "boxes", "=", "anchors", "\n", "", "else", ":", "\n", "# For end-to-end models, anchors must be transformed into boxes and", "\n", "# sampled into a training batch.", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "boxes", "=", "self", ".", "box_selector_train", "(", "\n", "anchors", ",", "objectness", ",", "rpn_box_regression", ",", "targets", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN.__init__": [[186, 257], ["torch.nn.Module.__init__", "float", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["return", "boxes", ",", "losses", "\n", "\n", "", "def", "_forward_test", "(", "self", ",", "anchors", ",", "objectness", ",", "rpn_box_regression", ")", ":", "\n", "        ", "boxes", "=", "self", ".", "box_selector_test", "(", "anchors", ",", "objectness", ",", "rpn_box_regression", ")", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "RPN_ONLY", ":", "\n", "# For end-to-end models, the RPN proposals are an intermediate state", "\n", "# and don't bother to sort them in decreasing score order. For RPN-only", "\n", "# models, the proposals are the final output and we return them in", "\n", "# high-to-low confidence order.", "\n", "            ", "inds", "=", "[", "\n", "box", ".", "get_field", "(", "\"objectness\"", ")", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "for", "box", "in", "boxes", "\n", "]", "\n", "boxes", "=", "[", "box", "[", "ind", "]", "for", "box", ",", "ind", "in", "zip", "(", "boxes", ",", "inds", ")", "]", "\n", "", "return", "boxes", ",", "{", "}", "\n", "\n", "\n", "", "", "def", "build_rpn", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "\"\"\"\n    This gives the gist of it. Not super important because it doesn't change as much\n    \"\"\"", "\n", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", ":", "\n", "        ", "return", "build_atss", "(", "cfg", ",", "in_channels", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "FCOS_ON", ":", "\n", "        ", "return", "build_fcos", "(", "cfg", ",", "in_channels", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "RETINANET_ON", ":", "\n", "        ", "return", "build_retinanet", "(", "cfg", ",", "in_channels", ")", "\n", "\n", "", "return", "RPNModule", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN.from_config": [[258, 286], ["anchor_generator.build_anchor_generator", "matcher.Matcher", "rpn.build_rpn_head", "box_regression.Box2BoxTransform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.anchor_generator.build_anchor_generator", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.build_rpn_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN._subsample_labels": [[287, 304], ["sampling.subsample_labels", "label.fill_", "label.scatter_", "label.scatter_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.sampling.subsample_labels"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN.label_and_sample_anchors": [[305, 364], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "detectron2.structures.Boxes.cat", "zip", "rpn.RPN.to", "rpn.RPN._subsample_labels", "gt_labels.append", "matched_gt_boxes.append", "detectron2.utils.memory.retry_if_cuda_oom", "detectron2.utils.memory.retry_if_cuda_oom", "detectron2.structures.Boxes.cat.inside_box", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN._subsample_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory.retry_if_cuda_oom", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory.retry_if_cuda_oom", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.inside_box"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN.losses": [[365, 430], ["len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pos_mask.sum().item", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "box_regression._dense_box_regression_loss", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "gt_labels[].to", "pos_mask.sum", "detectron2.layers.cat", "rpn.RPN.loss_weight.get", "losses.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression._dense_box_regression_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN.forward": [[431, 481], ["rpn.RPN.anchor_generator", "rpn.RPN.rpn_head", "rpn.RPN.predict_proposals", "score.permute().flatten", "x.view().permute().flatten", "rpn.RPN.label_and_sample_anchors", "rpn.RPN.losses", "score.permute", "x.view().permute", "x.view"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.RRPN.predict_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.RRPN.label_and_sample_anchors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN.predict_proposals": [[482, 512], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "rpn.RPN._decode_proposals", "proposal_utils.find_top_rpn_proposals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN._decode_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.proposal_utils.find_top_rpn_proposals"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN._decode_proposals": [[514, 534], ["zip", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.size", "pred_anchor_deltas_i.reshape.reshape.reshape", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape", "rpn.RPN.box2box_transform.apply_deltas", "proposals.append", "rpn.RPN.view", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand", "anchors_i.tensor.unsqueeze().expand().reshape.tensor.unsqueeze().expand().reshape.tensor.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.build_rpn_head": [[58, 64], ["RPN_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "\n", "for", "l", "in", "[", "self", ".", "conv", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.RRPN.__init__": [[130, 136], ["rpn.RPN.__init__", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "self", ".", "anchor_boundary_thresh", ">=", "0", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"anchor_boundary_thresh is a legacy option not implemented for RRPN.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.RRPN.from_config": [[138, 143], ["super().from_config", "box_regression.Box2BoxTransformRotated"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "ret", "[", "\"box2box_transform\"", "]", "=", "Box2BoxTransformRotated", "(", "weights", "=", "cfg", ".", "MODEL", ".", "RPN", ".", "BBOX_REG_WEIGHTS", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.RRPN.label_and_sample_anchors": [[144, 190], ["torch.no_grad", "detectron2.structures.RotatedBoxes.cat", "rrpn.RRPN.to", "rrpn.RRPN._subsample_labels", "gt_labels.append", "matched_gt_boxes.append", "detectron2.utils.memory.retry_if_cuda_oom", "detectron2.utils.memory.retry_if_cuda_oom", "len", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN._subsample_labels", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory.retry_if_cuda_oom", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.memory.retry_if_cuda_oom"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_anchors", "(", "self", ",", "anchors", ":", "List", "[", "RotatedBoxes", "]", ",", "gt_instances", ":", "List", "[", "Instances", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            anchors (list[RotatedBoxes]): anchors for each feature map.\n            gt_instances: the ground-truth instances for each image.\n\n        Returns:\n            list[Tensor]:\n                List of #img tensors. i-th element is a vector of labels whose length is\n                the total number of anchors across feature maps. Label values are in {-1, 0, 1},\n                with meanings: -1 = ignore; 0 = negative class; 1 = positive class.\n            list[Tensor]:\n                i-th element is a Nx5 tensor, where N is the total number of anchors across\n                feature maps.  The values are the matched gt boxes for each anchor.\n                Values are undefined for those anchors not labeled as 1.\n        \"\"\"", "\n", "anchors", "=", "RotatedBoxes", ".", "cat", "(", "anchors", ")", "\n", "\n", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "gt_instances", "]", "\n", "del", "gt_instances", "\n", "\n", "gt_labels", "=", "[", "]", "\n", "matched_gt_boxes", "=", "[", "]", "\n", "for", "gt_boxes_i", "in", "gt_boxes", ":", "\n", "            ", "\"\"\"\n            gt_boxes_i: ground-truth boxes for i-th image\n            \"\"\"", "\n", "match_quality_matrix", "=", "retry_if_cuda_oom", "(", "pairwise_iou_rotated", ")", "(", "gt_boxes_i", ",", "anchors", ")", "\n", "matched_idxs", ",", "gt_labels_i", "=", "retry_if_cuda_oom", "(", "self", ".", "anchor_matcher", ")", "(", "match_quality_matrix", ")", "\n", "# Matching is memory-expensive and may result in CPU tensors. But the result is small", "\n", "gt_labels_i", "=", "gt_labels_i", ".", "to", "(", "device", "=", "gt_boxes_i", ".", "device", ")", "\n", "\n", "# A vector of labels (-1, 0, 1) for each anchor", "\n", "gt_labels_i", "=", "self", ".", "_subsample_labels", "(", "gt_labels_i", ")", "\n", "\n", "if", "len", "(", "gt_boxes_i", ")", "==", "0", ":", "\n", "# These values won't be used anyway since the anchor is labeled as background", "\n", "                ", "matched_gt_boxes_i", "=", "torch", ".", "zeros_like", "(", "anchors", ".", "tensor", ")", "\n", "", "else", ":", "\n", "# TODO wasted indexing computation for ignored boxes", "\n", "                ", "matched_gt_boxes_i", "=", "gt_boxes_i", "[", "matched_idxs", "]", ".", "tensor", "\n", "\n", "", "gt_labels", ".", "append", "(", "gt_labels_i", ")", "# N,AHW", "\n", "matched_gt_boxes", ".", "append", "(", "matched_gt_boxes_i", ")", "\n", "", "return", "gt_labels", ",", "matched_gt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.RRPN.predict_proposals": [[191, 203], ["torch.no_grad", "rrpn.RRPN._decode_proposals", "rrpn.find_top_rrpn_proposals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rpn.RPN._decode_proposals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.find_top_rrpn_proposals"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "predict_proposals", "(", "self", ",", "anchors", ",", "pred_objectness_logits", ",", "pred_anchor_deltas", ",", "image_sizes", ")", ":", "\n", "        ", "pred_proposals", "=", "self", ".", "_decode_proposals", "(", "anchors", ",", "pred_anchor_deltas", ")", "\n", "return", "find_top_rrpn_proposals", "(", "\n", "pred_proposals", ",", "\n", "pred_objectness_logits", ",", "\n", "image_sizes", ",", "\n", "self", ".", "nms_thresh", ",", "\n", "self", ".", "pre_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "self", ".", "min_box_size", ",", "\n", "self", ".", "training", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.rrpn.find_top_rrpn_proposals": [[19, 122], ["len", "torch.arange", "zip", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "enumerate", "itertools.count", "min", "logits_i.sort", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.layers.cat.append", "detectron2.structures.RotatedBoxes", "detectron2.structures.RotatedBoxes.clip", "detectron2.structures.RotatedBoxes.nonempty", "detectron2.layers.batched_nms_rotated", "detectron2.structures.Instances", "results.append", "torch.full", "torch.isfinite().all", "torch.isfinite", "valid_mask.all", "detectron2.layers.batched_nms_rotated.sum().item", "len", "torch.isfinite", "detectron2.layers.batched_nms_rotated.sum"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms_rotated"], ["def", "find_top_rrpn_proposals", "(", "\n", "proposals", ",", "\n", "pred_objectness_logits", ",", "\n", "image_sizes", ",", "\n", "nms_thresh", ",", "\n", "pre_nms_topk", ",", "\n", "post_nms_topk", ",", "\n", "min_box_size", ",", "\n", "training", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    For each feature map, select the `pre_nms_topk` highest scoring proposals,\n    apply NMS, clip proposals, and remove small boxes. Return the `post_nms_topk`\n    highest scoring proposals among all the feature maps if `training` is True,\n    otherwise, returns the highest `post_nms_topk` scoring proposals for each\n    feature map.\n\n    Args:\n        proposals (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A, 5).\n            All proposal predictions on the feature maps.\n        pred_objectness_logits (list[Tensor]): A list of L tensors. Tensor i has shape (N, Hi*Wi*A).\n        image_sizes (list[tuple]): sizes (h, w) for each image\n        nms_thresh (float): IoU threshold to use for NMS\n        pre_nms_topk (int): number of top k scoring proposals to keep before applying NMS.\n            When RRPN is run on multiple feature maps (as in FPN) this number is per\n            feature map.\n        post_nms_topk (int): number of top k scoring proposals to keep after applying NMS.\n            When RRPN is run on multiple feature maps (as in FPN) this number is total,\n            over all feature maps.\n        min_box_size(float): minimum proposal box side length in pixels (absolute units wrt\n            input images).\n        training (bool): True if proposals are to be used in training, otherwise False.\n            This arg exists only to support a legacy bug; look for the \"NB: Legacy bug ...\"\n            comment.\n\n    Returns:\n        proposals (list[Instances]): list of N Instances. The i-th Instances\n            stores post_nms_topk object proposals for image i.\n    \"\"\"", "\n", "num_images", "=", "len", "(", "image_sizes", ")", "\n", "device", "=", "proposals", "[", "0", "]", ".", "device", "\n", "\n", "# 1. Select top-k anchor for every level and every image", "\n", "topk_scores", "=", "[", "]", "# #lvl Tensor, each of shape N x topk", "\n", "topk_proposals", "=", "[", "]", "\n", "level_ids", "=", "[", "]", "# #lvl Tensor, each of shape (topk,)", "\n", "batch_idx", "=", "torch", ".", "arange", "(", "num_images", ",", "device", "=", "device", ")", "\n", "for", "level_id", ",", "proposals_i", ",", "logits_i", "in", "zip", "(", "\n", "itertools", ".", "count", "(", ")", ",", "proposals", ",", "pred_objectness_logits", "\n", ")", ":", "\n", "        ", "Hi_Wi_A", "=", "logits_i", ".", "shape", "[", "1", "]", "\n", "num_proposals_i", "=", "min", "(", "pre_nms_topk", ",", "Hi_Wi_A", ")", "\n", "\n", "# sort is faster than topk (https://github.com/pytorch/pytorch/issues/22812)", "\n", "# topk_scores_i, topk_idx = logits_i.topk(num_proposals_i, dim=1)", "\n", "logits_i", ",", "idx", "=", "logits_i", ".", "sort", "(", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "topk_scores_i", "=", "logits_i", "[", "batch_idx", ",", ":", "num_proposals_i", "]", "\n", "topk_idx", "=", "idx", "[", "batch_idx", ",", ":", "num_proposals_i", "]", "\n", "\n", "# each is N x topk", "\n", "topk_proposals_i", "=", "proposals_i", "[", "batch_idx", "[", ":", ",", "None", "]", ",", "topk_idx", "]", "# N x topk x 5", "\n", "\n", "topk_proposals", ".", "append", "(", "topk_proposals_i", ")", "\n", "topk_scores", ".", "append", "(", "topk_scores_i", ")", "\n", "level_ids", ".", "append", "(", "torch", ".", "full", "(", "(", "num_proposals_i", ",", ")", ",", "level_id", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", ")", "\n", "\n", "# 2. Concat all levels together", "\n", "", "topk_scores", "=", "cat", "(", "topk_scores", ",", "dim", "=", "1", ")", "\n", "topk_proposals", "=", "cat", "(", "topk_proposals", ",", "dim", "=", "1", ")", "\n", "level_ids", "=", "cat", "(", "level_ids", ",", "dim", "=", "0", ")", "\n", "\n", "# 3. For each image, run a per-level NMS, and choose topk results.", "\n", "results", "=", "[", "]", "\n", "for", "n", ",", "image_size", "in", "enumerate", "(", "image_sizes", ")", ":", "\n", "        ", "boxes", "=", "RotatedBoxes", "(", "topk_proposals", "[", "n", "]", ")", "\n", "scores_per_img", "=", "topk_scores", "[", "n", "]", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ".", "tensor", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores_per_img", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "            ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores_per_img", "=", "scores_per_img", "[", "valid_mask", "]", "\n", "", "boxes", ".", "clip", "(", "image_size", ")", "\n", "\n", "# filter empty boxes", "\n", "keep", "=", "boxes", ".", "nonempty", "(", "threshold", "=", "min_box_size", ")", "\n", "lvl", "=", "level_ids", "\n", "if", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "len", "(", "boxes", ")", ":", "\n", "            ", "boxes", ",", "scores_per_img", ",", "lvl", "=", "(", "boxes", "[", "keep", "]", ",", "scores_per_img", "[", "keep", "]", ",", "level_ids", "[", "keep", "]", ")", "\n", "\n", "", "keep", "=", "batched_nms_rotated", "(", "boxes", ".", "tensor", ",", "scores_per_img", ",", "lvl", ",", "nms_thresh", ")", "\n", "# In Detectron1, there was different behavior during training vs. testing.", "\n", "# (https://github.com/facebookresearch/Detectron/issues/459)", "\n", "# During training, topk is over the proposals from *all* images in the training batch.", "\n", "# During testing, it is over the proposals for each image separately.", "\n", "# As a result, the training behavior becomes batch-dependent,", "\n", "# and the configuration \"POST_NMS_TOPK_TRAIN\" end up relying on the batch size.", "\n", "# This bug is addressed in Detectron2 to make the behavior independent of batch size.", "\n", "keep", "=", "keep", "[", ":", "post_nms_topk", "]", "\n", "\n", "res", "=", "Instances", "(", "image_size", ")", "\n", "res", ".", "proposal_boxes", "=", "boxes", "[", "keep", "]", "\n", "res", ".", "objectness_logits", "=", "scores_per_img", "[", "keep", "]", "\n", "results", ".", "append", "(", "res", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.proposal_generator.build.build_proposal_generator": [[15, 25], ["PROPOSAL_GENERATOR_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["from", ".", "transforms", "import", "build_transforms", "\n", "\n", "\n", "def", "build_dataset", "(", "dataset_list", ",", "transforms", ",", "dataset_catalog", ",", "is_train", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalog.get": [[57, 64], ["name.startswith", "name.startswith", "RuntimeError", "catalog.ModelCatalog._get_c2_detectron_baseline", "catalog.ModelCatalog._get_c2_imagenet_pretrained"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalog._get_c2_detectron_baseline", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalog._get_c2_imagenet_pretrained"], ["@", "staticmethod", "\n", "def", "get", "(", "name", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"Caffe2Detectron/COCO\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_detectron_baseline", "(", "name", ")", "\n", "", "if", "name", ".", "startswith", "(", "\"ImageNetPretrained/\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_imagenet_pretrained", "(", "name", ")", "\n", "", "raise", "RuntimeError", "(", "\"model not present in the catalog: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalog._get_c2_imagenet_pretrained": [[65, 72], ["len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_c2_imagenet_pretrained", "(", "name", ")", ":", "\n", "        ", "prefix", "=", "ModelCatalog", ".", "S3_C2_DETECTRON_PREFIX", "\n", "name", "=", "name", "[", "len", "(", "\"ImageNetPretrained/\"", ")", ":", "]", "\n", "name", "=", "ModelCatalog", ".", "C2_IMAGENET_MODELS", "[", "name", "]", "\n", "url", "=", "\"/\"", ".", "join", "(", "[", "prefix", ",", "name", "]", ")", "\n", "return", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalog._get_c2_detectron_baseline": [[73, 93], ["ModelCatalog.C2_DETECTRON_PATH_FORMAT.format", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_c2_detectron_baseline", "(", "name", ")", ":", "\n", "        ", "name", "=", "name", "[", "len", "(", "\"Caffe2Detectron/COCO/\"", ")", ":", "]", "\n", "url", "=", "ModelCatalog", ".", "C2_DETECTRON_MODELS", "[", "name", "]", "\n", "if", "\"keypoint_rcnn\"", "in", "name", ":", "\n", "            ", "dataset", "=", "ModelCatalog", ".", "C2_DATASET_COCO_KEYPOINTS", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ModelCatalog", ".", "C2_DATASET_COCO", "\n", "\n", "", "if", "\"35998355/rpn_R-50-C4_1x\"", "in", "name", ":", "\n", "# this one model is somehow different from others ..", "\n", "            ", "type", "=", "\"rpn\"", "\n", "", "else", ":", "\n", "            ", "type", "=", "\"generalized_rcnn\"", "\n", "\n", "# Detectron C2 models are stored in the structure defined in `C2_DETECTRON_PATH_FORMAT`.", "\n", "", "url", "=", "ModelCatalog", ".", "C2_DETECTRON_PATH_FORMAT", ".", "format", "(", "\n", "prefix", "=", "ModelCatalog", ".", "S3_C2_DETECTRON_PREFIX", ",", "url", "=", "url", ",", "type", "=", "type", ",", "dataset", "=", "dataset", "\n", ")", "\n", "return", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalogHandler._get_supported_prefixes": [[102, 104], ["None"], "methods", ["None"], ["def", "_get_supported_prefixes", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "PREFIX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalogHandler._get_local_path": [[105, 110], ["logging.getLogger", "catalog.ModelCatalog.get", "logging.getLogger.info", "detectron2.utils.file_io.PathManager.get_local_path", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_get_local_path", "(", "self", ",", "path", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "catalog_path", "=", "ModelCatalog", ".", "get", "(", "path", "[", "len", "(", "self", ".", "PREFIX", ")", ":", "]", ")", "\n", "logger", ".", "info", "(", "\"Catalog entry {} points to {}\"", ".", "format", "(", "path", ",", "catalog_path", ")", ")", "\n", "return", "PathManager", ".", "get_local_path", "(", "catalog_path", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalogHandler._open": [[111, 113], ["detectron2.utils.file_io.PathManager.open", "catalog.ModelCatalogHandler._get_local_path"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.catalog.ModelCatalogHandler._get_local_path"], ["", "def", "_open", "(", "self", ",", "path", ",", "mode", "=", "\"r\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "self", ".", "_get_local_path", "(", "path", ")", ",", "mode", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer.__init__": [[17, 26], ["detectron2.is_main_process", "fvcore.common.checkpoint.Checkpointer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "save_dir", "=", "\"\"", ",", "*", ",", "save_to_disk", "=", "None", ",", "**", "checkpointables", ")", ":", "\n", "        ", "is_main_process", "=", "comm", ".", "is_main_process", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "\n", "save_dir", ",", "\n", "save_to_disk", "=", "is_main_process", "if", "save_to_disk", "is", "None", "else", "save_to_disk", ",", "\n", "**", "checkpointables", ",", "\n", ")", "\n", "self", ".", "path_manager", "=", "PathManager", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file": [[27, 47], ["filename.endswith", "super()._load_file", "detectron2.utils.file_io.PathManager.open", "pickle.load", "detection_checkpoint.DetectionCheckpointer.logger.info", "pickle.load.items", "k.endswith"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "_load_file", "(", "self", ",", "filename", ")", ":", "\n", "        ", "if", "filename", ".", "endswith", "(", "\".pkl\"", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "data", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "", "if", "\"model\"", "in", "data", "and", "\"__author__\"", "in", "data", ":", "\n", "# file is in Detectron2 model zoo format", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"Reading a file from '{}'\"", ".", "format", "(", "data", "[", "\"__author__\"", "]", ")", ")", "\n", "return", "data", "\n", "", "else", ":", "\n", "# assume file is from Caffe2 / Detectron1 model zoo", "\n", "                ", "if", "\"blobs\"", "in", "data", ":", "\n", "# Detection models have \"blobs\", but ImageNet models don't", "\n", "                    ", "data", "=", "data", "[", "\"blobs\"", "]", "\n", "", "data", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", "if", "not", "k", ".", "endswith", "(", "\"_momentum\"", ")", "}", "\n", "return", "{", "\"model\"", ":", "data", ",", "\"__author__\"", ":", "\"Caffe2\"", ",", "\"matching_heuristics\"", ":", "True", "}", "\n", "\n", "", "", "loaded", "=", "super", "(", ")", ".", "_load_file", "(", "filename", ")", "# load native pth checkpoint", "\n", "if", "\"model\"", "not", "in", "loaded", ":", "\n", "            ", "loaded", "=", "{", "\"model\"", ":", "loaded", "}", "\n", "", "return", "loaded", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_model": [[48, 71], ["checkpoint.get", "super()._load_model", "dict", "detection_checkpoint.DetectionCheckpointer._convert_ndarray_to_tensor", "c2_model_loading.align_and_update_state_dicts", "detection_checkpoint.DetectionCheckpointer.model.named_buffers", "detection_checkpoint.DetectionCheckpointer.model.state_dict", "super()._load_model.missing_keys.remove", "checkpoint.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.detection_checkpoint.DetectionCheckpointer._load_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.align_and_update_state_dicts", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler.LRMultiplier.state_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_load_model", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "if", "checkpoint", ".", "get", "(", "\"matching_heuristics\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "_convert_ndarray_to_tensor", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "# convert weights by name-matching heuristics", "\n", "checkpoint", "[", "\"model\"", "]", "=", "align_and_update_state_dicts", "(", "\n", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "checkpoint", "[", "\"model\"", "]", ",", "\n", "c2_conversion", "=", "checkpoint", ".", "get", "(", "\"__author__\"", ",", "None", ")", "==", "\"Caffe2\"", ",", "\n", ")", "\n", "# for non-caffe2 models, use standard ways to load it", "\n", "", "incompatible", "=", "super", "(", ")", ".", "_load_model", "(", "checkpoint", ")", "\n", "\n", "model_buffers", "=", "dict", "(", "self", ".", "model", ".", "named_buffers", "(", "recurse", "=", "False", ")", ")", "\n", "for", "k", "in", "[", "\"pixel_mean\"", ",", "\"pixel_std\"", "]", ":", "\n", "# Ignore missing key message about pixel_mean/std.", "\n", "# Though they may be missing in old checkpoints, they will be correctly", "\n", "# initialized from config anyway.", "\n", "            ", "if", "k", "in", "model_buffers", ":", "\n", "                ", "try", ":", "\n", "                    ", "incompatible", ".", "missing_keys", ".", "remove", "(", "k", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "pass", "\n", "", "", "", "return", "incompatible", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.convert_basic_c2_names": [[10, 64], ["copy.deepcopy", "k.replace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "k.replace", "k.replace", "k.replace", "k.replace", "re.sub", "k.replace", "k.replace", "k.replace", "k.replace"], "function", ["None"], ["\n", "\n", "def", "_rename_basic_resnet_weights", "(", "layer_keys", ")", ":", "\n", "    ", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_\"", ",", "\".\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".w\"", ",", "\".weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".bn\"", ",", "\"_bn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".b\"", ",", "\".bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_bn.s\"", ",", "\"_bn.scale\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".biasranch\"", ",", "\".branch\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"bbox.pred\"", ",", "\"bbox_pred\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"cls.score\"", ",", "\"cls_score\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res.conv1_\"", ",", "\"conv1_\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# RPN / Faster RCNN", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".biasbox\"", ",", "\".bbox\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv.rpn\"", ",", "\"rpn.conv\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.bbox.pred\"", ",", "\"rpn.bbox_pred\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.cls.logits\"", ",", "\"rpn.cls_logits\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Affine-Channel -> BatchNorm enaming", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"_bn.scale\"", ",", "\"_bn.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Make torchvision-compatible", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv1_bn.\"", ",", "\"bn1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res2.\"", ",", "\"layer1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res3.\"", ",", "\"layer2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res4.\"", ",", "\"layer3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"res5.\"", ",", "\"layer4.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2a.\"", ",", "\".conv1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2a_bn.\"", ",", "\".bn1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2b.\"", ",", "\".conv2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2b_bn.\"", ",", "\".bn2.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2c.\"", ",", "\".conv3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch2c_bn.\"", ",", "\".bn3.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch1.\"", ",", "\".downsample.0.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".branch1_bn.\"", ",", "\".downsample.1.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# GroupNorm", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv1.gn.s\"", ",", "\"bn1.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv1.gn.bias\"", ",", "\"bn1.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv2.gn.s\"", ",", "\"bn2.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv2.gn.bias\"", ",", "\"bn2.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv3.gn.s\"", ",", "\"bn3.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv3.gn.bias\"", ",", "\"bn3.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"downsample.0.gn.s\"", ",", "\"downsample.1.weight\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"downsample.0.gn.bias\"", ",", "\"downsample.1.bias\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "return", "layer_keys", "\n", "\n", "", "def", "_rename_fpn_weights", "(", "layer_keys", ",", "stage_names", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.convert_c2_detectron_names": [[66, 205], ["logging.getLogger", "logging.getLogger.info", "sorted", "copy.deepcopy", "c2_model_loading.convert_basic_c2_names", "zip", "weights.keys", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "name.split", "name.startswith", "c2_model_loading.convert_c2_detectron_names.fpn_map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.convert_basic_c2_names"], ["        ", "suffix", "=", "\"\"", "\n", "if", "mapped_idx", "<", "4", ":", "\n", "            ", "suffix", "=", "\".lateral\"", "\n", "", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"fpn.inner.layer{}.sum{}\"", ".", "format", "(", "stage_name", ",", "suffix", ")", ",", "\"fpn_inner{}\"", ".", "format", "(", "mapped_idx", ")", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"fpn.layer{}.sum\"", ".", "format", "(", "stage_name", ")", ",", "\"fpn_layer{}\"", ".", "format", "(", "mapped_idx", ")", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "\n", "", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.conv.fpn2\"", ",", "\"rpn.conv\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.bbox_pred.fpn2\"", ",", "\"rpn.bbox_pred\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "\n", "k", ".", "replace", "(", "\"rpn.cls_logits.fpn2\"", ",", "\"rpn.cls_logits\"", ")", "for", "k", "in", "layer_keys", "\n", "]", "\n", "\n", "return", "layer_keys", "\n", "\n", "\n", "", "def", "_rename_weights_for_resnet", "(", "weights", ",", "stage_names", ")", ":", "\n", "    ", "original_keys", "=", "sorted", "(", "weights", ".", "keys", "(", ")", ")", "\n", "layer_keys", "=", "sorted", "(", "weights", ".", "keys", "(", ")", ")", "\n", "\n", "# for X-101, rename output to fc1000 to avoid conflicts afterwards", "\n", "layer_keys", "=", "[", "k", "if", "k", "!=", "\"pred_b\"", "else", "\"fc1000_b\"", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", "if", "k", "!=", "\"pred_w\"", "else", "\"fc1000_w\"", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# performs basic renaming: _ -> . , etc", "\n", "layer_keys", "=", "_rename_basic_resnet_weights", "(", "layer_keys", ")", "\n", "\n", "# FPN", "\n", "layer_keys", "=", "_rename_fpn_weights", "(", "layer_keys", ",", "stage_names", ")", "\n", "\n", "# Mask R-CNN", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"mask.fcn.logits\"", ",", "\"mask_fcn_logits\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\".[mask].fcn\"", ",", "\"mask_fcn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv5.mask\"", ",", "\"conv5_mask\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Keypoint R-CNN", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"kps.score.lowres\"", ",", "\"kps_score_lowres\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"kps.score\"", ",", "\"kps_score\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"conv.fcn\"", ",", "\"conv_fcn\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "# Rename for our RPN structure", "\n", "layer_keys", "=", "[", "k", ".", "replace", "(", "\"rpn.\"", ",", "\"rpn.head.\"", ")", "for", "k", "in", "layer_keys", "]", "\n", "\n", "key_map", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "original_keys", ",", "layer_keys", ")", "}", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Remapping C2 weights\"", ")", "\n", "max_c2_key_size", "=", "max", "(", "[", "len", "(", "k", ")", "for", "k", "in", "original_keys", "if", "\"_momentum\"", "not", "in", "k", "]", ")", "\n", "\n", "new_weights", "=", "OrderedDict", "(", ")", "\n", "for", "k", "in", "original_keys", ":", "\n", "        ", "v", "=", "weights", "[", "k", "]", "\n", "if", "\"_momentum\"", "in", "k", ":", "\n", "            ", "continue", "\n", "", "if", "'weight_order'", "in", "k", ":", "\n", "            ", "continue", "\n", "# if 'fc1000' in k:", "\n", "#     continue", "\n", "", "w", "=", "torch", ".", "from_numpy", "(", "v", ")", "\n", "# if \"bn\" in k:", "\n", "#     w = w.view(1, -1, 1, 1)", "\n", "logger", ".", "info", "(", "\"C2 name: {: <{}} mapped name: {}\"", ".", "format", "(", "k", ",", "max_c2_key_size", ",", "key_map", "[", "k", "]", ")", ")", "\n", "new_weights", "[", "key_map", "[", "k", "]", "]", "=", "w", "\n", "\n", "", "return", "new_weights", "\n", "\n", "\n", "", "def", "_load_c2_pickled_weights", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "if", "torch", ".", "_six", ".", "PY3", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "if", "\"blobs\"", "in", "data", ":", "\n", "        ", "weights", "=", "data", "[", "\"blobs\"", "]", "\n", "", "else", ":", "\n", "        ", "weights", "=", "data", "\n", "", "return", "weights", "\n", "\n", "\n", "", "def", "_rename_conv_weights_for_deformable_conv_layers", "(", "state_dict", ",", "cfg", ")", ":", "\n", "    ", "import", "re", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Remapping conv weights for deformable conv weights\"", ")", "\n", "layer_keys", "=", "sorted", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "for", "ix", ",", "stage_with_dcn", "in", "enumerate", "(", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STAGE_WITH_DCN", ",", "1", ")", ":", "\n", "        ", "if", "not", "stage_with_dcn", ":", "\n", "            ", "continue", "\n", "", "for", "old_key", "in", "layer_keys", ":", "\n", "            ", "pattern", "=", "\".*layer{}.*conv2.*\"", ".", "format", "(", "ix", ")", "\n", "r", "=", "re", ".", "match", "(", "pattern", ",", "old_key", ")", "\n", "if", "r", "is", "None", ":", "\n", "                ", "continue", "\n", "", "for", "param", "in", "[", "\"weight\"", ",", "\"bias\"", "]", ":", "\n", "                ", "if", "old_key", ".", "find", "(", "param", ")", "is", "-", "1", ":", "\n", "                    ", "continue", "\n", "", "new_key", "=", "old_key", ".", "replace", "(", "\n", "\"conv2.{}\"", ".", "format", "(", "param", ")", ",", "\"conv2.conv.{}\"", ".", "format", "(", "param", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"pattern: {}, old_key: {}, new_key: {}\"", ".", "format", "(", "\n", "pattern", ",", "old_key", ",", "new_key", "\n", ")", ")", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", "[", "old_key", "]", "\n", "del", "state_dict", "[", "old_key", "]", "\n", "", "", "", "return", "state_dict", "\n", "\n", "\n", "", "_C2_STAGE_NAMES", "=", "{", "\n", "\"R-50\"", ":", "[", "\"1.2\"", ",", "\"2.3\"", ",", "\"3.5\"", ",", "\"4.2\"", "]", ",", "\n", "\"R-101\"", ":", "[", "\"1.2\"", ",", "\"2.3\"", ",", "\"3.22\"", ",", "\"4.2\"", "]", ",", "\n", "\"R-152\"", ":", "[", "\"1.2\"", ",", "\"2.7\"", ",", "\"3.35\"", ",", "\"4.2\"", "]", ",", "\n", "}", "\n", "\n", "C2_FORMAT_LOADER", "=", "Registry", "(", ")", "\n", "\n", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-C4\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-C5\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-C4\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-C5\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-FPN\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-50-FPN-RETINANET\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-FPN\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-101-FPN-RETINANET\"", ")", "\n", "@", "C2_FORMAT_LOADER", ".", "register", "(", "\"R-152-FPN\"", ")", "\n", "def", "load_resnet_c2_format", "(", "cfg", ",", "f", ")", ":", "\n", "    ", "state_dict", "=", "_load_c2_pickled_weights", "(", "f", ")", "\n", "conv_body", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "\n", "arch", "=", "conv_body", ".", "replace", "(", "\"-C4\"", ",", "\"\"", ")", ".", "replace", "(", "\"-C5\"", ",", "\"\"", ")", ".", "replace", "(", "\"-FPN\"", ",", "\"\"", ")", "\n", "arch", "=", "arch", ".", "replace", "(", "\"-RETINANET\"", ",", "\"\"", ")", "\n", "stages", "=", "_C2_STAGE_NAMES", "[", "arch", "]", "\n", "state_dict", "=", "_rename_weights_for_resnet", "(", "state_dict", ",", "stages", ")", "\n", "# ***********************************", "\n", "# for deformable convolutional layer", "\n", "state_dict", "=", "_rename_conv_weights_for_deformable_conv_layers", "(", "state_dict", ",", "cfg", ")", "\n", "# ***********************************", "\n", "return", "dict", "(", "model", "=", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.align_and_update_state_dicts": [[209, 335], ["sorted", "sorted", "torch.as_tensor().view", "torch.as_tensor().view.max", "logging.getLogger", "enumerate", "sorted", "c2_model_loading._longest_common_prefix", "c2_model_loading._group_keys_by_module", "set", "tabulate.tabulate", "logging.getLogger.info", "model_state_dict.keys", "c2_model_loading.convert_c2_detectron_names", "ckpt_state_dict.keys", "len", "len", "idxs.tolist", "matched_keys.values", "len", "logging.getLogger.warning", "a.endswith", "c2_model_loading.align_and_update_state_dicts.match"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._longest_common_prefix", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._group_keys_by_module", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading.convert_c2_detectron_names"], ["", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._group_keys_by_module": [[337, 375], ["sorted", "key.rfind", "c2_model_loading._group_keys_by_module._submodule_name"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._longest_common_prefix": [[377, 386], ["n.split", "min", "max", "len", "zip"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._longest_common_prefix_str": [[388, 393], ["min", "max", "zip"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._group_str": [[395, 408], ["c2_model_loading._longest_common_prefix_str", "ret.replace.replace", "ret.replace.replace", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.checkpoint.c2_model_loading._longest_common_prefix_str"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_checkpoint_url": [[86, 102], ["config_path.replace", "RuntimeError"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_config_file": [[104, 121], ["pkg_resources.resource_filename", "os.path.join", "os.path.exists", "RuntimeError"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_config": [[123, 144], ["model_zoo.get_config_file", "detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "model_zoo.get_checkpoint_url"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_config_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_checkpoint_url"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get": [[146, 173], ["model_zoo.get_config", "detectron2.modeling.build_model", "detectron2.checkpoint.DetectionCheckpointer().load", "torch.cuda.is_available", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript.scripting_with_instances": [[14, 59], ["torchscript_patch.freeze_training_mode", "torchscript_patch.patch_instances", "torch.jit.script"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.freeze_training_mode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.patch_instances"], ["def", "scripting_with_instances", "(", "model", ",", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Run :func:`torch.jit.script` on a model that uses the :class:`Instances` class. Since\n    attributes of :class:`Instances` are \"dynamically\" added in eager mode\uff0cit is difficult\n    for scripting to support it out of the box. This function is made to support scripting\n    a model that uses :class:`Instances`. It does the following:\n\n    1. Create a scriptable ``new_Instances`` class which behaves similarly to ``Instances``,\n       but with all attributes been \"static\".\n       The attributes need to be statically declared in the ``fields`` argument.\n    2. Register ``new_Instances``, and force scripting compiler to\n       use it when trying to compile ``Instances``.\n\n    After this function, the process will be reverted. User should be able to script another model\n    using different fields.\n\n    Example:\n        Assume that ``Instances`` in the model consist of two attributes named\n        ``proposal_boxes`` and ``objectness_logits`` with type :class:`Boxes` and\n        :class:`Tensor` respectively during inference. You can call this function like:\n        ::\n            fields = {\"proposal_boxes\": Boxes, \"objectness_logits\": torch.Tensor}\n            torchscipt_model =  scripting_with_instances(model, fields)\n\n    Note:\n        It only support models in evaluation mode.\n\n    Args:\n        model (nn.Module): The input model to be exported by scripting.\n        fields (Dict[str, type]): Attribute names and corresponding type that\n            ``Instances`` will use in the model. Note that all attributes used in ``Instances``\n            need to be added, regardless of whether they are inputs/outputs of the model.\n            Data type not defined in detectron2 is not supported for now.\n\n    Returns:\n        torch.jit.ScriptModule: the model in torchscript format\n    \"\"\"", "\n", "assert", "TORCH_VERSION", ">=", "(", "1", ",", "8", ")", ",", "\"This feature is not available in PyTorch < 1.8\"", "\n", "assert", "(", "\n", "not", "model", ".", "training", "\n", ")", ",", "\"Currently we only support exporting models in evaluation mode to torchscript\"", "\n", "\n", "with", "freeze_training_mode", "(", "model", ")", ",", "patch_instances", "(", "fields", ")", ":", "\n", "        ", "scripted_model", "=", "torch", ".", "jit", ".", "script", "(", "model", ")", "\n", "return", "scripted_model", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript.dump_torchscript_IR": [[65, 128], ["detectron2.utils.file_io.PathManager.mkdirs", "isinstance", "detectron2.utils.file_io.PathManager.open", "torchscript.dump_torchscript_IR.dump_code"], "function", ["None"], ["def", "dump_torchscript_IR", "(", "model", ",", "dir", ")", ":", "\n", "    ", "\"\"\"\n    Dump IR of a TracedModule/ScriptModule at various levels.\n    Useful for debugging.\n\n    Args:\n        model (TracedModule or ScriptModule): traced or scripted module\n        dir (str): output directory to dump files.\n    \"\"\"", "\n", "# TODO: support ScriptFunction as well", "\n", "PathManager", ".", "mkdirs", "(", "dir", ")", "\n", "\n", "def", "_get_script_mod", "(", "mod", ")", ":", "\n", "        ", "if", "isinstance", "(", "mod", ",", "torch", ".", "jit", ".", "TracedModule", ")", ":", "\n", "            ", "return", "mod", ".", "_actual_script_module", "\n", "", "return", "mod", "\n", "\n", "# Dump pretty-printed code: https://pytorch.org/docs/stable/jit.html#inspecting-code", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_ts_code.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\n", "        ", "def", "get_code", "(", "mod", ")", ":", "\n", "# Try a few ways to get code using private attributes.", "\n", "            ", "try", ":", "\n", "# This contains more information than just `mod.code`", "\n", "                ", "return", "_get_script_mod", "(", "mod", ")", ".", "_c", ".", "code", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "", "try", ":", "\n", "                ", "return", "mod", ".", "code", "\n", "", "except", "AttributeError", ":", "\n", "                ", "return", "None", "\n", "\n", "", "", "def", "dump_code", "(", "prefix", ",", "mod", ")", ":", "\n", "            ", "code", "=", "get_code", "(", "mod", ")", "\n", "name", "=", "prefix", "or", "\"root model\"", "\n", "if", "code", "is", "None", ":", "\n", "                ", "f", ".", "write", "(", "f\"Could not found code for {name} (type={mod.original_name})\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                ", "f", ".", "write", "(", "f\"\\nCode for {name}, type={mod.original_name}:\\n\"", ")", "\n", "f", ".", "write", "(", "code", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"-\"", "*", "80", ")", "\n", "\n", "", "for", "name", ",", "m", "in", "mod", ".", "named_children", "(", ")", ":", "\n", "                ", "dump_code", "(", "prefix", "+", "\".\"", "+", "name", ",", "m", ")", "\n", "\n", "", "", "dump_code", "(", "\"\"", ",", "model", ")", "\n", "\n", "# Recursively dump IR of all modules", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_ts_IR.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "try", ":", "\n", "            ", "f", ".", "write", "(", "_get_script_mod", "(", "model", ")", ".", "_c", ".", "dump_to_str", "(", "True", ",", "False", ",", "False", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n", "# Dump IR of the entire graph (all submodules inlined)", "\n", "", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_ts_IR_inlined.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "model", ".", "inlined_graph", ")", ")", "\n", "\n", "# Dump the model structure in pytorch style", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "model", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.ScopedWS.__init__": [[130, 135], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ws_name", ",", "is_reset", ",", "is_cleanup", "=", "False", ")", ":", "\n", "        ", "self", ".", "ws_name", "=", "ws_name", "\n", "self", ".", "is_reset", "=", "is_reset", "\n", "self", ".", "is_cleanup", "=", "is_cleanup", "\n", "self", ".", "org_ws", "=", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.ScopedWS.__enter__": [[136, 144], ["caffe2.python.workspace.CurrentWorkspace", "caffe2.python.workspace.SwitchWorkspace", "caffe2.python.workspace.ResetWorkspace"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "org_ws", "=", "workspace", ".", "CurrentWorkspace", "(", ")", "\n", "if", "self", ".", "ws_name", "is", "not", "None", ":", "\n", "            ", "workspace", ".", "SwitchWorkspace", "(", "self", ".", "ws_name", ",", "True", ")", "\n", "", "if", "self", ".", "is_reset", ":", "\n", "            ", "workspace", ".", "ResetWorkspace", "(", ")", "\n", "\n", "", "return", "workspace", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.ScopedWS.__exit__": [[145, 150], ["caffe2.python.workspace.ResetWorkspace", "caffe2.python.workspace.SwitchWorkspace"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "if", "self", ".", "is_cleanup", ":", "\n", "            ", "workspace", ".", "ResetWorkspace", "(", ")", "\n", "", "if", "self", ".", "ws_name", "is", "not", "None", ":", "\n", "            ", "workspace", ".", "SwitchWorkspace", "(", "self", ".", "org_ws", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.__init__": [[785, 788], ["set", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "vertices", "=", "set", "(", ")", "\n", "self", ".", "graph", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.add_edge": [[789, 793], ["shared.DiGraph.graph[].append", "shared.DiGraph.vertices.add", "shared.DiGraph.vertices.add"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], ["", "def", "add_edge", "(", "self", ",", "u", ",", "v", ")", ":", "\n", "        ", "self", ".", "graph", "[", "u", "]", ".", "append", "(", "v", ")", "\n", "self", ".", "vertices", ".", "add", "(", "u", ")", "\n", "self", ".", "vertices", ".", "add", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.get_all_paths": [[795, 814], ["shared.DiGraph.get_all_paths._get_all_paths_util"], "methods", ["None"], ["", "def", "get_all_paths", "(", "self", ",", "s", ",", "d", ")", ":", "\n", "        ", "visited", "=", "{", "k", ":", "False", "for", "k", "in", "self", ".", "vertices", "}", "\n", "path", "=", "[", "]", "\n", "all_paths", "=", "[", "]", "\n", "\n", "def", "_get_all_paths_util", "(", "graph", ",", "u", ",", "d", ",", "visited", ",", "path", ")", ":", "\n", "            ", "visited", "[", "u", "]", "=", "True", "\n", "path", ".", "append", "(", "u", ")", "\n", "if", "u", "==", "d", ":", "\n", "                ", "all_paths", ".", "append", "(", "copy", ".", "deepcopy", "(", "path", ")", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "graph", "[", "u", "]", ":", "\n", "                    ", "if", "not", "visited", "[", "i", "]", ":", "\n", "                        ", "_get_all_paths_util", "(", "graph", ",", "i", ",", "d", ",", "visited", ",", "path", ")", "\n", "", "", "", "path", ".", "pop", "(", ")", "\n", "visited", "[", "u", "]", "=", "False", "\n", "\n", "", "_get_all_paths_util", "(", "self", ".", "graph", ",", "s", ",", "d", ",", "visited", ",", "path", ")", "\n", "return", "all_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.from_ssa": [[815, 823], ["shared.DiGraph", "range", "len", "shared.DiGraph.add_edge"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.add_edge"], ["", "@", "staticmethod", "\n", "def", "from_ssa", "(", "ssa", ")", ":", "\n", "        ", "graph", "=", "DiGraph", "(", ")", "\n", "for", "op_id", "in", "range", "(", "len", "(", "ssa", ")", ")", ":", "\n", "            ", "for", "inp", "in", "ssa", "[", "op_id", "]", "[", "0", "]", ":", "\n", "                ", "for", "outp", "in", "ssa", "[", "op_id", "]", "[", "1", "]", ":", "\n", "                    ", "graph", ".", "add_edge", "(", "inp", ",", "outp", ")", "\n", "", "", "", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device": [[25, 42], ["torch.device", "torch.device", "torch.ops._caffe2.CopyGPUToCPU", "torch.ops._caffe2.CopyGPUToCPU", "torch.ops._caffe2.CopyCPUToGPU", "torch.ops._caffe2.CopyCPUToGPU", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["def", "to_device", "(", "t", ",", "device_str", ")", ":", "\n", "    ", "\"\"\"\n    This function is a replacement of .to(another_device) such that it allows the\n    casting to be traced properly by explicitly calling the underlying copy ops.\n    It also avoids introducing unncessary op when casting to the same device.\n    \"\"\"", "\n", "src", "=", "t", ".", "device", "\n", "dst", "=", "torch", ".", "device", "(", "device_str", ")", "\n", "\n", "if", "src", "==", "dst", ":", "\n", "        ", "return", "t", "\n", "", "elif", "src", ".", "type", "==", "\"cuda\"", "and", "dst", ".", "type", "==", "\"cpu\"", ":", "\n", "        ", "return", "torch", ".", "ops", ".", "_caffe2", ".", "CopyGPUToCPU", "(", "t", ")", "\n", "", "elif", "src", ".", "type", "==", "\"cpu\"", "and", "dst", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "return", "torch", ".", "ops", ".", "_caffe2", ".", "CopyCPUToGPU", "(", "t", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Can't cast tensor from device {} to device {}\"", ".", "format", "(", "src", ",", "dst", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.BilinearInterpolation": [[48, 77], ["shared.BilinearInterpolation.upsample_filt"], "function", ["None"], ["", "", "def", "BilinearInterpolation", "(", "tensor_in", ",", "up_scale", ")", ":", "\n", "    ", "assert", "up_scale", "%", "2", "==", "0", ",", "\"Scale should be even\"", "\n", "\n", "def", "upsample_filt", "(", "size", ")", ":", "\n", "        ", "factor", "=", "(", "size", "+", "1", ")", "//", "2", "\n", "if", "size", "%", "2", "==", "1", ":", "\n", "            ", "center", "=", "factor", "-", "1", "\n", "", "else", ":", "\n", "            ", "center", "=", "factor", "-", "0.5", "\n", "\n", "", "og", "=", "np", ".", "ogrid", "[", ":", "size", ",", ":", "size", "]", "\n", "return", "(", "1", "-", "abs", "(", "og", "[", "0", "]", "-", "center", ")", "/", "factor", ")", "*", "(", "1", "-", "abs", "(", "og", "[", "1", "]", "-", "center", ")", "/", "factor", ")", "\n", "\n", "", "kernel_size", "=", "int", "(", "up_scale", ")", "*", "2", "\n", "bil_filt", "=", "upsample_filt", "(", "kernel_size", ")", "\n", "\n", "dim", "=", "int", "(", "tensor_in", ".", "shape", "[", "1", "]", ")", "\n", "kernel", "=", "np", ".", "zeros", "(", "(", "dim", ",", "dim", ",", "kernel_size", ",", "kernel_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "kernel", "[", "range", "(", "dim", ")", ",", "range", "(", "dim", ")", ",", ":", ",", ":", "]", "=", "bil_filt", "\n", "\n", "tensor_out", "=", "F", ".", "conv_transpose2d", "(", "\n", "tensor_in", ",", "\n", "weight", "=", "to_device", "(", "torch", ".", "Tensor", "(", "kernel", ")", ",", "tensor_in", ".", "device", ")", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "int", "(", "up_scale", ")", ",", "\n", "padding", "=", "int", "(", "up_scale", "/", "2", ")", ",", "\n", ")", "\n", "\n", "return", "tensor_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.onnx_compatibale_interpolate": [[82, 113], ["torch.nn.functional.interpolate", "logger.warning", "input.dim", "isinstance", "isinstance", "torch.ops._caffe2.ResizeNearest", "torch.ops._caffe2.ResizeNearest", "len", "logger.warning", "shared.BilinearInterpolation"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.BilinearInterpolation"], ["", "def", "onnx_compatibale_interpolate", "(", "\n", "input", ",", "size", "=", "None", ",", "scale_factor", "=", "None", ",", "mode", "=", "\"nearest\"", ",", "align_corners", "=", "None", "\n", ")", ":", "\n", "# NOTE: The input dimensions are interpreted in the form:", "\n", "# `mini-batch x channels x [optional depth] x [optional height] x width`.", "\n", "    ", "if", "size", "is", "None", "and", "scale_factor", "is", "not", "None", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "if", "isinstance", "(", "scale_factor", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "height_scale", ",", "width_scale", "=", "(", "scale_factor", ",", "scale_factor", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "scale_factor", ",", "(", "tuple", ",", "list", ")", ")", "\n", "assert", "len", "(", "scale_factor", ")", "==", "2", "\n", "height_scale", ",", "width_scale", "=", "scale_factor", "\n", "\n", "", "assert", "not", "align_corners", ",", "\"No matching C2 op for align_corners == True\"", "\n", "if", "mode", "==", "\"nearest\"", ":", "\n", "                ", "return", "torch", ".", "ops", ".", "_caffe2", ".", "ResizeNearest", "(", "\n", "input", ",", "order", "=", "\"NCHW\"", ",", "width_scale", "=", "width_scale", ",", "height_scale", "=", "height_scale", "\n", ")", "\n", "", "elif", "mode", "==", "\"bilinear\"", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"Use F.conv_transpose2d for bilinear interpolate\"", "\n", "\" because there's no such C2 op, this may cause significant\"", "\n", "\" slowdown and the boundary pixels won't be as same as\"", "\n", "\" using F.interpolate due to padding.\"", "\n", ")", "\n", "assert", "height_scale", "==", "width_scale", "\n", "return", "BilinearInterpolation", "(", "input", ",", "up_scale", "=", "height_scale", ")", "\n", "", "", "logger", ".", "warning", "(", "\"Output size is not static, it might cause ONNX conversion issue\"", ")", "\n", "\n", "", "return", "interp", "(", "input", ",", "size", ",", "scale_factor", ",", "mode", ",", "align_corners", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.mock_torch_nn_functional_interpolate": [[115, 124], ["torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "unittest.mock.patch"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_torch_nn_functional_interpolate", "(", ")", ":", "\n", "    ", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "        ", "with", "mock", ".", "patch", "(", "\n", "\"torch.nn.functional.interpolate\"", ",", "side_effect", "=", "onnx_compatibale_interpolate", "\n", ")", ":", "\n", "            ", "yield", "\n", "", "", "else", ":", "\n", "        ", "yield", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.fetch_any_blob": [[152, 162], ["caffe2.python.workspace.FetchBlob", "caffe2.python.workspace.FetchInt8Blob", "logger.error"], "function", ["None"], ["", "", "", "def", "fetch_any_blob", "(", "name", ")", ":", "\n", "    ", "bb", "=", "None", "\n", "try", ":", "\n", "        ", "bb", "=", "workspace", ".", "FetchBlob", "(", "name", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "bb", "=", "workspace", ".", "FetchInt8Blob", "(", "name", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"Get blob {} error: {}\"", ".", "format", "(", "name", ",", "e", ")", ")", "\n", "\n", "", "return", "bb", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg": [[167, 172], ["None"], "function", ["None"], ["", "def", "get_pb_arg", "(", "pb", ",", "arg_name", ")", ":", "\n", "    ", "for", "x", "in", "pb", ".", "arg", ":", "\n", "        ", "if", "x", ".", "name", "==", "arg_name", ":", "\n", "            ", "return", "x", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_valf": [[174, 177], ["shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg"], ["", "def", "get_pb_arg_valf", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "arg", ".", "f", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_floats": [[179, 182], ["shared.get_pb_arg", "list", "map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "get_pb_arg_floats", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "list", "(", "map", "(", "float", ",", "arg", ".", "floats", ")", ")", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_ints": [[184, 187], ["shared.get_pb_arg", "list", "map"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "get_pb_arg_ints", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "list", "(", "map", "(", "int", ",", "arg", ".", "ints", ")", ")", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali": [[189, 192], ["shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg"], ["", "def", "get_pb_arg_vali", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "arg", ".", "i", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals": [[194, 197], ["shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg"], ["", "def", "get_pb_arg_vals", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "arg", ".", "s", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_valstrings": [[199, 202], ["shared.get_pb_arg", "list"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "get_pb_arg_valstrings", "(", "pb", ",", "arg_name", ",", "default_val", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "return", "list", "(", "arg", ".", "strings", ")", "if", "arg", "is", "not", "None", "else", "default_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg": [[204, 219], ["shared.get_pb_arg", "caffe2.MakeArgument", "hasattr", "pb.arg.extend", "logger.warning", "setattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "check_set_pb_arg", "(", "pb", ",", "arg_name", ",", "arg_attr", ",", "arg_value", ",", "allow_override", "=", "False", ")", ":", "\n", "    ", "arg", "=", "get_pb_arg", "(", "pb", ",", "arg_name", ")", "\n", "if", "arg", "is", "None", ":", "\n", "        ", "arg", "=", "putils", ".", "MakeArgument", "(", "arg_name", ",", "arg_value", ")", "\n", "assert", "hasattr", "(", "arg", ",", "arg_attr", ")", "\n", "pb", ".", "arg", ".", "extend", "(", "[", "arg", "]", ")", "\n", "", "if", "allow_override", "and", "getattr", "(", "arg", ",", "arg_attr", ")", "!=", "arg_value", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Override argument {}: {} -> {}\"", ".", "format", "(", "arg_name", ",", "getattr", "(", "arg", ",", "arg_attr", ")", ",", "arg_value", ")", "\n", ")", "\n", "setattr", "(", "arg", ",", "arg_attr", ",", "arg_value", ")", "\n", "", "else", ":", "\n", "        ", "assert", "arg", "is", "not", "None", "\n", "assert", "getattr", "(", "arg", ",", "arg_attr", ")", "==", "arg_value", ",", "\"Existing value {}, new value {}\"", ".", "format", "(", "\n", "getattr", "(", "arg", ",", "arg_attr", ")", ",", "arg_value", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._create_const_fill_op_from_numpy": [[222, 241], ["caffe2.python.core.CreateOperator", "type", "numpy.dtype", "numpy.dtype", "numpy.dtype", "numpy.dtype", "numpy.dtype", "args_dict.update", "args_dict.update", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update"], ["", "", "def", "_create_const_fill_op_from_numpy", "(", "name", ",", "tensor", ",", "device_option", "=", "None", ")", ":", "\n", "    ", "assert", "type", "(", "tensor", ")", "==", "np", ".", "ndarray", "\n", "kTypeNameMapper", "=", "{", "\n", "np", ".", "dtype", "(", "\"float32\"", ")", ":", "\"GivenTensorFill\"", ",", "\n", "np", ".", "dtype", "(", "\"int32\"", ")", ":", "\"GivenTensorIntFill\"", ",", "\n", "np", ".", "dtype", "(", "\"int64\"", ")", ":", "\"GivenTensorInt64Fill\"", ",", "\n", "np", ".", "dtype", "(", "\"uint8\"", ")", ":", "\"GivenTensorStringFill\"", ",", "\n", "}", "\n", "\n", "args_dict", "=", "{", "}", "\n", "if", "tensor", ".", "dtype", "==", "np", ".", "dtype", "(", "\"uint8\"", ")", ":", "\n", "        ", "args_dict", ".", "update", "(", "{", "\"values\"", ":", "[", "str", "(", "tensor", ".", "data", ")", "]", ",", "\"shape\"", ":", "[", "1", "]", "}", ")", "\n", "", "else", ":", "\n", "        ", "args_dict", ".", "update", "(", "{", "\"values\"", ":", "tensor", ",", "\"shape\"", ":", "tensor", ".", "shape", "}", ")", "\n", "\n", "", "if", "device_option", "is", "not", "None", ":", "\n", "        ", "args_dict", "[", "\"device_option\"", "]", "=", "device_option", "\n", "\n", "", "return", "core", ".", "CreateOperator", "(", "kTypeNameMapper", "[", "tensor", ".", "dtype", "]", ",", "[", "]", ",", "[", "name", "]", ",", "**", "args_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._create_const_fill_op_from_c2_int8_tensor": [[243, 262], ["caffe2.python.core.CreateOperator", "type", "numpy.dtype", "numpy.dtype", "tensor.tobytes", "numpy.dtype", "numpy.dtype", "numpy.dtype"], "function", ["None"], ["", "def", "_create_const_fill_op_from_c2_int8_tensor", "(", "name", ",", "int8_tensor", ")", ":", "\n", "    ", "assert", "type", "(", "int8_tensor", ")", "==", "workspace", ".", "Int8Tensor", "\n", "kTypeNameMapper", "=", "{", "\n", "np", ".", "dtype", "(", "\"int32\"", ")", ":", "\"Int8GivenIntTensorFill\"", ",", "\n", "np", ".", "dtype", "(", "\"uint8\"", ")", ":", "\"Int8GivenTensorFill\"", ",", "\n", "}", "\n", "\n", "tensor", "=", "int8_tensor", ".", "data", "\n", "assert", "tensor", ".", "dtype", "in", "[", "np", ".", "dtype", "(", "\"uint8\"", ")", ",", "np", ".", "dtype", "(", "\"int32\"", ")", "]", "\n", "values", "=", "tensor", ".", "tobytes", "(", ")", "if", "tensor", ".", "dtype", "==", "np", ".", "dtype", "(", "\"uint8\"", ")", "else", "tensor", "\n", "\n", "return", "core", ".", "CreateOperator", "(", "\n", "kTypeNameMapper", "[", "tensor", ".", "dtype", "]", ",", "\n", "[", "]", ",", "\n", "[", "name", "]", ",", "\n", "values", "=", "values", ",", "\n", "shape", "=", "tensor", ".", "shape", ",", "\n", "Y_scale", "=", "int8_tensor", ".", "scale", ",", "\n", "Y_zero_point", "=", "int8_tensor", ".", "zero_point", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.create_const_fill_op": [[265, 288], ["type", "type", "shared._create_const_fill_op_from_numpy", "shared._create_const_fill_op_from_c2_int8_tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._create_const_fill_op_from_numpy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._create_const_fill_op_from_c2_int8_tensor"], ["", "def", "create_const_fill_op", "(", "\n", "name", ":", "str", ",", "\n", "blob", ":", "Union", "[", "np", ".", "ndarray", ",", "workspace", ".", "Int8Tensor", "]", ",", "\n", "device_option", ":", "Optional", "[", "caffe2_pb2", ".", "DeviceOption", "]", "=", "None", ",", "\n", ")", "->", "caffe2_pb2", ".", "OperatorDef", ":", "\n", "    ", "\"\"\"\n    Given a blob object, return the Caffe2 operator that creates this blob\n    as constant. Currently support NumPy tensor and Caffe2 Int8Tensor.\n    \"\"\"", "\n", "\n", "tensor_type", "=", "type", "(", "blob", ")", "\n", "assert", "tensor_type", "in", "[", "\n", "np", ".", "ndarray", ",", "\n", "workspace", ".", "Int8Tensor", ",", "\n", "]", ",", "'Error when creating const fill op for \"{}\", unsupported blob type: {}'", ".", "format", "(", "\n", "name", ",", "type", "(", "blob", ")", "\n", ")", "\n", "\n", "if", "tensor_type", "==", "np", ".", "ndarray", ":", "\n", "        ", "return", "_create_const_fill_op_from_numpy", "(", "name", ",", "blob", ",", "device_option", ")", "\n", "", "elif", "tensor_type", "==", "workspace", ".", "Int8Tensor", ":", "\n", "        ", "assert", "device_option", "is", "None", "\n", "return", "_create_const_fill_op_from_c2_int8_tensor", "(", "name", ",", "blob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.construct_init_net_from_params": [[290, 312], ["caffe2.proto.caffe2_pb2.NetDef", "params.items", "isinstance", "caffe2_pb2.NetDef.op.extend", "caffe2_pb2.NetDef.external_output.append", "logger.warning", "shared.create_const_fill_op", "type", "device_options.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.create_const_fill_op", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "construct_init_net_from_params", "(", "\n", "params", ":", "Dict", "[", "str", ",", "Any", "]", ",", "device_options", ":", "Optional", "[", "Dict", "[", "str", ",", "caffe2_pb2", ".", "DeviceOption", "]", "]", "=", "None", "\n", ")", "->", "caffe2_pb2", ".", "NetDef", ":", "\n", "    ", "\"\"\"\n    Construct the init_net from params dictionary\n    \"\"\"", "\n", "init_net", "=", "caffe2_pb2", ".", "NetDef", "(", ")", "\n", "device_options", "=", "device_options", "or", "{", "}", "\n", "for", "name", ",", "blob", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "blob", ",", "str", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "(", "\n", "\"Blob {} with type {} is not supported in generating init net,\"", "\n", "\" skipped.\"", ".", "format", "(", "name", ",", "type", "(", "blob", ")", ")", "\n", ")", "\n", ")", "\n", "continue", "\n", "", "init_net", ".", "op", ".", "extend", "(", "\n", "[", "create_const_fill_op", "(", "name", ",", "blob", ",", "device_option", "=", "device_options", ".", "get", "(", "name", ",", "None", ")", ")", "]", "\n", ")", "\n", "init_net", ".", "external_output", ".", "append", "(", "name", ")", "\n", "", "return", "init_net", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_producer_map": [[314, 325], ["range", "len", "enumerate"], "function", ["None"], ["", "def", "get_producer_map", "(", "ssa", ")", ":", "\n", "    ", "\"\"\"\n    Return dict from versioned blob to (i, j),\n        where i is index of producer op, j is the index of output of that op.\n    \"\"\"", "\n", "producer_map", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", ":", "\n", "        ", "outputs", "=", "ssa", "[", "i", "]", "[", "1", "]", "\n", "for", "j", ",", "outp", "in", "enumerate", "(", "outputs", ")", ":", "\n", "            ", "producer_map", "[", "outp", "]", "=", "(", "i", ",", "j", ")", "\n", "", "", "return", "producer_map", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_consumer_map": [[327, 338], ["collections.defaultdict", "range", "len", "enumerate", "consumer_map[].append"], "function", ["None"], ["", "def", "get_consumer_map", "(", "ssa", ")", ":", "\n", "    ", "\"\"\"\n    Return dict from versioned blob to list of (i, j),\n        where i is index of consumer op, j is the index of input of that op.\n    \"\"\"", "\n", "consumer_map", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", ":", "\n", "        ", "inputs", "=", "ssa", "[", "i", "]", "[", "0", "]", "\n", "for", "j", ",", "inp", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "consumer_map", "[", "inp", "]", ".", "append", "(", "(", "i", ",", "j", ")", ")", "\n", "", "", "return", "consumer_map", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_params_from_init_net": [[340, 367], ["caffe2.python.core.get_ssa", "shared.get_producer_map", "shared.ScopedWS", "ws.RunNetOnce", "shared.get_params_from_init_net._get_device_option"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_producer_map"], ["", "def", "get_params_from_init_net", "(", "\n", "init_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", ")", "->", "[", "Dict", "[", "str", ",", "Any", "]", ",", "Dict", "[", "str", ",", "caffe2_pb2", ".", "DeviceOption", "]", "]", ":", "\n", "    ", "\"\"\"\n    Take the output blobs from init_net by running it.\n    Outputs:\n        params: dict from blob name to numpy array\n        device_options: dict from blob name to the device option of its creating op\n    \"\"\"", "\n", "# NOTE: this assumes that the params is determined by producer op with the", "\n", "# only exception be CopyGPUToCPU which is CUDA op but returns CPU tensor.", "\n", "def", "_get_device_option", "(", "producer_op", ")", ":", "\n", "        ", "if", "producer_op", ".", "type", "==", "\"CopyGPUToCPU\"", ":", "\n", "            ", "return", "caffe2_pb2", ".", "DeviceOption", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "producer_op", ".", "device_option", "\n", "\n", "", "", "with", "ScopedWS", "(", "\"__get_params_from_init_net__\"", ",", "is_reset", "=", "True", ",", "is_cleanup", "=", "True", ")", "as", "ws", ":", "\n", "        ", "ws", ".", "RunNetOnce", "(", "init_net", ")", "\n", "params", "=", "{", "b", ":", "fetch_any_blob", "(", "b", ")", "for", "b", "in", "init_net", ".", "external_output", "}", "\n", "", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "init_net", ")", "\n", "producer_map", "=", "get_producer_map", "(", "ssa", ")", "\n", "device_options", "=", "{", "\n", "b", ":", "_get_device_option", "(", "init_net", ".", "op", "[", "producer_map", "[", "(", "b", ",", "versions", "[", "b", "]", ")", "]", "[", "0", "]", "]", ")", "\n", "for", "b", "in", "init_net", ".", "external_output", "\n", "}", "\n", "return", "params", ",", "device_options", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._updater_raise": [[369, 373], ["RuntimeError"], "function", ["None"], ["", "def", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "    ", "raise", "RuntimeError", "(", "\n", "\"Failed to apply updater for op {} given input_types {} and\"", "\n", "\" output_types {}\"", ".", "format", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._generic_status_identifier": [[376, 446], ["caffe2.python.core.get_ssa", "set().union", "set().union.union().union", "all", "all", "copy.deepcopy", "zip", "zip", "status_updater", "zip", "shared._generic_status_identifier._update_i"], "function", ["None"], ["", "def", "_generic_status_identifier", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "status_updater", ":", "Callable", ",", "\n", "known_status", ":", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "Any", "]", ",", "\n", ")", "->", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Statically infer the status of each blob, the status can be such as device type\n        (CPU/GPU), layout (NCHW/NHWC), data type (float32/int8), etc. \"Blob\" here\n        is versioned blob (Tuple[str, int]) in the format compatible with ssa.\n    Inputs:\n        predict_net: the caffe2 network\n        status_updater: a callable, given an op and the status of its input/output,\n            it returns the updated status of input/output. `None` is used for\n            representing unknown status.\n        known_status: a dict containing known status, used as initialization.\n    Outputs:\n        A dict mapping from versioned blob to its status\n    \"\"\"", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "versioned_ext_input", "=", "[", "(", "b", ",", "0", ")", "for", "b", "in", "predict_net", ".", "external_input", "]", "\n", "versioned_ext_output", "=", "[", "(", "b", ",", "versions", "[", "b", "]", ")", "for", "b", "in", "predict_net", ".", "external_output", "]", "\n", "all_versioned_blobs", "=", "set", "(", ")", ".", "union", "(", "*", "[", "set", "(", "x", "[", "0", "]", "+", "x", "[", "1", "]", ")", "for", "x", "in", "ssa", "]", ")", "\n", "\n", "allowed_vbs", "=", "all_versioned_blobs", ".", "union", "(", "versioned_ext_input", ")", ".", "union", "(", "versioned_ext_output", ")", "\n", "assert", "all", "(", "k", "in", "allowed_vbs", "for", "k", "in", "known_status", ")", "\n", "assert", "all", "(", "v", "is", "not", "None", "for", "v", "in", "known_status", ".", "values", "(", ")", ")", "\n", "_known_status", "=", "copy", ".", "deepcopy", "(", "known_status", ")", "\n", "\n", "def", "_check_and_update", "(", "key", ",", "value", ")", ":", "\n", "        ", "assert", "value", "is", "not", "None", "\n", "if", "key", "in", "_known_status", ":", "\n", "            ", "if", "not", "_known_status", "[", "key", "]", "==", "value", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Confilict status for {}, existing status {}, new status {}\"", ".", "format", "(", "\n", "key", ",", "_known_status", "[", "key", "]", ",", "value", "\n", ")", "\n", ")", "\n", "", "", "_known_status", "[", "key", "]", "=", "value", "\n", "\n", "", "def", "_update_i", "(", "op", ",", "ssa_i", ")", ":", "\n", "        ", "versioned_inputs", "=", "ssa_i", "[", "0", "]", "\n", "versioned_outputs", "=", "ssa_i", "[", "1", "]", "\n", "\n", "inputs_status", "=", "[", "_known_status", ".", "get", "(", "b", ",", "None", ")", "for", "b", "in", "versioned_inputs", "]", "\n", "outputs_status", "=", "[", "_known_status", ".", "get", "(", "b", ",", "None", ")", "for", "b", "in", "versioned_outputs", "]", "\n", "\n", "new_inputs_status", ",", "new_outputs_status", "=", "status_updater", "(", "op", ",", "inputs_status", ",", "outputs_status", ")", "\n", "\n", "for", "versioned_blob", ",", "status", "in", "zip", "(", "\n", "versioned_inputs", "+", "versioned_outputs", ",", "new_inputs_status", "+", "new_outputs_status", "\n", ")", ":", "\n", "            ", "if", "status", "is", "not", "None", ":", "\n", "                ", "_check_and_update", "(", "versioned_blob", ",", "status", ")", "\n", "\n", "", "", "", "for", "op", ",", "ssa_i", "in", "zip", "(", "predict_net", ".", "op", ",", "ssa", ")", ":", "\n", "        ", "_update_i", "(", "op", ",", "ssa_i", ")", "\n", "", "for", "op", ",", "ssa_i", "in", "zip", "(", "reversed", "(", "predict_net", ".", "op", ")", ",", "reversed", "(", "ssa", ")", ")", ":", "\n", "        ", "_update_i", "(", "op", ",", "ssa_i", ")", "\n", "\n", "# NOTE: This strictly checks all the blob from predict_net must be assgined", "\n", "# a known status. However sometimes it's impossible (eg. having deadend op),", "\n", "# we may relax this constraint if", "\n", "", "for", "k", "in", "all_versioned_blobs", ":", "\n", "        ", "if", "k", "not", "in", "_known_status", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Can not infer the status for {}. Currently only support the case where\"", "\n", "\" a single forward and backward pass can identify status for all blobs.\"", ".", "format", "(", "k", ")", "\n", ")", "\n", "\n", "", "", "return", "_known_status", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.infer_device_type": [[448, 486], ["shared._generic_status_identifier", "shared._updater_raise", "shared._updater_raise", "len", "all", "shared._updater_raise"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._generic_status_identifier", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._updater_raise", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._updater_raise", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._updater_raise"], ["", "def", "infer_device_type", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "known_status", ":", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "Any", "]", ",", "\n", "device_name_style", ":", "str", "=", "\"caffe2\"", ",", "\n", ")", "->", "Dict", "[", "Tuple", "[", "str", ",", "int", "]", ",", "str", "]", ":", "\n", "    ", "\"\"\" Return the device type (\"cpu\" or \"gpu\"/\"cuda\") of each (versioned) blob \"\"\"", "\n", "\n", "assert", "device_name_style", "in", "[", "\"caffe2\"", ",", "\"pytorch\"", "]", "\n", "_CPU_STR", "=", "\"cpu\"", "\n", "_GPU_STR", "=", "\"gpu\"", "if", "device_name_style", "==", "\"caffe2\"", "else", "\"cuda\"", "\n", "\n", "def", "_copy_cpu_to_gpu_updater", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "        ", "if", "input_types", "[", "0", "]", "==", "_GPU_STR", "or", "output_types", "[", "0", "]", "==", "_CPU_STR", ":", "\n", "            ", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", "", "return", "(", "[", "_CPU_STR", "]", ",", "[", "_GPU_STR", "]", ")", "\n", "\n", "", "def", "_copy_gpu_to_cpu_updater", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "        ", "if", "input_types", "[", "0", "]", "==", "_CPU_STR", "or", "output_types", "[", "0", "]", "==", "_GPU_STR", ":", "\n", "            ", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", "", "return", "(", "[", "_GPU_STR", "]", ",", "[", "_CPU_STR", "]", ")", "\n", "\n", "", "def", "_other_ops_updater", "(", "op", ",", "input_types", ",", "output_types", ")", ":", "\n", "        ", "non_none_types", "=", "[", "x", "for", "x", "in", "input_types", "+", "output_types", "if", "x", "is", "not", "None", "]", "\n", "if", "len", "(", "non_none_types", ")", ">", "0", ":", "\n", "            ", "the_type", "=", "non_none_types", "[", "0", "]", "\n", "if", "not", "all", "(", "x", "==", "the_type", "for", "x", "in", "non_none_types", ")", ":", "\n", "                ", "_updater_raise", "(", "op", ",", "input_types", ",", "output_types", ")", "\n", "", "", "else", ":", "\n", "            ", "the_type", "=", "None", "\n", "", "return", "(", "[", "the_type", "for", "_", "in", "op", ".", "input", "]", ",", "[", "the_type", "for", "_", "in", "op", ".", "output", "]", ")", "\n", "\n", "", "def", "_device_updater", "(", "op", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\n", "\"CopyCPUToGPU\"", ":", "_copy_cpu_to_gpu_updater", ",", "\n", "\"CopyGPUToCPU\"", ":", "_copy_gpu_to_cpu_updater", ",", "\n", "}", ".", "get", "(", "op", ".", "type", ",", "_other_ops_updater", ")", "(", "op", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "_generic_status_identifier", "(", "predict_net", ",", "_device_updater", ",", "known_status", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._modify_blob_names": [[491, 505], ["blob_list.extend", "copy.deepcopy", "shared._modify_blob_names._replace_list"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["", "def", "_modify_blob_names", "(", "ops", ",", "blob_rename_f", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "\n", "def", "_replace_list", "(", "blob_list", ",", "replaced_list", ")", ":", "\n", "        ", "del", "blob_list", "[", ":", "]", "\n", "blob_list", ".", "extend", "(", "replaced_list", ")", "\n", "\n", "", "for", "x", "in", "ops", ":", "\n", "        ", "cur", "=", "copy", ".", "deepcopy", "(", "x", ")", "\n", "_replace_list", "(", "cur", ".", "input", ",", "list", "(", "map", "(", "blob_rename_f", ",", "cur", ".", "input", ")", ")", ")", "\n", "_replace_list", "(", "cur", ".", "output", ",", "list", "(", "map", "(", "blob_rename_f", ",", "cur", ".", "output", ")", ")", ")", "\n", "ret", ".", "append", "(", "cur", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._rename_blob": [[507, 520], ["shared._rename_blob._list_to_str"], "function", ["None"], ["", "def", "_rename_blob", "(", "name", ",", "blob_sizes", ",", "blob_ranges", ")", ":", "\n", "    ", "def", "_list_to_str", "(", "bsize", ")", ":", "\n", "        ", "ret", "=", "\", \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "bsize", "]", ")", "\n", "ret", "=", "\"[\"", "+", "ret", "+", "\"]\"", "\n", "return", "ret", "\n", "\n", "", "ret", "=", "name", "\n", "if", "blob_sizes", "is", "not", "None", "and", "name", "in", "blob_sizes", ":", "\n", "        ", "ret", "+=", "\"\\n\"", "+", "_list_to_str", "(", "blob_sizes", "[", "name", "]", ")", "\n", "", "if", "blob_ranges", "is", "not", "None", "and", "name", "in", "blob_ranges", ":", "\n", "        ", "ret", "+=", "\"\\n\"", "+", "_list_to_str", "(", "blob_ranges", "[", "name", "]", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.save_graph": [[523, 526], ["functools.partial", "shared.save_graph_base"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.save_graph_base"], ["", "def", "save_graph", "(", "net", ",", "file_name", ",", "graph_name", "=", "\"net\"", ",", "op_only", "=", "True", ",", "blob_sizes", "=", "None", ",", "blob_ranges", "=", "None", ")", ":", "\n", "    ", "blob_rename_f", "=", "functools", ".", "partial", "(", "_rename_blob", ",", "blob_sizes", "=", "blob_sizes", ",", "blob_ranges", "=", "blob_ranges", ")", "\n", "return", "save_graph_base", "(", "net", ",", "file_name", ",", "graph_name", ",", "op_only", ",", "blob_rename_f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.save_graph_base": [[528, 558], ["shared._modify_blob_names", "caffe2.python.net_drawer.GetPydotGraph", "caffe2.python.net_drawer.GetPydotGraphMinimal", "os.path.dirname", "os.path.exists", "os.makedirs", "os.path.splitext", "net_drawer.GetPydotGraphMinimal.write_png", "print", "os.path.basename", "net_drawer.GetPydotGraphMinimal.write_pdf", "net_drawer.GetPydotGraphMinimal.write_svg", "print"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._modify_blob_names"], ["", "def", "save_graph_base", "(", "net", ",", "file_name", ",", "graph_name", "=", "\"net\"", ",", "op_only", "=", "True", ",", "blob_rename_func", "=", "None", ")", ":", "\n", "    ", "graph", "=", "None", "\n", "ops", "=", "net", ".", "op", "\n", "if", "blob_rename_func", "is", "not", "None", ":", "\n", "        ", "ops", "=", "_modify_blob_names", "(", "ops", ",", "blob_rename_func", ")", "\n", "", "if", "not", "op_only", ":", "\n", "        ", "graph", "=", "net_drawer", ".", "GetPydotGraph", "(", "ops", ",", "graph_name", ",", "rankdir", "=", "\"TB\"", ")", "\n", "", "else", ":", "\n", "        ", "graph", "=", "net_drawer", ".", "GetPydotGraphMinimal", "(", "\n", "ops", ",", "graph_name", ",", "rankdir", "=", "\"TB\"", ",", "minimal_dependency", "=", "True", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "par_dir", "=", "os", ".", "path", ".", "dirname", "(", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "par_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "par_dir", ")", "\n", "\n", "", "format", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "file_name", ")", ")", "[", "-", "1", "]", "\n", "if", "format", "==", "\".png\"", ":", "\n", "            ", "graph", ".", "write_png", "(", "file_name", ")", "\n", "", "elif", "format", "==", "\".pdf\"", ":", "\n", "            ", "graph", ".", "write_pdf", "(", "file_name", ")", "\n", "", "elif", "format", "==", "\".svg\"", ":", "\n", "            ", "graph", ".", "write_svg", "(", "file_name", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Incorrect format {}\"", ".", "format", "(", "format", ")", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Error when writing graph to image {}\"", ".", "format", "(", "e", ")", ")", "\n", "\n", "", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.group_norm_replace_aten_with_caffe2": [[563, 587], ["logger.info", "shared.get_pb_arg_vals", "op.arg.remove", "shared.get_pb_arg_vali", "shared.get_pb_arg_vali", "get_pb_arg_vals.decode", "shared.get_pb_arg", "op.arg.remove", "op.arg.remove", "shared.check_set_pb_arg", "shared.get_pb_arg", "shared.get_pb_arg"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg"], ["", "def", "group_norm_replace_aten_with_caffe2", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ")", ":", "\n", "    ", "\"\"\"\n    For ONNX exported model, GroupNorm will be represented as ATen op,\n        this can be a drop in replacement from ATen to GroupNorm\n    \"\"\"", "\n", "count", "=", "0", "\n", "for", "op", "in", "predict_net", ".", "op", ":", "\n", "        ", "if", "op", ".", "type", "==", "\"ATen\"", ":", "\n", "            ", "op_name", "=", "get_pb_arg_vals", "(", "op", ",", "\"operator\"", ",", "None", ")", "# return byte in py3", "\n", "if", "op_name", "and", "op_name", ".", "decode", "(", ")", "==", "\"group_norm\"", ":", "\n", "                ", "op", ".", "arg", ".", "remove", "(", "get_pb_arg", "(", "op", ",", "\"operator\"", ")", ")", "\n", "\n", "if", "get_pb_arg_vali", "(", "op", ",", "\"cudnn_enabled\"", ",", "None", ")", ":", "\n", "                    ", "op", ".", "arg", ".", "remove", "(", "get_pb_arg", "(", "op", ",", "\"cudnn_enabled\"", ")", ")", "\n", "\n", "", "num_groups", "=", "get_pb_arg_vali", "(", "op", ",", "\"num_groups\"", ",", "None", ")", "\n", "if", "num_groups", "is", "not", "None", ":", "\n", "                    ", "op", ".", "arg", ".", "remove", "(", "get_pb_arg", "(", "op", ",", "\"num_groups\"", ")", ")", "\n", "check_set_pb_arg", "(", "op", ",", "\"group\"", ",", "\"i\"", ",", "num_groups", ")", "\n", "\n", "", "op", ".", "type", "=", "\"GroupNorm\"", "\n", "count", "+=", "1", "\n", "", "", "", "if", "count", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Replaced {} ATen operator to GroupNormOp\"", ".", "format", "(", "count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias": [[592, 597], ["isinstance", "torch.ops._caffe2.AliasWithName", "torch.ops._caffe2.AliasWithName", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export"], "function", ["None"], ["", "", "def", "alias", "(", "x", ",", "name", ",", "is_backward", "=", "False", ")", ":", "\n", "    ", "if", "not", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "        ", "return", "x", "\n", "", "assert", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "\n", "return", "torch", ".", "ops", ".", "_caffe2", ".", "AliasWithName", "(", "x", ",", "name", ",", "is_backward", "=", "is_backward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.fuse_alias_placeholder": [[599, 622], ["enumerate", "predict_net.op.extend", "get_pb_arg_vals().decode", "bool", "shared.rename_op_input", "shared.rename_op_output", "new_ops.append", "len", "len", "shared.get_pb_arg_vali", "op.arg[].s.decode", "shared.get_pb_arg_vals"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.rename_op_input", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.rename_op_output", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals"], ["", "def", "fuse_alias_placeholder", "(", "predict_net", ",", "init_net", ")", ":", "\n", "    ", "\"\"\" Remove AliasWithName placeholder and rename the input/output of it \"\"\"", "\n", "# First we finish all the re-naming", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", ":", "\n", "        ", "if", "op", ".", "type", "==", "\"AliasWithName\"", ":", "\n", "            ", "assert", "len", "(", "op", ".", "input", ")", "==", "1", "\n", "assert", "len", "(", "op", ".", "output", ")", "==", "1", "\n", "name", "=", "get_pb_arg_vals", "(", "op", ",", "\"name\"", ",", "None", ")", ".", "decode", "(", ")", "\n", "is_backward", "=", "bool", "(", "get_pb_arg_vali", "(", "op", ",", "\"is_backward\"", ",", "0", ")", ")", "\n", "rename_op_input", "(", "predict_net", ",", "init_net", ",", "i", ",", "0", ",", "name", ",", "from_producer", "=", "is_backward", ")", "\n", "rename_op_output", "(", "predict_net", ",", "i", ",", "0", ",", "name", ")", "\n", "\n", "# Remove AliasWithName, should be very safe since it's a non-op", "\n", "", "", "new_ops", "=", "[", "]", "\n", "for", "op", "in", "predict_net", ".", "op", ":", "\n", "        ", "if", "op", ".", "type", "!=", "\"AliasWithName\"", ":", "\n", "            ", "new_ops", ".", "append", "(", "op", ")", "\n", "", "else", ":", "\n", "# safety check", "\n", "            ", "assert", "op", ".", "input", "==", "op", ".", "output", "\n", "assert", "op", ".", "input", "[", "0", "]", "==", "op", ".", "arg", "[", "0", "]", ".", "s", ".", "decode", "(", ")", "\n", "", "", "del", "predict_net", ".", "op", "[", ":", "]", "\n", "predict_net", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._rename_versioned_blob_in_proto": [[631, 660], ["zip", "range", "range", "start_versions.get", "range", "end_versions.get", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_rename_versioned_blob_in_proto", "(", "\n", "proto", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "old_name", ":", "str", ",", "\n", "new_name", ":", "str", ",", "\n", "version", ":", "int", ",", "\n", "ssa", ":", "List", "[", "Tuple", "[", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", ",", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", "]", "]", ",", "\n", "start_versions", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "end_versions", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", ")", ":", "\n", "    ", "\"\"\" In given proto, rename all blobs with matched version \"\"\"", "\n", "# Operater list", "\n", "for", "op", ",", "i_th_ssa", "in", "zip", "(", "proto", ".", "op", ",", "ssa", ")", ":", "\n", "        ", "versioned_inputs", ",", "versioned_outputs", "=", "i_th_ssa", "\n", "for", "i", "in", "range", "(", "len", "(", "op", ".", "input", ")", ")", ":", "\n", "            ", "if", "versioned_inputs", "[", "i", "]", "==", "(", "old_name", ",", "version", ")", ":", "\n", "                ", "op", ".", "input", "[", "i", "]", "=", "new_name", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "op", ".", "output", ")", ")", ":", "\n", "            ", "if", "versioned_outputs", "[", "i", "]", "==", "(", "old_name", ",", "version", ")", ":", "\n", "                ", "op", ".", "output", "[", "i", "]", "=", "new_name", "\n", "# external_input", "\n", "", "", "", "if", "start_versions", ".", "get", "(", "old_name", ",", "0", ")", "==", "version", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "proto", ".", "external_input", ")", ")", ":", "\n", "            ", "if", "proto", ".", "external_input", "[", "i", "]", "==", "old_name", ":", "\n", "                ", "proto", ".", "external_input", "[", "i", "]", "=", "new_name", "\n", "# external_output", "\n", "", "", "", "if", "end_versions", ".", "get", "(", "old_name", ",", "0", ")", "==", "version", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "proto", ".", "external_output", ")", ")", ":", "\n", "            ", "if", "proto", ".", "external_output", "[", "i", "]", "==", "old_name", ":", "\n", "                ", "proto", ".", "external_output", "[", "i", "]", "=", "new_name", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.rename_op_input": [[662, 726], ["isinstance", "isinstance", "caffe2.python.core.get_ssa", "caffe2.python.core.get_ssa", "shared._rename_versioned_blob_in_proto", "shared._rename_versioned_blob_in_proto", "copy.deepcopy", "shared.get_producer_map", "shared.rename_op_output", "shared.rename_op_input.contain_targets"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._rename_versioned_blob_in_proto", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._rename_versioned_blob_in_proto", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_producer_map", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.rename_op_output"], ["", "", "", "", "def", "rename_op_input", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "init_net", ":", "caffe2_pb2", ".", "NetDef", ",", "\n", "op_id", ":", "int", ",", "\n", "input_id", ":", "int", ",", "\n", "new_name", ":", "str", ",", "\n", "from_producer", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Rename the op_id-th operator in predict_net, change it's input_id-th input's\n        name to the new_name. It also does automatic re-route and change\n        external_input and init_net if necessary.\n    - It requires the input is only consumed by this op.\n    - This function modifies predict_net and init_net in-place.\n    - When from_producer is enable, this also updates other operators that consumes\n        the same input. Be cautious because may trigger unintended behavior.\n    \"\"\"", "\n", "assert", "isinstance", "(", "predict_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "assert", "isinstance", "(", "init_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "\n", "init_net_ssa", ",", "init_net_versions", "=", "core", ".", "get_ssa", "(", "init_net", ")", "\n", "predict_net_ssa", ",", "predict_net_versions", "=", "core", ".", "get_ssa", "(", "\n", "predict_net", ",", "copy", ".", "deepcopy", "(", "init_net_versions", ")", "\n", ")", "\n", "\n", "versioned_inputs", ",", "versioned_outputs", "=", "predict_net_ssa", "[", "op_id", "]", "\n", "old_name", ",", "version", "=", "versioned_inputs", "[", "input_id", "]", "\n", "\n", "if", "from_producer", ":", "\n", "        ", "producer_map", "=", "get_producer_map", "(", "predict_net_ssa", ")", "\n", "if", "not", "(", "old_name", ",", "version", ")", "in", "producer_map", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Can't find producer, the input {} is probably from\"", "\n", "\" init_net, this is not supported yet.\"", ".", "format", "(", "old_name", ")", "\n", ")", "\n", "", "producer", "=", "producer_map", "[", "(", "old_name", ",", "version", ")", "]", "\n", "rename_op_output", "(", "predict_net", ",", "producer", "[", "0", "]", ",", "producer", "[", "1", "]", ",", "new_name", ")", "\n", "return", "\n", "\n", "", "def", "contain_targets", "(", "op_ssa", ")", ":", "\n", "        ", "return", "(", "old_name", ",", "version", ")", "in", "op_ssa", "[", "0", "]", "\n", "\n", "", "is_consumer", "=", "[", "contain_targets", "(", "op_ssa", ")", "for", "op_ssa", "in", "predict_net_ssa", "]", "\n", "if", "sum", "(", "is_consumer", ")", ">", "1", ":", "\n", "        ", "raise", "IllegalGraphTransformError", "(", "\n", "(", "\n", "\"Input '{}' of operator(#{}) are consumed by other ops, please use\"", "\n", "+", "\" rename_op_output on the producer instead. Offending op: \\n{}\"", "\n", ")", ".", "format", "(", "old_name", ",", "op_id", ",", "predict_net", ".", "op", "[", "op_id", "]", ")", "\n", ")", "\n", "\n", "# update init_net", "\n", "", "_rename_versioned_blob_in_proto", "(", "\n", "init_net", ",", "old_name", ",", "new_name", ",", "version", ",", "init_net_ssa", ",", "{", "}", ",", "init_net_versions", "\n", ")", "\n", "# update predict_net", "\n", "_rename_versioned_blob_in_proto", "(", "\n", "predict_net", ",", "\n", "old_name", ",", "\n", "new_name", ",", "\n", "version", ",", "\n", "predict_net_ssa", ",", "\n", "init_net_versions", ",", "\n", "predict_net_versions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.rename_op_output": [[729, 747], ["isinstance", "caffe2.python.core.get_ssa", "shared._rename_versioned_blob_in_proto"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._rename_versioned_blob_in_proto"], ["", "def", "rename_op_output", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "op_id", ":", "int", ",", "output_id", ":", "int", ",", "new_name", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Rename the op_id-th operator in predict_net, change it's output_id-th input's\n        name to the new_name. It also does automatic re-route and change\n        external_output and if necessary.\n    - It allows multiple consumers of its output.\n    - This function modifies predict_net in-place, doesn't need init_net.\n    \"\"\"", "\n", "assert", "isinstance", "(", "predict_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "\n", "ssa", ",", "blob_versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "\n", "versioned_inputs", ",", "versioned_outputs", "=", "ssa", "[", "op_id", "]", "\n", "old_name", ",", "version", "=", "versioned_outputs", "[", "output_id", "]", "\n", "\n", "# update predict_net", "\n", "_rename_versioned_blob_in_proto", "(", "\n", "predict_net", ",", "old_name", ",", "new_name", ",", "version", ",", "ssa", ",", "{", "}", ",", "blob_versions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_sub_graph_external_input_output": [[750, 780], ["caffe2.python.core.get_ssa", "sum", "list", "range", "set", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "def", "get_sub_graph_external_input_output", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "sub_graph_op_indices", ":", "List", "[", "int", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", ",", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    Return the list of external input/output of sub-graph,\n    each element is tuple of the name and corresponding version in predict_net.\n\n    external input/output is defined the same way as caffe2 NetDef.\n    \"\"\"", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "\n", "all_inputs", "=", "[", "]", "\n", "all_outputs", "=", "[", "]", "\n", "for", "op_id", "in", "sub_graph_op_indices", ":", "\n", "        ", "all_inputs", "+=", "[", "inp", "for", "inp", "in", "ssa", "[", "op_id", "]", "[", "0", "]", "if", "inp", "not", "in", "all_inputs", "]", "\n", "all_outputs", "+=", "list", "(", "ssa", "[", "op_id", "]", "[", "1", "]", ")", "# ssa output won't repeat", "\n", "\n", "# for versioned blobs, external inputs are just those blob in all_inputs", "\n", "# but not in all_outputs", "\n", "", "ext_inputs", "=", "[", "inp", "for", "inp", "in", "all_inputs", "if", "inp", "not", "in", "all_outputs", "]", "\n", "\n", "# external outputs are essentially outputs of this subgraph that are used", "\n", "# outside of this sub-graph (including predict_net.external_output)", "\n", "all_other_inputs", "=", "sum", "(", "\n", "(", "ssa", "[", "i", "]", "[", "0", "]", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", "if", "i", "not", "in", "sub_graph_op_indices", ")", ",", "\n", "[", "(", "outp", ",", "versions", "[", "outp", "]", ")", "for", "outp", "in", "predict_net", ".", "external_output", "]", ",", "\n", ")", "\n", "ext_outputs", "=", "[", "outp", "for", "outp", "in", "all_outputs", "if", "outp", "in", "set", "(", "all_other_inputs", ")", "]", "\n", "\n", "return", "ext_inputs", ",", "ext_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._get_dependency_chain": [[825, 853], ["shared.get_consumer_map", "shared.get_producer_map", "shared.DiGraph.from_ssa", "DiGraph.from_ssa.get_all_paths", "sorted", "min", "len", "logger.warning", "set().union", "set", "set"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_consumer_map", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_producer_map", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.from_ssa", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.DiGraph.get_all_paths", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "", "def", "_get_dependency_chain", "(", "ssa", ",", "versioned_target", ",", "versioned_source", ")", ":", "\n", "    ", "\"\"\"\n    Return the index list of relevant operator to produce target blob from source blob,\n        if there's no dependency, return empty list.\n    \"\"\"", "\n", "\n", "# finding all paths between nodes can be O(N!), thus we can only search", "\n", "# in the subgraph using the op starting from the first consumer of source blob", "\n", "# to the producer of the target blob.", "\n", "consumer_map", "=", "get_consumer_map", "(", "ssa", ")", "\n", "producer_map", "=", "get_producer_map", "(", "ssa", ")", "\n", "start_op", "=", "min", "(", "x", "[", "0", "]", "for", "x", "in", "consumer_map", "[", "versioned_source", "]", ")", "-", "15", "\n", "end_op", "=", "(", "\n", "producer_map", "[", "versioned_target", "]", "[", "0", "]", "+", "15", "if", "versioned_target", "in", "producer_map", "else", "start_op", "\n", ")", "\n", "sub_graph_ssa", "=", "ssa", "[", "start_op", ":", "end_op", "+", "1", "]", "\n", "if", "len", "(", "sub_graph_ssa", ")", ">", "30", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Subgraph bebetween {} and {} is large (from op#{} to op#{}), it\"", "\n", "\" might take non-trival time to find all paths between them.\"", ".", "format", "(", "\n", "versioned_source", ",", "versioned_target", ",", "start_op", ",", "end_op", "\n", ")", "\n", ")", "\n", "\n", "", "dag", "=", "DiGraph", ".", "from_ssa", "(", "sub_graph_ssa", ")", "\n", "paths", "=", "dag", ".", "get_all_paths", "(", "versioned_source", ",", "versioned_target", ")", "# include two ends", "\n", "ops_in_paths", "=", "[", "[", "producer_map", "[", "blob", "]", "[", "0", "]", "for", "blob", "in", "path", "[", "1", ":", "]", "]", "for", "path", "in", "paths", "]", "\n", "return", "sorted", "(", "set", "(", ")", ".", "union", "(", "*", "[", "set", "(", "ops", ")", "for", "ops", "in", "ops_in_paths", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.identify_reshape_sub_graph": [[855, 880], ["caffe2.python.core.get_ssa", "enumerate", "shared._get_dependency_chain", "ret.append", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared._get_dependency_chain"], ["", "def", "identify_reshape_sub_graph", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Idenfity the reshape sub-graph in a protobuf.\n    The reshape sub-graph is defined as matching the following pattern:\n\n    (input_blob) -> Op_1 -> ... -> Op_N -> (new_shape) -\u2500\u2510\n        \u2514-------------------------------------------> Reshape -> (output_blob)\n\n    Return:\n        List of sub-graphs, each sub-graph is represented as a list of indices\n        of the relavent ops, [Op_1, Op_2, ..., Op_N, Reshape]\n    \"\"\"", "\n", "\n", "ssa", ",", "_", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", ":", "\n", "        ", "if", "op", ".", "type", "==", "\"Reshape\"", ":", "\n", "            ", "assert", "len", "(", "op", ".", "input", ")", "==", "2", "\n", "input_ssa", "=", "ssa", "[", "i", "]", "[", "0", "]", "\n", "data_source", "=", "input_ssa", "[", "0", "]", "\n", "shape_source", "=", "input_ssa", "[", "1", "]", "\n", "op_indices", "=", "_get_dependency_chain", "(", "ssa", ",", "shape_source", ",", "data_source", ")", "\n", "ret", ".", "append", "(", "op_indices", "+", "[", "i", "]", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.remove_reshape_for_fc": [[882, 950], ["shared.identify_reshape_sub_graph", "copy.deepcopy", "copy.deepcopy.op.extend", "caffe2.python.core.get_ssa", "all", "logger.info", "shared.rename_op_output", "shared.get_sub_graph_external_input_output", "remove_op_ids.extend", "params_to_remove.extend", "logger.info", "copy.deepcopy.external_input.remove", "shared.get_sub_graph_external_input_output", "enumerate", "range", "sub_graphs_to_remove.append", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.identify_reshape_sub_graph", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.rename_op_output", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_sub_graph_external_input_output", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.remove", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_sub_graph_external_input_output"], ["", "def", "remove_reshape_for_fc", "(", "predict_net", ",", "params", ")", ":", "\n", "    ", "\"\"\"\n    In PyTorch nn.Linear has to take 2D tensor, this often leads to reshape\n        a 4D tensor to 2D by calling .view(). However this (dynamic) reshaping\n        doesn't work well with ONNX and Int8 tools, and cause using extra\n        ops (eg. ExpandDims) that might not be available on mobile.\n    Luckily Caffe2 supports 4D tensor for FC, so we can remove those reshape\n        after exporting ONNX model.\n    \"\"\"", "\n", "from", "caffe2", ".", "python", "import", "core", "\n", "\n", "# find all reshape sub-graph that can be removed, which is now all Reshape", "\n", "# sub-graph whose output is only consumed by FC.", "\n", "# TODO: to make it safer, we may need the actually value to better determine", "\n", "# if a Reshape before FC is removable.", "\n", "reshape_sub_graphs", "=", "identify_reshape_sub_graph", "(", "predict_net", ")", "\n", "sub_graphs_to_remove", "=", "[", "]", "\n", "for", "reshape_sub_graph", "in", "reshape_sub_graphs", ":", "\n", "        ", "reshape_op_id", "=", "reshape_sub_graph", "[", "-", "1", "]", "\n", "assert", "predict_net", ".", "op", "[", "reshape_op_id", "]", ".", "type", "==", "\"Reshape\"", "\n", "ssa", ",", "_", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "reshape_output", "=", "ssa", "[", "reshape_op_id", "]", "[", "1", "]", "[", "0", "]", "\n", "consumers", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "ssa", ")", ")", "if", "reshape_output", "in", "ssa", "[", "i", "]", "[", "0", "]", "]", "\n", "if", "all", "(", "predict_net", ".", "op", "[", "consumer", "]", ".", "type", "==", "\"FC\"", "for", "consumer", "in", "consumers", ")", ":", "\n", "# safety check if the sub-graph is isolated, for this reshape sub-graph,", "\n", "# it means it has one non-param external input and one external output.", "\n", "            ", "ext_inputs", ",", "ext_outputs", "=", "get_sub_graph_external_input_output", "(", "\n", "predict_net", ",", "reshape_sub_graph", "\n", ")", "\n", "non_params_ext_inputs", "=", "[", "inp", "for", "inp", "in", "ext_inputs", "if", "inp", "[", "1", "]", "!=", "0", "]", "\n", "if", "len", "(", "non_params_ext_inputs", ")", "==", "1", "and", "len", "(", "ext_outputs", ")", "==", "1", ":", "\n", "                ", "sub_graphs_to_remove", ".", "append", "(", "reshape_sub_graph", ")", "\n", "\n", "# perform removing subgraph by:", "\n", "# 1: rename the Reshape's output to its input, then the graph can be", "\n", "#   seen as in-place itentify, meaning whose external input/output are the same.", "\n", "# 2: simply remove those ops.", "\n", "", "", "", "remove_op_ids", "=", "[", "]", "\n", "params_to_remove", "=", "[", "]", "\n", "for", "sub_graph", "in", "sub_graphs_to_remove", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Remove Reshape sub-graph:\\n{}\"", ".", "format", "(", "\n", "\"\"", ".", "join", "(", "[", "\"(#{:>4})\\n{}\"", ".", "format", "(", "i", ",", "predict_net", ".", "op", "[", "i", "]", ")", "for", "i", "in", "sub_graph", "]", ")", "\n", ")", "\n", ")", "\n", "reshape_op_id", "=", "sub_graph", "[", "-", "1", "]", "\n", "new_reshap_output", "=", "predict_net", ".", "op", "[", "reshape_op_id", "]", ".", "input", "[", "0", "]", "\n", "rename_op_output", "(", "predict_net", ",", "reshape_op_id", ",", "0", ",", "new_reshap_output", ")", "\n", "ext_inputs", ",", "ext_outputs", "=", "get_sub_graph_external_input_output", "(", "predict_net", ",", "sub_graph", ")", "\n", "non_params_ext_inputs", "=", "[", "inp", "for", "inp", "in", "ext_inputs", "if", "inp", "[", "1", "]", "!=", "0", "]", "\n", "params_ext_inputs", "=", "[", "inp", "for", "inp", "in", "ext_inputs", "if", "inp", "[", "1", "]", "==", "0", "]", "\n", "assert", "len", "(", "non_params_ext_inputs", ")", "==", "1", "and", "len", "(", "ext_outputs", ")", "==", "1", "\n", "assert", "ext_outputs", "[", "0", "]", "[", "0", "]", "==", "non_params_ext_inputs", "[", "0", "]", "[", "0", "]", "\n", "assert", "ext_outputs", "[", "0", "]", "[", "1", "]", "==", "non_params_ext_inputs", "[", "0", "]", "[", "1", "]", "+", "1", "\n", "remove_op_ids", ".", "extend", "(", "sub_graph", ")", "\n", "params_to_remove", ".", "extend", "(", "params_ext_inputs", ")", "\n", "\n", "", "predict_net", "=", "copy", ".", "deepcopy", "(", "predict_net", ")", "\n", "new_ops", "=", "[", "op", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", "if", "i", "not", "in", "remove_op_ids", "]", "\n", "del", "predict_net", ".", "op", "[", ":", "]", "\n", "predict_net", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "for", "versioned_params", "in", "params_to_remove", ":", "\n", "        ", "name", "=", "versioned_params", "[", "0", "]", "\n", "logger", ".", "info", "(", "\"Remove params: {} from init_net and predict_net.external_input\"", ".", "format", "(", "name", ")", ")", "\n", "del", "params", "[", "name", "]", "\n", "predict_net", ".", "external_input", ".", "remove", "(", "name", ")", "\n", "\n", "", "return", "predict_net", ",", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.fuse_copy_between_cpu_and_gpu": [[952, 1008], ["shared.fuse_copy_between_cpu_and_gpu._fuse_once"], "function", ["None"], ["", "def", "fuse_copy_between_cpu_and_gpu", "(", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ")", ":", "\n", "    ", "\"\"\"\n    In-place fuse extra copy ops between cpu/gpu for the following case:\n        a -CopyAToB-> b -CopyBToA> c1 -NextOp1-> d1\n                        -CopyBToA> c2 -NextOp2-> d2\n    The fused network will look like:\n        a -NextOp1-> d1\n          -NextOp2-> d2\n    \"\"\"", "\n", "\n", "_COPY_OPS", "=", "[", "\"CopyCPUToGPU\"", ",", "\"CopyGPUToCPU\"", "]", "\n", "\n", "def", "_fuse_once", "(", "predict_net", ")", ":", "\n", "        ", "ssa", ",", "blob_versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "consumer_map", "=", "get_consumer_map", "(", "ssa", ")", "\n", "versioned_external_output", "=", "[", "\n", "(", "name", ",", "blob_versions", "[", "name", "]", ")", "for", "name", "in", "predict_net", ".", "external_output", "\n", "]", "\n", "\n", "for", "op_id", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", ":", "\n", "            ", "if", "op", ".", "type", "in", "_COPY_OPS", ":", "\n", "                ", "fw_copy_versioned_output", "=", "ssa", "[", "op_id", "]", "[", "1", "]", "[", "0", "]", "\n", "consumer_ids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "consumer_map", "[", "fw_copy_versioned_output", "]", "]", "\n", "reverse_op_type", "=", "_COPY_OPS", "[", "1", "-", "_COPY_OPS", ".", "index", "(", "op", ".", "type", ")", "]", "\n", "\n", "is_fusable", "=", "(", "\n", "len", "(", "consumer_ids", ")", ">", "0", "\n", "and", "fw_copy_versioned_output", "not", "in", "versioned_external_output", "\n", "and", "all", "(", "\n", "predict_net", ".", "op", "[", "_op_id", "]", ".", "type", "==", "reverse_op_type", "\n", "and", "ssa", "[", "_op_id", "]", "[", "1", "]", "[", "0", "]", "not", "in", "versioned_external_output", "\n", "for", "_op_id", "in", "consumer_ids", "\n", ")", "\n", ")", "\n", "\n", "if", "is_fusable", ":", "\n", "                    ", "for", "rv_copy_op_id", "in", "consumer_ids", ":", "\n", "# making each NextOp uses \"a\" directly and removing Copy ops", "\n", "                        ", "rs_copy_versioned_output", "=", "ssa", "[", "rv_copy_op_id", "]", "[", "1", "]", "[", "0", "]", "\n", "next_op_id", ",", "inp_id", "=", "consumer_map", "[", "rs_copy_versioned_output", "]", "[", "0", "]", "\n", "predict_net", ".", "op", "[", "next_op_id", "]", ".", "input", "[", "inp_id", "]", "=", "op", ".", "input", "[", "0", "]", "\n", "# remove CopyOps", "\n", "", "new_ops", "=", "[", "\n", "op", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "predict_net", ".", "op", ")", "\n", "if", "i", "!=", "op_id", "and", "i", "not", "in", "consumer_ids", "\n", "]", "\n", "del", "predict_net", ".", "op", "[", ":", "]", "\n", "predict_net", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "return", "True", "\n", "\n", "", "", "", "return", "False", "\n", "\n", "# _fuse_once returns False is nothing can be fused", "\n", "", "while", "_fuse_once", "(", "predict_net", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.remove_dead_end_ops": [[1010, 1035], ["caffe2.python.core.get_ssa", "shared.get_consumer_map", "set", "reversed", "net_def.op.extend", "list", "all", "enumerate", "set.add", "enumerate", "shared.remove_dead_end_ops._is_dead_end"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_consumer_map", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], ["", "", "def", "remove_dead_end_ops", "(", "net_def", ":", "caffe2_pb2", ".", "NetDef", ")", ":", "\n", "    ", "\"\"\" remove ops if its output is not used or not in external_output \"\"\"", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "net_def", ")", "\n", "versioned_external_output", "=", "[", "(", "name", ",", "versions", "[", "name", "]", ")", "for", "name", "in", "net_def", ".", "external_output", "]", "\n", "consumer_map", "=", "get_consumer_map", "(", "ssa", ")", "\n", "removed_op_ids", "=", "set", "(", ")", "\n", "\n", "def", "_is_dead_end", "(", "versioned_blob", ")", ":", "\n", "        ", "return", "not", "(", "\n", "versioned_blob", "in", "versioned_external_output", "\n", "or", "(", "\n", "len", "(", "consumer_map", "[", "versioned_blob", "]", ")", ">", "0", "\n", "and", "all", "(", "x", "[", "0", "]", "not", "in", "removed_op_ids", "for", "x", "in", "consumer_map", "[", "versioned_blob", "]", ")", "\n", ")", "\n", ")", "\n", "\n", "", "for", "i", ",", "ssa_i", "in", "reversed", "(", "list", "(", "enumerate", "(", "ssa", ")", ")", ")", ":", "\n", "        ", "versioned_outputs", "=", "ssa_i", "[", "1", "]", "\n", "if", "all", "(", "_is_dead_end", "(", "outp", ")", "for", "outp", "in", "versioned_outputs", ")", ":", "\n", "            ", "removed_op_ids", ".", "add", "(", "i", ")", "\n", "\n", "# simply removing those deadend ops should have no effect to external_output", "\n", "", "", "new_ops", "=", "[", "op", "for", "i", ",", "op", "in", "enumerate", "(", "net_def", ".", "op", ")", "if", "i", "not", "in", "removed_op_ids", "]", "\n", "del", "net_def", ".", "op", "[", ":", "]", "\n", "net_def", ".", "op", ".", "extend", "(", "new_ops", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.Caffe2CompatibleConverter.__init__": [[32, 34], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "replaceCls", ")", ":", "\n", "        ", "self", ".", "replaceCls", "=", "replaceCls", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.Caffe2CompatibleConverter.create_from": [[35, 55], ["isinstance", "issubclass", "isinstance", "type"], "methods", ["None"], ["", "def", "create_from", "(", "self", ",", "module", ")", ":", "\n", "# update module's class to the new class", "\n", "        ", "assert", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "if", "issubclass", "(", "self", ".", "replaceCls", ",", "GenericMixin", ")", ":", "\n", "# replaceCls should act as mixin, create a new class on-the-fly", "\n", "            ", "new_class", "=", "type", "(", "\n", "\"{}MixedWith{}\"", ".", "format", "(", "self", ".", "replaceCls", ".", "__name__", ",", "module", ".", "__class__", ".", "__name__", ")", ",", "\n", "(", "self", ".", "replaceCls", ",", "module", ".", "__class__", ")", ",", "\n", "{", "}", ",", "# {\"new_method\": lambda self: ...},", "\n", ")", "\n", "module", ".", "__class__", "=", "new_class", "\n", "", "else", ":", "\n", "# replaceCls is complete class, this allow arbitrary class swap", "\n", "            ", "module", ".", "__class__", "=", "self", ".", "replaceCls", "\n", "\n", "# initialize Caffe2Compatible", "\n", "", "if", "isinstance", "(", "module", ",", "Caffe2Compatible", ")", ":", "\n", "            ", "module", ".", "tensor_mode", "=", "False", "\n", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.ROIHeadsPatcher.__init__": [[115, 118], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "heads", ",", "use_heatmap_max_keypoint", ")", ":", "\n", "        ", "self", ".", "heads", "=", "heads", "\n", "self", ".", "use_heatmap_max_keypoint", "=", "use_heatmap_max_keypoint", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.ROIHeadsPatcher.mock_roi_heads": [[119, 153], ["getattr", "getattr", "caffe2_patch.mock_fastrcnn_outputs_inference", "contextlib.ExitStack", "caffe2_patch.mock_keypoint_rcnn_inference", "caffe2_patch.mock_mask_rcnn_inference", "stack.enter_context", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.mock_fastrcnn_outputs_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.mock_keypoint_rcnn_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.mock_mask_rcnn_inference"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_roi_heads", "(", "self", ",", "tensor_mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Patching several inference functions inside ROIHeads and its subclasses\n\n        Args:\n            tensor_mode (bool): whether the inputs/outputs are caffe2's tensor\n                format or not. Default to True.\n        \"\"\"", "\n", "# NOTE: this requries the `keypoint_rcnn_inference` and `mask_rcnn_inference`", "\n", "# are called inside the same file as BaseXxxHead due to using mock.patch.", "\n", "kpt_heads_mod", "=", "keypoint_head", ".", "BaseKeypointRCNNHead", ".", "__module__", "\n", "mask_head_mod", "=", "mask_head", ".", "BaseMaskRCNNHead", ".", "__module__", "\n", "\n", "mock_ctx_managers", "=", "[", "\n", "mock_fastrcnn_outputs_inference", "(", "\n", "tensor_mode", "=", "tensor_mode", ",", "\n", "check", "=", "True", ",", "\n", "box_predictor_type", "=", "type", "(", "self", ".", "heads", ".", "box_predictor", ")", ",", "\n", ")", "\n", "]", "\n", "if", "getattr", "(", "self", ".", "heads", ",", "\"keypoint_on\"", ",", "False", ")", ":", "\n", "            ", "mock_ctx_managers", "+=", "[", "\n", "mock_keypoint_rcnn_inference", "(", "\n", "tensor_mode", ",", "kpt_heads_mod", ",", "self", ".", "use_heatmap_max_keypoint", "\n", ")", "\n", "]", "\n", "", "if", "getattr", "(", "self", ".", "heads", ",", "\"mask_on\"", ",", "False", ")", ":", "\n", "            ", "mock_ctx_managers", "+=", "[", "mock_mask_rcnn_inference", "(", "tensor_mode", ",", "mask_head_mod", ")", "]", "\n", "\n", "", "with", "contextlib", ".", "ExitStack", "(", ")", "as", "stack", ":", "# python 3.3+", "\n", "            ", "for", "mgr", "in", "mock_ctx_managers", ":", "\n", "                ", "stack", ".", "enter_context", "(", "mgr", ")", "\n", "", "yield", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch": [[57, 68], ["model.named_children", "isinstance", "caffe2_patch.patch", "updater.create_from", "detectron2.modeling.proposal_generator.rpn.RPN", "detectron2.modeling.poolers.ROIPooler"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.Caffe2CompatibleConverter.create_from"], ["", "", "def", "patch", "(", "model", ",", "target", ",", "updater", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    recursively (post-order) update all modules with the target type and its\n    subclasses, make a initialization/composition/inheritance/... via the\n    updater.create_from.\n    \"\"\"", "\n", "for", "name", ",", "module", "in", "model", ".", "named_children", "(", ")", ":", "\n", "        ", "model", ".", "_modules", "[", "name", "]", "=", "patch", "(", "module", ",", "target", ",", "updater", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "isinstance", "(", "model", ",", "target", ")", ":", "\n", "        ", "return", "updater", ".", "create_from", "(", "model", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch_generalized_rcnn": [[70, 76], ["caffe2_patch.patch", "caffe2_patch.patch", "ccc", "ccc"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch"], ["", "def", "patch_generalized_rcnn", "(", "model", ")", ":", "\n", "    ", "ccc", "=", "Caffe2CompatibleConverter", "\n", "model", "=", "patch", "(", "model", ",", "rpn", ".", "RPN", ",", "ccc", "(", "Caffe2RPN", ")", ")", "\n", "model", "=", "patch", "(", "model", ",", "poolers", ".", "ROIPooler", ",", "ccc", "(", "Caffe2ROIPooler", ")", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.mock_fastrcnn_outputs_inference": [[78, 91], ["unittest.mock.patch.object", "c10.Caffe2FastRCNNOutputsInference"], "function", ["None"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_fastrcnn_outputs_inference", "(", "\n", "tensor_mode", ",", "check", "=", "True", ",", "box_predictor_type", "=", "FastRCNNOutputLayers", "\n", ")", ":", "\n", "    ", "with", "mock", ".", "patch", ".", "object", "(", "\n", "box_predictor_type", ",", "\n", "\"inference\"", ",", "\n", "autospec", "=", "True", ",", "\n", "side_effect", "=", "Caffe2FastRCNNOutputsInference", "(", "tensor_mode", ")", ",", "\n", ")", "as", "mocked_func", ":", "\n", "        ", "yield", "\n", "", "if", "check", ":", "\n", "        ", "assert", "mocked_func", ".", "call_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.mock_mask_rcnn_inference": [[93, 101], ["unittest.mock.patch", "c10.Caffe2MaskRCNNInference"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_mask_rcnn_inference", "(", "tensor_mode", ",", "patched_module", ",", "check", "=", "True", ")", ":", "\n", "    ", "with", "mock", ".", "patch", "(", "\n", "\"{}.mask_rcnn_inference\"", ".", "format", "(", "patched_module", ")", ",", "side_effect", "=", "Caffe2MaskRCNNInference", "(", ")", "\n", ")", "as", "mocked_func", ":", "\n", "        ", "yield", "\n", "", "if", "check", ":", "\n", "        ", "assert", "mocked_func", ".", "call_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.mock_keypoint_rcnn_inference": [[103, 112], ["unittest.mock.patch", "c10.Caffe2KeypointRCNNInference"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "mock_keypoint_rcnn_inference", "(", "tensor_mode", ",", "patched_module", ",", "use_heatmap_max_keypoint", ",", "check", "=", "True", ")", ":", "\n", "    ", "with", "mock", ".", "patch", "(", "\n", "\"{}.keypoint_rcnn_inference\"", ".", "format", "(", "patched_module", ")", ",", "\n", "side_effect", "=", "Caffe2KeypointRCNNInference", "(", "use_heatmap_max_keypoint", ")", ",", "\n", ")", "as", "mocked_func", ":", "\n", "        ", "yield", "\n", "", "if", "check", ":", "\n", "        ", "assert", "mocked_func", ".", "call_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch.__init__": [[145, 156], ["super().__init__", "caffe2_modeling.Caffe2MetaArch.eval", "caffe2_modeling.set_caffe2_compatible_tensor_mode"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.set_caffe2_compatible_tensor_mode"], ["def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            torch_model (nn.Module): the detectron2 model (meta_arch) to be\n                converted.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_wrapped_model", "=", "torch_model", "\n", "self", ".", "eval", "(", ")", "\n", "set_caffe2_compatible_tensor_mode", "(", "self", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch.get_caffe2_inputs": [[157, 179], ["caffe2_modeling.convert_batched_inputs_to_c2_format"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.convert_batched_inputs_to_c2_format"], ["", "def", "get_caffe2_inputs", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Convert pytorch-style structured inputs to caffe2-style inputs that\n        are tuples of tensors.\n\n        Args:\n            batched_inputs (list[dict]): inputs to a detectron2 model\n                in its standard format. Each dict has \"image\" (CHW tensor), and optionally\n                \"height\" and \"width\".\n\n        Returns:\n            tuple[Tensor]:\n                tuple of tensors that will be the inputs to the\n                :meth:`forward` method. For existing models, the first\n                is an NCHW tensor (padded and batched); the second is\n                a im_info Nx3 tensor, where the rows are\n                (height, width, unused legacy parameter)\n        \"\"\"", "\n", "return", "convert_batched_inputs_to_c2_format", "(", "\n", "batched_inputs", ",", "\n", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", ",", "\n", "self", ".", "_wrapped_model", ".", "device", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch.encode_additional_info": [[181, 186], ["None"], "methods", ["None"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "\"\"\"\n        Save extra metadata that will be used by inference in the output protobuf.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch.forward": [[187, 201], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward in caffe2-style. It has to use caffe2-compatible ops\n        and the method will be used for tracing.\n\n        Args:\n            inputs (tuple[Tensor]): inputs defined by :meth:`get_caffe2_input`.\n                They will be the inputs of the converted caffe2 graph.\n\n        Returns:\n            tuple[Tensor]: output tensors. They will be the outputs of the\n                converted caffe2 graph.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image": [[202, 218], ["shared.alias", "shared.alias", "shared.alias", "detectron2.structures.ImageList"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias"], ["", "def", "_caffe2_preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Caffe2 implementation of preprocess_image, which is called inside each MetaArch's forward.\n        It normalizes the input images, and the final caffe2 graph assumes the\n        inputs have been batched already.\n        \"\"\"", "\n", "data", ",", "im_info", "=", "inputs", "\n", "data", "=", "alias", "(", "data", ",", "\"data\"", ")", "\n", "im_info", "=", "alias", "(", "im_info", ",", "\"im_info\"", ")", "\n", "mean", ",", "std", "=", "self", ".", "_wrapped_model", ".", "pixel_mean", ",", "self", ".", "_wrapped_model", ".", "pixel_std", "\n", "normalized_data", "=", "(", "data", "-", "mean", ")", "/", "std", "\n", "normalized_data", "=", "alias", "(", "normalized_data", ",", "\"normalized_data\"", ")", "\n", "\n", "# Pack (data, im_info) into ImageList which is recognized by self.inference.", "\n", "images", "=", "ImageList", "(", "tensor", "=", "normalized_data", ",", "image_sizes", "=", "im_info", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch.get_outputs_converter": [[219, 246], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "\"\"\"\n        Creates a function that converts outputs of the caffe2 model to\n        detectron2's standard format.\n        The function uses information in `predict_net` and `init_net` that are\n        available at inferene time. Therefore the function logic can be used in inference.\n\n        The returned function has the following signature:\n\n            def convert(batched_inputs, c2_inputs, c2_results) -> detectron2_outputs\n\n        Where\n\n            * batched_inputs (list[dict]): the original input format of the meta arch\n            * c2_inputs (tuple[Tensor]): the caffe2 inputs.\n            * c2_results (dict[str, Tensor]): the caffe2 output format,\n                corresponding to the outputs of the :meth:`forward` function.\n            * detectron2_outputs: the original output format of the meta arch.\n\n        This function can be used to compare the outputs of the original meta arch and\n        the converted caffe2 graph.\n\n        Returns:\n            callable: a callable of the above signature.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2GeneralizedRCNN.__init__": [[249, 256], ["isinstance", "caffe2_patch.patch_generalized_rcnn", "caffe2_modeling.Caffe2MetaArch.__init__", "caffe2_patch.ROIHeadsPatcher"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch_generalized_rcnn", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "torch_model", ",", "meta_arch", ".", "GeneralizedRCNN", ")", "\n", "torch_model", "=", "patch_generalized_rcnn", "(", "torch_model", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "torch_model", ")", "\n", "\n", "self", ".", "roi_heads_patcher", "=", "ROIHeadsPatcher", "(", "\n", "self", ".", "_wrapped_model", ".", "roi_heads", ",", "cfg", ".", "EXPORT_CAFFE2", ".", "USE_HEATMAP_MAX_KEYPOINT", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2GeneralizedRCNN.encode_additional_info": [[258, 265], ["shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "str.encode", "str"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "size_divisibility", "=", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"size_divisibility\"", ",", "\"i\"", ",", "size_divisibility", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"device\"", ",", "\"s\"", ",", "str", ".", "encode", "(", "str", "(", "self", ".", "_wrapped_model", ".", "device", ")", ",", "\"ascii\"", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"meta_architecture\"", ",", "\"s\"", ",", "b\"GeneralizedRCNN\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2GeneralizedRCNN.forward": [[266, 276], ["shared.mock_torch_nn_functional_interpolate", "caffe2_modeling.Caffe2GeneralizedRCNN._caffe2_preprocess_image", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.backbone", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.proposal_generator", "tuple", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.inference", "caffe2_modeling.Caffe2GeneralizedRCNN.roi_heads_patcher.mock_roi_heads", "caffe2_modeling.Caffe2GeneralizedRCNN._wrapped_model.roi_heads", "detector_results[].flatten"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.mock_torch_nn_functional_interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.ROIHeadsPatcher.mock_roi_heads", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "@", "mock_torch_nn_functional_interpolate", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "not", "self", ".", "tensor_mode", ":", "\n", "            ", "return", "self", ".", "_wrapped_model", ".", "inference", "(", "inputs", ")", "\n", "", "images", "=", "self", ".", "_caffe2_preprocess_image", "(", "inputs", ")", "\n", "features", "=", "self", ".", "_wrapped_model", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "proposals", ",", "_", "=", "self", ".", "_wrapped_model", ".", "proposal_generator", "(", "images", ",", "features", ")", "\n", "with", "self", ".", "roi_heads_patcher", ".", "mock_roi_heads", "(", ")", ":", "\n", "            ", "detector_results", ",", "_", "=", "self", ".", "_wrapped_model", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ")", "\n", "", "return", "tuple", "(", "detector_results", "[", "0", "]", ".", "flatten", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2GeneralizedRCNN.get_outputs_converter": [[277, 286], ["caffe2_modeling.assemble_rcnn_outputs_by_name", "detectron2.modeling.meta_arch.GeneralizedRCNN._postprocess", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.assemble_rcnn_outputs_by_name", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._postprocess"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "def", "f", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", ":", "\n", "            ", "_", ",", "im_info", "=", "c2_inputs", "\n", "image_sizes", "=", "[", "[", "int", "(", "im", "[", "0", "]", ")", ",", "int", "(", "im", "[", "1", "]", ")", "]", "for", "im", "in", "im_info", "]", "\n", "results", "=", "assemble_rcnn_outputs_by_name", "(", "image_sizes", ",", "c2_results", ")", "\n", "return", "meta_arch", ".", "GeneralizedRCNN", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "image_sizes", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2PanopticFPN.__init__": [[289, 296], ["isinstance", "caffe2_patch.patch_generalized_rcnn", "caffe2_modeling.Caffe2MetaArch.__init__", "caffe2_patch.ROIHeadsPatcher"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch_generalized_rcnn", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "torch_model", ",", "meta_arch", ".", "PanopticFPN", ")", "\n", "torch_model", "=", "patch_generalized_rcnn", "(", "torch_model", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "torch_model", ")", "\n", "\n", "self", ".", "roi_heads_patcher", "=", "ROIHeadsPatcher", "(", "\n", "self", ".", "_wrapped_model", ".", "roi_heads", ",", "cfg", ".", "EXPORT_CAFFE2", ".", "USE_HEATMAP_MAX_KEYPOINT", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2PanopticFPN.forward": [[298, 313], ["shared.mock_torch_nn_functional_interpolate", "caffe2_modeling.Caffe2PanopticFPN._caffe2_preprocess_image", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.backbone", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.sem_seg_head", "shared.alias", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.proposal_generator", "caffe2_modeling.Caffe2PanopticFPN.roi_heads_patcher.mock_roi_heads", "caffe2_modeling.Caffe2PanopticFPN._wrapped_model.roi_heads", "tuple", "detector_results[].flatten"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.mock_torch_nn_functional_interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.ROIHeadsPatcher.mock_roi_heads", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "@", "mock_torch_nn_functional_interpolate", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "self", ".", "tensor_mode", "\n", "images", "=", "self", ".", "_caffe2_preprocess_image", "(", "inputs", ")", "\n", "features", "=", "self", ".", "_wrapped_model", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "sem_seg_results", ",", "_", "=", "self", ".", "_wrapped_model", ".", "sem_seg_head", "(", "features", ")", "\n", "sem_seg_results", "=", "alias", "(", "sem_seg_results", ",", "\"sem_seg\"", ")", "\n", "\n", "proposals", ",", "_", "=", "self", ".", "_wrapped_model", ".", "proposal_generator", "(", "images", ",", "features", ")", "\n", "\n", "with", "self", ".", "roi_heads_patcher", ".", "mock_roi_heads", "(", "self", ".", "tensor_mode", ")", ":", "\n", "            ", "detector_results", ",", "_", "=", "self", ".", "_wrapped_model", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ")", "\n", "\n", "", "return", "tuple", "(", "detector_results", "[", "0", "]", ".", "flatten", "(", ")", ")", "+", "(", "sem_seg_results", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2PanopticFPN.encode_additional_info": [[314, 340], ["shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "str.encode", "caffe2_modeling._cast_to_f32", "caffe2_modeling._cast_to_f32", "str"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling._cast_to_f32", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling._cast_to_f32"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "size_divisibility", "=", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"size_divisibility\"", ",", "\"i\"", ",", "size_divisibility", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"device\"", ",", "\"s\"", ",", "str", ".", "encode", "(", "str", "(", "self", ".", "_wrapped_model", ".", "device", ")", ",", "\"ascii\"", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"meta_architecture\"", ",", "\"s\"", ",", "b\"PanopticFPN\"", ")", "\n", "\n", "# Inference parameters:", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"combine_overlap_threshold\"", ",", "\n", "\"f\"", ",", "\n", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "combine_overlap_thresh", ")", ",", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"combine_stuff_area_limit\"", ",", "\n", "\"i\"", ",", "\n", "self", ".", "_wrapped_model", ".", "combine_stuff_area_thresh", ",", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"combine_instances_confidence_threshold\"", ",", "\n", "\"f\"", ",", "\n", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "combine_instances_score_thresh", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2PanopticFPN.get_outputs_converter": [[342, 381], ["shared.get_pb_arg_valf", "shared.get_pb_arg_vali", "shared.get_pb_arg_valf", "caffe2_modeling.assemble_rcnn_outputs_by_name", "zip", "input_per_image.get", "input_per_image.get", "detectron2.modeling.postprocessing.sem_seg_postprocess", "detectron2.modeling.postprocessing.detector_postprocess", "processed_results.append", "detectron2.modeling.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs", "int", "int", "detectron2.modeling.postprocessing.sem_seg_postprocess.argmax"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.assemble_rcnn_outputs_by_name", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.detector_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.panoptic_fpn.combine_semantic_and_instance_outputs"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "combine_overlap_threshold", "=", "get_pb_arg_valf", "(", "predict_net", ",", "\"combine_overlap_threshold\"", ",", "None", ")", "\n", "combine_stuff_area_limit", "=", "get_pb_arg_vali", "(", "predict_net", ",", "\"combine_stuff_area_limit\"", ",", "None", ")", "\n", "combine_instances_confidence_threshold", "=", "get_pb_arg_valf", "(", "\n", "predict_net", ",", "\"combine_instances_confidence_threshold\"", ",", "None", "\n", ")", "\n", "\n", "def", "f", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", ":", "\n", "            ", "_", ",", "im_info", "=", "c2_inputs", "\n", "image_sizes", "=", "[", "[", "int", "(", "im", "[", "0", "]", ")", ",", "int", "(", "im", "[", "1", "]", ")", "]", "for", "im", "in", "im_info", "]", "\n", "detector_results", "=", "assemble_rcnn_outputs_by_name", "(", "\n", "image_sizes", ",", "c2_results", ",", "force_mask_on", "=", "True", "\n", ")", "\n", "sem_seg_results", "=", "c2_results", "[", "\"sem_seg\"", "]", "\n", "\n", "# copied from meta_arch/panoptic_fpn.py ...", "\n", "processed_results", "=", "[", "]", "\n", "for", "sem_seg_result", ",", "detector_result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "sem_seg_results", ",", "detector_results", ",", "batched_inputs", ",", "image_sizes", "\n", ")", ":", "\n", "                ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "sem_seg_r", "=", "sem_seg_postprocess", "(", "sem_seg_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "detector_r", "=", "detector_postprocess", "(", "detector_result", ",", "height", ",", "width", ")", "\n", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "sem_seg_r", ",", "\"instances\"", ":", "detector_r", "}", ")", "\n", "\n", "panoptic_r", "=", "combine_semantic_and_instance_outputs", "(", "\n", "detector_r", ",", "\n", "sem_seg_r", ".", "argmax", "(", "dim", "=", "0", ")", ",", "\n", "combine_overlap_threshold", ",", "\n", "combine_stuff_area_limit", ",", "\n", "combine_instances_confidence_threshold", ",", "\n", ")", "\n", "processed_results", "[", "-", "1", "]", "[", "\"panoptic_seg\"", "]", "=", "panoptic_r", "\n", "", "return", "processed_results", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet.__init__": [[384, 387], ["isinstance", "caffe2_modeling.Caffe2MetaArch.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "torch_model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "torch_model", ",", "meta_arch", ".", "RetinaNet", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "torch_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet.forward": [[388, 409], ["shared.mock_torch_nn_functional_interpolate", "caffe2_modeling.Caffe2RetinaNet._caffe2_preprocess_image", "caffe2_modeling.Caffe2RetinaNet._wrapped_model.backbone", "enumerate", "caffe2_modeling.Caffe2RetinaNet._wrapped_model.head", "enumerate", "tuple", "shared.alias", "return_tensors.append", "zip", "return_tensors.append", "return_tensors.append", "shared.alias", "shared.alias"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.mock_torch_nn_functional_interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch._caffe2_preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias"], ["", "@", "mock_torch_nn_functional_interpolate", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "self", ".", "tensor_mode", "\n", "images", "=", "self", ".", "_caffe2_preprocess_image", "(", "inputs", ")", "\n", "\n", "# explicitly return the images sizes to avoid removing \"im_info\" by ONNX", "\n", "# since it's not used in the forward path", "\n", "return_tensors", "=", "[", "images", ".", "image_sizes", "]", "\n", "\n", "features", "=", "self", ".", "_wrapped_model", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "_wrapped_model", ".", "head_in_features", "]", "\n", "for", "i", ",", "feature_i", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "features", "[", "i", "]", "=", "alias", "(", "feature_i", ",", "\"feature_{}\"", ".", "format", "(", "i", ")", ",", "is_backward", "=", "True", ")", "\n", "return_tensors", ".", "append", "(", "features", "[", "i", "]", ")", "\n", "\n", "", "pred_logits", ",", "pred_anchor_deltas", "=", "self", ".", "_wrapped_model", ".", "head", "(", "features", ")", "\n", "for", "i", ",", "(", "box_cls_i", ",", "box_delta_i", ")", "in", "enumerate", "(", "zip", "(", "pred_logits", ",", "pred_anchor_deltas", ")", ")", ":", "\n", "            ", "return_tensors", ".", "append", "(", "alias", "(", "box_cls_i", ",", "\"box_cls_{}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "return_tensors", ".", "append", "(", "alias", "(", "box_delta_i", ",", "\"box_delta_{}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "\n", "", "return", "tuple", "(", "return_tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet.encode_additional_info": [[410, 442], ["shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "shared.check_set_pb_arg", "caffe2_modeling.Caffe2RetinaNet._encode_anchor_generator_cfg", "str.encode", "caffe2_modeling._cast_to_f32", "caffe2_modeling._cast_to_f32", "str", "caffe2_modeling._cast_to_f32"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet._encode_anchor_generator_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.encode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling._cast_to_f32", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling._cast_to_f32", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling._cast_to_f32"], ["", "def", "encode_additional_info", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "size_divisibility", "=", "self", ".", "_wrapped_model", ".", "backbone", ".", "size_divisibility", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"size_divisibility\"", ",", "\"i\"", ",", "size_divisibility", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"device\"", ",", "\"s\"", ",", "str", ".", "encode", "(", "str", "(", "self", ".", "_wrapped_model", ".", "device", ")", ",", "\"ascii\"", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"meta_architecture\"", ",", "\"s\"", ",", "b\"RetinaNet\"", ")", "\n", "\n", "# Inference parameters:", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"score_threshold\"", ",", "\"f\"", ",", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "test_score_thresh", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"topk_candidates\"", ",", "\"i\"", ",", "self", ".", "_wrapped_model", ".", "test_topk_candidates", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\"nms_threshold\"", ",", "\"f\"", ",", "_cast_to_f32", "(", "self", ".", "_wrapped_model", ".", "test_nms_thresh", ")", "\n", ")", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"max_detections_per_image\"", ",", "\n", "\"i\"", ",", "\n", "self", ".", "_wrapped_model", ".", "max_detections_per_image", ",", "\n", ")", "\n", "\n", "check_set_pb_arg", "(", "\n", "predict_net", ",", "\n", "\"bbox_reg_weights\"", ",", "\n", "\"floats\"", ",", "\n", "[", "_cast_to_f32", "(", "w", ")", "for", "w", "in", "self", ".", "_wrapped_model", ".", "box2box_transform", ".", "weights", "]", ",", "\n", ")", "\n", "self", ".", "_encode_anchor_generator_cfg", "(", "predict_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet._encode_anchor_generator_cfg": [[443, 451], ["io.BytesIO", "torch.save", "io.BytesIO.getvalue", "shared.check_set_pb_arg"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.visualizer.VisImage.save", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.check_set_pb_arg"], ["", "def", "_encode_anchor_generator_cfg", "(", "self", ",", "predict_net", ")", ":", "\n", "# serialize anchor_generator for future use", "\n", "        ", "serialized_anchor_generator", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "_wrapped_model", ".", "anchor_generator", ",", "serialized_anchor_generator", ")", "\n", "# Ideally we can put anchor generating inside the model, then we don't", "\n", "# need to store this information.", "\n", "bytes", "=", "serialized_anchor_generator", ".", "getvalue", "(", ")", "\n", "check_set_pb_arg", "(", "predict_net", ",", "\"serialized_anchor_generator\"", ",", "\"s\"", ",", "bytes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet.get_outputs_converter": [[452, 497], ["types.SimpleNamespace", "io.BytesIO", "torch.load", "shared.get_pb_arg_floats", "detectron2.modeling.box_regression.Box2BoxTransform", "shared.get_pb_arg_valf", "shared.get_pb_arg_vali", "shared.get_pb_arg_valf", "shared.get_pb_arg_vali", "functools.partial", "functools.partial", "shared.get_pb_arg_vals", "len", "types.SimpleNamespace.anchor_generator", "types.SimpleNamespace.inference", "detectron2.modeling.meta_arch.GeneralizedRCNN._postprocess", "tuple", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "int", "int", "range", "range", "x.clone", "c2_results.keys", "x.startswith"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_floats", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_valf", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "@", "staticmethod", "\n", "def", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "self", "=", "types", ".", "SimpleNamespace", "(", ")", "\n", "serialized_anchor_generator", "=", "io", ".", "BytesIO", "(", "\n", "get_pb_arg_vals", "(", "predict_net", ",", "\"serialized_anchor_generator\"", ",", "None", ")", "\n", ")", "\n", "self", ".", "anchor_generator", "=", "torch", ".", "load", "(", "serialized_anchor_generator", ")", "\n", "bbox_reg_weights", "=", "get_pb_arg_floats", "(", "predict_net", ",", "\"bbox_reg_weights\"", ",", "None", ")", "\n", "self", ".", "box2box_transform", "=", "Box2BoxTransform", "(", "weights", "=", "tuple", "(", "bbox_reg_weights", ")", ")", "\n", "self", ".", "test_score_thresh", "=", "get_pb_arg_valf", "(", "predict_net", ",", "\"score_threshold\"", ",", "None", ")", "\n", "self", ".", "test_topk_candidates", "=", "get_pb_arg_vali", "(", "predict_net", ",", "\"topk_candidates\"", ",", "None", ")", "\n", "self", ".", "test_nms_thresh", "=", "get_pb_arg_valf", "(", "predict_net", ",", "\"nms_threshold\"", ",", "None", ")", "\n", "self", ".", "max_detections_per_image", "=", "get_pb_arg_vali", "(", "\n", "predict_net", ",", "\"max_detections_per_image\"", ",", "None", "\n", ")", "\n", "\n", "# hack to reuse inference code from RetinaNet", "\n", "self", ".", "inference", "=", "functools", ".", "partial", "(", "meta_arch", ".", "RetinaNet", ".", "inference", ",", "self", ")", "\n", "self", ".", "inference_single_image", "=", "functools", ".", "partial", "(", "\n", "meta_arch", ".", "RetinaNet", ".", "inference_single_image", ",", "self", "\n", ")", "\n", "\n", "def", "f", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", ":", "\n", "            ", "_", ",", "im_info", "=", "c2_inputs", "\n", "image_sizes", "=", "[", "[", "int", "(", "im", "[", "0", "]", ")", ",", "int", "(", "im", "[", "1", "]", ")", "]", "for", "im", "in", "im_info", "]", "\n", "\n", "num_features", "=", "len", "(", "[", "x", "for", "x", "in", "c2_results", ".", "keys", "(", ")", "if", "x", ".", "startswith", "(", "\"box_cls_\"", ")", "]", ")", "\n", "pred_logits", "=", "[", "c2_results", "[", "\"box_cls_{}\"", ".", "format", "(", "i", ")", "]", "for", "i", "in", "range", "(", "num_features", ")", "]", "\n", "pred_anchor_deltas", "=", "[", "c2_results", "[", "\"box_delta_{}\"", ".", "format", "(", "i", ")", "]", "for", "i", "in", "range", "(", "num_features", ")", "]", "\n", "\n", "# For each feature level, feature should have the same batch size and", "\n", "# spatial dimension as the box_cls and box_delta.", "\n", "dummy_features", "=", "[", "x", ".", "clone", "(", ")", "[", ":", ",", "0", ":", "0", ",", ":", ",", ":", "]", "for", "x", "in", "pred_logits", "]", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "dummy_features", ")", "\n", "\n", "# self.num_classess can be inferred", "\n", "self", ".", "num_classes", "=", "pred_logits", "[", "0", "]", ".", "shape", "[", "1", "]", "//", "(", "pred_anchor_deltas", "[", "0", "]", ".", "shape", "[", "1", "]", "//", "4", ")", "\n", "\n", "pred_logits", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "self", ".", "num_classes", ")", "for", "x", "in", "pred_logits", "]", "\n", "pred_anchor_deltas", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "4", ")", "for", "x", "in", "pred_anchor_deltas", "]", "\n", "\n", "results", "=", "self", ".", "inference", "(", "anchors", ",", "pred_logits", ",", "pred_anchor_deltas", ",", "image_sizes", ")", "\n", "return", "meta_arch", ".", "GeneralizedRCNN", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "image_sizes", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.assemble_rcnn_outputs_by_name": [[30, 96], ["tensor_outputs.get", "class_nms.to", "tensor_outputs.get", "tensor_outputs.get", "tensor_outputs.get", "detectron2.structures.Instances", "NotImplementedError", "len", "detectron2.structures.RotatedBoxes", "detectron2.structures.Boxes", "torch.arange", "torch.zeros", "keypoints_tensor.transpose", "detectron2.modeling.roi_heads.keypoint_head.keypoint_rcnn_inference"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.keypoint_head.keypoint_rcnn_inference"], ["def", "assemble_rcnn_outputs_by_name", "(", "image_sizes", ",", "tensor_outputs", ",", "force_mask_on", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    A function to assemble caffe2 model's outputs (i.e. Dict[str, Tensor])\n    to detectron2's format (i.e. list of Instances instance).\n    This only works when the model follows the Caffe2 detectron's naming convention.\n\n    Args:\n        image_sizes (List[List[int, int]]): [H, W] of every image.\n        tensor_outputs (Dict[str, Tensor]): external_output to its tensor.\n\n        force_mask_on (Bool): if true, the it make sure there'll be pred_masks even\n            if the mask is not found from tensor_outputs (usually due to model crash)\n    \"\"\"", "\n", "\n", "results", "=", "[", "Instances", "(", "image_size", ")", "for", "image_size", "in", "image_sizes", "]", "\n", "\n", "batch_splits", "=", "tensor_outputs", ".", "get", "(", "\"batch_splits\"", ",", "None", ")", "\n", "if", "batch_splits", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "assert", "len", "(", "image_sizes", ")", "==", "1", "\n", "result", "=", "results", "[", "0", "]", "\n", "\n", "bbox_nms", "=", "tensor_outputs", "[", "\"bbox_nms\"", "]", "\n", "score_nms", "=", "tensor_outputs", "[", "\"score_nms\"", "]", "\n", "class_nms", "=", "tensor_outputs", "[", "\"class_nms\"", "]", "\n", "# Detection will always success because Conv support 0-batch", "\n", "assert", "bbox_nms", "is", "not", "None", "\n", "assert", "score_nms", "is", "not", "None", "\n", "assert", "class_nms", "is", "not", "None", "\n", "if", "bbox_nms", ".", "shape", "[", "1", "]", "==", "5", ":", "\n", "        ", "result", ".", "pred_boxes", "=", "RotatedBoxes", "(", "bbox_nms", ")", "\n", "", "else", ":", "\n", "        ", "result", ".", "pred_boxes", "=", "Boxes", "(", "bbox_nms", ")", "\n", "", "result", ".", "scores", "=", "score_nms", "\n", "result", ".", "pred_classes", "=", "class_nms", ".", "to", "(", "torch", ".", "int64", ")", "\n", "\n", "mask_fcn_probs", "=", "tensor_outputs", ".", "get", "(", "\"mask_fcn_probs\"", ",", "None", ")", "\n", "if", "mask_fcn_probs", "is", "not", "None", ":", "\n", "# finish the mask pred", "\n", "        ", "mask_probs_pred", "=", "mask_fcn_probs", "\n", "num_masks", "=", "mask_probs_pred", ".", "shape", "[", "0", "]", "\n", "class_pred", "=", "result", ".", "pred_classes", "\n", "indices", "=", "torch", ".", "arange", "(", "num_masks", ",", "device", "=", "class_pred", ".", "device", ")", "\n", "mask_probs_pred", "=", "mask_probs_pred", "[", "indices", ",", "class_pred", "]", "[", ":", ",", "None", "]", "\n", "result", ".", "pred_masks", "=", "mask_probs_pred", "\n", "", "elif", "force_mask_on", ":", "\n", "# NOTE: there's no way to know the height/width of mask here, it won't be", "\n", "# used anyway when batch size is 0, so just set them to 0.", "\n", "        ", "result", ".", "pred_masks", "=", "torch", ".", "zeros", "(", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "", "keypoints_out", "=", "tensor_outputs", ".", "get", "(", "\"keypoints_out\"", ",", "None", ")", "\n", "kps_score", "=", "tensor_outputs", ".", "get", "(", "\"kps_score\"", ",", "None", ")", "\n", "if", "keypoints_out", "is", "not", "None", ":", "\n", "# keypoints_out: [N, 4, #kypoints], where 4 is in order of (x, y, score, prob)", "\n", "        ", "keypoints_tensor", "=", "keypoints_out", "\n", "# NOTE: it's possible that prob is not calculated if \"should_output_softmax\"", "\n", "# is set to False in HeatmapMaxKeypoint, so just using raw score, seems", "\n", "# it doesn't affect mAP. TODO: check more carefully.", "\n", "keypoint_xyp", "=", "keypoints_tensor", ".", "transpose", "(", "1", ",", "2", ")", "[", ":", ",", ":", ",", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "result", ".", "pred_keypoints", "=", "keypoint_xyp", "\n", "", "elif", "kps_score", "is", "not", "None", ":", "\n", "# keypoint heatmap to sparse data structure", "\n", "        ", "pred_keypoint_logits", "=", "kps_score", "\n", "keypoint_head", ".", "keypoint_rcnn_inference", "(", "pred_keypoint_logits", ",", "[", "result", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling._cast_to_f32": [[98, 100], ["struct.unpack", "struct.pack"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.pack"], ["", "def", "_cast_to_f32", "(", "f64", ")", ":", "\n", "    ", "return", "struct", ".", "unpack", "(", "\"f\"", ",", "struct", ".", "pack", "(", "\"f\"", ",", "f64", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.set_caffe2_compatible_tensor_mode": [[102, 108], ["model.apply", "isinstance"], "function", ["None"], ["", "def", "set_caffe2_compatible_tensor_mode", "(", "model", ",", "enable", "=", "True", ")", ":", "\n", "    ", "def", "_fn", "(", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "Caffe2Compatible", ")", ":", "\n", "            ", "m", ".", "tensor_mode", "=", "enable", "\n", "\n", "", "", "model", ".", "apply", "(", "_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.convert_batched_inputs_to_c2_format": [[110, 136], ["all", "all", "detectron2.structures.ImageList.from_tensors", "zip", "torch.Tensor", "input_per_image.get", "input_per_image.get", "torch.Tensor.append", "ImageList.from_tensors.tensor.to", "torch.Tensor.to", "isinstance", "x[].dim"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "convert_batched_inputs_to_c2_format", "(", "batched_inputs", ",", "size_divisibility", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    See get_caffe2_inputs() below.\n    \"\"\"", "\n", "assert", "all", "(", "isinstance", "(", "x", ",", "dict", ")", "for", "x", "in", "batched_inputs", ")", "\n", "assert", "all", "(", "x", "[", "\"image\"", "]", ".", "dim", "(", ")", "==", "3", "for", "x", "in", "batched_inputs", ")", "\n", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "size_divisibility", ")", "\n", "\n", "im_info", "=", "[", "]", "\n", "for", "input_per_image", ",", "image_size", "in", "zip", "(", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "        ", "target_height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "target_width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "# noqa", "\n", "# NOTE: The scale inside im_info is kept as convention and for providing", "\n", "# post-processing information if further processing is needed. For", "\n", "# current Caffe2 model definitions that don't include post-processing inside", "\n", "# the model, this number is not used.", "\n", "# NOTE: There can be a slight difference between width and height", "\n", "# scales, using a single number can results in numerical difference", "\n", "# compared with D2's post-processing.", "\n", "scale", "=", "target_height", "/", "image_size", "[", "0", "]", "\n", "im_info", ".", "append", "(", "[", "image_size", "[", "0", "]", ",", "image_size", "[", "1", "]", ",", "scale", "]", ")", "\n", "", "im_info", "=", "torch", ".", "Tensor", "(", "im_info", ")", "\n", "\n", "return", "images", ".", "tensor", ".", "to", "(", "device", ")", ",", "im_info", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._clear_jit_cache": [[20, 26], ["concrete_type_store.type_store.clear", "_jit_caching_layer.clear"], "function", ["None"], ["def", "_clear_jit_cache", "(", ")", ":", "\n", "    ", "from", "torch", ".", "jit", ".", "_recursive", "import", "concrete_type_store", "\n", "from", "torch", ".", "jit", ".", "_state", "import", "_jit_caching_layer", "\n", "\n", "concrete_type_store", ".", "type_store", ".", "clear", "(", ")", "# for modules", "\n", "_jit_caching_layer", ".", "clear", "(", ")", "# for free functions", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._add_instances_conversion_methods": [[28, 48], ["instances.get_fields", "newInstances", "instances.get_fields.items", "hasattr", "setattr", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields"], ["", "def", "_add_instances_conversion_methods", "(", "newInstances", ")", ":", "\n", "    ", "\"\"\"\n    Add from_instances methods to the scripted Instances class.\n    \"\"\"", "\n", "cls_name", "=", "newInstances", ".", "__name__", "\n", "\n", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "from_instances", "(", "instances", ":", "Instances", ")", ":", "\n", "        ", "\"\"\"\n        Create scripted Instances from original Instances\n        \"\"\"", "\n", "fields", "=", "instances", ".", "get_fields", "(", ")", "\n", "image_size", "=", "instances", ".", "image_size", "\n", "ret", "=", "newInstances", "(", "image_size", ")", "\n", "for", "name", ",", "val", "in", "fields", ".", "items", "(", ")", ":", "\n", "            ", "assert", "hasattr", "(", "ret", ",", "f\"_{name}\"", ")", ",", "f\"No attribute named {name} in {cls_name}\"", "\n", "setattr", "(", "ret", ",", "name", ",", "deepcopy", "(", "val", ")", ")", "\n", "", "return", "ret", "\n", "\n", "", "newInstances", ".", "from_instances", "=", "from_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.patch_instances": [[50, 88], ["tempfile.TemporaryDirectory", "tempfile.NamedTemporaryFile", "torchscript_patch._clear_jit_cache", "torchscript_patch._gen_instance_module", "f.write", "f.flush", "f.close", "torchscript_patch._import", "getattr", "torch.jit.script", "torch._jit_internal._qualified_name", "torchscript_patch._add_instances_conversion_methods", "sys.modules.pop"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._clear_jit_cache", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._gen_instance_module", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._import", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._add_instances_conversion_methods"], ["", "@", "contextmanager", "\n", "def", "patch_instances", "(", "fields", ")", ":", "\n", "    ", "\"\"\"\n    A contextmanager, under which the Instances class in detectron2 is replaced\n    by a statically-typed scriptable class, defined by `fields`.\n    See more in `scripting_with_instances`.\n    \"\"\"", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"detectron2\"", ")", "as", "dir", ",", "tempfile", ".", "NamedTemporaryFile", "(", "\n", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ",", "suffix", "=", "\".py\"", ",", "dir", "=", "dir", ",", "delete", "=", "False", "\n", ")", "as", "f", ":", "\n", "        ", "try", ":", "\n", "# Objects that use Instances should not reuse previously-compiled", "\n", "# results in cache, because `Instances` could be a new class each time.", "\n", "            ", "_clear_jit_cache", "(", ")", "\n", "\n", "cls_name", ",", "s", "=", "_gen_instance_module", "(", "fields", ")", "\n", "f", ".", "write", "(", "s", ")", "\n", "f", ".", "flush", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "module", "=", "_import", "(", "f", ".", "name", ")", "\n", "new_instances", "=", "getattr", "(", "module", ",", "cls_name", ")", "\n", "_", "=", "torch", ".", "jit", ".", "script", "(", "new_instances", ")", "\n", "# let torchscript think Instances was scripted already", "\n", "Instances", ".", "__torch_script_class__", "=", "True", "\n", "# let torchscript find new_instances when looking for the jit type of Instances", "\n", "Instances", ".", "_jit_override_qualname", "=", "torch", ".", "_jit_internal", ".", "_qualified_name", "(", "new_instances", ")", "\n", "\n", "_add_instances_conversion_methods", "(", "new_instances", ")", "\n", "yield", "new_instances", "\n", "", "finally", ":", "\n", "            ", "try", ":", "\n", "                ", "del", "Instances", ".", "__torch_script_class__", "\n", "del", "Instances", ".", "_jit_override_qualname", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "", "sys", ".", "modules", ".", "pop", "(", "module", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._gen_instance_class": [[90, 259], ["tuple", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "_FieldType", "lines.append", "lines.append", "lines.append", "lines.append", "hasattr", "lines.append", "lines.append", "os.linesep.join", "isinstance", "fields.items", "torchscript_patch._gen_instance_class.indent"], "function", ["None"], ["", "", "", "def", "_gen_instance_class", "(", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        fields (dict[name: type])\n    \"\"\"", "\n", "\n", "class", "_FieldType", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "name", ",", "type_", ")", ":", "\n", "            ", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "f\"Field name must be str, got {name}\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "type_", "=", "type_", "\n", "self", ".", "annotation", "=", "f\"{type_.__module__}.{type_.__name__}\"", "\n", "\n", "", "", "fields", "=", "[", "_FieldType", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "]", "\n", "\n", "def", "indent", "(", "level", ",", "s", ")", ":", "\n", "        ", "return", "\" \"", "*", "4", "*", "level", "+", "s", "\n", "\n", "", "lines", "=", "[", "]", "\n", "\n", "global", "_counter", "\n", "_counter", "+=", "1", "\n", "\n", "cls_name", "=", "\"ScriptedInstances{}\"", ".", "format", "(", "_counter", ")", "\n", "\n", "field_names", "=", "tuple", "(", "x", ".", "name", "for", "x", "in", "fields", ")", "\n", "lines", ".", "append", "(", "\n", "f\"\"\"\nclass {cls_name}:\n    def __init__(self, image_size: Tuple[int, int]):\n        self.image_size = image_size\n        self._field_names = {field_names}\n\"\"\"", "\n", ")", "\n", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "indent", "(", "2", ",", "f\"self._{f.name} = torch.jit.annotate(Optional[{f.annotation}], None)\"", ")", "\n", ")", "\n", "\n", "", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n    @property\n    def {f.name}(self) -> {f.annotation}:\n        # has to use a local for type refinement\n        # https://pytorch.org/docs/stable/jit_language_reference.html#optional-type-refinement\n        t = self._{f.name}\n        assert t is not None\n        return t\n\n    @{f.name}.setter\n    def {f.name}(self, value: {f.annotation}) -> None:\n        self._{f.name} = value\n\"\"\"", "\n", ")", "\n", "\n", "# support method `__len__`", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n    def __len__(self) -> int:\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            return len(t)\n\"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        raise NotImplementedError(\"Empty Instances does not support __len__!\")\n\"\"\"", "\n", ")", "\n", "\n", "# support method `has`", "\n", "lines", ".", "append", "(", "\n", "\"\"\"\n    def has(self, name: str) -> bool:\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        if name == \"{f.name}\":\n            return self._{f.name} is not None\n\"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return False\n\"\"\"", "\n", ")", "\n", "\n", "# support method `to`", "\n", "lines", ".", "append", "(", "\n", "f\"\"\"\n    def to(self, device: torch.device) -> \"{cls_name}\":\n        ret = {cls_name}(self.image_size)\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "if", "hasattr", "(", "f", ".", "type_", ",", "\"to\"", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            ret._{f.name} = t.to(device)\n\"\"\"", "\n", ")", "\n", "", "else", ":", "\n", "# For now, ignore fields that cannot be moved to devices.", "\n", "# Maybe can support other tensor-like classes (e.g. __torch_function__)", "\n", "            ", "pass", "\n", "", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return ret\n\"\"\"", "\n", ")", "\n", "\n", "# support method `getitem`", "\n", "lines", ".", "append", "(", "\n", "f\"\"\"\n    def __getitem__(self, item) -> \"{cls_name}\":\n        ret = {cls_name}(self.image_size)\n\"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            ret._{f.name} = t[item]\n\"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return ret\n\"\"\"", "\n", ")", "\n", "\n", "# support method `get_fields()`", "\n", "lines", ".", "append", "(", "\n", "\"\"\"\n    def get_fields(self) -> Dict[str, Tensor]:\n        ret = {}\n    \"\"\"", "\n", ")", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "if", "f", ".", "type_", "==", "Boxes", ":", "\n", "            ", "stmt", "=", "\"t.tensor\"", "\n", "", "elif", "f", ".", "type_", "==", "torch", ".", "Tensor", ":", "\n", "            ", "stmt", "=", "\"t\"", "\n", "", "else", ":", "\n", "            ", "stmt", "=", "f'assert False, \"unsupported type {str(f.type_)}\"'", "\n", "", "lines", ".", "append", "(", "\n", "f\"\"\"\n        t = self._{f.name}\n        if t is not None:\n            ret[\"{f.name}\"] = {stmt}\n        \"\"\"", "\n", ")", "\n", "", "lines", ".", "append", "(", "\n", "\"\"\"\n        return ret\"\"\"", "\n", ")", "\n", "return", "cls_name", ",", "os", ".", "linesep", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._gen_instance_module": [[261, 278], ["torchscript_patch._gen_instance_class"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._gen_instance_class"], ["", "def", "_gen_instance_module", "(", "fields", ")", ":", "\n", "# TODO: find a more automatic way to enable import of other classes", "\n", "    ", "s", "=", "\"\"\"\nfrom copy import deepcopy\nimport torch\nfrom torch import Tensor\nimport typing\nfrom typing import *\n\nimport detectron2\nfrom detectron2.structures import Boxes, Instances\n\n\"\"\"", "\n", "\n", "cls_name", ",", "cls_def", "=", "_gen_instance_class", "(", "fields", ")", "\n", "s", "+=", "cls_def", "\n", "return", "cls_name", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch._import": [[280, 283], ["detectron2.utils.env._import_file"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.env._import_file"], ["", "def", "_import", "(", "path", ")", ":", "\n", "    ", "return", "_import_file", "(", "\n", "\"{}{}\"", ".", "format", "(", "sys", ".", "modules", "[", "__name__", "]", ".", "__name__", ",", "_counter", ")", ",", "path", ",", "make_importable", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.patch_builtin_len": [[286, 311], ["obj.__len__", "contextlib.ExitStack", "list", "stack.enter_context", "unittest.mock.patch"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__len__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_patch.patch"], ["", "@", "contextmanager", "\n", "def", "patch_builtin_len", "(", "modules", "=", "(", ")", ")", ":", "\n", "    ", "\"\"\"\n    Patch the builtin len() function of a few detectron2 modules\n    to use __len__ instead, because __len__ does not convert values to\n    integers and therefore is friendly to tracing.\n\n    Args:\n        modules (list[stsr]): names of extra modules to patch len(), in\n            addition to those in detectron2.\n    \"\"\"", "\n", "\n", "def", "_new_len", "(", "obj", ")", ":", "\n", "        ", "return", "obj", ".", "__len__", "(", ")", "\n", "\n", "", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "MODULES", "=", "[", "\n", "\"detectron2.modeling.roi_heads.fast_rcnn\"", ",", "\n", "\"detectron2.modeling.roi_heads.mask_head\"", ",", "\n", "\"detectron2.modeling.roi_heads.keypoint_head\"", ",", "\n", "]", "+", "list", "(", "modules", ")", "\n", "ctxs", "=", "[", "stack", ".", "enter_context", "(", "mock", ".", "patch", "(", "mod", "+", "\".len\"", ")", ")", "for", "mod", "in", "MODULES", "]", "\n", "for", "m", "in", "ctxs", ":", "\n", "            ", "m", ".", "side_effect", "=", "_new_len", "\n", "", "yield", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.patch_nonscriptable_classes": [[313, 356], ["hasattr", "copy.deepcopy", "torch.nn.ModuleList", "copy.deepcopy", "torch.nn.ModuleList", "torch.nn.ModuleList", "torchscript_patch..named_children", "copy.deepcopy", "delattr", "name.startswith", "delattr"], "function", ["None"], ["", "", "def", "patch_nonscriptable_classes", "(", ")", ":", "\n", "    ", "\"\"\"\n    Apply patches on a few nonscriptable detectron2 classes.\n    Should not have side-effects on eager usage.\n    \"\"\"", "\n", "# __prepare_scriptable__ can also be added to models for easier maintenance.", "\n", "# But it complicates the clean model code.", "\n", "\n", "from", "detectron2", ".", "modeling", ".", "backbone", "import", "ResNet", ",", "FPN", "\n", "\n", "# Due to https://github.com/pytorch/pytorch/issues/36061,", "\n", "# we change backbone to use ModuleList for scripting.", "\n", "# (note: this changes param names in state_dict)", "\n", "\n", "def", "prepare_resnet", "(", "self", ")", ":", "\n", "        ", "ret", "=", "deepcopy", "(", "self", ")", "\n", "ret", ".", "stages", "=", "nn", ".", "ModuleList", "(", "ret", ".", "stages", ")", "\n", "for", "k", "in", "self", ".", "stage_names", ":", "\n", "            ", "delattr", "(", "ret", ",", "k", ")", "\n", "", "return", "ret", "\n", "\n", "", "ResNet", ".", "__prepare_scriptable__", "=", "prepare_resnet", "\n", "\n", "def", "prepare_fpn", "(", "self", ")", ":", "\n", "        ", "ret", "=", "deepcopy", "(", "self", ")", "\n", "ret", ".", "lateral_convs", "=", "nn", ".", "ModuleList", "(", "ret", ".", "lateral_convs", ")", "\n", "ret", ".", "output_convs", "=", "nn", ".", "ModuleList", "(", "ret", ".", "output_convs", ")", "\n", "for", "name", ",", "_", "in", "self", ".", "named_children", "(", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "\"fpn_\"", ")", ":", "\n", "                ", "delattr", "(", "ret", ",", "name", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "FPN", ".", "__prepare_scriptable__", "=", "prepare_fpn", "\n", "\n", "# Annotate some attributes to be constants for the purpose of scripting,", "\n", "# even though they are not constants in eager mode.", "\n", "from", "detectron2", ".", "modeling", ".", "roi_heads", "import", "StandardROIHeads", "\n", "\n", "if", "hasattr", "(", "StandardROIHeads", ",", "\"__annotations__\"", ")", ":", "\n", "# copy first to avoid editing annotations of base class", "\n", "        ", "StandardROIHeads", ".", "__annotations__", "=", "deepcopy", "(", "StandardROIHeads", ".", "__annotations__", ")", "\n", "StandardROIHeads", ".", "__annotations__", "[", "\"mask_on\"", "]", "=", "torch", ".", "jit", ".", "Final", "[", "bool", "]", "\n", "StandardROIHeads", ".", "__annotations__", "[", "\"keypoint_on\"", "]", "=", "torch", ".", "jit", ".", "Final", "[", "bool", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.freeze_training_mode": [[362, 378], ["type", "model.modules", "hasattr"], "function", ["None"], ["@", "contextmanager", "\n", "def", "freeze_training_mode", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context manager that annotates the \"training\" attribute of every submodule\n    to constant, so that the training codepath in these modules can be\n    meta-compiled away. Upon exiting, the annotations are reverted.\n    \"\"\"", "\n", "classes", "=", "{", "type", "(", "x", ")", "for", "x", "in", "model", ".", "modules", "(", ")", "}", "\n", "# __constants__ is the old way to annotate constants and not compatible", "\n", "# with __annotations__ .", "\n", "classes", "=", "{", "x", "for", "x", "in", "classes", "if", "not", "hasattr", "(", "x", ",", "\"__constants__\"", ")", "}", "\n", "for", "cls", "in", "classes", ":", "\n", "        ", "cls", ".", "__annotations__", "[", "\"training\"", "]", "=", "torch", ".", "jit", ".", "Final", "[", "bool", "]", "\n", "", "yield", "\n", "for", "cls", "in", "classes", ":", "\n", "        ", "cls", ".", "__annotations__", "[", "\"training\"", "]", "=", "bool", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export.export_onnx_model": [[33, 72], ["isinstance", "model.apply", "onnx.optimizer.get_available_passes", "all", "onnx.optimizer.optimize", "torch.no_grad", "io.BytesIO", "torch.onnx.export", "onnx.load_from_string", "f.getvalue"], "function", ["None"], ["def", "export_onnx_model", "(", "model", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Trace and export a model to onnx format.\n\n    Args:\n        model (nn.Module):\n        inputs (tuple[args]): the model will be called by `model(*inputs)`\n\n    Returns:\n        an onnx model\n    \"\"\"", "\n", "assert", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "\n", "# make sure all modules are in eval mode, onnx may change the training state", "\n", "# of the module if the states are not consistent", "\n", "def", "_check_eval", "(", "module", ")", ":", "\n", "        ", "assert", "not", "module", ".", "training", "\n", "\n", "", "model", ".", "apply", "(", "_check_eval", ")", "\n", "\n", "# Export the model to ONNX", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "with", "io", ".", "BytesIO", "(", ")", "as", "f", ":", "\n", "            ", "torch", ".", "onnx", ".", "export", "(", "\n", "model", ",", "\n", "inputs", ",", "\n", "f", ",", "\n", "operator_export_type", "=", "OperatorExportTypes", ".", "ONNX_ATEN_FALLBACK", ",", "\n", "# verbose=True,  # NOTE: uncomment this for debugging", "\n", "# export_params=True,", "\n", ")", "\n", "onnx_model", "=", "onnx", ".", "load_from_string", "(", "f", ".", "getvalue", "(", ")", ")", "\n", "\n", "# Apply ONNX's Optimization", "\n", "", "", "all_passes", "=", "onnx", ".", "optimizer", ".", "get_available_passes", "(", ")", "\n", "passes", "=", "[", "\"fuse_bn_into_conv\"", "]", "\n", "assert", "all", "(", "p", "in", "all_passes", "for", "p", "in", "passes", ")", "\n", "onnx_model", "=", "onnx", ".", "optimizer", ".", "optimize", "(", "onnx_model", ",", "passes", ")", "\n", "return", "onnx_model", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export._op_stats": [[74, 81], ["sorted", "sorted", "type_count.items", "type_count.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "_op_stats", "(", "net_def", ")", ":", "\n", "    ", "type_count", "=", "{", "}", "\n", "for", "t", "in", "[", "op", ".", "type", "for", "op", "in", "net_def", ".", "op", "]", ":", "\n", "        ", "type_count", "[", "t", "]", "=", "type_count", ".", "get", "(", "t", ",", "0", ")", "+", "1", "\n", "", "type_count_list", "=", "sorted", "(", "type_count", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "0", "]", ")", "# alphabet", "\n", "type_count_list", "=", "sorted", "(", "type_count_list", ",", "key", "=", "lambda", "kv", ":", "-", "kv", "[", "1", "]", ")", "# count", "\n", "return", "\"\\n\"", ".", "join", "(", "\"{:>4}x {}\"", ".", "format", "(", "count", ",", "name", ")", "for", "name", ",", "count", "in", "type_count_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export._assign_device_option": [[83, 127], ["shared.infer_device_type", "caffe2.python.core.get_ssa", "caffe2_export._assign_device_option._assign_op_device_option"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.infer_device_type"], ["", "def", "_assign_device_option", "(", "\n", "predict_net", ":", "caffe2_pb2", ".", "NetDef", ",", "init_net", ":", "caffe2_pb2", ".", "NetDef", ",", "tensor_inputs", ":", "List", "[", "torch", ".", "Tensor", "]", "\n", ")", ":", "\n", "    ", "\"\"\"\n    ONNX exported network doesn't have concept of device, assign necessary\n    device option for each op in order to make it runable on GPU runtime.\n    \"\"\"", "\n", "\n", "def", "_get_device_type", "(", "torch_tensor", ")", ":", "\n", "        ", "assert", "torch_tensor", ".", "device", ".", "type", "in", "[", "\"cpu\"", ",", "\"cuda\"", "]", "\n", "assert", "torch_tensor", ".", "device", ".", "index", "==", "0", "\n", "return", "torch_tensor", ".", "device", ".", "type", "\n", "\n", "", "def", "_assign_op_device_option", "(", "net_proto", ",", "net_ssa", ",", "blob_device_types", ")", ":", "\n", "        ", "for", "op", ",", "ssa_i", "in", "zip", "(", "net_proto", ".", "op", ",", "net_ssa", ")", ":", "\n", "            ", "if", "op", ".", "type", "in", "[", "\"CopyCPUToGPU\"", ",", "\"CopyGPUToCPU\"", "]", ":", "\n", "                ", "op", ".", "device_option", ".", "CopyFrom", "(", "core", ".", "DeviceOption", "(", "caffe2_pb2", ".", "CUDA", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "devices", "=", "[", "blob_device_types", "[", "b", "]", "for", "b", "in", "ssa_i", "[", "0", "]", "+", "ssa_i", "[", "1", "]", "]", "\n", "assert", "all", "(", "d", "==", "devices", "[", "0", "]", "for", "d", "in", "devices", ")", "\n", "if", "devices", "[", "0", "]", "==", "\"cuda\"", ":", "\n", "                    ", "op", ".", "device_option", ".", "CopyFrom", "(", "core", ".", "DeviceOption", "(", "caffe2_pb2", ".", "CUDA", ",", "0", ")", ")", "\n", "\n", "# update ops in predict_net", "\n", "", "", "", "", "predict_net_input_device_types", "=", "{", "\n", "(", "name", ",", "0", ")", ":", "_get_device_type", "(", "tensor", ")", "\n", "for", "name", ",", "tensor", "in", "zip", "(", "predict_net", ".", "external_input", ",", "tensor_inputs", ")", "\n", "}", "\n", "predict_net_device_types", "=", "infer_device_type", "(", "\n", "predict_net", ",", "known_status", "=", "predict_net_input_device_types", ",", "device_name_style", "=", "\"pytorch\"", "\n", ")", "\n", "predict_net_ssa", ",", "_", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "_assign_op_device_option", "(", "predict_net", ",", "predict_net_ssa", ",", "predict_net_device_types", ")", "\n", "\n", "# update ops in init_net", "\n", "init_net_ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "init_net", ")", "\n", "init_net_output_device_types", "=", "{", "\n", "(", "name", ",", "versions", "[", "name", "]", ")", ":", "predict_net_device_types", "[", "(", "name", ",", "0", ")", "]", "\n", "for", "name", "in", "init_net", ".", "external_output", "\n", "}", "\n", "init_net_device_types", "=", "infer_device_type", "(", "\n", "init_net", ",", "known_status", "=", "init_net_output_device_types", ",", "device_name_style", "=", "\"pytorch\"", "\n", ")", "\n", "_assign_op_device_option", "(", "init_net", ",", "init_net_ssa", ",", "init_net_device_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export.export_caffe2_detection_model": [[129, 173], ["copy.deepcopy", "isinstance", "hasattr", "logger.info", "caffe2_export.export_onnx_model", "caffe2.python.onnx.backend.Caffe2Backend.onnx_graph_to_caffe2_net", "tabulate.tabulate", "logger.info", "shared.fuse_alias_placeholder", "any", "shared.get_params_from_init_net", "shared.remove_reshape_for_fc", "shared.construct_init_net_from_params", "shared.group_norm_replace_aten_with_caffe2", "copy.deepcopy.encode_additional_info", "logger.info", "logger.info", "shared.fuse_copy_between_cpu_and_gpu", "shared.remove_dead_end_ops", "caffe2_export._assign_device_option", "termcolor.colored", "caffe2_export._op_stats", "caffe2_export._op_stats", "type"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.export_onnx_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.fuse_alias_placeholder", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_params_from_init_net", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.remove_reshape_for_fc", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.construct_init_net_from_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.group_norm_replace_aten_with_caffe2", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet.encode_additional_info", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.fuse_copy_between_cpu_and_gpu", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.remove_dead_end_ops", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export._assign_device_option", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export._op_stats", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export._op_stats"], ["", "def", "export_caffe2_detection_model", "(", "model", ":", "torch", ".", "nn", ".", "Module", ",", "tensor_inputs", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "    ", "\"\"\"\n    Export a caffe2-compatible Detectron2 model to caffe2 format via ONNX.\n\n    Arg:\n        model: a caffe2-compatible version of detectron2 model, defined in caffe2_modeling.py\n        tensor_inputs: a list of tensors that caffe2 model takes as input.\n    \"\"\"", "\n", "model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "assert", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "assert", "hasattr", "(", "model", ",", "\"encode_additional_info\"", ")", "\n", "\n", "# Export via ONNX", "\n", "logger", ".", "info", "(", "\n", "\"Exporting a {} model via ONNX ...\"", ".", "format", "(", "type", "(", "model", ")", ".", "__name__", ")", "\n", "+", "\" Some warnings from ONNX are expected and are usually not to worry about.\"", "\n", ")", "\n", "onnx_model", "=", "export_onnx_model", "(", "model", ",", "(", "tensor_inputs", ",", ")", ")", "\n", "# Convert ONNX model to Caffe2 protobuf", "\n", "init_net", ",", "predict_net", "=", "Caffe2Backend", ".", "onnx_graph_to_caffe2_net", "(", "onnx_model", ")", "\n", "ops_table", "=", "[", "[", "op", ".", "type", ",", "op", ".", "input", ",", "op", ".", "output", "]", "for", "op", "in", "predict_net", ".", "op", "]", "\n", "table", "=", "tabulate", "(", "ops_table", ",", "headers", "=", "[", "\"type\"", ",", "\"input\"", ",", "\"output\"", "]", ",", "tablefmt", "=", "\"pipe\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"ONNX export Done. Exported predict_net (before optimizations):\\n\"", "+", "colored", "(", "table", ",", "\"cyan\"", ")", "\n", ")", "\n", "\n", "# Apply protobuf optimization", "\n", "fuse_alias_placeholder", "(", "predict_net", ",", "init_net", ")", "\n", "if", "any", "(", "t", ".", "device", ".", "type", "!=", "\"cpu\"", "for", "t", "in", "tensor_inputs", ")", ":", "\n", "        ", "fuse_copy_between_cpu_and_gpu", "(", "predict_net", ")", "\n", "remove_dead_end_ops", "(", "init_net", ")", "\n", "_assign_device_option", "(", "predict_net", ",", "init_net", ",", "tensor_inputs", ")", "\n", "", "params", ",", "device_options", "=", "get_params_from_init_net", "(", "init_net", ")", "\n", "predict_net", ",", "params", "=", "remove_reshape_for_fc", "(", "predict_net", ",", "params", ")", "\n", "init_net", "=", "construct_init_net_from_params", "(", "params", ",", "device_options", ")", "\n", "group_norm_replace_aten_with_caffe2", "(", "predict_net", ")", "\n", "\n", "# Record necessary information for running the pb model in Detectron2 system.", "\n", "model", ".", "encode_additional_info", "(", "predict_net", ",", "init_net", ")", "\n", "\n", "logger", ".", "info", "(", "\"Operators used in predict_net: \\n{}\"", ".", "format", "(", "_op_stats", "(", "predict_net", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Operators used in init_net: \\n{}\"", ".", "format", "(", "_op_stats", "(", "init_net", ")", ")", ")", "\n", "\n", "return", "predict_net", ",", "init_net", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export.run_and_save_graph": [[175, 208], ["logger.info", "shared.save_graph", "logger.info", "shared.ScopedWS", "ws.RunNetOnce", "set", "zip", "logger.info", "shared.save_graph", "ws.Blobs", "ws.FeedBlob", "ws.RunNetOnce", "ws.FetchBlob", "logger.warning", "ws.Blobs", "isinstance", "str"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_graph", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_graph"], ["", "def", "run_and_save_graph", "(", "predict_net", ",", "init_net", ",", "tensor_inputs", ",", "graph_save_path", ")", ":", "\n", "    ", "\"\"\"\n    Run the caffe2 model on given inputs, recording the shape and draw the graph.\n\n    predict_net/init_net: caffe2 model.\n    tensor_inputs: a list of tensors that caffe2 model takes as input.\n    graph_save_path: path for saving graph of exported model.\n    \"\"\"", "\n", "\n", "logger", ".", "info", "(", "\"Saving graph of ONNX exported model to {} ...\"", ".", "format", "(", "graph_save_path", ")", ")", "\n", "save_graph", "(", "predict_net", ",", "graph_save_path", ",", "op_only", "=", "False", ")", "\n", "\n", "# Run the exported Caffe2 net", "\n", "logger", ".", "info", "(", "\"Running ONNX exported model ...\"", ")", "\n", "with", "ScopedWS", "(", "\"__ws_tmp__\"", ",", "True", ")", "as", "ws", ":", "\n", "        ", "ws", ".", "RunNetOnce", "(", "init_net", ")", "\n", "initialized_blobs", "=", "set", "(", "ws", ".", "Blobs", "(", ")", ")", "\n", "uninitialized", "=", "[", "inp", "for", "inp", "in", "predict_net", ".", "external_input", "if", "inp", "not", "in", "initialized_blobs", "]", "\n", "for", "name", ",", "blob", "in", "zip", "(", "uninitialized", ",", "tensor_inputs", ")", ":", "\n", "            ", "ws", ".", "FeedBlob", "(", "name", ",", "blob", ")", "\n", "\n", "", "try", ":", "\n", "            ", "ws", ".", "RunNetOnce", "(", "predict_net", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Encountered RuntimeError: \\n{}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "\n", "", "ws_blobs", "=", "{", "b", ":", "ws", ".", "FetchBlob", "(", "b", ")", "for", "b", "in", "ws", ".", "Blobs", "(", ")", "}", "\n", "blob_sizes", "=", "{", "b", ":", "ws_blobs", "[", "b", "]", ".", "shape", "for", "b", "in", "ws_blobs", "if", "isinstance", "(", "ws_blobs", "[", "b", "]", ",", "np", ".", "ndarray", ")", "}", "\n", "\n", "logger", ".", "info", "(", "\"Saving graph with blob shapes to {} ...\"", ".", "format", "(", "graph_save_path", ")", ")", "\n", "save_graph", "(", "predict_net", ",", "graph_save_path", ",", "op_only", "=", "False", ",", "blob_sizes", "=", "blob_sizes", ")", "\n", "\n", "return", "ws_blobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2Boxes.__init__": [[29, 35], ["isinstance", "tensor.size", "tensor.dim", "tensor.size"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "assert", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "2", "and", "tensor", ".", "size", "(", "-", "1", ")", "in", "[", "4", ",", "5", ",", "6", "]", ",", "tensor", ".", "size", "(", ")", "\n", "# TODO: make tensor immutable when dim is Nx5 for Boxes,", "\n", "# and Nx6 for RotatedBoxes?", "\n", "self", ".", "tensor", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__init__": [[48, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "im_info", ",", "indices", ",", "extra_fields", "=", "None", ")", ":", "\n", "# [N, 3] -> (H, W, Scale)", "\n", "        ", "self", ".", "im_info", "=", "im_info", "\n", "# [N,] -> indice of batch to which the instance belongs", "\n", "self", ".", "indices", "=", "indices", "\n", "# [N, ...]", "\n", "self", ".", "batch_extra_fields", "=", "extra_fields", "or", "{", "}", "\n", "\n", "self", ".", "image_size", "=", "self", ".", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields": [[58, 71], ["c10.InstancesList.batch_extra_fields.items"], "methods", ["None"], ["", "def", "get_fields", "(", "self", ")", ":", "\n", "        ", "\"\"\"like `get_fields` in the Instances object,\n        but return each field in tensor representations\"\"\"", "\n", "ret", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "batch_extra_fields", ".", "items", "(", ")", ":", "\n", "# if isinstance(v, torch.Tensor):", "\n", "#     tensor_rep = v", "\n", "# elif isinstance(v, (Boxes, Keypoints)):", "\n", "#     tensor_rep = v.tensor", "\n", "# else:", "\n", "#     raise ValueError(\"Can't find tensor representation for: {}\".format())", "\n", "            ", "ret", "[", "k", "]", "=", "v", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has": [[72, 74], ["None"], "methods", ["None"], ["", "def", "has", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "name", "in", "self", ".", "batch_extra_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set": [[75, 82], ["len", "len", "len", "len"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "data_len", "=", "len", "(", "value", ")", "\n", "if", "len", "(", "self", ".", "batch_extra_fields", ")", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "self", ")", "==", "data_len", "\n", ")", ",", "\"Adding a field of length {} to a Instances of length {}\"", ".", "format", "(", "data_len", ",", "len", "(", "self", ")", ")", "\n", "", "self", ".", "batch_extra_fields", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__setattr__": [[83, 88], ["object.__setattr__", "c10.InstancesList.set"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__setattr__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "val", ")", ":", "\n", "        ", "if", "name", "in", "[", "\"im_info\"", ",", "\"indices\"", ",", "\"batch_extra_fields\"", ",", "\"image_size\"", "]", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "set", "(", "name", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__getattr__": [[89, 93], ["AttributeError"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "not", "in", "self", ".", "batch_extra_fields", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Cannot find field '{}' in the given Instances!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "self", ".", "batch_extra_fields", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.__len__": [[94, 96], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.flatten": [[97, 105], ["c10.InstancesList.batch_extra_fields.items", "isinstance", "ret.append", "ret.append"], "methods", ["None"], ["", "def", "flatten", "(", "self", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "_", ",", "v", "in", "self", ".", "batch_extra_fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "(", "Boxes", ",", "Keypoints", ")", ")", ":", "\n", "                ", "ret", ".", "append", "(", "v", ".", "tensor", ")", "\n", "", "else", ":", "\n", "                ", "ret", ".", "append", "(", "v", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.to_d2_instances_list": [[106, 145], ["enumerate", "isinstance", "all", "detectron2.structures.Instances", "instances_list.batch_extra_fields.items", "ret.append", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "isinstance", "isinstance", "issubclass", "isinstance", "detectron2.structures.Instances.set", "isinstance", "detectron2.structures.Instances.set", "issubclass", "int", "int", "detectron2.structures.Instances.set", "detectron2.structures.Boxes", "detectron2.structures.Instances.set", "issubclass", "info[].item", "info[].item", "detectron2.structures.Keypoints", "detectron2.structures.Instances.set", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["", "@", "staticmethod", "\n", "def", "to_d2_instances_list", "(", "instances_list", ")", ":", "\n", "        ", "\"\"\"\n        Convert InstancesList to List[Instances]. The input `instances_list` can\n        also be a List[Instances], in this case this method is a non-op.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "instances_list", ",", "InstancesList", ")", ":", "\n", "            ", "assert", "all", "(", "isinstance", "(", "x", ",", "Instances", ")", "for", "x", "in", "instances_list", ")", "\n", "return", "instances_list", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "i", ",", "info", "in", "enumerate", "(", "instances_list", ".", "im_info", ")", ":", "\n", "            ", "instances", "=", "Instances", "(", "torch", ".", "Size", "(", "[", "int", "(", "info", "[", "0", "]", ".", "item", "(", ")", ")", ",", "int", "(", "info", "[", "1", "]", ".", "item", "(", ")", ")", "]", ")", ")", "\n", "\n", "ids", "=", "instances_list", ".", "indices", "==", "i", "\n", "for", "k", ",", "v", "in", "instances_list", ".", "batch_extra_fields", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "v", "[", "ids", "]", ")", "\n", "continue", "\n", "", "elif", "isinstance", "(", "v", ",", "Boxes", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "v", "[", "ids", ",", "-", "4", ":", "]", ")", "\n", "continue", "\n", "\n", "", "target_type", ",", "tensor_source", "=", "v", "\n", "assert", "isinstance", "(", "tensor_source", ",", "torch", ".", "Tensor", ")", "\n", "assert", "tensor_source", ".", "shape", "[", "0", "]", "==", "instances_list", ".", "indices", ".", "shape", "[", "0", "]", "\n", "tensor_source", "=", "tensor_source", "[", "ids", "]", "\n", "\n", "if", "issubclass", "(", "target_type", ",", "Boxes", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "Boxes", "(", "tensor_source", "[", ":", ",", "-", "4", ":", "]", ")", ")", "\n", "", "elif", "issubclass", "(", "target_type", ",", "Keypoints", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "Keypoints", "(", "tensor_source", ")", ")", "\n", "", "elif", "issubclass", "(", "target_type", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "instances", ".", "set", "(", "k", ",", "tensor_source", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Can't handle targe type: {}\"", ".", "format", "(", "target_type", ")", ")", "\n", "\n", "", "", "ret", ".", "append", "(", "instances", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2Compatible._get_tensor_mode": [[152, 154], ["None"], "methods", ["None"], ["def", "_get_tensor_mode", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_tensor_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2Compatible._set_tensor_mode": [[155, 157], ["None"], "methods", ["None"], ["", "def", "_set_tensor_mode", "(", "self", ",", "v", ")", ":", "\n", "        ", "self", ".", "_tensor_mode", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2RPN._generate_proposals": [[165, 247], ["isinstance", "isinstance", "zip", "c10.Caffe2RPN.c2_postprocess", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "iter", "scores.detach.detach.detach", "bbox_deltas.detach.detach.detach", "torch.ops._caffe2.GenerateProposals", "torch.ops._caffe2.GenerateProposals", "torch.ops._caffe2.GenerateProposals", "torch.ops._caffe2.GenerateProposals", "rpn_rois_list.append", "rpn_roi_probs_list.append", "len", "list", "int", "int", "torch.ops._caffe2.CollectRpnProposals", "torch.ops._caffe2.CollectRpnProposals", "torch.ops._caffe2.CollectRpnProposals", "torch.ops._caffe2.CollectRpnProposals", "shared.to_device", "len", "len", "shared.to_device", "math.log2", "math.log2", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2RPN.c2_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device"], ["    ", "def", "_generate_proposals", "(", "\n", "self", ",", "images", ",", "objectness_logits_pred", ",", "anchor_deltas_pred", ",", "gt_instances", "=", "None", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "images", ",", "ImageList", ")", "\n", "if", "self", ".", "tensor_mode", ":", "\n", "            ", "im_info", "=", "images", ".", "image_sizes", "\n", "", "else", ":", "\n", "            ", "im_info", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "im_sz", "[", "0", "]", ",", "im_sz", "[", "1", "]", ",", "torch", ".", "Tensor", "(", "[", "1.0", "]", ")", "]", "for", "im_sz", "in", "images", ".", "image_sizes", "]", "\n", ")", ".", "to", "(", "images", ".", "tensor", ".", "device", ")", "\n", "", "assert", "isinstance", "(", "im_info", ",", "torch", ".", "Tensor", ")", "\n", "\n", "rpn_rois_list", "=", "[", "]", "\n", "rpn_roi_probs_list", "=", "[", "]", "\n", "for", "scores", ",", "bbox_deltas", ",", "cell_anchors_tensor", ",", "feat_stride", "in", "zip", "(", "\n", "objectness_logits_pred", ",", "\n", "anchor_deltas_pred", ",", "\n", "iter", "(", "self", ".", "anchor_generator", ".", "cell_anchors", ")", ",", "\n", "self", ".", "anchor_generator", ".", "strides", ",", "\n", ")", ":", "\n", "            ", "scores", "=", "scores", ".", "detach", "(", ")", "\n", "bbox_deltas", "=", "bbox_deltas", ".", "detach", "(", ")", "\n", "\n", "rpn_rois", ",", "rpn_roi_probs", "=", "torch", ".", "ops", ".", "_caffe2", ".", "GenerateProposals", "(", "\n", "scores", ",", "\n", "bbox_deltas", ",", "\n", "im_info", ",", "\n", "cell_anchors_tensor", ",", "\n", "spatial_scale", "=", "1.0", "/", "feat_stride", ",", "\n", "pre_nms_topN", "=", "self", ".", "pre_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "post_nms_topN", "=", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", ",", "\n", "nms_thresh", "=", "self", ".", "nms_thresh", ",", "\n", "min_size", "=", "self", ".", "min_box_size", ",", "\n", "# correct_transform_coords=True,  # deprecated argument", "\n", "angle_bound_on", "=", "True", ",", "# Default", "\n", "angle_bound_lo", "=", "-", "180", ",", "\n", "angle_bound_hi", "=", "180", ",", "\n", "clip_angle_thresh", "=", "1.0", ",", "# Default", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "rpn_rois_list", ".", "append", "(", "rpn_rois", ")", "\n", "rpn_roi_probs_list", ".", "append", "(", "rpn_roi_probs", ")", "\n", "\n", "# For FPN in D2, in RPN all proposals from different levels are concated", "\n", "# together, ranked and picked by top post_nms_topk. Then in ROIPooler", "\n", "# it calculates level_assignments and calls the RoIAlign from", "\n", "# the corresponding level.", "\n", "\n", "", "if", "len", "(", "objectness_logits_pred", ")", "==", "1", ":", "\n", "            ", "rpn_rois", "=", "rpn_rois_list", "[", "0", "]", "\n", "rpn_roi_probs", "=", "rpn_roi_probs_list", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "rpn_rois_list", ")", "==", "len", "(", "rpn_roi_probs_list", ")", "\n", "rpn_post_nms_topN", "=", "self", ".", "post_nms_topk", "[", "self", ".", "training", "]", "\n", "\n", "device", "=", "rpn_rois_list", "[", "0", "]", ".", "device", "\n", "input_list", "=", "[", "to_device", "(", "x", ",", "\"cpu\"", ")", "for", "x", "in", "(", "rpn_rois_list", "+", "rpn_roi_probs_list", ")", "]", "\n", "\n", "# TODO remove this after confirming rpn_max_level/rpn_min_level", "\n", "# is not needed in CollectRpnProposals.", "\n", "feature_strides", "=", "list", "(", "self", ".", "anchor_generator", ".", "strides", ")", "\n", "rpn_min_level", "=", "int", "(", "math", ".", "log2", "(", "feature_strides", "[", "0", "]", ")", ")", "\n", "rpn_max_level", "=", "int", "(", "math", ".", "log2", "(", "feature_strides", "[", "-", "1", "]", ")", ")", "\n", "assert", "(", "rpn_max_level", "-", "rpn_min_level", "+", "1", ")", "==", "len", "(", "\n", "rpn_rois_list", "\n", ")", ",", "\"CollectRpnProposals requires continuous levels\"", "\n", "\n", "rpn_rois", "=", "torch", ".", "ops", ".", "_caffe2", ".", "CollectRpnProposals", "(", "\n", "input_list", ",", "\n", "# NOTE: in current implementation, rpn_max_level and rpn_min_level", "\n", "# are not needed, only the subtraction of two matters and it", "\n", "# can be infer from the number of inputs. Keep them now for", "\n", "# consistency.", "\n", "rpn_max_level", "=", "2", "+", "len", "(", "rpn_rois_list", ")", "-", "1", ",", "\n", "rpn_min_level", "=", "2", ",", "\n", "rpn_post_nms_topN", "=", "rpn_post_nms_topN", ",", "\n", ")", "\n", "rpn_rois", "=", "to_device", "(", "rpn_rois", ",", "device", ")", "\n", "rpn_roi_probs", "=", "[", "]", "\n", "\n", "", "proposals", "=", "self", ".", "c2_postprocess", "(", "im_info", ",", "rpn_rois", ",", "rpn_roi_probs", ",", "self", ".", "tensor_mode", ")", "\n", "return", "proposals", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2RPN.forward": [[248, 257], ["c10.Caffe2RPN.rpn_head", "c10.Caffe2RPN._generate_proposals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2RPN._generate_proposals"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "gt_instances", "=", "None", ")", ":", "\n", "        ", "assert", "not", "self", ".", "training", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "objectness_logits_pred", ",", "anchor_deltas_pred", "=", "self", ".", "rpn_head", "(", "features", ")", "\n", "return", "self", ".", "_generate_proposals", "(", "\n", "images", ",", "\n", "objectness_logits_pred", ",", "\n", "anchor_deltas_pred", ",", "\n", "gt_instances", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2RPN.c2_postprocess": [[259, 274], ["c10.InstancesList", "c10.InstancesList.to_d2_instances_list", "c10.Caffe2Boxes"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.to_d2_instances_list"], ["", "@", "staticmethod", "\n", "def", "c2_postprocess", "(", "im_info", ",", "rpn_rois", ",", "rpn_roi_probs", ",", "tensor_mode", ")", ":", "\n", "        ", "proposals", "=", "InstancesList", "(", "\n", "im_info", "=", "im_info", ",", "\n", "indices", "=", "rpn_rois", "[", ":", ",", "0", "]", ",", "\n", "extra_fields", "=", "{", "\n", "\"proposal_boxes\"", ":", "Caffe2Boxes", "(", "rpn_rois", ")", ",", "\n", "\"objectness_logits\"", ":", "(", "torch", ".", "Tensor", ",", "rpn_roi_probs", ")", ",", "\n", "}", ",", "\n", ")", "\n", "if", "not", "tensor_mode", ":", "\n", "            ", "proposals", "=", "InstancesList", ".", "to_d2_instances_list", "(", "proposals", ")", "\n", "", "else", ":", "\n", "            ", "proposals", "=", "[", "proposals", "]", "\n", "", "return", "proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2ROIPooler.c2_preprocess": [[277, 287], ["all", "all", "detectron2.modeling.poolers.convert_boxes_to_pooler_format", "isinstance", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.poolers.convert_boxes_to_pooler_format"], ["    ", "@", "staticmethod", "\n", "def", "c2_preprocess", "(", "box_lists", ")", ":", "\n", "        ", "assert", "all", "(", "isinstance", "(", "x", ",", "Boxes", ")", "for", "x", "in", "box_lists", ")", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "Caffe2Boxes", ")", "for", "x", "in", "box_lists", ")", ":", "\n", "# input is pure-tensor based", "\n", "            ", "assert", "len", "(", "box_lists", ")", "==", "1", "\n", "pooler_fmt_boxes", "=", "box_lists", "[", "0", "]", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "pooler_fmt_boxes", "=", "poolers", ".", "convert_boxes_to_pooler_format", "(", "box_lists", ")", "\n", "", "return", "pooler_fmt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2ROIPooler.forward": [[288, 359], ["c10.Caffe2ROIPooler.c2_preprocess", "len", "torch.ops._caffe2.DistributeFpnProposals", "torch.ops._caffe2.DistributeFpnProposals", "torch.ops._caffe2.DistributeFpnProposals", "torch.ops._caffe2.DistributeFpnProposals", "zip", "detectron2.layers.cat", "torch.ops._caffe2.BatchPermutation", "torch.ops._caffe2.BatchPermutation", "torch.ops._caffe2.BatchPermutation", "torch.ops._caffe2.BatchPermutation", "isinstance", "c2_roi_align", "shared.to_device", "shared.to_device", "isinstance", "c2_roi_align", "roi_feat_fpn_list.append", "bool", "detectron2.layers.cat.numel", "rois_idx_restore_int32.numel", "float", "int", "int", "int", "float", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2ROIPooler.c2_preprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device"], ["", "def", "forward", "(", "self", ",", "x", ",", "box_lists", ")", ":", "\n", "        ", "assert", "not", "self", ".", "training", "\n", "\n", "pooler_fmt_boxes", "=", "self", ".", "c2_preprocess", "(", "box_lists", ")", "\n", "num_level_assignments", "=", "len", "(", "self", ".", "level_poolers", ")", "\n", "\n", "if", "num_level_assignments", "==", "1", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "level_poolers", "[", "0", "]", ",", "ROIAlignRotated", ")", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlignRotated", "\n", "aligned", "=", "True", "\n", "", "else", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlign", "\n", "aligned", "=", "self", ".", "level_poolers", "[", "0", "]", ".", "aligned", "\n", "\n", "", "out", "=", "c2_roi_align", "(", "\n", "x", "[", "0", "]", ",", "\n", "pooler_fmt_boxes", ",", "\n", "order", "=", "\"NCHW\"", ",", "\n", "spatial_scale", "=", "float", "(", "self", ".", "level_poolers", "[", "0", "]", ".", "spatial_scale", ")", ",", "\n", "pooled_h", "=", "int", "(", "self", ".", "output_size", "[", "0", "]", ")", ",", "\n", "pooled_w", "=", "int", "(", "self", ".", "output_size", "[", "1", "]", ")", ",", "\n", "sampling_ratio", "=", "int", "(", "self", ".", "level_poolers", "[", "0", "]", ".", "sampling_ratio", ")", ",", "\n", "aligned", "=", "aligned", ",", "\n", ")", "\n", "return", "out", "\n", "\n", "", "device", "=", "pooler_fmt_boxes", ".", "device", "\n", "assert", "(", "\n", "self", ".", "max_level", "-", "self", ".", "min_level", "+", "1", "==", "4", "\n", ")", ",", "\"Currently DistributeFpnProposals only support 4 levels\"", "\n", "fpn_outputs", "=", "torch", ".", "ops", ".", "_caffe2", ".", "DistributeFpnProposals", "(", "\n", "to_device", "(", "pooler_fmt_boxes", ",", "\"cpu\"", ")", ",", "\n", "roi_canonical_scale", "=", "self", ".", "canonical_box_size", ",", "\n", "roi_canonical_level", "=", "self", ".", "canonical_level", ",", "\n", "roi_max_level", "=", "self", ".", "max_level", ",", "\n", "roi_min_level", "=", "self", ".", "min_level", ",", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "fpn_outputs", "=", "[", "to_device", "(", "x", ",", "device", ")", "for", "x", "in", "fpn_outputs", "]", "\n", "\n", "rois_fpn_list", "=", "fpn_outputs", "[", ":", "-", "1", "]", "\n", "rois_idx_restore_int32", "=", "fpn_outputs", "[", "-", "1", "]", "\n", "\n", "roi_feat_fpn_list", "=", "[", "]", "\n", "for", "roi_fpn", ",", "x_level", ",", "pooler", "in", "zip", "(", "rois_fpn_list", ",", "x", ",", "self", ".", "level_poolers", ")", ":", "\n", "            ", "if", "isinstance", "(", "pooler", ",", "ROIAlignRotated", ")", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlignRotated", "\n", "aligned", "=", "True", "\n", "", "else", ":", "\n", "                ", "c2_roi_align", "=", "torch", ".", "ops", ".", "_caffe2", ".", "RoIAlign", "\n", "aligned", "=", "bool", "(", "pooler", ".", "aligned", ")", "\n", "\n", "", "roi_feat_fpn", "=", "c2_roi_align", "(", "\n", "x_level", ",", "\n", "roi_fpn", ",", "\n", "order", "=", "\"NCHW\"", ",", "\n", "spatial_scale", "=", "float", "(", "pooler", ".", "spatial_scale", ")", ",", "\n", "pooled_h", "=", "int", "(", "self", ".", "output_size", "[", "0", "]", ")", ",", "\n", "pooled_w", "=", "int", "(", "self", ".", "output_size", "[", "1", "]", ")", ",", "\n", "sampling_ratio", "=", "int", "(", "pooler", ".", "sampling_ratio", ")", ",", "\n", "aligned", "=", "aligned", ",", "\n", ")", "\n", "roi_feat_fpn_list", ".", "append", "(", "roi_feat_fpn", ")", "\n", "\n", "", "roi_feat_shuffled", "=", "cat", "(", "roi_feat_fpn_list", ",", "dim", "=", "0", ")", "\n", "assert", "roi_feat_shuffled", ".", "numel", "(", ")", ">", "0", "and", "rois_idx_restore_int32", ".", "numel", "(", ")", ">", "0", ",", "(", "\n", "\"Caffe2 export requires tracing with a model checkpoint + input that can produce valid\"", "\n", "\" detections. But no detections were obtained with the given checkpoint and input!\"", "\n", ")", "\n", "roi_feat", "=", "torch", ".", "ops", ".", "_caffe2", ".", "BatchPermutation", "(", "roi_feat_shuffled", ",", "rois_idx_restore_int32", ")", "\n", "return", "roi_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2FastRCNNOutputsInference.__init__": [[362, 364], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tensor_mode", ")", ":", "\n", "        ", "self", ".", "tensor_mode", "=", "tensor_mode", "# whether the output is caffe2 tensor mode", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2FastRCNNOutputsInference.__call__": [[365, 493], ["type().cat", "torch.ops._caffe2.BBoxTransform", "torch.ops._caffe2.BBoxTransform", "torch.ops._caffe2.BBoxTransform", "torch.ops._caffe2.BBoxTransform", "shared.to_device", "shared.to_device", "torch.ops._caffe2.BoxWithNMSLimit", "torch.ops._caffe2.BoxWithNMSLimit", "torch.ops._caffe2.BoxWithNMSLimit", "torch.ops._caffe2.BoxWithNMSLimit", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "detectron2.layers.cat", "shared.alias", "shared.alias", "shared.alias", "shared.alias", "shared.alias", "shared.alias", "c10.InstancesList", "len", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "detectron2.layers.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "shared.to_device", "roi_class_nms.to.to.to", "c10.InstancesList.to_d2_instances_list", "shared.alias.int().tolist", "list", "type", "float", "float", "int", "torch.full", "torch.full", "torch.full", "torch.full", "shared.alias.to().split", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.full", "torch.full", "torch.full", "torch.full", "enumerate", "c10.Caffe2Boxes", "shared.alias.int", "enumerate", "shared.alias.to", "int", "len", "x.item"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.to_d2_instances_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "__call__", "(", "self", ",", "box_predictor", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\" equivalent to FastRCNNOutputLayers.inference \"\"\"", "\n", "num_classes", "=", "box_predictor", ".", "num_classes", "\n", "score_thresh", "=", "box_predictor", ".", "test_score_thresh", "\n", "nms_thresh", "=", "box_predictor", ".", "test_nms_thresh", "\n", "topk_per_image", "=", "box_predictor", ".", "test_topk_per_image", "\n", "is_rotated", "=", "len", "(", "box_predictor", ".", "box2box_transform", ".", "weights", ")", "==", "5", "\n", "\n", "if", "is_rotated", ":", "\n", "            ", "box_dim", "=", "5", "\n", "assert", "box_predictor", ".", "box2box_transform", ".", "weights", "[", "4", "]", "==", "1", ",", "(", "\n", "\"The weights for Rotated BBoxTransform in C2 have only 4 dimensions,\"", "\n", "+", "\" thus enforcing the angle weight to be 1 for now\"", "\n", ")", "\n", "box2box_transform_weights", "=", "box_predictor", ".", "box2box_transform", ".", "weights", "[", ":", "4", "]", "\n", "", "else", ":", "\n", "            ", "box_dim", "=", "4", "\n", "box2box_transform_weights", "=", "box_predictor", ".", "box2box_transform", ".", "weights", "\n", "\n", "", "class_logits", ",", "box_regression", "=", "predictions", "\n", "if", "num_classes", "+", "1", "==", "class_logits", ".", "shape", "[", "1", "]", ":", "\n", "            ", "class_prob", "=", "F", ".", "softmax", "(", "class_logits", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "assert", "num_classes", "==", "class_logits", ".", "shape", "[", "1", "]", "\n", "class_prob", "=", "F", ".", "sigmoid", "(", "class_logits", ")", "\n", "# BoxWithNMSLimit will infer num_classes from the shape of the class_prob", "\n", "# So append a zero column as placeholder for the background class", "\n", "class_prob", "=", "torch", ".", "cat", "(", "(", "class_prob", ",", "torch", ".", "zeros", "(", "class_prob", ".", "shape", "[", "0", "]", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "assert", "box_regression", ".", "shape", "[", "1", "]", "%", "box_dim", "==", "0", "\n", "cls_agnostic_bbox_reg", "=", "box_regression", ".", "shape", "[", "1", "]", "//", "box_dim", "==", "1", "\n", "\n", "input_tensor_mode", "=", "proposals", "[", "0", "]", ".", "proposal_boxes", ".", "tensor", ".", "shape", "[", "1", "]", "==", "box_dim", "+", "1", "\n", "\n", "rois", "=", "type", "(", "proposals", "[", "0", "]", ".", "proposal_boxes", ")", ".", "cat", "(", "[", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "]", ")", "\n", "device", ",", "dtype", "=", "rois", ".", "tensor", ".", "device", ",", "rois", ".", "tensor", ".", "dtype", "\n", "if", "input_tensor_mode", ":", "\n", "            ", "im_info", "=", "proposals", "[", "0", "]", ".", "image_size", "\n", "rois", "=", "rois", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "im_info", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ",", "1.0", "]", "for", "sz", "in", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "]", "\n", ")", "\n", "batch_ids", "=", "cat", "(", "\n", "[", "\n", "torch", ".", "full", "(", "(", "b", ",", "1", ")", ",", "i", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "len", "(", "p", ")", "for", "p", "in", "proposals", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "rois", "=", "torch", ".", "cat", "(", "[", "batch_ids", ",", "rois", ".", "tensor", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "roi_pred_bbox", ",", "roi_batch_splits", "=", "torch", ".", "ops", ".", "_caffe2", ".", "BBoxTransform", "(", "\n", "to_device", "(", "rois", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "box_regression", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "im_info", ",", "\"cpu\"", ")", ",", "\n", "weights", "=", "box2box_transform_weights", ",", "\n", "apply_scale", "=", "True", ",", "\n", "rotated", "=", "is_rotated", ",", "\n", "angle_bound_on", "=", "True", ",", "\n", "angle_bound_lo", "=", "-", "180", ",", "\n", "angle_bound_hi", "=", "180", ",", "\n", "clip_angle_thresh", "=", "1.0", ",", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "roi_pred_bbox", "=", "to_device", "(", "roi_pred_bbox", ",", "device", ")", "\n", "roi_batch_splits", "=", "to_device", "(", "roi_batch_splits", ",", "device", ")", "\n", "\n", "nms_outputs", "=", "torch", ".", "ops", ".", "_caffe2", ".", "BoxWithNMSLimit", "(", "\n", "to_device", "(", "class_prob", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "roi_pred_bbox", ",", "\"cpu\"", ")", ",", "\n", "to_device", "(", "roi_batch_splits", ",", "\"cpu\"", ")", ",", "\n", "score_thresh", "=", "float", "(", "score_thresh", ")", ",", "\n", "nms", "=", "float", "(", "nms_thresh", ")", ",", "\n", "detections_per_im", "=", "int", "(", "topk_per_image", ")", ",", "\n", "soft_nms_enabled", "=", "False", ",", "\n", "soft_nms_method", "=", "\"linear\"", ",", "\n", "soft_nms_sigma", "=", "0.5", ",", "\n", "soft_nms_min_score_thres", "=", "0.001", ",", "\n", "rotated", "=", "is_rotated", ",", "\n", "cls_agnostic_bbox_reg", "=", "cls_agnostic_bbox_reg", ",", "\n", "input_boxes_include_bg_cls", "=", "False", ",", "\n", "output_classes_include_bg_cls", "=", "False", ",", "\n", "legacy_plus_one", "=", "False", ",", "\n", ")", "\n", "roi_score_nms", "=", "to_device", "(", "nms_outputs", "[", "0", "]", ",", "device", ")", "\n", "roi_bbox_nms", "=", "to_device", "(", "nms_outputs", "[", "1", "]", ",", "device", ")", "\n", "roi_class_nms", "=", "to_device", "(", "nms_outputs", "[", "2", "]", ",", "device", ")", "\n", "roi_batch_splits_nms", "=", "to_device", "(", "nms_outputs", "[", "3", "]", ",", "device", ")", "\n", "roi_keeps_nms", "=", "to_device", "(", "nms_outputs", "[", "4", "]", ",", "device", ")", "\n", "roi_keeps_size_nms", "=", "to_device", "(", "nms_outputs", "[", "5", "]", ",", "device", ")", "\n", "if", "not", "self", ".", "tensor_mode", ":", "\n", "            ", "roi_class_nms", "=", "roi_class_nms", ".", "to", "(", "torch", ".", "int64", ")", "\n", "\n", "", "roi_batch_ids", "=", "cat", "(", "\n", "[", "\n", "torch", ".", "full", "(", "(", "b", ",", "1", ")", ",", "i", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "int", "(", "x", ".", "item", "(", ")", ")", "for", "x", "in", "roi_batch_splits_nms", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "roi_class_nms", "=", "alias", "(", "roi_class_nms", ",", "\"class_nms\"", ")", "\n", "roi_score_nms", "=", "alias", "(", "roi_score_nms", ",", "\"score_nms\"", ")", "\n", "roi_bbox_nms", "=", "alias", "(", "roi_bbox_nms", ",", "\"bbox_nms\"", ")", "\n", "roi_batch_splits_nms", "=", "alias", "(", "roi_batch_splits_nms", ",", "\"batch_splits_nms\"", ")", "\n", "roi_keeps_nms", "=", "alias", "(", "roi_keeps_nms", ",", "\"keeps_nms\"", ")", "\n", "roi_keeps_size_nms", "=", "alias", "(", "roi_keeps_size_nms", ",", "\"keeps_size_nms\"", ")", "\n", "\n", "results", "=", "InstancesList", "(", "\n", "im_info", "=", "im_info", ",", "\n", "indices", "=", "roi_batch_ids", "[", ":", ",", "0", "]", ",", "\n", "extra_fields", "=", "{", "\n", "\"pred_boxes\"", ":", "Caffe2Boxes", "(", "roi_bbox_nms", ")", ",", "\n", "\"scores\"", ":", "roi_score_nms", ",", "\n", "\"pred_classes\"", ":", "roi_class_nms", ",", "\n", "}", ",", "\n", ")", "\n", "\n", "if", "not", "self", ".", "tensor_mode", ":", "\n", "            ", "results", "=", "InstancesList", ".", "to_d2_instances_list", "(", "results", ")", "\n", "batch_splits", "=", "roi_batch_splits_nms", ".", "int", "(", ")", ".", "tolist", "(", ")", "\n", "kept_indices", "=", "list", "(", "roi_keeps_nms", ".", "to", "(", "torch", ".", "int64", ")", ".", "split", "(", "batch_splits", ")", ")", "\n", "", "else", ":", "\n", "            ", "results", "=", "[", "results", "]", "\n", "kept_indices", "=", "[", "roi_keeps_nms", "]", "\n", "\n", "", "return", "results", ",", "kept_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2MaskRCNNInference.__call__": [[496, 505], ["all", "pred_mask_logits.sigmoid", "shared.alias", "detectron2.modeling.roi_heads.mask_head.mask_rcnn_inference", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_inference"], ["    ", "def", "__call__", "(", "self", ",", "pred_mask_logits", ",", "pred_instances", ")", ":", "\n", "        ", "\"\"\" equivalent to mask_head.mask_rcnn_inference \"\"\"", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "InstancesList", ")", "for", "x", "in", "pred_instances", ")", ":", "\n", "            ", "assert", "len", "(", "pred_instances", ")", "==", "1", "\n", "mask_probs_pred", "=", "pred_mask_logits", ".", "sigmoid", "(", ")", "\n", "mask_probs_pred", "=", "alias", "(", "mask_probs_pred", ",", "\"mask_fcn_probs\"", ")", "\n", "pred_instances", "[", "0", "]", ".", "pred_masks", "=", "mask_probs_pred", "\n", "", "else", ":", "\n", "            ", "mask_rcnn_inference", "(", "pred_mask_logits", ",", "pred_instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2KeypointRCNNInference.__init__": [[508, 510], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "use_heatmap_max_keypoint", ")", ":", "\n", "        ", "self", ".", "use_heatmap_max_keypoint", "=", "use_heatmap_max_keypoint", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.Caffe2KeypointRCNNInference.__call__": [[511, 528], ["shared.alias", "all", "isinstance", "len", "torch.ops._caffe2.HeatmapMaxKeypoint", "torch.ops._caffe2.HeatmapMaxKeypoint", "torch.ops._caffe2.HeatmapMaxKeypoint", "torch.ops._caffe2.HeatmapMaxKeypoint", "shared.to_device", "shared.alias", "shared.to_device"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.alias", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.to_device"], ["", "def", "__call__", "(", "self", ",", "pred_keypoint_logits", ",", "pred_instances", ")", ":", "\n", "# just return the keypoint heatmap for now,", "\n", "# there will be option to call HeatmapMaxKeypointOp", "\n", "        ", "output", "=", "alias", "(", "pred_keypoint_logits", ",", "\"kps_score\"", ")", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "InstancesList", ")", "for", "x", "in", "pred_instances", ")", ":", "\n", "            ", "assert", "len", "(", "pred_instances", ")", "==", "1", "\n", "if", "self", ".", "use_heatmap_max_keypoint", ":", "\n", "                ", "device", "=", "output", ".", "device", "\n", "output", "=", "torch", ".", "ops", ".", "_caffe2", ".", "HeatmapMaxKeypoint", "(", "\n", "to_device", "(", "output", ",", "\"cpu\"", ")", ",", "\n", "pred_instances", "[", "0", "]", ".", "pred_boxes", ".", "tensor", ",", "\n", "should_output_softmax", "=", "True", ",", "# worth make it configerable?", "\n", ")", "\n", "output", "=", "to_device", "(", "output", ",", "device", ")", "\n", "output", "=", "alias", "(", "output", ",", "\"keypoints_out\"", ")", "\n", "", "pred_instances", "[", "0", "]", ".", "pred_keypoints", "=", "output", "\n", "", "return", "pred_keypoint_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.__init__": [[68, 91], ["isinstance", "isinstance", "type", "C2MetaArch", "api.Caffe2Tracer.traceable_model.get_caffe2_inputs", "api.add_export_config", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2MetaArch.get_caffe2_inputs", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.add_export_config"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "model", ":", "nn", ".", "Module", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode): a detectron2 config, with extra export-related options\n                added by :func:`add_export_config`. It's used to construct\n                caffe2-compatible model.\n            model (nn.Module): An original pytorch model. Must be among a few official models\n                in detectron2 that can be converted to become caffe2-compatible automatically.\n                Weights have to be already loaded to this model.\n            inputs: sample inputs that the given model takes for inference.\n                Will be used to trace the model. For most models, random inputs with\n                no detected objects will not work as they lead to wrong traces.\n        \"\"\"", "\n", "assert", "isinstance", "(", "cfg", ",", "CfgNode", ")", ",", "cfg", "\n", "assert", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "Module", ")", ",", "type", "(", "model", ")", "\n", "\n", "if", "\"EXPORT_CAFFE2\"", "not", "in", "cfg", ":", "\n", "            ", "cfg", "=", "add_export_config", "(", "cfg", ")", "# will just the defaults", "\n", "# TODO make it support custom models, by passing in c2 model directly", "\n", "", "C2MetaArch", "=", "META_ARCH_CAFFE2_EXPORT_TYPE_MAP", "[", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "]", "\n", "self", ".", "traceable_model", "=", "C2MetaArch", "(", "cfg", ",", "copy", ".", "deepcopy", "(", "model", ")", ")", "\n", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "traceable_inputs", "=", "self", ".", "traceable_model", ".", "get_caffe2_inputs", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_caffe2": [[92, 107], ["export_caffe2_detection_model", "api.Caffe2Model"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export.export_caffe2_detection_model"], ["", "def", "export_caffe2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Export the model to Caffe2's protobuf format.\n        The returned object can be saved with its :meth:`.save_protobuf()` method.\n        The result can be loaded and executed using Caffe2 runtime.\n\n        Returns:\n            :class:`Caffe2Model`\n        \"\"\"", "\n", "from", ".", "caffe2_export", "import", "export_caffe2_detection_model", "\n", "\n", "predict_net", ",", "init_net", "=", "export_caffe2_detection_model", "(", "\n", "self", ".", "traceable_model", ",", "self", ".", "traceable_inputs", "\n", ")", "\n", "return", "Caffe2Model", "(", "predict_net", ",", "init_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_onnx": [[108, 122], ["export_onnx_model_impl"], "methods", ["None"], ["", "def", "export_onnx", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Export the model to ONNX format.\n        Note that the exported model contains custom ops only available in caffe2, therefore it\n        cannot be directly executed by other runtime (such as onnxruntime or TensorRT).\n        Post-processing or transformation passes may be applied on the model to accommodate\n        different runtimes, but we currently do not provide support for them.\n\n        Returns:\n            onnx.ModelProto: an onnx model.\n        \"\"\"", "\n", "from", ".", "caffe2_export", "import", "export_onnx_model", "as", "export_onnx_model_impl", "\n", "\n", "return", "export_onnx_model_impl", "(", "self", ".", "traceable_model", ",", "(", "self", ".", "traceable_inputs", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_torchscript": [[123, 135], ["logging.getLogger", "logging.getLogger.info", "torch.no_grad", "torch.jit.trace"], "methods", ["None"], ["", "def", "export_torchscript", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Export the model to a ``torch.jit.TracedModule`` by tracing.\n        The returned object can be saved to a file by ``.save()``.\n\n        Returns:\n            torch.jit.TracedModule: a torch TracedModule\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Tracing the model with torch.jit.trace ...\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "torch", ".", "jit", ".", "trace", "(", "self", ".", "traceable_model", ",", "(", "self", ".", "traceable_inputs", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.__init__": [[153, 159], ["torch.nn.Module.__init__", "api.Caffe2Model.eval"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eval", "(", ")", "# always in eval mode", "\n", "self", ".", "_predict_net", "=", "predict_net", "\n", "self", ".", "_init_net", "=", "init_net", "\n", "self", ".", "_predictor", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.predict_net": [[162, 168], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "predict_net", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        caffe2.core.Net: the underlying caffe2 predict net\n        \"\"\"", "\n", "return", "self", ".", "_predict_net", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.init_net": [[169, 175], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "init_net", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        caffe2.core.Net: the underlying caffe2 init net\n        \"\"\"", "\n", "return", "self", ".", "_init_net", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_protobuf": [[176, 201], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.file_io.PathManager.exists", "detectron2.utils.file_io.PathManager.mkdirs", "detectron2.utils.file_io.PathManager.open", "f.write", "detectron2.utils.file_io.PathManager.open", "f.write", "detectron2.utils.file_io.PathManager.open", "f.write", "os.path.join", "api.Caffe2Model._predict_net.SerializeToString", "os.path.join", "str", "os.path.join", "api.Caffe2Model._init_net.SerializeToString"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.SampleCountMetricPrinter.write"], ["", "def", "save_protobuf", "(", "self", ",", "output_dir", ")", ":", "\n", "        ", "\"\"\"\n        Save the model as caffe2's protobuf format.\n        It saves the following files:\n\n            * \"model.pb\": definition of the graph. Can be visualized with\n              tools like `netron <https://github.com/lutzroeder/netron>`_.\n            * \"model_init.pb\": model parameters\n            * \"model.pbtxt\": human-readable definition of the graph. Not\n              needed for deployment.\n\n        Args:\n            output_dir (str): the output directory to save protobuf files.\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Saving model to {} ...\"", ".", "format", "(", "output_dir", ")", ")", "\n", "if", "not", "PathManager", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "output_dir", ")", "\n", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model.pb\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "self", ".", "_predict_net", ".", "SerializeToString", "(", ")", ")", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model.pbtxt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "self", ".", "_predict_net", ")", ")", "\n", "", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model_init.pb\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "self", ".", "_init_net", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_graph": [[202, 223], ["shared.save_graph", "shared.get_pb_arg_vali", "shared.get_pb_arg_vals().decode", "caffe2_modeling.convert_batched_inputs_to_c2_format", "run_and_save_graph", "x.cpu().numpy", "shared.get_pb_arg_vals", "x.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.save_graph", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.convert_batched_inputs_to_c2_format", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_export.run_and_save_graph", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals"], ["", "", "def", "save_graph", "(", "self", ",", "output_file", ",", "inputs", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Save the graph as SVG format.\n\n        Args:\n            output_file (str): a SVG file\n            inputs: optional inputs given to the model.\n                If given, the inputs will be used to run the graph to record\n                shape of every tensor. The shape information will be\n                saved together with the graph.\n        \"\"\"", "\n", "from", ".", "caffe2_export", "import", "run_and_save_graph", "\n", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "save_graph", "(", "self", ".", "_predict_net", ",", "output_file", ",", "op_only", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "size_divisibility", "=", "get_pb_arg_vali", "(", "self", ".", "_predict_net", ",", "\"size_divisibility\"", ",", "0", ")", "\n", "device", "=", "get_pb_arg_vals", "(", "self", ".", "_predict_net", ",", "\"device\"", ",", "b\"cpu\"", ")", ".", "decode", "(", "\"ascii\"", ")", "\n", "inputs", "=", "convert_batched_inputs_to_c2_format", "(", "inputs", ",", "size_divisibility", ",", "device", ")", "\n", "inputs", "=", "[", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "x", "in", "inputs", "]", "\n", "run_and_save_graph", "(", "self", ".", "_predict_net", ",", "self", ".", "_init_net", ",", "inputs", ",", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.load_protobuf": [[224, 244], ["caffe2.proto.caffe2_pb2.NetDef", "caffe2.proto.caffe2_pb2.NetDef", "api.Caffe2Model", "detectron2.utils.file_io.PathManager.open", "caffe2.proto.caffe2_pb2.NetDef.ParseFromString", "detectron2.utils.file_io.PathManager.open", "caffe2.proto.caffe2_pb2.NetDef.ParseFromString", "os.path.join", "f.read", "os.path.join", "f.read"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "load_protobuf", "(", "dir", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dir (str): a directory used to save Caffe2Model with\n                :meth:`save_protobuf`.\n                The files \"model.pb\" and \"model_init.pb\" are needed.\n\n        Returns:\n            Caffe2Model: the caffe2 model loaded from this directory.\n        \"\"\"", "\n", "predict_net", "=", "caffe2_pb2", ".", "NetDef", "(", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model.pb\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "predict_net", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "init_net", "=", "caffe2_pb2", ".", "NetDef", "(", ")", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"model_init.pb\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "init_net", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "return", "Caffe2Model", "(", "predict_net", ",", "init_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Model.__call__": [[245, 258], ["api.Caffe2Model._predictor", "caffe2_inference.ProtobufDetectionModel"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        An interface that wraps around a Caffe2 model and mimics detectron2's models'\n        input/output format. See details about the format at :doc:`/tutorials/models`.\n        This is used to compare the outputs of caffe2 model with its original torch model.\n\n        Due to the extra conversion between Pytorch/Caffe2, this method is not meant for\n        benchmark. Because of the conversion, this method also has dependency\n        on detectron2 in order to convert to detectron2's output format.\n        \"\"\"", "\n", "if", "self", ".", "_predictor", "is", "None", ":", "\n", "            ", "self", ".", "_predictor", "=", "ProtobufDetectionModel", "(", "self", ".", "_predict_net", ",", "self", ".", "_init_net", ")", "\n", "", "return", "self", ".", "_predictor", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.add_export_config": [[25, 43], ["cfg.is_frozen", "cfg.defrost", "detectron2.config.CfgNode", "cfg.freeze"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], ["def", "add_export_config", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Add options needed by caffe2 export.\n\n    Args:\n        cfg (CfgNode): a detectron2 config\n\n    Returns:\n        CfgNode:\n            an updated config with new options that will be used by :class:`Caffe2Tracer`.\n    \"\"\"", "\n", "is_frozen", "=", "cfg", ".", "is_frozen", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "EXPORT_CAFFE2", "=", "CfgNode", "(", ")", "\n", "cfg", ".", "EXPORT_CAFFE2", ".", "USE_HEATMAP_MAX_KEYPOINT", "=", "False", "\n", "if", "is_frozen", ":", "\n", "        ", "cfg", ".", "freeze", "(", ")", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.export_caffe2_model": [[260, 266], ["logging.getLogger", "logging.getLogger.warning", "api.Caffe2Tracer.export_caffe2", "api.Caffe2Tracer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_caffe2"], ["", "", "def", "export_caffe2_model", "(", "cfg", ",", "model", ",", "inputs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"export_caffe2_model() is deprecated. Please use `Caffe2Tracer().export_caffe2() instead.\"", "\n", ")", "\n", "return", "Caffe2Tracer", "(", "cfg", ",", "model", ",", "inputs", ")", ".", "export_caffe2", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.export_onnx_model": [[268, 274], ["logging.getLogger", "logging.getLogger.warning", "api.Caffe2Tracer.export_onnx", "api.Caffe2Tracer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.api.Caffe2Tracer.export_onnx"], ["", "def", "export_onnx_model", "(", "cfg", ",", "model", ",", "inputs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"export_caffe2_model() is deprecated. Please use `Caffe2Tracer().export_onnx() instead.\"", "\n", ")", "\n", "return", "Caffe2Tracer", "(", "cfg", ",", "model", ",", "inputs", ")", ".", "export_onnx", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.Schema.flatten": [[35, 38], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.Schema.__call__": [[39, 41], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.Schema._concat": [[42, 51], ["isinstance", "sizes.append", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_concat", "(", "values", ")", ":", "\n", "        ", "ret", "=", "(", ")", "\n", "sizes", "=", "[", "]", "\n", "for", "v", "in", "values", ":", "\n", "            ", "assert", "isinstance", "(", "v", ",", "tuple", ")", ",", "\"Flattened results must be a tuple\"", "\n", "ret", "=", "ret", "+", "v", "\n", "sizes", ".", "append", "(", "len", "(", "v", ")", ")", "\n", "", "return", "ret", ",", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.Schema._split": [[52, 64], ["len", "range", "sum", "len", "ret.append", "len", "sum", "sum", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_split", "(", "values", ",", "sizes", ")", ":", "\n", "        ", "if", "len", "(", "sizes", ")", ":", "\n", "            ", "expected_len", "=", "sum", "(", "sizes", ")", "\n", "assert", "(", "\n", "len", "(", "values", ")", "==", "expected_len", "\n", ")", ",", "f\"Values has length {len(values)} but expect length {expected_len}.\"", "\n", "", "ret", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "sizes", ")", ")", ":", "\n", "            ", "begin", ",", "end", "=", "sum", "(", "sizes", "[", ":", "k", "]", ")", ",", "sum", "(", "sizes", "[", ":", "k", "+", "1", "]", ")", "\n", "ret", ".", "append", "(", "values", "[", "begin", ":", "end", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.ListSchema.__call__": [[71, 79], ["flatten.ListSchema._split", "list", "len", "len", "ValueError", "m", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.Schema._split", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "values", "=", "self", ".", "_split", "(", "values", ",", "self", ".", "sizes", ")", "\n", "if", "len", "(", "values", ")", "!=", "len", "(", "self", ".", "schemas", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Values has length {len(values)} but schemas \"", "f\"has length {len(self.schemas)}!\"", "\n", ")", "\n", "", "values", "=", "[", "m", "(", "v", ")", "for", "m", ",", "v", "in", "zip", "(", "self", ".", "schemas", ",", "values", ")", "]", "\n", "return", "list", "(", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.ListSchema.flatten": [[80, 85], ["cls._concat", "flatten.flatten_to_tuple", "cls"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.Schema._concat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.flatten_to_tuple"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "res", "=", "[", "flatten_to_tuple", "(", "k", ")", "for", "k", "in", "obj", "]", "\n", "values", ",", "sizes", "=", "cls", ".", "_concat", "(", "[", "k", "[", "0", "]", "for", "k", "in", "res", "]", ")", "\n", "return", "values", ",", "cls", "(", "[", "k", "[", "1", "]", "for", "k", "in", "res", "]", ",", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TupleSchema.__call__": [[89, 91], ["tuple", "flatten.ListSchema.__call__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoreThresholdedExtractor.__call__"], ["    ", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "return", "tuple", "(", "super", "(", ")", ".", "__call__", "(", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.IdentitySchema.__call__": [[95, 97], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "return", "values", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.IdentitySchema.flatten": [[98, 101], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "return", "(", "obj", ",", ")", ",", "cls", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.DictSchema.__call__": [[107, 110], ["flatten.ListSchema.__call__", "dict", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoreThresholdedExtractor.__call__"], ["def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "values", "=", "super", "(", ")", ".", "__call__", "(", "values", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "keys", ",", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.DictSchema.flatten": [[111, 120], ["obj.keys", "sorted", "ListSchema.flatten", "obj.keys", "cls", "isinstance", "KeyError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "for", "k", "in", "obj", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "k", ",", "str", ")", ":", "\n", "                ", "raise", "KeyError", "(", "\"Only support flattening dictionaries if keys are str.\"", ")", "\n", "", "", "keys", "=", "sorted", "(", "obj", ".", "keys", "(", ")", ")", "\n", "values", "=", "[", "obj", "[", "k", "]", "for", "k", "in", "keys", "]", "\n", "ret", ",", "schema", "=", "ListSchema", ".", "flatten", "(", "values", ")", "\n", "return", "ret", ",", "cls", "(", "schema", ".", "schemas", ",", "schema", ".", "sizes", ",", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.InstancesSchema.__call__": [[124, 128], ["flatten.DictSchema.__call__", "detectron2.structures.Instances"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoreThresholdedExtractor.__call__"], ["    ", "def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "image_size", ",", "fields", "=", "values", "[", "-", "1", "]", ",", "values", "[", ":", "-", "1", "]", "\n", "fields", "=", "super", "(", ")", ".", "__call__", "(", "fields", ")", "\n", "return", "Instances", "(", "image_size", ",", "**", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.InstancesSchema.flatten": [[129, 136], ["flatten.DictSchema.flatten", "obj.get_fields", "isinstance", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "ret", ",", "schema", "=", "super", "(", ")", ".", "flatten", "(", "obj", ".", "get_fields", "(", ")", ")", "\n", "size", "=", "obj", ".", "image_size", "\n", "if", "not", "isinstance", "(", "size", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "size", "=", "torch", ".", "tensor", "(", "size", ")", "\n", "", "return", "ret", "+", "(", "size", ",", ")", ",", "schema", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.__call__": [[147, 149], ["detectron2.utils.registry.locate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry.locate"], ["def", "__call__", "(", "self", ",", "values", ")", ":", "\n", "        ", "return", "locate", "(", "self", ".", "class_name", ")", "(", "values", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten": [[150, 153], ["cls", "detectron2.utils.registry._convert_target_to_string", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.registry._convert_target_to_string"], ["", "@", "classmethod", "\n", "def", "flatten", "(", "cls", ",", "obj", ")", ":", "\n", "        ", "return", "(", "obj", ".", "tensor", ",", ")", ",", "cls", "(", "_convert_target_to_string", "(", "type", "(", "obj", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TracingAdapter.__init__": [[224, 275], ["torch.nn.Module.__init__", "isinstance", "flatten.flatten_to_tuple", "all", "isinstance", "tuple", "model", "isinstance", "isinstance", "ValueError", "isinstance", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.flatten_to_tuple"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "inputs", ",", "\n", "inference_func", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "allow_non_tensor", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model: an nn.Module\n            inputs: An input argument or a tuple of input arguments used to call model.\n                After flattening, it has to only consist of tensors.\n            inference_func: a callable that takes (model, *inputs), calls the\n                model with inputs, and return outputs. By default it\n                is ``lambda model, *inputs: model(*inputs)``. Can be override\n                if you need to call the model differently.\n            allow_non_tensor: allow inputs/outputs to contain non-tensor objects.\n                This option will filter out non-tensor objects to make the\n                model traceable, but ``inputs_schema``/``outputs_schema`` cannot be\n                used anymore because inputs/outputs cannot be rebuilt from pure tensors.\n                This is useful when you're only interested in the single trace of\n                execution (e.g. for flop count), but not interested in\n                generalizing the traced graph to new inputs.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "model", ",", "(", "nn", ".", "parallel", ".", "distributed", ".", "DistributedDataParallel", ",", "nn", ".", "DataParallel", ")", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "", "self", ".", "model", "=", "model", "\n", "if", "not", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "            ", "inputs", "=", "(", "inputs", ",", ")", "\n", "", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "allow_non_tensor", "=", "allow_non_tensor", "\n", "\n", "if", "inference_func", "is", "None", ":", "\n", "            ", "inference_func", "=", "lambda", "model", ",", "*", "inputs", ":", "model", "(", "*", "inputs", ")", "# noqa", "\n", "", "self", ".", "inference_func", "=", "inference_func", "\n", "\n", "self", ".", "flattened_inputs", ",", "self", ".", "inputs_schema", "=", "flatten_to_tuple", "(", "inputs", ")", "\n", "\n", "if", "all", "(", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "for", "x", "in", "self", ".", "flattened_inputs", ")", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "allow_non_tensor", ":", "\n", "            ", "self", ".", "flattened_inputs", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "self", ".", "flattened_inputs", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "]", "\n", ")", "\n", "self", ".", "inputs_schema", "=", "None", "\n", "", "else", ":", "\n", "            ", "for", "input", "in", "self", ".", "flattened_inputs", ":", "\n", "                ", "if", "not", "isinstance", "(", "input", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Inputs for tracing must only contain tensors. \"", "\n", "f\"Got a {type(input)} instead.\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TracingAdapter.forward": [[278, 315], ["torch.no_grad", "torchscript_patch.patch_builtin_len", "flatten.TracingAdapter.inference_func", "flatten.flatten_to_tuple", "tuple", "flatten.TracingAdapter.inputs_schema", "len", "len", "ValueError", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.torchscript_patch.patch_builtin_len", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.flatten_to_tuple"], ["", "", "", "", "def", "forward", "(", "self", ",", "*", "args", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ",", "patch_builtin_len", "(", ")", ":", "\n", "            ", "if", "self", ".", "inputs_schema", "is", "not", "None", ":", "\n", "                ", "inputs_orig_format", "=", "self", ".", "inputs_schema", "(", "args", ")", "\n", "", "else", ":", "\n", "                ", "if", "args", "!=", "self", ".", "flattened_inputs", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"TracingAdapter does not contain valid inputs_schema.\"", "\n", "\" So it cannot generalize to other inputs and must be\"", "\n", "\" traced with `.flattened_inputs`.\"", "\n", ")", "\n", "", "inputs_orig_format", "=", "self", ".", "inputs", "\n", "\n", "", "outputs", "=", "self", ".", "inference_func", "(", "self", ".", "model", ",", "*", "inputs_orig_format", ")", "\n", "flattened_outputs", ",", "schema", "=", "flatten_to_tuple", "(", "outputs", ")", "\n", "\n", "flattened_output_tensors", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "flattened_outputs", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "]", "\n", ")", "\n", "if", "len", "(", "flattened_output_tensors", ")", "<", "len", "(", "flattened_outputs", ")", ":", "\n", "                ", "if", "self", ".", "allow_non_tensor", ":", "\n", "                    ", "flattened_outputs", "=", "flattened_output_tensors", "\n", "self", ".", "outputs_schema", "=", "None", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Model cannot be traced because some model outputs \"", "\n", "\"cannot flatten to tensors.\"", "\n", ")", "\n", "", "", "else", ":", "# schema is valid", "\n", "                ", "if", "self", ".", "outputs_schema", "is", "None", ":", "\n", "                    ", "self", ".", "outputs_schema", "=", "schema", "\n", "", "else", ":", "\n", "                    ", "assert", "self", ".", "outputs_schema", "==", "schema", ",", "(", "\n", "\"Model should always return outputs with the same \"", "\n", "\"structure so it can be traced!\"", "\n", ")", "\n", "", "", "return", "flattened_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TracingAdapter._create_wrapper": [[316, 328], ["flatten.flatten_to_tuple", "traced_model", "flatten.TracingAdapter.outputs_schema"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.flatten_to_tuple"], ["", "", "def", "_create_wrapper", "(", "self", ",", "traced_model", ")", ":", "\n", "        ", "\"\"\"\n        Return a function that has an input/output interface the same as the\n        original model, but it calls the given traced model under the hood.\n        \"\"\"", "\n", "\n", "def", "forward", "(", "*", "args", ")", ":", "\n", "            ", "flattened_inputs", ",", "_", "=", "flatten_to_tuple", "(", "args", ")", "\n", "flattened_outputs", "=", "traced_model", "(", "*", "flattened_inputs", ")", "\n", "return", "self", ".", "outputs_schema", "(", "flattened_outputs", ")", "\n", "\n", "", "return", "forward", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.flatten_to_tuple": [[157, 183], ["F.flatten", "isinstance"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "", "def", "flatten_to_tuple", "(", "obj", ")", ":", "\n", "    ", "\"\"\"\n    Flatten an object so it can be used for PyTorch tracing.\n    Also returns how to rebuild the original object from the flattened outputs.\n\n    Returns:\n        res (tuple): the flattened results that can be used as tracing outputs\n        schema: an object with a ``__call__`` method such that ``schema(res) == obj``.\n             It is a pure dataclass that can be serialized.\n    \"\"\"", "\n", "schemas", "=", "[", "\n", "(", "(", "str", ",", "bytes", ")", ",", "IdentitySchema", ")", ",", "\n", "(", "list", ",", "ListSchema", ")", ",", "\n", "(", "tuple", ",", "TupleSchema", ")", ",", "\n", "(", "collections", ".", "abc", ".", "Mapping", ",", "DictSchema", ")", ",", "\n", "(", "Instances", ",", "InstancesSchema", ")", ",", "\n", "(", "Boxes", ",", "TensorWrapSchema", ")", ",", "\n", "]", "\n", "for", "klass", ",", "schema", "in", "schemas", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "klass", ")", ":", "\n", "            ", "F", "=", "schema", "\n", "break", "\n", "", "", "else", ":", "\n", "        ", "F", "=", "IdentitySchema", "\n", "\n", "", "return", "F", ".", "flatten", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufModel.__init__": [[26, 47], ["logger.info", "super().__init__", "isinstance", "isinstance", "caffe2.python.core.Net", "logger.info", "set", "next", "shared.ScopedWS", "ws.RunNetOnce", "ws.CreateNet", "caffe2_inference.ProtobufModel.net.Proto", "ws.Blobs", "uninitialized_external_input.append", "ws.CreateBlob"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["def", "__init__", "(", "self", ",", "predict_net", ",", "init_net", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Initializing ProtobufModel for: {predict_net.name} ...\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "predict_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "assert", "isinstance", "(", "init_net", ",", "caffe2_pb2", ".", "NetDef", ")", "\n", "# create unique temporary workspace for each instance", "\n", "self", ".", "ws_name", "=", "\"__tmp_ProtobufModel_{}__\"", ".", "format", "(", "next", "(", "self", ".", "_ids", ")", ")", "\n", "self", ".", "net", "=", "core", ".", "Net", "(", "predict_net", ")", "\n", "\n", "logger", ".", "info", "(", "\"Running init_net once to fill the parameters ...\"", ")", "\n", "with", "ScopedWS", "(", "self", ".", "ws_name", ",", "is_reset", "=", "True", ",", "is_cleanup", "=", "False", ")", "as", "ws", ":", "\n", "            ", "ws", ".", "RunNetOnce", "(", "init_net", ")", "\n", "uninitialized_external_input", "=", "[", "]", "\n", "for", "blob", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_input", ":", "\n", "                ", "if", "blob", "not", "in", "ws", ".", "Blobs", "(", ")", ":", "\n", "                    ", "uninitialized_external_input", ".", "append", "(", "blob", ")", "\n", "ws", ".", "CreateBlob", "(", "blob", ")", "\n", "", "", "ws", ".", "CreateNet", "(", "self", ".", "net", ")", "\n", "\n", "", "self", ".", "_error_msgs", "=", "set", "(", ")", "\n", "self", ".", "_input_blobs", "=", "uninitialized_external_input", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufModel._infer_output_devices": [[48, 70], ["caffe2_inference.ProtobufModel.net.Proto", "shared.infer_device_type", "caffe2.python.core.get_ssa", "caffe2_inference.ProtobufModel._infer_output_devices._get_device_type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.infer_device_type"], ["", "def", "_infer_output_devices", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[str]: list of device for each external output\n        \"\"\"", "\n", "\n", "def", "_get_device_type", "(", "torch_tensor", ")", ":", "\n", "            ", "assert", "torch_tensor", ".", "device", ".", "type", "in", "[", "\"cpu\"", ",", "\"cuda\"", "]", "\n", "assert", "torch_tensor", ".", "device", ".", "index", "==", "0", "\n", "return", "torch_tensor", ".", "device", ".", "type", "\n", "\n", "", "predict_net", "=", "self", ".", "net", ".", "Proto", "(", ")", "\n", "input_device_types", "=", "{", "\n", "(", "name", ",", "0", ")", ":", "_get_device_type", "(", "tensor", ")", "for", "name", ",", "tensor", "in", "zip", "(", "self", ".", "_input_blobs", ",", "inputs", ")", "\n", "}", "\n", "device_type_map", "=", "infer_device_type", "(", "\n", "predict_net", ",", "known_status", "=", "input_device_types", ",", "device_name_style", "=", "\"pytorch\"", "\n", ")", "\n", "ssa", ",", "versions", "=", "core", ".", "get_ssa", "(", "predict_net", ")", "\n", "versioned_outputs", "=", "[", "(", "name", ",", "versions", "[", "name", "]", ")", "for", "name", "in", "predict_net", ".", "external_output", "]", "\n", "output_devices", "=", "[", "device_type_map", "[", "outp", "]", "for", "outp", "in", "versioned_outputs", "]", "\n", "return", "output_devices", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufModel.forward": [[71, 123], ["zip", "tuple", "len", "len", "shared.ScopedWS", "zip", "any", "caffe2_inference.ProtobufModel._infer_output_devices", "outputs.append", "len", "ws.FeedBlob", "ws.RunNet", "ws.FetchBlob", "caffe2_inference.ProtobufModel.net.Proto", "ws.FeedBlob", "caffe2_inference.ProtobufModel.net.Proto", "isinstance", "RuntimeError", "torch.Tensor().to", "logger.warning", "caffe2_inference.ProtobufModel.net.Proto", "caffe2_inference.ProtobufModel._error_msgs.add", "logger.warning", "caffe2_inference.ProtobufModel.net.Proto", "caffe2_inference.ProtobufModel.net.Proto", "torch.Tensor", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufModel._infer_output_devices", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (tuple[torch.Tensor])\n\n        Returns:\n            tuple[torch.Tensor]\n        \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "self", ".", "_input_blobs", ")", ",", "(", "\n", "f\"Length of inputs ({len(inputs)}) \"", "\n", "f\"doesn't match the required input blobs: {self._input_blobs}\"", "\n", ")", "\n", "\n", "with", "ScopedWS", "(", "self", ".", "ws_name", ",", "is_reset", "=", "False", ",", "is_cleanup", "=", "False", ")", "as", "ws", ":", "\n", "            ", "for", "b", ",", "tensor", "in", "zip", "(", "self", ".", "_input_blobs", ",", "inputs", ")", ":", "\n", "                ", "ws", ".", "FeedBlob", "(", "b", ",", "tensor", ")", "\n", "\n", "", "try", ":", "\n", "                ", "ws", ".", "RunNet", "(", "self", ".", "net", ".", "Proto", "(", ")", ".", "name", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "not", "str", "(", "e", ")", "in", "self", ".", "_error_msgs", ":", "\n", "                    ", "self", ".", "_error_msgs", ".", "add", "(", "str", "(", "e", ")", ")", "\n", "logger", ".", "warning", "(", "\"Encountered new RuntimeError: \\n{}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "", "logger", ".", "warning", "(", "\"Catch the error and use partial results.\"", ")", "\n", "\n", "", "c2_outputs", "=", "[", "ws", ".", "FetchBlob", "(", "b", ")", "for", "b", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", "]", "\n", "# Remove outputs of current run, this is necessary in order to", "\n", "# prevent fetching the result from previous run if the model fails", "\n", "# in the middle.", "\n", "for", "b", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", ":", "\n", "# Needs to create uninitialized blob to make the net runable.", "\n", "# This is \"equivalent\" to: ws.RemoveBlob(b) then ws.CreateBlob(b),", "\n", "# but there'no such API.", "\n", "                ", "ws", ".", "FeedBlob", "(", "b", ",", "f\"{b}, a C++ native class of type nullptr (uninitialized).\"", ")", "\n", "\n", "# Cast output to torch.Tensor on the desired device", "\n", "", "", "output_devices", "=", "(", "\n", "self", ".", "_infer_output_devices", "(", "inputs", ")", "\n", "if", "any", "(", "t", ".", "device", ".", "type", "!=", "\"cpu\"", "for", "t", "in", "inputs", ")", "\n", "else", "[", "\"cpu\"", "for", "_", "in", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", "]", "\n", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "for", "name", ",", "c2_output", ",", "device", "in", "zip", "(", "\n", "self", ".", "net", ".", "Proto", "(", ")", ".", "external_output", ",", "c2_outputs", ",", "output_devices", "\n", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "c2_output", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Invalid output for blob {}, received: {}\"", ".", "format", "(", "name", ",", "c2_output", ")", "\n", ")", "\n", "", "outputs", ".", "append", "(", "torch", ".", "Tensor", "(", "c2_output", ")", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "", "return", "tuple", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufDetectionModel.__init__": [[131, 150], ["super().__init__", "caffe2_inference.ProtobufModel", "shared.get_pb_arg_vali", "shared.get_pb_arg_vals().decode", "shared.get_pb_arg_vals", "shared.get_pb_arg_vals.get_outputs_converter", "shared.get_pb_arg_vals", "shared.get_pb_arg_vals.decode"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vali", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.Caffe2RetinaNet.get_outputs_converter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.shared.get_pb_arg_vals", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode"], ["def", "__init__", "(", "self", ",", "predict_net", ",", "init_net", ",", "*", ",", "convert_outputs", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predict_net, init_net (core.Net): caffe2 nets\n            convert_outptus (callable): a function that converts caffe2\n                outputs to the same format of the original pytorch model.\n                By default, use the one defined in the caffe2 meta_arch.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "protobuf_model", "=", "ProtobufModel", "(", "predict_net", ",", "init_net", ")", "\n", "self", ".", "size_divisibility", "=", "get_pb_arg_vali", "(", "predict_net", ",", "\"size_divisibility\"", ",", "0", ")", "\n", "self", ".", "device", "=", "get_pb_arg_vals", "(", "predict_net", ",", "\"device\"", ",", "b\"cpu\"", ")", ".", "decode", "(", "\"ascii\"", ")", "\n", "\n", "if", "convert_outputs", "is", "None", ":", "\n", "            ", "meta_arch", "=", "get_pb_arg_vals", "(", "predict_net", ",", "\"meta_architecture\"", ",", "b\"GeneralizedRCNN\"", ")", "\n", "meta_arch", "=", "META_ARCH_CAFFE2_EXPORT_TYPE_MAP", "[", "meta_arch", ".", "decode", "(", "\"ascii\"", ")", "]", "\n", "self", ".", "_convert_outputs", "=", "meta_arch", ".", "get_outputs_converter", "(", "predict_net", ",", "init_net", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_convert_outputs", "=", "convert_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufDetectionModel._convert_inputs": [[151, 155], ["caffe2_modeling.convert_batched_inputs_to_c2_format"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_modeling.convert_batched_inputs_to_c2_format"], ["", "", "def", "_convert_inputs", "(", "self", ",", "batched_inputs", ")", ":", "\n", "# currently all models convert inputs in the same way", "\n", "        ", "return", "convert_batched_inputs_to_c2_format", "(", "\n", "batched_inputs", ",", "self", ".", "size_divisibility", ",", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufDetectionModel.forward": [[157, 162], ["caffe2_inference.ProtobufDetectionModel._convert_inputs", "caffe2_inference.ProtobufDetectionModel.protobuf_model", "dict", "caffe2_inference.ProtobufDetectionModel._convert_outputs", "zip", "caffe2_inference.ProtobufDetectionModel.protobuf_model.net.Proto"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.caffe2_inference.ProtobufDetectionModel._convert_inputs"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "c2_inputs", "=", "self", ".", "_convert_inputs", "(", "batched_inputs", ")", "\n", "c2_results", "=", "self", ".", "protobuf_model", "(", "c2_inputs", ")", "\n", "c2_results", "=", "dict", "(", "zip", "(", "self", ".", "protobuf_model", ".", "net", ".", "Proto", "(", ")", ".", "external_output", ",", "c2_results", ")", ")", "\n", "return", "self", ".", "_convert_outputs", "(", "batched_inputs", ",", "c2_inputs", ",", "c2_results", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_evaluator": [[54, 97], ["detectron2.evaluation.DatasetEvaluators", "detectron2.evaluation.DatasetEvaluators", "os.path.join", "detectron2.data.MetadataCatalog.get", "detectron2.data.MetadataCatalog.get", "evaluator_list.append", "evaluator_list.append", "evaluator_list.append", "evaluator_list.append", "len", "NotImplementedError", "detectron2.evaluation.COCOPanopticEvaluator", "detectron2.evaluation.COCOPanopticEvaluator", "torch.cuda.device_count", "detectron2.get_rank", "detectron2.get_rank", "detectron2.evaluation.CityscapesSemSegEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "detectron2.evaluation.CityscapesInstanceEvaluator", "detectron2.evaluation.CityscapesInstanceEvaluator", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.COCOEvaluator", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], [")", "\n", "\n", "", "arguments", "=", "{", "}", "\n", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "\n", "save_to_disk", "=", "get_rank", "(", ")", "==", "0", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "\n", "cfg", ",", "model", ",", "optimizer", ",", "scheduler", ",", "output_dir", ",", "save_to_disk", "\n", ")", "\n", "extra_checkpoint_data", "=", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHT", ")", "\n", "arguments", ".", "update", "(", "extra_checkpoint_data", ")", "\n", "\n", "if", "search", ":", "\n", "        ", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "", "data_loader", "=", "make_data_loader", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "is_distributed", "=", "distributed", ",", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", ",", "\n", ")", "\n", "\n", "test_period", "=", "cfg", ".", "SOLVER", ".", "TEST_PERIOD", "\n", "if", "test_period", ">", "0", ":", "\n", "        ", "data_loader_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ",", "is_for_period", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_val", "=", "None", "\n", "\n", "", "checkpoint_period", "=", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", "\n", "loss_hist", "=", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "checkpointer", ",", "\n", "device", ",", "\n", "checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_train_loader": [[98, 102], ["detectron2.projects.panoptic_deeplab.PanopticDeeplabDatasetMapper", "detectron2.projects.panoptic_deeplab.PanopticDeeplabDatasetMapper", "detectron2.data.build_detection_train_loader", "detectron2.data.build_detection_train_loader", "train_net.build_sem_seg_train_aug"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.build_sem_seg_train_aug"], ["search", ",", "\n", ")", "\n", "\n", "return", "model", ",", "loss_hist", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_lr_scheduler": [[103, 110], ["detectron2.projects.deeplab.build_lr_scheduler", "detectron2.projects.deeplab.build_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler"], ["\n", "", "def", "run_test", "(", "cfg", ",", "model", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "# TODO check if it helps", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.Trainer.build_optimizer": [[111, 134], ["detectron2.solver.get_default_optimizer_params", "detectron2.solver.get_default_optimizer_params", "detectron2.solver.build.maybe_add_gradient_clipping", "detectron2.solver.build.maybe_add_gradient_clipping", "NotImplementedError", "detectron2.solver.build.maybe_add_gradient_clipping", "detectron2.solver.build.maybe_add_gradient_clipping"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.get_default_optimizer_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.get_default_optimizer_params", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.build.maybe_add_gradient_clipping"], ["", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "output_folders", "=", "[", "None", "]", "*", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "\n", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "if", "cfg", ".", "OUTPUT_DIR", ":", "\n", "        ", "for", "idx", ",", "dataset_name", "in", "enumerate", "(", "dataset_names", ")", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "mkdir", "(", "output_folder", ")", "\n", "output_folders", "[", "idx", "]", "=", "output_folder", "\n", "", "", "data_loaders_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ")", "\n", "for", "output_folder", ",", "dataset_name", ",", "data_loader_val", "in", "zip", "(", "output_folders", ",", "dataset_names", ",", "data_loaders_val", ")", ":", "\n", "        ", "results", "=", "inference", "(", "\n", "model", ",", "\n", "data_loader_val", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "box_only", "=", "False", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", "or", "cfg", ".", "MODEL", ".", "FCOS_ON", "or", "cfg", ".", "MODEL", ".", "RETINANET_ON", "else", "cfg", ".", "MODEL", ".", "RPN_ONLY", ",", "\n", "device", "=", "cfg", ".", "MODEL", ".", "DEVICE", ",", "\n", "expected_results", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS", ",", "\n", "expected_results_sigma_tol", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS_SIGMA_TOL", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", ")", "\n", "synchronize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.build_sem_seg_train_aug": [[34, 44], ["augs.append", "detectron2.ResizeShortestEdge", "augs.append", "detectron2.RandomFlip", "detectron2.RandomCrop"], "function", ["None"], ["\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n", "    ", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "make_optimizer", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "make_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Initialize mixed-precision training", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.setup": [[136, 147], ["detectron2.config.get_cfg", "detectron2.projects.panoptic_deeplab.add_panoptic_deeplab_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.config.add_panoptic_deeplab_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["        ", "return", "results", "\n", "\n", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"PyTorch Object Detection Training\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.Panoptic-DeepLab.train_net.main": [[149, 163], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test"], ["\"--skip-test\"", ",", "\n", "dest", "=", "\"skip_test\"", ",", "\n", "help", "=", "\"Do not test the final model\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line\"", ",", "\n", "default", "=", "None", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "num_gpus", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "if", "\"WORLD_SIZE\"", "in", "os", ".", "environ", "else", "1", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.config.add_panoptic_deeplab_config": [[8, 60], ["detectron2.projects.deeplab.add_deeplab_config", "detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.config.add_deeplab_config"], ["\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    ", "\"\"\"\n    The same as `fvcore.common.config.CfgNode`, but different in:\n\n    1. Use unsafe yaml loading by default.\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    2. Support config versioning.\n       When attempting to merge an old config, it will convert the old config automatically.\n    \"\"\"", "\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n", "# Note that the default value of allow_unsafe is changed to True", "\n", "", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n", "if", "loaded_ver", "is", "None", ":", "\n", "            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n", "loaded_ver", ",", "self", ".", "VERSION", "\n", ")", "\n", "\n", "if", "loaded_ver", "==", "self", ".", "VERSION", ":", "\n", "            ", "self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "", "else", ":", "\n", "# compat.py needs to import CfgNode", "\n", "            ", "from", ".", "compat", "import", "upgrade_config", ",", "downgrade_config", "\n", "\n", "logger", ".", "warning", "(", "\n", "\"Loading an old v{} config file '{}' by automatically upgrading to v{}. \"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLab.__init__": [[42, 62], ["torch.nn.Module.__init__", "detectron2.modeling.build_backbone", "detectron2.modeling.build_sem_seg_head", "panoptic_seg.build_ins_embed_branch", "panoptic_seg.PanopticDeepLab.register_buffer", "panoptic_seg.PanopticDeepLab.register_buffer", "detectron2.data.MetadataCatalog.get", "panoptic_seg.PanopticDeepLab.backbone.output_shape", "panoptic_seg.PanopticDeepLab.backbone.output_shape", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.semantic_seg.build_sem_seg_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.build_ins_embed_branch", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "self", ".", "sem_seg_head", "=", "build_sem_seg_head", "(", "cfg", ",", "self", ".", "backbone", ".", "output_shape", "(", ")", ")", "\n", "self", ".", "ins_embed_head", "=", "build_ins_embed_branch", "(", "cfg", ",", "self", ".", "backbone", ".", "output_shape", "(", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "cfg", ".", "MODEL", ".", "PIXEL_STD", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "meta", "=", "MetadataCatalog", ".", "get", "(", "cfg", ".", "DATASETS", ".", "TRAIN", "[", "0", "]", ")", "\n", "self", ".", "stuff_area", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "STUFF_AREA", "\n", "self", ".", "threshold", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "CENTER_THRESHOLD", "\n", "self", ".", "nms_kernel", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "NMS_KERNEL", "\n", "self", ".", "top_k", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "TOP_K_INSTANCE", "\n", "self", ".", "predict_instances", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "PREDICT_INSTANCES", "\n", "self", ".", "use_depthwise_separable_conv", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "USE_DEPTHWISE_SEPARABLE_CONV", "\n", "assert", "(", "\n", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "USE_DEPTHWISE_SEPARABLE_CONV", "\n", "==", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "USE_DEPTHWISE_SEPARABLE_CONV", "\n", ")", "\n", "self", ".", "size_divisibility", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "SIZE_DIVISIBILITY", "\n", "self", ".", "benchmark_network_speed", "=", "cfg", ".", "MODEL", ".", "PANOPTIC_DEEPLAB", ".", "BENCHMARK_NETWORK_SPEED", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLab.device": [[63, 66], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLab.forward": [[67, 220], ["detectron2.structures.ImageList.from_tensors", "panoptic_seg.PanopticDeepLab.backbone", "panoptic_seg.PanopticDeepLab.sem_seg_head", "losses.update", "panoptic_seg.PanopticDeepLab.ins_embed_head", "losses.update", "losses.update", "zip", "x[].to", "detectron2.structures.ImageList.from_tensors().tensor.unsqueeze", "input_per_image.get", "input_per_image.get", "detectron2.modeling.postprocessing.sem_seg_postprocess", "detectron2.modeling.postprocessing.sem_seg_postprocess", "detectron2.modeling.postprocessing.sem_seg_postprocess", "post_processing.get_panoptic_segmentation", "processed_results.append", "panoptic_image.squeeze.squeeze.squeeze", "torch.nn.functional.softmax", "x[].to", "detectron2.structures.ImageList.from_tensors", "x[].to", "x[].to", "detectron2.structures.ImageList.from_tensors", "x[].to", "detectron2.structures.ImageList.from_tensors", "x[].to", "detectron2.structures.ImageList.from_tensors", "detectron2.modeling.postprocessing.sem_seg_postprocess.argmax", "panoptic_image.squeeze.squeeze.cpu().numpy", "numpy.unique", "x[].to", "detectron2.structures.ImageList.from_tensors", "panoptic_seg.PanopticDeepLab.meta.thing_dataset_id_to_contiguous_id.values", "len", "detectron2.structures.Instances.cat", "detectron2.structures.ImageList.from_tensors", "panoptic_image.squeeze.squeeze.cpu", "list", "detectron2.structures.Instances", "torch.tensor", "mask.unsqueeze", "torch.mean", "torch.nonzero().float", "torch.tensor", "detectron2.structures.BitMasks().get_bounding_boxes", "instances.append", "panoptic_seg.PanopticDeepLab.meta.thing_dataset_id_to_contiguous_id.values", "torch.mean", "torch.mean", "torch.nonzero", "detectron2.structures.BitMasks", "int", "int", "center_y.item", "center_x.item"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.postprocessing.sem_seg_postprocess", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.get_panoptic_segmentation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.get_bounding_boxes"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n                For now, each item in the list is a dict that contains:\n                   * \"image\": Tensor, image in (C, H, W) format.\n                   * \"sem_seg\": semantic segmentation ground truth\n                   * \"center\": center points heatmap ground truth\n                   * \"offset\": pixel offsets to center points ground truth\n                   * Other information that's included in the original dicts, such as:\n                     \"height\", \"width\" (int): the output resolution of the model (may be different\n                     from input resolution), used in inference.\n        Returns:\n            list[dict]:\n                each dict is the results for one image. The dict contains the following keys:\n\n                * \"panoptic_seg\", \"sem_seg\": see documentation\n                    :doc:`/tutorials/models` for the standard output format\n                * \"instances\": available if ``predict_instances is True``. see documentation\n                    :doc:`/tutorials/models` for the standard output format\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "# To avoid error in ASPP layer when input has different size.", "\n", "size_divisibility", "=", "(", "\n", "self", ".", "size_divisibility", "\n", "if", "self", ".", "size_divisibility", ">", "0", "\n", "else", "self", ".", "backbone", ".", "size_divisibility", "\n", ")", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "size_divisibility", ")", "\n", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "if", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "targets", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "targets", "=", "ImageList", ".", "from_tensors", "(", "\n", "targets", ",", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "if", "\"sem_seg_weights\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "# The default D2 DatasetMapper may not contain \"sem_seg_weights\"", "\n", "# Avoid error in testing when default DatasetMapper is used.", "\n", "                ", "weights", "=", "[", "x", "[", "\"sem_seg_weights\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "weights", "=", "ImageList", ".", "from_tensors", "(", "weights", ",", "size_divisibility", ")", ".", "tensor", "\n", "", "else", ":", "\n", "                ", "weights", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "targets", "=", "None", "\n", "weights", "=", "None", "\n", "", "sem_seg_results", ",", "sem_seg_losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "targets", ",", "weights", ")", "\n", "losses", ".", "update", "(", "sem_seg_losses", ")", "\n", "\n", "if", "\"center\"", "in", "batched_inputs", "[", "0", "]", "and", "\"offset\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "center_targets", "=", "[", "x", "[", "\"center\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "center_targets", "=", "ImageList", ".", "from_tensors", "(", "\n", "center_targets", ",", "size_divisibility", "\n", ")", ".", "tensor", ".", "unsqueeze", "(", "1", ")", "\n", "center_weights", "=", "[", "x", "[", "\"center_weights\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "center_weights", "=", "ImageList", ".", "from_tensors", "(", "center_weights", ",", "size_divisibility", ")", ".", "tensor", "\n", "\n", "offset_targets", "=", "[", "x", "[", "\"offset\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "offset_targets", "=", "ImageList", ".", "from_tensors", "(", "offset_targets", ",", "size_divisibility", ")", ".", "tensor", "\n", "offset_weights", "=", "[", "x", "[", "\"offset_weights\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "offset_weights", "=", "ImageList", ".", "from_tensors", "(", "offset_weights", ",", "size_divisibility", ")", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "center_targets", "=", "None", "\n", "center_weights", "=", "None", "\n", "\n", "offset_targets", "=", "None", "\n", "offset_weights", "=", "None", "\n", "\n", "", "center_results", ",", "offset_results", ",", "center_losses", ",", "offset_losses", "=", "self", ".", "ins_embed_head", "(", "\n", "features", ",", "center_targets", ",", "center_weights", ",", "offset_targets", ",", "offset_weights", "\n", ")", "\n", "losses", ".", "update", "(", "center_losses", ")", "\n", "losses", ".", "update", "(", "offset_losses", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "losses", "\n", "\n", "", "if", "self", ".", "benchmark_network_speed", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "sem_seg_result", ",", "center_result", ",", "offset_result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "sem_seg_results", ",", "center_results", ",", "offset_results", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ")", "\n", "r", "=", "sem_seg_postprocess", "(", "sem_seg_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "c", "=", "sem_seg_postprocess", "(", "center_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "o", "=", "sem_seg_postprocess", "(", "offset_result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "# Post-processing to get panoptic segmentation.", "\n", "panoptic_image", ",", "_", "=", "get_panoptic_segmentation", "(", "\n", "r", ".", "argmax", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ",", "\n", "c", ",", "\n", "o", ",", "\n", "thing_ids", "=", "self", ".", "meta", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", ",", "\n", "label_divisor", "=", "self", ".", "meta", ".", "label_divisor", ",", "\n", "stuff_area", "=", "self", ".", "stuff_area", ",", "\n", "void_label", "=", "-", "1", ",", "\n", "threshold", "=", "self", ".", "threshold", ",", "\n", "nms_kernel", "=", "self", ".", "nms_kernel", ",", "\n", "top_k", "=", "self", ".", "top_k", ",", "\n", ")", "\n", "# For semantic segmentation evaluation.", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "r", "}", ")", "\n", "panoptic_image", "=", "panoptic_image", ".", "squeeze", "(", "0", ")", "\n", "semantic_prob", "=", "F", ".", "softmax", "(", "r", ",", "dim", "=", "0", ")", "\n", "# For panoptic segmentation evaluation.", "\n", "processed_results", "[", "-", "1", "]", "[", "\"panoptic_seg\"", "]", "=", "(", "panoptic_image", ",", "None", ")", "\n", "# For instance segmentation evaluation.", "\n", "if", "self", ".", "predict_instances", ":", "\n", "                ", "instances", "=", "[", "]", "\n", "panoptic_image_cpu", "=", "panoptic_image", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "panoptic_label", "in", "np", ".", "unique", "(", "panoptic_image_cpu", ")", ":", "\n", "                    ", "if", "panoptic_label", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "pred_class", "=", "panoptic_label", "//", "self", ".", "meta", ".", "label_divisor", "\n", "isthing", "=", "pred_class", "in", "list", "(", "\n", "self", ".", "meta", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", "\n", ")", "\n", "# Get instance segmentation results.", "\n", "if", "isthing", ":", "\n", "                        ", "instance", "=", "Instances", "(", "(", "height", ",", "width", ")", ")", "\n", "# Evaluation code takes continuous id starting from 0", "\n", "instance", ".", "pred_classes", "=", "torch", ".", "tensor", "(", "\n", "[", "pred_class", "]", ",", "device", "=", "panoptic_image", ".", "device", "\n", ")", "\n", "mask", "=", "panoptic_image", "==", "panoptic_label", "\n", "instance", ".", "pred_masks", "=", "mask", ".", "unsqueeze", "(", "0", ")", "\n", "# Average semantic probability", "\n", "sem_scores", "=", "semantic_prob", "[", "pred_class", ",", "...", "]", "\n", "sem_scores", "=", "torch", ".", "mean", "(", "sem_scores", "[", "mask", "]", ")", "\n", "# Center point probability", "\n", "mask_indices", "=", "torch", ".", "nonzero", "(", "mask", ")", ".", "float", "(", ")", "\n", "center_y", ",", "center_x", "=", "(", "\n", "torch", ".", "mean", "(", "mask_indices", "[", ":", ",", "0", "]", ")", ",", "\n", "torch", ".", "mean", "(", "mask_indices", "[", ":", ",", "1", "]", ")", ",", "\n", ")", "\n", "center_scores", "=", "c", "[", "0", ",", "int", "(", "center_y", ".", "item", "(", ")", ")", ",", "int", "(", "center_x", ".", "item", "(", ")", ")", "]", "\n", "# Confidence score is semantic prob * center prob.", "\n", "instance", ".", "scores", "=", "torch", ".", "tensor", "(", "\n", "[", "sem_scores", "*", "center_scores", "]", ",", "device", "=", "panoptic_image", ".", "device", "\n", ")", "\n", "# Get bounding boxes", "\n", "instance", ".", "pred_boxes", "=", "BitMasks", "(", "instance", ".", "pred_masks", ")", ".", "get_bounding_boxes", "(", ")", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "", "", "if", "len", "(", "instances", ")", ">", "0", ":", "\n", "                    ", "processed_results", "[", "-", "1", "]", "[", "\"instances\"", "]", "=", "Instances", ".", "cat", "(", "instances", ")", "\n", "\n", "", "", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabSemSegHead.__init__": [[228, 317], ["detectron2.projects.deeplab.DeepLabV3PlusHead.__init__", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "torch.nn.init.constant_", "detectron2.layers.DepthwiseSeparableConv2d", "torch.nn.Sequential", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "torch.nn.CrossEntropyLoss", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.projects.deeplab.loss.DeepLabCE", "ValueError", "detectron2.layers.get_norm", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ",", "\n", "*", ",", "\n", "decoder_channels", ":", "List", "[", "int", "]", ",", "\n", "norm", ":", "Union", "[", "str", ",", "Callable", "]", ",", "\n", "head_channels", ":", "int", ",", "\n", "loss_weight", ":", "float", ",", "\n", "loss_type", ":", "str", ",", "\n", "loss_top_k", ":", "float", ",", "\n", "ignore_value", ":", "int", ",", "\n", "num_classes", ":", "int", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature\n            decoder_channels (list[int]): a list of output channels of each\n                decoder stage. It should have the same length as \"input_shape\"\n                (each element in \"input_shape\" corresponds to one decoder stage).\n            norm (str or callable): normalization for all conv layers.\n            head_channels (int): the output channels of extra convolutions\n                between decoder and predictor.\n            loss_weight (float): loss weight.\n            loss_top_k: (float): setting the top k% hardest pixels for\n                \"hard_pixel_mining\" loss.\n            loss_type, ignore_value, num_classes: the same as the base class.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "input_shape", ",", "\n", "decoder_channels", "=", "decoder_channels", ",", "\n", "norm", "=", "norm", ",", "\n", "ignore_value", "=", "ignore_value", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "assert", "self", ".", "decoder_only", "\n", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "use_bias", "=", "norm", "==", "\"\"", "\n", "# `head` is additional transform before predictor", "\n", "if", "self", ".", "use_depthwise_separable_conv", ":", "\n", "# We use a single 5x5 DepthwiseSeparableConv2d to replace", "\n", "# 2 3x3 Conv2d since they have the same receptive field.", "\n", "            ", "self", ".", "head", "=", "DepthwiseSeparableConv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "head_channels", ",", "\n", "kernel_size", "=", "5", ",", "\n", "padding", "=", "2", ",", "\n", "norm1", "=", "norm", ",", "\n", "activation1", "=", "F", ".", "relu", ",", "\n", "norm2", "=", "norm", ",", "\n", "activation2", "=", "F", ".", "relu", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "decoder_channels", "[", "0", "]", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", ",", "\n", "Conv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "head_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "head_channels", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", ",", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "head", "[", "0", "]", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "head", "[", "1", "]", ")", "\n", "", "self", ".", "predictor", "=", "Conv2d", "(", "head_channels", ",", "num_classes", ",", "kernel_size", "=", "1", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "predictor", ".", "weight", ",", "0", ",", "0.001", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "predictor", ".", "bias", ",", "0", ")", "\n", "\n", "if", "loss_type", "==", "\"cross_entropy\"", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"mean\"", ",", "ignore_index", "=", "ignore_value", ")", "\n", "", "elif", "loss_type", "==", "\"hard_pixel_mining\"", ":", "\n", "            ", "self", ".", "loss", "=", "DeepLabCE", "(", "ignore_label", "=", "ignore_value", ",", "top_k_percent_pixels", "=", "loss_top_k", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unexpected loss type: %s\"", "%", "loss_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabSemSegHead.from_config": [[318, 324], ["super().from_config"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "from_config", "(", "cfg", ",", "input_shape", ")", "\n", "ret", "[", "\"head_channels\"", "]", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "HEAD_CHANNELS", "\n", "ret", "[", "\"loss_top_k\"", "]", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "LOSS_TOP_K", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabSemSegHead.forward": [[325, 339], ["panoptic_seg.PanopticDeepLabSemSegHead.layers", "torch.nn.functional.interpolate", "panoptic_seg.PanopticDeepLabSemSegHead.losses"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses"], ["", "def", "forward", "(", "self", ",", "features", ",", "targets", "=", "None", ",", "weights", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            In training, returns (None, dict of losses)\n            In inference, returns (CxHxW logits, {})\n        \"\"\"", "\n", "y", "=", "self", ".", "layers", "(", "features", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "None", ",", "self", ".", "losses", "(", "y", ",", "targets", ",", "weights", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "F", ".", "interpolate", "(", "\n", "y", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "return", "y", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabSemSegHead.layers": [[340, 346], ["super().layers", "panoptic_seg.PanopticDeepLabSemSegHead.head", "panoptic_seg.PanopticDeepLabSemSegHead.predictor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers"], ["", "", "def", "layers", "(", "self", ",", "features", ")", ":", "\n", "        ", "assert", "self", ".", "decoder_only", "\n", "y", "=", "super", "(", ")", ".", "layers", "(", "features", ")", "\n", "y", "=", "self", ".", "head", "(", "y", ")", "\n", "y", "=", "self", ".", "predictor", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabSemSegHead.losses": [[347, 354], ["torch.nn.functional.interpolate", "panoptic_seg.PanopticDeepLabSemSegHead.loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "losses", "(", "self", ",", "predictions", ",", "targets", ",", "weights", "=", "None", ")", ":", "\n", "        ", "predictions", "=", "F", ".", "interpolate", "(", "\n", "predictions", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "loss", "=", "self", ".", "loss", "(", "predictions", ",", "targets", ",", "weights", ")", "\n", "losses", "=", "{", "\"loss_sem_seg\"", ":", "loss", "*", "self", ".", "loss_weight", "}", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.__init__": [[370, 474], ["detectron2.projects.deeplab.DeepLabV3PlusHead.__init__", "torch.nn.Sequential", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "torch.nn.init.constant_", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.MSELoss", "torch.nn.L1Loss", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.DepthwiseSeparableConv2d", "torch.nn.Sequential", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ",", "\n", "*", ",", "\n", "decoder_channels", ":", "List", "[", "int", "]", ",", "\n", "norm", ":", "Union", "[", "str", ",", "Callable", "]", ",", "\n", "head_channels", ":", "int", ",", "\n", "center_loss_weight", ":", "float", ",", "\n", "offset_loss_weight", ":", "float", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature\n            decoder_channels (list[int]): a list of output channels of each\n                decoder stage. It should have the same length as \"input_shape\"\n                (each element in \"input_shape\" corresponds to one decoder stage).\n            norm (str or callable): normalization for all conv layers.\n            head_channels (int): the output channels of extra convolutions\n                between decoder and predictor.\n            center_loss_weight (float): loss weight for center point prediction.\n            offset_loss_weight (float): loss weight for center offset prediction.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "input_shape", ",", "decoder_channels", "=", "decoder_channels", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "\n", "assert", "self", ".", "decoder_only", "\n", "\n", "self", ".", "center_loss_weight", "=", "center_loss_weight", "\n", "self", ".", "offset_loss_weight", "=", "offset_loss_weight", "\n", "use_bias", "=", "norm", "==", "\"\"", "\n", "# center prediction", "\n", "# `head` is additional transform before predictor", "\n", "self", ".", "center_head", "=", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "decoder_channels", "[", "0", "]", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", ",", "\n", "Conv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "head_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "head_channels", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", ",", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "center_head", "[", "0", "]", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "center_head", "[", "1", "]", ")", "\n", "self", ".", "center_predictor", "=", "Conv2d", "(", "head_channels", ",", "1", ",", "kernel_size", "=", "1", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "center_predictor", ".", "weight", ",", "0", ",", "0.001", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "center_predictor", ".", "bias", ",", "0", ")", "\n", "\n", "# offset prediction", "\n", "# `head` is additional transform before predictor", "\n", "if", "self", ".", "use_depthwise_separable_conv", ":", "\n", "# We use a single 5x5 DepthwiseSeparableConv2d to replace", "\n", "# 2 3x3 Conv2d since they have the same receptive field.", "\n", "            ", "self", ".", "offset_head", "=", "DepthwiseSeparableConv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "head_channels", ",", "\n", "kernel_size", "=", "5", ",", "\n", "padding", "=", "2", ",", "\n", "norm1", "=", "norm", ",", "\n", "activation1", "=", "F", ".", "relu", ",", "\n", "norm2", "=", "norm", ",", "\n", "activation2", "=", "F", ".", "relu", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "offset_head", "=", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "decoder_channels", "[", "0", "]", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", ",", "\n", "Conv2d", "(", "\n", "decoder_channels", "[", "0", "]", ",", "\n", "head_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "head_channels", ")", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", ")", ",", "\n", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "offset_head", "[", "0", "]", ")", "\n", "weight_init", ".", "c2_xavier_fill", "(", "self", ".", "offset_head", "[", "1", "]", ")", "\n", "", "self", ".", "offset_predictor", "=", "Conv2d", "(", "head_channels", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "offset_predictor", ".", "weight", ",", "0", ",", "0.001", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "offset_predictor", ".", "bias", ",", "0", ")", "\n", "\n", "self", ".", "center_loss", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "\"none\"", ")", "\n", "self", ".", "offset_loss", "=", "nn", ".", "L1Loss", "(", "reduction", "=", "\"none\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.from_config": [[475, 502], ["dict", "len", "input_shape.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", ":", "\n", "            ", "assert", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", "==", "\"absolute\"", "\n", "train_size", "=", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", "\n", "", "else", ":", "\n", "            ", "train_size", "=", "None", "\n", "", "decoder_channels", "=", "[", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "CONVS_DIM", "]", "*", "(", "\n", "len", "(", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "IN_FEATURES", ")", "-", "1", "\n", ")", "+", "[", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "ASPP_CHANNELS", "]", "\n", "ret", "=", "dict", "(", "\n", "input_shape", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input_shape", ".", "items", "(", ")", "if", "k", "in", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "IN_FEATURES", "\n", "}", ",", "\n", "project_channels", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "PROJECT_CHANNELS", ",", "\n", "aspp_dilations", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "ASPP_DILATIONS", ",", "\n", "aspp_dropout", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "ASPP_DROPOUT", ",", "\n", "decoder_channels", "=", "decoder_channels", ",", "\n", "common_stride", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "COMMON_STRIDE", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "NORM", ",", "\n", "train_size", "=", "train_size", ",", "\n", "head_channels", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "HEAD_CHANNELS", ",", "\n", "center_loss_weight", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "CENTER_LOSS_WEIGHT", ",", "\n", "offset_loss_weight", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "OFFSET_LOSS_WEIGHT", ",", "\n", "use_depthwise_separable_conv", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "USE_DEPTHWISE_SEPARABLE_CONV", ",", "\n", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.forward": [[503, 535], ["panoptic_seg.PanopticDeepLabInsEmbedHead.layers", "torch.nn.functional.interpolate", "panoptic_seg.PanopticDeepLabInsEmbedHead.center_losses", "panoptic_seg.PanopticDeepLabInsEmbedHead.offset_losses", "torch.nn.functional.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.center_losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.offset_losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "features", ",", "\n", "center_targets", "=", "None", ",", "\n", "center_weights", "=", "None", ",", "\n", "offset_targets", "=", "None", ",", "\n", "offset_weights", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            In training, returns (None, dict of losses)\n            In inference, returns (CxHxW logits, {})\n        \"\"\"", "\n", "center", ",", "offset", "=", "self", ".", "layers", "(", "features", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "(", "\n", "None", ",", "\n", "None", ",", "\n", "self", ".", "center_losses", "(", "center", ",", "center_targets", ",", "center_weights", ")", ",", "\n", "self", ".", "offset_losses", "(", "offset", ",", "offset_targets", ",", "offset_weights", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "center", "=", "F", ".", "interpolate", "(", "\n", "center", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "offset", "=", "(", "\n", "F", ".", "interpolate", "(", "\n", "offset", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "*", "self", ".", "common_stride", "\n", ")", "\n", "return", "center", ",", "offset", ",", "{", "}", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.layers": [[536, 546], ["super().layers", "panoptic_seg.PanopticDeepLabInsEmbedHead.center_head", "panoptic_seg.PanopticDeepLabInsEmbedHead.center_predictor", "panoptic_seg.PanopticDeepLabInsEmbedHead.offset_head", "panoptic_seg.PanopticDeepLabInsEmbedHead.offset_predictor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers"], ["", "", "def", "layers", "(", "self", ",", "features", ")", ":", "\n", "        ", "assert", "self", ".", "decoder_only", "\n", "y", "=", "super", "(", ")", ".", "layers", "(", "features", ")", "\n", "# center", "\n", "center", "=", "self", ".", "center_head", "(", "y", ")", "\n", "center", "=", "self", ".", "center_predictor", "(", "center", ")", "\n", "# offset", "\n", "offset", "=", "self", ".", "offset_head", "(", "y", ")", "\n", "offset", "=", "self", ".", "offset_predictor", "(", "offset", ")", "\n", "return", "center", ",", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.center_losses": [[547, 558], ["torch.nn.functional.interpolate", "panoptic_seg.PanopticDeepLabInsEmbedHead.center_loss", "weights.sum", "loss.sum", "weights.sum", "loss.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "center_losses", "(", "self", ",", "predictions", ",", "targets", ",", "weights", ")", ":", "\n", "        ", "predictions", "=", "F", ".", "interpolate", "(", "\n", "predictions", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "loss", "=", "self", ".", "center_loss", "(", "predictions", ",", "targets", ")", "*", "weights", "\n", "if", "weights", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "/", "weights", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "*", "0", "\n", "", "losses", "=", "{", "\"loss_center\"", ":", "loss", "*", "self", ".", "center_loss_weight", "}", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.PanopticDeepLabInsEmbedHead.offset_losses": [[559, 573], ["torch.nn.functional.interpolate", "panoptic_seg.PanopticDeepLabInsEmbedHead.offset_loss", "weights.sum", "loss.sum", "weights.sum", "loss.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "offset_losses", "(", "self", ",", "predictions", ",", "targets", ",", "weights", ")", ":", "\n", "        ", "predictions", "=", "(", "\n", "F", ".", "interpolate", "(", "\n", "predictions", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "*", "self", ".", "common_stride", "\n", ")", "\n", "loss", "=", "self", ".", "offset_loss", "(", "predictions", ",", "targets", ")", "*", "weights", "\n", "if", "weights", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "/", "weights", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "*", "0", "\n", "", "losses", "=", "{", "\"loss_offset\"", ":", "loss", "*", "self", ".", "offset_loss_weight", "}", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.panoptic_seg.build_ins_embed_branch": [[356, 362], ["INS_EMBED_BRANCHES_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "build_ins_embed_branch", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a instance embedding branch from `cfg.MODEL.INS_EMBED_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "INS_EMBED_HEAD", ".", "NAME", "\n", "return", "INS_EMBED_BRANCHES_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.target_generator.PanopticDeepLabTargetGenerator.__init__": [[12, 51], ["set", "numpy.arange", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ignore_label", ",", "\n", "thing_ids", ",", "\n", "sigma", "=", "8", ",", "\n", "ignore_stuff_in_offset", "=", "False", ",", "\n", "small_instance_area", "=", "0", ",", "\n", "small_instance_weight", "=", "1", ",", "\n", "ignore_crowd_in_semantic", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            ignore_label: Integer, the ignore label for semantic segmentation.\n            thing_ids: Set, a set of ids from contiguous category ids belonging\n                to thing categories.\n            sigma: the sigma for Gaussian kernel.\n            ignore_stuff_in_offset: Boolean, whether to ignore stuff region when\n                training the offset branch.\n            small_instance_area: Integer, indicates largest area for small instances.\n            small_instance_weight: Integer, indicates semantic loss weights for\n                small instances.\n            ignore_crowd_in_semantic: Boolean, whether to ignore crowd region in\n                semantic segmentation branch, crowd region is ignored in the original\n                TensorFlow implementation.\n        \"\"\"", "\n", "self", ".", "ignore_label", "=", "ignore_label", "\n", "self", ".", "thing_ids", "=", "set", "(", "thing_ids", ")", "\n", "self", ".", "ignore_stuff_in_offset", "=", "ignore_stuff_in_offset", "\n", "self", ".", "small_instance_area", "=", "small_instance_area", "\n", "self", ".", "small_instance_weight", "=", "small_instance_weight", "\n", "self", ".", "ignore_crowd_in_semantic", "=", "ignore_crowd_in_semantic", "\n", "\n", "# Generate the default Gaussian image for each center", "\n", "self", ".", "sigma", "=", "sigma", "\n", "size", "=", "6", "*", "sigma", "+", "3", "\n", "x", "=", "np", ".", "arange", "(", "0", ",", "size", ",", "1", ",", "float", ")", "\n", "y", "=", "x", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "x0", ",", "y0", "=", "3", "*", "sigma", "+", "1", ",", "3", "*", "sigma", "+", "1", "\n", "self", ".", "g", "=", "np", ".", "exp", "(", "-", "(", "(", "x", "-", "x0", ")", "**", "2", "+", "(", "y", "-", "y0", ")", "**", "2", ")", "/", "(", "2", "*", "sigma", "**", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.target_generator.PanopticDeepLabTargetGenerator.__call__": [[52, 155], ["numpy.zeros", "numpy.zeros", "numpy.meshgrid", "numpy.ones_like", "numpy.zeros_like", "numpy.zeros_like", "dict", "numpy.zeros_like", "numpy.arange", "numpy.arange", "numpy.where", "len", "center_pts.append", "numpy.maximum", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "len", "numpy.mean", "numpy.mean", "int", "int", "int", "int", "int", "int", "max", "max", "max", "min", "max", "min", "semantic.astype", "numpy.zeros.astype", "numpy.zeros.astype", "numpy.ones_like.astype", "numpy.zeros_like.astype", "numpy.zeros_like.astype", "round", "round", "numpy.round", "numpy.round", "numpy.round", "numpy.round", "min", "min"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "panoptic", ",", "segments_info", ")", ":", "\n", "        ", "\"\"\"Generates the training target.\n        reference: https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/preparation/createPanopticImgs.py  # noqa\n        reference: https://github.com/facebookresearch/detectron2/blob/master/datasets/prepare_panoptic_fpn.py#L18  # noqa\n\n        Args:\n            panoptic: numpy.array, panoptic label, we assume it is already\n                converted from rgb image by panopticapi.utils.rgb2id.\n            segments_info (list[dict]): see detectron2 documentation of \"Use Custom Datasets\".\n\n        Returns:\n            A dictionary with fields:\n                - sem_seg: Tensor, semantic label, shape=(H, W).\n                - center: Tensor, center heatmap, shape=(H, W).\n                - center_points: List, center coordinates, with tuple\n                    (y-coord, x-coord).\n                - offset: Tensor, offset, shape=(2, H, W), first dim is\n                    (offset_y, offset_x).\n                - sem_seg_weights: Tensor, loss weight for semantic prediction,\n                    shape=(H, W).\n                - center_weights: Tensor, ignore region of center prediction,\n                    shape=(H, W), used as weights for center regression 0 is\n                    ignore, 1 is has instance. Multiply this mask to loss.\n                - offset_weights: Tensor, ignore region of offset prediction,\n                    shape=(H, W), used as weights for offset regression 0 is\n                    ignore, 1 is has instance. Multiply this mask to loss.\n        \"\"\"", "\n", "height", ",", "width", "=", "panoptic", ".", "shape", "[", "0", "]", ",", "panoptic", ".", "shape", "[", "1", "]", "\n", "semantic", "=", "np", ".", "zeros_like", "(", "panoptic", ",", "dtype", "=", "np", ".", "uint8", ")", "+", "self", ".", "ignore_label", "\n", "center", "=", "np", ".", "zeros", "(", "(", "height", ",", "width", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "center_pts", "=", "[", "]", "\n", "offset", "=", "np", ".", "zeros", "(", "(", "2", ",", "height", ",", "width", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "y_coord", ",", "x_coord", "=", "np", ".", "meshgrid", "(", "\n", "np", ".", "arange", "(", "height", ",", "dtype", "=", "np", ".", "float32", ")", ",", "np", ".", "arange", "(", "width", ",", "dtype", "=", "np", ".", "float32", ")", ",", "indexing", "=", "\"ij\"", "\n", ")", "\n", "# Generate pixel-wise loss weights", "\n", "semantic_weights", "=", "np", ".", "ones_like", "(", "panoptic", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "# 0: ignore, 1: has instance", "\n", "# three conditions for a region to be ignored for instance branches:", "\n", "# (1) It is labeled as `ignore_label`", "\n", "# (2) It is crowd region (iscrowd=1)", "\n", "# (3) (Optional) It is stuff region (for offset branch)", "\n", "center_weights", "=", "np", ".", "zeros_like", "(", "panoptic", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "offset_weights", "=", "np", ".", "zeros_like", "(", "panoptic", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "seg", "in", "segments_info", ":", "\n", "            ", "cat_id", "=", "seg", "[", "\"category_id\"", "]", "\n", "if", "not", "(", "self", ".", "ignore_crowd_in_semantic", "and", "seg", "[", "\"iscrowd\"", "]", ")", ":", "\n", "                ", "semantic", "[", "panoptic", "==", "seg", "[", "\"id\"", "]", "]", "=", "cat_id", "\n", "", "if", "not", "seg", "[", "\"iscrowd\"", "]", ":", "\n", "# Ignored regions are not in `segments_info`.", "\n", "# Handle crowd region.", "\n", "                ", "center_weights", "[", "panoptic", "==", "seg", "[", "\"id\"", "]", "]", "=", "1", "\n", "if", "not", "self", ".", "ignore_stuff_in_offset", "or", "cat_id", "in", "self", ".", "thing_ids", ":", "\n", "                    ", "offset_weights", "[", "panoptic", "==", "seg", "[", "\"id\"", "]", "]", "=", "1", "\n", "", "", "if", "cat_id", "in", "self", ".", "thing_ids", ":", "\n", "# find instance center", "\n", "                ", "mask_index", "=", "np", ".", "where", "(", "panoptic", "==", "seg", "[", "\"id\"", "]", ")", "\n", "if", "len", "(", "mask_index", "[", "0", "]", ")", "==", "0", ":", "\n", "# the instance is completely cropped", "\n", "                    ", "continue", "\n", "\n", "# Find instance area", "\n", "", "ins_area", "=", "len", "(", "mask_index", "[", "0", "]", ")", "\n", "if", "ins_area", "<", "self", ".", "small_instance_area", ":", "\n", "                    ", "semantic_weights", "[", "panoptic", "==", "seg", "[", "\"id\"", "]", "]", "=", "self", ".", "small_instance_weight", "\n", "\n", "", "center_y", ",", "center_x", "=", "np", ".", "mean", "(", "mask_index", "[", "0", "]", ")", ",", "np", ".", "mean", "(", "mask_index", "[", "1", "]", ")", "\n", "center_pts", ".", "append", "(", "[", "center_y", ",", "center_x", "]", ")", "\n", "\n", "# generate center heatmap", "\n", "y", ",", "x", "=", "int", "(", "round", "(", "center_y", ")", ")", ",", "int", "(", "round", "(", "center_x", ")", ")", "\n", "sigma", "=", "self", ".", "sigma", "\n", "# upper left", "\n", "ul", "=", "int", "(", "np", ".", "round", "(", "x", "-", "3", "*", "sigma", "-", "1", ")", ")", ",", "int", "(", "np", ".", "round", "(", "y", "-", "3", "*", "sigma", "-", "1", ")", ")", "\n", "# bottom right", "\n", "br", "=", "int", "(", "np", ".", "round", "(", "x", "+", "3", "*", "sigma", "+", "2", ")", ")", ",", "int", "(", "np", ".", "round", "(", "y", "+", "3", "*", "sigma", "+", "2", ")", ")", "\n", "\n", "# start and end indices in default Gaussian image", "\n", "gaussian_x0", ",", "gaussian_x1", "=", "max", "(", "0", ",", "-", "ul", "[", "0", "]", ")", ",", "min", "(", "br", "[", "0", "]", ",", "width", ")", "-", "ul", "[", "0", "]", "\n", "gaussian_y0", ",", "gaussian_y1", "=", "max", "(", "0", ",", "-", "ul", "[", "1", "]", ")", ",", "min", "(", "br", "[", "1", "]", ",", "height", ")", "-", "ul", "[", "1", "]", "\n", "\n", "# start and end indices in center heatmap image", "\n", "center_x0", ",", "center_x1", "=", "max", "(", "0", ",", "ul", "[", "0", "]", ")", ",", "min", "(", "br", "[", "0", "]", ",", "width", ")", "\n", "center_y0", ",", "center_y1", "=", "max", "(", "0", ",", "ul", "[", "1", "]", ")", ",", "min", "(", "br", "[", "1", "]", ",", "height", ")", "\n", "center", "[", "center_y0", ":", "center_y1", ",", "center_x0", ":", "center_x1", "]", "=", "np", ".", "maximum", "(", "\n", "center", "[", "center_y0", ":", "center_y1", ",", "center_x0", ":", "center_x1", "]", ",", "\n", "self", ".", "g", "[", "gaussian_y0", ":", "gaussian_y1", ",", "gaussian_x0", ":", "gaussian_x1", "]", ",", "\n", ")", "\n", "\n", "# generate offset (2, h, w) -> (y-dir, x-dir)", "\n", "offset", "[", "0", "]", "[", "mask_index", "]", "=", "center_y", "-", "y_coord", "[", "mask_index", "]", "\n", "offset", "[", "1", "]", "[", "mask_index", "]", "=", "center_x", "-", "x_coord", "[", "mask_index", "]", "\n", "\n", "", "", "center_weights", "=", "center_weights", "[", "None", "]", "\n", "offset_weights", "=", "offset_weights", "[", "None", "]", "\n", "return", "dict", "(", "\n", "sem_seg", "=", "torch", ".", "as_tensor", "(", "semantic", ".", "astype", "(", "\"long\"", ")", ")", ",", "\n", "center", "=", "torch", ".", "as_tensor", "(", "center", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "\n", "center_points", "=", "center_pts", ",", "\n", "offset", "=", "torch", ".", "as_tensor", "(", "offset", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "\n", "sem_seg_weights", "=", "torch", ".", "as_tensor", "(", "semantic_weights", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "\n", "center_weights", "=", "torch", ".", "as_tensor", "(", "center_weights", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "\n", "offset_weights", "=", "torch", ".", "as_tensor", "(", "offset_weights", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.find_instance_center": [[9, 42], ["torch.threshold", "torch.max_pool2d", "center_heatmap.squeeze.squeeze", "len", "torch.nonzero", "torch.nonzero", "torch.topk", "torch.topk", "torch.nonzero", "torch.nonzero", "center_heatmap.squeeze.size", "torch.flatten", "torch.flatten", "top_k_scores[].clamp_"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["def", "find_instance_center", "(", "center_heatmap", ",", "threshold", "=", "0.1", ",", "nms_kernel", "=", "3", ",", "top_k", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Find the center points from the center heatmap.\n    Args:\n        center_heatmap: A Tensor of shape [1, H, W] of raw center heatmap output.\n        threshold: A float, threshold applied to center heatmap score.\n        nms_kernel: An integer, NMS max pooling kernel size.\n        top_k: An integer, top k centers to keep.\n    Returns:\n        A Tensor of shape [K, 2] where K is the number of center points. The\n            order of second dim is (y, x).\n    \"\"\"", "\n", "# Thresholding, setting values below threshold to -1.", "\n", "center_heatmap", "=", "F", ".", "threshold", "(", "center_heatmap", ",", "threshold", ",", "-", "1", ")", "\n", "\n", "# NMS", "\n", "nms_padding", "=", "(", "nms_kernel", "-", "1", ")", "//", "2", "\n", "center_heatmap_max_pooled", "=", "F", ".", "max_pool2d", "(", "\n", "center_heatmap", ",", "kernel_size", "=", "nms_kernel", ",", "stride", "=", "1", ",", "padding", "=", "nms_padding", "\n", ")", "\n", "center_heatmap", "[", "center_heatmap", "!=", "center_heatmap_max_pooled", "]", "=", "-", "1", "\n", "\n", "# Squeeze first two dimensions.", "\n", "center_heatmap", "=", "center_heatmap", ".", "squeeze", "(", ")", "\n", "assert", "len", "(", "center_heatmap", ".", "size", "(", ")", ")", "==", "2", ",", "\"Something is wrong with center heatmap dimension.\"", "\n", "\n", "# Find non-zero elements.", "\n", "if", "top_k", "is", "None", ":", "\n", "        ", "return", "torch", ".", "nonzero", "(", "center_heatmap", ">", "0", ")", "\n", "", "else", ":", "\n", "# find top k centers.", "\n", "        ", "top_k_scores", ",", "_", "=", "torch", ".", "topk", "(", "torch", ".", "flatten", "(", "center_heatmap", ")", ",", "top_k", ")", "\n", "return", "torch", ".", "nonzero", "(", "center_heatmap", ">", "top_k_scores", "[", "-", "1", "]", ".", "clamp_", "(", "min", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.group_pixels": [[44, 77], ["torch.meshgrid", "torch.meshgrid", "torch.cat", "torch.cat", "center_loc.flatten().T.unsqueeze_.flatten().T.unsqueeze_", "center_points.unsqueeze.unsqueeze", "torch.norm", "torch.norm", "offsets.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.argmin().reshape", "torch.argmin().reshape", "y_coord.unsqueeze", "x_coord.unsqueeze", "center_loc.flatten().T.unsqueeze_.flatten", "torch.argmin", "torch.argmin"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "", "def", "group_pixels", "(", "center_points", ",", "offsets", ")", ":", "\n", "    ", "\"\"\"\n    Gives each pixel in the image an instance id.\n    Args:\n        center_points: A Tensor of shape [K, 2] where K is the number of center points.\n            The order of second dim is (y, x).\n        offsets: A Tensor of shape [2, H, W] of raw offset output. The order of\n            second dim is (offset_y, offset_x).\n    Returns:\n        A Tensor of shape [1, H, W] with values in range [1, K], which represents\n            the center this pixel belongs to.\n    \"\"\"", "\n", "height", ",", "width", "=", "offsets", ".", "size", "(", ")", "[", "1", ":", "]", "\n", "\n", "# Generates a coordinate map, where each location is the coordinate of", "\n", "# that location.", "\n", "y_coord", ",", "x_coord", "=", "torch", ".", "meshgrid", "(", "\n", "torch", ".", "arange", "(", "height", ",", "dtype", "=", "offsets", ".", "dtype", ",", "device", "=", "offsets", ".", "device", ")", ",", "\n", "torch", ".", "arange", "(", "width", ",", "dtype", "=", "offsets", ".", "dtype", ",", "device", "=", "offsets", ".", "device", ")", ",", "\n", ")", "\n", "coord", "=", "torch", ".", "cat", "(", "(", "y_coord", ".", "unsqueeze", "(", "0", ")", ",", "x_coord", ".", "unsqueeze", "(", "0", ")", ")", ",", "dim", "=", "0", ")", "\n", "\n", "center_loc", "=", "coord", "+", "offsets", "\n", "center_loc", "=", "center_loc", ".", "flatten", "(", "1", ")", ".", "T", ".", "unsqueeze_", "(", "0", ")", "# [1, H*W, 2]", "\n", "center_points", "=", "center_points", ".", "unsqueeze", "(", "1", ")", "# [K, 1, 2]", "\n", "\n", "# Distance: [K, H*W].", "\n", "distance", "=", "torch", ".", "norm", "(", "center_points", "-", "center_loc", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Finds center with minimum distance at each location, offset by 1, to", "\n", "# reserve id=0 for stuff.", "\n", "instance_id", "=", "torch", ".", "argmin", "(", "distance", ",", "dim", "=", "0", ")", ".", "reshape", "(", "(", "1", ",", "height", ",", "width", ")", ")", "+", "1", "\n", "return", "instance_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.get_instance_segmentation": [[79, 109], ["post_processing.find_instance_center", "post_processing.group_pixels", "find_instance_center.size", "find_instance_center.unsqueeze", "torch.zeros_like", "torch.zeros_like", "find_instance_center.unsqueeze"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.find_instance_center", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.group_pixels"], ["", "def", "get_instance_segmentation", "(", "\n", "sem_seg", ",", "center_heatmap", ",", "offsets", ",", "thing_seg", ",", "thing_ids", ",", "threshold", "=", "0.1", ",", "nms_kernel", "=", "3", ",", "top_k", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Post-processing for instance segmentation, gets class agnostic instance id.\n    Args:\n        sem_seg: A Tensor of shape [1, H, W], predicted semantic label.\n        center_heatmap: A Tensor of shape [1, H, W] of raw center heatmap output.\n        offsets: A Tensor of shape [2, H, W] of raw offset output. The order of\n            second dim is (offset_y, offset_x).\n        thing_seg: A Tensor of shape [1, H, W], predicted foreground mask,\n            if not provided, inference from semantic prediction.\n        thing_ids: A set of ids from contiguous category ids belonging\n            to thing categories.\n        threshold: A float, threshold applied to center heatmap score.\n        nms_kernel: An integer, NMS max pooling kernel size.\n        top_k: An integer, top k centers to keep.\n    Returns:\n        A Tensor of shape [1, H, W] with value 0 represent stuff (not instance)\n            and other positive values represent different instances.\n        A Tensor of shape [1, K, 2] where K is the number of center points.\n            The order of second dim is (y, x).\n    \"\"\"", "\n", "center_points", "=", "find_instance_center", "(", "\n", "center_heatmap", ",", "threshold", "=", "threshold", ",", "nms_kernel", "=", "nms_kernel", ",", "top_k", "=", "top_k", "\n", ")", "\n", "if", "center_points", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "return", "torch", ".", "zeros_like", "(", "sem_seg", ")", ",", "center_points", ".", "unsqueeze", "(", "0", ")", "\n", "", "ins_seg", "=", "group_pixels", "(", "center_points", ",", "offsets", ")", "\n", "return", "thing_seg", "*", "ins_seg", ",", "center_points", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.merge_semantic_and_instance": [[111, 163], ["collections.Counter", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.zeros_like", "torch.zeros_like", "torch.mode", "torch.mode", "torch.nonzero().size", "torch.nonzero().size", "sem_seg[].view", "class_id.item", "stuff_mask.sum().item", "class_id.item", "class_id.item", "torch.nonzero", "torch.nonzero", "stuff_mask.sum"], "function", ["None"], ["", "def", "merge_semantic_and_instance", "(", "\n", "sem_seg", ",", "ins_seg", ",", "semantic_thing_seg", ",", "label_divisor", ",", "thing_ids", ",", "stuff_area", ",", "void_label", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Post-processing for panoptic segmentation, by merging semantic segmentation\n        label and class agnostic instance segmentation label.\n    Args:\n        sem_seg: A Tensor of shape [1, H, W], predicted category id for each pixel.\n        ins_seg: A Tensor of shape [1, H, W], predicted instance id for each pixel.\n        semantic_thing_seg: A Tensor of shape [1, H, W], predicted foreground mask.\n        label_divisor: An integer, used to convert panoptic id =\n            semantic id * label_divisor + instance_id.\n        thing_ids: Set, a set of ids from contiguous category ids belonging\n            to thing categories.\n        stuff_area: An integer, remove stuff whose area is less tan stuff_area.\n        void_label: An integer, indicates the region has no confident prediction.\n    Returns:\n        A Tensor of shape [1, H, W].\n    \"\"\"", "\n", "# In case thing mask does not align with semantic prediction.", "\n", "pan_seg", "=", "torch", ".", "zeros_like", "(", "sem_seg", ")", "+", "void_label", "\n", "is_thing", "=", "(", "ins_seg", ">", "0", ")", "&", "(", "semantic_thing_seg", ">", "0", ")", "\n", "\n", "# Keep track of instance id for each class.", "\n", "class_id_tracker", "=", "Counter", "(", ")", "\n", "\n", "# Paste thing by majority voting.", "\n", "instance_ids", "=", "torch", ".", "unique", "(", "ins_seg", ")", "\n", "for", "ins_id", "in", "instance_ids", ":", "\n", "        ", "if", "ins_id", "==", "0", ":", "\n", "            ", "continue", "\n", "# Make sure only do majority voting within `semantic_thing_seg`.", "\n", "", "thing_mask", "=", "(", "ins_seg", "==", "ins_id", ")", "&", "is_thing", "\n", "if", "torch", ".", "nonzero", "(", "thing_mask", ")", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "class_id", ",", "_", "=", "torch", ".", "mode", "(", "sem_seg", "[", "thing_mask", "]", ".", "view", "(", "-", "1", ")", ")", "\n", "class_id_tracker", "[", "class_id", ".", "item", "(", ")", "]", "+=", "1", "\n", "new_ins_id", "=", "class_id_tracker", "[", "class_id", ".", "item", "(", ")", "]", "\n", "pan_seg", "[", "thing_mask", "]", "=", "class_id", "*", "label_divisor", "+", "new_ins_id", "\n", "\n", "# Paste stuff to unoccupied area.", "\n", "", "class_ids", "=", "torch", ".", "unique", "(", "sem_seg", ")", "\n", "for", "class_id", "in", "class_ids", ":", "\n", "        ", "if", "class_id", ".", "item", "(", ")", "in", "thing_ids", ":", "\n", "# thing class", "\n", "            ", "continue", "\n", "# Calculate stuff area.", "\n", "", "stuff_mask", "=", "(", "sem_seg", "==", "class_id", ")", "&", "(", "ins_seg", "==", "0", ")", "\n", "if", "stuff_mask", ".", "sum", "(", ")", ".", "item", "(", ")", ">=", "stuff_area", ":", "\n", "            ", "pan_seg", "[", "stuff_mask", "]", "=", "class_id", "*", "label_divisor", "\n", "\n", "", "", "return", "pan_seg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.get_panoptic_segmentation": [[165, 235], ["post_processing.get_instance_segmentation", "post_processing.merge_semantic_and_instance", "ValueError", "center_heatmap.dim", "ValueError", "offsets.dim", "ValueError", "torch.zeros_like", "torch.zeros_like", "list", "sem_seg.dim", "sem_seg.size", "ValueError", "sem_seg.size", "center_heatmap.dim", "offsets.dim", "foreground_mask.dim", "foreground_mask.size", "sem_seg.size"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.get_instance_segmentation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.post_processing.merge_semantic_and_instance", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "get_panoptic_segmentation", "(", "\n", "sem_seg", ",", "\n", "center_heatmap", ",", "\n", "offsets", ",", "\n", "thing_ids", ",", "\n", "label_divisor", ",", "\n", "stuff_area", ",", "\n", "void_label", ",", "\n", "threshold", "=", "0.1", ",", "\n", "nms_kernel", "=", "7", ",", "\n", "top_k", "=", "200", ",", "\n", "foreground_mask", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Post-processing for panoptic segmentation.\n    Args:\n        sem_seg: A Tensor of shape [1, H, W] of predicted semantic label.\n        center_heatmap: A Tensor of shape [1, H, W] of raw center heatmap output.\n        offsets: A Tensor of shape [2, H, W] of raw offset output. The order of\n            second dim is (offset_y, offset_x).\n        thing_ids: A set of ids from contiguous category ids belonging\n            to thing categories.\n        label_divisor: An integer, used to convert panoptic id =\n            semantic id * label_divisor + instance_id.\n        stuff_area: An integer, remove stuff whose area is less tan stuff_area.\n        void_label: An integer, indicates the region has no confident prediction.\n        threshold: A float, threshold applied to center heatmap score.\n        nms_kernel: An integer, NMS max pooling kernel size.\n        top_k: An integer, top k centers to keep.\n        foreground_mask: Optional, A Tensor of shape [1, H, W] of predicted\n            binary foreground mask. If not provided, it will be generated from\n            sem_seg.\n    Returns:\n        A Tensor of shape [1, H, W], int64.\n    \"\"\"", "\n", "if", "sem_seg", ".", "dim", "(", ")", "!=", "3", "and", "sem_seg", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Semantic prediction with un-supported shape: {}.\"", ".", "format", "(", "sem_seg", ".", "size", "(", ")", ")", ")", "\n", "", "if", "center_heatmap", ".", "dim", "(", ")", "!=", "3", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Center prediction with un-supported dimension: {}.\"", ".", "format", "(", "center_heatmap", ".", "dim", "(", ")", ")", "\n", ")", "\n", "", "if", "offsets", ".", "dim", "(", ")", "!=", "3", ":", "\n", "        ", "raise", "ValueError", "(", "\"Offset prediction with un-supported dimension: {}.\"", ".", "format", "(", "offsets", ".", "dim", "(", ")", ")", ")", "\n", "", "if", "foreground_mask", "is", "not", "None", ":", "\n", "        ", "if", "foreground_mask", ".", "dim", "(", ")", "!=", "3", "and", "foreground_mask", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Foreground prediction with un-supported shape: {}.\"", ".", "format", "(", "sem_seg", ".", "size", "(", ")", ")", "\n", ")", "\n", "", "thing_seg", "=", "foreground_mask", "\n", "", "else", ":", "\n", "# inference from semantic segmentation", "\n", "        ", "thing_seg", "=", "torch", ".", "zeros_like", "(", "sem_seg", ")", "\n", "for", "thing_class", "in", "list", "(", "thing_ids", ")", ":", "\n", "            ", "thing_seg", "[", "sem_seg", "==", "thing_class", "]", "=", "1", "\n", "\n", "", "", "instance", ",", "center", "=", "get_instance_segmentation", "(", "\n", "sem_seg", ",", "\n", "center_heatmap", ",", "\n", "offsets", ",", "\n", "thing_seg", ",", "\n", "thing_ids", ",", "\n", "threshold", "=", "threshold", ",", "\n", "nms_kernel", "=", "nms_kernel", ",", "\n", "top_k", "=", "top_k", ",", "\n", ")", "\n", "panoptic", "=", "merge_semantic_and_instance", "(", "\n", "sem_seg", ",", "instance", ",", "thing_seg", ",", "label_divisor", ",", "thing_ids", ",", "stuff_area", ",", "void_label", "\n", ")", "\n", "\n", "return", "panoptic", ",", "center", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.dataset_mapper.PanopticDeeplabDatasetMapper.__init__": [[28, 53], ["detectron2.data.transforms.AugmentationList", "logging.getLogger", "logging.getLogger.info", "str"], "methods", ["None"], ["\n", "\n", "@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "is_train", ":", "bool", ",", "\n", "*", ",", "\n", "augmentations", ":", "List", "[", "Union", "[", "T", ".", "Augmentation", ",", "T", ".", "Transform", "]", "]", ",", "\n", "image_format", ":", "str", ",", "\n", "use_instance_mask", ":", "bool", "=", "False", ",", "\n", "use_keypoint", ":", "bool", "=", "False", ",", "\n", "instance_mask_format", ":", "str", "=", "\"polygon\"", ",", "\n", "keypoint_hflip_indices", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "precomputed_proposal_topk", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "recompute_boxes", ":", "bool", "=", "False", ",", "\n", "aug", "=", "None", ",", "\n", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.dataset_mapper.PanopticDeeplabDatasetMapper.from_config": [[54, 86], ["augs.append", "detectron2.data.MetadataCatalog.get", "target_generator.PanopticDeepLabTargetGenerator", "detectron2.data.transforms.ResizeShortestEdge", "augs.append", "detectron2.data.transforms.RandomFlip", "detectron2.data.transforms.RandomCrop", "list", "detectron2.data.MetadataCatalog.get.thing_dataset_id_to_contiguous_id.values"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["\n", "if", "recompute_boxes", ":", "\n", "            ", "assert", "use_instance_mask", ",", "\"recompute_boxes requires instance masks\"", "\n", "# fmt: off", "\n", "", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "augmentations", "=", "T", ".", "AugmentationList", "(", "augmentations", ")", "\n", "self", ".", "image_format", "=", "image_format", "\n", "self", ".", "use_instance_mask", "=", "use_instance_mask", "\n", "self", ".", "instance_mask_format", "=", "instance_mask_format", "\n", "self", ".", "use_keypoint", "=", "use_keypoint", "\n", "self", ".", "keypoint_hflip_indices", "=", "keypoint_hflip_indices", "\n", "self", ".", "proposal_topk", "=", "precomputed_proposal_topk", "\n", "self", ".", "recompute_boxes", "=", "recompute_boxes", "\n", "self", ".", "aug", "=", "aug", "\n", "# fmt: on", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "mode", "=", "\"training\"", "if", "is_train", "else", "\"inference\"", "\n", "logger", ".", "info", "(", "f\"[DatasetMapper] Augmentations used in {mode}: {augmentations}\"", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.panoptic_deeplab.dataset_mapper.PanopticDeeplabDatasetMapper.__call__": [[87, 117], ["copy.deepcopy", "detectron2.data.detection_utils.read_image", "detectron2.data.detection_utils.check_image_size", "detectron2.data.detection_utils.read_image", "detectron2.data.transforms.AugInput", "dataset_mapper.PanopticDeeplabDatasetMapper.augmentations", "torch.as_tensor", "dataset_mapper.PanopticDeeplabDatasetMapper.panoptic_target_generator", "copy.deepcopy.update", "copy.deepcopy.pop", "numpy.ascontiguousarray", "panopticapi.utils.rgb2id", "detectron2.data.detection_utils.read_image.transpose"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.check_image_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose"], ["\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "is_train", ":", "bool", "=", "True", ")", ":", "\n", "        ", "augs", "=", "utils", ".", "build_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", "and", "is_train", ":", "\n", "            ", "augs", ".", "insert", "(", "0", ",", "T", ".", "RandomCrop", "(", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", ",", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", ")", ")", "\n", "recompute_boxes", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "", "else", ":", "\n", "            ", "recompute_boxes", "=", "False", "\n", "\n", "", "ret", "=", "{", "\n", "\"is_train\"", ":", "is_train", ",", "\n", "\"augmentations\"", ":", "augs", ",", "\n", "\"image_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"use_instance_mask\"", ":", "cfg", ".", "MODEL", ".", "MASK_ON", ",", "\n", "\"instance_mask_format\"", ":", "cfg", ".", "INPUT", ".", "MASK_FORMAT", ",", "\n", "\"use_keypoint\"", ":", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\n", "\"recompute_boxes\"", ":", "recompute_boxes", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "ret", "[", "\"keypoint_hflip_indices\"", "]", "=", "utils", ".", "create_keypoint_hflip_indices", "(", "cfg", ".", "DATASETS", ".", "TRAIN", ")", "\n", "\n", "", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", ":", "\n", "            ", "ret", "[", "\"precomputed_proposal_topk\"", "]", "=", "(", "\n", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "\n", "if", "is_train", "\n", "else", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "\n", ")", "\n", "", "ret", "[", "\"aug\"", "]", "=", "SA_Aug", "(", "cfg", ")", "if", "cfg", ".", "AUTOAUG", ".", "USE", "and", "is_train", "else", "None", "\n", "return", "ret", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TensorMask.setup.get_extensions": [[11, 59], ["os.path.dirname", "os.path.join", "os.path.join", "glob.glob", "os.path.abspath", "os.path.join", "glob.glob", "glob.glob", "os.environ.get", "os.path.join", "extension", "os.path.join", "os.path.join", "torch.cuda.is_available", "os.getenv", "extra_compile_args[].append"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["from", "torch", ".", "utils", ".", "cpp_extension", "import", "CppExtension", "\n", "from", "torch", ".", "utils", ".", "cpp_extension", "import", "CUDAExtension", "\n", "\n", "requirements", "=", "[", "\"torch\"", ",", "\"torchvision\"", "]", "\n", "\n", "\n", "def", "get_extensions", "(", ")", ":", "\n", "    ", "this_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "extensions_dir", "=", "os", ".", "path", ".", "join", "(", "this_dir", ",", "\"maskrcnn_benchmark\"", ",", "\"csrc\"", ")", "\n", "\n", "main_file", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"*.cpp\"", ")", ")", "\n", "source_cpu", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"cpu\"", ",", "\"*.cpp\"", ")", ")", "\n", "source_cuda", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "\"cuda\"", ",", "\"*.cu\"", ")", ")", "\n", "\n", "sources", "=", "main_file", "+", "source_cpu", "\n", "extension", "=", "CppExtension", "\n", "\n", "extra_compile_args", "=", "{", "\"cxx\"", ":", "[", "]", "}", "\n", "define_macros", "=", "[", "]", "\n", "\n", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "CUDA_HOME", "is", "not", "None", ")", "or", "os", ".", "getenv", "(", "\"FORCE_CUDA\"", ",", "\"0\"", ")", "==", "\"1\"", ":", "\n", "        ", "extension", "=", "CUDAExtension", "\n", "sources", "+=", "source_cuda", "\n", "define_macros", "+=", "[", "(", "\"WITH_CUDA\"", ",", "None", ")", "]", "\n", "extra_compile_args", "[", "\"nvcc\"", "]", "=", "[", "\n", "\"-DCUDA_HAS_FP16=1\"", ",", "\n", "\"-D__CUDA_NO_HALF_OPERATORS__\"", ",", "\n", "\"-D__CUDA_NO_HALF_CONVERSIONS__\"", ",", "\n", "\"-D__CUDA_NO_HALF2_OPERATORS__\"", ",", "\n", "]", "\n", "\n", "", "sources", "=", "[", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "s", ")", "for", "s", "in", "sources", "]", "\n", "\n", "include_dirs", "=", "[", "extensions_dir", "]", "\n", "\n", "ext_modules", "=", "[", "\n", "extension", "(", "\n", "\"maskrcnn_benchmark._C\"", ",", "\n", "sources", ",", "\n", "include_dirs", "=", "include_dirs", ",", "\n", "define_macros", "=", "define_macros", ",", "\n", "extra_compile_args", "=", "extra_compile_args", ",", "\n", ")", "\n", "]", "\n", "\n", "return", "ext_modules", "\n", "\n", "\n", "", "setup", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TensorMask.train_net.Trainer.build_evaluator": [[22, 27], ["detectron2.evaluation.COCOEvaluator", "os.path.join"], "methods", ["None"], ["from", "maskrcnn_benchmark", ".", "utils", ".", "collect_env", "import", "collect_env_info", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "comm", "import", "synchronize", ",", "get_rank", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "imports", "import", "import_file", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "logger", "import", "setup_logger", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "miscellaneous", "import", "mkdir", ",", "save_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TensorMask.train_net.setup": [[29, 40], ["detectron2.config.get_cfg", "tensormask.add_tensormask_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.config.add_tensormask_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["# and enable mixed-precision via apex.amp", "\n", "try", ":", "\n", "    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for multi-precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n", "    ", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TensorMask.train_net.main": [[42, 58], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.is_main_process", "detectron2.evaluation.verify_results", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.verify_results"], ["scheduler", "=", "make_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Initialize mixed-precision training", "\n", "use_mixed_precision", "=", "cfg", ".", "DTYPE", "==", "\"float16\"", "\n", "amp_opt_level", "=", "'O1'", "if", "use_mixed_precision", "else", "'O0'", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "amp_opt_level", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ",", "\n", "# this should be removed if we update BatchNorm stats", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n", "", "arguments", "=", "{", "}", "\n", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.config.add_tensormask_config": [[7, 51], ["detectron2.config.CfgNode"], "function", ["None"], ["from", "fvcore", ".", "common", ".", "config", "import", "CfgNode", "as", "_CfgNode", "\n", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    ", "\"\"\"\n    The same as `fvcore.common.config.CfgNode`, but different in:\n\n    1. Use unsafe yaml loading by default.\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    2. Support config versioning.\n       When attempting to merge an old config, it will convert the old config automatically.\n    \"\"\"", "\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n", "# Note that the default value of allow_unsafe is changed to True", "\n", "", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n", "if", "loaded_ver", "is", "None", ":", "\n", "            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n", "loaded_ver", ",", "self", ".", "VERSION", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMaskAnchorGenerator.grid_anchors_with_unit_lengths_and_indexes": [[235, 269], ["enumerate", "zip", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "anchors.append", "unit_lengths.append", "torch.full", "torch.full", "torch.full", "torch.full", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "indexes.append", "torch.full", "torch.full", "torch.full", "torch.full", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "base_anchors.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["def", "grid_anchors_with_unit_lengths_and_indexes", "(", "self", ",", "grid_sizes", ")", ":", "\n", "        ", "anchors", "=", "[", "]", "\n", "unit_lengths", "=", "[", "]", "\n", "indexes", "=", "[", "]", "\n", "for", "lvl", ",", "(", "size", ",", "stride", ",", "base_anchors", ")", "in", "enumerate", "(", "\n", "zip", "(", "grid_sizes", ",", "self", ".", "strides", ",", "self", ".", "cell_anchors", ")", "\n", ")", ":", "\n", "            ", "grid_height", ",", "grid_width", "=", "size", "\n", "device", "=", "base_anchors", ".", "device", "\n", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "grid_width", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "grid_height", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shifts", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ",", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "2", ")", "\n", "# Stack anchors in shapes of (HWA, 4)", "\n", "cur_anchor", "=", "(", "shifts", "[", ":", ",", ":", ",", "None", ",", ":", "]", "+", "base_anchors", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "4", ")", ")", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "anchors", ".", "append", "(", "cur_anchor", ")", "\n", "unit_lengths", ".", "append", "(", "\n", "torch", ".", "full", "(", "(", "cur_anchor", ".", "shape", "[", "0", "]", ",", ")", ",", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", ")", "\n", "# create mask indexes using mesh grid", "\n", "shifts_l", "=", "torch", ".", "full", "(", "(", "1", ",", ")", ",", "lvl", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "shifts_i", "=", "torch", ".", "zeros", "(", "(", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "shifts_h", "=", "torch", ".", "arange", "(", "0", ",", "grid_height", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "shifts_w", "=", "torch", ".", "arange", "(", "0", ",", "grid_width", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "shifts_a", "=", "torch", ".", "arange", "(", "0", ",", "base_anchors", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "grids", "=", "torch", ".", "meshgrid", "(", "shifts_l", ",", "shifts_i", ",", "shifts_h", ",", "shifts_w", ",", "shifts_a", ")", "\n", "\n", "indexes", ".", "append", "(", "torch", ".", "stack", "(", "grids", ",", "dim", "=", "5", ")", ".", "view", "(", "-", "1", ",", "5", ")", ")", "\n", "\n", "", "return", "anchors", ",", "unit_lengths", ",", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMaskAnchorGenerator.forward": [[270, 298], ["len", "arch.TensorMaskAnchorGenerator.grid_anchors_with_unit_lengths_and_indexes", "detectron2.structures.Boxes", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMaskAnchorGenerator.grid_anchors_with_unit_lengths_and_indexes"], ["", "def", "forward", "(", "self", ",", "features", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[list[Boxes]]: a list of #image elements. Each is a list of #feature level Boxes.\n                The Boxes contains anchors of this image on the specific feature level.\n            list[list[Tensor]]: a list of #image elements. Each is a list of #feature level tensors.\n                The tensor contains strides, or unit lengths for the anchors.\n            list[list[Tensor]]: a list of #image elements. Each is a list of #feature level tensors.\n                The Tensor contains indexes for the anchors, with the last dimension meaning\n                (L, N, H, W, A), where L is level, I is image (not set yet), H is height,\n                W is width, and A is anchor.\n        \"\"\"", "\n", "num_images", "=", "len", "(", "features", "[", "0", "]", ")", "\n", "grid_sizes", "=", "[", "feature_map", ".", "shape", "[", "-", "2", ":", "]", "for", "feature_map", "in", "features", "]", "\n", "anchors_list", ",", "lengths_list", ",", "indexes_list", "=", "self", ".", "grid_anchors_with_unit_lengths_and_indexes", "(", "\n", "grid_sizes", "\n", ")", "\n", "\n", "# Convert anchors from Tensor to Boxes", "\n", "anchors_per_im", "=", "[", "Boxes", "(", "x", ")", "for", "x", "in", "anchors_list", "]", "\n", "\n", "# TODO it can be simplified to not return duplicated information for", "\n", "# each image, just like detectron2's own AnchorGenerator", "\n", "anchors", "=", "[", "copy", ".", "deepcopy", "(", "anchors_per_im", ")", "for", "_", "in", "range", "(", "num_images", ")", "]", "\n", "unit_lengths", "=", "[", "copy", ".", "deepcopy", "(", "lengths_list", ")", "for", "_", "in", "range", "(", "num_images", ")", "]", "\n", "indexes", "=", "[", "copy", ".", "deepcopy", "(", "indexes_list", ")", "for", "_", "in", "range", "(", "num_images", ")", "]", "\n", "\n", "return", "anchors", ",", "unit_lengths", ",", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.__init__": [[308, 353], ["torch.nn.Module.__init__", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "detectron2.modeling.backbone.build_backbone", "arch.TensorMask.backbone.output_shape", "arch.TensorMaskAnchorGenerator", "arch.TensorMaskHead", "detectron2.modeling.box_regression.Box2BoxTransform", "arch.TensorMask.register_buffer", "arch.TensorMask.register_buffer", "min", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.build.build_backbone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.backbone.Backbone.output_shape"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# fmt: off", "\n", "self", ".", "num_classes", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "NUM_CLASSES", "\n", "self", ".", "in_features", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "IN_FEATURES", "\n", "self", ".", "anchor_sizes", "=", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "SIZES", "\n", "self", ".", "num_levels", "=", "len", "(", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "SIZES", ")", "\n", "# Loss parameters:", "\n", "self", ".", "focal_loss_alpha", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "FOCAL_LOSS_ALPHA", "\n", "self", ".", "focal_loss_gamma", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "FOCAL_LOSS_GAMMA", "\n", "# Inference parameters:", "\n", "self", ".", "score_threshold", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "SCORE_THRESH_TEST", "\n", "self", ".", "topk_candidates", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "TOPK_CANDIDATES_TEST", "\n", "self", ".", "nms_threshold", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "NMS_THRESH_TEST", "\n", "self", ".", "detections_im", "=", "cfg", ".", "TEST", ".", "DETECTIONS_PER_IMAGE", "\n", "# Mask parameters:", "\n", "self", ".", "mask_on", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "self", ".", "mask_loss_weight", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "MASK_LOSS_WEIGHT", "\n", "self", ".", "mask_pos_weight", "=", "torch", ".", "tensor", "(", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "POSITIVE_WEIGHT", ",", "\n", "dtype", "=", "torch", ".", "float32", ")", "\n", "self", ".", "bipyramid_on", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "BIPYRAMID_ON", "\n", "# fmt: on", "\n", "\n", "# build the backbone", "\n", "self", ".", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "\n", "backbone_shape", "=", "self", ".", "backbone", ".", "output_shape", "(", ")", "\n", "feature_shapes", "=", "[", "backbone_shape", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "feature_strides", "=", "[", "x", ".", "stride", "for", "x", "in", "feature_shapes", "]", "\n", "# build anchors", "\n", "self", ".", "anchor_generator", "=", "TensorMaskAnchorGenerator", "(", "cfg", ",", "feature_shapes", ")", "\n", "self", ".", "num_anchors", "=", "self", ".", "anchor_generator", ".", "num_cell_anchors", "[", "0", "]", "\n", "anchors_min_level", "=", "cfg", ".", "MODEL", ".", "ANCHOR_GENERATOR", ".", "SIZES", "[", "0", "]", "\n", "self", ".", "mask_sizes", "=", "[", "size", "//", "feature_strides", "[", "0", "]", "for", "size", "in", "anchors_min_level", "]", "\n", "self", ".", "min_anchor_size", "=", "min", "(", "anchors_min_level", ")", "-", "feature_strides", "[", "0", "]", "\n", "\n", "# head of the TensorMask", "\n", "self", ".", "head", "=", "TensorMaskHead", "(", "\n", "cfg", ",", "self", ".", "num_levels", ",", "self", ".", "num_anchors", ",", "self", ".", "mask_sizes", ",", "feature_shapes", "\n", ")", "\n", "# box transform", "\n", "self", ".", "box2box_transform", "=", "Box2BoxTransform", "(", "weights", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "BBOX_REG_WEIGHTS", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "cfg", ".", "MODEL", ".", "PIXEL_STD", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device": [[354, 357], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.forward": [[358, 415], ["arch.TensorMask.preprocess_image", "arch.TensorMask.backbone", "arch.TensorMask.head", "arch.TensorMask.anchor_generator", "arch.TensorMask.get_ground_truth", "arch.TensorMask.losses", "arch.TensorMask.inference", "zip", "x[].to", "input_im.get", "input_im.get", "arch._postprocess", "processed_results.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.get_ground_truth", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._postprocess"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DetectionTransform` .\n                Each item in the list contains the inputs for one image.\n            For now, each item in the list is a dict that contains:\n                image: Tensor, image in (C, H, W) format.\n                instances: Instances\n                Other information that's included in the original dicts, such as:\n                    \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                        See :meth:`postprocess` for details.\n         Returns:\n            losses (dict[str: Tensor]): mapping from a named loss to a tensor\n                storing the loss. Used during training only.\n        \"\"\"", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "# apply the TensorMask head", "\n", "pred_logits", ",", "pred_deltas", ",", "pred_masks", "=", "self", ".", "head", "(", "features", ")", "\n", "# generate anchors based on features, is it image specific?", "\n", "anchors", ",", "unit_lengths", ",", "indexes", "=", "self", ".", "anchor_generator", "(", "features", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# get ground truths for class labels and box targets, it will label each anchor", "\n", "            ", "gt_class_info", ",", "gt_delta_info", ",", "gt_mask_info", ",", "num_fg", "=", "self", ".", "get_ground_truth", "(", "\n", "anchors", ",", "unit_lengths", ",", "indexes", ",", "gt_instances", "\n", ")", "\n", "# compute the loss", "\n", "return", "self", ".", "losses", "(", "\n", "gt_class_info", ",", "\n", "gt_delta_info", ",", "\n", "gt_mask_info", ",", "\n", "num_fg", ",", "\n", "pred_logits", ",", "\n", "pred_deltas", ",", "\n", "pred_masks", ",", "\n", ")", "\n", "", "else", ":", "\n", "# do inference to get the output", "\n", "            ", "results", "=", "self", ".", "inference", "(", "pred_logits", ",", "pred_deltas", ",", "pred_masks", ",", "anchors", ",", "indexes", ",", "images", ")", "\n", "processed_results", "=", "[", "]", "\n", "for", "results_im", ",", "input_im", ",", "image_size", "in", "zip", "(", "\n", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", ":", "\n", "                ", "height", "=", "input_im", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_im", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "# this is to do post-processing with the image size", "\n", "result_box", ",", "result_mask", "=", "results_im", "\n", "r", "=", "_postprocess", "(", "result_box", ",", "result_mask", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.losses": [[416, 501], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "arch.permute_all_cls_and_box_to_N_HWA_K_and_concat", "max", "fvcore.nn.sigmoid_focal_loss_star_jit", "range", "pred_deltas.sum", "fvcore.nn.smooth_l1_loss", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "cur_pred_masks.view", "[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.permute_all_cls_and_box_to_N_HWA_K_and_concat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "", "def", "losses", "(", "\n", "self", ",", "\n", "gt_class_info", ",", "\n", "gt_delta_info", ",", "\n", "gt_mask_info", ",", "\n", "num_fg", ",", "\n", "pred_logits", ",", "\n", "pred_deltas", ",", "\n", "pred_masks", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            For `gt_class_info`, `gt_delta_info`, `gt_mask_info` and `num_fg` parameters, see\n                :meth:`TensorMask.get_ground_truth`.\n            For `pred_logits`, `pred_deltas` and `pred_masks`, see\n                :meth:`TensorMaskHead.forward`.\n\n        Returns:\n            losses (dict[str: Tensor]): mapping from a named loss to a scalar tensor\n                storing the loss. Used during training only. The potential dict keys are:\n                \"loss_cls\", \"loss_box_reg\" and \"loss_mask\".\n        \"\"\"", "\n", "gt_classes_target", ",", "gt_valid_inds", "=", "gt_class_info", "\n", "gt_deltas", ",", "gt_fg_inds", "=", "gt_delta_info", "\n", "gt_masks", ",", "gt_mask_inds", "=", "gt_mask_info", "\n", "loss_normalizer", "=", "torch", ".", "tensor", "(", "max", "(", "1", ",", "num_fg", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# classification and regression", "\n", "pred_logits", ",", "pred_deltas", "=", "permute_all_cls_and_box_to_N_HWA_K_and_concat", "(", "\n", "pred_logits", ",", "pred_deltas", ",", "self", ".", "num_classes", "\n", ")", "\n", "loss_cls", "=", "(", "\n", "sigmoid_focal_loss_star_jit", "(", "\n", "pred_logits", "[", "gt_valid_inds", "]", ",", "\n", "gt_classes_target", "[", "gt_valid_inds", "]", ",", "\n", "alpha", "=", "self", ".", "focal_loss_alpha", ",", "\n", "gamma", "=", "self", ".", "focal_loss_gamma", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "/", "loss_normalizer", "\n", ")", "\n", "\n", "if", "num_fg", "==", "0", ":", "\n", "            ", "loss_box_reg", "=", "pred_deltas", ".", "sum", "(", ")", "*", "0", "\n", "", "else", ":", "\n", "            ", "loss_box_reg", "=", "(", "\n", "smooth_l1_loss", "(", "pred_deltas", "[", "gt_fg_inds", "]", ",", "gt_deltas", ",", "beta", "=", "0.0", ",", "reduction", "=", "\"sum\"", ")", "\n", "/", "loss_normalizer", "\n", ")", "\n", "", "losses", "=", "{", "\"loss_cls\"", ":", "loss_cls", ",", "\"loss_box_reg\"", ":", "loss_box_reg", "}", "\n", "\n", "# mask prediction", "\n", "if", "self", ".", "mask_on", ":", "\n", "            ", "loss_mask", "=", "0", "\n", "for", "lvl", "in", "range", "(", "self", ".", "num_levels", ")", ":", "\n", "                ", "cur_level_factor", "=", "2", "**", "lvl", "if", "self", ".", "bipyramid_on", "else", "1", "\n", "for", "anc", "in", "range", "(", "self", ".", "num_anchors", ")", ":", "\n", "                    ", "cur_gt_mask_inds", "=", "gt_mask_inds", "[", "lvl", "]", "[", "anc", "]", "\n", "if", "cur_gt_mask_inds", "is", "None", ":", "\n", "                        ", "loss_mask", "+=", "pred_masks", "[", "lvl", "]", "[", "anc", "]", "[", "0", ",", "0", ",", "0", ",", "0", "]", "*", "0", "\n", "", "else", ":", "\n", "                        ", "cur_mask_size", "=", "self", ".", "mask_sizes", "[", "anc", "]", "*", "cur_level_factor", "\n", "# TODO maybe there are numerical issues when mask sizes are large", "\n", "cur_size_divider", "=", "torch", ".", "tensor", "(", "\n", "self", ".", "mask_loss_weight", "/", "(", "cur_mask_size", "**", "2", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", ")", "\n", "\n", "cur_pred_masks", "=", "pred_masks", "[", "lvl", "]", "[", "anc", "]", "[", "\n", "cur_gt_mask_inds", "[", ":", ",", "0", "]", ",", "# N", "\n", ":", ",", "# V x U", "\n", "cur_gt_mask_inds", "[", ":", ",", "1", "]", ",", "# H", "\n", "cur_gt_mask_inds", "[", ":", ",", "2", "]", ",", "# W", "\n", "]", "\n", "\n", "loss_mask", "+=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "cur_pred_masks", ".", "view", "(", "-", "1", ",", "cur_mask_size", ",", "cur_mask_size", ")", ",", "# V, U", "\n", "gt_masks", "[", "lvl", "]", "[", "anc", "]", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "weight", "=", "cur_size_divider", ",", "\n", "pos_weight", "=", "self", ".", "mask_pos_weight", ",", "\n", ")", "\n", "", "", "", "losses", "[", "\"loss_mask\"", "]", "=", "loss_mask", "/", "loss_normalizer", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.get_ground_truth": [[502, 631], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "detectron2.layers.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "detectron2.structures.Boxes.cat", "detectron2.layers.cat", "detectron2.layers.cat", "zip", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "detectron2.layers.cat.append", "detectron2.layers.cat", "range", "range", "len", "arch._assignment_rule", "len", "arch.TensorMask.box2box_transform.get_deltas", "gt_deltas.append", "range", "range", "range", "detectron2.layers.cat", "detectron2.layers.cat", "torch.any", "torch.any", "torch.any", "torch.any", "range", "torch.any", "torch.any", "torch.any", "torch.any", "[].append", "[].append", "targets_im[].gt_masks.crop_and_resize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._assignment_rule", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.get_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.crop_and_resize"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "get_ground_truth", "(", "self", ",", "anchors", ",", "unit_lengths", ",", "indexes", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            anchors (list[list[Boxes]]): a list of N=#image elements. Each is a\n                list of #feature level Boxes. The Boxes contains anchors of\n                this image on the specific feature level.\n            unit_lengths (list[list[Tensor]]): a list of N=#image elements. Each is a\n                list of #feature level Tensor. The tensor contains unit lengths for anchors of\n                this image on the specific feature level.\n            indexes (list[list[Tensor]]): a list of N=#image elements. Each is a\n                list of #feature level Tensor. The tensor contains the 5D index of\n                each anchor, the second dimension means (L, N, H, W, A), where L\n                is level, I is image, H is height, W is width, and A is anchor.\n            targets (list[Instances]): a list of N `Instances`s. The i-th\n                `Instances` contains the ground-truth per-instance annotations\n                for the i-th input image.  Specify `targets` during training only.\n\n        Returns:\n            gt_class_info (Tensor, Tensor): A pair of two tensors for classification.\n                The first one is an integer tensor of shape (R, #classes) storing ground-truth\n                labels for each anchor. R is the total number of anchors in the batch.\n                The second one is an integer tensor of shape (R,), to indicate which\n                anchors are valid for loss computation, which anchors are not.\n            gt_delta_info (Tensor, Tensor): A pair of two tensors for boxes.\n                The first one, of shape (F, 4). F=#foreground anchors.\n                The last dimension represents ground-truth box2box transform\n                targets (dx, dy, dw, dh) that map each anchor to its matched ground-truth box.\n                Only foreground anchors have values in this tensor. Could be `None` if F=0.\n                The second one, of shape (R,), is an integer tensor indicating which anchors\n                are foreground ones used for box regression. Could be `None` if F=0.\n            gt_mask_info (list[list[Tensor]], list[list[Tensor]]): A pair of two lists for masks.\n                The first one is a list of P=#feature level elements. Each is a\n                list of A=#anchor tensors. Each tensor contains the ground truth\n                masks of the same size and for the same feature level. Could be `None`.\n                The second one is a list of P=#feature level elements. Each is a\n                list of A=#anchor tensors. Each tensor contains the location of the ground truth\n                masks of the same size and for the same feature level. The second dimension means\n                (N, H, W), where N is image, H is height, and W is width. Could be `None`.\n            num_fg (int): F=#foreground anchors, used later for loss normalization.\n        \"\"\"", "\n", "gt_classes", "=", "[", "]", "\n", "gt_deltas", "=", "[", "]", "\n", "gt_masks", "=", "[", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_anchors", ")", "]", "for", "_", "in", "range", "(", "self", ".", "num_levels", ")", "]", "\n", "gt_mask_inds", "=", "[", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_anchors", ")", "]", "for", "_", "in", "range", "(", "self", ".", "num_levels", ")", "]", "\n", "\n", "anchors", "=", "[", "Boxes", ".", "cat", "(", "anchors_i", ")", "for", "anchors_i", "in", "anchors", "]", "\n", "unit_lengths", "=", "[", "cat", "(", "unit_lengths_i", ")", "for", "unit_lengths_i", "in", "unit_lengths", "]", "\n", "indexes", "=", "[", "cat", "(", "indexes_i", ")", "for", "indexes_i", "in", "indexes", "]", "\n", "\n", "num_fg", "=", "0", "\n", "for", "i", ",", "(", "anchors_im", ",", "unit_lengths_im", ",", "indexes_im", ",", "targets_im", ")", "in", "enumerate", "(", "\n", "zip", "(", "anchors", ",", "unit_lengths", ",", "indexes", ",", "targets", ")", "\n", ")", ":", "\n", "# Initialize all", "\n", "            ", "gt_classes_i", "=", "torch", ".", "full_like", "(", "\n", "unit_lengths_im", ",", "self", ".", "num_classes", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", "# Ground truth classes", "\n", "has_gt", "=", "len", "(", "targets_im", ")", ">", "0", "\n", "if", "has_gt", ":", "\n", "# Compute the pairwise matrix", "\n", "                ", "gt_matched_inds", ",", "anchor_labels", "=", "_assignment_rule", "(", "\n", "targets_im", ".", "gt_boxes", ",", "anchors_im", ",", "unit_lengths_im", ",", "self", ".", "min_anchor_size", "\n", ")", "\n", "# Find the foreground instances", "\n", "fg_inds", "=", "anchor_labels", "==", "1", "\n", "fg_anchors", "=", "anchors_im", "[", "fg_inds", "]", "\n", "num_fg", "+=", "len", "(", "fg_anchors", ")", "\n", "# Find the ground truths for foreground instances", "\n", "gt_fg_matched_inds", "=", "gt_matched_inds", "[", "fg_inds", "]", "\n", "# Assign labels for foreground instances", "\n", "gt_classes_i", "[", "fg_inds", "]", "=", "targets_im", ".", "gt_classes", "[", "gt_fg_matched_inds", "]", "\n", "# Anchors with label -1 are ignored, others are left as negative", "\n", "gt_classes_i", "[", "anchor_labels", "==", "-", "1", "]", "=", "-", "1", "\n", "\n", "# Boxes", "\n", "# Ground truth box regression, only for foregrounds", "\n", "matched_gt_boxes", "=", "targets_im", "[", "gt_fg_matched_inds", "]", ".", "gt_boxes", "\n", "# Compute box regression offsets for foregrounds only", "\n", "gt_deltas_i", "=", "self", ".", "box2box_transform", ".", "get_deltas", "(", "\n", "fg_anchors", ".", "tensor", ",", "matched_gt_boxes", ".", "tensor", "\n", ")", "\n", "gt_deltas", ".", "append", "(", "gt_deltas_i", ")", "\n", "\n", "# Masks", "\n", "if", "self", ".", "mask_on", ":", "\n", "# Compute masks for each level and each anchor", "\n", "                    ", "matched_indexes", "=", "indexes_im", "[", "fg_inds", ",", ":", "]", "\n", "for", "lvl", "in", "range", "(", "self", ".", "num_levels", ")", ":", "\n", "                        ", "ids_lvl", "=", "matched_indexes", "[", ":", ",", "0", "]", "==", "lvl", "\n", "if", "torch", ".", "any", "(", "ids_lvl", ")", ":", "\n", "                            ", "cur_level_factor", "=", "2", "**", "lvl", "if", "self", ".", "bipyramid_on", "else", "1", "\n", "for", "anc", "in", "range", "(", "self", ".", "num_anchors", ")", ":", "\n", "                                ", "ids_lvl_anchor", "=", "ids_lvl", "&", "(", "matched_indexes", "[", ":", ",", "4", "]", "==", "anc", ")", "\n", "if", "torch", ".", "any", "(", "ids_lvl_anchor", ")", ":", "\n", "                                    ", "gt_masks", "[", "lvl", "]", "[", "anc", "]", ".", "append", "(", "\n", "targets_im", "[", "\n", "gt_fg_matched_inds", "[", "ids_lvl_anchor", "]", "\n", "]", ".", "gt_masks", ".", "crop_and_resize", "(", "\n", "fg_anchors", "[", "ids_lvl_anchor", "]", ".", "tensor", ",", "\n", "self", ".", "mask_sizes", "[", "anc", "]", "*", "cur_level_factor", ",", "\n", ")", "\n", ")", "\n", "# Select (N, H, W) dimensions", "\n", "gt_mask_inds_lvl_anc", "=", "matched_indexes", "[", "ids_lvl_anchor", ",", "1", ":", "4", "]", "\n", "# Set the image index to the current image", "\n", "gt_mask_inds_lvl_anc", "[", ":", ",", "0", "]", "=", "i", "\n", "gt_mask_inds", "[", "lvl", "]", "[", "anc", "]", ".", "append", "(", "gt_mask_inds_lvl_anc", ")", "\n", "", "", "", "", "", "", "gt_classes", ".", "append", "(", "gt_classes_i", ")", "\n", "\n", "# Classes and boxes", "\n", "", "gt_classes", "=", "cat", "(", "gt_classes", ")", "\n", "gt_valid_inds", "=", "gt_classes", ">=", "0", "\n", "gt_fg_inds", "=", "gt_valid_inds", "&", "(", "gt_classes", "<", "self", ".", "num_classes", ")", "\n", "gt_classes_target", "=", "torch", ".", "zeros", "(", "\n", "(", "gt_classes", ".", "shape", "[", "0", "]", ",", "self", ".", "num_classes", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", "gt_classes_target", "[", "gt_fg_inds", ",", "gt_classes", "[", "gt_fg_inds", "]", "]", "=", "1", "\n", "gt_deltas", "=", "cat", "(", "gt_deltas", ")", "if", "gt_deltas", "else", "None", "\n", "\n", "# Masks", "\n", "gt_masks", "=", "[", "[", "cat", "(", "mla", ")", "if", "mla", "else", "None", "for", "mla", "in", "ml", "]", "for", "ml", "in", "gt_masks", "]", "\n", "gt_mask_inds", "=", "[", "[", "cat", "(", "ila", ")", "if", "ila", "else", "None", "for", "ila", "in", "il", "]", "for", "il", "in", "gt_mask_inds", "]", "\n", "return", "(", "\n", "(", "gt_classes_target", ",", "gt_valid_inds", ")", ",", "\n", "(", "gt_deltas", ",", "gt_fg_inds", ")", ",", "\n", "(", "gt_masks", ",", "gt_mask_inds", ")", ",", "\n", "num_fg", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference": [[633, 674], ["detectron2.layers.cat", "detectron2.layers.cat", "enumerate", "len", "len", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "zip", "arch.TensorMask.inference_single_image", "results.append", "detectron2.structures.Boxes.cat", "detectron2.layers.cat", "tuple"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference_single_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "inference", "(", "self", ",", "pred_logits", ",", "pred_deltas", ",", "pred_masks", ",", "anchors", ",", "indexes", ",", "images", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            pred_logits, pred_deltas, pred_masks: Same as the output of:\n                meth:`TensorMaskHead.forward`\n            anchors, indexes: Same as the input of meth:`TensorMask.get_ground_truth`\n            images (ImageList): the input images\n\n        Returns:\n            results (List[Instances]): a list of #images elements.\n        \"\"\"", "\n", "assert", "len", "(", "anchors", ")", "==", "len", "(", "images", ")", "\n", "results", "=", "[", "]", "\n", "\n", "pred_logits", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "self", ".", "num_classes", ")", "for", "x", "in", "pred_logits", "]", "\n", "pred_deltas", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "4", ")", "for", "x", "in", "pred_deltas", "]", "\n", "\n", "pred_logits", "=", "cat", "(", "pred_logits", ",", "dim", "=", "1", ")", "\n", "pred_deltas", "=", "cat", "(", "pred_deltas", ",", "dim", "=", "1", ")", "\n", "\n", "for", "img_idx", ",", "(", "anchors_im", ",", "indexes_im", ")", "in", "enumerate", "(", "zip", "(", "anchors", ",", "indexes", ")", ")", ":", "\n", "# Get the size of the current image", "\n", "            ", "image_size", "=", "images", ".", "image_sizes", "[", "img_idx", "]", "\n", "\n", "logits_im", "=", "pred_logits", "[", "img_idx", "]", "\n", "deltas_im", "=", "pred_deltas", "[", "img_idx", "]", "\n", "\n", "if", "self", ".", "mask_on", ":", "\n", "                ", "masks_im", "=", "[", "[", "mla", "[", "img_idx", "]", "for", "mla", "in", "ml", "]", "for", "ml", "in", "pred_masks", "]", "\n", "", "else", ":", "\n", "                ", "masks_im", "=", "[", "None", "]", "*", "self", ".", "num_levels", "\n", "", "results_im", "=", "self", ".", "inference_single_image", "(", "\n", "logits_im", ",", "\n", "deltas_im", ",", "\n", "masks_im", ",", "\n", "Boxes", ".", "cat", "(", "anchors_im", ")", ",", "\n", "cat", "(", "indexes_im", ")", ",", "\n", "tuple", "(", "image_size", ")", ",", "\n", ")", "\n", "results", ".", "append", "(", "results_im", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.inference_single_image": [[675, 743], ["pred_logits.flatten().sigmoid_.flatten().sigmoid_.flatten().sigmoid_", "min", "pred_logits[].sort", "arch.TensorMask.box2box_transform.apply_deltas", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.where", "torch.where", "torch.where", "torch.where", "result_indexes.tolist", "pred_logits.flatten().sigmoid_.flatten().sigmoid_.flatten", "result_masks.append", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "[].view"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.box_regression.Box2BoxTransformRotated.apply_deltas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], ["", "def", "inference_single_image", "(", "\n", "self", ",", "pred_logits", ",", "pred_deltas", ",", "pred_masks", ",", "anchors", ",", "indexes", ",", "image_size", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Single-image inference. Return bounding-box detection results by thresholding\n        on scores and applying non-maximum suppression (NMS).\n\n        Arguments:\n            pred_logits (list[Tensor]): list of #feature levels. Each entry contains\n                tensor of size (AxHxW, K)\n            pred_deltas (list[Tensor]): Same shape as 'pred_logits' except that K becomes 4.\n            pred_masks (list[list[Tensor]]): List of #feature levels, each is a list of #anchors.\n                Each entry contains tensor of size (M_i*M_i, H, W). `None` if mask_on=False.\n            anchors (list[Boxes]): list of #feature levels. Each entry contains\n                a Boxes object, which contains all the anchors for that\n                image in that feature level.\n            image_size (tuple(H, W)): a tuple of the image height and width.\n\n        Returns:\n            Same as `inference`, but for only one image.\n        \"\"\"", "\n", "pred_logits", "=", "pred_logits", ".", "flatten", "(", ")", ".", "sigmoid_", "(", ")", "\n", "# We get top locations across all levels to accelerate the inference speed,", "\n", "# which does not seem to affect the accuracy.", "\n", "# First select values above the threshold", "\n", "logits_top_idxs", "=", "torch", ".", "where", "(", "pred_logits", ">", "self", ".", "score_threshold", ")", "[", "0", "]", "\n", "# Then get the top values", "\n", "num_topk", "=", "min", "(", "self", ".", "topk_candidates", ",", "logits_top_idxs", ".", "shape", "[", "0", "]", ")", "\n", "pred_prob", ",", "topk_idxs", "=", "pred_logits", "[", "logits_top_idxs", "]", ".", "sort", "(", "descending", "=", "True", ")", "\n", "# Keep top k scoring values", "\n", "pred_prob", "=", "pred_prob", "[", ":", "num_topk", "]", "\n", "# Keep top k values", "\n", "top_idxs", "=", "logits_top_idxs", "[", "topk_idxs", "[", ":", "num_topk", "]", "]", "\n", "\n", "# class index", "\n", "cls_idxs", "=", "top_idxs", "%", "self", ".", "num_classes", "\n", "# HWA index", "\n", "top_idxs", "//=", "self", ".", "num_classes", "\n", "# predict boxes", "\n", "pred_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "pred_deltas", "[", "top_idxs", "]", ",", "anchors", "[", "top_idxs", "]", ".", "tensor", "\n", ")", "\n", "# apply nms", "\n", "keep", "=", "batched_nms", "(", "pred_boxes", ",", "pred_prob", ",", "cls_idxs", ",", "self", ".", "nms_threshold", ")", "\n", "# pick the top ones", "\n", "keep", "=", "keep", "[", ":", "self", ".", "detections_im", "]", "\n", "\n", "results", "=", "Instances", "(", "image_size", ")", "\n", "results", ".", "pred_boxes", "=", "Boxes", "(", "pred_boxes", "[", "keep", "]", ")", "\n", "results", ".", "scores", "=", "pred_prob", "[", "keep", "]", "\n", "results", ".", "pred_classes", "=", "cls_idxs", "[", "keep", "]", "\n", "\n", "# deal with masks", "\n", "result_masks", ",", "result_anchors", "=", "[", "]", ",", "None", "\n", "if", "self", ".", "mask_on", ":", "\n", "# index and anchors, useful for masks", "\n", "            ", "top_indexes", "=", "indexes", "[", "top_idxs", "]", "\n", "top_anchors", "=", "anchors", "[", "top_idxs", "]", "\n", "result_indexes", "=", "top_indexes", "[", "keep", "]", "\n", "result_anchors", "=", "top_anchors", "[", "keep", "]", "\n", "# Get masks and do sigmoid", "\n", "for", "lvl", ",", "_", ",", "h", ",", "w", ",", "anc", "in", "result_indexes", ".", "tolist", "(", ")", ":", "\n", "                ", "cur_size", "=", "self", ".", "mask_sizes", "[", "anc", "]", "*", "(", "2", "**", "lvl", "if", "self", ".", "bipyramid_on", "else", "1", ")", "\n", "result_masks", ".", "append", "(", "\n", "torch", ".", "sigmoid", "(", "pred_masks", "[", "lvl", "]", "[", "anc", "]", "[", ":", ",", "h", ",", "w", "]", ".", "view", "(", "1", ",", "cur_size", ",", "cur_size", ")", ")", "\n", ")", "\n", "\n", "", "", "return", "results", ",", "(", "result_masks", ",", "result_anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.preprocess_image": [[744, 752], ["detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.image_list.ImageList.from_tensors", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "preprocess_image", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Normalize, pad and batch the input images.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMaskHead.__init__": [[755, 856], ["torch.nn.Module.__init__", "range", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "range", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "modules_list.extend", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "cls_subnet.append", "cls_subnet.append", "bbox_subnet.append", "bbox_subnet.append", "range", "torch.nn.Sequential", "torch.nn.Sequential", "modules_list.append", "modules.modules", "math.log", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "mask_subnet.append", "mask_subnet.append", "arch.TensorMaskHead.add_module", "modules_list.append", "isinstance", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "getattr", "range", "torch.nn.Sequential", "torch.nn.Sequential", "modules_list.append", "tensormask.layers.SwapAlign2Nat", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "setattr", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "tensormask.layers.SwapAlign2Nat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "num_levels", ",", "num_anchors", ",", "mask_sizes", ",", "input_shape", ":", "List", "[", "ShapeSpec", "]", ")", ":", "\n", "        ", "\"\"\"\n        TensorMask head.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# fmt: off", "\n", "self", ".", "in_features", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "IN_FEATURES", "\n", "in_channels", "=", "input_shape", "[", "0", "]", ".", "channels", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "NUM_CLASSES", "\n", "cls_channels", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "CLS_CHANNELS", "\n", "num_convs", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "NUM_CONVS", "\n", "# box parameters", "\n", "bbox_channels", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "BBOX_CHANNELS", "\n", "# mask parameters", "\n", "self", ".", "mask_on", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "self", ".", "mask_sizes", "=", "mask_sizes", "\n", "mask_channels", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "MASK_CHANNELS", "\n", "self", ".", "align_on", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "ALIGNED_ON", "\n", "self", ".", "bipyramid_on", "=", "cfg", ".", "MODEL", ".", "TENSOR_MASK", ".", "BIPYRAMID_ON", "\n", "# fmt: on", "\n", "\n", "# class subnet", "\n", "cls_subnet", "=", "[", "]", "\n", "cur_channels", "=", "in_channels", "\n", "for", "_", "in", "range", "(", "num_convs", ")", ":", "\n", "            ", "cls_subnet", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "cur_channels", ",", "cls_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "cur_channels", "=", "cls_channels", "\n", "cls_subnet", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "cls_subnet", "=", "nn", ".", "Sequential", "(", "*", "cls_subnet", ")", "\n", "self", ".", "cls_score", "=", "nn", ".", "Conv2d", "(", "\n", "cur_channels", ",", "num_anchors", "*", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "modules_list", "=", "[", "self", ".", "cls_subnet", ",", "self", ".", "cls_score", "]", "\n", "\n", "# box subnet", "\n", "bbox_subnet", "=", "[", "]", "\n", "cur_channels", "=", "in_channels", "\n", "for", "_", "in", "range", "(", "num_convs", ")", ":", "\n", "            ", "bbox_subnet", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "cur_channels", ",", "bbox_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "cur_channels", "=", "bbox_channels", "\n", "bbox_subnet", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "bbox_subnet", "=", "nn", ".", "Sequential", "(", "*", "bbox_subnet", ")", "\n", "self", ".", "bbox_pred", "=", "nn", ".", "Conv2d", "(", "\n", "cur_channels", ",", "num_anchors", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "modules_list", ".", "extend", "(", "[", "self", ".", "bbox_subnet", ",", "self", ".", "bbox_pred", "]", ")", "\n", "\n", "# mask subnet", "\n", "if", "self", ".", "mask_on", ":", "\n", "            ", "mask_subnet", "=", "[", "]", "\n", "cur_channels", "=", "in_channels", "\n", "for", "_", "in", "range", "(", "num_convs", ")", ":", "\n", "                ", "mask_subnet", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "cur_channels", ",", "mask_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "cur_channels", "=", "mask_channels", "\n", "mask_subnet", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "mask_subnet", "=", "nn", ".", "Sequential", "(", "*", "mask_subnet", ")", "\n", "modules_list", ".", "append", "(", "self", ".", "mask_subnet", ")", "\n", "for", "mask_size", "in", "self", ".", "mask_sizes", ":", "\n", "                ", "cur_mask_module", "=", "\"mask_pred_%02d\"", "%", "mask_size", "\n", "self", ".", "add_module", "(", "\n", "cur_mask_module", ",", "\n", "nn", ".", "Conv2d", "(", "\n", "cur_channels", ",", "mask_size", "*", "mask_size", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", "\n", ")", ",", "\n", ")", "\n", "modules_list", ".", "append", "(", "getattr", "(", "self", ",", "cur_mask_module", ")", ")", "\n", "", "if", "self", ".", "align_on", ":", "\n", "                ", "if", "self", ".", "bipyramid_on", ":", "\n", "                    ", "for", "lvl", "in", "range", "(", "num_levels", ")", ":", "\n", "                        ", "cur_mask_module", "=", "\"align2nat_%02d\"", "%", "lvl", "\n", "lambda_val", "=", "2", "**", "lvl", "\n", "setattr", "(", "self", ",", "cur_mask_module", ",", "SwapAlign2Nat", "(", "lambda_val", ")", ")", "\n", "# Also the fusing layer, stay at the same channel size", "\n", "", "mask_fuse", "=", "[", "\n", "nn", ".", "Conv2d", "(", "cur_channels", ",", "cur_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "]", "\n", "self", ".", "mask_fuse", "=", "nn", ".", "Sequential", "(", "*", "mask_fuse", ")", "\n", "modules_list", ".", "append", "(", "self", ".", "mask_fuse", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "align2nat", "=", "SwapAlign2Nat", "(", "1", ")", "\n", "\n", "# Initialization", "\n", "", "", "", "for", "modules", "in", "modules_list", ":", "\n", "            ", "for", "layer", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "layer", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "layer", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", ",", "0", ")", "\n", "\n", "# Use prior in model initialization to improve stability", "\n", "", "", "", "bias_value", "=", "-", "(", "math", ".", "log", "(", "(", "1", "-", "0.01", ")", "/", "0.01", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_score", ".", "bias", ",", "bias_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMaskHead.forward": [[857, 914], ["arch.TensorMaskHead.cls_score", "arch.TensorMaskHead.bbox_pred", "enumerate", "arch.TensorMaskHead.cls_subnet", "arch.TensorMaskHead.bbox_subnet", "arch.TensorMaskHead.mask_subnet", "enumerate", "pred_masks.append", "mask_feats_up.append", "getattr", "getattr.", "cur_masks.append", "torch.interpolate", "torch.interpolate", "arch.TensorMaskHead.mask_fuse", "getattr", "getattr.", "arch.TensorMaskHead.align2nat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "forward", "(", "self", ",", "features", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            features (list[Tensor]): FPN feature map tensors in high to low resolution.\n                Each tensor in the list correspond to different feature levels.\n\n        Returns:\n            pred_logits (list[Tensor]): #lvl tensors, each has shape (N, AxK, Hi, Wi).\n                The tensor predicts the classification probability\n                at each spatial position for each of the A anchors and K object\n                classes.\n            pred_deltas (list[Tensor]): #lvl tensors, each has shape (N, Ax4, Hi, Wi).\n                The tensor predicts 4-vector (dx,dy,dw,dh) box\n                regression values for every anchor. These values are the\n                relative offset between the anchor and the ground truth box.\n            pred_masks (list(list[Tensor])): #lvl list of tensors, each is a list of\n                A tensors of shape (N, M_{i,a}, Hi, Wi).\n                The tensor predicts a dense set of M_ixM_i masks at every location.\n        \"\"\"", "\n", "pred_logits", "=", "[", "self", ".", "cls_score", "(", "self", ".", "cls_subnet", "(", "x", ")", ")", "for", "x", "in", "features", "]", "\n", "pred_deltas", "=", "[", "self", ".", "bbox_pred", "(", "self", ".", "bbox_subnet", "(", "x", ")", ")", "for", "x", "in", "features", "]", "\n", "\n", "pred_masks", "=", "None", "\n", "if", "self", ".", "mask_on", ":", "\n", "            ", "mask_feats", "=", "[", "self", ".", "mask_subnet", "(", "x", ")", "for", "x", "in", "features", "]", "\n", "\n", "if", "self", ".", "bipyramid_on", ":", "\n", "                ", "mask_feat_high_res", "=", "mask_feats", "[", "0", "]", "\n", "H", ",", "W", "=", "mask_feat_high_res", ".", "shape", "[", "-", "2", ":", "]", "\n", "mask_feats_up", "=", "[", "]", "\n", "for", "lvl", ",", "mask_feat", "in", "enumerate", "(", "mask_feats", ")", ":", "\n", "                    ", "lambda_val", "=", "2.0", "**", "lvl", "\n", "mask_feat_up", "=", "mask_feat", "\n", "if", "lvl", ">", "0", ":", "\n", "                        ", "mask_feat_up", "=", "F", ".", "interpolate", "(", "\n", "mask_feat", ",", "scale_factor", "=", "lambda_val", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "", "mask_feats_up", ".", "append", "(", "\n", "self", ".", "mask_fuse", "(", "mask_feat_up", "[", ":", ",", ":", ",", ":", "H", ",", ":", "W", "]", "+", "mask_feat_high_res", ")", "\n", ")", "\n", "", "mask_feats", "=", "mask_feats_up", "\n", "\n", "", "pred_masks", "=", "[", "]", "\n", "for", "lvl", ",", "mask_feat", "in", "enumerate", "(", "mask_feats", ")", ":", "\n", "                ", "cur_masks", "=", "[", "]", "\n", "for", "mask_size", "in", "self", ".", "mask_sizes", ":", "\n", "                    ", "cur_mask_module", "=", "getattr", "(", "self", ",", "\"mask_pred_%02d\"", "%", "mask_size", ")", "\n", "cur_mask", "=", "cur_mask_module", "(", "mask_feat", ")", "\n", "if", "self", ".", "align_on", ":", "\n", "                        ", "if", "self", ".", "bipyramid_on", ":", "\n", "                            ", "cur_mask_module", "=", "getattr", "(", "self", ",", "\"align2nat_%02d\"", "%", "lvl", ")", "\n", "cur_mask", "=", "cur_mask_module", "(", "cur_mask", ")", "\n", "", "else", ":", "\n", "                            ", "cur_mask", "=", "self", ".", "align2nat", "(", "cur_mask", ")", "\n", "", "", "cur_masks", ".", "append", "(", "cur_mask", ")", "\n", "", "pred_masks", ".", "append", "(", "cur_masks", ")", "\n", "", "", "return", "pred_logits", ",", "pred_deltas", ",", "pred_masks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.permute_all_cls_and_box_to_N_HWA_K_and_concat": [[23, 40], ["detectron2.layers.cat().view", "detectron2.layers.cat().view", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "detectron2.modeling.meta_arch.retinanet.permute_to_N_HWA_K", "detectron2.layers.cat", "detectron2.layers.cat"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.retinanet.permute_to_N_HWA_K", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["def", "permute_all_cls_and_box_to_N_HWA_K_and_concat", "(", "pred_logits", ",", "pred_anchor_deltas", ",", "num_classes", "=", "80", ")", ":", "\n", "    ", "\"\"\"\n    Rearrange the tensor layout from the network output, i.e.:\n    list[Tensor]: #lvl tensors of shape (N, A x K, Hi, Wi)\n    to per-image predictions, i.e.:\n    Tensor: of shape (N x sum(Hi x Wi x A), K)\n    \"\"\"", "\n", "# for each feature level, permute the outputs to make them be in the", "\n", "# same format as the labels.", "\n", "pred_logits_flattened", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "num_classes", ")", "for", "x", "in", "pred_logits", "]", "\n", "pred_anchor_deltas_flattened", "=", "[", "permute_to_N_HWA_K", "(", "x", ",", "4", ")", "for", "x", "in", "pred_anchor_deltas", "]", "\n", "# concatenate on the first dimension (representing the feature levels), to", "\n", "# take into account the way the labels were generated (with all feature maps", "\n", "# being concatenated as well)", "\n", "pred_logits", "=", "cat", "(", "pred_logits_flattened", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "num_classes", ")", "\n", "pred_anchor_deltas", "=", "cat", "(", "pred_anchor_deltas_flattened", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "return", "pred_logits", ",", "pred_anchor_deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._assignment_rule": [[42, 133], ["torch.min", "torch.min", "torch.max", "torch.max", "detectron2.layers.cat", "torch.zeros_like", "torch.zeros_like", "torch.all", "torch.all", "assign_matrix.max", "matches.new_full", "torch.max", "torch.max", "torch.sum", "torch.sum", "matches.size", "assign_matrix.sum", "gt_boxes.new_full", "gt_boxes.new_full", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "_assignment_rule", "(", "\n", "gt_boxes", ",", "\n", "anchor_boxes", ",", "\n", "unit_lengths", ",", "\n", "min_anchor_size", ",", "\n", "scale_thresh", "=", "2.0", ",", "\n", "spatial_thresh", "=", "1.0", ",", "\n", "uniqueness_on", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Given two lists of boxes of N ground truth boxes and M anchor boxes,\n    compute the assignment between the two, following the assignment rules in\n    https://arxiv.org/abs/1903.12174.\n    The box order must be (xmin, ymin, xmax, ymax), so please make sure to convert\n    to BoxMode.XYXY_ABS before calling this function.\n\n    Args:\n        gt_boxes, anchor_boxes (Boxes): two Boxes. Contains N & M boxes/anchors, respectively.\n        unit_lengths (Tensor): Contains the unit lengths of M anchor boxes.\n        min_anchor_size (float): Minimum size of the anchor, in pixels\n        scale_thresh (float): The `scale` threshold: the maximum size of the anchor\n                              should not be greater than scale_thresh x max(h, w) of\n                              the ground truth box.\n        spatial_thresh (float): The `spatial` threshold: the l2 distance between the\n                              center of the anchor and the ground truth box should not\n                              be greater than spatial_thresh x u where u is the unit length.\n\n    Returns:\n        matches (Tensor[int64]): a vector of length M, where matches[i] is a matched\n                ground-truth index in [0, N)\n        match_labels (Tensor[int8]): a vector of length M, where pred_labels[i] indicates\n            whether a prediction is a true or false positive or ignored\n    \"\"\"", "\n", "gt_boxes", ",", "anchor_boxes", "=", "gt_boxes", ".", "tensor", ",", "anchor_boxes", ".", "tensor", "\n", "N", "=", "gt_boxes", ".", "shape", "[", "0", "]", "\n", "M", "=", "anchor_boxes", ".", "shape", "[", "0", "]", "\n", "if", "N", "==", "0", "or", "M", "==", "0", ":", "\n", "        ", "return", "(", "\n", "gt_boxes", ".", "new_full", "(", "(", "N", ",", ")", ",", "0", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "gt_boxes", ".", "new_full", "(", "(", "N", ",", ")", ",", "-", "1", ",", "dtype", "=", "torch", ".", "int8", ")", ",", "\n", ")", "\n", "\n", "# Containment rule", "\n", "", "lt", "=", "torch", ".", "min", "(", "gt_boxes", "[", ":", ",", "None", ",", ":", "2", "]", ",", "anchor_boxes", "[", ":", ",", ":", "2", "]", ")", "# [N,M,2]", "\n", "rb", "=", "torch", ".", "max", "(", "gt_boxes", "[", ":", ",", "None", ",", "2", ":", "]", ",", "anchor_boxes", "[", ":", ",", "2", ":", "]", ")", "# [N,M,2]", "\n", "union", "=", "cat", "(", "[", "lt", ",", "rb", "]", ",", "dim", "=", "2", ")", "# [N,M,4]", "\n", "\n", "dummy_gt_boxes", "=", "torch", ".", "zeros_like", "(", "gt_boxes", ")", "\n", "anchor", "=", "dummy_gt_boxes", "[", ":", ",", "None", ",", ":", "]", "+", "anchor_boxes", "[", ":", ",", ":", "]", "# [N,M,4]", "\n", "\n", "contain_matrix", "=", "torch", ".", "all", "(", "union", "==", "anchor", ",", "dim", "=", "2", ")", "# [N,M]", "\n", "\n", "# Centrality rule, scale", "\n", "gt_size_lower", "=", "torch", ".", "max", "(", "gt_boxes", "[", ":", ",", "2", ":", "]", "-", "gt_boxes", "[", ":", ",", ":", "2", "]", ",", "dim", "=", "1", ")", "[", "0", "]", "# [N]", "\n", "gt_size_upper", "=", "gt_size_lower", "*", "scale_thresh", "# [N]", "\n", "# Fall back for small objects", "\n", "gt_size_upper", "[", "gt_size_upper", "<", "min_anchor_size", "]", "=", "min_anchor_size", "\n", "# Due to sampling of locations, the anchor sizes are deducted with sampling strides", "\n", "anchor_size", "=", "(", "\n", "torch", ".", "max", "(", "anchor_boxes", "[", ":", ",", "2", ":", "]", "-", "anchor_boxes", "[", ":", ",", ":", "2", "]", ",", "dim", "=", "1", ")", "[", "0", "]", "-", "unit_lengths", "\n", ")", "# [M]", "\n", "\n", "size_diff_upper", "=", "gt_size_upper", "[", ":", ",", "None", "]", "-", "anchor_size", "# [N,M]", "\n", "scale_matrix", "=", "size_diff_upper", ">=", "0", "# [N,M]", "\n", "\n", "# Centrality rule, spatial", "\n", "gt_center", "=", "(", "gt_boxes", "[", ":", ",", "2", ":", "]", "+", "gt_boxes", "[", ":", ",", ":", "2", "]", ")", "/", "2", "# [N,2]", "\n", "anchor_center", "=", "(", "anchor_boxes", "[", ":", ",", "2", ":", "]", "+", "anchor_boxes", "[", ":", ",", ":", "2", "]", ")", "/", "2", "# [M,2]", "\n", "offset_center", "=", "gt_center", "[", ":", ",", "None", ",", ":", "]", "-", "anchor_center", "[", ":", ",", ":", "]", "# [N,M,2]", "\n", "offset_center", "/=", "unit_lengths", "[", ":", ",", "None", "]", "# [N,M,2]", "\n", "spatial_square", "=", "spatial_thresh", "*", "spatial_thresh", "\n", "spatial_matrix", "=", "torch", ".", "sum", "(", "offset_center", "*", "offset_center", ",", "dim", "=", "2", ")", "<=", "spatial_square", "\n", "\n", "assign_matrix", "=", "(", "contain_matrix", "&", "scale_matrix", "&", "spatial_matrix", ")", ".", "int", "(", ")", "\n", "\n", "# assign_matrix is N (gt) x M (predicted)", "\n", "# Max over gt elements (dim 0) to find best gt candidate for each prediction", "\n", "matched_vals", ",", "matches", "=", "assign_matrix", ".", "max", "(", "dim", "=", "0", ")", "\n", "match_labels", "=", "matches", ".", "new_full", "(", "matches", ".", "size", "(", ")", ",", "1", ",", "dtype", "=", "torch", ".", "int8", ")", "\n", "\n", "match_labels", "[", "matched_vals", "==", "0", "]", "=", "0", "\n", "match_labels", "[", "matched_vals", "==", "1", "]", "=", "1", "\n", "\n", "# find all the elements that match to ground truths multiple times", "\n", "not_unique_idxs", "=", "assign_matrix", ".", "sum", "(", "dim", "=", "0", ")", ">", "1", "\n", "if", "uniqueness_on", ":", "\n", "        ", "match_labels", "[", "not_unique_idxs", "]", "=", "0", "\n", "", "else", ":", "\n", "        ", "match_labels", "[", "not_unique_idxs", "]", "=", "-", "1", "\n", "\n", "", "return", "matches", ",", "match_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._paste_mask_lists_in_image": [[136, 180], ["torch.tensor", "torch.tensor", "torch.unique", "torch.unique", "torch.unique.tolist", "detectron2.layers.cat", "detectron2.layers.cat", "torch.empty_like", "torch.empty_like", "len", "torch.empty", "torch.empty", "detectron2.layers.cat.append", "detectron2.layers.cat", "detectron2.layers.cat.append", "torch.where", "torch.where", "detectron2.layers.paste_masks_in_image"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.mask_ops.paste_masks_in_image"], ["", "def", "_paste_mask_lists_in_image", "(", "masks", ",", "boxes", ",", "image_shape", ",", "threshold", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    Paste a list of masks that are of various resolutions (e.g., 28 x 28) into an image.\n    The location, height, and width for pasting each mask is determined by their\n    corresponding bounding boxes in boxes.\n\n    Args:\n        masks (list(Tensor)): A list of Tensor of shape (1, Hmask_i, Wmask_i).\n                            Values are in [0, 1]. The list length, Bimg, is the\n                            number of detected object instances in the image.\n        boxes (Boxes): A Boxes of length Bimg. boxes.tensor[i] and masks[i] correspond\n                            to the same object instance.\n        image_shape (tuple): height, width\n        threshold (float): A threshold in [0, 1] for converting the (soft) masks to\n            binary masks.\n\n    Returns:\n        img_masks (Tensor): A tensor of shape (Bimg, Himage, Wimage), where Bimg is the\n        number of detected object instances and Himage, Wimage are the image width\n        and height. img_masks[i] is a binary mask for object instance i.\n    \"\"\"", "\n", "if", "len", "(", "masks", ")", "==", "0", ":", "\n", "        ", "return", "torch", ".", "empty", "(", "(", "0", ",", "1", ")", "+", "image_shape", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "# Loop over masks groups. Each group has the same mask prediction size.", "\n", "", "img_masks", "=", "[", "]", "\n", "ind_masks", "=", "[", "]", "\n", "mask_sizes", "=", "torch", ".", "tensor", "(", "[", "m", ".", "shape", "[", "-", "1", "]", "for", "m", "in", "masks", "]", ")", "\n", "unique_sizes", "=", "torch", ".", "unique", "(", "mask_sizes", ")", "\n", "for", "msize", "in", "unique_sizes", ".", "tolist", "(", ")", ":", "\n", "        ", "cur_ind", "=", "torch", ".", "where", "(", "mask_sizes", "==", "msize", ")", "[", "0", "]", "\n", "ind_masks", ".", "append", "(", "cur_ind", ")", "\n", "\n", "cur_masks", "=", "cat", "(", "[", "masks", "[", "i", "]", "for", "i", "in", "cur_ind", "]", ")", "\n", "cur_boxes", "=", "boxes", "[", "cur_ind", "]", "\n", "img_masks", ".", "append", "(", "paste_masks_in_image", "(", "cur_masks", ",", "cur_boxes", ",", "image_shape", ",", "threshold", ")", ")", "\n", "\n", "", "img_masks", "=", "cat", "(", "img_masks", ")", "\n", "ind_masks", "=", "cat", "(", "ind_masks", ")", "\n", "\n", "img_masks_out", "=", "torch", ".", "empty_like", "(", "img_masks", ")", "\n", "img_masks_out", "[", "ind_masks", ",", ":", ",", ":", "]", "=", "img_masks", "\n", "\n", "return", "img_masks_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._postprocess": [[182, 227], ["detectron2.structures.Instances", "output_boxes.clip", "output_boxes.nonempty", "arch._paste_mask_lists_in_image", "detectron2.structures.Instances.get_fields", "zip", "output_boxes.nonempty.tolist"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.nonempty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch._paste_mask_lists_in_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.get_fields"], ["", "def", "_postprocess", "(", "results", ",", "result_mask_info", ",", "output_height", ",", "output_width", ",", "mask_threshold", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    Post-process the output boxes for TensorMask.\n    The input images are often resized when entering an object detector.\n    As a result, we often need the outputs of the detector in a different\n    resolution from its inputs.\n\n    This function will postprocess the raw outputs of TensorMask\n    to produce outputs according to the desired output resolution.\n\n    Args:\n        results (Instances): the raw outputs from the detector.\n            `results.image_size` contains the input image resolution the detector sees.\n            This object might be modified in-place. Note that it does not contain the field\n            `pred_masks`, which is provided by another input `result_masks`.\n        result_mask_info (list[Tensor], Boxes): a pair of two items for mask related results.\n                The first item is a list of #detection tensors, each is the predicted masks.\n                The second item is the anchors corresponding to the predicted masks.\n        output_height, output_width: the desired output resolution.\n\n    Returns:\n        Instances: the postprocessed output from the model, based on the output resolution\n    \"\"\"", "\n", "scale_x", ",", "scale_y", "=", "(", "output_width", "/", "results", ".", "image_size", "[", "1", "]", ",", "output_height", "/", "results", ".", "image_size", "[", "0", "]", ")", "\n", "results", "=", "Instances", "(", "(", "output_height", ",", "output_width", ")", ",", "**", "results", ".", "get_fields", "(", ")", ")", "\n", "\n", "output_boxes", "=", "results", ".", "pred_boxes", "\n", "output_boxes", ".", "tensor", "[", ":", ",", "0", ":", ":", "2", "]", "*=", "scale_x", "\n", "output_boxes", ".", "tensor", "[", ":", ",", "1", ":", ":", "2", "]", "*=", "scale_y", "\n", "output_boxes", ".", "clip", "(", "results", ".", "image_size", ")", "\n", "\n", "inds_nonempty", "=", "output_boxes", ".", "nonempty", "(", ")", "\n", "results", "=", "results", "[", "inds_nonempty", "]", "\n", "result_masks", ",", "result_anchors", "=", "result_mask_info", "\n", "if", "result_masks", ":", "\n", "        ", "result_anchors", ".", "tensor", "[", ":", ",", "0", ":", ":", "2", "]", "*=", "scale_x", "\n", "result_anchors", ".", "tensor", "[", ":", ",", "1", ":", ":", "2", "]", "*=", "scale_y", "\n", "result_masks", "=", "[", "x", "for", "(", "i", ",", "x", ")", "in", "zip", "(", "inds_nonempty", ".", "tolist", "(", ")", ",", "result_masks", ")", "if", "i", "]", "\n", "results", ".", "pred_masks", "=", "_paste_mask_lists_in_image", "(", "\n", "result_masks", ",", "\n", "result_anchors", "[", "inds_nonempty", "]", ",", "\n", "results", ".", "image_size", ",", "\n", "threshold", "=", "mask_threshold", ",", "\n", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_swap_align2nat.SwapAlign2NatTest.test_swap_align2nat_gradcheck_cuda": [[12, 20], ["unittest.skipIf", "torch.device", "tensormask.layers.swap_align2nat.SwapAlign2Nat().to", "torch.rand", "test_swap_align2nat.SwapAlign2NatTest.assertTrue", "torch.autograd.gradcheck", "torch.cuda.is_available", "tensormask.layers.swap_align2nat.SwapAlign2Nat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["    ", "@", "unittest", ".", "skipIf", "(", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"CUDA not available\"", ")", "\n", "def", "test_swap_align2nat_gradcheck_cuda", "(", "self", ")", ":", "\n", "        ", "dtype", "=", "torch", ".", "float64", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "m", "=", "SwapAlign2Nat", "(", "2", ")", ".", "to", "(", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "x", "=", "torch", ".", "rand", "(", "2", ",", "4", ",", "10", ",", "10", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "assertTrue", "(", "gradcheck", "(", "m", ",", "x", ")", ",", "\"gradcheck failed for SwapAlign2Nat CUDA\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_swap_align2nat.SwapAlign2NatTest._swap_align2nat": [[21, 29], ["tensormask.layers.swap_align2nat.SwapAlign2Nat", "torch.from_numpy", "tensormask.layers.swap_align2nat.SwapAlign2Nat.forward().cpu().numpy", "tensor[].astype", "tensormask.layers.swap_align2nat.SwapAlign2Nat.forward().cpu", "tensormask.layers.swap_align2nat.SwapAlign2Nat.forward", "torch.from_numpy.cuda"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward"], ["", "def", "_swap_align2nat", "(", "self", ",", "tensor", ",", "lambda_val", ")", ":", "\n", "        ", "\"\"\"\n        The basic setup for testing Swap_Align\n        \"\"\"", "\n", "op", "=", "SwapAlign2Nat", "(", "lambda_val", ",", "pad_val", "=", "0.0", ")", "\n", "input", "=", "torch", ".", "from_numpy", "(", "tensor", "[", "None", ",", ":", ",", ":", ",", ":", "]", ".", "astype", "(", "\"float32\"", ")", ")", "\n", "output", "=", "op", ".", "forward", "(", "input", ".", "cuda", "(", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "output", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_image_resize_transform.TestImageResizeTransform.test_image_resize_1": [[10, 17], ["densepose.data.transform.ImageResizeTransform", "densepose.data.transform.ImageResizeTransform.", "test_image_resize_transform.TestImageResizeTransform.assertEqual", "test_image_resize_transform.TestImageResizeTransform.assertAlmostEqual", "torch.ones", "torch.ones", "densepose.data.transform.ImageResizeTransform.size", "IMAGES_GT.size", "torch.abs().max().item", "torch.abs().max", "torch.abs"], "methods", ["None"], ["    ", "def", "test_image_resize_1", "(", "self", ")", ":", "\n", "        ", "images_batch", "=", "torch", ".", "ones", "(", "(", "3", ",", "100", ",", "100", ",", "3", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "*", "100", "\n", "transform", "=", "ImageResizeTransform", "(", ")", "\n", "images_transformed", "=", "transform", "(", "images_batch", ")", "\n", "IMAGES_GT", "=", "torch", ".", "ones", "(", "(", "3", ",", "3", ",", "800", ",", "800", ")", ",", "dtype", "=", "torch", ".", "float", ")", "*", "100", "\n", "self", ".", "assertEqual", "(", "images_transformed", ".", "size", "(", ")", ",", "IMAGES_GT", ".", "size", "(", ")", ")", "\n", "self", ".", "assertAlmostEqual", "(", "torch", ".", "abs", "(", "IMAGES_GT", "-", "images_transformed", ")", ".", "max", "(", ")", ".", "item", "(", ")", ",", "0.0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_combine_data_loader.TestCombinedDataLoader.test_combine_loaders_1": [[31, 47], ["test_combine_data_loader._grouper", "test_combine_data_loader._grouper", "random.seed", "densepose.data.CombinedDataLoader", "enumerate", "test_combine_data_loader.TestCombinedDataLoader.assertEqual", "test_combine_data_loader.TestCombinedDataLoader.assertEqual", "len", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_combine_data_loader._grouper", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_combine_data_loader._grouper"], ["    ", "def", "test_combine_loaders_1", "(", "self", ")", ":", "\n", "        ", "loader1", "=", "_grouper", "(", "[", "f\"1_{i}\"", "for", "i", "in", "range", "(", "10", ")", "]", ",", "2", ")", "\n", "loader2", "=", "_grouper", "(", "[", "f\"2_{i}\"", "for", "i", "in", "range", "(", "11", ")", "]", ",", "3", ")", "\n", "batch_size", "=", "4", "\n", "ratios", "=", "(", "0.1", ",", "0.9", ")", "\n", "random", ".", "seed", "(", "43", ")", "\n", "combined", "=", "CombinedDataLoader", "(", "(", "loader1", ",", "loader2", ")", ",", "batch_size", ",", "ratios", ")", "\n", "BATCHES_GT", "=", "[", "\n", "[", "\"1_0\"", ",", "\"1_1\"", ",", "\"2_0\"", ",", "\"2_1\"", "]", ",", "\n", "[", "\"2_2\"", ",", "\"2_3\"", ",", "\"2_4\"", ",", "\"2_5\"", "]", ",", "\n", "[", "\"1_2\"", ",", "\"1_3\"", ",", "\"2_6\"", ",", "\"2_7\"", "]", ",", "\n", "[", "\"2_8\"", ",", "\"2_9\"", ",", "\"2_10\"", ",", "None", "]", ",", "\n", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "combined", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "len", "(", "batch", ")", ",", "batch_size", ")", "\n", "self", ".", "assertEqual", "(", "batch", ",", "BATCHES_GT", "[", "i", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_combine_data_loader._grouper": [[10, 28], ["iter", "range", "values.append", "tuple", "next", "values.extend", "tuple", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.rpn.anchor_generator.BufferList.extend"], ["def", "_grouper", "(", "iterable", ":", "Iterable", "[", "Any", "]", ",", "n", ":", "int", ",", "fillvalue", "=", "None", ")", "->", "Iterator", "[", "Tuple", "[", "Any", "]", "]", ":", "\n", "    ", "\"\"\"\n    Group elements of an iterable by chunks of size `n`, e.g.\n    grouper(range(9), 4) ->\n        (0, 1, 2, 3), (4, 5, 6, 7), (8, None, None, None)\n    \"\"\"", "\n", "it", "=", "iter", "(", "iterable", ")", "\n", "while", "True", ":", "\n", "        ", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "value", "=", "next", "(", "it", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "values", ".", "extend", "(", "[", "fillvalue", "]", "*", "(", "n", "-", "len", "(", "values", ")", ")", ")", "\n", "yield", "tuple", "(", "values", ")", "\n", "return", "\n", "", "values", ".", "append", "(", "value", ")", "\n", "", "yield", "tuple", "(", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_coco_test": [[36, 41], ["test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_test"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_test"], ["def", "generic_coco_test", "(", "self", ",", "dataset_info", ")", ":", "\n", "        ", "if", "dataset_info", ".", "name", "not", "in", "self", ".", "COCO_DATASET_DATA", ":", "\n", "            ", "return", "\n", "", "n_inst", "=", "self", ".", "COCO_DATASET_DATA", "[", "dataset_info", ".", "name", "]", "[", "\"n_instances\"", "]", "\n", "self", ".", "generic_test", "(", "dataset_info", ",", "n_inst", ",", "load_coco_json", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_lvis_test": [[42, 47], ["test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_test"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_test"], ["", "def", "generic_lvis_test", "(", "self", ",", "dataset_info", ")", ":", "\n", "        ", "if", "dataset_info", ".", "name", "not", "in", "self", ".", "LVIS_DATASET_DATA", ":", "\n", "            ", "return", "\n", "", "n_inst", "=", "self", ".", "LVIS_DATASET_DATA", "[", "dataset_info", ".", "name", "]", "[", "\"n_instances\"", "]", "\n", "self", ".", "generic_test", "(", "dataset_info", ",", "n_inst", ",", "load_lvis_json", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_test": [[48, 64], ["densepose.data.utils.maybe_prepend_base_path", "densepose.data.utils.maybe_prepend_base_path", "loader_fun", "sum", "test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.assertEqual", "densepose.structures.DensePoseDataRelative.validate_annotation"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.validate_annotation"], ["", "def", "generic_test", "(", "self", ",", "dataset_info", ",", "n_inst", ",", "loader_fun", ")", ":", "\n", "        ", "datasets_root", "=", "DENSEPOSE_ANNOTATIONS_DIR", "\n", "annotations_fpath", "=", "maybe_prepend_base_path", "(", "datasets_root", ",", "dataset_info", ".", "annotations_fpath", ")", "\n", "images_root", "=", "maybe_prepend_base_path", "(", "datasets_root", ",", "dataset_info", ".", "images_root", ")", "\n", "image_annotation_dicts", "=", "loader_fun", "(", "\n", "annotations_json_file", "=", "annotations_fpath", ",", "\n", "image_root", "=", "images_root", ",", "\n", "dataset_name", "=", "dataset_info", ".", "name", ",", "\n", ")", "\n", "num_valid", "=", "sum", "(", "\n", "1", "\n", "for", "image_annotation_dict", "in", "image_annotation_dicts", "\n", "for", "ann", "in", "image_annotation_dict", "[", "\"annotations\"", "]", "\n", "if", "DensePoseDataRelative", ".", "validate_annotation", "(", "ann", ")", "[", "0", "]", "\n", ")", "\n", "self", ".", "assertEqual", "(", "num_valid", ",", "n_inst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.coco_test_fun": [[66, 68], ["test_dataset_loaded_annotations..generic_coco_test"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_coco_test"], ["", "", "def", "coco_test_fun", "(", "dataset_info", ")", ":", "\n", "    ", "return", "lambda", "self", ":", "self", ".", "generic_coco_test", "(", "dataset_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.lvis_test_fun": [[78, 80], ["test_dataset_loaded_annotations..generic_lvis_test"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_dataset_loaded_annotations.TestDatasetLoadedAnnotations.generic_lvis_test"], ["", "def", "lvis_test_fun", "(", "dataset_info", ")", ":", "\n", "    ", "return", "lambda", "self", ":", "self", ".", "generic_lvis_test", "(", "dataset_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.test_chart_based_annotations_accumulator_no_gt_densepose": [[20, 26], ["densepose.modeling.losses.utils.ChartBasedAnnotationsAccumulator", "densepose.modeling.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.assertEqual", "getattr", "expected_values.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["    ", "def", "test_chart_based_annotations_accumulator_no_gt_densepose", "(", "self", ")", ":", "\n", "        ", "accumulator", "=", "ChartBasedAnnotationsAccumulator", "(", ")", "\n", "accumulator", ".", "accumulate", "(", "instances", ")", "\n", "expected_values", "=", "{", "\"nxt_bbox_with_dp_index\"", ":", "0", ",", "\"nxt_bbox_index\"", ":", "n_instances", "}", "\n", "for", "key", "in", "accumulator", ".", "__dict__", ":", "\n", "            ", "self", ".", "assertEqual", "(", "getattr", "(", "accumulator", ",", "key", ")", ",", "expected_values", ".", "get", "(", "key", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.test_chart_based_annotations_accumulator_gt_densepose_none": [[27, 34], ["densepose.modeling.losses.utils.ChartBasedAnnotationsAccumulator", "densepose.modeling.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.assertEqual", "getattr", "expected_values.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "test_chart_based_annotations_accumulator_gt_densepose_none", "(", "self", ")", ":", "\n", "        ", "instances", ".", "gt_densepose", "=", "[", "None", "]", "*", "n_instances", "\n", "accumulator", "=", "ChartBasedAnnotationsAccumulator", "(", ")", "\n", "accumulator", ".", "accumulate", "(", "instances", ")", "\n", "expected_values", "=", "{", "\"nxt_bbox_with_dp_index\"", ":", "0", ",", "\"nxt_bbox_index\"", ":", "n_instances", "}", "\n", "for", "key", "in", "accumulator", ".", "__dict__", ":", "\n", "            ", "self", ".", "assertEqual", "(", "getattr", "(", "accumulator", ",", "key", ")", ",", "expected_values", ".", "get", "(", "key", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.test_chart_based_annotations_accumulator_gt_densepose": [[35, 77], ["densepose.structures.DensePoseList", "densepose.modeling.losses.utils.ChartBasedAnnotationsAccumulator", "densepose.modeling.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "detectron2.structures.BoxMode.convert", "detectron2.structures.BoxMode.convert", "instances.proposal_boxes.tensor.clone", "instances.gt_boxes.tensor.clone", "detectron2.structures.BoxMode.convert.split", "detectron2.structures.BoxMode.convert.split", "list", "getattr", "expected_values.get", "densepose.structures.DensePoseDataRelative", "torch.tensor", "torch.tensor", "range", "torch.tensor", "test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.assertEqual", "torch.zeros", "range", "range", "test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.assertListEqual", "test_chart_based_annotations_accumulator.TestChartBasedAnnotationsAccumulator.assertTrue", "torch.allclose", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "test_chart_based_annotations_accumulator_gt_densepose", "(", "self", ")", ":", "\n", "        ", "data_relative_keys", "=", "[", "\n", "DensePoseDataRelative", ".", "X_KEY", ",", "\n", "DensePoseDataRelative", ".", "Y_KEY", ",", "\n", "DensePoseDataRelative", ".", "I_KEY", ",", "\n", "DensePoseDataRelative", ".", "U_KEY", ",", "\n", "DensePoseDataRelative", ".", "V_KEY", ",", "\n", "DensePoseDataRelative", ".", "S_KEY", ",", "\n", "]", "\n", "annotations", "=", "[", "DensePoseDataRelative", "(", "{", "k", ":", "[", "0", "]", "for", "k", "in", "data_relative_keys", "}", ")", "]", "*", "n_instances", "\n", "instances", ".", "gt_densepose", "=", "DensePoseList", "(", "annotations", ",", "instances", ".", "gt_boxes", ",", "image_shape", ")", "\n", "accumulator", "=", "ChartBasedAnnotationsAccumulator", "(", ")", "\n", "accumulator", ".", "accumulate", "(", "instances", ")", "\n", "bbox_xywh_est", "=", "BoxMode", ".", "convert", "(", "\n", "instances", ".", "proposal_boxes", ".", "tensor", ".", "clone", "(", ")", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", "\n", ")", "\n", "bbox_xywh_gt", "=", "BoxMode", ".", "convert", "(", "\n", "instances", ".", "gt_boxes", ".", "tensor", ".", "clone", "(", ")", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", "\n", ")", "\n", "expected_values", "=", "{", "\n", "\"s_gt\"", ":", "[", "\n", "torch", ".", "zeros", "(", "(", "3", ",", "DensePoseDataRelative", ".", "MASK_SIZE", ",", "DensePoseDataRelative", ".", "MASK_SIZE", ")", ")", "\n", "]", "\n", "*", "n_instances", ",", "\n", "\"bbox_xywh_est\"", ":", "bbox_xywh_est", ".", "split", "(", "1", ")", ",", "\n", "\"bbox_xywh_gt\"", ":", "bbox_xywh_gt", ".", "split", "(", "1", ")", ",", "\n", "\"point_bbox_with_dp_indices\"", ":", "[", "torch", ".", "tensor", "(", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_instances", ")", "]", ",", "\n", "\"point_bbox_indices\"", ":", "[", "torch", ".", "tensor", "(", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_instances", ")", "]", ",", "\n", "\"bbox_indices\"", ":", "list", "(", "range", "(", "n_instances", ")", ")", ",", "\n", "\"nxt_bbox_with_dp_index\"", ":", "n_instances", ",", "\n", "\"nxt_bbox_index\"", ":", "n_instances", ",", "\n", "}", "\n", "default_value", "=", "[", "torch", ".", "tensor", "(", "[", "0", "]", ")", "]", "*", "3", "\n", "for", "key", "in", "accumulator", ".", "__dict__", ":", "\n", "            ", "to_test", "=", "getattr", "(", "accumulator", ",", "key", ")", "\n", "gt_value", "=", "expected_values", ".", "get", "(", "key", ",", "default_value", ")", "\n", "if", "key", "in", "[", "\"nxt_bbox_with_dp_index\"", ",", "\"nxt_bbox_index\"", "]", ":", "\n", "                ", "self", ".", "assertEqual", "(", "to_test", ",", "gt_value", ")", "\n", "", "elif", "key", "==", "\"bbox_indices\"", ":", "\n", "                ", "self", ".", "assertListEqual", "(", "to_test", ",", "gt_value", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "torch", ".", "stack", "(", "to_test", ")", ",", "torch", ".", "stack", "(", "gt_value", ")", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir": [[20, 25], ["os.path.join", "os.path.dirname", "os.path.realpath"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_evolution_config_dir": [[27, 32], ["os.path.join", "common._get_base_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir"], ["\n", "def", "__init__", "(", "self", ",", "dataset", ",", "map_func", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_map_func", "=", "PicklableWrapper", "(", "map_func", ")", "# wrap so that a lambda will work", "\n", "\n", "self", ".", "_rng", "=", "random", ".", "Random", "(", "42", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_hrnet_config_dir": [[34, 39], ["os.path.join", "common._get_base_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_dataset", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "retry_count", "=", "0", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_quick_schedules_config_dir": [[41, 46], ["os.path.join", "common._get_base_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir"], ["\n", "while", "True", ":", "\n", "            ", "data", "=", "self", ".", "_map_func", "(", "self", ".", "_dataset", "[", "cur_idx", "]", ")", "\n", "if", "data", "is", "not", "None", ":", "\n", "                ", "self", ".", "_fallback_candidates", ".", "add", "(", "cur_idx", ")", "\n", "return", "data", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._collect_config_files": [[48, 66], ["common._get_base_config_dir", "os.listdir", "os.path.join", "os.path.splitext", "entry.startswith", "os.path.relpath", "results.append", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir"], ["# _map_func fails for this idx, use a random new index from the pool", "\n", "", "retry_count", "+=", "1", "\n", "self", ".", "_fallback_candidates", ".", "discard", "(", "cur_idx", ")", "\n", "cur_idx", "=", "self", ".", "_rng", ".", "sample", "(", "self", ".", "_fallback_candidates", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "if", "retry_count", ">=", "3", ":", "\n", "                ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Failed to apply `_map_func` for idx: {}, retry count: {}\"", ".", "format", "(", "\n", "idx", ",", "retry_count", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "", "", "", "class", "DatasetFromList", "(", "data", ".", "Dataset", ")", ":", "\n", "    ", "\"\"\"\n    Wrap a list to a torch Dataset. It produces elements of the list as data.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_config_files": [[68, 73], ["common._collect_config_files", "common._get_base_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._collect_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir"], ["        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_evolution_config_files": [[75, 80], ["common._collect_config_files", "common._get_evolution_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._collect_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_evolution_config_dir"], ["\n", "self", ".", "_lst", "=", "lst", "\n", "self", ".", "_copy", "=", "copy", "\n", "self", ".", "_serialize", "=", "serialize", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_hrnet_config_files": [[82, 87], ["common._collect_config_files", "common._get_hrnet_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._collect_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_hrnet_config_dir"], ["def", "_serialize", "(", "data", ")", ":", "\n", "            ", "buffer", "=", "pickle", ".", "dumps", "(", "data", ",", "protocol", "=", "-", "1", ")", "\n", "return", "np", ".", "frombuffer", "(", "buffer", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "", "if", "self", ".", "_serialize", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_quick_schedules_config_files": [[89, 94], ["common._collect_config_files", "common._get_quick_schedules_config_dir"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._collect_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_quick_schedules_config_dir"], ["\"Serializing {} elements to byte tensors and concatenating them all ...\"", ".", "format", "(", "\n", "len", "(", "self", ".", "_lst", ")", "\n", ")", "\n", ")", "\n", "self", ".", "_lst", "=", "[", "_serialize", "(", "x", ")", "for", "x", "in", "self", ".", "_lst", "]", "\n", "self", ".", "_addr", "=", "np", ".", "asarray", "(", "[", "len", "(", "x", ")", "for", "x", "in", "self", ".", "_lst", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_model_config": [[96, 108], ["detectron2.config.get_cfg", "densepose.add_densepose_config", "os.path.join", "detectron2.config.get_cfg.merge_from_file", "common._get_base_config_dir", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_base_config_dir"], ["self", ".", "_lst", "=", "np", ".", "concatenate", "(", "self", ".", "_lst", ")", "\n", "logger", ".", "info", "(", "\"Serialized dataset takes {:.2f} MiB\"", ".", "format", "(", "len", "(", "self", ".", "_lst", ")", "/", "1024", "**", "2", ")", ")", "\n", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_serialize", ":", "\n", "            ", "return", "len", "(", "self", ".", "_addr", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_lst", ")", "\n", "\n", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "_serialize", ":", "\n", "            ", "start_addr", "=", "0", "if", "idx", "==", "0", "else", "self", ".", "_addr", "[", "idx", "-", "1", "]", ".", "item", "(", ")", "\n", "end_addr", "=", "self", ".", "_addr", "[", "idx", "]", ".", "item", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_model": [[110, 116], ["common._get_model_config", "detectron2.modeling.build_model"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_model_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model"], ["return", "pickle", ".", "loads", "(", "bytes", ")", "\n", "", "elif", "self", ".", "_copy", ":", "\n", "            ", "return", "copy", ".", "deepcopy", "(", "self", ".", "_lst", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_lst", "[", "idx", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.setup": [[118, 125], ["common._get_model_config", "_get_model_config.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common._get_model_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["    ", "\"\"\"\n    Convert an old indices-based (also called map-style) dataset\n    to an iterable-style dataset.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "dataset", ",", "sampler", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_frame_selector.TestFrameSelector.test_frame_selector_random_k_1": [[10, 19], ["random.seed", "densepose.data.video.RandomKFramesSelector", "list", "densepose.data.video.RandomKFramesSelector.", "test_frame_selector.TestFrameSelector.assertEqual", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["    ", "def", "test_frame_selector_random_k_1", "(", "self", ")", ":", "\n", "        ", "_SEED", "=", "43", "\n", "_K", "=", "4", "\n", "random", ".", "seed", "(", "_SEED", ")", "\n", "selector", "=", "RandomKFramesSelector", "(", "_K", ")", "\n", "frame_tss", "=", "list", "(", "range", "(", "0", ",", "20", ",", "2", ")", ")", "\n", "_SELECTED_GT", "=", "[", "0", ",", "8", ",", "4", ",", "6", "]", "\n", "selected", "=", "selector", "(", "frame_tss", ")", "\n", "self", ".", "assertEqual", "(", "_SELECTED_GT", ",", "selected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_frame_selector.TestFrameSelector.test_frame_selector_random_k_2": [[20, 29], ["random.seed", "densepose.data.video.RandomKFramesSelector", "list", "densepose.data.video.RandomKFramesSelector.", "test_frame_selector.TestFrameSelector.assertEqual", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "test_frame_selector_random_k_2", "(", "self", ")", ":", "\n", "        ", "_SEED", "=", "43", "\n", "_K", "=", "10", "\n", "random", ".", "seed", "(", "_SEED", ")", "\n", "selector", "=", "RandomKFramesSelector", "(", "_K", ")", "\n", "frame_tss", "=", "list", "(", "range", "(", "0", ",", "6", ",", "2", ")", ")", "\n", "_SELECTED_GT", "=", "[", "0", ",", "2", ",", "4", "]", "\n", "selected", "=", "selector", "(", "frame_tss", ")", "\n", "self", ".", "assertEqual", "(", "_SELECTED_GT", ",", "selected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_frame_selector.TestFrameSelector.test_frame_selector_first_k_1": [[30, 37], ["densepose.data.video.FirstKFramesSelector", "list", "densepose.data.video.FirstKFramesSelector.", "test_frame_selector.TestFrameSelector.assertEqual", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "test_frame_selector_first_k_1", "(", "self", ")", ":", "\n", "        ", "_K", "=", "4", "\n", "selector", "=", "FirstKFramesSelector", "(", "_K", ")", "\n", "frame_tss", "=", "list", "(", "range", "(", "0", ",", "20", ",", "2", ")", ")", "\n", "_SELECTED_GT", "=", "frame_tss", "[", ":", "_K", "]", "\n", "selected", "=", "selector", "(", "frame_tss", ")", "\n", "self", ".", "assertEqual", "(", "_SELECTED_GT", ",", "selected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_frame_selector.TestFrameSelector.test_frame_selector_first_k_2": [[38, 45], ["densepose.data.video.FirstKFramesSelector", "list", "densepose.data.video.FirstKFramesSelector.", "test_frame_selector.TestFrameSelector.assertEqual", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "test_frame_selector_first_k_2", "(", "self", ")", ":", "\n", "        ", "_K", "=", "10", "\n", "selector", "=", "FirstKFramesSelector", "(", "_K", ")", "\n", "frame_tss", "=", "list", "(", "range", "(", "0", ",", "6", ",", "2", ")", ")", "\n", "_SELECTED_GT", "=", "frame_tss", "[", ":", "_K", "]", "\n", "selected", "=", "selector", "(", "frame_tss", ")", "\n", "self", ".", "assertEqual", "(", "_SELECTED_GT", ",", "selected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_frame_selector.TestFrameSelector.test_frame_selector_last_k_1": [[46, 53], ["densepose.data.video.LastKFramesSelector", "list", "densepose.data.video.LastKFramesSelector.", "test_frame_selector.TestFrameSelector.assertEqual", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "test_frame_selector_last_k_1", "(", "self", ")", ":", "\n", "        ", "_K", "=", "4", "\n", "selector", "=", "LastKFramesSelector", "(", "_K", ")", "\n", "frame_tss", "=", "list", "(", "range", "(", "0", ",", "20", ",", "2", ")", ")", "\n", "_SELECTED_GT", "=", "frame_tss", "[", "-", "_K", ":", "]", "\n", "selected", "=", "selector", "(", "frame_tss", ")", "\n", "self", ".", "assertEqual", "(", "_SELECTED_GT", ",", "selected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_frame_selector.TestFrameSelector.test_frame_selector_last_k_2": [[54, 61], ["densepose.data.video.LastKFramesSelector", "list", "densepose.data.video.LastKFramesSelector.", "test_frame_selector.TestFrameSelector.assertEqual", "range"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "test_frame_selector_last_k_2", "(", "self", ")", ":", "\n", "        ", "_K", "=", "10", "\n", "selector", "=", "LastKFramesSelector", "(", "_K", ")", "\n", "frame_tss", "=", "list", "(", "range", "(", "0", ",", "6", ",", "2", ")", ")", "\n", "_SELECTED_GT", "=", "frame_tss", "[", "-", "_K", ":", "]", "\n", "selected", "=", "selector", "(", "frame_tss", ")", "\n", "self", ".", "assertEqual", "(", "_SELECTED_GT", ",", "selected", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.ModelE2ETest.setUp": [[30, 32], ["common.get_model"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_model"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "get_model", "(", "self", ".", "CONFIG_PATH", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.ModelE2ETest._test_eval": [[33, 37], ["test_model_e2e.ModelE2ETest.model.eval", "test_model_e2e.ModelE2ETest.model", "test_model_e2e.make_model_inputs", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.make_model_inputs"], ["", "def", "_test_eval", "(", "self", ",", "sizes", ")", ":", "\n", "        ", "inputs", "=", "[", "make_model_inputs", "(", "torch", ".", "rand", "(", "3", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ")", ")", "for", "size", "in", "sizes", "]", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "model", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.DensePoseRCNNE2ETest.test_empty_data": [[42, 44], ["test_model_e2e.DensePoseRCNNE2ETest._test_eval"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.ModelE2ETest._test_eval"], ["def", "test_empty_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "_test_eval", "(", "[", "(", "200", ",", "250", ")", ",", "(", "200", ",", "249", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.make_model_inputs": [[12, 17], ["None"], "function", ["None"], ["def", "make_model_inputs", "(", "image", ",", "instances", "=", "None", ")", ":", "\n", "    ", "if", "instances", "is", "None", ":", "\n", "        ", "return", "{", "\"image\"", ":", "image", "}", "\n", "\n", "", "return", "{", "\"image\"", ":", "image", ",", "\"instances\"", ":", "instances", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_model_e2e.make_empty_instances": [[19, 25], ["detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.tensor().to", "detectron2.structures.BitMasks", "torch.rand", "torch.rand", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "def", "make_empty_instances", "(", "h", ",", "w", ")", ":", "\n", "    ", "instances", "=", "Instances", "(", "(", "h", ",", "w", ")", ")", "\n", "instances", ".", "gt_boxes", "=", "Boxes", "(", "torch", ".", "rand", "(", "0", ",", "4", ")", ")", "\n", "instances", ".", "gt_classes", "=", "torch", ".", "tensor", "(", "[", "]", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int64", ")", "\n", "instances", ".", "gt_masks", "=", "BitMasks", "(", "torch", ".", "rand", "(", "0", ",", "h", ",", "w", ")", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup._test_setup": [[15, 17], ["common.setup"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup"], ["    ", "def", "_test_setup", "(", "self", ",", "config_file", ")", ":", "\n", "        ", "setup", "(", "config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup.test_setup_configs": [[18, 22], ["common.get_config_files", "test_setup.TestSetup._test_setup"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup._test_setup"], ["", "def", "test_setup_configs", "(", "self", ")", ":", "\n", "        ", "config_files", "=", "get_config_files", "(", ")", "\n", "for", "config_file", "in", "config_files", ":", "\n", "            ", "self", ".", "_test_setup", "(", "config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup.test_setup_evolution_configs": [[23, 27], ["common.get_evolution_config_files", "test_setup.TestSetup._test_setup"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_evolution_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup._test_setup"], ["", "", "def", "test_setup_evolution_configs", "(", "self", ")", ":", "\n", "        ", "config_files", "=", "get_evolution_config_files", "(", ")", "\n", "for", "config_file", "in", "config_files", ":", "\n", "            ", "self", ".", "_test_setup", "(", "config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup.test_setup_hrnet_configs": [[28, 32], ["common.get_hrnet_config_files", "test_setup.TestSetup._test_setup"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_hrnet_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup._test_setup"], ["", "", "def", "test_setup_hrnet_configs", "(", "self", ")", ":", "\n", "        ", "config_files", "=", "get_hrnet_config_files", "(", ")", "\n", "for", "config_file", "in", "config_files", ":", "\n", "            ", "self", ".", "_test_setup", "(", "config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup.test_setup_quick_schedules_configs": [[33, 37], ["common.get_quick_schedules_config_files", "test_setup.TestSetup._test_setup"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.common.get_quick_schedules_config_files", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_setup.TestSetup._test_setup"], ["", "", "def", "test_setup_quick_schedules_configs", "(", "self", ")", ":", "\n", "        ", "config_files", "=", "get_quick_schedules_config_files", "(", ")", "\n", "for", "config_file", "in", "config_files", ":", "\n", "            ", "self", ".", "_test_setup", "(", "config_file", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.test_cse_annotations_accumulator_nodp": [[13, 18], ["test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_nodp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_nodp"], ["    ", "def", "test_cse_annotations_accumulator_nodp", "(", "self", ")", ":", "\n", "        ", "instances_lst", "=", "[", "\n", "self", ".", "_create_instances_nodp", "(", ")", ",", "\n", "]", "\n", "self", ".", "_test_template", "(", "instances_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.test_cse_annotations_accumulator_sparsedp": [[19, 24], ["test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_sparsedp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_sparsedp"], ["", "def", "test_cse_annotations_accumulator_sparsedp", "(", "self", ")", ":", "\n", "        ", "instances_lst", "=", "[", "\n", "self", ".", "_create_instances_sparsedp", "(", ")", ",", "\n", "]", "\n", "self", ".", "_test_template", "(", "instances_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.test_cse_annotations_accumulator_fulldp": [[25, 30], ["test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_fulldp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_fulldp"], ["", "def", "test_cse_annotations_accumulator_fulldp", "(", "self", ")", ":", "\n", "        ", "instances_lst", "=", "[", "\n", "self", ".", "_create_instances_fulldp", "(", ")", ",", "\n", "]", "\n", "self", ".", "_test_template", "(", "instances_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.test_cse_annotations_accumulator_combined": [[31, 38], ["test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_nodp", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_sparsedp", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_fulldp"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_nodp", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_sparsedp", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_fulldp"], ["", "def", "test_cse_annotations_accumulator_combined", "(", "self", ")", ":", "\n", "        ", "instances_lst", "=", "[", "\n", "self", ".", "_create_instances_nodp", "(", ")", ",", "\n", "self", ".", "_create_instances_sparsedp", "(", ")", ",", "\n", "self", ".", "_create_instances_fulldp", "(", ")", ",", "\n", "]", "\n", "self", ".", "_test_template", "(", "instances_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._test_template": [[39, 45], ["densepose.modeling.losses.embed_utils.CseAnnotationsAccumulator", "densepose.modeling.losses.embed_utils.CseAnnotationsAccumulator.pack", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._check_correspondence", "densepose.modeling.losses.embed_utils.CseAnnotationsAccumulator.accumulate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.pack", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._check_correspondence", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate"], ["", "def", "_test_template", "(", "self", ",", "instances_lst", ")", ":", "\n", "        ", "acc", "=", "CseAnnotationsAccumulator", "(", ")", "\n", "for", "instances", "in", "instances_lst", ":", "\n", "            ", "acc", ".", "accumulate", "(", "instances", ")", "\n", "", "packed_anns", "=", "acc", ".", "pack", "(", ")", "\n", "self", ".", "_check_correspondence", "(", "packed_anns", ",", "instances_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_nodp": [[46, 69], ["detectron2.structures.Instances", "detectron2.structures.Boxes", "detectron2.structures.Boxes", "torch.as_tensor", "torch.as_tensor"], "methods", ["None"], ["", "def", "_create_instances_nodp", "(", "self", ")", ":", "\n", "        ", "image_shape", "=", "(", "480", ",", "640", ")", "\n", "instances", "=", "Instances", "(", "image_shape", ")", "\n", "instances", ".", "gt_boxes", "=", "Boxes", "(", "\n", "torch", ".", "as_tensor", "(", "\n", "[", "\n", "[", "40.0", ",", "40.0", ",", "140.0", ",", "140.0", "]", ",", "\n", "[", "160.0", ",", "160.0", ",", "270.0", ",", "270.0", "]", ",", "\n", "[", "40.0", ",", "160.0", ",", "160.0", ",", "280.0", "]", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "instances", ".", "proposal_boxes", "=", "Boxes", "(", "\n", "torch", ".", "as_tensor", "(", "\n", "[", "\n", "[", "41.0", ",", "39.0", ",", "142.0", ",", "138.0", "]", ",", "\n", "[", "161.0", ",", "159.0", ",", "272.0", ",", "268.0", "]", ",", "\n", "[", "41.0", ",", "159.0", ",", "162.0", ",", "278.0", "]", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "# do not add gt_densepose", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_sparsedp": [[70, 110], ["detectron2.structures.Instances", "detectron2.structures.Boxes", "detectron2.structures.Boxes", "densepose.structures.DensePoseList", "torch.as_tensor", "torch.as_tensor", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data"], ["", "def", "_create_instances_sparsedp", "(", "self", ")", ":", "\n", "        ", "image_shape", "=", "(", "540", ",", "720", ")", "\n", "instances", "=", "Instances", "(", "image_shape", ")", "\n", "instances", ".", "gt_boxes", "=", "Boxes", "(", "\n", "torch", ".", "as_tensor", "(", "\n", "[", "\n", "[", "50.0", ",", "50.0", ",", "130.0", ",", "130.0", "]", ",", "\n", "[", "150.0", ",", "150.0", ",", "240.0", ",", "240.0", "]", ",", "\n", "[", "50.0", ",", "150.0", ",", "230.0", ",", "330.0", "]", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "instances", ".", "proposal_boxes", "=", "Boxes", "(", "\n", "torch", ".", "as_tensor", "(", "\n", "[", "\n", "[", "49.0", ",", "51.0", ",", "131.0", ",", "129.0", "]", ",", "\n", "[", "151.0", ",", "149.0", ",", "241.0", ",", "239.0", "]", ",", "\n", "[", "51.0", ",", "149.0", ",", "232.0", ",", "329.0", "]", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "instances", ".", "gt_densepose", "=", "DensePoseList", "(", "\n", "[", "\n", "None", ",", "\n", "self", ".", "_create_dp_data", "(", "\n", "{", "\n", "\"dp_x\"", ":", "[", "81.69", ",", "153.47", ",", "151.00", "]", ",", "\n", "\"dp_y\"", ":", "[", "162.24", ",", "128.71", ",", "113.81", "]", ",", "\n", "\"dp_vertex\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"ref_model\"", ":", "\"zebra_5002\"", ",", "\n", "\"dp_masks\"", ":", "[", "]", ",", "\n", "}", ",", "\n", "{", "\"c\"", ":", "(", "166", ",", "133", ")", ",", "\"r\"", ":", "64", "}", ",", "\n", ")", ",", "\n", "None", ",", "\n", "]", ",", "\n", "instances", ".", "gt_boxes", ",", "\n", "image_shape", ",", "\n", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_instances_fulldp": [[111, 169], ["detectron2.structures.Instances", "detectron2.structures.Boxes", "detectron2.structures.Boxes", "densepose.structures.DensePoseList", "torch.as_tensor", "torch.as_tensor", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data"], ["", "def", "_create_instances_fulldp", "(", "self", ")", ":", "\n", "        ", "image_shape", "=", "(", "680", ",", "840", ")", "\n", "instances", "=", "Instances", "(", "image_shape", ")", "\n", "instances", ".", "gt_boxes", "=", "Boxes", "(", "\n", "torch", ".", "as_tensor", "(", "\n", "[", "\n", "[", "65.0", ",", "55.0", ",", "165.0", ",", "155.0", "]", ",", "\n", "[", "170.0", ",", "175.0", ",", "275.0", ",", "280.0", "]", ",", "\n", "[", "55.0", ",", "165.0", ",", "165.0", ",", "275.0", "]", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "instances", ".", "proposal_boxes", "=", "Boxes", "(", "\n", "torch", ".", "as_tensor", "(", "\n", "[", "\n", "[", "66.0", ",", "54.0", ",", "166.0", ",", "154.0", "]", ",", "\n", "[", "171.0", ",", "174.0", ",", "276.0", ",", "279.0", "]", ",", "\n", "[", "56.0", ",", "164.0", ",", "166.0", ",", "274.0", "]", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "instances", ".", "gt_densepose", "=", "DensePoseList", "(", "\n", "[", "\n", "self", ".", "_create_dp_data", "(", "\n", "{", "\n", "\"dp_x\"", ":", "[", "149.99", ",", "198.62", ",", "157.59", "]", ",", "\n", "\"dp_y\"", ":", "[", "170.74", ",", "197.73", ",", "123.12", "]", ",", "\n", "\"dp_vertex\"", ":", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "\"ref_model\"", ":", "\"cat_5001\"", ",", "\n", "\"dp_masks\"", ":", "[", "]", ",", "\n", "}", ",", "\n", "{", "\"c\"", ":", "(", "100", ",", "100", ")", ",", "\"r\"", ":", "50", "}", ",", "\n", ")", ",", "\n", "self", ".", "_create_dp_data", "(", "\n", "{", "\n", "\"dp_x\"", ":", "[", "234.53", ",", "116.72", ",", "71.66", "]", ",", "\n", "\"dp_y\"", ":", "[", "107.53", ",", "11.31", ",", "142.32", "]", ",", "\n", "\"dp_vertex\"", ":", "[", "6", ",", "7", ",", "8", "]", ",", "\n", "\"ref_model\"", ":", "\"dog_5002\"", ",", "\n", "\"dp_masks\"", ":", "[", "]", ",", "\n", "}", ",", "\n", "{", "\"c\"", ":", "(", "200", ",", "150", ")", ",", "\"r\"", ":", "40", "}", ",", "\n", ")", ",", "\n", "self", ".", "_create_dp_data", "(", "\n", "{", "\n", "\"dp_x\"", ":", "[", "225.54", ",", "202.61", ",", "135.90", "]", ",", "\n", "\"dp_y\"", ":", "[", "167.46", ",", "181.00", ",", "211.47", "]", ",", "\n", "\"dp_vertex\"", ":", "[", "9", ",", "10", ",", "11", "]", ",", "\n", "\"ref_model\"", ":", "\"elephant_5002\"", ",", "\n", "\"dp_masks\"", ":", "[", "]", ",", "\n", "}", ",", "\n", "{", "\"c\"", ":", "(", "100", ",", "200", ")", ",", "\"r\"", ":", "45", "}", ",", "\n", ")", ",", "\n", "]", ",", "\n", "instances", ".", "gt_boxes", ",", "\n", "image_shape", ",", "\n", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._create_dp_data": [[170, 178], ["densepose.structures.DensePoseDataRelative"], "methods", ["None"], ["", "def", "_create_dp_data", "(", "self", ",", "anns", ",", "blob_def", "=", "None", ")", ":", "\n", "        ", "dp_data", "=", "DensePoseDataRelative", "(", "anns", ")", "\n", "if", "blob_def", "is", "not", "None", ":", "\n", "            ", "dp_data", ".", "segm", "[", "\n", "blob_def", "[", "\"c\"", "]", "[", "0", "]", "-", "blob_def", "[", "\"r\"", "]", ":", "blob_def", "[", "\"c\"", "]", "[", "0", "]", "+", "blob_def", "[", "\"r\"", "]", ",", "\n", "blob_def", "[", "\"c\"", "]", "[", "1", "]", "-", "blob_def", "[", "\"r\"", "]", ":", "blob_def", "[", "\"c\"", "]", "[", "1", "]", "+", "blob_def", "[", "\"r\"", "]", ",", "\n", "]", "=", "1", "\n", "", "return", "dp_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_cse_annotations_accumulator.TestCseAnnotationsAccumulator._check_correspondence": [[179, 241], ["detectron2.structures.BoxMode.convert", "detectron2.structures.BoxMode.convert", "enumerate", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertIsNone", "packed_anns.bbox_xywh_gt.clone", "packed_anns.bbox_xywh_est.clone", "hasattr", "len", "len", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertTrue", "test_cse_annotations_accumulator.TestCseAnnotationsAccumulator.assertEqual", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "def", "_check_correspondence", "(", "self", ",", "packed_anns", ",", "instances_lst", ")", ":", "\n", "        ", "instance_idx", "=", "0", "\n", "data_idx", "=", "0", "\n", "pt_offset", "=", "0", "\n", "if", "packed_anns", "is", "not", "None", ":", "\n", "            ", "bbox_xyxy_gt", "=", "BoxMode", ".", "convert", "(", "\n", "packed_anns", ".", "bbox_xywh_gt", ".", "clone", "(", ")", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", "\n", ")", "\n", "bbox_xyxy_est", "=", "BoxMode", ".", "convert", "(", "\n", "packed_anns", ".", "bbox_xywh_est", ".", "clone", "(", ")", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", "\n", ")", "\n", "", "for", "instances", "in", "instances_lst", ":", "\n", "            ", "if", "not", "hasattr", "(", "instances", ",", "\"gt_densepose\"", ")", ":", "\n", "                ", "instance_idx", "+=", "len", "(", "instances", ")", "\n", "continue", "\n", "", "for", "i", ",", "dp_data", "in", "enumerate", "(", "instances", ".", "gt_densepose", ")", ":", "\n", "                ", "if", "dp_data", "is", "None", ":", "\n", "                    ", "instance_idx", "+=", "1", "\n", "continue", "\n", "", "n_pts", "=", "len", "(", "dp_data", ".", "x", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "dp_data", ".", "x", ",", "packed_anns", ".", "x_gt", "[", "pt_offset", ":", "pt_offset", "+", "n_pts", "]", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "dp_data", ".", "y", ",", "packed_anns", ".", "y_gt", "[", "pt_offset", ":", "pt_offset", "+", "n_pts", "]", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "dp_data", ".", "segm", ",", "packed_anns", ".", "coarse_segm_gt", "[", "data_idx", "]", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "\n", "torch", ".", "ones", "(", "n_pts", ",", "dtype", "=", "torch", ".", "long", ")", "*", "dp_data", ".", "mesh_id", ",", "\n", "packed_anns", ".", "vertex_mesh_ids_gt", "[", "pt_offset", ":", "pt_offset", "+", "n_pts", "]", ",", "\n", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "\n", "dp_data", ".", "vertex_ids", ",", "packed_anns", ".", "vertex_ids_gt", "[", "pt_offset", ":", "pt_offset", "+", "n_pts", "]", "\n", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "instances", ".", "gt_boxes", ".", "tensor", "[", "i", "]", ",", "bbox_xyxy_gt", "[", "data_idx", "]", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "instances", ".", "proposal_boxes", ".", "tensor", "[", "i", "]", ",", "bbox_xyxy_est", "[", "data_idx", "]", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "\n", "torch", ".", "ones", "(", "n_pts", ",", "dtype", "=", "torch", ".", "long", ")", "*", "data_idx", ",", "\n", "packed_anns", ".", "point_bbox_with_dp_indices", "[", "pt_offset", ":", "pt_offset", "+", "n_pts", "]", ",", "\n", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "\n", "torch", ".", "ones", "(", "n_pts", ",", "dtype", "=", "torch", ".", "long", ")", "*", "instance_idx", ",", "\n", "packed_anns", ".", "point_bbox_indices", "[", "pt_offset", ":", "pt_offset", "+", "n_pts", "]", ",", "\n", ")", "\n", ")", "\n", "self", ".", "assertEqual", "(", "instance_idx", ",", "packed_anns", ".", "bbox_indices", "[", "data_idx", "]", ")", "\n", "pt_offset", "+=", "n_pts", "\n", "instance_idx", "+=", "1", "\n", "data_idx", "+=", "1", "\n", "", "", "if", "data_idx", "==", "0", ":", "\n", "            ", "self", ".", "assertIsNone", "(", "packed_anns", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.TestSingleProcessRamTensorStorage.test_read_write_1": [[22, 50], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "range", "densepose.evaluation.tensor_storage.SingleProcessRamTensorStorage", "range", "range", "densepose.evaluation.tensor_storage.SizeData", "densepose.evaluation.tensor_storage.SizeData", "data_elts.append", "io.BytesIO", "densepose.evaluation.tensor_storage.SingleProcessRamTensorStorage.put", "test_tensor_storage.TestSingleProcessRamTensorStorage.assertEqual", "densepose.evaluation.tensor_storage.SingleProcessRamTensorStorage.get", "test_tensor_storage.TestSingleProcessRamTensorStorage.assertEqual", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "len", "len", "test_tensor_storage.TestSingleProcessRamTensorStorage.assertTrue", "test_tensor_storage.TestSingleProcessRamTensorStorage.assertEqual", "test_tensor_storage.TestSingleProcessRamTensorStorage.assertEqual", "test_tensor_storage.TestSingleProcessRamTensorStorage.assertTrue", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["    ", "def", "test_read_write_1", "(", "self", ")", ":", "\n", "        ", "schema", "=", "{", "\n", "\"tf\"", ":", "SizeData", "(", "dtype", "=", "\"float32\"", ",", "shape", "=", "(", "112", ",", "112", ")", ")", ",", "\n", "\"ti\"", ":", "SizeData", "(", "dtype", "=", "\"int32\"", ",", "shape", "=", "(", "4", ",", "64", ",", "64", ")", ")", ",", "\n", "}", "\n", "# generate data which corresponds to the schema", "\n", "data_elts", "=", "[", "]", "\n", "torch", ".", "manual_seed", "(", "23", ")", "\n", "for", "_i", "in", "range", "(", "3", ")", ":", "\n", "            ", "data_elt", "=", "{", "\n", "\"tf\"", ":", "torch", ".", "rand", "(", "(", "112", ",", "112", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "\"ti\"", ":", "(", "torch", ".", "rand", "(", "4", ",", "64", ",", "64", ")", "*", "1000", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "}", "\n", "data_elts", ".", "append", "(", "data_elt", ")", "\n", "", "storage", "=", "SingleProcessRamTensorStorage", "(", "schema", ",", "io", ".", "BytesIO", "(", ")", ")", "\n", "# write data to the storage", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "record_id", "=", "storage", ".", "put", "(", "data_elts", "[", "i", "]", ")", "\n", "self", ".", "assertEqual", "(", "record_id", ",", "i", ")", "\n", "# read data from the storage", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "record", "=", "storage", ".", "get", "(", "i", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "record", ")", ",", "len", "(", "schema", ")", ")", "\n", "for", "field_name", "in", "schema", ":", "\n", "                ", "self", ".", "assertTrue", "(", "field_name", "in", "record", ")", "\n", "self", ".", "assertEqual", "(", "data_elts", "[", "i", "]", "[", "field_name", "]", ".", "shape", ",", "record", "[", "field_name", "]", ".", "shape", ")", "\n", "self", ".", "assertEqual", "(", "data_elts", "[", "i", "]", "[", "field_name", "]", ".", "dtype", ",", "record", "[", "field_name", "]", ".", "dtype", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "data_elts", "[", "i", "]", "[", "field_name", "]", ",", "record", "[", "field_name", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.TestSingleProcessFileTensorStorage.test_read_write_1": [[53, 85], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "range", "densepose.evaluation.tensor_storage.SizeData", "densepose.evaluation.tensor_storage.SizeData", "data_elts.append", "tempfile.NamedTemporaryFile", "densepose.evaluation.tensor_storage.SingleProcessFileTensorStorage", "range", "hFile.seek", "densepose.evaluation.tensor_storage.SingleProcessFileTensorStorage", "range", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "densepose.evaluation.tensor_storage.SingleProcessFileTensorStorage.put", "test_tensor_storage.TestSingleProcessFileTensorStorage.assertEqual", "densepose.evaluation.tensor_storage.SingleProcessFileTensorStorage.get", "test_tensor_storage.TestSingleProcessFileTensorStorage.assertEqual", "len", "len", "test_tensor_storage.TestSingleProcessFileTensorStorage.assertTrue", "test_tensor_storage.TestSingleProcessFileTensorStorage.assertEqual", "test_tensor_storage.TestSingleProcessFileTensorStorage.assertEqual", "test_tensor_storage.TestSingleProcessFileTensorStorage.assertTrue", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["    ", "def", "test_read_write_1", "(", "self", ")", ":", "\n", "        ", "schema", "=", "{", "\n", "\"tf\"", ":", "SizeData", "(", "dtype", "=", "\"float32\"", ",", "shape", "=", "(", "112", ",", "112", ")", ")", ",", "\n", "\"ti\"", ":", "SizeData", "(", "dtype", "=", "\"int32\"", ",", "shape", "=", "(", "4", ",", "64", ",", "64", ")", ")", ",", "\n", "}", "\n", "# generate data which corresponds to the schema", "\n", "data_elts", "=", "[", "]", "\n", "torch", ".", "manual_seed", "(", "23", ")", "\n", "for", "_i", "in", "range", "(", "3", ")", ":", "\n", "            ", "data_elt", "=", "{", "\n", "\"tf\"", ":", "torch", ".", "rand", "(", "(", "112", ",", "112", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "\"ti\"", ":", "(", "torch", ".", "rand", "(", "4", ",", "64", ",", "64", ")", "*", "1000", ")", ".", "to", "(", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "}", "\n", "data_elts", ".", "append", "(", "data_elt", ")", "\n", "# WARNING: opens the file several times! may not work on all platforms", "\n", "", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "hFile", ":", "\n", "            ", "storage", "=", "SingleProcessFileTensorStorage", "(", "schema", ",", "hFile", ".", "name", ",", "\"wb\"", ")", "\n", "# write data to the storage", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                ", "record_id", "=", "storage", ".", "put", "(", "data_elts", "[", "i", "]", ")", "\n", "self", ".", "assertEqual", "(", "record_id", ",", "i", ")", "\n", "", "hFile", ".", "seek", "(", "0", ")", "\n", "storage", "=", "SingleProcessFileTensorStorage", "(", "schema", ",", "hFile", ".", "name", ",", "\"rb\"", ")", "\n", "# read data from the storage", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                ", "record", "=", "storage", ".", "get", "(", "i", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "record", ")", ",", "len", "(", "schema", ")", ")", "\n", "for", "field_name", "in", "schema", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "field_name", "in", "record", ")", "\n", "self", ".", "assertEqual", "(", "data_elts", "[", "i", "]", "[", "field_name", "]", ".", "shape", ",", "record", "[", "field_name", "]", ".", "shape", ")", "\n", "self", ".", "assertEqual", "(", "data_elts", "[", "i", "]", "[", "field_name", "]", ".", "dtype", ",", "record", "[", "field_name", "]", ".", "dtype", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "data_elts", "[", "i", "]", "[", "field_name", "]", ",", "record", "[", "field_name", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.TestMultiProcessRamTensorStorage.test_read_write_1": [[245, 247], ["test_tensor_storage.launch"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.launch"], ["    ", "def", "test_read_write_1", "(", "self", ")", ":", "\n", "        ", "launch", "(", "ram_read_write_worker", ",", "8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.TestMultiProcessFileTensorStorage.test_read_write_1": [[250, 257], ["contextlib.ExitStack", "test_tensor_storage.launch", "stack.enter_context", "range", "tempfile.NamedTemporaryFile"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.launch"], ["    ", "def", "test_read_write_1", "(", "self", ")", ":", "\n", "        ", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "# WARNING: opens the files several times! may not work on all platforms", "\n", "            ", "rank_to_fpath", "=", "{", "\n", "i", ":", "stack", ".", "enter_context", "(", "tempfile", ".", "NamedTemporaryFile", "(", ")", ")", ".", "name", "for", "i", "in", "range", "(", "8", ")", "\n", "}", "\n", "launch", "(", "file_read_write_worker", ",", "8", ",", "(", "rank_to_fpath", ",", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage._find_free_port": [[87, 100], ["socket.socket", "socket.socket.bind", "socket.socket.close", "socket.socket.getsockname"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["", "", "", "", "", "def", "_find_free_port", "(", ")", ":", "\n", "    ", "\"\"\"\n    Copied from detectron2/engine/launch.py\n    \"\"\"", "\n", "import", "socket", "\n", "\n", "sock", "=", "socket", ".", "socket", "(", "socket", ".", "AF_INET", ",", "socket", ".", "SOCK_STREAM", ")", "\n", "# Binding to port 0 will cause the OS to find an available port for us", "\n", "sock", ".", "bind", "(", "(", "\"\"", ",", "0", ")", ")", "\n", "port", "=", "sock", ".", "getsockname", "(", ")", "[", "1", "]", "\n", "sock", ".", "close", "(", ")", "\n", "# NOTE: there is still a chance the port could be taken by other processes.", "\n", "return", "port", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.launch": [[102, 108], ["test_tensor_storage._find_free_port", "torch.spawn", "test_tensor_storage.ram_read_write_worker", "test_tensor_storage.file_read_write_worker"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage._find_free_port", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.ram_read_write_worker", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.file_read_write_worker"], ["", "def", "launch", "(", "main_func", ",", "nprocs", ",", "args", "=", "(", ")", ")", ":", "\n", "    ", "port", "=", "_find_free_port", "(", ")", "\n", "dist_url", "=", "f\"tcp://127.0.0.1:{port}\"", "\n", "# dist_url = \"env://\"", "\n", "mp", ".", "spawn", "(", "\n", "distributed_worker", ",", "nprocs", "=", "nprocs", ",", "args", "=", "(", "main_func", ",", "nprocs", ",", "dist_url", ",", "args", ")", ",", "daemon", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.distributed_worker": [[111, 120], ["torch.init_process_group", "detectron2.utils.comm.synchronize", "torch.new_group", "main_func", "list", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["", "def", "distributed_worker", "(", "local_rank", ",", "main_func", ",", "nprocs", ",", "dist_url", ",", "args", ")", ":", "\n", "    ", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"gloo\"", ",", "init_method", "=", "dist_url", ",", "world_size", "=", "nprocs", ",", "rank", "=", "local_rank", "\n", ")", "\n", "comm", ".", "synchronize", "(", ")", "\n", "assert", "comm", ".", "_LOCAL_PROCESS_GROUP", "is", "None", "\n", "pg", "=", "dist", ".", "new_group", "(", "list", "(", "range", "(", "nprocs", ")", ")", ")", "\n", "comm", ".", "_LOCAL_PROCESS_GROUP", "=", "pg", "\n", "main_func", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.ram_read_write_worker": [[122, 177], ["densepose.evaluation.tensor_storage.SingleProcessRamTensorStorage", "detectron2.utils.comm.get_world_size", "detectron2.utils.comm.get_rank", "range", "range", "detectron2.utils.comm.synchronize", "densepose.evaluation.tensor_storage.storage_gather", "range", "densepose.evaluation.tensor_storage.SizeData", "densepose.evaluation.tensor_storage.SizeData", "io.BytesIO", "data_elts.append", "densepose.evaluation.tensor_storage.SingleProcessRamTensorStorage.put", "range", "densepose.evaluation.tensor_storage.storage_gather.get", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "len", "torch.allclose", "torch.allclose", "torch.allclose", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.storage_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "ram_read_write_worker", "(", ")", ":", "\n", "    ", "schema", "=", "{", "\n", "\"tf\"", ":", "SizeData", "(", "dtype", "=", "\"float32\"", ",", "shape", "=", "(", "112", ",", "112", ")", ")", ",", "\n", "\"ti\"", ":", "SizeData", "(", "dtype", "=", "\"int32\"", ",", "shape", "=", "(", "4", ",", "64", ",", "64", ")", ")", ",", "\n", "}", "\n", "storage", "=", "SingleProcessRamTensorStorage", "(", "schema", ",", "io", ".", "BytesIO", "(", ")", ")", "\n", "world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "data_elts", "=", "[", "]", "\n", "# prepare different number of tensors in different processes", "\n", "for", "i", "in", "range", "(", "rank", "+", "1", ")", ":", "\n", "        ", "data_elt", "=", "{", "\n", "\"tf\"", ":", "torch", ".", "ones", "(", "(", "112", ",", "112", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "*", "(", "rank", "+", "i", "*", "world_size", ")", ",", "\n", "\"ti\"", ":", "torch", ".", "ones", "(", "(", "4", ",", "64", ",", "64", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "*", "(", "rank", "+", "i", "*", "world_size", ")", ",", "\n", "}", "\n", "data_elts", ".", "append", "(", "data_elt", ")", "\n", "# write data to the single process storage", "\n", "", "for", "i", "in", "range", "(", "rank", "+", "1", ")", ":", "\n", "        ", "record_id", "=", "storage", ".", "put", "(", "data_elts", "[", "i", "]", ")", "\n", "assert", "record_id", "==", "i", ",", "f\"Process {rank}: record ID {record_id}, expected {i}\"", "\n", "", "comm", ".", "synchronize", "(", ")", "\n", "# gather all data in process rank 0", "\n", "multi_storage", "=", "storage_gather", "(", "storage", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "        ", "return", "\n", "# read and check data from the multiprocess storage", "\n", "", "for", "j", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "j", ")", ":", "\n", "            ", "record", "=", "multi_storage", ".", "get", "(", "j", ",", "i", ")", "\n", "record_gt", "=", "{", "\n", "\"tf\"", ":", "torch", ".", "ones", "(", "(", "112", ",", "112", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "*", "(", "j", "+", "i", "*", "world_size", ")", ",", "\n", "\"ti\"", ":", "torch", ".", "ones", "(", "(", "4", ",", "64", ",", "64", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "*", "(", "j", "+", "i", "*", "world_size", ")", ",", "\n", "}", "\n", "assert", "len", "(", "record", ")", "==", "len", "(", "schema", ")", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"expected {len(schema)} fields in the record, got {len(record)}\"", "\n", ")", "\n", "for", "field_name", "in", "schema", ":", "\n", "                ", "assert", "field_name", "in", "record", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name} not in the record\"", "\n", ")", "\n", "\n", "assert", "record_gt", "[", "field_name", "]", ".", "shape", "==", "record", "[", "field_name", "]", ".", "shape", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name}, expected shape {record_gt[field_name].shape} \"", "\n", "f\"got {record[field_name].shape}\"", "\n", ")", "\n", "assert", "record_gt", "[", "field_name", "]", ".", "dtype", "==", "record", "[", "field_name", "]", ".", "dtype", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name}, expected dtype {record_gt[field_name].dtype} \"", "\n", "f\"got {record[field_name].dtype}\"", "\n", ")", "\n", "assert", "torch", ".", "allclose", "(", "record_gt", "[", "field_name", "]", ",", "record", "[", "field_name", "]", ")", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name}, tensors are not close enough:\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_tensor_storage.file_read_write_worker": [[183, 238], ["detectron2.utils.comm.get_world_size", "detectron2.utils.comm.get_rank", "densepose.evaluation.tensor_storage.SingleProcessFileTensorStorage", "range", "range", "detectron2.utils.comm.synchronize", "densepose.evaluation.tensor_storage.storage_gather", "range", "densepose.evaluation.tensor_storage.SizeData", "densepose.evaluation.tensor_storage.SizeData", "data_elts.append", "densepose.evaluation.tensor_storage.SingleProcessFileTensorStorage.put", "range", "densepose.evaluation.tensor_storage.storage_gather.get", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "len", "torch.allclose", "torch.allclose", "torch.allclose", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_world_size", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.synchronize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.storage_gather", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.tensor_storage.MultiProcessTensorStorage.put", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "", "", "def", "file_read_write_worker", "(", "rank_to_fpath", ")", ":", "\n", "    ", "schema", "=", "{", "\n", "\"tf\"", ":", "SizeData", "(", "dtype", "=", "\"float32\"", ",", "shape", "=", "(", "112", ",", "112", ")", ")", ",", "\n", "\"ti\"", ":", "SizeData", "(", "dtype", "=", "\"int32\"", ",", "shape", "=", "(", "4", ",", "64", ",", "64", ")", ")", ",", "\n", "}", "\n", "world_size", "=", "comm", ".", "get_world_size", "(", ")", "\n", "rank", "=", "comm", ".", "get_rank", "(", ")", "\n", "storage", "=", "SingleProcessFileTensorStorage", "(", "schema", ",", "rank_to_fpath", "[", "rank", "]", ",", "\"wb\"", ")", "\n", "data_elts", "=", "[", "]", "\n", "# prepare different number of tensors in different processes", "\n", "for", "i", "in", "range", "(", "rank", "+", "1", ")", ":", "\n", "        ", "data_elt", "=", "{", "\n", "\"tf\"", ":", "torch", ".", "ones", "(", "(", "112", ",", "112", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "*", "(", "rank", "+", "i", "*", "world_size", ")", ",", "\n", "\"ti\"", ":", "torch", ".", "ones", "(", "(", "4", ",", "64", ",", "64", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "*", "(", "rank", "+", "i", "*", "world_size", ")", ",", "\n", "}", "\n", "data_elts", ".", "append", "(", "data_elt", ")", "\n", "# write data to the single process storage", "\n", "", "for", "i", "in", "range", "(", "rank", "+", "1", ")", ":", "\n", "        ", "record_id", "=", "storage", ".", "put", "(", "data_elts", "[", "i", "]", ")", "\n", "assert", "record_id", "==", "i", ",", "f\"Process {rank}: record ID {record_id}, expected {i}\"", "\n", "", "comm", ".", "synchronize", "(", ")", "\n", "# gather all data in process rank 0", "\n", "multi_storage", "=", "storage_gather", "(", "storage", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "        ", "return", "\n", "# read and check data from the multiprocess storage", "\n", "", "for", "j", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "j", ")", ":", "\n", "            ", "record", "=", "multi_storage", ".", "get", "(", "j", ",", "i", ")", "\n", "record_gt", "=", "{", "\n", "\"tf\"", ":", "torch", ".", "ones", "(", "(", "112", ",", "112", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "*", "(", "j", "+", "i", "*", "world_size", ")", ",", "\n", "\"ti\"", ":", "torch", ".", "ones", "(", "(", "4", ",", "64", ",", "64", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "*", "(", "j", "+", "i", "*", "world_size", ")", ",", "\n", "}", "\n", "assert", "len", "(", "record", ")", "==", "len", "(", "schema", ")", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"expected {len(schema)} fields in the record, got {len(record)}\"", "\n", ")", "\n", "for", "field_name", "in", "schema", ":", "\n", "                ", "assert", "field_name", "in", "record", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name} not in the record\"", "\n", ")", "\n", "\n", "assert", "record_gt", "[", "field_name", "]", ".", "shape", "==", "record", "[", "field_name", "]", ".", "shape", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name}, expected shape {record_gt[field_name].shape} \"", "\n", "f\"got {record[field_name].shape}\"", "\n", ")", "\n", "assert", "record_gt", "[", "field_name", "]", ".", "dtype", "==", "record", "[", "field_name", "]", ".", "dtype", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name}, expected dtype {record_gt[field_name].dtype} \"", "\n", "f\"got {record[field_name].dtype}\"", "\n", ")", "\n", "assert", "torch", ".", "allclose", "(", "record_gt", "[", "field_name", "]", ",", "record", "[", "field_name", "]", ")", ",", "(", "\n", "f\"Process {rank}: multi storage record, rank {j}, id {i}: \"", "\n", "f\"field {field_name}, tensors are not close enough:\"", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_structures.TestStructures.test_normalized_coords_transform": [[9, 26], ["densepose.structures.normalized_coords_transform", "test_structures.TestStructures.assertEqual", "test_structures.TestStructures.assertEqual", "test_structures.TestStructures.assertEqual", "test_structures.TestStructures.assertEqual", "densepose.structures.normalized_coords_transform.", "densepose.structures.normalized_coords_transform.", "densepose.structures.normalized_coords_transform.", "densepose.structures.normalized_coords_transform."], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.transform_data.normalized_coords_transform"], ["    ", "def", "test_normalized_coords_transform", "(", "self", ")", ":", "\n", "        ", "bbox", "=", "(", "32", ",", "24", ",", "288", ",", "216", ")", "\n", "x0", ",", "y0", ",", "w", ",", "h", "=", "bbox", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "x0", ",", "y0", ",", "x0", "+", "w", ",", "y0", "+", "h", "\n", "f", "=", "normalized_coords_transform", "(", "*", "bbox", ")", "\n", "# Top-left", "\n", "expected_p", ",", "actual_p", "=", "(", "-", "1", ",", "-", "1", ")", ",", "f", "(", "(", "xmin", ",", "ymin", ")", ")", "\n", "self", ".", "assertEqual", "(", "expected_p", ",", "actual_p", ")", "\n", "# Top-right", "\n", "expected_p", ",", "actual_p", "=", "(", "1", ",", "-", "1", ")", ",", "f", "(", "(", "xmax", ",", "ymin", ")", ")", "\n", "self", ".", "assertEqual", "(", "expected_p", ",", "actual_p", ")", "\n", "# Bottom-left", "\n", "expected_p", ",", "actual_p", "=", "(", "-", "1", ",", "1", ")", ",", "f", "(", "(", "xmin", ",", "ymax", ")", ")", "\n", "self", ".", "assertEqual", "(", "expected_p", ",", "actual_p", ")", "\n", "# Bottom-right", "\n", "expected_p", ",", "actual_p", "=", "(", "1", ",", "1", ")", ",", "f", "(", "(", "xmax", ",", "ymax", ")", ")", "\n", "self", ".", "assertEqual", "(", "expected_p", ",", "actual_p", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.TestVideoKeyframeDataset.test_read_keyframes_all": [[56, 66], ["test_video_keyframe_dataset.TestVideoKeyframeDataset.assertTrue", "test_video_keyframe_dataset.temp_video", "densepose.data.video.VideoKeyframeDataset", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "len", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.temp_video"], ["    ", "def", "test_read_keyframes_all", "(", "self", ")", ":", "\n", "        ", "with", "temp_video", "(", "60", ",", "300", ",", "300", ",", "5", ",", "video_codec", "=", "\"mpeg4\"", ")", "as", "(", "fname", ",", "data", ")", ":", "\n", "            ", "video_list", "=", "[", "fname", "]", "\n", "dataset", "=", "VideoKeyframeDataset", "(", "video_list", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "dataset", ")", ",", "1", ")", "\n", "data1", "=", "dataset", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "data1", ".", "shape", ",", "torch", ".", "Size", "(", "(", "5", ",", "300", ",", "300", ",", "3", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "data1", ".", "dtype", ",", "torch", ".", "uint8", ")", "\n", "return", "\n", "", "self", ".", "assertTrue", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.TestVideoKeyframeDataset.test_read_keyframes_with_selector": [[67, 79], ["test_video_keyframe_dataset.TestVideoKeyframeDataset.assertTrue", "test_video_keyframe_dataset.temp_video", "random.seed", "densepose.data.video.RandomKFramesSelector", "densepose.data.video.VideoKeyframeDataset", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "len", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.temp_video"], ["", "def", "test_read_keyframes_with_selector", "(", "self", ")", ":", "\n", "        ", "with", "temp_video", "(", "60", ",", "300", ",", "300", ",", "5", ",", "video_codec", "=", "\"mpeg4\"", ")", "as", "(", "fname", ",", "data", ")", ":", "\n", "            ", "video_list", "=", "[", "fname", "]", "\n", "random", ".", "seed", "(", "0", ")", "\n", "frame_selector", "=", "RandomKFramesSelector", "(", "3", ")", "\n", "dataset", "=", "VideoKeyframeDataset", "(", "video_list", ",", "frame_selector", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "dataset", ")", ",", "1", ")", "\n", "data1", "=", "dataset", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "data1", ".", "shape", ",", "torch", ".", "Size", "(", "(", "3", ",", "300", ",", "300", ",", "3", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "data1", ".", "dtype", ",", "torch", ".", "uint8", ")", "\n", "return", "\n", "", "self", ".", "assertTrue", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.TestVideoKeyframeDataset.test_read_keyframes_with_selector_with_transform": [[80, 93], ["test_video_keyframe_dataset.TestVideoKeyframeDataset.assertTrue", "test_video_keyframe_dataset.temp_video", "random.seed", "densepose.data.video.RandomKFramesSelector", "densepose.data.transform.ImageResizeTransform", "densepose.data.video.VideoKeyframeDataset", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "test_video_keyframe_dataset.TestVideoKeyframeDataset.assertEqual", "len", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.temp_video"], ["", "def", "test_read_keyframes_with_selector_with_transform", "(", "self", ")", ":", "\n", "        ", "with", "temp_video", "(", "60", ",", "300", ",", "300", ",", "5", ",", "video_codec", "=", "\"mpeg4\"", ")", "as", "(", "fname", ",", "data", ")", ":", "\n", "            ", "video_list", "=", "[", "fname", "]", "\n", "random", ".", "seed", "(", "0", ")", "\n", "frame_selector", "=", "RandomKFramesSelector", "(", "1", ")", "\n", "transform", "=", "ImageResizeTransform", "(", ")", "\n", "dataset", "=", "VideoKeyframeDataset", "(", "video_list", ",", "frame_selector", ",", "transform", ")", "\n", "data1", "=", "dataset", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "dataset", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "data1", ".", "shape", ",", "torch", ".", "Size", "(", "(", "1", ",", "3", ",", "800", ",", "800", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "data1", ".", "dtype", ",", "torch", ".", "float32", ")", "\n", "return", "\n", "", "self", ".", "assertTrue", "(", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset._create_video_frames": [[21, 30], ["torch.meshgrid", "range", "torch.stack", "torch.linspace", "torch.linspace", "data.append", "float", "torch.exp", "d.unsqueeze().repeat().byte", "float", "d.unsqueeze().repeat", "d.unsqueeze"], "function", ["None"], ["", "def", "_create_video_frames", "(", "num_frames", ",", "height", ",", "width", ")", ":", "\n", "    ", "y", ",", "x", "=", "torch", ".", "meshgrid", "(", "torch", ".", "linspace", "(", "-", "2", ",", "2", ",", "height", ")", ",", "torch", ".", "linspace", "(", "-", "2", ",", "2", ",", "width", ")", ")", "\n", "data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "xc", "=", "float", "(", "i", ")", "/", "num_frames", "\n", "yc", "=", "1", "-", "float", "(", "i", ")", "/", "(", "2", "*", "num_frames", ")", "\n", "d", "=", "torch", ".", "exp", "(", "-", "(", "(", "x", "-", "xc", ")", "**", "2", "+", "(", "y", "-", "yc", ")", "**", "2", ")", "/", "2", ")", "*", "255", "\n", "data", ".", "append", "(", "d", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "3", ")", ".", "byte", "(", ")", ")", "\n", "", "return", "torch", ".", "stack", "(", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset.temp_video": [[33, 52], ["test_video_keyframe_dataset._create_video_frames", "os.unlink", "tempfile.NamedTemporaryFile", "f.close", "torchvision.write_video", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tests.test_video_keyframe_dataset._create_video_frames", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "temp_video", "(", "num_frames", ",", "height", ",", "width", ",", "fps", ",", "lossless", "=", "False", ",", "video_codec", "=", "None", ",", "options", "=", "None", ")", ":", "\n", "    ", "if", "lossless", ":", "\n", "        ", "if", "video_codec", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"video_codec can't be specified together with lossless\"", ")", "\n", "", "if", "options", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"options can't be specified together with lossless\"", ")", "\n", "", "video_codec", "=", "\"libx264rgb\"", "\n", "options", "=", "{", "\"crf\"", ":", "\"0\"", "}", "\n", "", "if", "video_codec", "is", "None", ":", "\n", "        ", "video_codec", "=", "\"libx264\"", "\n", "", "if", "options", "is", "None", ":", "\n", "        ", "options", "=", "{", "}", "\n", "", "data", "=", "_create_video_frames", "(", "num_frames", ",", "height", ",", "width", ")", "\n", "with", "tempfile", ".", "NamedTemporaryFile", "(", "suffix", "=", "\".mp4\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "close", "(", ")", "\n", "io", ".", "write_video", "(", "f", ".", "name", ",", "data", ",", "fps", "=", "fps", ",", "video_codec", "=", "video_codec", ",", "options", "=", "options", ")", "\n", "yield", "f", ".", "name", ",", "data", "\n", "", "os", ".", "unlink", "(", "f", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DeepLab.train_net.Trainer.build_evaluator": [[50, 82], ["detectron2.evaluation.DatasetEvaluators", "detectron2.evaluation.DatasetEvaluators", "os.path.join", "detectron2.data.MetadataCatalog.get", "detectron2.data.MetadataCatalog.get", "detectron2.evaluation.SemSegEvaluator", "detectron2.evaluation.SemSegEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "len", "NotImplementedError", "len", "torch.cuda.device_count", "detectron2.get_rank", "detectron2.get_rank"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ",", "\n", "# this should be removed if we update BatchNorm stats", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n", "", "arguments", "=", "{", "}", "\n", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "\n", "save_to_disk", "=", "get_rank", "(", ")", "==", "0", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "\n", "cfg", ",", "model", ",", "optimizer", ",", "scheduler", ",", "output_dir", ",", "save_to_disk", "\n", ")", "\n", "extra_checkpoint_data", "=", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHT", ")", "\n", "arguments", ".", "update", "(", "extra_checkpoint_data", ")", "\n", "\n", "if", "search", ":", "\n", "        ", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "", "data_loader", "=", "make_data_loader", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "is_distributed", "=", "distributed", ",", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", ",", "\n", ")", "\n", "\n", "test_period", "=", "cfg", ".", "SOLVER", ".", "TEST_PERIOD", "\n", "if", "test_period", ">", "0", ":", "\n", "        ", "data_loader_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ",", "is_for_period", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_val", "=", "None", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DeepLab.train_net.Trainer.build_train_loader": [[83, 90], ["detectron2.data.build_detection_train_loader", "detectron2.data.build_detection_train_loader", "detectron2.data.DatasetMapper", "detectron2.data.DatasetMapper", "train_net.build_sem_seg_train_aug"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.build_sem_seg_train_aug"], ["\n", "", "checkpoint_period", "=", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", "\n", "loss_hist", "=", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DeepLab.train_net.Trainer.build_lr_scheduler": [[91, 98], ["detectron2.projects.deeplab.build_lr_scheduler", "detectron2.projects.deeplab.build_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler"], ["optimizer", ",", "\n", "scheduler", ",", "\n", "checkpointer", ",", "\n", "device", ",", "\n", "checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n", "search", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DeepLab.train_net.build_sem_seg_train_aug": [[23, 40], ["augs.append", "detectron2.ResizeShortestEdge", "augs.append", "detectron2.RandomFlip", "detectron2.RandomCrop_CategoryAreaConstraint"], "function", ["None"], ["from", "maskrcnn_benchmark", ".", "utils", ".", "comm", "import", "synchronize", ",", "get_rank", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "imports", "import", "import_file", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "logger", "import", "setup_logger", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "miscellaneous", "import", "mkdir", ",", "save_config", "\n", "\n", "# See if we can use apex.DistributedDataParallel instead of the torch default,", "\n", "# and enable mixed-precision via apex.amp", "\n", "try", ":", "\n", "    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for multi-precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n", "    ", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DeepLab.train_net.setup": [[100, 111], ["detectron2.config.get_cfg", "detectron2.projects.deeplab.add_deeplab_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.config.add_deeplab_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["\n", "return", "model", ",", "loss_hist", "\n", "\n", "\n", "", "def", "run_test", "(", "cfg", ",", "model", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "# TODO check if it helps", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"segm\"", ",", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DeepLab.train_net.main": [[113, 127], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test"], ["", "output_folders", "=", "[", "None", "]", "*", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "\n", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "if", "cfg", ".", "OUTPUT_DIR", ":", "\n", "        ", "for", "idx", ",", "dataset_name", "in", "enumerate", "(", "dataset_names", ")", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "mkdir", "(", "output_folder", ")", "\n", "output_folders", "[", "idx", "]", "=", "output_folder", "\n", "", "", "data_loaders_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ")", "\n", "for", "output_folder", ",", "dataset_name", ",", "data_loader_val", "in", "zip", "(", "output_folders", ",", "dataset_names", ",", "data_loaders_val", ")", ":", "\n", "        ", "results", "=", "inference", "(", "\n", "model", ",", "\n", "data_loader_val", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "box_only", "=", "False", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", "or", "cfg", ".", "MODEL", ".", "FCOS_ON", "or", "cfg", ".", "MODEL", ".", "RETINANET_ON", "else", "cfg", ".", "MODEL", ".", "RPN_ONLY", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.config.add_deeplab_config": [[5, 29], ["None"], "function", ["None"], ["import", "inspect", "\n", "import", "logging", "\n", "from", "fvcore", ".", "common", ".", "config", "import", "CfgNode", "as", "_CfgNode", "\n", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    ", "\"\"\"\n    The same as `fvcore.common.config.CfgNode`, but different in:\n\n    1. Use unsafe yaml loading by default.\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    2. Support config versioning.\n       When attempting to merge an old config, it will convert the old config automatically.\n    \"\"\"", "\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n", "# Note that the default value of allow_unsafe is changed to True", "\n", "", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.loss.DeepLabCE.__init__": [[20, 26], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["\n", "class", "RPNLossComputation", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    This class computes the RPN loss.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "proposal_matcher", ",", "fg_bg_sampler", ",", "box_coder", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.loss.DeepLabCE.forward": [[28, 41], ["int", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "pixel_losses.contiguous().view.contiguous().view.mean", "loss.DeepLabCE.criterion().contiguous().view", "pixel_losses.contiguous().view.contiguous().view.contiguous().view", "pixel_losses.contiguous().view.contiguous().view.mean", "loss.DeepLabCE.criterion", "pixel_losses.contiguous().view.contiguous().view.numel", "loss.DeepLabCE.criterion().contiguous", "pixel_losses.contiguous().view.contiguous().view.contiguous", "loss.DeepLabCE.criterion"], "methods", ["None"], ["        ", "\"\"\"\n        Arguments:\n            proposal_matcher (Matcher)\n            fg_bg_sampler (BalancedPositiveNegativeSampler)\n            box_coder (BoxCoder)\n        \"\"\"", "\n", "# self.target_preparator = target_preparator", "\n", "self", ".", "proposal_matcher", "=", "proposal_matcher", "\n", "self", ".", "fg_bg_sampler", "=", "fg_bg_sampler", "\n", "self", ".", "box_coder", "=", "box_coder", "\n", "self", ".", "copied_fields", "=", "[", "]", "\n", "self", ".", "generate_labels_func", "=", "generate_labels_func", "\n", "self", ".", "discard_cases", "=", "[", "'not_visibility'", ",", "'between_thresholds'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.resnet.DeepLabStem.__init__": [[20, 58], ["detectron2.layers.CNNBlockBase.__init__", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "fvcore.c2_msra_fill", "fvcore.c2_msra_fill", "fvcore.c2_msra_fill", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["\n", "import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "torch", "import", "nn", "\n", "\n", "from", "maskrcnn_benchmark", ".", "layers", "import", "FrozenBatchNorm2d", "\n", "from", "maskrcnn_benchmark", ".", "layers", "import", "Conv2d", "\n", "from", "maskrcnn_benchmark", ".", "layers", "import", "DFConv2d", "\n", "from", "maskrcnn_benchmark", ".", "modeling", ".", "make_layers", "import", "group_norm", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "registry", "import", "Registry", "\n", "\n", "\n", "# ResNet stage specification", "\n", "StageSpec", "=", "namedtuple", "(", "\n", "\"StageSpec\"", ",", "\n", "[", "\n", "\"index\"", ",", "# Index of the stage, eg 1, 2, ..,. 5", "\n", "\"block_count\"", ",", "# Number of residual blocks in the stage", "\n", "\"return_features\"", ",", "# True => return the last feature map from this stage", "\n", "]", ",", "\n", ")", "\n", "\n", "# -----------------------------------------------------------------------------", "\n", "# Standard ResNet models", "\n", "# -----------------------------------------------------------------------------", "\n", "# ResNet-50 (including all stages)", "\n", "ResNet50StagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "6", ",", "False", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-50 up to stage 4 (excludes stage 5)", "\n", "ResNet50StagesTo4", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "6", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-101 (including all stages)", "\n", "ResNet101StagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "23", ",", "False", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.resnet.DeepLabStem.forward": [[59, 68], ["resnet.DeepLabStem.conv1", "torch.relu_", "resnet.DeepLabStem.conv2", "torch.relu_", "resnet.DeepLabStem.conv3", "torch.relu_", "torch.max_pool2d"], "methods", ["None"], [")", "\n", "# ResNet-101 up to stage 4 (excludes stage 5)", "\n", "ResNet101StagesTo4", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "False", ")", ",", "(", "2", ",", "4", ",", "False", ")", ",", "(", "3", ",", "23", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-50-FPN (including all stages)", "\n", "ResNet50FPNStagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "True", ")", ",", "(", "2", ",", "4", ",", "True", ")", ",", "(", "3", ",", "6", ",", "True", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.resnet.build_resnet_deeplab_backbone": [[70, 159], ["detectron2.modeling.BACKBONE_REGISTRY.register", "max", "enumerate", "detectron2.modeling.backbone.resnet.ResNet().freeze", "detectron2.modeling.backbone.resnet.BasicStem", "range", "detectron2.modeling.backbone.resnet.ResNet.make_stage", "stages.append", "resnet.DeepLabStem", "ValueError", "stage_kargs.pop", "detectron2.modeling.backbone.resnet.ResNet"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage"], ["# ResNet-101-FPN (including all stages)", "\n", "ResNet101FPNStagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "True", ")", ",", "(", "2", ",", "4", ",", "True", ")", ",", "(", "3", ",", "23", ",", "True", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "# ResNet-152-FPN (including all stages)", "\n", "ResNet152FPNStagesTo5", "=", "tuple", "(", "\n", "StageSpec", "(", "index", "=", "i", ",", "block_count", "=", "c", ",", "return_features", "=", "r", ")", "\n", "for", "(", "i", ",", "c", ",", "r", ")", "in", "(", "(", "1", ",", "3", ",", "True", ")", ",", "(", "2", ",", "8", ",", "True", ")", ",", "(", "3", ",", "36", ",", "True", ")", ",", "(", "4", ",", "3", ",", "True", ")", ")", "\n", ")", "\n", "\n", "class", "ResNet", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# If we want to use the cfg in forward(), then we should make a copy", "\n", "# of it and store it for later use:", "\n", "# self.cfg = cfg.clone()", "\n", "\n", "# Translate string names to implementations", "\n", "stem_module", "=", "_STEM_MODULES", "[", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_FUNC", "]", "\n", "stage_specs", "=", "_STAGE_SPECS", "[", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "CONV_BODY", "]", "\n", "transformation_module", "=", "_TRANSFORMATION_MODULES", "[", "cfg", ".", "MODEL", ".", "RESNETS", ".", "TRANS_FUNC", "]", "\n", "\n", "# Construct the stem module", "\n", "self", ".", "stem", "=", "stem_module", "(", "cfg", ")", "\n", "\n", "# Constuct the specified ResNet stages", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n", "width_per_group", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "\n", "in_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "stage2_bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "stage2_out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "self", ".", "stages", "=", "[", "]", "\n", "self", ".", "return_features", "=", "{", "}", "\n", "for", "stage_spec", "in", "stage_specs", ":", "\n", "            ", "name", "=", "\"layer\"", "+", "str", "(", "stage_spec", ".", "index", ")", "\n", "stage2_relative_factor", "=", "2", "**", "(", "stage_spec", ".", "index", "-", "1", ")", "\n", "bottleneck_channels", "=", "stage2_bottleneck_channels", "*", "stage2_relative_factor", "\n", "out_channels", "=", "stage2_out_channels", "*", "stage2_relative_factor", "\n", "stage_with_dcn", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STAGE_WITH_DCN", "[", "stage_spec", ".", "index", "-", "1", "]", "\n", "module", "=", "_make_stage", "(", "\n", "transformation_module", ",", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "stage_spec", ".", "block_count", ",", "\n", "num_groups", ",", "\n", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", ",", "\n", "first_stride", "=", "int", "(", "stage_spec", ".", "index", ">", "1", ")", "+", "1", ",", "\n", "dcn_config", "=", "{", "\n", "\"stage_with_dcn\"", ":", "stage_with_dcn", ",", "\n", "\"with_modulated_dcn\"", ":", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WITH_MODULATED_DCN", ",", "\n", "\"deformable_groups\"", ":", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORMABLE_GROUPS", ",", "\n", "}", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "self", ".", "add_module", "(", "name", ",", "module", ")", "\n", "self", ".", "stages", ".", "append", "(", "name", ")", "\n", "self", ".", "return_features", "[", "name", "]", "=", "stage_spec", ".", "return_features", "\n", "\n", "# Optionally freeze (requires_grad=False) parts of the backbone", "\n", "", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_CONV_BODY_AT", ")", "\n", "\n", "", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "if", "freeze_at", "<", "0", ":", "\n", "            ", "return", "\n", "", "for", "stage_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "if", "stage_index", "==", "0", ":", "\n", "                ", "m", "=", "self", ".", "stem", "# stage 0 is the stem", "\n", "", "else", ":", "\n", "                ", "m", "=", "getattr", "(", "self", ",", "\"layer\"", "+", "str", "(", "stage_index", ")", ")", "\n", "", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "for", "stage_name", "in", "self", ".", "stages", ":", "\n", "            ", "x", "=", "getattr", "(", "self", ",", "stage_name", ")", "(", "x", ")", "\n", "if", "self", ".", "return_features", "[", "stage_name", "]", ":", "\n", "                ", "outputs", ".", "append", "(", "x", ")", "\n", "", "", "return", "outputs", "\n", "\n", "\n", "", "", "class", "ResNetHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "block_module", ",", "\n", "stages", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler": [[10, 29], ["lr_scheduler.WarmupPolyLR", "detectron2.solver.build_lr_scheduler"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.build_solver.build_lr_scheduler"], ["def", "build_lr_scheduler", "(", "\n", "cfg", ":", "CfgNode", ",", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", "\n", ")", "->", "torch", ".", "optim", ".", "lr_scheduler", ".", "_LRScheduler", ":", "\n", "    ", "\"\"\"\n    Build a LR scheduler from config.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "SOLVER", ".", "LR_SCHEDULER_NAME", "\n", "if", "name", "==", "\"WarmupPolyLR\"", ":", "\n", "        ", "return", "WarmupPolyLR", "(", "\n", "optimizer", ",", "\n", "cfg", ".", "SOLVER", ".", "MAX_ITER", ",", "\n", "warmup_factor", "=", "cfg", ".", "SOLVER", ".", "WARMUP_FACTOR", ",", "\n", "warmup_iters", "=", "cfg", ".", "SOLVER", ".", "WARMUP_ITERS", ",", "\n", "warmup_method", "=", "cfg", ".", "SOLVER", ".", "WARMUP_METHOD", ",", "\n", "power", "=", "cfg", ".", "SOLVER", ".", "POLY_LR_POWER", ",", "\n", "constant_ending", "=", "cfg", ".", "SOLVER", ".", "POLY_LR_CONSTANT_ENDING", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "build_d2_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.lr_scheduler.WarmupPolyLR.__init__": [[25, 43], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], [")", "\n", "\n", "", "if", "warmup_method", "not", "in", "(", "\"constant\"", ",", "\"linear\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only 'constant' or 'linear' warmup_method accepted\"", "\n", "\"got {}\"", ".", "format", "(", "warmup_method", ")", "\n", ")", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", "WarmupMultiStepLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n", "", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "warmup_factor", "=", "1", "\n", "if", "self", ".", "last_epoch", "<", "self", ".", "warmup_iters", ":", "\n", "            ", "if", "self", ".", "warmup_method", "==", "\"constant\"", ":", "\n", "                ", "warmup_factor", "=", "self", ".", "warmup_factor", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.lr_scheduler.WarmupPolyLR.get_lr": [[44, 58], ["detectron2.solver.lr_scheduler._get_warmup_factor_at_iter", "math.pow", "math.pow"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.solver.lr_scheduler._get_warmup_factor_at_iter"], ["", "elif", "self", ".", "warmup_method", "==", "\"linear\"", ":", "\n", "                ", "alpha", "=", "float", "(", "self", ".", "last_epoch", ")", "/", "self", ".", "warmup_iters", "\n", "warmup_factor", "=", "self", ".", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "", "", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n", "*", "self", ".", "gamma", "**", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.lr_scheduler.WarmupPolyLR._compute_values": [[60, 63], ["lr_scheduler.WarmupPolyLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.lr_scheduler.WarmupPolyLR.get_lr"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.__init__": [[21, 189], ["torch.nn.Module.__init__", "sorted", "torch.nn.ModuleDict", "enumerate", "sorted.items", "len", "len", "len", "len", "len", "len", "torch.nn.ModuleDict", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "torch.nn.init.constant_", "len", "len", "detectron2.layers.ASPP", "detectron2.layers.Conv2d", "fvcore.c2_xavier_fill", "torch.nn.CrossEntropyLoss", "len", "detectron2.layers.DepthwiseSeparableConv2d", "torch.nn.Sequential", "fvcore.c2_xavier_fill", "fvcore.c2_xavier_fill", "loss.DeepLabCE", "ValueError", "ValueError", "detectron2.layers.get_norm", "detectron2.layers.Conv2d", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["SEM_SEG_HEADS_REGISTRY", "=", "Registry", "(", "\"SEM_SEG_HEADS\"", ")", "\n", "SEM_SEG_HEADS_REGISTRY", ".", "__doc__", "=", "\"\"\"\nRegistry for semantic segmentation heads, which make semantic segmentation predictions\nfrom feature maps.\n\"\"\"", "\n", "\n", "\n", "@", "META_ARCH_REGISTRY", ".", "register", "(", ")", "\n", "class", "SemanticSegmentor", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Main class for semantic segmentation architectures.\n    \"\"\"", "\n", "\n", "@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "backbone", ":", "Backbone", ",", "\n", "sem_seg_head", ":", "nn", ".", "Module", ",", "\n", "pixel_mean", ":", "Tuple", "[", "float", "]", ",", "\n", "pixel_std", ":", "Tuple", "[", "float", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            sem_seg_head: a module that predicts semantic segmentation from backbone features\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "sem_seg_head", "=", "sem_seg_head", "\n", "self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "sem_seg_head", "=", "build_sem_seg_head", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"sem_seg_head\"", ":", "sem_seg_head", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n", "\n", "", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n", "", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n\n                For now, each item in the list is a dict that contains:\n\n                   * \"image\": Tensor, image in (C, H, W) format.\n                   * \"sem_seg\": semantic segmentation ground truth\n                   * Other information that's included in the original dicts, such as:\n                     \"height\", \"width\" (int): the output resolution of the model (may be different\n                     from input resolution), used in inference.\n\n\n        Returns:\n            list[dict]:\n              Each dict is the output for one input image.\n              The dict contains one key \"sem_seg\" whose value is a\n              Tensor that represents the\n              per-pixel segmentation prediced by the head.\n              The prediction has shape KxHxW that represents the logits of\n              each class for each pixel.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "targets", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "targets", "=", "ImageList", ".", "from_tensors", "(", "\n", "targets", ",", "self", ".", "backbone", ".", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "targets", "=", "None", "\n", "", "results", ",", "losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "targets", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "losses", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ")", "\n", "r", "=", "sem_seg_postprocess", "(", "result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n", "\n", "", "", "def", "build_sem_seg_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a semantic segmentation head from `cfg.MODEL.SEM_SEG_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NAME", "\n", "return", "SEM_SEG_HEADS_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n", "\n", "", "@", "SEM_SEG_HEADS_REGISTRY", ".", "register", "(", ")", "\n", "class", "SemSegFPNHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    A semantic segmentation head described in :paper:`PanopticFPN`.\n    It takes a list of FPN features as input, and applies a sequence of\n    3x3 convs and upsampling to scale all of them to the stride defined by\n    ``common_stride``. Then these features are added and used to make final\n    predictions by another 1x1 conv layer.\n    \"\"\"", "\n", "\n", "@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ",", "\n", "*", ",", "\n", "num_classes", ":", "int", ",", "\n", "conv_dims", ":", "int", ",", "\n", "common_stride", ":", "int", ",", "\n", "loss_weight", ":", "float", "=", "1.0", ",", "\n", "norm", ":", "Optional", "[", "Union", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "ignore_value", ":", "int", "=", "-", "1", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape: shapes (channels and stride) of the input features\n            num_classes: number of classes to predict\n            conv_dims: number of output channels for the intermediate conv layers.\n            common_stride: the common stride that all features will be upscaled to\n            loss_weight: loss weight\n            norm (str or callable): normalization for all conv layers\n            ignore_value: category id to be ignored during training.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "input_shape", "=", "sorted", "(", "input_shape", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ".", "stride", ")", "\n", "self", ".", "in_features", "=", "[", "k", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "feature_strides", "=", "[", "v", ".", "stride", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "feature_channels", "=", "[", "v", ".", "channels", "for", "k", ",", "v", "in", "input_shape", "]", "\n", "\n", "self", ".", "ignore_value", "=", "ignore_value", "\n", "self", ".", "common_stride", "=", "common_stride", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n", "self", ".", "scale_heads", "=", "[", "]", "\n", "for", "in_feature", ",", "stride", ",", "channels", "in", "zip", "(", "\n", "self", ".", "in_features", ",", "feature_strides", ",", "feature_channels", "\n", ")", ":", "\n", "            ", "head_ops", "=", "[", "]", "\n", "head_length", "=", "max", "(", "1", ",", "int", "(", "np", ".", "log2", "(", "stride", ")", "-", "np", ".", "log2", "(", "self", ".", "common_stride", ")", ")", ")", "\n", "for", "k", "in", "range", "(", "head_length", ")", ":", "\n", "                ", "norm_module", "=", "get_norm", "(", "norm", ",", "conv_dims", ")", "\n", "conv", "=", "Conv2d", "(", "\n", "channels", "if", "k", "==", "0", "else", "conv_dims", ",", "\n", "conv_dims", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "norm", ",", "\n", "norm", "=", "norm_module", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.from_config": [[190, 218], ["dict", "len", "input_shape.items"], "methods", ["None"], ["activation", "=", "F", ".", "relu", ",", "\n", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "conv", ")", "\n", "head_ops", ".", "append", "(", "conv", ")", "\n", "if", "stride", "!=", "self", ".", "common_stride", ":", "\n", "                    ", "head_ops", ".", "append", "(", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", ")", "\n", "", "", "self", ".", "scale_heads", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "head_ops", ")", ")", "\n", "self", ".", "add_module", "(", "in_feature", ",", "self", ".", "scale_heads", "[", "-", "1", "]", ")", "\n", "", "self", ".", "predictor", "=", "Conv2d", "(", "conv_dims", ",", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "weight_init", ".", "c2_msra_fill", "(", "self", ".", "predictor", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "return", "{", "\n", "\"input_shape\"", ":", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input_shape", ".", "items", "(", ")", "if", "k", "in", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IN_FEATURES", "\n", "}", ",", "\n", "\"ignore_value\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "IGNORE_VALUE", ",", "\n", "\"num_classes\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NUM_CLASSES", ",", "\n", "\"conv_dims\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "CONVS_DIM", ",", "\n", "\"common_stride\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "COMMON_STRIDE", ",", "\n", "\"norm\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NORM", ",", "\n", "\"loss_weight\"", ":", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "LOSS_WEIGHT", ",", "\n", "}", "\n", "\n", "", "def", "forward", "(", "self", ",", "features", ",", "targets", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.forward": [[219, 236], ["semantic_seg.DeepLabV3PlusHead.layers", "torch.nn.functional.interpolate", "semantic_seg.DeepLabV3PlusHead.losses"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses"], ["\n", "x", "=", "self", ".", "layers", "(", "features", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "None", ",", "self", ".", "losses", "(", "x", ",", "targets", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "\n", "x", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "return", "x", ",", "{", "}", "\n", "\n", "", "", "def", "layers", "(", "self", ",", "features", ")", ":", "\n", "        ", "for", "i", ",", "f", "in", "enumerate", "(", "self", ".", "in_features", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "x", "=", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "f", "]", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers": [[237, 253], ["semantic_seg.DeepLabV3PlusHead.predictor", "torch.nn.functional.interpolate", "torch.cat", "proj_x.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["                ", "x", "=", "x", "+", "self", ".", "scale_heads", "[", "i", "]", "(", "features", "[", "f", "]", ")", "\n", "", "", "x", "=", "self", ".", "predictor", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "def", "losses", "(", "self", ",", "predictions", ",", "targets", ")", ":", "\n", "        ", "predictions", "=", "predictions", ".", "float", "(", ")", "# https://github.com/pytorch/pytorch/issues/48163", "\n", "predictions", "=", "F", ".", "interpolate", "(", "\n", "predictions", ",", "scale_factor", "=", "self", ".", "common_stride", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "predictions", ",", "targets", ",", "reduction", "=", "\"mean\"", ",", "ignore_index", "=", "self", ".", "ignore_value", "\n", ")", "\n", "losses", "=", "{", "\"loss_sem_seg\"", ":", "loss", "*", "self", ".", "loss_weight", "}", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.losses": [[254, 261], ["torch.nn.functional.interpolate", "semantic_seg.DeepLabV3PlusHead.loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.__init__": [[269, 324], ["torch.nn.Module.__init__", "detectron2.layers.ASPP", "detectron2.layers.Conv2d", "torch.nn.init.normal_", "torch.nn.init.constant_", "len", "len", "torch.nn.CrossEntropyLoss", "ValueError", "loss.DeepLabCE", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.forward": [[325, 341], ["semantic_seg.DeepLabV3Head.aspp", "semantic_seg.DeepLabV3Head.predictor", "torch.nn.functional.interpolate", "semantic_seg.DeepLabV3Head.losses"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses": [[342, 349], ["torch.nn.functional.interpolate", "semantic_seg.DeepLabV3Head.loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.Action.add_arguments": [[40, 47], ["parser.add_argument"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"-v\"", ",", "\n", "\"--verbosity\"", ",", "\n", "action", "=", "\"count\"", ",", "\n", "help", "=", "\"Verbose mode. Multiple -v options increase the verbosity.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.EntrywiseAction.add_arguments": [[60, 75], ["query_db.Action.add_arguments", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["    ", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "super", "(", "EntrywiseAction", ",", "cls", ")", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"dataset\"", ",", "metavar", "=", "\"<dataset>\"", ",", "help", "=", "\"Dataset name (e.g. densepose_coco_2014_train)\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"selector\"", ",", "\n", "metavar", "=", "\"<selector>\"", ",", "\n", "help", "=", "\"Dataset entry selector in the form field1[:type]=value1[,\"", "\n", "\"field2[:type]=value_min-value_max...] which selects all \"", "\n", "\"entries from the dataset that satisfy the constraints\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-entries\"", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"Maximum number of entries to process\"", ",", "type", "=", "int", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.EntrywiseAction.execute": [[77, 90], ["query_db.setup_dataset", "densepose.utils.dbhelper.EntrySelector.from_string", "cls.create_context", "zip", "range", "densepose.utils.dbhelper.EntrySelector.from_string.", "densepose.utils.dbhelper.EntrySelector.from_string.", "cls.execute_on_entry", "cls.execute_on_entry"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.setup_dataset", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.dbhelper.EntrySelector.from_string", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.create_context", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction.execute_on_entry", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction.execute_on_entry"], ["", "@", "classmethod", "\n", "def", "execute", "(", "cls", ":", "type", ",", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "        ", "dataset", "=", "setup_dataset", "(", "args", ".", "dataset", ")", "\n", "entry_selector", "=", "EntrySelector", ".", "from_string", "(", "args", ".", "selector", ")", "\n", "context", "=", "cls", ".", "create_context", "(", "args", ")", "\n", "if", "args", ".", "max_entries", "is", "not", "None", ":", "\n", "            ", "for", "_", ",", "entry", "in", "zip", "(", "range", "(", "args", ".", "max_entries", ")", ",", "dataset", ")", ":", "\n", "                ", "if", "entry_selector", "(", "entry", ")", ":", "\n", "                    ", "cls", ".", "execute_on_entry", "(", "entry", ",", "context", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "entry", "in", "dataset", ":", "\n", "                ", "if", "entry_selector", "(", "entry", ")", ":", "\n", "                    ", "cls", ".", "execute_on_entry", "(", "entry", ",", "context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.EntrywiseAction.create_context": [[91, 95], ["None"], "methods", ["None"], ["", "", "", "", "@", "classmethod", "\n", "def", "create_context", "(", "cls", ":", "type", ",", "args", ":", "argparse", ".", "Namespace", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "context", "=", "{", "}", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.PrintAction.add_parser": [[105, 110], ["subparsers.add_parser", "cls.add_arguments", "subparsers.add_parser.set_defaults"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["@", "classmethod", "\n", "def", "add_parser", "(", "cls", ":", "type", ",", "subparsers", ":", "argparse", ".", "_SubParsersAction", ")", ":", "\n", "        ", "parser", "=", "subparsers", ".", "add_parser", "(", "cls", ".", "COMMAND", ",", "help", "=", "\"Output selected entries to stdout. \"", ")", "\n", "cls", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "set_defaults", "(", "func", "=", "cls", ".", "execute", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.PrintAction.add_arguments": [[111, 114], ["query_db.EntrywiseAction.add_arguments"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "super", "(", "PrintAction", ",", "cls", ")", ".", "add_arguments", "(", "parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.PrintAction.execute_on_entry": [[115, 121], ["pprint.PrettyPrinter", "pprint.PrettyPrinter.pprint"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "execute_on_entry", "(", "cls", ":", "type", ",", "entry", ":", "Dict", "[", "str", ",", "Any", "]", ",", "context", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "import", "pprint", "\n", "\n", "printer", "=", "pprint", ".", "PrettyPrinter", "(", "indent", "=", "2", ",", "width", "=", "200", ",", "compact", "=", "True", ")", "\n", "printer", ".", "pprint", "(", "entry", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction.add_parser": [[139, 144], ["subparsers.add_parser", "cls.add_arguments", "subparsers.add_parser.set_defaults"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["@", "classmethod", "\n", "def", "add_parser", "(", "cls", ":", "type", ",", "subparsers", ":", "argparse", ".", "_SubParsersAction", ")", ":", "\n", "        ", "parser", "=", "subparsers", ".", "add_parser", "(", "cls", ".", "COMMAND", ",", "help", "=", "\"Visualize selected entries\"", ")", "\n", "cls", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "set_defaults", "(", "func", "=", "cls", ".", "execute", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction.add_arguments": [[145, 159], ["query_db.EntrywiseAction.add_arguments", "parser.add_argument", "parser.add_argument", "sorted", "cls.VISUALIZERS.keys"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "super", "(", "ShowAction", ",", "cls", ")", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"visualizations\"", ",", "\n", "metavar", "=", "\"<visualizations>\"", ",", "\n", "help", "=", "\"Comma separated list of visualizations, possible values: \"", "\n", "\"[{}]\"", ".", "format", "(", "\",\"", ".", "join", "(", "sorted", "(", "cls", ".", "VISUALIZERS", ".", "keys", "(", ")", ")", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "metavar", "=", "\"<image_file>\"", ",", "\n", "default", "=", "\"output.png\"", ",", "\n", "help", "=", "\"File name to save output to\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction.execute_on_entry": [[161, 177], ["detectron2.utils.file_io.PathManager.get_local_path", "cv2.imread", "np.tile", "cls._extract_data_for_visualizers_from_entry", "visualizer.visualize", "cls._get_out_fname", "cv2.imwrite", "logger.info"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction._extract_data_for_visualizers_from_entry", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction._get_out_fname"], ["", "@", "classmethod", "\n", "def", "execute_on_entry", "(", "cls", ":", "type", ",", "entry", ":", "Dict", "[", "str", ",", "Any", "]", ",", "context", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "import", "cv2", "\n", "import", "numpy", "as", "np", "\n", "\n", "image_fpath", "=", "PathManager", ".", "get_local_path", "(", "entry", "[", "\"file_name\"", "]", ")", "\n", "image", "=", "cv2", ".", "imread", "(", "image_fpath", ",", "cv2", ".", "IMREAD_GRAYSCALE", ")", "\n", "image", "=", "np", ".", "tile", "(", "image", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", ",", "[", "1", ",", "1", ",", "3", "]", ")", "\n", "datas", "=", "cls", ".", "_extract_data_for_visualizers_from_entry", "(", "context", "[", "\"vis_specs\"", "]", ",", "entry", ")", "\n", "visualizer", "=", "context", "[", "\"visualizer\"", "]", "\n", "image_vis", "=", "visualizer", ".", "visualize", "(", "image", ",", "datas", ")", "\n", "entry_idx", "=", "context", "[", "\"entry_idx\"", "]", "+", "1", "\n", "out_fname", "=", "cls", ".", "_get_out_fname", "(", "entry_idx", ",", "context", "[", "\"out_fname\"", "]", ")", "\n", "cv2", ".", "imwrite", "(", "out_fname", ",", "image_vis", ")", "\n", "logger", ".", "info", "(", "f\"Output saved to {out_fname}\"", ")", "\n", "context", "[", "\"entry_idx\"", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction._get_out_fname": [[178, 182], ["os.path.splitext"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_out_fname", "(", "cls", ":", "type", ",", "entry_idx", ":", "int", ",", "fname_base", ":", "str", ")", ":", "\n", "        ", "base", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "fname_base", ")", "\n", "return", "base", "+", "\".{0:04d}\"", ".", "format", "(", "entry_idx", ")", "+", "ext", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction.create_context": [[183, 197], ["args.visualizations.split", "visualizers.append", "densepose.vis.base.CompoundVisualizer"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "create_context", "(", "cls", ":", "type", ",", "args", ":", "argparse", ".", "Namespace", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "vis_specs", "=", "args", ".", "visualizations", ".", "split", "(", "\",\"", ")", "\n", "visualizers", "=", "[", "]", "\n", "for", "vis_spec", "in", "vis_specs", ":", "\n", "            ", "vis", "=", "cls", ".", "VISUALIZERS", "[", "vis_spec", "]", "\n", "visualizers", ".", "append", "(", "vis", ")", "\n", "", "context", "=", "{", "\n", "\"vis_specs\"", ":", "vis_specs", ",", "\n", "\"visualizer\"", ":", "CompoundVisualizer", "(", "visualizers", ")", ",", "\n", "\"out_fname\"", ":", "args", ".", "output", ",", "\n", "\"entry_idx\"", ":", "0", ",", "\n", "}", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.ShowAction._extract_data_for_visualizers_from_entry": [[198, 216], ["densepose.structures.DensePoseDataRelative.validate_annotation", "torch.as_tensor", "bbox_list.append", "densepose.structures.DensePoseDataRelative", "dp_list.append", "datas.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.data_relative.DensePoseDataRelative.validate_annotation"], ["", "@", "classmethod", "\n", "def", "_extract_data_for_visualizers_from_entry", "(", "\n", "cls", ":", "type", ",", "vis_specs", ":", "List", "[", "str", "]", ",", "entry", ":", "Dict", "[", "str", ",", "Any", "]", "\n", ")", ":", "\n", "        ", "dp_list", "=", "[", "]", "\n", "bbox_list", "=", "[", "]", "\n", "for", "annotation", "in", "entry", "[", "\"annotations\"", "]", ":", "\n", "            ", "is_valid", ",", "_", "=", "DensePoseDataRelative", ".", "validate_annotation", "(", "annotation", ")", "\n", "if", "not", "is_valid", ":", "\n", "                ", "continue", "\n", "", "bbox", "=", "torch", ".", "as_tensor", "(", "annotation", "[", "\"bbox\"", "]", ")", "\n", "bbox_list", ".", "append", "(", "bbox", ")", "\n", "dp_data", "=", "DensePoseDataRelative", "(", "annotation", ")", "\n", "dp_list", ".", "append", "(", "dp_data", ")", "\n", "", "datas", "=", "[", "]", "\n", "for", "vis_spec", "in", "vis_specs", ":", "\n", "            ", "datas", ".", "append", "(", "bbox_list", "if", "\"bbox\"", "==", "vis_spec", "else", "(", "bbox_list", ",", "dp_list", ")", ")", "\n", "", "return", "datas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.register_action": [[50, 57], ["None"], "function", ["None"], ["", "", "def", "register_action", "(", "cls", ":", "type", ")", ":", "\n", "    ", "\"\"\"\n    Decorator for action classes to automate action registration\n    \"\"\"", "\n", "global", "_ACTION_REGISTRY", "\n", "_ACTION_REGISTRY", "[", "cls", ".", "COMMAND", "]", "=", "cls", "\n", "return", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.setup_dataset": [[218, 225], ["logger.info", "timeit.default_timer", "detectron2.data.catalog.DatasetCatalog.get", "timeit.default_timer", "logger.info"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "setup_dataset", "(", "dataset_name", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Loading dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "start", "=", "timer", "(", ")", "\n", "dataset", "=", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", "\n", "stop", "=", "timer", "(", ")", "\n", "logger", ".", "info", "(", "\"Loaded dataset {} in {:.3f}s\"", ".", "format", "(", "dataset_name", ",", "stop", "-", "start", ")", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.create_argument_parser": [[227, 237], ["argparse.ArgumentParser", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_subparsers", "_ACTION_REGISTRY.items", "action.add_parser", "argparse.HelpFormatter", "argparse.ArgumentParser.print_help"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser"], ["", "def", "create_argument_parser", "(", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "DOC", ",", "\n", "formatter_class", "=", "lambda", "prog", ":", "argparse", ".", "HelpFormatter", "(", "prog", ",", "max_help_position", "=", "120", ")", ",", "\n", ")", "\n", "parser", ".", "set_defaults", "(", "func", "=", "lambda", "_", ":", "parser", ".", "print_help", "(", "sys", ".", "stdout", ")", ")", "\n", "subparsers", "=", "parser", ".", "add_subparsers", "(", "title", "=", "\"Actions\"", ")", "\n", "for", "_", ",", "action", "in", "_ACTION_REGISTRY", ".", "items", "(", ")", ":", "\n", "        ", "action", ".", "add_parser", "(", "subparsers", ")", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.query_db.main": [[239, 247], ["query_db.create_argument_parser", "create_argument_parser.parse_args", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger.setLevel", "parser.parse_args.func", "hasattr", "densepose.utils.logger.verbosity_to_level"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.create_argument_parser", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.verbosity_to_level"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "create_argument_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "verbosity", "=", "args", ".", "verbosity", "if", "hasattr", "(", "args", ",", "\"verbosity\"", ")", "else", "None", "\n", "global", "logger", "\n", "logger", "=", "setup_logger", "(", "name", "=", "LOGGER_NAME", ")", "\n", "logger", ".", "setLevel", "(", "verbosity_to_level", "(", "verbosity", ")", ")", "\n", "args", ".", "func", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.Action.add_arguments": [[56, 63], ["parser.add_argument"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"-v\"", ",", "\n", "\"--verbosity\"", ",", "\n", "action", "=", "\"count\"", ",", "\n", "help", "=", "\"Verbose mode. Multiple -v options increase the verbosity.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.InferenceAction.add_arguments": [[76, 87], ["apply_net.Action.add_arguments", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["    ", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "super", "(", "InferenceAction", ",", "cls", ")", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\"cfg\"", ",", "metavar", "=", "\"<config>\"", ",", "help", "=", "\"Config file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "metavar", "=", "\"<model>\"", ",", "help", "=", "\"Model file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"input\"", ",", "metavar", "=", "\"<input>\"", ",", "help", "=", "\"Input data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line 'KEY VALUE' pairs\"", ",", "\n", "default", "=", "[", "]", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.InferenceAction.execute": [[89, 108], ["logger.info", "cls.setup_config", "logger.info", "detectron2.engine.defaults.DefaultPredictor", "logger.info", "cls._get_input_file_list", "cls.create_context", "cls.postexecute", "len", "logger.warning", "detectron2.data.detection_utils.read_image", "torch.no_grad", "cls.execute_on_outputs", "detectron2.engine.defaults.DefaultPredictor."], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.setup_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.InferenceAction._get_input_file_list", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.create_context", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.postexecute", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.detection_utils.read_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.execute_on_outputs"], ["", "@", "classmethod", "\n", "def", "execute", "(", "cls", ":", "type", ",", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Loading config from {args.cfg}\"", ")", "\n", "opts", "=", "[", "]", "\n", "cfg", "=", "cls", ".", "setup_config", "(", "args", ".", "cfg", ",", "args", ".", "model", ",", "args", ",", "opts", ")", "\n", "logger", ".", "info", "(", "f\"Loading model from {args.model}\"", ")", "\n", "predictor", "=", "DefaultPredictor", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "f\"Loading data from {args.input}\"", ")", "\n", "file_list", "=", "cls", ".", "_get_input_file_list", "(", "args", ".", "input", ")", "\n", "if", "len", "(", "file_list", ")", "==", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"No input images for {args.input}\"", ")", "\n", "return", "\n", "", "context", "=", "cls", ".", "create_context", "(", "args", ",", "cfg", ")", "\n", "for", "file_name", "in", "file_list", ":", "\n", "            ", "img", "=", "read_image", "(", "file_name", ",", "format", "=", "\"BGR\"", ")", "# predictor expects BGR image.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "predictor", "(", "img", ")", "[", "\"instances\"", "]", "\n", "cls", ".", "execute_on_outputs", "(", "context", ",", "{", "\"file_name\"", ":", "file_name", ",", "\"image\"", ":", "img", "}", ",", "outputs", ")", "\n", "", "", "cls", ".", "postexecute", "(", "context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.InferenceAction.setup_config": [[109, 122], ["detectron2.config.get_cfg", "densepose.add_densepose_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.config.get_cfg.merge_from_list"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], ["", "@", "classmethod", "\n", "def", "setup_config", "(", "\n", "cls", ":", "type", ",", "config_fpath", ":", "str", ",", "model_fpath", ":", "str", ",", "args", ":", "argparse", ".", "Namespace", ",", "opts", ":", "List", "[", "str", "]", "\n", ")", ":", "\n", "        ", "cfg", "=", "get_cfg", "(", ")", "\n", "add_densepose_config", "(", "cfg", ")", "\n", "cfg", ".", "merge_from_file", "(", "config_fpath", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "if", "opts", ":", "\n", "            ", "cfg", ".", "merge_from_list", "(", "opts", ")", "\n", "", "cfg", ".", "MODEL", ".", "WEIGHTS", "=", "model_fpath", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.InferenceAction._get_input_file_list": [[123, 136], ["os.path.isdir", "os.path.isfile", "os.path.join", "glob.glob", "os.listdir", "os.path.isfile", "os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_input_file_list", "(", "cls", ":", "type", ",", "input_spec", ":", "str", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "input_spec", ")", ":", "\n", "            ", "file_list", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "input_spec", ",", "fname", ")", "\n", "for", "fname", "in", "os", ".", "listdir", "(", "input_spec", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "input_spec", ",", "fname", ")", ")", "\n", "]", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "input_spec", ")", ":", "\n", "            ", "file_list", "=", "[", "input_spec", "]", "\n", "", "else", ":", "\n", "            ", "file_list", "=", "glob", ".", "glob", "(", "input_spec", ")", "\n", "", "return", "file_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.DumpAction.add_parser": [[146, 151], ["subparsers.add_parser", "cls.add_arguments", "subparsers.add_parser.set_defaults"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["@", "classmethod", "\n", "def", "add_parser", "(", "cls", ":", "type", ",", "subparsers", ":", "argparse", ".", "_SubParsersAction", ")", ":", "\n", "        ", "parser", "=", "subparsers", ".", "add_parser", "(", "cls", ".", "COMMAND", ",", "help", "=", "\"Dump model outputs to a file.\"", ")", "\n", "cls", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "set_defaults", "(", "func", "=", "cls", ".", "execute", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.DumpAction.add_arguments": [[152, 160], ["apply_net.InferenceAction.add_arguments", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "super", "(", "DumpAction", ",", "cls", ")", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "metavar", "=", "\"<dump_file>\"", ",", "\n", "default", "=", "\"results.pkl\"", ",", "\n", "help", "=", "\"File name to save dump to\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.DumpAction.execute_on_outputs": [[162, 180], ["logger.info", "outputs.has", "outputs.has", "context[].append", "outputs.get().cpu", "outputs.get().tensor.cpu", "outputs.has", "isinstance", "outputs.get", "densepose.vis.extractor.DensePoseResultExtractor", "isinstance", "densepose.vis.extractor.DensePoseOutputsExtractor.", "outputs.get", "densepose.vis.extractor.DensePoseOutputsExtractor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "@", "classmethod", "\n", "def", "execute_on_outputs", "(", "\n", "cls", ":", "type", ",", "context", ":", "Dict", "[", "str", ",", "Any", "]", ",", "entry", ":", "Dict", "[", "str", ",", "Any", "]", ",", "outputs", ":", "Instances", "\n", ")", ":", "\n", "        ", "image_fpath", "=", "entry", "[", "\"file_name\"", "]", "\n", "logger", ".", "info", "(", "f\"Processing {image_fpath}\"", ")", "\n", "result", "=", "{", "\"file_name\"", ":", "image_fpath", "}", "\n", "if", "outputs", ".", "has", "(", "\"scores\"", ")", ":", "\n", "            ", "result", "[", "\"scores\"", "]", "=", "outputs", ".", "get", "(", "\"scores\"", ")", ".", "cpu", "(", ")", "\n", "", "if", "outputs", ".", "has", "(", "\"pred_boxes\"", ")", ":", "\n", "            ", "result", "[", "\"pred_boxes_XYXY\"", "]", "=", "outputs", ".", "get", "(", "\"pred_boxes\"", ")", ".", "tensor", ".", "cpu", "(", ")", "\n", "if", "outputs", ".", "has", "(", "\"pred_densepose\"", ")", ":", "\n", "                ", "if", "isinstance", "(", "outputs", ".", "pred_densepose", ",", "DensePoseChartPredictorOutput", ")", ":", "\n", "                    ", "extractor", "=", "DensePoseResultExtractor", "(", ")", "\n", "", "elif", "isinstance", "(", "outputs", ".", "pred_densepose", ",", "DensePoseEmbeddingPredictorOutput", ")", ":", "\n", "                    ", "extractor", "=", "DensePoseOutputsExtractor", "(", ")", "\n", "", "result", "[", "\"pred_densepose\"", "]", "=", "extractor", "(", "outputs", ")", "[", "0", "]", "\n", "", "", "context", "[", "\"results\"", "]", ".", "append", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.DumpAction.create_context": [[181, 185], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "create_context", "(", "cls", ":", "type", ",", "args", ":", "argparse", ".", "Namespace", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "context", "=", "{", "\"results\"", ":", "[", "]", ",", "\"out_fname\"", ":", "args", ".", "output", "}", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.DumpAction.postexecute": [[186, 195], ["os.path.dirname", "os.makedirs", "open", "pickle.dump", "logger.info", "len", "os.path.exists"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.dump"], ["", "@", "classmethod", "\n", "def", "postexecute", "(", "cls", ":", "type", ",", "context", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "out_fname", "=", "context", "[", "\"out_fname\"", "]", "\n", "out_dir", "=", "os", ".", "path", ".", "dirname", "(", "out_fname", ")", "\n", "if", "len", "(", "out_dir", ")", ">", "0", "and", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "with", "open", "(", "out_fname", ",", "\"wb\"", ")", "as", "hFile", ":", "\n", "            ", "pickle", ".", "dump", "(", "context", "[", "\"results\"", "]", ",", "hFile", ")", "\n", "logger", ".", "info", "(", "f\"Output saved to {out_fname}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser": [[215, 220], ["subparsers.add_parser", "cls.add_arguments", "subparsers.add_parser.set_defaults"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["@", "classmethod", "\n", "def", "add_parser", "(", "cls", ":", "type", ",", "subparsers", ":", "argparse", ".", "_SubParsersAction", ")", ":", "\n", "        ", "parser", "=", "subparsers", ".", "add_parser", "(", "cls", ".", "COMMAND", ",", "help", "=", "\"Visualize selected entries\"", ")", "\n", "cls", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "set_defaults", "(", "func", "=", "cls", ".", "execute", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments": [[221, 257], ["apply_net.InferenceAction.add_arguments", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "sorted", "cls.VISUALIZERS.keys"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_arguments"], ["", "@", "classmethod", "\n", "def", "add_arguments", "(", "cls", ":", "type", ",", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "        ", "super", "(", "ShowAction", ",", "cls", ")", ".", "add_arguments", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"visualizations\"", ",", "\n", "metavar", "=", "\"<visualizations>\"", ",", "\n", "help", "=", "\"Comma separated list of visualizations, possible values: \"", "\n", "\"[{}]\"", ".", "format", "(", "\",\"", ".", "join", "(", "sorted", "(", "cls", ".", "VISUALIZERS", ".", "keys", "(", ")", ")", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--min_score\"", ",", "\n", "metavar", "=", "\"<score>\"", ",", "\n", "default", "=", "0.8", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Minimum detection score to visualize\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--nms_thresh\"", ",", "metavar", "=", "\"<threshold>\"", ",", "default", "=", "None", ",", "type", "=", "float", ",", "help", "=", "\"NMS threshold\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--texture_atlas\"", ",", "\n", "metavar", "=", "\"<texture_atlas>\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Texture atlas file (for IUV texture transfer)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--texture_atlases_map\"", ",", "\n", "metavar", "=", "\"<texture_atlases_map>\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"JSON string of a dict containing texture atlas files for each mesh\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "metavar", "=", "\"<image_file>\"", ",", "\n", "default", "=", "\"outputres.png\"", ",", "\n", "help", "=", "\"File name to save output to\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.setup_config": [[259, 270], ["opts.append", "opts.append", "apply_net.InferenceAction.setup_config", "str", "opts.append", "opts.append", "str"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.setup_config"], ["", "@", "classmethod", "\n", "def", "setup_config", "(", "\n", "cls", ":", "type", ",", "config_fpath", ":", "str", ",", "model_fpath", ":", "str", ",", "args", ":", "argparse", ".", "Namespace", ",", "opts", ":", "List", "[", "str", "]", "\n", ")", ":", "\n", "        ", "opts", ".", "append", "(", "\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\"", ")", "\n", "opts", ".", "append", "(", "str", "(", "args", ".", "min_score", ")", ")", "\n", "if", "args", ".", "nms_thresh", "is", "not", "None", ":", "\n", "            ", "opts", ".", "append", "(", "\"MODEL.ROI_HEADS.NMS_THRESH_TEST\"", ")", "\n", "opts", ".", "append", "(", "str", "(", "args", ".", "nms_thresh", ")", ")", "\n", "", "cfg", "=", "super", "(", "ShowAction", ",", "cls", ")", ".", "setup_config", "(", "config_fpath", ",", "model_fpath", ",", "args", ",", "opts", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.execute_on_outputs": [[271, 294], ["logger.info", "cv2.cvtColor", "np.tile", "extractor", "visualizer.visualize", "cls._get_out_fname", "os.path.dirname", "cv2.imwrite", "logger.info", "os.makedirs", "len", "os.path.exists"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction._get_out_fname"], ["", "@", "classmethod", "\n", "def", "execute_on_outputs", "(", "\n", "cls", ":", "type", ",", "context", ":", "Dict", "[", "str", ",", "Any", "]", ",", "entry", ":", "Dict", "[", "str", ",", "Any", "]", ",", "outputs", ":", "Instances", "\n", ")", ":", "\n", "        ", "import", "cv2", "\n", "import", "numpy", "as", "np", "\n", "\n", "visualizer", "=", "context", "[", "\"visualizer\"", "]", "\n", "extractor", "=", "context", "[", "\"extractor\"", "]", "\n", "image_fpath", "=", "entry", "[", "\"file_name\"", "]", "\n", "logger", ".", "info", "(", "f\"Processing {image_fpath}\"", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "entry", "[", "\"image\"", "]", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "image", "=", "np", ".", "tile", "(", "image", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", ",", "[", "1", ",", "1", ",", "3", "]", ")", "\n", "data", "=", "extractor", "(", "outputs", ")", "\n", "image_vis", "=", "visualizer", ".", "visualize", "(", "image", ",", "data", ")", "\n", "entry_idx", "=", "context", "[", "\"entry_idx\"", "]", "+", "1", "\n", "out_fname", "=", "cls", ".", "_get_out_fname", "(", "entry_idx", ",", "context", "[", "\"out_fname\"", "]", ")", "\n", "out_dir", "=", "os", ".", "path", ".", "dirname", "(", "out_fname", ")", "\n", "if", "len", "(", "out_dir", ")", ">", "0", "and", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "cv2", ".", "imwrite", "(", "out_fname", ",", "image_vis", ")", "\n", "logger", ".", "info", "(", "f\"Output saved to {out_fname}\"", ")", "\n", "context", "[", "\"entry_idx\"", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.postexecute": [[295, 298], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "postexecute", "(", "cls", ":", "type", ",", "context", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction._get_out_fname": [[299, 303], ["os.path.splitext"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_out_fname", "(", "cls", ":", "type", ",", "entry_idx", ":", "int", ",", "fname_base", ":", "str", ")", ":", "\n", "        ", "base", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "fname_base", ")", "\n", "return", "base", "+", "\".{0:04d}\"", ".", "format", "(", "entry_idx", ")", "+", "ext", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.create_context": [[304, 329], ["args.visualizations.split", "densepose.vis.base.CompoundVisualizer", "densepose.vis.extractor.CompoundExtractor", "densepose.vis.densepose_results_textures.get_texture_atlas", "densepose.vis.densepose_outputs_vertex.get_texture_atlases", "visualizers.append", "densepose.vis.extractor.create_extractor", "extractors.append"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.get_texture_atlas", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.get_texture_atlases", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.create_extractor"], ["", "@", "classmethod", "\n", "def", "create_context", "(", "cls", ":", "type", ",", "args", ":", "argparse", ".", "Namespace", ",", "cfg", ":", "CfgNode", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "vis_specs", "=", "args", ".", "visualizations", ".", "split", "(", "\",\"", ")", "\n", "visualizers", "=", "[", "]", "\n", "extractors", "=", "[", "]", "\n", "for", "vis_spec", "in", "vis_specs", ":", "\n", "            ", "texture_atlas", "=", "get_texture_atlas", "(", "args", ".", "texture_atlas", ")", "\n", "texture_atlases_dict", "=", "get_texture_atlases", "(", "args", ".", "texture_atlases_map", ")", "\n", "vis", "=", "cls", ".", "VISUALIZERS", "[", "vis_spec", "]", "(", "\n", "cfg", "=", "cfg", ",", "\n", "texture_atlas", "=", "texture_atlas", ",", "\n", "texture_atlases_dict", "=", "texture_atlases_dict", ",", "\n", ")", "\n", "visualizers", ".", "append", "(", "vis", ")", "\n", "extractor", "=", "create_extractor", "(", "vis", ")", "\n", "extractors", ".", "append", "(", "extractor", ")", "\n", "", "visualizer", "=", "CompoundVisualizer", "(", "visualizers", ")", "\n", "extractor", "=", "CompoundExtractor", "(", "extractors", ")", "\n", "context", "=", "{", "\n", "\"extractor\"", ":", "extractor", ",", "\n", "\"visualizer\"", ":", "visualizer", ",", "\n", "\"out_fname\"", ":", "args", ".", "output", ",", "\n", "\"entry_idx\"", ":", "0", ",", "\n", "}", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.register_action": [[66, 73], ["None"], "function", ["None"], ["", "", "def", "register_action", "(", "cls", ":", "type", ")", ":", "\n", "    ", "\"\"\"\n    Decorator for action classes to automate action registration\n    \"\"\"", "\n", "global", "_ACTION_REGISTRY", "\n", "_ACTION_REGISTRY", "[", "cls", ".", "COMMAND", "]", "=", "cls", "\n", "return", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.create_argument_parser": [[331, 341], ["argparse.ArgumentParser", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_subparsers", "_ACTION_REGISTRY.items", "action.add_parser", "argparse.HelpFormatter", "argparse.ArgumentParser.print_help"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.ShowAction.add_parser"], ["", "", "def", "create_argument_parser", "(", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "DOC", ",", "\n", "formatter_class", "=", "lambda", "prog", ":", "argparse", ".", "HelpFormatter", "(", "prog", ",", "max_help_position", "=", "120", ")", ",", "\n", ")", "\n", "parser", ".", "set_defaults", "(", "func", "=", "lambda", "_", ":", "parser", ".", "print_help", "(", "sys", ".", "stdout", ")", ")", "\n", "subparsers", "=", "parser", ".", "add_subparsers", "(", "title", "=", "\"Actions\"", ")", "\n", "for", "_", ",", "action", "in", "_ACTION_REGISTRY", ".", "items", "(", ")", ":", "\n", "        ", "action", ".", "add_parser", "(", "subparsers", ")", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.main": [[343, 351], ["apply_net.create_argument_parser", "create_argument_parser.parse_args", "detectron2.utils.logger.setup_logger", "detectron2.utils.logger.setup_logger.setLevel", "parser.parse_args.func", "hasattr", "densepose.utils.logger.verbosity_to_level"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.apply_net.create_argument_parser", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cityscapes.convert_cityscapes_to_coco.parse_args", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.verbosity_to_level"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "create_argument_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "verbosity", "=", "args", ".", "verbosity", "if", "hasattr", "(", "args", ",", "\"verbosity\"", ")", "else", "None", "\n", "global", "logger", "\n", "logger", "=", "setup_logger", "(", "name", "=", "LOGGER_NAME", ")", "\n", "logger", ".", "setLevel", "(", "verbosity_to_level", "(", "verbosity", ")", ")", "\n", "args", ".", "func", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.train_net.setup": [[26, 36], ["detectron2.config.get_cfg", "densepose.add_densepose_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup", "detectron2.utils.logger.setup_logger", "detectron2.get_rank"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.logger.setup_logger", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["from", "maskrcnn_benchmark", ".", "utils", ".", "miscellaneous", "import", "mkdir", ",", "save_config", "\n", "\n", "# See if we can use apex.DistributedDataParallel instead of the torch default,", "\n", "# and enable mixed-precision via apex.amp", "\n", "try", ":", "\n", "    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for multi-precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.DensePose.train_net.main": [[38, 63], ["train_net.setup", "detectron2.utils.file_io.PathManager.set_strict_kwargs_checking", "densepose.engine.Trainer", "densepose.engine.Trainer.resume_or_load", "densepose.engine.Trainer.train", "densepose.engine.Trainer.build_model", "densepose.modeling.densepose_checkpoint.DensePoseCheckpointer().resume_or_load", "densepose.engine.Trainer.test", "detectron2.is_main_process", "densepose.engine.Trainer.register_hooks", "Trainer.test.update", "detectron2.evaluation.verify_results", "densepose.modeling.densepose_checkpoint.DensePoseCheckpointer", "densepose.engine.Trainer.test_with_TTA", "detectron2.engine.hooks.EvalHook", "densepose.engine.Trainer.test_with_TTA"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.register_hooks", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.verify_results", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test_with_TTA", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test_with_TTA"], ["device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "make_optimizer", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "make_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Initialize mixed-precision training", "\n", "use_mixed_precision", "=", "cfg", ".", "DTYPE", "==", "\"float16\"", "\n", "amp_opt_level", "=", "'O1'", "if", "use_mixed_precision", "else", "'O0'", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "amp_opt_level", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ",", "\n", "# this should be removed if we update BatchNorm stats", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n", "", "arguments", "=", "{", "}", "\n", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "output_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", "\n", "save_to_disk", "=", "get_rank", "(", ")", "==", "0", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "\n", "cfg", ",", "model", ",", "optimizer", ",", "scheduler", ",", "output_dir", ",", "save_to_disk", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_dataset_category_config": [[8, 19], ["detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["None"], ["\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_evaluation_config": [[21, 44], ["detectron2.config.CfgNode"], "function", ["None"], ["\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n", "# Note that the default value of allow_unsafe is changed to True", "\n", "", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_bootstrap_config": [[46, 53], ["detectron2.config.CfgNode"], "function", ["None"], ["            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n", "loaded_ver", ",", "self", ".", "VERSION", "\n", ")", "\n", "\n", "if", "loaded_ver", "==", "self", ".", "VERSION", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.get_bootstrap_dataset_config": [[55, 78], ["detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["None"], ["", "else", ":", "\n", "# compat.py needs to import CfgNode", "\n", "            ", "from", ".", "compat", "import", "upgrade_config", ",", "downgrade_config", "\n", "\n", "logger", ".", "warning", "(", "\n", "\"Loading an old v{} config file '{}' by automatically upgrading to v{}. \"", "\n", "\"See docs/CHANGELOG.md for instructions to update your files.\"", ".", "format", "(", "\n", "loaded_ver", ",", "cfg_filename", ",", "self", ".", "VERSION", "\n", ")", "\n", ")", "\n", "# To convert, first obtain a full config at an old version", "\n", "old_self", "=", "downgrade_config", "(", "self", ",", "to_version", "=", "loaded_ver", ")", "\n", "old_self", ".", "merge_from_other_cfg", "(", "loaded_cfg", ")", "\n", "new_config", "=", "upgrade_config", "(", "old_self", ")", "\n", "self", ".", "clear", "(", ")", "\n", "self", ".", "update", "(", "new_config", ")", "\n", "\n", "", "", "def", "dump", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            str: a yaml string representation of the config\n        \"\"\"", "\n", "# to make it show up in docs", "\n", "return", "super", "(", ")", ".", "dump", "(", "*", "args", ",", "**", "kwargs", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.load_bootstrap_config": [[80, 95], ["get_bootstrap_dataset_config().clone", "get_bootstrap_dataset_config().clone.merge_from_other_cfg", "bootstrap_datasets_cfgnodes.append", "detectron2.config.CfgNode", "config.get_bootstrap_dataset_config"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.get_bootstrap_dataset_config"], ["\n", "", "", "global_cfg", "=", "CfgNode", "(", ")", "\n", "\n", "\n", "def", "get_cfg", "(", ")", "->", "CfgNode", ":", "\n", "    ", "\"\"\"\n    Get a copy of the default config.\n\n    Returns:\n        a detectron2 CfgNode instance.\n    \"\"\"", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "return", "_C", ".", "clone", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_head_cse_config": [[97, 121], ["detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["None"], ["    ", "\"\"\"\n    Let the global config point to the given cfg.\n\n    Assume that the given \"cfg\" has the key \"KEY\", after calling\n    `set_global_cfg(cfg)`, the key can be accessed by:\n    ::\n        from detectron2.config import global_cfg\n        print(global_cfg.KEY)\n\n    By using a hacky global config, you can access these configs anywhere,\n    without having to pass the config object or the values deep into the code.\n    This is a hacky feature introduced for quick prototyping / research exploration.\n    \"\"\"", "\n", "global", "global_cfg", "\n", "global_cfg", ".", "clear", "(", ")", "\n", "global_cfg", ".", "update", "(", "cfg", ")", "\n", "\n", "\n", "", "def", "configurable", "(", "init_func", "=", "None", ",", "*", ",", "from_config", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_head_config": [[123, 200], ["detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode", "config.add_densepose_head_cse_config"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_head_cse_config"], ["\n", "\n", "if", "init_func", "is", "not", "None", ":", "\n", "        ", "assert", "(", "\n", "inspect", ".", "isfunction", "(", "init_func", ")", "\n", "and", "from_config", "is", "None", "\n", "and", "init_func", ".", "__name__", "==", "\"__init__\"", "\n", ")", ",", "\"Incorrect use of @configurable. Check API documentation for examples.\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "init_func", ")", "\n", "def", "wrapped", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "from_config_func", "=", "type", "(", "self", ")", ".", "from_config", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "                ", "raise", "AttributeError", "(", "\n", "\"Class with @configurable must have a 'from_config' classmethod.\"", "\n", ")", "from", "e", "\n", "", "if", "not", "inspect", ".", "ismethod", "(", "from_config_func", ")", ":", "\n", "                ", "raise", "TypeError", "(", "\"Class with @configurable must have a 'from_config' classmethod.\"", ")", "\n", "\n", "", "if", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "explicit_args", "=", "_get_args_from_config", "(", "from_config_func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "init_func", "(", "self", ",", "**", "explicit_args", ")", "\n", "", "else", ":", "\n", "                ", "init_func", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapped", "\n", "\n", "", "else", ":", "\n", "        ", "if", "from_config", "is", "None", ":", "\n", "            ", "return", "configurable", "# @configurable() is made equivalent to @configurable", "\n", "", "assert", "inspect", ".", "isfunction", "(", "\n", "from_config", "\n", ")", ",", "\"from_config argument of configurable must be a function!\"", "\n", "\n", "def", "wrapper", "(", "orig_func", ")", ":", "\n", "            ", "@", "functools", ".", "wraps", "(", "orig_func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "if", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                    ", "explicit_args", "=", "_get_args_from_config", "(", "from_config", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "orig_func", "(", "**", "explicit_args", ")", "\n", "", "else", ":", "\n", "                    ", "return", "orig_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapped", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_hrnet_config": [[202, 235], ["detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["None"], ["", "", "def", "_get_args_from_config", "(", "from_config_func", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Use `from_config` to obtain explicit arguments.\n\n    Returns:\n        dict: arguments to be used for cls.__init__\n    \"\"\"", "\n", "signature", "=", "inspect", ".", "signature", "(", "from_config_func", ")", "\n", "if", "list", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "[", "0", "]", "!=", "\"cfg\"", ":", "\n", "        ", "if", "inspect", ".", "isfunction", "(", "from_config_func", ")", ":", "\n", "            ", "name", "=", "from_config_func", ".", "__name__", "\n", "", "else", ":", "\n", "            ", "name", "=", "f\"{from_config_func.__self__}.from_config\"", "\n", "", "raise", "TypeError", "(", "f\"{name} must take 'cfg' as the first argument!\"", ")", "\n", "", "support_var_arg", "=", "any", "(", "\n", "param", ".", "kind", "in", "[", "param", ".", "VAR_POSITIONAL", ",", "param", ".", "VAR_KEYWORD", "]", "\n", "for", "param", "in", "signature", ".", "parameters", ".", "values", "(", ")", "\n", ")", "\n", "if", "support_var_arg", ":", "# forward all arguments to from_config, if from_config accepts them", "\n", "        ", "ret", "=", "from_config_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# forward supported arguments to from_config", "\n", "        ", "supported_arg_names", "=", "set", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "\n", "extra_kwargs", "=", "{", "}", "\n", "for", "name", "in", "list", "(", "kwargs", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "name", "not", "in", "supported_arg_names", ":", "\n", "                ", "extra_kwargs", "[", "name", "]", "=", "kwargs", ".", "pop", "(", "name", ")", "\n", "", "", "ret", "=", "from_config_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# forward the other arguments to __init__", "\n", "ret", ".", "update", "(", "extra_kwargs", ")", "\n", "", "return", "ret", "\n", "\n", "\n", "", "def", "_called_with_cfg", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_config": [[237, 243], ["config.add_densepose_head_config", "config.add_hrnet_config", "config.add_bootstrap_config", "config.add_dataset_category_config", "config.add_evaluation_config"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_densepose_head_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_hrnet_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_bootstrap_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_dataset_category_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.densepose.config.add_evaluation_config"], ["\n", "from", "omegaconf", "import", "DictConfig", "\n", "\n", "if", "len", "(", "args", ")", "and", "isinstance", "(", "args", "[", "0", "]", ",", "(", "_CfgNode", ",", "DictConfig", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart_confidence.DensePoseChartConfidencePredictorMixin.__init__": [[32, 46], ["super().__init__", "confidence.DensePoseConfidenceModelConfig.from_cfg", "chart_confidence.DensePoseChartConfidencePredictorMixin._initialize_confidence_estimation_layers", "utils.initialize_module_params"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.confidence.DensePoseConfidenceModelConfig.from_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._initialize_confidence_estimation_layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.initialize_module_params"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence predictor using configuration options.\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): number of input channels\n        \"\"\"", "\n", "# we rely on base predictor to call nn.Module.__init__", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "input_channels", ")", "# pyre-ignore[19]", "\n", "self", ".", "confidence_model_cfg", "=", "DensePoseConfidenceModelConfig", ".", "from_cfg", "(", "cfg", ")", "\n", "self", ".", "_initialize_confidence_estimation_layers", "(", "cfg", ",", "input_channels", ")", "\n", "self", ".", "_registry", "=", "{", "}", "\n", "initialize_module_params", "(", "self", ")", "# pyre-ignore[6]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart_confidence.DensePoseChartConfidencePredictorMixin._initialize_confidence_estimation_layers": [[47, 86], ["detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "ValueError", "int", "int", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "_initialize_confidence_estimation_layers", "(", "self", ",", "cfg", ":", "CfgNode", ",", "dim_in", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence estimation layers based on configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n            dim_in (int): number of input channels\n        \"\"\"", "\n", "dim_out_patches", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_PATCHES", "+", "1", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "enabled", ":", "\n", "            ", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "==", "DensePoseUVConfidenceType", ".", "IID_ISO", ":", "\n", "                ", "self", ".", "sigma_2_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "", "elif", "(", "\n", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "\n", "==", "DensePoseUVConfidenceType", ".", "INDEP_ANISO", "\n", ")", ":", "\n", "                ", "self", ".", "sigma_2_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "kappa_u_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "kappa_v_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Unknown confidence model type: \"", "\n", "f\"{self.confidence_model_cfg.confidence_model_type}\"", "\n", ")", "\n", "", "", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "            ", "self", ".", "fine_segm_confidence_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "1", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "coarse_segm_confidence_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "1", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart_confidence.DensePoseChartConfidencePredictorMixin.forward": [[88, 148], ["super().forward", "chart_confidence.DensePoseChartConfidencePredictorMixin._create_output_instance", "chart_confidence.DensePoseChartConfidencePredictorMixin.interp2d", "torch.nn.functional.softplus", "torch.repeat_interleave", "torch.nn.functional.softplus", "torch.repeat_interleave", "chart_confidence.DensePoseChartConfidencePredictorMixin.sigma_2_lowres", "chart_confidence.DensePoseChartConfidencePredictorMixin.interp2d", "chart_confidence.DensePoseChartConfidencePredictorMixin.interp2d", "chart_confidence.DensePoseChartConfidencePredictorMixin.interp2d", "ValueError", "chart_confidence.DensePoseChartConfidencePredictorMixin.interp2d", "chart_confidence.DensePoseChartConfidencePredictorMixin.interp2d", "chart_confidence.DensePoseChartConfidencePredictorMixin.sigma_2_lowres", "chart_confidence.DensePoseChartConfidencePredictorMixin.kappa_u_lowres", "chart_confidence.DensePoseChartConfidencePredictorMixin.kappa_v_lowres", "chart_confidence.DensePoseChartConfidencePredictorMixin.fine_segm_confidence_lowres", "chart_confidence.DensePoseChartConfidencePredictorMixin.coarse_segm_confidence_lowres"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._create_output_instance", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d"], ["", "", "def", "forward", "(", "self", ",", "head_outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward operation on head outputs used as inputs for the predictor.\n        Calls forward method from the base predictor and uses its outputs to compute\n        confidences.\n\n        Args:\n            head_outputs (Tensor): head outputs used as predictor inputs\n        Return:\n            An instance of outputs with confidences,\n            see `decorate_predictor_output_class_with_confidences`\n        \"\"\"", "\n", "# assuming base class returns SIUV estimates in its first result", "\n", "base_predictor_outputs", "=", "super", "(", ")", ".", "forward", "(", "head_outputs", ")", "# pyre-ignore[16]", "\n", "\n", "# create output instance by extending base predictor outputs:", "\n", "output", "=", "self", ".", "_create_output_instance", "(", "base_predictor_outputs", ")", "\n", "\n", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "enabled", ":", "\n", "            ", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "==", "DensePoseUVConfidenceType", ".", "IID_ISO", ":", "\n", "# assuming base class defines interp2d method for bilinear interpolation", "\n", "                ", "output", ".", "sigma_2", "=", "self", ".", "interp2d", "(", "self", ".", "sigma_2_lowres", "(", "head_outputs", ")", ")", "# pyre-ignore[16]", "\n", "", "elif", "(", "\n", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "\n", "==", "DensePoseUVConfidenceType", ".", "INDEP_ANISO", "\n", ")", ":", "\n", "# assuming base class defines interp2d method for bilinear interpolation", "\n", "                ", "output", ".", "sigma_2", "=", "self", ".", "interp2d", "(", "self", ".", "sigma_2_lowres", "(", "head_outputs", ")", ")", "\n", "output", ".", "kappa_u", "=", "self", ".", "interp2d", "(", "self", ".", "kappa_u_lowres", "(", "head_outputs", ")", ")", "# pyre-ignore[16]", "\n", "output", ".", "kappa_v", "=", "self", ".", "interp2d", "(", "self", ".", "kappa_v_lowres", "(", "head_outputs", ")", ")", "# pyre-ignore[16]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Unknown confidence model type: \"", "\n", "f\"{self.confidence_model_cfg.confidence_model_type}\"", "\n", ")", "\n", "", "", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "# base predictor outputs are assumed to have `fine_segm` and `coarse_segm` attributes", "\n", "# base predictor is assumed to define `interp2d` method for bilinear interpolation", "\n", "            ", "output", ".", "fine_segm_confidence", "=", "(", "\n", "F", ".", "softplus", "(", "\n", "self", ".", "interp2d", "(", "self", ".", "fine_segm_confidence_lowres", "(", "head_outputs", ")", ")", "# pyre-ignore[16]", "\n", ")", "\n", "+", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "epsilon", "\n", ")", "\n", "output", ".", "fine_segm", "=", "base_predictor_outputs", ".", "fine_segm", "*", "torch", ".", "repeat_interleave", "(", "\n", "output", ".", "fine_segm_confidence", ",", "base_predictor_outputs", ".", "fine_segm", ".", "shape", "[", "1", "]", ",", "dim", "=", "1", "\n", ")", "\n", "output", ".", "coarse_segm_confidence", "=", "(", "\n", "F", ".", "softplus", "(", "\n", "self", ".", "interp2d", "(", "\n", "self", ".", "coarse_segm_confidence_lowres", "(", "head_outputs", ")", "# pyre-ignore[16]", "\n", ")", "\n", ")", "\n", "+", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "epsilon", "\n", ")", "\n", "output", ".", "coarse_segm", "=", "base_predictor_outputs", ".", "coarse_segm", "*", "torch", ".", "repeat_interleave", "(", "\n", "output", ".", "coarse_segm_confidence", ",", "base_predictor_outputs", ".", "coarse_segm", ".", "shape", "[", "1", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart_confidence.DensePoseChartConfidencePredictorMixin._create_output_instance": [[149, 175], ["structures.decorate_predictor_output_class_with_confidences", "structures.decorate_predictor_output_class_with_confidences.", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_confidence.decorate_predictor_output_class_with_confidences"], ["", "def", "_create_output_instance", "(", "self", ",", "base_predictor_outputs", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Create an instance of predictor outputs by copying the outputs from the\n        base predictor and initializing confidence\n\n        Args:\n            base_predictor_outputs: an instance of base predictor outputs\n                (the outputs type is assumed to be a dataclass)\n        Return:\n           An instance of outputs with confidences\n        \"\"\"", "\n", "PredictorOutput", "=", "decorate_predictor_output_class_with_confidences", "(", "\n", "type", "(", "base_predictor_outputs", ")", "# pyre-ignore[6]", "\n", ")", "\n", "# base_predictor_outputs is assumed to be a dataclass", "\n", "# reassign all the fields from base_predictor_outputs (no deep copy!), add new fields", "\n", "output", "=", "PredictorOutput", "(", "\n", "**", "base_predictor_outputs", ".", "__dict__", ",", "\n", "coarse_segm_confidence", "=", "None", ",", "\n", "fine_segm_confidence", "=", "None", ",", "\n", "sigma_1", "=", "None", ",", "\n", "sigma_2", "=", "None", ",", "\n", "kappa_u", "=", "None", ",", "\n", "kappa_v", "=", "None", ",", "\n", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse.DensePoseEmbeddingPredictor.__init__": [[21, 44], ["torch.nn.Module.__init__", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "utils.initialize_module_params", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.initialize_module_params"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize predictor using configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): input tensor size along the channel dimension\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_in", "=", "input_channels", "\n", "n_segm_chan", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_COARSE_SEGM_CHANNELS", "\n", "embed_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBED_SIZE", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "# coarse segmentation", "\n", "self", ".", "coarse_segm_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "n_segm_chan", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# embedding", "\n", "self", ".", "embed_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "embed_size", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "scale_factor", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UP_SCALE", "\n", "initialize_module_params", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse.DensePoseEmbeddingPredictor.interp2d": [[45, 57], ["detectron2.layers.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "interp2d", "(", "self", ",", "tensor_nchw", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Bilinear interpolation method to be used for upscaling\n\n        Args:\n            tensor_nchw (tensor): tensor of shape (N, C, H, W)\n        Return:\n            tensor of shape (N, C, Hout, Wout), where Hout and Wout are computed\n                by applying the scale factor to H and W\n        \"\"\"", "\n", "return", "interpolate", "(", "\n", "tensor_nchw", ",", "scale_factor", "=", "self", ".", "scale_factor", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse.DensePoseEmbeddingPredictor.forward": [[59, 71], ["cse.DensePoseEmbeddingPredictor.embed_lowres", "cse.DensePoseEmbeddingPredictor.coarse_segm_lowres", "cse.DensePoseEmbeddingPredictor.interp2d", "cse.DensePoseEmbeddingPredictor.interp2d", "structures.DensePoseEmbeddingPredictorOutput"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d"], ["", "def", "forward", "(", "self", ",", "head_outputs", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward step on DensePose head outputs\n\n        Args:\n            head_outputs (tensor): DensePose head outputs, tensor of shape [N, D, H, W]\n        \"\"\"", "\n", "embed_lowres", "=", "self", ".", "embed_lowres", "(", "head_outputs", ")", "\n", "coarse_segm_lowres", "=", "self", ".", "coarse_segm_lowres", "(", "head_outputs", ")", "\n", "embed", "=", "self", ".", "interp2d", "(", "embed_lowres", ")", "\n", "coarse_segm", "=", "self", ".", "interp2d", "(", "coarse_segm_lowres", ")", "\n", "return", "DensePoseEmbeddingPredictorOutput", "(", "embedding", "=", "embed", ",", "coarse_segm", "=", "coarse_segm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.__init__": [[34, 65], ["torch.nn.Module.__init__", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "detectron2.layers.ConvTranspose2d", "utils.initialize_module_params", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.initialize_module_params"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize predictor using configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): input tensor size along the channel dimension\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_in", "=", "input_channels", "\n", "n_segm_chan", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_COARSE_SEGM_CHANNELS", "\n", "dim_out_patches", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_PATCHES", "+", "1", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "# coarse segmentation", "\n", "self", ".", "ann_index_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "n_segm_chan", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# fine segmentation", "\n", "self", ".", "index_uv_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# U", "\n", "self", ".", "u_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# V", "\n", "self", ".", "v_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "scale_factor", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UP_SCALE", "\n", "initialize_module_params", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d": [[66, 78], ["detectron2.layers.interpolate"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "interp2d", "(", "self", ",", "tensor_nchw", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Bilinear interpolation method to be used for upscaling\n\n        Args:\n            tensor_nchw (tensor): tensor of shape (N, C, H, W)\n        Return:\n            tensor of shape (N, C, Hout, Wout), where Hout and Wout are computed\n                by applying the scale factor to H and W\n        \"\"\"", "\n", "return", "interpolate", "(", "\n", "tensor_nchw", ",", "scale_factor", "=", "self", ".", "scale_factor", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.forward": [[80, 94], ["structures.DensePoseChartPredictorOutput", "chart.DensePoseChartPredictor.interp2d", "chart.DensePoseChartPredictor.interp2d", "chart.DensePoseChartPredictor.interp2d", "chart.DensePoseChartPredictor.interp2d", "chart.DensePoseChartPredictor.ann_index_lowres", "chart.DensePoseChartPredictor.index_uv_lowres", "chart.DensePoseChartPredictor.u_lowres", "chart.DensePoseChartPredictor.v_lowres"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d"], ["", "def", "forward", "(", "self", ",", "head_outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward step on DensePose head outputs\n\n        Args:\n            head_outputs (tensor): DensePose head outputs, tensor of shape [N, D, H, W]\n        Return:\n           An instance of DensePoseChartPredictorOutput\n        \"\"\"", "\n", "return", "DensePoseChartPredictorOutput", "(", "\n", "coarse_segm", "=", "self", ".", "interp2d", "(", "self", ".", "ann_index_lowres", "(", "head_outputs", ")", ")", ",", "\n", "fine_segm", "=", "self", ".", "interp2d", "(", "self", ".", "index_uv_lowres", "(", "head_outputs", ")", ")", ",", "\n", "u", "=", "self", ".", "interp2d", "(", "self", ".", "u_lowres", "(", "head_outputs", ")", ")", ",", "\n", "v", "=", "self", ".", "interp2d", "(", "self", ".", "v_lowres", "(", "head_outputs", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin.__init__": [[31, 45], ["super().__init__", "densepose.modeling.confidence.DensePoseConfidenceModelConfig.from_cfg", "cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._initialize_confidence_estimation_layers", "densepose.modeling.utils.initialize_module_params"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.confidence.DensePoseConfidenceModelConfig.from_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._initialize_confidence_estimation_layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.utils.initialize_module_params"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ",", "input_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence predictor using configuration options.\n\n        Args:\n            cfg (CfgNode): configuration options\n            input_channels (int): number of input channels\n        \"\"\"", "\n", "# we rely on base predictor to call nn.Module.__init__", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "input_channels", ")", "# pyre-ignore[19]", "\n", "self", ".", "confidence_model_cfg", "=", "DensePoseConfidenceModelConfig", ".", "from_cfg", "(", "cfg", ")", "\n", "self", ".", "_initialize_confidence_estimation_layers", "(", "cfg", ",", "input_channels", ")", "\n", "self", ".", "_registry", "=", "{", "}", "\n", "initialize_module_params", "(", "self", ")", "# pyre-ignore[6]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._initialize_confidence_estimation_layers": [[46, 58], ["detectron2.layers.ConvTranspose2d", "int"], "methods", ["None"], ["", "def", "_initialize_confidence_estimation_layers", "(", "self", ",", "cfg", ":", "CfgNode", ",", "dim_in", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize confidence estimation layers based on configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n            dim_in (int): number of input channels\n        \"\"\"", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "            ", "self", ".", "coarse_segm_confidence_lowres", "=", "ConvTranspose2d", "(", "# pyre-ignore[16]", "\n", "dim_in", ",", "1", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin.forward": [[60, 94], ["super().forward", "cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._create_output_instance", "torch.nn.functional.softplus", "torch.repeat_interleave", "cse_confidence.DensePoseEmbeddingConfidencePredictorMixin.interp2d", "cse_confidence.DensePoseEmbeddingConfidencePredictorMixin.coarse_segm_confidence_lowres"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._create_output_instance", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.chart.DensePoseChartPredictor.interp2d"], ["", "", "def", "forward", "(", "self", ",", "head_outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward operation on head outputs used as inputs for the predictor.\n        Calls forward method from the base predictor and uses its outputs to compute\n        confidences.\n\n        Args:\n            head_outputs (Tensor): head outputs used as predictor inputs\n        Return:\n            An instance of outputs with confidences,\n            see `decorate_cse_predictor_output_class_with_confidences`\n        \"\"\"", "\n", "# assuming base class returns SIUV estimates in its first result", "\n", "base_predictor_outputs", "=", "super", "(", ")", ".", "forward", "(", "head_outputs", ")", "# pyre-ignore[16]", "\n", "\n", "# create output instance by extending base predictor outputs:", "\n", "output", "=", "self", ".", "_create_output_instance", "(", "base_predictor_outputs", ")", "\n", "\n", "if", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "enabled", ":", "\n", "# base predictor outputs are assumed to have `coarse_segm` attribute", "\n", "# base predictor is assumed to define `interp2d` method for bilinear interpolation", "\n", "            ", "output", ".", "coarse_segm_confidence", "=", "(", "\n", "F", ".", "softplus", "(", "\n", "self", ".", "interp2d", "(", "# pyre-ignore[16]", "\n", "self", ".", "coarse_segm_confidence_lowres", "(", "head_outputs", ")", "# pyre-ignore[16]", "\n", ")", "\n", ")", "\n", "+", "self", ".", "confidence_model_cfg", ".", "segm_confidence", ".", "epsilon", "\n", ")", "\n", "output", ".", "coarse_segm", "=", "base_predictor_outputs", ".", "coarse_segm", "*", "torch", ".", "repeat_interleave", "(", "\n", "output", ".", "coarse_segm_confidence", ",", "base_predictor_outputs", ".", "coarse_segm", ".", "shape", "[", "1", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.predictors.cse_confidence.DensePoseEmbeddingConfidencePredictorMixin._create_output_instance": [[95, 116], ["densepose.structures.decorate_cse_predictor_output_class_with_confidences", "densepose.structures.decorate_cse_predictor_output_class_with_confidences.", "type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.cse_confidence.decorate_cse_predictor_output_class_with_confidences"], ["", "def", "_create_output_instance", "(", "self", ",", "base_predictor_outputs", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Create an instance of predictor outputs by copying the outputs from the\n        base predictor and initializing confidence\n\n        Args:\n            base_predictor_outputs: an instance of base predictor outputs\n                (the outputs type is assumed to be a dataclass)\n        Return:\n           An instance of outputs with confidences\n        \"\"\"", "\n", "PredictorOutput", "=", "decorate_cse_predictor_output_class_with_confidences", "(", "\n", "type", "(", "base_predictor_outputs", ")", "# pyre-ignore[6]", "\n", ")", "\n", "# base_predictor_outputs is assumed to be a dataclass", "\n", "# reassign all the fields from base_predictor_outputs (no deep copy!), add new fields", "\n", "output", "=", "PredictorOutput", "(", "\n", "**", "base_predictor_outputs", ".", "__dict__", ",", "\n", "coarse_segm_confidence", "=", "None", ",", "\n", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_feature_embedder.VertexFeatureEmbedder.__init__": [[24, 44], ["torch.nn.Module.__init__", "torch.nn.Parameter", "vertex_feature_embedder.VertexFeatureEmbedder.reset_parameters", "torch.nn.Parameter", "vertex_feature_embedder.VertexFeatureEmbedder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "num_vertices", ":", "int", ",", "feature_dim", ":", "int", ",", "embed_dim", ":", "int", ",", "train_features", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize embedder, set random embeddings\n\n        Args:\n            num_vertices (int): number of vertices to embed\n            feature_dim (int): number of dimensions in the feature space\n            embed_dim (int): number of dimensions in the embedding space\n            train_features (bool): determines whether vertex features should\n                be trained (default: False)\n        \"\"\"", "\n", "super", "(", "VertexFeatureEmbedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "train_features", ":", "\n", "            ", "self", ".", "features", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_vertices", ",", "feature_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "\"features\"", ",", "torch", ".", "Tensor", "(", "num_vertices", ",", "feature_dim", ")", ")", "\n", "", "self", ".", "embeddings", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "feature_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_feature_embedder.VertexFeatureEmbedder.reset_parameters": [[45, 49], ["torch.no_grad", "vertex_feature_embedder.VertexFeatureEmbedder.features.zero_", "vertex_feature_embedder.VertexFeatureEmbedder.embeddings.zero_"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "features", ".", "zero_", "(", ")", "\n", "self", ".", "embeddings", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_feature_embedder.VertexFeatureEmbedder.forward": [[50, 60], ["utils.normalize_embeddings", "torch.mm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.normalize_embeddings"], ["", "def", "forward", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Produce vertex embeddings, a tensor of shape [N, D] where:\n            N = number of vertices\n            D = number of dimensions in the embedding space\n\n        Return:\n           Full vertex embeddings, a tensor of shape [N, D]\n        \"\"\"", "\n", "return", "normalize_embeddings", "(", "torch", ".", "mm", "(", "self", ".", "features", ",", "self", ".", "embeddings", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_feature_embedder.VertexFeatureEmbedder.load": [[61, 75], ["torch.no_grad", "detectron2.utils.file_io.PathManager.open", "pickle.load", "getattr().copy_", "torch.tensor().float().to", "getattr", "torch.tensor().float", "getattr", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "@", "torch", ".", "no_grad", "(", ")", "# pyre-ignore[56]", "\n", "def", "load", "(", "self", ",", "fpath", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Load data from a file\n\n        Args:\n            fpath (str): file path to load data from\n        \"\"\"", "\n", "with", "PathManager", ".", "open", "(", "fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "hFile", ")", "# pyre-ignore[6]", "\n", "for", "name", "in", "[", "\"features\"", ",", "\"embeddings\"", "]", ":", "\n", "                ", "if", "name", "in", "data", ":", "\n", "                    ", "getattr", "(", "self", ",", "name", ")", ".", "copy_", "(", "\n", "torch", ".", "tensor", "(", "data", "[", "name", "]", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "getattr", "(", "self", ",", "name", ")", ".", "device", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.__init__": [[20, 31], ["torch.nn.Module.__init__", "torch.nn.Parameter", "vertex_direct_embedder.VertexDirectEmbedder.reset_parameters", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_vertices", ":", "int", ",", "embed_dim", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initialize embedder, set random embeddings\n\n        Args:\n            num_vertices (int): number of vertices to embed\n            embed_dim (int): number of dimensions in the embedding space\n        \"\"\"", "\n", "super", "(", "VertexDirectEmbedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddings", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_vertices", ",", "embed_dim", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.reset_parameters": [[32, 38], ["torch.no_grad", "vertex_direct_embedder.VertexDirectEmbedder.embeddings.zero_"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset embeddings to random values\n        \"\"\"", "\n", "self", ".", "embeddings", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.forward": [[39, 49], ["utils.normalize_embeddings"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.normalize_embeddings"], ["", "def", "forward", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Produce vertex embeddings, a tensor of shape [N, D] where:\n            N = number of vertices\n            D = number of dimensions in the embedding space\n\n        Return:\n           Full vertex embeddings, a tensor of shape [N, D]\n        \"\"\"", "\n", "return", "normalize_embeddings", "(", "self", ".", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load": [[50, 64], ["torch.no_grad", "detectron2.utils.file_io.PathManager.open", "pickle.load", "getattr().copy_", "torch.tensor().float().to", "getattr", "torch.tensor().float", "getattr", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["", "@", "torch", ".", "no_grad", "(", ")", "# pyre-ignore[56]", "\n", "def", "load", "(", "self", ",", "fpath", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Load data from a file\n\n        Args:\n            fpath (str): file path to load data from\n        \"\"\"", "\n", "with", "PathManager", ".", "open", "(", "fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "hFile", ")", "# pyre-ignore[6]", "\n", "for", "name", "in", "[", "\"embeddings\"", "]", ":", "\n", "                ", "if", "name", "in", "data", ":", "\n", "                    ", "getattr", "(", "self", ",", "name", ")", ".", "copy_", "(", "\n", "torch", ".", "tensor", "(", "data", "[", "name", "]", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "getattr", "(", "self", ",", "name", ")", ".", "device", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.Embedder.__init__": [[74, 94], ["torch.nn.Module.__init__", "set", "logging.getLogger", "cfg.MODEL.ROI_DENSEPOSE_HEAD.CSE.EMBEDDERS.items", "logging.getLogger.info", "embedder.Embedder.add_module", "embedder.Embedder.mesh_names.add", "embedder.Embedder.load_from_model_checkpoint", "embedder.create_embedder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.set", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.timer.Timer.add", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.Embedder.load_from_model_checkpoint", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.create_embedder"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "\"\"\"\n        Initialize mesh embedders. An embedder for mesh `i` is stored in a submodule\n        \"embedder_{i}\".\n\n        Args:\n            cfg (CfgNode): configuration options\n        \"\"\"", "\n", "super", "(", "Embedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mesh_names", "=", "set", "(", ")", "\n", "embedder_dim", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBED_SIZE", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "for", "mesh_name", ",", "embedder_spec", "in", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBEDDERS", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Adding embedder embedder_{mesh_name} with spec {embedder_spec}\"", ")", "\n", "self", ".", "add_module", "(", "# pyre-ignore[16]", "\n", "f\"embedder_{mesh_name}\"", ",", "create_embedder", "(", "embedder_spec", ",", "embedder_dim", ")", "\n", ")", "\n", "self", ".", "mesh_names", ".", "add", "(", "mesh_name", ")", "\n", "", "if", "cfg", ".", "MODEL", ".", "WEIGHTS", "!=", "\"\"", ":", "\n", "            ", "self", ".", "load_from_model_checkpoint", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.Embedder.load_from_model_checkpoint": [[95, 115], ["fpath.endswith", "embedder.Embedder.load_state_dict", "detectron2.utils.file_io.PathManager.open", "pickle.load", "detectron2.utils.file_io.PathManager.open", "torch.load", "key.startswith", "isinstance", "torch.device", "torch.from_numpy", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["", "", "def", "load_from_model_checkpoint", "(", "self", ",", "fpath", ":", "str", ",", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "if", "prefix", "is", "None", ":", "\n", "            ", "prefix", "=", "Embedder", ".", "DEFAULT_MODEL_CHECKPOINT_PREFIX", "\n", "", "state_dict", "=", "None", "\n", "if", "fpath", ".", "endswith", "(", "\".pkl\"", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "                ", "state_dict", "=", "pickle", ".", "load", "(", "hFile", ",", "encoding", "=", "\"latin1\"", ")", "# pyre-ignore[6]", "\n", "", "", "else", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "fpath", ",", "\"rb\"", ")", "as", "hFile", ":", "\n", "                ", "state_dict", "=", "torch", ".", "load", "(", "hFile", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "", "", "if", "state_dict", "is", "not", "None", "and", "\"model\"", "in", "state_dict", ":", "\n", "            ", "state_dict_local", "=", "{", "}", "\n", "for", "key", "in", "state_dict", "[", "\"model\"", "]", ":", "\n", "                ", "if", "key", ".", "startswith", "(", "prefix", ")", ":", "\n", "                    ", "v_key", "=", "state_dict", "[", "\"model\"", "]", "[", "key", "]", "\n", "if", "isinstance", "(", "v_key", ",", "np", ".", "ndarray", ")", ":", "\n", "                        ", "v_key", "=", "torch", ".", "from_numpy", "(", "v_key", ")", "\n", "", "state_dict_local", "[", "key", "[", "len", "(", "prefix", ")", ":", "]", "]", "=", "v_key", "\n", "# non-strict loading to finetune on different meshes", "\n", "", "", "self", ".", "load_state_dict", "(", "state_dict_local", ",", "strict", "=", "False", ")", "# pyre-ignore[28]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.Embedder.forward": [[116, 128], ["getattr"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "mesh_name", ":", "str", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Produce vertex embeddings for the specific mesh; vertex embeddings are\n        a tensor of shape [N, D] where:\n            N = number of vertices\n            D = number of dimensions in the embedding space\n        Args:\n            mesh_name (str): name of a mesh for which to obtain vertex embeddings\n        Return:\n            Vertex embeddings, a tensor of shape [N, D]\n        \"\"\"", "\n", "return", "getattr", "(", "self", ",", "f\"embedder_{mesh_name}\"", ")", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.Embedder.has_embeddings": [[129, 131], ["hasattr"], "methods", ["None"], ["", "def", "has_embeddings", "(", "self", ",", "mesh_name", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "hasattr", "(", "self", ",", "f\"embedder_{mesh_name}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.create_embedder": [[29, 64], ["embedder.EmbedderType", "vertex_direct_embedder.VertexDirectEmbedder", "vertex_feature_embedder.VertexFeatureEmbedder.requires_grad_", "vertex_feature_embedder.VertexFeatureEmbedder.load", "vertex_feature_embedder.VertexFeatureEmbedder", "ValueError", "vertex_feature_embedder.VertexFeatureEmbedder.load"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load"], ["", "def", "create_embedder", "(", "embedder_spec", ":", "CfgNode", ",", "embedder_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "\"\"\"\n    Create an embedder based on the provided configuration\n\n    Args:\n        embedder_spec (CfgNode): embedder configuration\n        embedder_dim (int): embedding space dimensionality\n    Return:\n        An embedder instance for the specified configuration\n        Raises ValueError, in case of unexpected  embedder type\n    \"\"\"", "\n", "embedder_type", "=", "EmbedderType", "(", "embedder_spec", ".", "TYPE", ")", "\n", "if", "embedder_type", "==", "EmbedderType", ".", "VERTEX_DIRECT", ":", "\n", "        ", "embedder", "=", "VertexDirectEmbedder", "(", "\n", "num_vertices", "=", "embedder_spec", ".", "NUM_VERTICES", ",", "\n", "embed_dim", "=", "embedder_dim", ",", "\n", ")", "\n", "if", "embedder_spec", ".", "INIT_FILE", "!=", "\"\"", ":", "\n", "            ", "embedder", ".", "load", "(", "embedder_spec", ".", "INIT_FILE", ")", "\n", "", "", "elif", "embedder_type", "==", "EmbedderType", ".", "VERTEX_FEATURE", ":", "\n", "        ", "embedder", "=", "VertexFeatureEmbedder", "(", "\n", "num_vertices", "=", "embedder_spec", ".", "NUM_VERTICES", ",", "\n", "feature_dim", "=", "embedder_spec", ".", "FEATURE_DIM", ",", "\n", "embed_dim", "=", "embedder_dim", ",", "\n", "train_features", "=", "embedder_spec", ".", "FEATURES_TRAINABLE", ",", "\n", ")", "\n", "if", "embedder_spec", ".", "INIT_FILE", "!=", "\"\"", ":", "\n", "            ", "embedder", ".", "load", "(", "embedder_spec", ".", "INIT_FILE", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unexpected embedder type {embedder_type}\"", ")", "\n", "\n", "", "if", "not", "embedder_spec", ".", "IS_TRAINABLE", ":", "\n", "        ", "embedder", ".", "requires_grad_", "(", "False", ")", "# pyre-ignore[16]", "\n", "\n", "", "return", "embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.squared_euclidean_distance_matrix": [[7, 23], ["torch.mm", "torch.mm.contiguous", "pts2.t"], "function", ["None"], ["\n", "\n", "def", "cat", "(", "tensors", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Efficient version of torch.cat that avoids a copy if there is only a single element in a list\n    \"\"\"", "\n", "assert", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", "\n", "if", "len", "(", "tensors", ")", "==", "1", ":", "\n", "        ", "return", "tensors", "[", "0", "]", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.normalize_embeddings": [[25, 37], ["torch.clamp", "embeddings.norm"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.get_closest_vertices_mask_from_ES": [[40, 84], ["[].to", "[].to", "torch.zeros", "embedding_resized[].t", "range", "torch.cat", "[].to.argmax", "len", "edm.append", "torch.argmin", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "utils.squared_euclidean_distance_matrix", "len"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.squared_euclidean_distance_matrix"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.DensePoseChartWithConfidenceLoss.__init__": [[21, 31], ["chart.DensePoseChartLoss.__init__", "DensePoseConfidenceModelConfig.from_cfg", "chart_with_confidences.IIDIsotropicGaussianUVLoss", "chart_with_confidences.IndepAnisotropicGaussianUVLoss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.confidence.DensePoseConfidenceModelConfig.from_cfg"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "confidence_model_cfg", "=", "DensePoseConfidenceModelConfig", ".", "from_cfg", "(", "cfg", ")", "\n", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "==", "DensePoseUVConfidenceType", ".", "IID_ISO", ":", "\n", "            ", "self", ".", "uv_loss_with_confidences", "=", "IIDIsotropicGaussianUVLoss", "(", "\n", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "epsilon", "\n", ")", "\n", "", "elif", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "==", "DensePoseUVConfidenceType", ".", "INDEP_ANISO", ":", "\n", "            ", "self", ".", "uv_loss_with_confidences", "=", "IndepAnisotropicGaussianUVLoss", "(", "\n", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "epsilon", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.DensePoseChartWithConfidenceLoss.produce_fake_densepose_losses_uv": [[33, 70], ["super().produce_fake_densepose_losses_uv", "densepose_predictor_outputs.u.sum", "densepose_predictor_outputs.v.sum", "densepose_predictor_outputs.sigma_2.sum", "densepose_predictor_outputs.kappa_v.sum", "densepose_predictor_outputs.sigma_2.sum", "densepose_predictor_outputs.kappa_u.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses_uv"], ["", "", "def", "produce_fake_densepose_losses_uv", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ")", "->", "LossDict", ":", "\n", "        ", "\"\"\"\n        Overrides fake losses for fine segmentation and U/V coordinates to\n        include computation graphs for additional confidence parameters.\n        These are used when no suitable ground truth data was found in a batch.\n        The loss has a value 0 and is primarily used to construct the computation graph,\n        so that `DistributedDataParallel` has similar graphs on all GPUs and can\n        perform reduction properly.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor outputs, an object\n                of a dataclass that is assumed to have the following attributes:\n             * fine_segm - fine segmentation estimates, tensor of shape [N, C, S, S]\n             * u - U coordinate estimates per fine labels, tensor of shape [N, C, S, S]\n             * v - V coordinate estimates per fine labels, tensor of shape [N, C, S, S]\n        Return:\n            dict: str -> tensor: dict of losses with the following entries:\n             * `loss_densepose_U`: has value 0\n             * `loss_densepose_V`: has value 0\n             * `loss_densepose_I`: has value 0\n        \"\"\"", "\n", "conf_type", "=", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "\n", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "enabled", ":", "\n", "            ", "loss_uv", "=", "(", "\n", "densepose_predictor_outputs", ".", "u", ".", "sum", "(", ")", "+", "densepose_predictor_outputs", ".", "v", ".", "sum", "(", ")", "\n", ")", "*", "0", "\n", "if", "conf_type", "==", "DensePoseUVConfidenceType", ".", "IID_ISO", ":", "\n", "                ", "loss_uv", "+=", "densepose_predictor_outputs", ".", "sigma_2", ".", "sum", "(", ")", "*", "0", "\n", "", "elif", "conf_type", "==", "DensePoseUVConfidenceType", ".", "INDEP_ANISO", ":", "\n", "                ", "loss_uv", "+=", "(", "\n", "densepose_predictor_outputs", ".", "sigma_2", ".", "sum", "(", ")", "\n", "+", "densepose_predictor_outputs", ".", "kappa_u", ".", "sum", "(", ")", "\n", "+", "densepose_predictor_outputs", ".", "kappa_v", ".", "sum", "(", ")", "\n", ")", "*", "0", "\n", "", "return", "{", "\"loss_densepose_UV\"", ":", "loss_uv", "}", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "produce_fake_densepose_losses_uv", "(", "densepose_predictor_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.DensePoseChartWithConfidenceLoss.produce_densepose_losses_uv": [[71, 116], ["super().produce_densepose_losses_uv", "interpolator.extract_at_points", "interpolator.extract_at_points", "interpolator.extract_at_points", "chart_with_confidences.DensePoseChartWithConfidenceLoss.uv_loss_with_confidences", "interpolator.extract_at_points", "interpolator.extract_at_points", "chart_with_confidences.DensePoseChartWithConfidenceLoss.uv_loss_with_confidences"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_densepose_losses_uv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points"], ["", "", "def", "produce_densepose_losses_uv", "(", "\n", "self", ",", "\n", "proposals_with_gt", ":", "List", "[", "Instances", "]", ",", "\n", "densepose_predictor_outputs", ":", "Any", ",", "\n", "packed_annotations", ":", "Any", ",", "\n", "interpolator", ":", "BilinearInterpolationHelper", ",", "\n", "j_valid_fg", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "LossDict", ":", "\n", "        ", "conf_type", "=", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "type", "\n", "if", "self", ".", "confidence_model_cfg", ".", "uv_confidence", ".", "enabled", ":", "\n", "            ", "u_gt", "=", "packed_annotations", ".", "u_gt", "[", "j_valid_fg", "]", "\n", "u_est", "=", "interpolator", ".", "extract_at_points", "(", "densepose_predictor_outputs", ".", "u", ")", "[", "j_valid_fg", "]", "\n", "v_gt", "=", "packed_annotations", ".", "v_gt", "[", "j_valid_fg", "]", "\n", "v_est", "=", "interpolator", ".", "extract_at_points", "(", "densepose_predictor_outputs", ".", "v", ")", "[", "j_valid_fg", "]", "\n", "sigma_2_est", "=", "interpolator", ".", "extract_at_points", "(", "densepose_predictor_outputs", ".", "sigma_2", ")", "[", "\n", "j_valid_fg", "\n", "]", "\n", "if", "conf_type", "==", "DensePoseUVConfidenceType", ".", "IID_ISO", ":", "\n", "                ", "return", "{", "\n", "\"loss_densepose_UV\"", ":", "(", "\n", "self", ".", "uv_loss_with_confidences", "(", "u_est", ",", "v_est", ",", "sigma_2_est", ",", "u_gt", ",", "v_gt", ")", "\n", "*", "self", ".", "w_points", "\n", ")", "\n", "}", "\n", "", "elif", "conf_type", "in", "[", "DensePoseUVConfidenceType", ".", "INDEP_ANISO", "]", ":", "\n", "                ", "kappa_u_est", "=", "interpolator", ".", "extract_at_points", "(", "densepose_predictor_outputs", ".", "kappa_u", ")", "[", "\n", "j_valid_fg", "\n", "]", "\n", "kappa_v_est", "=", "interpolator", ".", "extract_at_points", "(", "densepose_predictor_outputs", ".", "kappa_v", ")", "[", "\n", "j_valid_fg", "\n", "]", "\n", "return", "{", "\n", "\"loss_densepose_UV\"", ":", "(", "\n", "self", ".", "uv_loss_with_confidences", "(", "\n", "u_est", ",", "v_est", ",", "sigma_2_est", ",", "kappa_u_est", ",", "kappa_v_est", ",", "u_gt", ",", "v_gt", "\n", ")", "\n", "*", "self", ".", "w_points", "\n", ")", "\n", "}", "\n", "", "", "return", "super", "(", ")", ".", "produce_densepose_losses_uv", "(", "\n", "proposals_with_gt", ",", "\n", "densepose_predictor_outputs", ",", "\n", "packed_annotations", ",", "\n", "interpolator", ",", "\n", "j_valid_fg", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.IIDIsotropicGaussianUVLoss.__init__": [[132, 136], ["torch.nn.Module.__init__", "math.log"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "sigma_lower_bound", ":", "float", ")", ":", "\n", "        ", "super", "(", "IIDIsotropicGaussianUVLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigma_lower_bound", "=", "sigma_lower_bound", "\n", "self", ".", "log2pi", "=", "math", ".", "log", "(", "2", "*", "math", ".", "pi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.IIDIsotropicGaussianUVLoss.forward": [[137, 154], ["loss.sum", "torch.nn.functional.softplus", "torch.log"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "u", ":", "torch", ".", "Tensor", ",", "\n", "v", ":", "torch", ".", "Tensor", ",", "\n", "sigma_u", ":", "torch", ".", "Tensor", ",", "\n", "target_u", ":", "torch", ".", "Tensor", ",", "\n", "target_v", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "# compute $\\sigma_i^2$", "\n", "# use sigma_lower_bound to avoid degenerate solution for variance", "\n", "# (sigma -> 0)", "\n", "        ", "sigma2", "=", "F", ".", "softplus", "(", "sigma_u", ")", "+", "self", ".", "sigma_lower_bound", "\n", "# compute \\|delta_i\\|^2", "\n", "delta_t_delta", "=", "(", "u", "-", "target_u", ")", "**", "2", "+", "(", "v", "-", "target_v", ")", "**", "2", "\n", "# the total loss from the formula above:", "\n", "loss", "=", "0.5", "*", "(", "self", ".", "log2pi", "+", "2", "*", "torch", ".", "log", "(", "sigma2", ")", "+", "delta_t_delta", "/", "sigma2", ")", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.IndepAnisotropicGaussianUVLoss.__init__": [[172, 176], ["torch.nn.Module.__init__", "math.log"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "sigma_lower_bound", ":", "float", ")", ":", "\n", "        ", "super", "(", "IndepAnisotropicGaussianUVLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigma_lower_bound", "=", "sigma_lower_bound", "\n", "self", ".", "log2pi", "=", "math", ".", "log", "(", "2", "*", "math", ".", "pi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart_with_confidences.IndepAnisotropicGaussianUVLoss.forward": [[177, 206], ["loss.sum", "torch.nn.functional.softplus", "torch.log"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "u", ":", "torch", ".", "Tensor", ",", "\n", "v", ":", "torch", ".", "Tensor", ",", "\n", "sigma_u", ":", "torch", ".", "Tensor", ",", "\n", "kappa_u_est", ":", "torch", ".", "Tensor", ",", "\n", "kappa_v_est", ":", "torch", ".", "Tensor", ",", "\n", "target_u", ":", "torch", ".", "Tensor", ",", "\n", "target_v", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "# compute $\\sigma_i^2$", "\n", "        ", "sigma2", "=", "F", ".", "softplus", "(", "sigma_u", ")", "+", "self", ".", "sigma_lower_bound", "\n", "# compute \\|r_i\\|^2", "\n", "r_sqnorm2", "=", "kappa_u_est", "**", "2", "+", "kappa_v_est", "**", "2", "\n", "delta_u", "=", "u", "-", "target_u", "\n", "delta_v", "=", "v", "-", "target_v", "\n", "# compute \\|delta_i\\|^2", "\n", "delta_sqnorm", "=", "delta_u", "**", "2", "+", "delta_v", "**", "2", "\n", "delta_u_r_u", "=", "delta_u", "*", "kappa_u_est", "\n", "delta_v_r_v", "=", "delta_v", "*", "kappa_v_est", "\n", "# compute the scalar product <delta_i, r_i>", "\n", "delta_r", "=", "delta_u_r_u", "+", "delta_v_r_v", "\n", "# compute squared scalar product <delta_i, r_i>^2", "\n", "delta_r_sqnorm", "=", "delta_r", "**", "2", "\n", "denom2", "=", "sigma2", "*", "(", "sigma2", "+", "r_sqnorm2", ")", "\n", "loss", "=", "0.5", "*", "(", "\n", "self", ".", "log2pi", "+", "torch", ".", "log", "(", "denom2", ")", "+", "delta_sqnorm", "/", "sigma2", "-", "delta_r_sqnorm", "/", "denom2", "\n", ")", "\n", "return", "loss", ".", "sum", "(", ")", "# pyre-ignore[16]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed_utils.CseAnnotationsAccumulator.__init__": [[32, 45], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "x_gt", "=", "[", "]", "\n", "self", ".", "y_gt", "=", "[", "]", "\n", "self", ".", "s_gt", "=", "[", "]", "\n", "self", ".", "vertex_mesh_ids_gt", "=", "[", "]", "\n", "self", ".", "vertex_ids_gt", "=", "[", "]", "\n", "self", ".", "bbox_xywh_gt", "=", "[", "]", "\n", "self", ".", "bbox_xywh_est", "=", "[", "]", "\n", "self", ".", "point_bbox_with_dp_indices", "=", "[", "]", "\n", "self", ".", "point_bbox_indices", "=", "[", "]", "\n", "self", ".", "bbox_indices", "=", "[", "]", "\n", "self", ".", "nxt_bbox_with_dp_index", "=", "0", "\n", "self", ".", "nxt_bbox_index", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed_utils.CseAnnotationsAccumulator.accumulate": [[46, 79], ["detectron2.structures.BoxMode.convert", "detectron2.structures.BoxMode.convert", "len", "zip", "instances_one_image.proposal_boxes.tensor.clone", "instances_one_image.gt_boxes.tensor.clone", "len", "len", "len", "hasattr", "embed_utils.CseAnnotationsAccumulator._do_accumulate", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator._do_accumulate"], ["", "def", "accumulate", "(", "self", ",", "instances_one_image", ":", "Instances", ")", ":", "\n", "        ", "\"\"\"\n        Accumulate instances data for one image\n\n        Args:\n            instances_one_image (Instances): instances data to accumulate\n        \"\"\"", "\n", "boxes_xywh_est", "=", "BoxMode", ".", "convert", "(", "\n", "instances_one_image", ".", "proposal_boxes", ".", "tensor", ".", "clone", "(", ")", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", "\n", ")", "\n", "boxes_xywh_gt", "=", "BoxMode", ".", "convert", "(", "\n", "instances_one_image", ".", "gt_boxes", ".", "tensor", ".", "clone", "(", ")", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", "\n", ")", "\n", "n_matches", "=", "len", "(", "boxes_xywh_gt", ")", "\n", "assert", "n_matches", "==", "len", "(", "\n", "boxes_xywh_est", "\n", ")", ",", "f\"Got {len(boxes_xywh_est)} proposal boxes and {len(boxes_xywh_gt)} GT boxes\"", "\n", "if", "not", "n_matches", ":", "\n", "# no detection - GT matches", "\n", "            ", "return", "\n", "", "if", "(", "\n", "not", "hasattr", "(", "instances_one_image", ",", "\"gt_densepose\"", ")", "\n", "or", "instances_one_image", ".", "gt_densepose", "is", "None", "\n", ")", ":", "\n", "# no densepose GT for the detections, just increase the bbox index", "\n", "            ", "self", ".", "nxt_bbox_index", "+=", "n_matches", "\n", "return", "\n", "", "for", "box_xywh_est", ",", "box_xywh_gt", ",", "dp_gt", "in", "zip", "(", "\n", "boxes_xywh_est", ",", "boxes_xywh_gt", ",", "instances_one_image", ".", "gt_densepose", "\n", ")", ":", "\n", "            ", "if", "(", "dp_gt", "is", "not", "None", ")", "and", "(", "len", "(", "dp_gt", ".", "x", ")", ">", "0", ")", ":", "\n", "                ", "self", ".", "_do_accumulate", "(", "box_xywh_gt", ",", "box_xywh_est", ",", "dp_gt", ")", "# pyre-ignore[6]", "\n", "", "self", ".", "nxt_bbox_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed_utils.CseAnnotationsAccumulator._do_accumulate": [[80, 107], ["embed_utils.CseAnnotationsAccumulator.x_gt.append", "embed_utils.CseAnnotationsAccumulator.y_gt.append", "hasattr", "embed_utils.CseAnnotationsAccumulator.vertex_ids_gt.append", "embed_utils.CseAnnotationsAccumulator.vertex_mesh_ids_gt.append", "embed_utils.CseAnnotationsAccumulator.bbox_xywh_gt.append", "embed_utils.CseAnnotationsAccumulator.bbox_xywh_est.append", "embed_utils.CseAnnotationsAccumulator.point_bbox_with_dp_indices.append", "embed_utils.CseAnnotationsAccumulator.point_bbox_indices.append", "embed_utils.CseAnnotationsAccumulator.bbox_indices.append", "embed_utils.CseAnnotationsAccumulator.s_gt.append", "torch.full_like", "box_xywh_gt.view", "box_xywh_est.view", "torch.full_like", "torch.full_like", "dp_gt.segm.unsqueeze"], "methods", ["None"], ["", "", "def", "_do_accumulate", "(", "self", ",", "box_xywh_gt", ":", "torch", ".", "Tensor", ",", "box_xywh_est", ":", "torch", ".", "Tensor", ",", "dp_gt", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Accumulate instances data for one image, given that the data is not empty\n\n        Args:\n            box_xywh_gt (tensor): GT bounding box\n            box_xywh_est (tensor): estimated bounding box\n            dp_gt: GT densepose data with the following attributes:\n             - x: normalized X coordinates\n             - y: normalized Y coordinates\n             - segm: tensor of size [S, S] with coarse segmentation\n             -\n        \"\"\"", "\n", "self", ".", "x_gt", ".", "append", "(", "dp_gt", ".", "x", ")", "\n", "self", ".", "y_gt", ".", "append", "(", "dp_gt", ".", "y", ")", "\n", "if", "hasattr", "(", "dp_gt", ",", "\"segm\"", ")", ":", "\n", "            ", "self", ".", "s_gt", ".", "append", "(", "dp_gt", ".", "segm", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "self", ".", "vertex_ids_gt", ".", "append", "(", "dp_gt", ".", "vertex_ids", ")", "\n", "self", ".", "vertex_mesh_ids_gt", ".", "append", "(", "torch", ".", "full_like", "(", "dp_gt", ".", "vertex_ids", ",", "dp_gt", ".", "mesh_id", ")", ")", "\n", "self", ".", "bbox_xywh_gt", ".", "append", "(", "box_xywh_gt", ".", "view", "(", "-", "1", ",", "4", ")", ")", "\n", "self", ".", "bbox_xywh_est", ".", "append", "(", "box_xywh_est", ".", "view", "(", "-", "1", ",", "4", ")", ")", "\n", "self", ".", "point_bbox_with_dp_indices", ".", "append", "(", "\n", "torch", ".", "full_like", "(", "dp_gt", ".", "vertex_ids", ",", "self", ".", "nxt_bbox_with_dp_index", ")", "\n", ")", "\n", "self", ".", "point_bbox_indices", ".", "append", "(", "torch", ".", "full_like", "(", "dp_gt", ".", "vertex_ids", ",", "self", ".", "nxt_bbox_index", ")", ")", "\n", "self", ".", "bbox_indices", ".", "append", "(", "self", ".", "nxt_bbox_index", ")", "\n", "self", ".", "nxt_bbox_with_dp_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed_utils.CseAnnotationsAccumulator.pack": [[108, 134], ["embed_utils.PackedCseAnnotations", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.as_tensor", "torch.cat", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "pack", "(", "self", ")", "->", "Optional", "[", "PackedCseAnnotations", "]", ":", "\n", "        ", "\"\"\"\n        Pack data into tensors\n        \"\"\"", "\n", "if", "not", "len", "(", "self", ".", "x_gt", ")", ":", "\n", "# TODO:", "\n", "# returning proper empty annotations would require", "\n", "# creating empty tensors of appropriate shape and", "\n", "# type on an appropriate device;", "\n", "# we return None so far to indicate empty annotations", "\n", "            ", "return", "None", "\n", "", "return", "PackedCseAnnotations", "(", "\n", "x_gt", "=", "torch", ".", "cat", "(", "self", ".", "x_gt", ",", "0", ")", ",", "\n", "y_gt", "=", "torch", ".", "cat", "(", "self", ".", "y_gt", ",", "0", ")", ",", "\n", "vertex_mesh_ids_gt", "=", "torch", ".", "cat", "(", "self", ".", "vertex_mesh_ids_gt", ",", "0", ")", ",", "\n", "vertex_ids_gt", "=", "torch", ".", "cat", "(", "self", ".", "vertex_ids_gt", ",", "0", ")", ",", "\n", "# ignore segmentation annotations, if not all the instances contain those", "\n", "coarse_segm_gt", "=", "torch", ".", "cat", "(", "self", ".", "s_gt", ",", "0", ")", "\n", "if", "len", "(", "self", ".", "s_gt", ")", "==", "len", "(", "self", ".", "bbox_xywh_gt", ")", "\n", "else", "None", ",", "\n", "bbox_xywh_gt", "=", "torch", ".", "cat", "(", "self", ".", "bbox_xywh_gt", ",", "0", ")", ",", "\n", "bbox_xywh_est", "=", "torch", ".", "cat", "(", "self", ".", "bbox_xywh_est", ",", "0", ")", ",", "\n", "point_bbox_with_dp_indices", "=", "torch", ".", "cat", "(", "self", ".", "point_bbox_with_dp_indices", ",", "0", ")", ",", "\n", "point_bbox_indices", "=", "torch", ".", "cat", "(", "self", ".", "point_bbox_indices", ",", "0", ")", ",", "\n", "bbox_indices", "=", "torch", ".", "as_tensor", "(", "\n", "self", ".", "bbox_indices", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "x_gt", "[", "0", "]", ".", "device", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.segm.SegmentationLoss.__init__": [[21, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "\"\"\"\n        Initialize segmentation loss from configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n        \"\"\"", "\n", "self", ".", "heatmap_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "HEATMAP_SIZE", "\n", "self", ".", "n_segm_chan", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_COARSE_SEGM_CHANNELS", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.segm.SegmentationLoss.__call__": [[31, 68], ["torch.nn.functional.cross_entropy", "segm.SegmentationLoss.fake_value", "torch.no_grad", "utils.resample_data().squeeze", "utils.resample_data().squeeze.long", "utils.resample_data", "packed_annotations.coarse_segm_gt.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.resample_data"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "proposals_with_gt", ":", "List", "[", "Instances", "]", ",", "\n", "densepose_predictor_outputs", ":", "Any", ",", "\n", "packed_annotations", ":", "Any", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Compute segmentation loss as cross-entropy on aligned segmentation\n        ground truth and estimated scores.\n\n        Args:\n            proposals_with_gt (list of Instances): detections with associated ground truth data\n            densepose_predictor_outputs: an object of a dataclass that contains predictor outputs\n                with estimated values; assumed to have the following attributes:\n                * coarse_segm - coarse segmentation estimates, tensor of shape [N, D, S, S]\n            packed_annotations: packed annotations for efficient loss computation;\n                the following attributes are used:\n                 - coarse_segm_gt\n                 - bbox_xywh_gt\n                 - bbox_xywh_est\n        \"\"\"", "\n", "if", "packed_annotations", ".", "coarse_segm_gt", "is", "None", ":", "\n", "            ", "return", "self", ".", "fake_value", "(", "densepose_predictor_outputs", ")", "\n", "", "coarse_segm_est", "=", "densepose_predictor_outputs", ".", "coarse_segm", "[", "packed_annotations", ".", "bbox_indices", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "coarse_segm_gt", "=", "resample_data", "(", "\n", "packed_annotations", ".", "coarse_segm_gt", ".", "unsqueeze", "(", "1", ")", ",", "\n", "packed_annotations", ".", "bbox_xywh_gt", ",", "\n", "packed_annotations", ".", "bbox_xywh_est", ",", "\n", "self", ".", "heatmap_size", ",", "\n", "self", ".", "heatmap_size", ",", "\n", "mode", "=", "\"nearest\"", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", ")", ".", "squeeze", "(", "1", ")", "\n", "", "if", "self", ".", "n_segm_chan", "==", "2", ":", "\n", "            ", "coarse_segm_gt", "=", "coarse_segm_gt", ">", "0", "\n", "", "return", "F", ".", "cross_entropy", "(", "coarse_segm_est", ",", "coarse_segm_gt", ".", "long", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.segm.SegmentationLoss.fake_value": [[69, 84], ["densepose_predictor_outputs.coarse_segm.sum"], "methods", ["None"], ["", "def", "fake_value", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Fake segmentation loss used when no suitable ground truth data\n        was found in a batch. The loss has a value 0 and is primarily used to\n        construct the computation graph, so that `DistributedDataParallel`\n        has similar graphs on all GPUs and can perform reduction properly.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor outputs, an object\n                of a dataclass that is assumed to have `coarse_segm`\n                attribute\n        Return:\n            Zero value loss with proper computation graph\n        \"\"\"", "\n", "return", "densepose_predictor_outputs", ".", "coarse_segm", ".", "sum", "(", ")", "*", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed.EmbeddingLoss.__init__": [[28, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "\"\"\"\n        Initialize embedding loss from config\n        \"\"\"", "\n", "self", ".", "embdist_gauss_sigma", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBEDDING_DIST_GAUSS_SIGMA", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed.EmbeddingLoss.__call__": [[34, 109], ["packed_annotations.vertex_mesh_ids_gt.unique", "mesh_id_tensor.item", "densepose.data.meshes.catalog.MeshCatalog.get_mesh_name", "densepose.modeling.cse.utils.normalize_embeddings", "embedder", "torch.nn.functional.cross_entropy", "densepose.modeling.cse.utils.squared_euclidean_distance_matrix", "embed.EmbeddingLoss.fake_value", "interpolator.extract_at_points", "slice"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.get_mesh_name", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.normalize_embeddings", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.squared_euclidean_distance_matrix", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "proposals_with_gt", ":", "List", "[", "Instances", "]", ",", "\n", "densepose_predictor_outputs", ":", "Any", ",", "\n", "packed_annotations", ":", "PackedCseAnnotations", ",", "\n", "interpolator", ":", "BilinearInterpolationHelper", ",", "\n", "embedder", ":", "nn", ".", "Module", ",", "\n", ")", "->", "Dict", "[", "int", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Produces losses for estimated embeddings given annotated vertices.\n        Embeddings for all the vertices of a mesh are computed by the embedder.\n        Embeddings for observed pixels are estimated by a predictor.\n        Losses are computed as cross-entropy for squared distances between\n        observed vertex embeddings and all mesh vertex embeddings given\n        ground truth vertex IDs.\n\n        Args:\n            proposals_with_gt (list of Instances): detections with associated\n                ground truth data; each item corresponds to instances detected\n                on 1 image; the number of items corresponds to the number of\n                images in a batch\n            densepose_predictor_outputs: an object of a dataclass that contains predictor\n                outputs with estimated values; assumed to have the following attributes:\n                * embedding - embedding estimates, tensor of shape [N, D, S, S], where\n                  N = number of instances (= sum N_i, where N_i is the number of\n                      instances on image i)\n                  D = embedding space dimensionality (MODEL.ROI_DENSEPOSE_HEAD.CSE.EMBED_SIZE)\n                  S = output size (width and height)\n            packed_annotations (PackedCseAnnotations): contains various data useful\n                for loss computation, each data is packed into a single tensor\n            interpolator (BilinearInterpolationHelper): bilinear interpolation helper\n            embedder (nn.Module): module that computes vertex embeddings for different meshes\n        Return:\n            dict(int -> tensor): losses for different mesh IDs\n        \"\"\"", "\n", "losses", "=", "{", "}", "\n", "for", "mesh_id_tensor", "in", "packed_annotations", ".", "vertex_mesh_ids_gt", ".", "unique", "(", ")", ":", "# pyre-ignore[16]", "\n", "            ", "mesh_id", "=", "mesh_id_tensor", ".", "item", "(", ")", "\n", "mesh_name", "=", "MeshCatalog", ".", "get_mesh_name", "(", "mesh_id", ")", "\n", "# valid points are those that fall into estimated bbox", "\n", "# and correspond to the current mesh", "\n", "j_valid", "=", "interpolator", ".", "j_valid", "*", "(", "# pyre-ignore[16]", "\n", "packed_annotations", ".", "vertex_mesh_ids_gt", "==", "mesh_id", "\n", ")", "\n", "# extract estimated embeddings for valid points", "\n", "# -> tensor [J, D]", "\n", "vertex_embeddings_i", "=", "normalize_embeddings", "(", "\n", "interpolator", ".", "extract_at_points", "(", "\n", "densepose_predictor_outputs", ".", "embedding", ",", "\n", "slice_fine_segm", "=", "slice", "(", "None", ")", ",", "\n", "w_ylo_xlo", "=", "interpolator", ".", "w_ylo_xlo", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", "w_ylo_xhi", "=", "interpolator", ".", "w_ylo_xhi", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", "w_yhi_xlo", "=", "interpolator", ".", "w_yhi_xlo", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", "w_yhi_xhi", "=", "interpolator", ".", "w_yhi_xhi", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", ")", "[", "j_valid", ",", ":", "]", "\n", ")", "\n", "# extract vertex ids for valid points", "\n", "# -> tensor [J]", "\n", "vertex_indices_i", "=", "packed_annotations", ".", "vertex_ids_gt", "[", "j_valid", "]", "\n", "# embeddings for all mesh vertices", "\n", "# -> tensor [K, D]", "\n", "mesh_vertex_embeddings", "=", "embedder", "(", "mesh_name", ")", "\n", "# unnormalized scores for valid points", "\n", "# -> tensor [J, K]", "\n", "scores", "=", "squared_euclidean_distance_matrix", "(", "\n", "vertex_embeddings_i", ",", "mesh_vertex_embeddings", "\n", ")", "/", "(", "-", "self", ".", "embdist_gauss_sigma", ")", "\n", "losses", "[", "mesh_name", "]", "=", "F", ".", "cross_entropy", "(", "scores", ",", "vertex_indices_i", ",", "ignore_index", "=", "-", "1", ")", "\n", "\n", "", "for", "mesh_name", "in", "embedder", ".", "mesh_names", ":", "# pyre-ignore[16]", "\n", "            ", "if", "mesh_name", "not", "in", "losses", ":", "\n", "                ", "losses", "[", "mesh_name", "]", "=", "self", ".", "fake_value", "(", "\n", "densepose_predictor_outputs", ",", "embedder", ",", "mesh_name", "\n", ")", "\n", "", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed.EmbeddingLoss.fake_values": [[110, 115], ["embed.EmbeddingLoss.fake_value"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value"], ["", "def", "fake_values", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ",", "embedder", ":", "nn", ".", "Module", ")", ":", "\n", "        ", "losses", "=", "{", "}", "\n", "for", "mesh_name", "in", "embedder", ".", "mesh_names", ":", "# pyre-ignore[16]", "\n", "            ", "losses", "[", "mesh_name", "]", "=", "self", ".", "fake_value", "(", "densepose_predictor_outputs", ",", "embedder", ",", "mesh_name", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.embed.EmbeddingLoss.fake_value": [[116, 118], ["densepose_predictor_outputs.embedding.sum", "embedder().sum", "embedder"], "methods", ["None"], ["", "def", "fake_value", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ",", "embedder", ":", "nn", ".", "Module", ",", "mesh_name", ":", "str", ")", ":", "\n", "        ", "return", "densepose_predictor_outputs", ".", "embedding", ".", "sum", "(", ")", "*", "0", "+", "embedder", "(", "mesh_name", ")", ".", "sum", "(", ")", "*", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask_or_segm.MaskOrSegmentationLoss.__init__": [[21, 32], ["segm.SegmentationLoss", "mask.MaskLoss"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "\"\"\"\n        Initialize segmentation loss from configuration options\n\n        Args:\n            cfg (CfgNode): configuration options\n        \"\"\"", "\n", "self", ".", "segm_trained_by_masks", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "COARSE_SEGM_TRAINED_BY_MASKS", "\n", "if", "self", ".", "segm_trained_by_masks", ":", "\n", "            ", "self", ".", "mask_loss", "=", "MaskLoss", "(", ")", "\n", "", "self", ".", "segm_loss", "=", "SegmentationLoss", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask_or_segm.MaskOrSegmentationLoss.__call__": [[33, 57], ["mask_or_segm.MaskOrSegmentationLoss.segm_loss", "mask_or_segm.MaskOrSegmentationLoss.mask_loss"], "methods", ["None"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "proposals_with_gt", ":", "List", "[", "Instances", "]", ",", "\n", "densepose_predictor_outputs", ":", "Any", ",", "\n", "packed_annotations", ":", "Any", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Compute segmentation loss as cross-entropy between aligned unnormalized\n        score estimates and ground truth; with ground truth given\n        either by masks, or by coarse segmentation annotations.\n\n        Args:\n            proposals_with_gt (list of Instances): detections with associated ground truth data\n            densepose_predictor_outputs: an object of a dataclass that contains predictor outputs\n                with estimated values; assumed to have the following attributes:\n                * coarse_segm - coarse segmentation estimates, tensor of shape [N, D, S, S]\n            packed_annotations: packed annotations for efficient loss computation\n        Return:\n            tensor: loss value as cross-entropy for raw unnormalized scores\n                given ground truth labels\n        \"\"\"", "\n", "if", "self", ".", "segm_trained_by_masks", ":", "\n", "            ", "return", "self", ".", "mask_loss", "(", "proposals_with_gt", ",", "densepose_predictor_outputs", ")", "\n", "", "return", "self", ".", "segm_loss", "(", "proposals_with_gt", ",", "densepose_predictor_outputs", ",", "packed_annotations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask_or_segm.MaskOrSegmentationLoss.fake_value": [[58, 73], ["densepose_predictor_outputs.coarse_segm.sum"], "methods", ["None"], ["", "def", "fake_value", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Fake segmentation loss used when no suitable ground truth data\n        was found in a batch. The loss has a value 0 and is primarily used to\n        construct the computation graph, so that `DistributedDataParallel`\n        has similar graphs on all GPUs and can perform reduction properly.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor outputs, an object\n                of a dataclass that is assumed to have `coarse_segm`\n                attribute\n        Return:\n            Zero value loss with proper computation graph\n        \"\"\"", "\n", "return", "densepose_predictor_outputs", ".", "coarse_segm", ".", "sum", "(", ")", "*", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.__init__": [[26, 37], ["mask_or_segm.MaskOrSegmentationLoss", "cse.DensePoseCseLoss.create_embed_loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.create_embed_loss"], ["\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_in", "=", "input_channels", "\n", "n_segm_chan", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "NUM_COARSE_SEGM_CHANNELS", "\n", "embed_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBED_SIZE", "\n", "kernel_size", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "DECONV_KERNEL", "\n", "# coarse segmentation", "\n", "self", ".", "coarse_segm_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "n_segm_chan", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.create_embed_loss": [[38, 43], ["None"], "methods", ["None"], ["# embedding", "\n", "self", ".", "embed_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "embed_size", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "scale_factor", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UP_SCALE", "\n", "initialize_module_params", "(", "self", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.__call__": [[44, 77], ["embed_utils.CseAnnotationsAccumulator", "utils.extract_packed_annotations_from_matches", "utils.BilinearInterpolationHelper.from_matches", "cse.DensePoseCseLoss.embed_loss", "len", "cse.DensePoseCseLoss.produce_fake_losses", "cse.DensePoseCseLoss.produce_fake_losses", "cse.DensePoseCseLoss.segm_loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.extract_packed_annotations_from_matches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.from_matches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.produce_fake_losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.produce_fake_losses"], ["\n", "", "def", "interp2d", "(", "self", ",", "tensor_nchw", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Bilinear interpolation method to be used for upscaling\n\n        Args:\n            tensor_nchw (tensor): tensor of shape (N, C, H, W)\n        Return:\n            tensor of shape (N, C, Hout, Wout), where Hout and Wout are computed\n                by applying the scale factor to H and W\n        \"\"\"", "\n", "return", "interpolate", "(", "\n", "tensor_nchw", ",", "scale_factor", "=", "self", ".", "scale_factor", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "head_outputs", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward step on DensePose head outputs\n\n        Args:\n            head_outputs (tensor): DensePose head outputs, tensor of shape [N, D, H, W]\n        \"\"\"", "\n", "embed_lowres", "=", "self", ".", "embed_lowres", "(", "head_outputs", ")", "\n", "coarse_segm_lowres", "=", "self", ".", "coarse_segm_lowres", "(", "head_outputs", ")", "\n", "embed", "=", "self", ".", "interp2d", "(", "embed_lowres", ")", "\n", "coarse_segm", "=", "self", ".", "interp2d", "(", "coarse_segm_lowres", ")", "\n", "return", "DensePoseEmbeddingPredictorOutput", "(", "embedding", "=", "embed", ",", "coarse_segm", "=", "coarse_segm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.cse.DensePoseCseLoss.produce_fake_losses": [[79, 92], ["cse.DensePoseCseLoss.embed_loss.fake_values", "cse.DensePoseCseLoss.segm_loss.fake_value"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_values", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.__init__": [[47, 63], ["mask_or_segm.MaskOrSegmentationLoss"], "methods", ["None"], ["# coarse segmentation", "\n", "self", ".", "ann_index_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "n_segm_chan", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# fine segmentation", "\n", "self", ".", "index_uv_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# U", "\n", "self", ".", "u_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "# V", "\n", "self", ".", "v_lowres", "=", "ConvTranspose2d", "(", "\n", "dim_in", ",", "dim_out_patches", ",", "kernel_size", ",", "stride", "=", "2", ",", "padding", "=", "int", "(", "kernel_size", "/", "2", "-", "1", ")", "\n", ")", "\n", "self", ".", "scale_factor", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "UP_SCALE", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.__call__": [[64, 135], ["utils.ChartBasedAnnotationsAccumulator", "utils.extract_packed_annotations_from_matches", "utils.BilinearInterpolationHelper.from_matches", "chart.DensePoseChartLoss.produce_densepose_losses_uv", "chart.DensePoseChartLoss.produce_densepose_losses_segm", "len", "chart.DensePoseChartLoss.produce_fake_densepose_losses", "chart.DensePoseChartLoss.produce_fake_densepose_losses"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.extract_packed_annotations_from_matches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.from_matches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_densepose_losses_uv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_densepose_losses_segm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses"], ["initialize_module_params", "(", "self", ")", "\n", "\n", "", "def", "interp2d", "(", "self", ",", "tensor_nchw", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Bilinear interpolation method to be used for upscaling\n\n        Args:\n            tensor_nchw (tensor): tensor of shape (N, C, H, W)\n        Return:\n            tensor of shape (N, C, Hout, Wout), where Hout and Wout are computed\n                by applying the scale factor to H and W\n        \"\"\"", "\n", "return", "interpolate", "(", "\n", "tensor_nchw", ",", "scale_factor", "=", "self", ".", "scale_factor", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "head_outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Perform forward step on DensePose head outputs\n\n        Args:\n            head_outputs (tensor): DensePose head outputs, tensor of shape [N, D, H, W]\n        Return:\n           An instance of DensePoseChartPredictorOutput\n        \"\"\"", "\n", "return", "DensePoseChartPredictorOutput", "(", "\n", "coarse_segm", "=", "self", ".", "interp2d", "(", "self", ".", "ann_index_lowres", "(", "head_outputs", ")", ")", ",", "\n", "fine_segm", "=", "self", ".", "interp2d", "(", "self", ".", "index_uv_lowres", "(", "head_outputs", ")", ")", ",", "\n", "u", "=", "self", ".", "interp2d", "(", "self", ".", "u_lowres", "(", "head_outputs", ")", ")", ",", "\n", "v", "=", "self", ".", "interp2d", "(", "self", ".", "v_lowres", "(", "head_outputs", ")", ")", ",", "\n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses": [[136, 160], ["chart.DensePoseChartLoss.produce_fake_densepose_losses_uv", "chart.DensePoseChartLoss.produce_fake_densepose_losses_segm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses_uv", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses_segm"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses_uv": [[161, 182], ["densepose_predictor_outputs.u.sum", "densepose_predictor_outputs.v.sum"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_fake_densepose_losses_segm": [[184, 207], ["chart.DensePoseChartLoss.segm_loss.fake_value", "densepose_predictor_outputs.fine_segm.sum"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_densepose_losses_uv": [[208, 238], ["interpolator.extract_at_points", "interpolator.extract_at_points", "torch.nn.functional.smooth_l1_loss", "torch.nn.functional.smooth_l1_loss"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.smooth_l1_loss.smooth_l1_loss"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.chart.DensePoseChartLoss.produce_densepose_losses_segm": [[240, 288], ["interpolator.extract_at_points", "torch.nn.functional.cross_entropy", "chart.DensePoseChartLoss.segm_loss", "slice", "fine_segm_gt.long"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask.MaskLoss.__call__": [[79, 111], ["torch.nn.functional.cross_entropy", "len", "mask.MaskLoss.fake_value", "torch.no_grad", "mask.extract_data_for_mask_loss_from_matches", "mask.MaskLoss.fake_value", "extract_data_for_mask_loss_from_matches.masks_gt.long"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask.extract_data_for_mask_loss_from_matches", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value"], ["def", "__call__", "(", "\n", "self", ",", "proposals_with_gt", ":", "List", "[", "Instances", "]", ",", "densepose_predictor_outputs", ":", "Any", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes segmentation loss as cross-entropy for raw unnormalized\n        scores given ground truth labels.\n\n        Args:\n            proposals_with_gt (list of Instances): detections with associated ground truth data\n            densepose_predictor_outputs: an object of a dataclass that contains predictor outputs\n                with estimated values; assumed to have the following attribute:\n                * coarse_segm (tensor of shape [N, D, S, S]): coarse segmentation estimates\n                    as raw unnormalized scores\n                where N is the number of detections, S is the estimate size ( = width = height)\n                and D is the number of coarse segmentation channels.\n        Return:\n            Cross entropy for raw unnormalized scores for coarse segmentation given\n            ground truth labels from masks\n        \"\"\"", "\n", "if", "not", "len", "(", "proposals_with_gt", ")", ":", "\n", "            ", "return", "self", ".", "fake_value", "(", "densepose_predictor_outputs", ")", "\n", "# densepose outputs are computed for all images and all bounding boxes;", "\n", "# i.e. if a batch has 4 images with (3, 1, 2, 1) proposals respectively,", "\n", "# the outputs will have size(0) == 3+1+2+1 == 7", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "mask_loss_data", "=", "extract_data_for_mask_loss_from_matches", "(", "\n", "proposals_with_gt", ",", "densepose_predictor_outputs", ".", "coarse_segm", "\n", ")", "\n", "", "if", "(", "mask_loss_data", ".", "masks_gt", "is", "None", ")", "or", "(", "mask_loss_data", ".", "masks_est", "is", "None", ")", ":", "\n", "            ", "return", "self", ".", "fake_value", "(", "densepose_predictor_outputs", ")", "\n", "", "return", "F", ".", "cross_entropy", "(", "\n", "mask_loss_data", ".", "masks_est", ",", "mask_loss_data", ".", "masks_gt", ".", "long", "(", ")", "# pyre-ignore[16]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask.MaskLoss.fake_value": [[113, 128], ["densepose_predictor_outputs.coarse_segm.sum"], "methods", ["None"], ["", "def", "fake_value", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Fake segmentation loss used when no suitable ground truth data\n        was found in a batch. The loss has a value 0 and is primarily used to\n        construct the computation graph, so that `DistributedDataParallel`\n        has similar graphs on all GPUs and can perform reduction properly.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor outputs, an object\n                of a dataclass that is assumed to have `coarse_segm`\n                attribute\n        Return:\n            Zero value loss with proper computation graph\n        \"\"\"", "\n", "return", "densepose_predictor_outputs", ".", "coarse_segm", ".", "sum", "(", ")", "*", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.mask.extract_data_for_mask_loss_from_matches": [[23, 69], ["mask.DataForMaskLoss", "sum", "proposals_targets_per_image.proposal_boxes.tensor.size", "proposals_targets_per_image.gt_masks.crop_and_resize().to", "masks_gt.append", "torch.cat", "inst.proposal_boxes.tensor.size", "proposals_targets_per_image.gt_masks.crop_and_resize"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.masks.PolygonMasks.crop_and_resize"], ["", "def", "extract_data_for_mask_loss_from_matches", "(", "\n", "proposals_targets", ":", "Iterable", "[", "Instances", "]", ",", "estimated_segm", ":", "torch", ".", "Tensor", "\n", ")", "->", "DataForMaskLoss", ":", "\n", "    ", "\"\"\"\n    Extract data for mask loss from instances that contain matched GT and\n    estimated bounding boxes.\n    Args:\n        proposals_targets: Iterable[Instances]\n            matched GT and estimated results, each item in the iterable\n            corresponds to data in 1 image\n        estimated_segm: tensor(K, C, S, S) of float - raw unnormalized\n            segmentation scores, here S is the size to which GT masks are\n            to be resized\n    Return:\n        masks_est: tensor(K, C, S, S) of float - class scores\n        masks_gt: tensor(K, S, S) of int64 - labels\n    \"\"\"", "\n", "data", "=", "DataForMaskLoss", "(", ")", "\n", "masks_gt", "=", "[", "]", "\n", "offset", "=", "0", "\n", "assert", "estimated_segm", ".", "shape", "[", "2", "]", "==", "estimated_segm", ".", "shape", "[", "3", "]", ",", "(", "\n", "f\"Expected estimated segmentation to have a square shape, \"", "\n", "f\"but the actual shape is {estimated_segm.shape[2:]}\"", "\n", ")", "\n", "mask_size", "=", "estimated_segm", ".", "shape", "[", "2", "]", "\n", "num_proposals", "=", "sum", "(", "inst", ".", "proposal_boxes", ".", "tensor", ".", "size", "(", "0", ")", "for", "inst", "in", "proposals_targets", ")", "\n", "num_estimated", "=", "estimated_segm", ".", "shape", "[", "0", "]", "\n", "assert", "(", "\n", "num_proposals", "==", "num_estimated", "\n", ")", ",", "\"The number of proposals {} must be equal to the number of estimates {}\"", ".", "format", "(", "\n", "num_proposals", ",", "num_estimated", "\n", ")", "\n", "\n", "for", "proposals_targets_per_image", "in", "proposals_targets", ":", "\n", "        ", "n_i", "=", "proposals_targets_per_image", ".", "proposal_boxes", ".", "tensor", ".", "size", "(", "0", ")", "\n", "if", "not", "n_i", ":", "\n", "            ", "continue", "\n", "", "gt_masks_per_image", "=", "proposals_targets_per_image", ".", "gt_masks", ".", "crop_and_resize", "(", "\n", "proposals_targets_per_image", ".", "proposal_boxes", ".", "tensor", ",", "mask_size", "\n", ")", ".", "to", "(", "device", "=", "estimated_segm", ".", "device", ")", "\n", "masks_gt", ".", "append", "(", "gt_masks_per_image", ")", "\n", "offset", "+=", "n_i", "\n", "", "if", "masks_gt", ":", "\n", "        ", "data", ".", "masks_est", "=", "estimated_segm", "\n", "data", ".", "masks_gt", "=", "torch", ".", "cat", "(", "masks_gt", ",", "dim", "=", "0", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.__init__": [[86, 102], ["locals().items", "locals", "setattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.from_matches": [[103, 155], ["packed_annotations.bbox_xywh_gt[].unbind", "packed_annotations.bbox_xywh_est[].unbind", "utils._linear_interpolation_utilities", "utils._linear_interpolation_utilities", "utils.BilinearInterpolationHelper"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils._linear_interpolation_utilities", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils._linear_interpolation_utilities"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points": [[157, 192], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.AnnotationsAccumulator.accumulate": [[243, 252], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.AnnotationsAccumulator.pack": [[253, 259], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.__init__": [[308, 322], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate": [[323, 356], ["detectron2.structures.BoxMode.convert", "detectron2.structures.BoxMode.convert", "len", "zip", "instances_one_image.proposal_boxes.tensor.clone", "instances_one_image.gt_boxes.tensor.clone", "len", "len", "len", "hasattr", "utils.ChartBasedAnnotationsAccumulator._do_accumulate", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator._do_accumulate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator._do_accumulate": [[357, 383], ["utils.ChartBasedAnnotationsAccumulator.i_gt.append", "utils.ChartBasedAnnotationsAccumulator.x_gt.append", "utils.ChartBasedAnnotationsAccumulator.y_gt.append", "utils.ChartBasedAnnotationsAccumulator.u_gt.append", "utils.ChartBasedAnnotationsAccumulator.v_gt.append", "hasattr", "utils.ChartBasedAnnotationsAccumulator.bbox_xywh_gt.append", "utils.ChartBasedAnnotationsAccumulator.bbox_xywh_est.append", "utils.ChartBasedAnnotationsAccumulator.point_bbox_with_dp_indices.append", "utils.ChartBasedAnnotationsAccumulator.point_bbox_indices.append", "utils.ChartBasedAnnotationsAccumulator.bbox_indices.append", "utils.ChartBasedAnnotationsAccumulator.s_gt.append", "box_xywh_gt.view", "box_xywh_est.view", "torch.full_like", "torch.full_like", "dp_gt.segm.unsqueeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.pack": [[384, 411], ["utils.PackedChartBasedAnnotations", "len", "torch.cat().long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().long", "torch.cat().long", "torch.as_tensor().long", "torch.cat", "torch.cat", "len", "len", "torch.cat", "torch.cat", "torch.as_tensor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils._linear_interpolation_utilities": [[16, 60], ["torch.min.floor().long().clamp", "torch.min", "v_hi.float", "v_grid.floor().long().clamp.float", "torch.min.floor().long", "torch.min.floor"], "function", ["None"], ["", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.resample_data": [[194, 235], ["bbox_xywh_src.size", "bbox_xywh_src.unbind", "bbox_xywh_dst.unbind", "grid_w[].expand", "grid_h[].expand", "[].expand", "[].expand", "x0dst_norm[].expand", "y0dst_norm[].expand", "torch.stack", "torch.nn.functional.grid_sample", "bbox_xywh_dst.size", "bbox_xywh_src.size", "bbox_xywh_dst.size", "torch.arange", "torch.arange"], "function", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.extract_packed_annotations_from_matches": [[415, 421], ["accumulator.pack", "accumulator.accumulate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.pack", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.ChartBasedAnnotationsAccumulator.accumulate"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.__init__": [[31, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ":", "CfgNode", ")", ":", "\n", "        ", "\"\"\"\n        Initialize embedding loss from config\n        \"\"\"", "\n", "self", ".", "embdist_gauss_sigma", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "EMBEDDING_DIST_GAUSS_SIGMA", "\n", "self", ".", "geodist_gauss_sigma", "=", "cfg", ".", "MODEL", ".", "ROI_DENSEPOSE_HEAD", ".", "CSE", ".", "GEODESIC_DIST_GAUSS_SIGMA", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.__call__": [[38, 123], ["packed_annotations.vertex_mesh_ids_gt.unique", "mesh_id_tensor.item", "densepose.data.meshes.catalog.MeshCatalog.get_mesh_name", "densepose.modeling.cse.utils.normalize_embeddings", "embedder", "densepose.structures.mesh.create_mesh", "torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "soft_embed.SoftEmbeddingLoss.fake_value", "interpolator.extract_at_points", "densepose.modeling.cse.utils.squared_euclidean_distance_matrix", "slice"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.get_mesh_name", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.normalize_embeddings", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.create_mesh", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.utils.BilinearInterpolationHelper.extract_at_points", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.squared_euclidean_distance_matrix"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "proposals_with_gt", ":", "List", "[", "Instances", "]", ",", "\n", "densepose_predictor_outputs", ":", "Any", ",", "\n", "packed_annotations", ":", "PackedCseAnnotations", ",", "\n", "interpolator", ":", "BilinearInterpolationHelper", ",", "\n", "embedder", ":", "nn", ".", "Module", ",", "\n", ")", "->", "Dict", "[", "int", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Produces losses for estimated embeddings given annotated vertices.\n        Embeddings for all the vertices of a mesh are computed by the embedder.\n        Embeddings for observed pixels are estimated by a predictor.\n        Losses are computed as cross-entropy for unnormalized scores given\n        ground truth vertex IDs.\n         1) squared distances between estimated vertex embeddings\n            and mesh vertex embeddings;\n         2) geodesic distances between vertices of a mesh\n\n        Args:\n            proposals_with_gt (list of Instances): detections with associated\n                ground truth data; each item corresponds to instances detected\n                on 1 image; the number of items corresponds to the number of\n                images in a batch\n            densepose_predictor_outputs: an object of a dataclass that contains predictor\n                outputs with estimated values; assumed to have the following attributes:\n                * embedding - embedding estimates, tensor of shape [N, D, S, S], where\n                  N = number of instances (= sum N_i, where N_i is the number of\n                      instances on image i)\n                  D = embedding space dimensionality (MODEL.ROI_DENSEPOSE_HEAD.CSE.EMBED_SIZE)\n                  S = output size (width and height)\n            packed_annotations (PackedCseAnnotations): contains various data useful\n                for loss computation, each data is packed into a single tensor\n            interpolator (BilinearInterpolationHelper): bilinear interpolation helper\n            embedder (nn.Module): module that computes vertex embeddings for different meshes\n        Return:\n            dict(int -> tensor): losses for different mesh IDs\n        \"\"\"", "\n", "losses", "=", "{", "}", "\n", "for", "mesh_id_tensor", "in", "packed_annotations", ".", "vertex_mesh_ids_gt", ".", "unique", "(", ")", ":", "# pyre-ignore[16]", "\n", "            ", "mesh_id", "=", "mesh_id_tensor", ".", "item", "(", ")", "\n", "mesh_name", "=", "MeshCatalog", ".", "get_mesh_name", "(", "mesh_id", ")", "\n", "# valid points are those that fall into estimated bbox", "\n", "# and correspond to the current mesh", "\n", "j_valid", "=", "interpolator", ".", "j_valid", "*", "(", "# pyre-ignore[16]", "\n", "packed_annotations", ".", "vertex_mesh_ids_gt", "==", "mesh_id", "\n", ")", "\n", "# extract estimated embeddings for valid points", "\n", "# -> tensor [J, D]", "\n", "vertex_embeddings_i", "=", "normalize_embeddings", "(", "\n", "interpolator", ".", "extract_at_points", "(", "\n", "densepose_predictor_outputs", ".", "embedding", ",", "\n", "slice_fine_segm", "=", "slice", "(", "None", ")", ",", "\n", "w_ylo_xlo", "=", "interpolator", ".", "w_ylo_xlo", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", "w_ylo_xhi", "=", "interpolator", ".", "w_ylo_xhi", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", "w_yhi_xlo", "=", "interpolator", ".", "w_yhi_xlo", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", "w_yhi_xhi", "=", "interpolator", ".", "w_yhi_xhi", "[", ":", ",", "None", "]", ",", "# pyre-ignore[16]", "\n", ")", "[", "j_valid", ",", ":", "]", "\n", ")", "\n", "# extract vertex ids for valid points", "\n", "# -> tensor [J]", "\n", "vertex_indices_i", "=", "packed_annotations", ".", "vertex_ids_gt", "[", "j_valid", "]", "\n", "# embeddings for all mesh vertices", "\n", "# -> tensor [K, D]", "\n", "mesh_vertex_embeddings", "=", "embedder", "(", "mesh_name", ")", "\n", "# softmax values of geodesic distances for GT mesh vertices", "\n", "# -> tensor [J, K]", "\n", "mesh", "=", "create_mesh", "(", "mesh_name", ",", "mesh_vertex_embeddings", ".", "device", ")", "\n", "geodist_softmax_values", "=", "F", ".", "softmax", "(", "\n", "mesh", ".", "geodists", "[", "vertex_indices_i", "]", "/", "(", "-", "self", ".", "geodist_gauss_sigma", ")", ",", "dim", "=", "1", "\n", ")", "\n", "# logsoftmax values for valid points", "\n", "# -> tensor [J, K]", "\n", "embdist_logsoftmax_values", "=", "F", ".", "log_softmax", "(", "\n", "squared_euclidean_distance_matrix", "(", "vertex_embeddings_i", ",", "mesh_vertex_embeddings", ")", "\n", "/", "(", "-", "self", ".", "embdist_gauss_sigma", ")", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "losses", "[", "mesh_name", "]", "=", "(", "-", "geodist_softmax_values", "*", "embdist_logsoftmax_values", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "for", "mesh_name", "in", "embedder", ".", "mesh_names", ":", "# pyre-ignore[16]", "\n", "            ", "if", "mesh_name", "not", "in", "losses", ":", "\n", "                ", "losses", "[", "mesh_name", "]", "=", "self", ".", "fake_value", "(", "\n", "densepose_predictor_outputs", ",", "embedder", ",", "mesh_name", "\n", ")", "\n", "", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_values": [[124, 129], ["soft_embed.SoftEmbeddingLoss.fake_value"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value"], ["", "def", "fake_values", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ",", "embedder", ":", "nn", ".", "Module", ")", ":", "\n", "        ", "losses", "=", "{", "}", "\n", "for", "mesh_name", "in", "embedder", ".", "mesh_names", ":", "# pyre-ignore[16]", "\n", "            ", "losses", "[", "mesh_name", "]", "=", "self", ".", "fake_value", "(", "densepose_predictor_outputs", ",", "embedder", ",", "mesh_name", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.losses.soft_embed.SoftEmbeddingLoss.fake_value": [[130, 132], ["densepose_predictor_outputs.embedding.sum", "embedder().sum", "embedder"], "methods", ["None"], ["", "def", "fake_value", "(", "self", ",", "densepose_predictor_outputs", ":", "Any", ",", "embedder", ":", "nn", ".", "Module", ",", "mesh_name", ":", "str", ")", ":", "\n", "        ", "return", "densepose_predictor_outputs", ".", "embedding", ".", "sum", "(", ")", "*", "0", "+", "embedder", "(", "mesh_name", ")", ".", "sum", "(", ")", "*", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register": [[15, 36], ["cls._do_register", "cls._do_register"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._do_register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._do_register"], ["@", "classmethod", "\n", "def", "register", "(", "cls", ",", "from_type", ":", "Type", ",", "converter", ":", "Any", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Registers a converter for the specified type.\n        Can be used as a decorator (if converter is None), or called as a method.\n\n        Args:\n            from_type (type): type to register the converter for;\n                all instances of this type will use the same converter\n            converter (callable): converter to be registered for the given\n                type; if None, this method is assumed to be a decorator for the converter\n        \"\"\"", "\n", "\n", "if", "converter", "is", "not", "None", ":", "\n", "            ", "cls", ".", "_do_register", "(", "from_type", ",", "converter", ")", "\n", "\n", "", "def", "wrapper", "(", "converter", ":", "Any", ")", "->", "Any", ":", "\n", "            ", "cls", ".", "_do_register", "(", "from_type", ",", "converter", ")", "\n", "return", "converter", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._do_register": [[37, 40], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_do_register", "(", "cls", ",", "from_type", ":", "Type", ",", "converter", ":", "Any", ")", ":", "\n", "        ", "cls", ".", "registry", "[", "from_type", "]", "=", "converter", "# pyre-ignore[16]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._lookup_converter": [[41, 62], ["cls._lookup_converter", "cls._do_register"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._lookup_converter", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._do_register"], ["", "@", "classmethod", "\n", "def", "_lookup_converter", "(", "cls", ",", "from_type", ":", "Type", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Perform recursive lookup for the given type\n        to find registered converter. If a converter was found for some base\n        class, it gets registered for this class to save on further lookups.\n\n        Args:\n            from_type: type for which to find a converter\n        Return:\n            callable or None - registered converter or None\n                if no suitable entry was found in the registry\n        \"\"\"", "\n", "if", "from_type", "in", "cls", ".", "registry", ":", "# pyre-ignore[16]", "\n", "            ", "return", "cls", ".", "registry", "[", "from_type", "]", "\n", "", "for", "base", "in", "from_type", ".", "__bases__", ":", "\n", "            ", "converter", "=", "cls", ".", "_lookup_converter", "(", "base", ")", "\n", "if", "converter", "is", "not", "None", ":", "\n", "                ", "cls", ".", "_do_register", "(", "from_type", ",", "converter", ")", "\n", "return", "converter", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.convert": [[63, 85], ["type", "cls._lookup_converter", "cls._lookup_converter.", "KeyError"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter._lookup_converter"], ["", "@", "classmethod", "\n", "def", "convert", "(", "cls", ",", "instance", ":", "Any", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Convert an instance to the destination type using some registered\n        converter. Does recursive lookup for base classes, so there's no need\n        for explicit registration for derived classes.\n\n        Args:\n            instance: source instance to convert to the destination type\n        Return:\n            An instance of the destination type obtained from the source instance\n            Raises KeyError, if no suitable converter found\n        \"\"\"", "\n", "instance_type", "=", "type", "(", "instance", ")", "\n", "converter", "=", "cls", ".", "_lookup_converter", "(", "instance_type", ")", "\n", "if", "converter", "is", "None", ":", "\n", "            ", "if", "cls", ".", "dst_type", "is", "None", ":", "# pyre-ignore[16]", "\n", "                ", "output_type_str", "=", "\"itself\"", "\n", "", "else", ":", "\n", "                ", "output_type_str", "=", "cls", ".", "dst_type", "\n", "", "raise", "KeyError", "(", "f\"Could not find converter from {instance_type} to {output_type_str}\"", ")", "\n", "", "return", "converter", "(", "instance", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.make_int_box": [[90, 94], ["tuple", "box.long().tolist", "box.long"], "function", ["None"], ["def", "make_int_box", "(", "box", ":", "torch", ".", "Tensor", ")", "->", "IntTupleBox", ":", "\n", "    ", "int_box", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "int_box", "[", "0", "]", ",", "int_box", "[", "1", "]", ",", "int_box", "[", "2", "]", ",", "int_box", "[", "3", "]", "=", "tuple", "(", "box", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "\n", "return", "int_box", "[", "0", "]", ",", "int_box", "[", "1", "]", ",", "int_box", "[", "2", "]", ",", "int_box", "[", "3", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.hflip.HFlipConverter.convert": [[17, 32], ["super().convert"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["@", "classmethod", "\n", "def", "convert", "(", "cls", ",", "predictor_outputs", ":", "Any", ",", "transform_data", ":", "Any", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Performs an horizontal flip on DensePose predictor outputs.\n        Does recursive lookup for base classes, so there's no need\n        for explicit registration for derived classes.\n\n        Args:\n            predictor_outputs: DensePose predictor output to be converted to BitMasks\n            transform_data: Anything useful for the flip\n        Return:\n            An instance of the same type as predictor_outputs\n        \"\"\"", "\n", "return", "super", "(", "HFlipConverter", ",", "cls", ")", ".", "convert", "(", "\n", "predictor_outputs", ",", "transform_data", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_hflip.densepose_chart_predictor_output_hflip": [[8, 39], ["len", "type", "dataclasses.fields", "chart_output_hflip._flip_iuv_semantics_tensor", "chart_output_hflip._flip_segm_semantics_tensor", "dataclasses.fields", "type.", "getattr", "isinstance", "getattr", "setattr", "torch.flip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_hflip._flip_iuv_semantics_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_hflip._flip_segm_semantics_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.bounding_box.BoxList.fields"], ["def", "densepose_chart_predictor_output_hflip", "(", "\n", "densepose_predictor_output", ":", "DensePoseChartPredictorOutput", ",", "\n", "transform_data", ":", "DensePoseTransformData", ",", "\n", ")", "->", "DensePoseChartPredictorOutput", ":", "\n", "    ", "\"\"\"\n    Change  to take into account a Horizontal flip.\n    \"\"\"", "\n", "if", "len", "(", "densepose_predictor_output", ")", ">", "0", ":", "\n", "\n", "        ", "PredictorOutput", "=", "type", "(", "densepose_predictor_output", ")", "\n", "output_dict", "=", "{", "}", "\n", "\n", "for", "field", "in", "fields", "(", "densepose_predictor_output", ")", ":", "\n", "            ", "field_value", "=", "getattr", "(", "densepose_predictor_output", ",", "field", ".", "name", ")", "\n", "# flip tensors", "\n", "if", "isinstance", "(", "field_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "setattr", "(", "densepose_predictor_output", ",", "field", ".", "name", ",", "torch", ".", "flip", "(", "field_value", ",", "[", "3", "]", ")", ")", "\n", "\n", "", "", "densepose_predictor_output", "=", "_flip_iuv_semantics_tensor", "(", "\n", "densepose_predictor_output", ",", "transform_data", "\n", ")", "\n", "densepose_predictor_output", "=", "_flip_segm_semantics_tensor", "(", "\n", "densepose_predictor_output", ",", "transform_data", "\n", ")", "\n", "\n", "for", "field", "in", "fields", "(", "densepose_predictor_output", ")", ":", "\n", "            ", "output_dict", "[", "field", ".", "name", "]", "=", "getattr", "(", "densepose_predictor_output", ",", "field", ".", "name", ")", "\n", "\n", "", "return", "PredictorOutput", "(", "**", "output_dict", ")", "\n", "", "else", ":", "\n", "        ", "return", "densepose_predictor_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_hflip._flip_iuv_semantics_tensor": [[41, 62], ["[].expand", "densepose_predictor_output.u[].clamp", "densepose_predictor_output.v[].clamp", "torch.arange"], "function", ["None"], ["", "", "def", "_flip_iuv_semantics_tensor", "(", "\n", "densepose_predictor_output", ":", "DensePoseChartPredictorOutput", ",", "\n", "dp_transform_data", ":", "DensePoseTransformData", ",", "\n", ")", "->", "DensePoseChartPredictorOutput", ":", "\n", "    ", "point_label_symmetries", "=", "dp_transform_data", ".", "point_label_symmetries", "\n", "uv_symmetries", "=", "dp_transform_data", ".", "uv_symmetries", "\n", "\n", "N", ",", "C", ",", "H", ",", "W", "=", "densepose_predictor_output", ".", "u", ".", "shape", "\n", "u_loc", "=", "(", "densepose_predictor_output", ".", "u", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ".", "clamp", "(", "0", ",", "1", ")", "*", "255", ")", ".", "long", "(", ")", "\n", "v_loc", "=", "(", "densepose_predictor_output", ".", "v", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ".", "clamp", "(", "0", ",", "1", ")", "*", "255", ")", ".", "long", "(", ")", "\n", "Iindex", "=", "torch", ".", "arange", "(", "C", "-", "1", ",", "device", "=", "densepose_predictor_output", ".", "u", ".", "device", ")", "[", "\n", "None", ",", ":", ",", "None", ",", "None", "\n", "]", ".", "expand", "(", "N", ",", "C", "-", "1", ",", "H", ",", "W", ")", "\n", "densepose_predictor_output", ".", "u", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "=", "uv_symmetries", "[", "\"U_transforms\"", "]", "[", "Iindex", ",", "v_loc", ",", "u_loc", "]", "\n", "densepose_predictor_output", ".", "v", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "=", "uv_symmetries", "[", "\"V_transforms\"", "]", "[", "Iindex", ",", "v_loc", ",", "u_loc", "]", "\n", "\n", "for", "el", "in", "[", "\"fine_segm\"", ",", "\"u\"", ",", "\"v\"", "]", ":", "\n", "        ", "densepose_predictor_output", ".", "__dict__", "[", "el", "]", "=", "densepose_predictor_output", ".", "__dict__", "[", "el", "]", "[", "\n", ":", ",", "point_label_symmetries", ",", ":", ",", ":", "\n", "]", "\n", "", "return", "densepose_predictor_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_hflip._flip_segm_semantics_tensor": [[64, 72], ["None"], "function", ["None"], ["", "def", "_flip_segm_semantics_tensor", "(", "\n", "densepose_predictor_output", ":", "DensePoseChartPredictorOutput", ",", "dp_transform_data", "\n", ")", ":", "\n", "    ", "if", "densepose_predictor_output", ".", "coarse_segm", ".", "shape", "[", "1", "]", ">", "2", ":", "\n", "        ", "densepose_predictor_output", ".", "coarse_segm", "=", "densepose_predictor_output", ".", "coarse_segm", "[", "\n", ":", ",", "dp_transform_data", ".", "mask_label_symmetries", ",", ":", ",", ":", "\n", "]", "\n", "", "return", "densepose_predictor_output", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.to_chart_result.ToChartResultConverter.convert": [[20, 36], ["super().convert"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["@", "classmethod", "\n", "def", "convert", "(", "cls", ",", "predictor_outputs", ":", "Any", ",", "boxes", ":", "Boxes", ",", "*", "args", ",", "**", "kwargs", ")", "->", "DensePoseChartResult", ":", "\n", "        ", "\"\"\"\n        Convert DensePose predictor outputs to DensePoseResult using some registered\n        converter. Does recursive lookup for base classes, so there's no need\n        for explicit registration for derived classes.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor output to be\n                converted to BitMasks\n            boxes (Boxes): bounding boxes that correspond to the DensePose\n                predictor outputs\n        Return:\n            An instance of DensePoseResult. If no suitable converter was found, raises KeyError\n        \"\"\"", "\n", "return", "super", "(", "ToChartResultConverter", ",", "cls", ")", ".", "convert", "(", "predictor_outputs", ",", "boxes", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.to_chart_result.ToChartResultConverterWithConfidences.convert": [[47, 66], ["super().convert"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["@", "classmethod", "\n", "def", "convert", "(", "\n", "cls", ",", "predictor_outputs", ":", "Any", ",", "boxes", ":", "Boxes", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "->", "DensePoseChartResultWithConfidences", ":", "\n", "        ", "\"\"\"\n        Convert DensePose predictor outputs to DensePoseResult with confidences\n        using some registered converter. Does recursive lookup for base classes,\n        so there's no need for explicit registration for derived classes.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor output with confidences\n                to be converted to BitMasks\n            boxes (Boxes): bounding boxes that correspond to the DensePose\n                predictor outputs\n        Return:\n            An instance of DensePoseResult. If no suitable converter was found, raises KeyError\n        \"\"\"", "\n", "return", "super", "(", "ToChartResultConverterWithConfidences", ",", "cls", ")", ".", "convert", "(", "\n", "predictor_outputs", ",", "boxes", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.to_mask.ToMaskConverter.convert": [[22, 47], ["super().convert"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["@", "classmethod", "\n", "def", "convert", "(", "\n", "cls", ",", "\n", "densepose_predictor_outputs", ":", "Any", ",", "\n", "boxes", ":", "Boxes", ",", "\n", "image_size_hw", ":", "ImageSizeType", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "->", "BitMasks", ":", "\n", "        ", "\"\"\"\n        Convert DensePose predictor outputs to BitMasks using some registered\n        converter. Does recursive lookup for base classes, so there's no need\n        for explicit registration for derived classes.\n\n        Args:\n            densepose_predictor_outputs: DensePose predictor output to be\n                converted to BitMasks\n            boxes (Boxes): bounding boxes that correspond to the DensePose\n                predictor outputs\n            image_size_hw (tuple [int, int]): image height and width\n        Return:\n            An instance of `BitMasks`. If no suitable converter was found, raises KeyError\n        \"\"\"", "\n", "return", "super", "(", "ToMaskConverter", ",", "cls", ")", ".", "convert", "(", "\n", "densepose_predictor_outputs", ",", "boxes", ",", "image_size_hw", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_coarse_segm_tensor_to_bbox": [[13, 30], ["max", "max", "torch.nn.functional.interpolate().argmax", "int", "int", "torch.nn.functional.interpolate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["def", "resample_coarse_segm_tensor_to_bbox", "(", "coarse_segm", ":", "torch", ".", "Tensor", ",", "box_xywh_abs", ":", "IntTupleBox", ")", ":", "\n", "    ", "\"\"\"\n    Resample coarse segmentation tensor to the given\n    bounding box and derive labels for each pixel of the bounding box\n\n    Args:\n        coarse_segm: float tensor of shape [1, K, Hout, Wout]\n        box_xywh_abs (tuple of 4 int): bounding box given by its upper-left\n            corner coordinates, width (W) and height (H)\n    Return:\n        Labels for each pixel of the bounding box, a long tensor of size [1, H, W]\n    \"\"\"", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "box_xywh_abs", "\n", "w", "=", "max", "(", "int", "(", "w", ")", ",", "1", ")", "\n", "h", "=", "max", "(", "int", "(", "h", ")", ",", "1", ")", "\n", "labels", "=", "F", ".", "interpolate", "(", "coarse_segm", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox": [[32, 60], ["max", "max", "torch.nn.functional.interpolate().argmax", "int", "int", "torch.nn.functional.interpolate().argmax", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "resample_fine_and_coarse_segm_tensors_to_bbox", "(", "\n", "fine_segm", ":", "torch", ".", "Tensor", ",", "coarse_segm", ":", "torch", ".", "Tensor", ",", "box_xywh_abs", ":", "IntTupleBox", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Resample fine and coarse segmentation tensors to the given\n    bounding box and derive labels for each pixel of the bounding box\n\n    Args:\n        fine_segm: float tensor of shape [1, C, Hout, Wout]\n        coarse_segm: float tensor of shape [1, K, Hout, Wout]\n        box_xywh_abs (tuple of 4 int): bounding box given by its upper-left\n            corner coordinates, width (W) and height (H)\n    Return:\n        Labels for each pixel of the bounding box, a long tensor of size [1, H, W]\n    \"\"\"", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "box_xywh_abs", "\n", "w", "=", "max", "(", "int", "(", "w", ")", ",", "1", ")", "\n", "h", "=", "max", "(", "int", "(", "h", ")", ",", "1", ")", "\n", "# coarse segmentation", "\n", "coarse_segm_bbox", "=", "F", ".", "interpolate", "(", "\n", "coarse_segm", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "# combined coarse and fine segmentation", "\n", "labels", "=", "(", "\n", "F", ".", "interpolate", "(", "fine_segm", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "*", "(", "coarse_segm_bbox", ">", "0", ")", ".", "long", "(", ")", "\n", ")", "\n", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_to_bbox": [[62, 79], ["segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_tensors_to_bbox"], ["", "def", "resample_fine_and_coarse_segm_to_bbox", "(", "predictor_output", ":", "Any", ",", "box_xywh_abs", ":", "IntTupleBox", ")", ":", "\n", "    ", "\"\"\"\n    Resample fine and coarse segmentation outputs from a predictor to the given\n    bounding box and derive labels for each pixel of the bounding box\n\n    Args:\n        predictor_output: DensePose predictor output that contains segmentation\n            results to be resampled\n        box_xywh_abs (tuple of 4 int): bounding box given by its upper-left\n            corner coordinates, width (W) and height (H)\n    Return:\n        Labels for each pixel of the bounding box, a long tensor of size [1, H, W]\n    \"\"\"", "\n", "return", "resample_fine_and_coarse_segm_tensors_to_bbox", "(", "\n", "predictor_output", ".", "fine_segm", ",", "\n", "predictor_output", ".", "coarse_segm", ",", "\n", "box_xywh_abs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.predictor_output_with_coarse_segm_to_mask": [[82, 113], ["boxes.tensor.clone", "detectron2.structures.BoxMode.convert", "len", "torch.zeros", "range", "detectron2.structures.BitMasks", "len", "base.make_int_box", "segm_to_mask.resample_coarse_segm_tensor_to_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.make_int_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_coarse_segm_tensor_to_bbox"], ["", "def", "predictor_output_with_coarse_segm_to_mask", "(", "\n", "predictor_output", ":", "Any", ",", "boxes", ":", "Boxes", ",", "image_size_hw", ":", "ImageSizeType", "\n", ")", "->", "BitMasks", ":", "\n", "    ", "\"\"\"\n    Convert predictor output with coarse and fine segmentation to a mask.\n    Assumes that predictor output has the following attributes:\n     - coarse_segm (tensor of size [N, D, H, W]): coarse segmentation\n         unnormalized scores for N instances; D is the number of coarse\n         segmentation labels, H and W is the resolution of the estimate\n\n    Args:\n        predictor_output: DensePose predictor output to be converted to mask\n        boxes (Boxes): bounding boxes that correspond to the DensePose\n            predictor outputs\n        image_size_hw (tuple [int, int]): image height Himg and width Wimg\n    Return:\n        BitMasks that contain a bool tensor of size [N, Himg, Wimg] with\n        a mask of the size of the image for each instance\n    \"\"\"", "\n", "H", ",", "W", "=", "image_size_hw", "\n", "boxes_xyxy_abs", "=", "boxes", ".", "tensor", ".", "clone", "(", ")", "\n", "boxes_xywh_abs", "=", "BoxMode", ".", "convert", "(", "boxes_xyxy_abs", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "N", "=", "len", "(", "boxes_xywh_abs", ")", "\n", "masks", "=", "torch", ".", "zeros", "(", "(", "N", ",", "H", ",", "W", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "boxes", ".", "tensor", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "boxes_xywh_abs", ")", ")", ":", "\n", "        ", "box_xywh", "=", "make_int_box", "(", "boxes_xywh_abs", "[", "i", "]", ")", "\n", "box_mask", "=", "resample_coarse_segm_tensor_to_bbox", "(", "predictor_output", "[", "i", "]", ".", "coarse_segm", ",", "box_xywh", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "box_xywh", "\n", "masks", "[", "i", ",", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", "]", "=", "box_mask", "\n", "\n", "", "return", "BitMasks", "(", "masks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.predictor_output_with_fine_and_coarse_segm_to_mask": [[115, 148], ["boxes.tensor.clone", "detectron2.structures.BoxMode.convert", "len", "torch.zeros", "range", "detectron2.structures.BitMasks", "len", "base.make_int_box", "segm_to_mask.resample_fine_and_coarse_segm_to_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.make_int_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_to_bbox"], ["", "def", "predictor_output_with_fine_and_coarse_segm_to_mask", "(", "\n", "predictor_output", ":", "Any", ",", "boxes", ":", "Boxes", ",", "image_size_hw", ":", "ImageSizeType", "\n", ")", "->", "BitMasks", ":", "\n", "    ", "\"\"\"\n    Convert predictor output with coarse and fine segmentation to a mask.\n    Assumes that predictor output has the following attributes:\n     - coarse_segm (tensor of size [N, D, H, W]): coarse segmentation\n         unnormalized scores for N instances; D is the number of coarse\n         segmentation labels, H and W is the resolution of the estimate\n     - fine_segm (tensor of size [N, C, H, W]): fine segmentation\n         unnormalized scores for N instances; C is the number of fine\n         segmentation labels, H and W is the resolution of the estimate\n\n    Args:\n        predictor_output: DensePose predictor output to be converted to mask\n        boxes (Boxes): bounding boxes that correspond to the DensePose\n            predictor outputs\n        image_size_hw (tuple [int, int]): image height Himg and width Wimg\n    Return:\n        BitMasks that contain a bool tensor of size [N, Himg, Wimg] with\n        a mask of the size of the image for each instance\n    \"\"\"", "\n", "H", ",", "W", "=", "image_size_hw", "\n", "boxes_xyxy_abs", "=", "boxes", ".", "tensor", ".", "clone", "(", ")", "\n", "boxes_xywh_abs", "=", "BoxMode", ".", "convert", "(", "boxes_xyxy_abs", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "N", "=", "len", "(", "boxes_xywh_abs", ")", "\n", "masks", "=", "torch", ".", "zeros", "(", "(", "N", ",", "H", ",", "W", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "boxes", ".", "tensor", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "boxes_xywh_abs", ")", ")", ":", "\n", "        ", "box_xywh", "=", "make_int_box", "(", "boxes_xywh_abs", "[", "i", "]", ")", "\n", "labels_i", "=", "resample_fine_and_coarse_segm_to_bbox", "(", "predictor_output", "[", "i", "]", ",", "box_xywh", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "box_xywh", "\n", "masks", "[", "i", ",", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", "]", "=", "labels_i", ">", "0", "\n", "", "return", "BitMasks", "(", "masks", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_uv_tensors_to_bbox": [[18, 46], ["max", "max", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.zeros", "range", "int", "int", "F.interpolate.size"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["def", "resample_uv_tensors_to_bbox", "(", "\n", "u", ":", "torch", ".", "Tensor", ",", "\n", "v", ":", "torch", ".", "Tensor", ",", "\n", "labels", ":", "torch", ".", "Tensor", ",", "\n", "box_xywh_abs", ":", "IntTupleBox", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Resamples U and V coordinate estimates for the given bounding box\n\n    Args:\n        u (tensor [1, C, H, W] of float): U coordinates\n        v (tensor [1, C, H, W] of float): V coordinates\n        labels (tensor [H, W] of long): labels obtained by resampling segmentation\n            outputs for the given bounding box\n        box_xywh_abs (tuple of 4 int): bounding box that corresponds to predictor outputs\n    Return:\n       Resampled U and V coordinates - a tensor [2, H, W] of float\n    \"\"\"", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "box_xywh_abs", "\n", "w", "=", "max", "(", "int", "(", "w", ")", ",", "1", ")", "\n", "h", "=", "max", "(", "int", "(", "h", ")", ",", "1", ")", "\n", "u_bbox", "=", "F", ".", "interpolate", "(", "u", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "v_bbox", "=", "F", ".", "interpolate", "(", "v", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "uv", "=", "torch", ".", "zeros", "(", "[", "2", ",", "h", ",", "w", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "u", ".", "device", ")", "\n", "for", "part_id", "in", "range", "(", "1", ",", "u_bbox", ".", "size", "(", "1", ")", ")", ":", "\n", "        ", "uv", "[", "0", "]", "[", "labels", "==", "part_id", "]", "=", "u_bbox", "[", "0", ",", "part_id", "]", "[", "labels", "==", "part_id", "]", "\n", "uv", "[", "1", "]", "[", "labels", "==", "part_id", "]", "=", "v_bbox", "[", "0", ",", "part_id", "]", "[", "labels", "==", "part_id", "]", "\n", "", "return", "uv", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_uv_to_bbox": [[48, 70], ["chart_output_to_chart_result.resample_uv_tensors_to_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_uv_tensors_to_bbox"], ["", "def", "resample_uv_to_bbox", "(", "\n", "predictor_output", ":", "DensePoseChartPredictorOutput", ",", "\n", "labels", ":", "torch", ".", "Tensor", ",", "\n", "box_xywh_abs", ":", "IntTupleBox", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Resamples U and V coordinate estimates for the given bounding box\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output to be resampled\n        labels (tensor [H, W] of long): labels obtained by resampling segmentation\n            outputs for the given bounding box\n        box_xywh_abs (tuple of 4 int): bounding box that corresponds to predictor outputs\n    Return:\n       Resampled U and V coordinates - a tensor [2, H, W] of float\n    \"\"\"", "\n", "return", "resample_uv_tensors_to_bbox", "(", "\n", "predictor_output", ".", "u", ",", "\n", "predictor_output", ".", "v", ",", "\n", "labels", ",", "\n", "box_xywh_abs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.densepose_chart_predictor_output_to_result": [[73, 99], ["boxes.tensor.clone", "detectron2.structures.boxes.BoxMode.convert", "base.make_int_box", "resample_fine_and_coarse_segm_to_bbox().squeeze", "chart_output_to_chart_result.resample_uv_to_bbox", "structures.DensePoseChartResult", "len", "len", "len", "len", "resample_fine_and_coarse_segm_to_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.make_int_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_uv_to_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_to_bbox"], ["", "def", "densepose_chart_predictor_output_to_result", "(", "\n", "predictor_output", ":", "DensePoseChartPredictorOutput", ",", "boxes", ":", "Boxes", "\n", ")", "->", "DensePoseChartResult", ":", "\n", "    ", "\"\"\"\n    Convert densepose chart predictor outputs to results\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output to be converted to results, must contain only 1 output\n        boxes (Boxes): bounding box that corresponds to the predictor output,\n            must contain only 1 bounding box\n    Return:\n       DensePose chart-based result (DensePoseChartResult)\n    \"\"\"", "\n", "assert", "len", "(", "predictor_output", ")", "==", "1", "and", "len", "(", "boxes", ")", "==", "1", ",", "(", "\n", "f\"Predictor output to result conversion can operate only single outputs\"", "\n", "f\", got {len(predictor_output)} predictor outputs and {len(boxes)} boxes\"", "\n", ")", "\n", "\n", "boxes_xyxy_abs", "=", "boxes", ".", "tensor", ".", "clone", "(", ")", "\n", "boxes_xywh_abs", "=", "BoxMode", ".", "convert", "(", "boxes_xyxy_abs", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "box_xywh", "=", "make_int_box", "(", "boxes_xywh_abs", "[", "0", "]", ")", "\n", "\n", "labels", "=", "resample_fine_and_coarse_segm_to_bbox", "(", "predictor_output", ",", "box_xywh", ")", ".", "squeeze", "(", "0", ")", "\n", "uv", "=", "resample_uv_to_bbox", "(", "predictor_output", ",", "labels", ",", "box_xywh", ")", "\n", "return", "DensePoseChartResult", "(", "labels", "=", "labels", ",", "uv", "=", "uv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_confidences_to_bbox": [[101, 157], ["max", "max", "torch.zeros", "int", "int", "torch.nn.functional.interpolate", "torch.zeros.clone", "range", "getattr", "predictor_output.u.size", "F.interpolate.size", "predictor_output.u.size", "getattr", "F.interpolate.size", "predictor_output.u.size"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "def", "resample_confidences_to_bbox", "(", "\n", "predictor_output", ":", "DensePoseChartPredictorOutput", ",", "\n", "labels", ":", "torch", ".", "Tensor", ",", "\n", "box_xywh_abs", ":", "IntTupleBox", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Resamples confidences for the given bounding box\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output to be resampled\n        labels (tensor [H, W] of long): labels obtained by resampling segmentation\n            outputs for the given bounding box\n        box_xywh_abs (tuple of 4 int): bounding box that corresponds to predictor outputs\n    Return:\n       Resampled confidences - a dict of [H, W] tensors of float\n    \"\"\"", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "box_xywh_abs", "\n", "w", "=", "max", "(", "int", "(", "w", ")", ",", "1", ")", "\n", "h", "=", "max", "(", "int", "(", "h", ")", ",", "1", ")", "\n", "\n", "confidence_names", "=", "[", "\n", "\"sigma_1\"", ",", "\n", "\"sigma_2\"", ",", "\n", "\"kappa_u\"", ",", "\n", "\"kappa_v\"", ",", "\n", "\"fine_segm_confidence\"", ",", "\n", "\"coarse_segm_confidence\"", ",", "\n", "]", "\n", "confidence_results", "=", "{", "key", ":", "None", "for", "key", "in", "confidence_names", "}", "\n", "confidence_names", "=", "[", "\n", "key", "for", "key", "in", "confidence_names", "if", "getattr", "(", "predictor_output", ",", "key", ")", "is", "not", "None", "\n", "]", "\n", "confidence_base", "=", "torch", ".", "zeros", "(", "[", "h", ",", "w", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "predictor_output", ".", "u", ".", "device", ")", "\n", "\n", "# assign data from channels that correspond to the labels", "\n", "for", "key", "in", "confidence_names", ":", "\n", "        ", "resampled_confidence", "=", "F", ".", "interpolate", "(", "\n", "getattr", "(", "predictor_output", ",", "key", ")", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "result", "=", "confidence_base", ".", "clone", "(", ")", "\n", "for", "part_id", "in", "range", "(", "1", ",", "predictor_output", ".", "u", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "if", "resampled_confidence", ".", "size", "(", "1", ")", "!=", "predictor_output", ".", "u", ".", "size", "(", "1", ")", ":", "\n", "# confidence is not part-based, don't try to fill it part by part", "\n", "                ", "continue", "\n", "", "result", "[", "labels", "==", "part_id", "]", "=", "resampled_confidence", "[", "0", ",", "part_id", "]", "[", "labels", "==", "part_id", "]", "\n", "\n", "", "if", "resampled_confidence", ".", "size", "(", "1", ")", "!=", "predictor_output", ".", "u", ".", "size", "(", "1", ")", ":", "\n", "# confidence is not part-based, fill the data with the first channel", "\n", "# (targeted for segmentation confidences that have only 1 channel)", "\n", "            ", "result", "=", "resampled_confidence", "[", "0", ",", "0", "]", "\n", "\n", "", "confidence_results", "[", "key", "]", "=", "result", "\n", "\n", "", "return", "confidence_results", "# pyre-ignore[7]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.densepose_chart_predictor_output_to_result_with_confidences": [[159, 186], ["boxes.tensor.clone", "detectron2.structures.boxes.BoxMode.convert", "base.make_int_box", "resample_fine_and_coarse_segm_to_bbox().squeeze", "chart_output_to_chart_result.resample_uv_to_bbox", "chart_output_to_chart_result.resample_confidences_to_bbox", "structures.DensePoseChartResultWithConfidences", "len", "len", "len", "len", "resample_fine_and_coarse_segm_to_bbox"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.make_int_box", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_uv_to_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.chart_output_to_chart_result.resample_confidences_to_bbox", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.segm_to_mask.resample_fine_and_coarse_segm_to_bbox"], ["", "def", "densepose_chart_predictor_output_to_result_with_confidences", "(", "\n", "predictor_output", ":", "DensePoseChartPredictorOutput", ",", "boxes", ":", "Boxes", "\n", ")", "->", "DensePoseChartResultWithConfidences", ":", "\n", "    ", "\"\"\"\n    Convert densepose chart predictor outputs to results\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output with confidences to be converted to results, must contain only 1 output\n        boxes (Boxes): bounding box that corresponds to the predictor output,\n            must contain only 1 bounding box\n    Return:\n       DensePose chart-based result with confidences (DensePoseChartResultWithConfidences)\n    \"\"\"", "\n", "assert", "len", "(", "predictor_output", ")", "==", "1", "and", "len", "(", "boxes", ")", "==", "1", ",", "(", "\n", "f\"Predictor output to result conversion can operate only single outputs\"", "\n", "f\", got {len(predictor_output)} predictor outputs and {len(boxes)} boxes\"", "\n", ")", "\n", "\n", "boxes_xyxy_abs", "=", "boxes", ".", "tensor", ".", "clone", "(", ")", "\n", "boxes_xywh_abs", "=", "BoxMode", ".", "convert", "(", "boxes_xyxy_abs", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "box_xywh", "=", "make_int_box", "(", "boxes_xywh_abs", "[", "0", "]", ")", "\n", "\n", "labels", "=", "resample_fine_and_coarse_segm_to_bbox", "(", "predictor_output", ",", "box_xywh", ")", ".", "squeeze", "(", "0", ")", "\n", "uv", "=", "resample_uv_to_bbox", "(", "predictor_output", ",", "labels", ",", "box_xywh", ")", "\n", "confidences", "=", "resample_confidences_to_bbox", "(", "predictor_output", ",", "labels", ",", "box_xywh", ")", "\n", "return", "DensePoseChartResultWithConfidences", "(", "labels", "=", "labels", ",", "uv", "=", "uv", ",", "**", "confidences", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.frame_selector.RandomKFramesSelector.__init__": [[35, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "k", ":", "int", ")", ":", "\n", "        ", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.frame_selector.RandomKFramesSelector.__call__": [[38, 48], ["random.sample", "min", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_tss", ":", "FrameTsList", ")", "->", "FrameTsList", ":", "\n", "        ", "\"\"\"\n        Select `k` random frames\n\n        Args:\n          frames_tss (List[int]): timestamps of input frames\n        Returns:\n          List[int]: timestamps of selected frames\n        \"\"\"", "\n", "return", "random", ".", "sample", "(", "frame_tss", ",", "min", "(", "self", ".", "k", ",", "len", "(", "frame_tss", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.frame_selector.FirstKFramesSelector.__init__": [[55, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "k", ":", "int", ")", ":", "\n", "        ", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.frame_selector.FirstKFramesSelector.__call__": [[58, 68], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_tss", ":", "FrameTsList", ")", "->", "FrameTsList", ":", "\n", "        ", "\"\"\"\n        Select `k` first frames\n\n        Args:\n          frames_tss (List[int]): timestamps of input frames\n        Returns:\n          List[int]: timestamps of selected frames\n        \"\"\"", "\n", "return", "frame_tss", "[", ":", "self", ".", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.frame_selector.LastKFramesSelector.__init__": [[75, 77], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "k", ":", "int", ")", ":", "\n", "        ", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.frame_selector.LastKFramesSelector.__call__": [[78, 88], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_tss", ":", "FrameTsList", ")", "->", "FrameTsList", ":", "\n", "        ", "\"\"\"\n        Select `k` last frames\n\n        Args:\n          frames_tss (List[int]): timestamps of input frames\n        Returns:\n          List[int]: timestamps of selected frames\n        \"\"\"", "\n", "return", "frame_tss", "[", "-", "self", ".", "k", ":", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__init__": [[222, 251], ["video_keyframe_dataset.read_keyframe_helper_data"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.read_keyframe_helper_data"], ["def", "__init__", "(", "\n", "self", ",", "\n", "video_list", ":", "List", "[", "str", "]", ",", "\n", "frame_selector", ":", "Optional", "[", "FrameSelector", "]", "=", "None", ",", "\n", "transform", ":", "Optional", "[", "FrameTransform", "]", "=", "None", ",", "\n", "keyframe_helper_fpath", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Dataset constructor\n\n        Args:\n            video_list (List[str]): list of paths to video files\n            frame_selector (Callable: KeyFrameList -> KeyFrameList):\n                selects keyframes to process, keyframes are given by\n                packet timestamps in timebase counts. If None, all keyframes\n                are selected (default: None)\n            transform (Callable: torch.Tensor -> torch.Tensor):\n                transforms a batch of RGB images (tensors of size [B, H, W, 3]),\n                returns a tensor of the same size. If None, no transform is\n                applied (default: None)\n\n        \"\"\"", "\n", "self", ".", "video_list", "=", "video_list", "\n", "self", ".", "frame_selector", "=", "frame_selector", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "keyframe_helper_data", "=", "(", "\n", "read_keyframe_helper_data", "(", "keyframe_helper_fpath", ")", "\n", "if", "keyframe_helper_fpath", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__getitem__": [[253, 281], ["video_keyframe_dataset.read_keyframes", "numpy.stack", "torch.as_tensor", "video_keyframe_dataset.list_keyframes", "video_keyframe_dataset.VideoKeyframeDataset.frame_selector", "video_keyframe_dataset.VideoKeyframeDataset.transform", "frame.to_rgb().to_ndarray", "torch.device", "frame.to_rgb"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.read_keyframes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.list_keyframes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transforms.augmentation.AugInput.transform", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Gets selected keyframes from a given video\n\n        Args:\n            idx (int): video index in the video list file\n        Returns:\n            frames (torch.Tensor): tensor of size [N, H, W, 3] or of size\n                defined by the transform that contains keyframes data\n        \"\"\"", "\n", "fpath", "=", "self", ".", "video_list", "[", "idx", "]", "\n", "keyframes", "=", "(", "\n", "list_keyframes", "(", "fpath", ")", "\n", "if", "self", ".", "keyframe_helper_data", "is", "None", "or", "idx", "not", "in", "self", ".", "keyframe_helper_data", "\n", "else", "self", ".", "keyframe_helper_data", "[", "idx", "]", "\n", ")", "\n", "if", "not", "keyframes", ":", "\n", "            ", "return", "self", ".", "_EMPTY_FRAMES", "\n", "", "if", "self", ".", "frame_selector", "is", "not", "None", ":", "\n", "            ", "keyframes", "=", "self", ".", "frame_selector", "(", "keyframes", ")", "# pyre-ignore[29]", "\n", "", "frames", "=", "read_keyframes", "(", "fpath", ",", "keyframes", ")", "\n", "if", "not", "frames", ":", "\n", "            ", "return", "self", ".", "_EMPTY_FRAMES", "\n", "", "frames", "=", "np", ".", "stack", "(", "[", "frame", ".", "to_rgb", "(", ")", ".", "to_ndarray", "(", ")", "for", "frame", "in", "frames", "]", ")", "\n", "frames", "=", "torch", ".", "as_tensor", "(", "frames", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "frames", "=", "self", ".", "transform", "(", "frames", ")", "# pyre-ignore[29]", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.VideoKeyframeDataset.__len__": [[282, 284], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "video_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.list_keyframes": [[21, 94], ["detectron2.utils.file_io.PathManager.open", "av.open", "logging.getLogger", "logging.getLogger.warning", "logging.getLogger", "logging.getLogger.warning", "next", "av.open.seek", "av.open.demux", "logging.getLogger", "logging.getLogger.warning", "keyframes.append", "logging.getLogger", "logging.getLogger.debug", "logging.getLogger", "logging.getLogger.warning"], "function", ["None"], ["def", "list_keyframes", "(", "video_fpath", ":", "str", ",", "video_stream_idx", ":", "int", "=", "0", ")", "->", "FrameTsList", ":", "\n", "    ", "\"\"\"\n    Traverses all keyframes of a video file. Returns a list of keyframe\n    timestamps. Timestamps are counts in timebase units.\n\n    Args:\n       video_fpath (str): Video file path\n       video_stream_idx (int): Video stream index (default: 0)\n    Returns:\n       List[int]: list of keyframe timestaps (timestamp is a count in timebase\n           units)\n    \"\"\"", "\n", "try", ":", "\n", "        ", "with", "PathManager", ".", "open", "(", "video_fpath", ",", "\"rb\"", ")", "as", "io", ":", "\n", "            ", "container", "=", "av", ".", "open", "(", "io", ",", "mode", "=", "\"r\"", ")", "\n", "stream", "=", "container", ".", "streams", ".", "video", "[", "video_stream_idx", "]", "\n", "keyframes", "=", "[", "]", "\n", "pts", "=", "-", "1", "\n", "# Note: even though we request forward seeks for keyframes, sometimes", "\n", "# a keyframe in backwards direction is returned. We introduce tolerance", "\n", "# as a max count of ignored backward seeks", "\n", "tolerance_backward_seeks", "=", "2", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "container", ".", "seek", "(", "pts", "+", "1", ",", "backward", "=", "False", ",", "any_frame", "=", "False", ",", "stream", "=", "stream", ")", "\n", "", "except", "av", ".", "AVError", "as", "e", ":", "\n", "# the exception occurs when the video length is exceeded,", "\n", "# we then return whatever data we've already collected", "\n", "                    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "debug", "(", "\n", "f\"List keyframes: Error seeking video file {video_fpath}, \"", "\n", "f\"video stream {video_stream_idx}, pts {pts + 1}, AV error: {e}\"", "\n", ")", "\n", "return", "keyframes", "\n", "", "except", "OSError", "as", "e", ":", "\n", "                    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"List keyframes: Error seeking video file {video_fpath}, \"", "\n", "f\"video stream {video_stream_idx}, pts {pts + 1}, OS error: {e}\"", "\n", ")", "\n", "return", "[", "]", "\n", "", "packet", "=", "next", "(", "container", ".", "demux", "(", "video", "=", "video_stream_idx", ")", ")", "\n", "if", "packet", ".", "pts", "is", "not", "None", "and", "packet", ".", "pts", "<=", "pts", ":", "\n", "                    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"Video file {video_fpath}, stream {video_stream_idx}: \"", "\n", "f\"bad seek for packet {pts + 1} (got packet {packet.pts}), \"", "\n", "f\"tolerance {tolerance_backward_seeks}.\"", "\n", ")", "\n", "tolerance_backward_seeks", "-=", "1", "\n", "if", "tolerance_backward_seeks", "==", "0", ":", "\n", "                        ", "return", "[", "]", "\n", "", "pts", "+=", "1", "\n", "continue", "\n", "", "tolerance_backward_seeks", "=", "2", "\n", "pts", "=", "packet", ".", "pts", "\n", "if", "pts", "is", "None", ":", "\n", "                    ", "return", "keyframes", "\n", "", "if", "packet", ".", "is_keyframe", ":", "\n", "                    ", "keyframes", ".", "append", "(", "pts", ")", "\n", "", "", "return", "keyframes", "\n", "", "", "except", "OSError", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"List keyframes: Error opening video file container {video_fpath}, \"", "f\"OS error: {e}\"", "\n", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"List keyframes: Error opening video file container {video_fpath}, \"", "\n", "f\"Runtime error: {e}\"", "\n", ")", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.read_keyframes": [[96, 158], ["detectron2.utils.file_io.PathManager.open", "av.open", "av.open.close", "logging.getLogger", "logging.getLogger.warning", "logging.getLogger", "logging.getLogger.warning", "av.open.seek", "next", "frames.append", "av.open.decode", "logging.getLogger", "logging.getLogger.warning", "av.open.close", "logging.getLogger", "logging.getLogger.warning", "av.open.close", "logging.getLogger", "logging.getLogger.warning", "av.open.close"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.atss.atss.BoxCoder.decode", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.TensorboardXWriter.close"], ["", "def", "read_keyframes", "(", "\n", "video_fpath", ":", "str", ",", "keyframes", ":", "FrameTsList", ",", "video_stream_idx", ":", "int", "=", "0", "\n", ")", "->", "FrameList", ":", "# pyre-ignore[11]", "\n", "    ", "\"\"\"\n    Reads keyframe data from a video file.\n\n    Args:\n        video_fpath (str): Video file path\n        keyframes (List[int]): List of keyframe timestamps (as counts in\n            timebase units to be used in container seek operations)\n        video_stream_idx (int): Video stream index (default: 0)\n    Returns:\n        List[Frame]: list of frames that correspond to the specified timestamps\n    \"\"\"", "\n", "try", ":", "\n", "        ", "with", "PathManager", ".", "open", "(", "video_fpath", ",", "\"rb\"", ")", "as", "io", ":", "\n", "            ", "container", "=", "av", ".", "open", "(", "io", ")", "\n", "stream", "=", "container", ".", "streams", ".", "video", "[", "video_stream_idx", "]", "\n", "frames", "=", "[", "]", "\n", "for", "pts", "in", "keyframes", ":", "\n", "                ", "try", ":", "\n", "                    ", "container", ".", "seek", "(", "pts", ",", "any_frame", "=", "False", ",", "stream", "=", "stream", ")", "\n", "frame", "=", "next", "(", "container", ".", "decode", "(", "video", "=", "0", ")", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "except", "av", ".", "AVError", "as", "e", ":", "\n", "                    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"Read keyframes: Error seeking video file {video_fpath}, \"", "\n", "f\"video stream {video_stream_idx}, pts {pts}, AV error: {e}\"", "\n", ")", "\n", "container", ".", "close", "(", ")", "\n", "return", "frames", "\n", "", "except", "OSError", "as", "e", ":", "\n", "                    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"Read keyframes: Error seeking video file {video_fpath}, \"", "\n", "f\"video stream {video_stream_idx}, pts {pts}, OS error: {e}\"", "\n", ")", "\n", "container", ".", "close", "(", ")", "\n", "return", "frames", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"Read keyframes: Error decoding frame from {video_fpath}, \"", "\n", "f\"video stream {video_stream_idx}, pts {pts}\"", "\n", ")", "\n", "container", ".", "close", "(", ")", "\n", "return", "frames", "\n", "\n", "", "", "container", ".", "close", "(", ")", "\n", "return", "frames", "\n", "", "", "except", "OSError", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"Read keyframes: Error opening video file container {video_fpath}, OS error: {e}\"", "\n", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "f\"Read keyframes: Error opening video file container {video_fpath}, Runtime error: {e}\"", "\n", ")", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.video_list_from_file": [[160, 173], ["detectron2.utils.file_io.PathManager.open", "video_list.append", "utils.maybe_prepend_base_path", "str", "line.strip"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path"], ["", "def", "video_list_from_file", "(", "video_list_fpath", ":", "str", ",", "base_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Create a list of paths to video files from a text file.\n\n    Args:\n        video_list_fpath (str): path to a plain text file with the list of videos\n        base_path (str): base path for entries from the video list (default: None)\n    \"\"\"", "\n", "video_list", "=", "[", "]", "\n", "with", "PathManager", ".", "open", "(", "video_list_fpath", ",", "\"r\"", ")", "as", "io", ":", "\n", "        ", "for", "line", "in", "io", ":", "\n", "            ", "video_list", ".", "append", "(", "maybe_prepend_base_path", "(", "base_path", ",", "str", "(", "line", ".", "strip", "(", ")", ")", ")", ")", "\n", "", "", "return", "video_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.video.video_keyframe_dataset.read_keyframe_helper_data": [[175, 213], ["detectron2.utils.file_io.PathManager.open", "csv.reader", "next", "next.index", "next.index", "logging.getLogger", "logging.getLogger.warning", "int", "len", "int", "[].split"], "function", ["None"], ["", "def", "read_keyframe_helper_data", "(", "fpath", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Read keyframe data from a file in CSV format: the header should contain\n    \"video_id\" and \"keyframes\" fields. Value specifications are:\n      video_id: int\n      keyframes: list(int)\n    Example of contents:\n      video_id,keyframes\n      2,\"[1,11,21,31,41,51,61,71,81]\"\n\n    Args:\n        fpath (str): File containing keyframe data\n\n    Return:\n        video_id_to_keyframes (dict: int -> list(int)): for a given video ID it\n          contains a list of keyframes for that video\n    \"\"\"", "\n", "video_id_to_keyframes", "=", "{", "}", "\n", "try", ":", "\n", "        ", "with", "PathManager", ".", "open", "(", "fpath", ",", "\"r\"", ")", "as", "io", ":", "\n", "            ", "csv_reader", "=", "csv", ".", "reader", "(", "io", ")", "# pyre-ignore[6]", "\n", "header", "=", "next", "(", "csv_reader", ")", "\n", "video_id_idx", "=", "header", ".", "index", "(", "\"video_id\"", ")", "\n", "keyframes_idx", "=", "header", ".", "index", "(", "\"keyframes\"", ")", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                ", "video_id", "=", "int", "(", "row", "[", "video_id_idx", "]", ")", "\n", "assert", "(", "\n", "video_id", "not", "in", "video_id_to_keyframes", "\n", ")", ",", "f\"Duplicate keyframes entry for video {fpath}\"", "\n", "video_id_to_keyframes", "[", "video_id", "]", "=", "(", "\n", "[", "int", "(", "v", ")", "for", "v", "in", "row", "[", "keyframes_idx", "]", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "if", "len", "(", "row", "[", "keyframes_idx", "]", ")", ">", "2", "\n", "else", "[", "]", "\n", ")", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "f\"Error reading keyframe helper data from {fpath}: {e}\"", ")", "\n", "", "return", "video_id_to_keyframes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.__init__": [[21, 26], ["collections.UserDict.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["# NOTE: Most of the BN models here are no longer used. We use the", "\n", "# re-converted pre-trained models under detectron2 model zoo instead.", "\n", "C2_IMAGENET_MODELS", "=", "{", "\n", "\"MSRA/R-50\"", ":", "\"ImageNetPretrained/MSRA/R-50.pkl\"", ",", "\n", "\"MSRA/R-101\"", ":", "\"ImageNetPretrained/MSRA/R-101.pkl\"", ",", "\n", "\"FAIR/R-50-GN\"", ":", "\"ImageNetPretrained/47261647/R-50-GN.pkl\"", ",", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.__setitem__": [[27, 41], ["super().__setitem__", "logging.getLogger", "logging.getLogger.warning"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.__setitem__"], ["\"FAIR/R-101-GN\"", ":", "\"ImageNetPretrained/47592356/R-101-GN.pkl\"", ",", "\n", "\"FAIR/X-101-32x8d\"", ":", "\"ImageNetPretrained/20171220/X-101-32x8d.pkl\"", ",", "\n", "\"FAIR/X-101-64x4d\"", ":", "\"ImageNetPretrained/FBResNeXt/X-101-64x4d.pkl\"", ",", "\n", "\"FAIR/X-152-32x8d-IN5k\"", ":", "\"ImageNetPretrained/25093814/X-152-32x8d-IN5k.pkl\"", ",", "\n", "}", "\n", "\n", "C2_DETECTRON_PATH_FORMAT", "=", "(", "\n", "\"{prefix}/{url}/output/train/{dataset}/{type}/model_final.pkl\"", "# noqa B950", "\n", ")", "\n", "\n", "C2_DATASET_COCO", "=", "\"coco_2014_train%3Acoco_2014_valminusminival\"", "\n", "C2_DATASET_COCO_KEYPOINTS", "=", "\"keypoints_coco_2014_train%3Akeypoints_coco_2014_valminusminival\"", "\n", "\n", "# format: {model_name} -> part of the url", "\n", "C2_DETECTRON_MODELS", "=", "{", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.get_mesh_id": [[42, 44], ["None"], "methods", ["None"], ["\"35857197/e2e_faster_rcnn_R-50-C4_1x\"", ":", "\"35857197/12_2017_baselines/e2e_faster_rcnn_R-50-C4_1x.yaml.01_33_49.iAX0mXvW\"", ",", "# noqa B950", "\n", "\"35857345/e2e_faster_rcnn_R-50-FPN_1x\"", ":", "\"35857345/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml.01_36_30.cUF7QR7I\"", ",", "# noqa B950", "\n", "\"35857890/e2e_faster_rcnn_R-101-FPN_1x\"", ":", "\"35857890/12_2017_baselines/e2e_faster_rcnn_R-101-FPN_1x.yaml.01_38_50.sNxI7sX7\"", ",", "# noqa B950", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog._MeshCatalog.get_mesh_name": [[45, 47], ["None"], "methods", ["None"], ["\"36761737/e2e_faster_rcnn_X-101-32x8d-FPN_1x\"", ":", "\"36761737/12_2017_baselines/e2e_faster_rcnn_X-101-32x8d-FPN_1x.yaml.06_31_39.5MIHi1fZ\"", ",", "# noqa B950", "\n", "\"35858791/e2e_mask_rcnn_R-50-C4_1x\"", ":", "\"35858791/12_2017_baselines/e2e_mask_rcnn_R-50-C4_1x.yaml.01_45_57.ZgkA7hPB\"", ",", "# noqa B950", "\n", "\"35858933/e2e_mask_rcnn_R-50-FPN_1x\"", ":", "\"35858933/12_2017_baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml.01_48_14.DzEQe4wC\"", ",", "# noqa B950", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog.register_mesh": [[52, 66], ["catalog.MeshInfo", "utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path", "utils.maybe_prepend_base_path"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.maybe_prepend_base_path"], ["\"35998355/rpn_R-50-C4_1x\"", ":", "\"35998355/12_2017_baselines/rpn_R-50-C4_1x.yaml.08_00_43.njH5oD9L\"", ",", "# noqa B950", "\n", "\"35998814/rpn_R-50-FPN_1x\"", ":", "\"35998814/12_2017_baselines/rpn_R-50-FPN_1x.yaml.08_06_03.Axg0r179\"", ",", "# noqa B950", "\n", "\"36225147/fast_R-50-FPN_1x\"", ":", "\"36225147/12_2017_baselines/fast_rcnn_R-50-FPN_1x.yaml.08_39_09.L3obSdQ2\"", ",", "# noqa B950", "\n", "}", "\n", "\n", "@", "staticmethod", "\n", "def", "get", "(", "name", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"Caffe2Detectron/COCO\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_detectron_baseline", "(", "name", ")", "\n", "", "if", "name", ".", "startswith", "(", "\"ImageNetPretrained/\"", ")", ":", "\n", "            ", "return", "ModelCatalog", ".", "_get_c2_imagenet_pretrained", "(", "name", ")", "\n", "", "raise", "RuntimeError", "(", "\"model not present in the catalog: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_get_c2_imagenet_pretrained", "(", "name", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog.register_meshes": [[69, 72], ["catalog.register_mesh"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meshes.catalog.register_mesh"], ["name", "=", "ModelCatalog", ".", "C2_IMAGENET_MODELS", "[", "name", "]", "\n", "url", "=", "\"/\"", ".", "join", "(", "[", "prefix", ",", "name", "]", ")", "\n", "return", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transform.image.ImageResizeTransform.__init__": [[13, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "min_size", ":", "int", "=", "800", ",", "max_size", ":", "int", "=", "1333", ")", ":", "\n", "        ", "self", ".", "min_size", "=", "min_size", "\n", "self", ".", "max_size", "=", "max_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.transform.image.ImageResizeTransform.__call__": [[17, 38], ["torch.nn.functional.interpolate.permute().float", "min", "max", "min", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate.permute"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate"], ["", "def", "__call__", "(", "self", ",", "frames", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Args:\n            frames (torch.Tensor): tensor of size [N, H, W, 3] that contains\n                RGB data (typically in uint8)\n        Returns:\n            frames (torch.Tensor): tensor of size [N, 3, H1, W1] where\n                H1 and W1 are chosen to respect the specified min and max sizes\n                and preserve the original aspect ratio, the data channels\n                follow BGR order and the data type is `torch.float32`\n        \"\"\"", "\n", "frames", "=", "frames", "[", "...", ",", "[", "2", ",", "1", ",", "0", "]", "]", "# RGB -> BGR", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "float", "(", ")", "# NHWC -> NCHW", "\n", "# resize with min size", "\n", "min_size", "=", "min", "(", "frames", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "max_size", "=", "max", "(", "frames", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "scale", "=", "min", "(", "self", ".", "min_size", "/", "min_size", ",", "self", ".", "max_size", "/", "max_size", ")", "\n", "frames", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "frames", ",", "scale_factor", "=", "scale", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", "\n", ")", "\n", "return", "frames", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer.__init__": [[16, 31], ["None"], "methods", ["None"], ["def", "register", "(", "cls", ",", "from_type", ":", "Type", ",", "converter", ":", "Any", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Registers a converter for the specified type.\n        Can be used as a decorator (if converter is None), or called as a method.\n\n        Args:\n            from_type (type): type to register the converter for;\n                all instances of this type will use the same converter\n            converter (callable): converter to be registered for the given\n                type; if None, this method is assumed to be a decorator for the converter\n        \"\"\"", "\n", "\n", "if", "converter", "is", "not", "None", ":", "\n", "            ", "cls", ".", "_do_register", "(", "from_type", ",", "converter", ")", "\n", "\n", "", "def", "wrapper", "(", "converter", ":", "Any", ")", "->", "Any", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer.visualize": [[32, 58], ["base.MatrixVisualizer._check_image", "base.MatrixVisualizer._check_mask_matrix", "base.MatrixVisualizer._resize", "numpy.tile", "numpy.any", "matrix_scaled.clip().astype", "cv2.applyColorMap", "image_target_bgr.astype", "int", "matrix.astype", "logging.getLogger", "logging.getLogger.warning", "matrix_scaled.clip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer._check_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer._check_mask_matrix", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer._resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["            ", "cls", ".", "_do_register", "(", "from_type", ",", "converter", ")", "\n", "return", "converter", "\n", "\n", "", "return", "wrapper", "\n", "\n", "", "@", "classmethod", "\n", "def", "_do_register", "(", "cls", ",", "from_type", ":", "Type", ",", "converter", ":", "Any", ")", ":", "\n", "        ", "cls", ".", "registry", "[", "from_type", "]", "=", "converter", "# pyre-ignore[16]", "\n", "\n", "", "@", "classmethod", "\n", "def", "_lookup_converter", "(", "cls", ",", "from_type", ":", "Type", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Perform recursive lookup for the given type\n        to find registered converter. If a converter was found for some base\n        class, it gets registered for this class to save on further lookups.\n\n        Args:\n            from_type: type for which to find a converter\n        Return:\n            callable or None - registered converter or None\n                if no suitable entry was found in the registry\n        \"\"\"", "\n", "if", "from_type", "in", "cls", ".", "registry", ":", "# pyre-ignore[16]", "\n", "            ", "return", "cls", ".", "registry", "[", "from_type", "]", "\n", "", "for", "base", "in", "from_type", ".", "__bases__", ":", "\n", "            ", "converter", "=", "cls", ".", "_lookup_converter", "(", "base", ")", "\n", "if", "converter", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer._resize": [[59, 65], ["cv2.resize", "cv2.resize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.resize"], ["                ", "cls", ".", "_do_register", "(", "from_type", ",", "converter", ")", "\n", "return", "converter", "\n", "", "", "return", "None", "\n", "\n", "", "@", "classmethod", "\n", "def", "convert", "(", "cls", ",", "instance", ":", "Any", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer._check_image": [[66, 70], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.MatrixVisualizer._check_mask_matrix": [[71, 75], ["len", "len"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.RectangleVisualizer.__init__": [[81, 84], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "output_type_str", "=", "cls", ".", "dst_type", "\n", "", "raise", "KeyError", "(", "f\"Could not find converter from {instance_type} to {output_type_str}\"", ")", "\n", "", "return", "converter", "(", "instance", ",", "*", "args", ",", "**", "kwargs", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.RectangleVisualizer.visualize": [[85, 91], ["cv2.rectangle", "int", "int", "int", "int"], "methods", ["None"], ["\n", "\n", "", "", "IntTupleBox", "=", "Tuple", "[", "int", ",", "int", ",", "int", ",", "int", "]", "\n", "\n", "\n", "def", "make_int_box", "(", "box", ":", "torch", ".", "Tensor", ")", "->", "IntTupleBox", ":", "\n", "    ", "int_box", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.PointsVisualizer.__init__": [[97, 100], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.PointsVisualizer.visualize": [[101, 108], ["enumerate", "cv2.circle"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.TextVisualizer.__init__": [[115, 138], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.TextVisualizer.visualize": [[139, 166], ["base.TextVisualizer.get_text_size_wh", "tuple", "cv2.putText", "map", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.TextVisualizer.get_text_size_wh"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.TextVisualizer.get_text_size_wh": [[167, 172], ["cv2.getTextSize"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.CompoundVisualizer.__init__": [[175, 177], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.CompoundVisualizer.visualize": [[178, 188], ["enumerate", "len", "len", "len", "len", "visualizer.visualize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.base.CompoundVisualizer.__str__": [[189, 192], ["str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.DensePoseResultsVisualizerWithTexture.__init__": [[28, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "texture_atlas", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "texture_atlas", "=", "texture_atlas", "\n", "self", ".", "body_part_size", "=", "texture_atlas", ".", "shape", "[", "0", "]", "//", "6", "\n", "assert", "self", ".", "body_part_size", "==", "texture_atlas", ".", "shape", "[", "1", "]", "//", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.DensePoseResultsVisualizerWithTexture.visualize": [[33, 52], ["boxes_xywh.int().cpu().numpy.int().cpu().numpy.int().cpu().numpy", "densepose_results_textures.DensePoseResultsVisualizerWithTexture.get_texture", "enumerate", "torch.cat", "densepose_results_textures.DensePoseResultsVisualizerWithTexture.generate_image_with_texture", "boxes_xywh.int().cpu().numpy.int().cpu().numpy.int().cpu", "torch.cat.cpu().numpy", "result.uv.clamp", "boxes_xywh.int().cpu().numpy.int().cpu().numpy.int", "torch.cat.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.DensePoseResultsVisualizerWithTexture.get_texture", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.generate_image_with_texture"], ["", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "results_and_boxes_xywh", ":", "Tuple", "[", "Optional", "[", "List", "[", "DensePoseChartResult", "]", "]", ",", "Optional", "[", "Boxes", "]", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "densepose_result", ",", "boxes_xywh", "=", "results_and_boxes_xywh", "\n", "if", "densepose_result", "is", "None", "or", "boxes_xywh", "is", "None", ":", "\n", "            ", "return", "image_bgr", "\n", "\n", "", "boxes_xywh", "=", "boxes_xywh", ".", "int", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "texture_image", ",", "alpha", "=", "self", ".", "get_texture", "(", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "densepose_result", ")", ":", "\n", "            ", "iuv_array", "=", "torch", ".", "cat", "(", "(", "result", ".", "labels", "[", "None", "]", ",", "result", ".", "uv", ".", "clamp", "(", "0", ",", "1", ")", ")", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "boxes_xywh", "[", "i", "]", "\n", "bbox_image", "=", "image_bgr", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", "]", "\n", "image_bgr", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", "]", "=", "self", ".", "generate_image_with_texture", "(", "\n", "texture_image", ",", "alpha", ",", "bbox_image", ",", "iuv_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.DensePoseResultsVisualizerWithTexture.get_texture": [[53, 69], ["numpy.zeros", "range", "range", "numpy.zeros.sum"], "methods", ["None"], ["", "def", "get_texture", "(", "self", ")", ":", "\n", "        ", "N", "=", "self", ".", "body_part_size", "\n", "texture_image", "=", "np", ".", "zeros", "(", "[", "24", ",", "N", ",", "N", ",", "self", ".", "texture_atlas", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "6", ")", ":", "\n", "                ", "texture_image", "[", "(", "6", "*", "i", "+", "j", ")", ",", ":", ",", ":", ",", ":", "]", "=", "self", ".", "texture_atlas", "[", "\n", "N", "*", "j", ":", "N", "*", "(", "j", "+", "1", ")", ",", "N", "*", "i", ":", "N", "*", "(", "i", "+", "1", ")", ",", ":", "\n", "]", "\n", "\n", "", "", "if", "texture_image", ".", "shape", "[", "-", "1", "]", "==", "4", ":", "# Image with alpha channel", "\n", "            ", "alpha", "=", "texture_image", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", "/", "255.0", "\n", "texture_image", "=", "texture_image", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "texture_image", ".", "sum", "(", "axis", "=", "-", "1", ")", ">", "0", "\n", "\n", "", "return", "texture_image", ",", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.DensePoseResultsVisualizerWithTexture.generate_image_with_texture": [[70, 86], ["bbox_image_bgr.copy", "range", "bbox_image_bgr.copy.astype", "numpy.where", "numpy.expand_dims"], "methods", ["None"], ["", "def", "generate_image_with_texture", "(", "self", ",", "texture_image", ",", "alpha", ",", "bbox_image_bgr", ",", "iuv_array", ")", ":", "\n", "\n", "        ", "I", ",", "U", ",", "V", "=", "iuv_array", "\n", "generated_image_bgr", "=", "bbox_image_bgr", ".", "copy", "(", ")", "\n", "\n", "for", "PartInd", "in", "range", "(", "1", ",", "25", ")", ":", "\n", "            ", "x", ",", "y", "=", "np", ".", "where", "(", "I", "==", "PartInd", ")", "\n", "x_index", "=", "(", "U", "[", "x", ",", "y", "]", "*", "(", "self", ".", "body_part_size", "-", "1", ")", ")", ".", "astype", "(", "int", ")", "\n", "y_index", "=", "(", "(", "1", "-", "V", "[", "x", ",", "y", "]", ")", "*", "(", "self", ".", "body_part_size", "-", "1", ")", ")", ".", "astype", "(", "int", ")", "\n", "part_alpha", "=", "np", ".", "expand_dims", "(", "alpha", "[", "PartInd", "-", "1", ",", "y_index", ",", "x_index", "]", ",", "-", "1", ")", "\n", "generated_image_bgr", "[", "I", "==", "PartInd", "]", "=", "(", "\n", "generated_image_bgr", "[", "I", "==", "PartInd", "]", "*", "(", "1", "-", "part_alpha", ")", "\n", "+", "texture_image", "[", "PartInd", "-", "1", ",", "y_index", ",", "x_index", "]", "*", "part_alpha", "\n", ")", "\n", "\n", "", "return", "generated_image_bgr", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.get_texture_atlas": [[14, 19], ["cv2.imread", "detectron2.utils.file_io.PathManager.get_local_path"], "function", ["None"], ["def", "get_texture_atlas", "(", "path", ":", "Optional", "[", "str", "]", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "    ", "if", "path", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "cv2", ".", "imread", "(", "PathManager", ".", "get_local_path", "(", "path", ")", ",", "cv2", ".", "IMREAD_UNCHANGED", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.__init__": [[41, 63], ["base.MatrixVisualizer", "data.utils.get_class_to_mesh_name_mapping", "densepose.modeling.build_densepose_embedder", "torch.device", "densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.embedder().to", "densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.class_to_mesh_name.values", "densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.embedder.has_embeddings", "densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.embedder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.get_class_to_mesh_name_mapping", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_embedder", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.embedder.Embedder.has_embeddings"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ",", "\n", "inplace", "=", "True", ",", "\n", "cmap", "=", "cv2", ".", "COLORMAP_JET", ",", "\n", "alpha", "=", "0.7", ",", "\n", "device", "=", "\"cuda\"", ",", "\n", "default_class", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "mask_visualizer", "=", "MatrixVisualizer", "(", "\n", "inplace", "=", "inplace", ",", "cmap", "=", "cmap", ",", "val_scale", "=", "1.0", ",", "alpha", "=", "alpha", "\n", ")", "\n", "self", ".", "class_to_mesh_name", "=", "get_class_to_mesh_name_mapping", "(", "cfg", ")", "\n", "self", ".", "embedder", "=", "build_densepose_embedder", "(", "cfg", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "default_class", "=", "default_class", "\n", "\n", "self", ".", "mesh_vertex_embeddings", "=", "{", "\n", "mesh_name", ":", "self", ".", "embedder", "(", "mesh_name", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "mesh_name", "in", "self", ".", "class_to_mesh_name", ".", "values", "(", ")", "\n", "if", "self", ".", "embedder", ".", "has_embeddings", "(", "mesh_name", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.visualize": [[65, 96], ["densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.extract_and_check_outputs_and_boxes", "range", "bboxes_xywh[].int().tolist", "densepose.modeling.cse.utils.get_closest_vertices_mask_from_ES", "densepose_outputs_vertex.get_xyz_vertex_embedding", "mask.cpu().numpy().astype", "densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.mask_visualizer.visualize", "bboxes_xywh[].int", "mask.cpu().numpy", "mask.cpu", "embed_map[].clip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.extract_and_check_outputs_and_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.get_closest_vertices_mask_from_ES", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.get_xyz_vertex_embedding", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "outputs_boxes_xywh_classes", ":", "Tuple", "[", "\n", "Optional", "[", "DensePoseEmbeddingPredictorOutput", "]", ",", "Optional", "[", "Boxes", "]", ",", "Optional", "[", "List", "[", "int", "]", "]", "\n", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "if", "outputs_boxes_xywh_classes", "[", "0", "]", "is", "None", ":", "\n", "            ", "return", "image_bgr", "\n", "\n", "", "S", ",", "E", ",", "N", ",", "bboxes_xywh", ",", "pred_classes", "=", "self", ".", "extract_and_check_outputs_and_boxes", "(", "\n", "outputs_boxes_xywh_classes", "\n", ")", "\n", "\n", "for", "n", "in", "range", "(", "N", ")", ":", "\n", "            ", "x", ",", "y", ",", "w", ",", "h", "=", "bboxes_xywh", "[", "n", "]", ".", "int", "(", ")", ".", "tolist", "(", ")", "\n", "mesh_name", "=", "self", ".", "class_to_mesh_name", "[", "pred_classes", "[", "n", "]", "]", "\n", "closest_vertices", ",", "mask", "=", "get_closest_vertices_mask_from_ES", "(", "\n", "E", "[", "[", "n", "]", "]", ",", "\n", "S", "[", "[", "n", "]", "]", ",", "\n", "h", ",", "\n", "w", ",", "\n", "self", ".", "mesh_vertex_embeddings", "[", "mesh_name", "]", ",", "\n", "self", ".", "device", ",", "\n", ")", "\n", "embed_map", "=", "get_xyz_vertex_embedding", "(", "mesh_name", ",", "self", ".", "device", ")", "\n", "vis", "=", "(", "embed_map", "[", "closest_vertices", "]", ".", "clip", "(", "0", ",", "1", ")", "*", "255.0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "mask_numpy", "=", "mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "dtype", "=", "np", ".", "uint8", ")", "\n", "image_bgr", "=", "self", ".", "mask_visualizer", ".", "visualize", "(", "image_bgr", ",", "mask_numpy", ",", "vis", ",", "[", "x", ",", "y", ",", "w", ",", "h", "]", ")", "\n", "\n", "", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.extract_and_check_outputs_and_boxes": [[97, 129], ["isinstance", "S.size", "type", "E.size", "S.size", "E.size", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "extract_and_check_outputs_and_boxes", "(", "self", ",", "outputs_boxes_xywh_classes", ")", ":", "\n", "\n", "        ", "densepose_output", ",", "bboxes_xywh", ",", "pred_classes", "=", "outputs_boxes_xywh_classes", "\n", "\n", "if", "pred_classes", "is", "None", ":", "\n", "            ", "pred_classes", "=", "[", "self", ".", "default_class", "]", "*", "len", "(", "bboxes_xywh", ")", "\n", "\n", "", "assert", "isinstance", "(", "\n", "densepose_output", ",", "DensePoseEmbeddingPredictorOutput", "\n", ")", ",", "\"DensePoseEmbeddingPredictorOutput expected, {} encountered\"", ".", "format", "(", "\n", "type", "(", "densepose_output", ")", "\n", ")", "\n", "\n", "S", "=", "densepose_output", ".", "coarse_segm", "\n", "E", "=", "densepose_output", ".", "embedding", "\n", "N", "=", "S", ".", "size", "(", "0", ")", "\n", "assert", "N", "==", "E", ".", "size", "(", "\n", "0", "\n", ")", ",", "\"CSE coarse_segm {} and embeddings {}\"", "\" should have equal first dim size\"", ".", "format", "(", "\n", "S", ".", "size", "(", ")", ",", "E", ".", "size", "(", ")", "\n", ")", "\n", "assert", "N", "==", "len", "(", "\n", "bboxes_xywh", "\n", ")", ",", "\"number of bounding boxes {}\"", "\" should be equal to first dim size of outputs {}\"", ".", "format", "(", "\n", "len", "(", "bboxes_xywh", ")", ",", "N", "\n", ")", "\n", "assert", "N", "==", "len", "(", "pred_classes", ")", ",", "(", "\n", "\"number of predicted classes {}\"", "\n", "\" should be equal to first dim size of outputs {}\"", ".", "format", "(", "len", "(", "bboxes_xywh", ")", ",", "N", ")", "\n", ")", "\n", "\n", "return", "S", ",", "E", ",", "N", ",", "bboxes_xywh", ",", "pred_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.__init__": [[143, 171], ["densepose.modeling.build_densepose_embedder", "texture_atlases_dict.keys", "torch.device", "data.utils.get_class_to_mesh_name_mapping", "densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.embedder().to", "densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.class_to_mesh_name.values", "texture_atlases_dict[].sum", "densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.embedder"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.modeling.build.build_densepose_embedder", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tensormask.arch.TensorMask.device", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.utils.get_class_to_mesh_name_mapping", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ",", "\n", "texture_atlases_dict", ",", "\n", "device", "=", "\"cuda\"", ",", "\n", "default_class", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "embedder", "=", "build_densepose_embedder", "(", "cfg", ")", "\n", "\n", "self", ".", "texture_image_dict", "=", "{", "}", "\n", "self", ".", "alpha_dict", "=", "{", "}", "\n", "\n", "for", "mesh_name", "in", "texture_atlases_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "texture_atlases_dict", "[", "mesh_name", "]", ".", "shape", "[", "-", "1", "]", "==", "4", ":", "# Image with alpha channel", "\n", "                ", "self", ".", "alpha_dict", "[", "mesh_name", "]", "=", "texture_atlases_dict", "[", "mesh_name", "]", "[", ":", ",", ":", ",", "-", "1", "]", "/", "255.0", "\n", "self", ".", "texture_image_dict", "[", "mesh_name", "]", "=", "texture_atlases_dict", "[", "mesh_name", "]", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "alpha_dict", "[", "mesh_name", "]", "=", "texture_atlases_dict", "[", "mesh_name", "]", ".", "sum", "(", "axis", "=", "-", "1", ")", ">", "0", "\n", "self", ".", "texture_image_dict", "[", "mesh_name", "]", "=", "texture_atlases_dict", "[", "mesh_name", "]", "\n", "\n", "", "", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "class_to_mesh_name", "=", "get_class_to_mesh_name_mapping", "(", "cfg", ")", "\n", "self", ".", "default_class", "=", "default_class", "\n", "\n", "self", ".", "mesh_vertex_embeddings", "=", "{", "\n", "mesh_name", ":", "self", ".", "embedder", "(", "mesh_name", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "mesh_name", "in", "self", ".", "class_to_mesh_name", ".", "values", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.visualize": [[173, 216], ["image_bgr.copy", "densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.extract_and_check_outputs_and_boxes", "range", "structures.mesh.create_mesh", "bboxes_xywh[].int().cpu().numpy", "densepose.modeling.cse.utils.get_closest_vertices_mask_from_ES", "meshes[].texcoords[].permute", "uv_array.cpu().numpy().clip.cpu().numpy().clip.cpu().numpy().clip", "densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.generate_image_with_texture", "numpy.unique", "mask.cpu().numpy", "bboxes_xywh[].int().cpu", "uv_array.cpu().numpy().clip.cpu().numpy().clip.cpu().numpy", "mask.cpu", "bboxes_xywh[].int", "uv_array.cpu().numpy().clip.cpu().numpy().clip.cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsVertexVisualizer.extract_and_check_outputs_and_boxes", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.create_mesh", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.utils.get_closest_vertices_mask_from_ES", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.generate_image_with_texture"], ["", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "outputs_boxes_xywh_classes", ":", "Tuple", "[", "\n", "Optional", "[", "DensePoseEmbeddingPredictorOutput", "]", ",", "Optional", "[", "Boxes", "]", ",", "Optional", "[", "List", "[", "int", "]", "]", "\n", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "image_target_bgr", "=", "image_bgr", ".", "copy", "(", ")", "\n", "if", "outputs_boxes_xywh_classes", "[", "0", "]", "is", "None", ":", "\n", "            ", "return", "image_target_bgr", "\n", "\n", "", "S", ",", "E", ",", "N", ",", "bboxes_xywh", ",", "pred_classes", "=", "self", ".", "extract_and_check_outputs_and_boxes", "(", "\n", "outputs_boxes_xywh_classes", "\n", ")", "\n", "\n", "meshes", "=", "{", "\n", "p", ":", "create_mesh", "(", "self", ".", "class_to_mesh_name", "[", "p", "]", ",", "self", ".", "device", ")", "for", "p", "in", "np", ".", "unique", "(", "pred_classes", ")", "\n", "}", "\n", "\n", "for", "n", "in", "range", "(", "N", ")", ":", "\n", "            ", "x", ",", "y", ",", "w", ",", "h", "=", "bboxes_xywh", "[", "n", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "mesh_name", "=", "self", ".", "class_to_mesh_name", "[", "pred_classes", "[", "n", "]", "]", "\n", "closest_vertices", ",", "mask", "=", "get_closest_vertices_mask_from_ES", "(", "\n", "E", "[", "[", "n", "]", "]", ",", "\n", "S", "[", "[", "n", "]", "]", ",", "\n", "h", ",", "\n", "w", ",", "\n", "self", ".", "mesh_vertex_embeddings", "[", "mesh_name", "]", ",", "\n", "self", ".", "device", ",", "\n", ")", "\n", "uv_array", "=", "meshes", "[", "pred_classes", "[", "n", "]", "]", ".", "texcoords", "[", "closest_vertices", "]", ".", "permute", "(", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "uv_array", "=", "uv_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "clip", "(", "0", ",", "1", ")", "\n", "textured_image", "=", "self", ".", "generate_image_with_texture", "(", "\n", "image_target_bgr", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", "]", ",", "\n", "uv_array", ",", "\n", "mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "self", ".", "class_to_mesh_name", "[", "pred_classes", "[", "n", "]", "]", ",", "\n", ")", "\n", "if", "textured_image", "is", "None", ":", "\n", "                ", "continue", "\n", "", "image_target_bgr", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", "]", "=", "textured_image", "\n", "\n", "", "return", "image_target_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.generate_image_with_texture": [[217, 230], ["densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.alpha_dict.get", "densepose_outputs_vertex.DensePoseOutputsTextureVisualizer.texture_image_dict.get", "numpy.expand_dims", "bbox_image_bgr.copy", "bbox_image_bgr.copy.astype"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "def", "generate_image_with_texture", "(", "self", ",", "bbox_image_bgr", ",", "uv_array", ",", "mask", ",", "mesh_name", ")", ":", "\n", "        ", "alpha", "=", "self", ".", "alpha_dict", ".", "get", "(", "mesh_name", ")", "\n", "texture_image", "=", "self", ".", "texture_image_dict", ".", "get", "(", "mesh_name", ")", "\n", "if", "alpha", "is", "None", "or", "texture_image", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "U", ",", "V", "=", "uv_array", "\n", "x_index", "=", "(", "U", "*", "texture_image", ".", "shape", "[", "1", "]", ")", ".", "astype", "(", "int", ")", "\n", "y_index", "=", "(", "V", "*", "texture_image", ".", "shape", "[", "0", "]", ")", ".", "astype", "(", "int", ")", "\n", "local_texture", "=", "texture_image", "[", "y_index", ",", "x_index", "]", "[", "mask", "]", "\n", "local_alpha", "=", "np", ".", "expand_dims", "(", "alpha", "[", "y_index", ",", "x_index", "]", "[", "mask", "]", ",", "-", "1", ")", "\n", "output_image", "=", "bbox_image_bgr", ".", "copy", "(", ")", "\n", "output_image", "[", "mask", "]", "=", "output_image", "[", "mask", "]", "*", "(", "1", "-", "local_alpha", ")", "+", "local_texture", "*", "local_alpha", "\n", "return", "output_image", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.get_xyz_vertex_embedding": [[21, 38], ["functools.lru_cache", "detectron2.utils.file_io.PathManager.get_local_path", "numpy.load", "mesh.vertices.sum.min", "mesh.vertices.sum.max", "structures.mesh.create_mesh", "structures.mesh.create_mesh.vertices.sum", "mesh.vertices.sum.min", "mesh.vertices.sum.max", "torch.tensor().float", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.cse.vertex_direct_embedder.VertexDirectEmbedder.load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.mesh.create_mesh"], ["@", "lru_cache", "(", ")", "\n", "def", "get_xyz_vertex_embedding", "(", "mesh_name", ":", "str", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "    ", "if", "mesh_name", "==", "\"smpl_27554\"", ":", "\n", "        ", "embed_path", "=", "PathManager", ".", "get_local_path", "(", "\n", "\"https://dl.fbaipublicfiles.com/densepose/data/cse/mds_d=256.npy\"", "\n", ")", "\n", "embed_map", ",", "_", "=", "np", ".", "load", "(", "embed_path", ",", "allow_pickle", "=", "True", ")", "\n", "embed_map", "=", "torch", ".", "tensor", "(", "embed_map", ")", ".", "float", "(", ")", "[", ":", ",", "0", "]", "\n", "embed_map", "-=", "embed_map", ".", "min", "(", ")", "\n", "embed_map", "/=", "embed_map", ".", "max", "(", ")", "\n", "", "else", ":", "\n", "        ", "mesh", "=", "create_mesh", "(", "mesh_name", ",", "device", ")", "\n", "embed_map", "=", "mesh", ".", "vertices", ".", "sum", "(", "dim", "=", "1", ")", "\n", "embed_map", "-=", "embed_map", ".", "min", "(", ")", "\n", "embed_map", "/=", "embed_map", ".", "max", "(", ")", "\n", "embed_map", "=", "embed_map", "**", "2", "\n", "", "return", "embed_map", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_vertex.get_texture_atlases": [[131, 140], ["json.loads", "densepose_results_textures.get_texture_atlas", "json.loads.items"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results_textures.get_texture_atlas"], ["", "", "def", "get_texture_atlases", "(", "json_str", ":", "Optional", "[", "str", "]", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "np", ".", "ndarray", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    json_str is a JSON string representing a mesh_name -> texture_atlas_path dictionary\n    \"\"\"", "\n", "if", "json_str", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "paths", "=", "json", ".", "loads", "(", "json_str", ")", "\n", "return", "{", "mesh_name", ":", "get_texture_atlas", "(", "path", ")", "for", "mesh_name", ",", "path", "in", "paths", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_iuv.DensePoseOutputsVisualizer.__init__": [[13, 25], ["base.MatrixVisualizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "to_visualize", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "assert", "to_visualize", "in", "\"IUV\"", ",", "\"can only visualize IUV\"", "\n", "self", ".", "to_visualize", "=", "to_visualize", "\n", "\n", "if", "self", ".", "to_visualize", "==", "\"I\"", ":", "\n", "            ", "val_scale", "=", "255.0", "/", "DensePoseDataRelative", ".", "N_PART_LABELS", "\n", "", "else", ":", "\n", "            ", "val_scale", "=", "1.0", "\n", "", "self", ".", "mask_visualizer", "=", "MatrixVisualizer", "(", "\n", "inplace", "=", "inplace", ",", "cmap", "=", "cmap", ",", "val_scale", "=", "val_scale", ",", "alpha", "=", "alpha", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_iuv.DensePoseOutputsVisualizer.visualize": [[27, 86], ["isinstance", "S.size", "range", "type", "I.size", "S.size", "I.size", "U.size", "S.size", "U.size", "V.size", "S.size", "V.size", "len", "len", "S[].argmax", "In.cpu().numpy().astype", "numpy.zeros", "densepose_outputs_iuv.DensePoseOutputsVisualizer.mask_visualizer.visualize", "I[].argmax", "In.cpu().numpy", "[].cpu().numpy().astype", "numpy.zeros", "range", "In.cpu", "[].cpu().numpy", "[].clip", "[].cpu"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "dp_output_with_bboxes", ":", "Tuple", "[", "Optional", "[", "DensePoseChartPredictorOutput", "]", ",", "Optional", "[", "Boxes", "]", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "densepose_output", ",", "bboxes_xywh", "=", "dp_output_with_bboxes", "\n", "if", "densepose_output", "is", "None", "or", "bboxes_xywh", "is", "None", ":", "\n", "            ", "return", "image_bgr", "\n", "\n", "", "assert", "isinstance", "(", "\n", "densepose_output", ",", "DensePoseChartPredictorOutput", "\n", ")", ",", "\"DensePoseChartPredictorOutput expected, {} encountered\"", ".", "format", "(", "type", "(", "densepose_output", ")", ")", "\n", "\n", "S", "=", "densepose_output", ".", "coarse_segm", "\n", "I", "=", "densepose_output", ".", "fine_segm", "# noqa", "\n", "U", "=", "densepose_output", ".", "u", "\n", "V", "=", "densepose_output", ".", "v", "\n", "N", "=", "S", ".", "size", "(", "0", ")", "\n", "assert", "N", "==", "I", ".", "size", "(", "\n", "0", "\n", ")", ",", "\"densepose outputs S {} and I {}\"", "\" should have equal first dim size\"", ".", "format", "(", "\n", "S", ".", "size", "(", ")", ",", "I", ".", "size", "(", ")", "\n", ")", "\n", "assert", "N", "==", "U", ".", "size", "(", "\n", "0", "\n", ")", ",", "\"densepose outputs S {} and U {}\"", "\" should have equal first dim size\"", ".", "format", "(", "\n", "S", ".", "size", "(", ")", ",", "U", ".", "size", "(", ")", "\n", ")", "\n", "assert", "N", "==", "V", ".", "size", "(", "\n", "0", "\n", ")", ",", "\"densepose outputs S {} and V {}\"", "\" should have equal first dim size\"", ".", "format", "(", "\n", "S", ".", "size", "(", ")", ",", "V", ".", "size", "(", ")", "\n", ")", "\n", "assert", "N", "==", "len", "(", "\n", "bboxes_xywh", "\n", ")", ",", "\"number of bounding boxes {}\"", "\" should be equal to first dim size of outputs {}\"", ".", "format", "(", "\n", "len", "(", "bboxes_xywh", ")", ",", "N", "\n", ")", "\n", "for", "n", "in", "range", "(", "N", ")", ":", "\n", "            ", "Sn", "=", "S", "[", "n", "]", ".", "argmax", "(", "dim", "=", "0", ")", "\n", "In", "=", "I", "[", "n", "]", ".", "argmax", "(", "dim", "=", "0", ")", "*", "(", "Sn", ">", "0", ")", ".", "long", "(", ")", "\n", "segmentation", "=", "In", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "segmentation", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "mask", "[", "segmentation", ">", "0", "]", "=", "1", "\n", "bbox_xywh", "=", "bboxes_xywh", "[", "n", "]", "\n", "\n", "if", "self", ".", "to_visualize", "==", "\"I\"", ":", "\n", "                ", "vis", "=", "segmentation", "\n", "", "elif", "self", ".", "to_visualize", "in", "\"UV\"", ":", "\n", "                ", "U_or_Vn", "=", "{", "\"U\"", ":", "U", ",", "\"V\"", ":", "V", "}", "[", "self", ".", "to_visualize", "]", "[", "n", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "vis", "=", "np", ".", "zeros", "(", "segmentation", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "partId", "in", "range", "(", "U_or_Vn", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "vis", "[", "segmentation", "==", "partId", "]", "=", "(", "\n", "U_or_Vn", "[", "partId", "]", "[", "segmentation", "==", "partId", "]", ".", "clip", "(", "0", ",", "1", ")", "*", "255", "\n", ")", "\n", "\n", "", "", "image_bgr", "=", "self", ".", "mask_visualizer", ".", "visualize", "(", "image_bgr", ",", "mask", ",", "vis", ",", "bbox_xywh", ")", "\n", "\n", "", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_iuv.DensePoseOutputsUVisualizer.__init__": [[89, 91], ["densepose_outputs_iuv.DensePoseOutputsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "inplace", "=", "inplace", ",", "cmap", "=", "cmap", ",", "alpha", "=", "alpha", ",", "to_visualize", "=", "\"U\"", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_iuv.DensePoseOutputsVVisualizer.__init__": [[94, 96], ["densepose_outputs_iuv.DensePoseOutputsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "inplace", "=", "inplace", ",", "cmap", "=", "cmap", ",", "alpha", "=", "alpha", ",", "to_visualize", "=", "\"V\"", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_outputs_iuv.DensePoseOutputsFineSegmentationVisualizer.__init__": [[99, 101], ["densepose_outputs_iuv.DensePoseOutputsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "inplace", "=", "inplace", ",", "cmap", "=", "cmap", ",", "alpha", "=", "alpha", ",", "to_visualize", "=", "\"I\"", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.BoundingBoxExtractor.__call__": [[65, 68], ["extractor.extract_boxes_xywh_from_instances"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_boxes_xywh_from_instances"], ["def", "__call__", "(", "self", ",", "instances", ":", "Instances", ")", ":", "\n", "        ", "boxes_xywh", "=", "extract_boxes_xywh_from_instances", "(", "instances", ")", "\n", "return", "boxes_xywh", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoredBoundingBoxExtractor.__call__": [[75, 84], ["extractor.extract_scores_from_instances", "extractor.extract_boxes_xywh_from_instances"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_scores_from_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_boxes_xywh_from_instances"], ["def", "__call__", "(", "self", ",", "instances", ":", "Instances", ",", "select", "=", "None", ")", ":", "\n", "        ", "scores", "=", "extract_scores_from_instances", "(", "instances", ")", "\n", "boxes_xywh", "=", "extract_boxes_xywh_from_instances", "(", "instances", ")", "\n", "if", "(", "scores", "is", "None", ")", "or", "(", "boxes_xywh", "is", "None", ")", ":", "\n", "            ", "return", "(", "boxes_xywh", ",", "scores", ")", "\n", "", "if", "select", "is", "not", "None", ":", "\n", "            ", "scores", "=", "scores", "[", "select", "]", "\n", "boxes_xywh", "=", "boxes_xywh", "[", "select", "]", "\n", "", "return", "(", "boxes_xywh", ",", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.DensePoseResultExtractor.__call__": [[91, 106], ["instances.has", "instances.has", "extractor.extract_boxes_xywh_from_instances", "densepose.converters.ToChartResultConverterWithConfidences", "densepose.converters.ToChartResultConverterWithConfidences.convert", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_boxes_xywh_from_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["def", "__call__", "(", "\n", "self", ",", "instances", ":", "Instances", ",", "select", "=", "None", "\n", ")", "->", "Tuple", "[", "Optional", "[", "DensePoseChartResultsWithConfidences", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "if", "instances", ".", "has", "(", "\"pred_densepose\"", ")", "and", "instances", ".", "has", "(", "\"pred_boxes\"", ")", ":", "\n", "            ", "dpout", "=", "instances", ".", "pred_densepose", "\n", "boxes_xyxy", "=", "instances", ".", "pred_boxes", "\n", "boxes_xywh", "=", "extract_boxes_xywh_from_instances", "(", "instances", ")", "\n", "if", "select", "is", "not", "None", ":", "\n", "                ", "dpout", "=", "dpout", "[", "select", "]", "\n", "boxes_xyxy", "=", "boxes_xyxy", "[", "select", "]", "\n", "", "converter", "=", "ToChartResultConverterWithConfidences", "(", ")", "\n", "results", "=", "[", "converter", ".", "convert", "(", "dpout", "[", "i", "]", ",", "boxes_xyxy", "[", "[", "i", "]", "]", ")", "for", "i", "in", "range", "(", "len", "(", "dpout", ")", ")", "]", "\n", "return", "results", ",", "boxes_xywh", "\n", "", "else", ":", "\n", "            ", "return", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.DensePoseOutputsExtractor.__call__": [[113, 139], ["extractor.extract_boxes_xywh_from_instances", "instances.has", "instances.pred_classes.tolist", "instances.has", "instances.has"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_boxes_xywh_from_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["def", "__call__", "(", "\n", "self", ",", "\n", "instances", ":", "Instances", ",", "\n", "select", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "\n", "Optional", "[", "DensePoseEmbeddingPredictorOutput", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "List", "[", "int", "]", "]", "\n", "]", ":", "\n", "        ", "if", "not", "(", "instances", ".", "has", "(", "\"pred_densepose\"", ")", "and", "instances", ".", "has", "(", "\"pred_boxes\"", ")", ")", ":", "\n", "            ", "return", "None", ",", "None", ",", "None", "\n", "\n", "", "dpout", "=", "instances", ".", "pred_densepose", "\n", "boxes_xyxy", "=", "instances", ".", "pred_boxes", "\n", "boxes_xywh", "=", "extract_boxes_xywh_from_instances", "(", "instances", ")", "\n", "\n", "if", "instances", ".", "has", "(", "\"pred_classes\"", ")", ":", "\n", "            ", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "classes", "=", "None", "\n", "\n", "", "if", "select", "is", "not", "None", ":", "\n", "            ", "dpout", "=", "dpout", "[", "select", "]", "\n", "boxes_xyxy", "=", "boxes_xyxy", "[", "select", "]", "\n", "if", "classes", "is", "not", "None", ":", "\n", "                ", "classes", "=", "classes", "[", "select", "]", "\n", "\n", "", "", "return", "dpout", ",", "boxes_xywh", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.CompoundExtractor.__init__": [[146, 148], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "extractors", ")", ":", "\n", "        ", "self", ".", "extractors", "=", "extractors", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.CompoundExtractor.__call__": [[149, 155], ["extractor", "datas.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "instances", ":", "Instances", ",", "select", "=", "None", ")", ":", "\n", "        ", "datas", "=", "[", "]", "\n", "for", "extractor", "in", "self", ".", "extractors", ":", "\n", "            ", "data", "=", "extractor", "(", "instances", ",", "select", ")", "\n", "datas", ".", "append", "(", "data", ")", "\n", "", "return", "datas", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.NmsFilteredExtractor.__init__": [[162, 165], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "extractor", ",", "iou_threshold", ")", ":", "\n", "        ", "self", ".", "extractor", "=", "extractor", "\n", "self", ".", "iou_threshold", "=", "iou_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.NmsFilteredExtractor.__call__": [[166, 181], ["extractor.extract_scores_from_instances", "extractor.extract_boxes_xywh_from_instances", "detectron2.layers.nms.batched_nms().squeeze", "torch.zeros", "extractor.NmsFilteredExtractor.extractor", "len", "detectron2.layers.nms.batched_nms", "torch.zeros", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_scores_from_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_boxes_xywh_from_instances", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms"], ["", "def", "__call__", "(", "self", ",", "instances", ":", "Instances", ",", "select", "=", "None", ")", ":", "\n", "        ", "scores", "=", "extract_scores_from_instances", "(", "instances", ")", "\n", "boxes_xywh", "=", "extract_boxes_xywh_from_instances", "(", "instances", ")", "\n", "if", "boxes_xywh", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "select_local_idx", "=", "batched_nms", "(", "\n", "boxes_xywh", ",", "\n", "scores", ",", "\n", "torch", ".", "zeros", "(", "len", "(", "scores", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "iou_threshold", "=", "self", ".", "iou_threshold", ",", "\n", ")", ".", "squeeze", "(", ")", "\n", "select_local", "=", "torch", ".", "zeros", "(", "len", "(", "boxes_xywh", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "boxes_xywh", ".", "device", ")", "\n", "select_local", "[", "select_local_idx", "]", "=", "True", "\n", "select", "=", "select_local", "if", "select", "is", "None", "else", "(", "select", "&", "select_local", ")", "\n", "return", "self", ".", "extractor", "(", "instances", ",", "select", "=", "select", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoreThresholdedExtractor.__init__": [[188, 191], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "extractor", ",", "min_score", ")", ":", "\n", "        ", "self", ".", "extractor", "=", "extractor", "\n", "self", ".", "min_score", "=", "min_score", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.ScoreThresholdedExtractor.__call__": [[192, 200], ["extractor.extract_scores_from_instances", "extractor.ScoreThresholdedExtractor.extractor"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_scores_from_instances"], ["", "def", "__call__", "(", "self", ",", "instances", ":", "Instances", ",", "select", "=", "None", ")", ":", "\n", "        ", "scores", "=", "extract_scores_from_instances", "(", "instances", ")", "\n", "if", "scores", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "select_local", "=", "scores", ">", "self", ".", "min_score", "\n", "select", "=", "select_local", "if", "select", "is", "None", "else", "(", "select", "&", "select_local", ")", "\n", "data", "=", "self", ".", "extractor", "(", "instances", ",", "select", "=", "select", ")", "\n", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_scores_from_instances": [[24, 28], ["instances.has"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has"], ["def", "extract_scores_from_instances", "(", "instances", ":", "Instances", ",", "select", "=", "None", ")", ":", "\n", "    ", "if", "instances", ".", "has", "(", "\"scores\"", ")", ":", "\n", "        ", "return", "instances", ".", "scores", "if", "select", "is", "None", "else", "instances", ".", "scores", "[", "select", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.extract_boxes_xywh_from_instances": [[30, 37], ["instances.has", "instances.pred_boxes.tensor.clone"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.c10.InstancesList.has", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "def", "extract_boxes_xywh_from_instances", "(", "instances", ":", "Instances", ",", "select", "=", "None", ")", ":", "\n", "    ", "if", "instances", ".", "has", "(", "\"pred_boxes\"", ")", ":", "\n", "        ", "boxes_xywh", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "clone", "(", ")", "\n", "boxes_xywh", "[", ":", ",", "2", "]", "-=", "boxes_xywh", "[", ":", ",", "0", "]", "\n", "boxes_xywh", "[", ":", ",", "3", "]", "-=", "boxes_xywh", "[", ":", ",", "1", "]", "\n", "return", "boxes_xywh", "if", "select", "is", "None", "else", "boxes_xywh", "[", "select", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.create_extractor": [[39, 58], ["isinstance", "extractor.CompoundExtractor", "isinstance", "extractor.create_extractor", "extractor.DensePoseResultExtractor", "isinstance", "extractor.CompoundExtractor", "isinstance", "isinstance", "extractor.DensePoseOutputsExtractor", "logging.getLogger", "logging.getLogger.error"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.extractor.create_extractor"], ["", "def", "create_extractor", "(", "visualizer", ":", "object", ")", ":", "\n", "    ", "\"\"\"\n    Create an extractor for the provided visualizer\n    \"\"\"", "\n", "if", "isinstance", "(", "visualizer", ",", "CompoundVisualizer", ")", ":", "\n", "        ", "extractors", "=", "[", "create_extractor", "(", "v", ")", "for", "v", "in", "visualizer", ".", "visualizers", "]", "\n", "return", "CompoundExtractor", "(", "extractors", ")", "\n", "", "elif", "isinstance", "(", "visualizer", ",", "DensePoseResultsVisualizer", ")", ":", "\n", "        ", "return", "DensePoseResultExtractor", "(", ")", "\n", "", "elif", "isinstance", "(", "visualizer", ",", "ScoredBoundingBoxVisualizer", ")", ":", "\n", "        ", "return", "CompoundExtractor", "(", "[", "extract_boxes_xywh_from_instances", ",", "extract_scores_from_instances", "]", ")", "\n", "", "elif", "isinstance", "(", "visualizer", ",", "BoundingBoxVisualizer", ")", ":", "\n", "        ", "return", "extract_boxes_xywh_from_instances", "\n", "", "elif", "isinstance", "(", "visualizer", ",", "DensePoseOutputsVertexVisualizer", ")", ":", "\n", "        ", "return", "DensePoseOutputsExtractor", "(", ")", "\n", "", "else", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "error", "(", "f\"Could not create extractor for {visualizer}\"", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.bounding_box.BoundingBoxVisualizer.__init__": [[6, 8], ["base.RectangleVisualizer"], "methods", ["None"], ["FLIP_TOP_BOTTOM", "=", "1", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.bounding_box.BoundingBoxVisualizer.visualize": [[9, 13], ["bounding_box.BoundingBoxVisualizer.rectangle_visualizer.visualize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize"], ["class", "BoxList", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.bounding_box.ScoredBoundingBoxVisualizer.__init__": [[16, 23], ["base.RectangleVisualizer", "base.TextVisualizer"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "bbox", ",", "image_size", ",", "mode", "=", "\"xyxy\"", ")", ":", "\n", "        ", "device", "=", "bbox", ".", "device", "if", "isinstance", "(", "bbox", ",", "torch", ".", "Tensor", ")", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "bbox", "=", "torch", ".", "as_tensor", "(", "bbox", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "if", "bbox", ".", "ndimension", "(", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.bounding_box.ScoredBoundingBoxVisualizer.visualize": [[24, 38], ["enumerate", "len", "len", "len", "len", "bounding_box.ScoredBoundingBoxVisualizer.visualizer_bbox.visualize", "bounding_box.ScoredBoundingBoxVisualizer.visualizer_score.visualize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize"], ["\"bbox should have 2 dimensions, got {}\"", ".", "format", "(", "bbox", ".", "ndimension", "(", ")", ")", "\n", ")", "\n", "", "if", "bbox", ".", "size", "(", "-", "1", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"last dimension of bbox should have a \"", "\n", "\"size of 4, got {}\"", ".", "format", "(", "bbox", ".", "size", "(", "-", "1", ")", ")", "\n", ")", "\n", "", "if", "mode", "not", "in", "(", "\"xyxy\"", ",", "\"xywh\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode should be 'xyxy' or 'xywh'\"", ")", "\n", "\n", "", "self", ".", "bbox", "=", "bbox", "\n", "self", ".", "size", "=", "image_size", "# (image_width, image_height)", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "extra_fields", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.visualize": [[15, 33], ["boxes_xywh.cpu().numpy.cpu().numpy.cpu().numpy", "densepose_results.DensePoseResultsVisualizer.create_visualization_context", "enumerate", "densepose_results.DensePoseResultsVisualizer.context_to_image_bgr", "torch.cat().type", "densepose_results.DensePoseResultsVisualizer.visualize_iuv_arr", "boxes_xywh.cpu().numpy.cpu().numpy.cpu", "torch.cat().type.cpu().numpy", "torch.cat", "torch.cat().type.cpu", "result.labels[].type"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsMplContourVisualizer.create_visualization_context", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsMplContourVisualizer.context_to_image_bgr", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer.visualize_iuv_arr", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["    ", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "results_and_boxes_xywh", ":", "Tuple", "[", "Optional", "[", "List", "[", "DensePoseChartResult", "]", "]", ",", "Optional", "[", "Boxes", "]", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "densepose_result", ",", "boxes_xywh", "=", "results_and_boxes_xywh", "\n", "if", "densepose_result", "is", "None", "or", "boxes_xywh", "is", "None", ":", "\n", "            ", "return", "image_bgr", "\n", "\n", "", "boxes_xywh", "=", "boxes_xywh", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "context", "=", "self", ".", "create_visualization_context", "(", "image_bgr", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "densepose_result", ")", ":", "\n", "            ", "iuv_array", "=", "torch", ".", "cat", "(", "\n", "(", "result", ".", "labels", "[", "None", "]", ".", "type", "(", "torch", ".", "float32", ")", ",", "result", ".", "uv", "*", "255.0", ")", "\n", ")", ".", "type", "(", "torch", ".", "uint8", ")", "\n", "self", ".", "visualize_iuv_arr", "(", "context", ",", "iuv_array", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "boxes_xywh", "[", "i", "]", ")", "\n", "", "image_bgr", "=", "self", ".", "context_to_image_bgr", "(", "context", ")", "\n", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.create_visualization_context": [[34, 36], ["None"], "methods", ["None"], ["", "def", "create_visualization_context", "(", "self", ",", "image_bgr", ":", "Image", ")", ":", "\n", "        ", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.visualize_iuv_arr": [[37, 39], ["None"], "methods", ["None"], ["", "def", "visualize_iuv_arr", "(", "self", ",", "context", ",", "iuv_arr", ":", "np", ".", "ndarray", ",", "bbox_xywh", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.context_to_image_bgr": [[40, 42], ["None"], "methods", ["None"], ["", "def", "context_to_image_bgr", "(", "self", ",", "context", ")", ":", "\n", "        ", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.get_image_bgr_from_context": [[43, 45], ["None"], "methods", ["None"], ["", "def", "get_image_bgr_from_context", "(", "self", ",", "context", ")", ":", "\n", "        ", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseMaskedColormapResultsVisualizer.__init__": [[48, 63], ["base.MatrixVisualizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_extractor", ",", "\n", "segm_extractor", ",", "\n", "inplace", "=", "True", ",", "\n", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "\n", "alpha", "=", "0.7", ",", "\n", "val_scale", "=", "1.0", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "mask_visualizer", "=", "MatrixVisualizer", "(", "\n", "inplace", "=", "inplace", ",", "cmap", "=", "cmap", ",", "val_scale", "=", "val_scale", ",", "alpha", "=", "alpha", "\n", ")", "\n", "self", ".", "data_extractor", "=", "data_extractor", "\n", "self", ".", "segm_extractor", "=", "segm_extractor", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseMaskedColormapResultsVisualizer.context_to_image_bgr": [[64, 66], ["None"], "methods", ["None"], ["", "def", "context_to_image_bgr", "(", "self", ",", "context", ")", ":", "\n", "        ", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseMaskedColormapResultsVisualizer.visualize_iuv_arr": [[67, 74], ["densepose_results.DensePoseMaskedColormapResultsVisualizer.get_image_bgr_from_context", "densepose_results.DensePoseMaskedColormapResultsVisualizer.data_extractor", "densepose_results.DensePoseMaskedColormapResultsVisualizer.segm_extractor", "numpy.zeros", "densepose_results.DensePoseMaskedColormapResultsVisualizer.mask_visualizer.visualize"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.get_image_bgr_from_context", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize"], ["", "def", "visualize_iuv_arr", "(", "self", ",", "context", ",", "iuv_arr", ":", "np", ".", "ndarray", ",", "bbox_xywh", ")", "->", "None", ":", "\n", "        ", "image_bgr", "=", "self", ".", "get_image_bgr_from_context", "(", "context", ")", "\n", "matrix", "=", "self", ".", "data_extractor", "(", "iuv_arr", ")", "\n", "segm", "=", "self", ".", "segm_extractor", "(", "iuv_arr", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "matrix", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "mask", "[", "segm", ">", "0", "]", "=", "1", "\n", "image_bgr", "=", "self", ".", "mask_visualizer", ".", "visualize", "(", "image_bgr", ",", "mask", ",", "matrix", ",", "bbox_xywh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsMplContourVisualizer.__init__": [[89, 92], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "levels", "=", "10", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "levels", "=", "levels", "\n", "self", ".", "plot_args", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsMplContourVisualizer.create_visualization_context": [[93, 111], ["plt.figure", "plt.axes", "plt.axis", "FigureCanvas", "plt.imshow", "float", "float"], "methods", ["None"], ["", "def", "create_visualization_context", "(", "self", ",", "image_bgr", ":", "Image", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "from", "matplotlib", ".", "backends", ".", "backend_agg", "import", "FigureCanvasAgg", "as", "FigureCanvas", "\n", "\n", "context", "=", "{", "}", "\n", "context", "[", "\"image_bgr\"", "]", "=", "image_bgr", "\n", "dpi", "=", "100", "\n", "height_inches", "=", "float", "(", "image_bgr", ".", "shape", "[", "0", "]", ")", "/", "dpi", "\n", "width_inches", "=", "float", "(", "image_bgr", ".", "shape", "[", "1", "]", ")", "/", "dpi", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "width_inches", ",", "height_inches", ")", ",", "dpi", "=", "dpi", ")", "\n", "plt", ".", "axes", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ")", "\n", "plt", ".", "axis", "(", "\"off\"", ")", "\n", "context", "[", "\"fig\"", "]", "=", "fig", "\n", "canvas", "=", "FigureCanvas", "(", "fig", ")", "\n", "context", "[", "\"canvas\"", "]", "=", "canvas", "\n", "extent", "=", "(", "0", ",", "image_bgr", ".", "shape", "[", "1", "]", ",", "image_bgr", ".", "shape", "[", "0", "]", ",", "0", ")", "\n", "plt", ".", "imshow", "(", "image_bgr", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ",", "extent", "=", "extent", ")", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsMplContourVisualizer.context_to_image_bgr": [[112, 121], ["map", "canvas.draw", "numpy.fromstring", "numpy.fromstring.reshape", "image_rgb[].copy", "canvas.tostring_rgb", "fig.get_size_inches", "fig.get_dpi"], "methods", ["None"], ["", "def", "context_to_image_bgr", "(", "self", ",", "context", ")", ":", "\n", "        ", "fig", "=", "context", "[", "\"fig\"", "]", "\n", "w", ",", "h", "=", "map", "(", "int", ",", "fig", ".", "get_size_inches", "(", ")", "*", "fig", ".", "get_dpi", "(", ")", ")", "\n", "canvas", "=", "context", "[", "\"canvas\"", "]", "\n", "canvas", ".", "draw", "(", ")", "\n", "image_1d", "=", "np", ".", "fromstring", "(", "canvas", ".", "tostring_rgb", "(", ")", ",", "dtype", "=", "\"uint8\"", ")", "\n", "image_rgb", "=", "image_1d", ".", "reshape", "(", "h", ",", "w", ",", "3", ")", "\n", "image_bgr", "=", "image_rgb", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "copy", "(", ")", "\n", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsMplContourVisualizer.visualize_iuv_arr": [[122, 135], ["plt.contour", "plt.contour", "_extract_u_from_iuvarr().astype", "_extract_v_from_iuvarr().astype", "densepose_results._extract_u_from_iuvarr", "densepose_results._extract_v_from_iuvarr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_u_from_iuvarr", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_v_from_iuvarr"], ["", "def", "visualize_iuv_arr", "(", "self", ",", "context", ",", "iuv_arr", ":", "np", ".", "ndarray", ",", "bbox_xywh", ":", "Boxes", ")", "->", "None", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "u", "=", "_extract_u_from_iuvarr", "(", "iuv_arr", ")", ".", "astype", "(", "float", ")", "/", "255.0", "\n", "v", "=", "_extract_v_from_iuvarr", "(", "iuv_arr", ")", ".", "astype", "(", "float", ")", "/", "255.0", "\n", "extent", "=", "(", "\n", "bbox_xywh", "[", "0", "]", ",", "\n", "bbox_xywh", "[", "0", "]", "+", "bbox_xywh", "[", "2", "]", ",", "\n", "bbox_xywh", "[", "1", "]", ",", "\n", "bbox_xywh", "[", "1", "]", "+", "bbox_xywh", "[", "3", "]", ",", "\n", ")", "\n", "plt", ".", "contour", "(", "u", ",", "self", ".", "levels", ",", "extent", "=", "extent", ",", "**", "self", ".", "plot_args", ")", "\n", "plt", ".", "contour", "(", "v", ",", "self", ".", "levels", ",", "extent", "=", "extent", ",", "**", "self", ".", "plot_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer.__init__": [[142, 157], ["isinstance", "cv2.applyColorMap", "numpy.linspace", "len", "int", "img_color_bgr.ravel"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "levels", "=", "10", ",", "**", "kwargs", ")", ":", "\n", "# TODO: colormap is hardcoded", "\n", "        ", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", "\n", "if", "isinstance", "(", "levels", ",", "int", ")", ":", "\n", "            ", "self", ".", "levels", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "levels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "levels", "=", "levels", "\n", "", "if", "\"linewidths\"", "in", "kwargs", ":", "\n", "            ", "self", ".", "linewidths", "=", "kwargs", "[", "\"linewidths\"", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "linewidths", "=", "[", "1", "]", "*", "len", "(", "self", ".", "levels", ")", "\n", "", "self", ".", "plot_args", "=", "kwargs", "\n", "img_colors_bgr", "=", "cv2", ".", "applyColorMap", "(", "(", "self", ".", "levels", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", ",", "cmap", ")", "\n", "self", ".", "level_colors_bgr", "=", "[", "\n", "[", "int", "(", "v", ")", "for", "v", "in", "img_color_bgr", ".", "ravel", "(", ")", "]", "for", "img_color_bgr", "in", "img_colors_bgr", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer.visualize_iuv_arr": [[159, 166], ["densepose_results.DensePoseResultsCustomContourVisualizer.get_image_bgr_from_context", "densepose_results._extract_i_from_iuvarr", "densepose_results.DensePoseResultsCustomContourVisualizer._contours", "densepose_results.DensePoseResultsCustomContourVisualizer._contours", "_extract_u_from_iuvarr().astype", "_extract_v_from_iuvarr().astype", "densepose_results._extract_u_from_iuvarr", "densepose_results._extract_v_from_iuvarr"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVisualizer.get_image_bgr_from_context", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_i_from_iuvarr", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._contours", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._contours", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_u_from_iuvarr", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_v_from_iuvarr"], ["", "def", "visualize_iuv_arr", "(", "self", ",", "context", ",", "iuv_arr", ":", "np", ".", "ndarray", ",", "bbox_xywh", ":", "Boxes", ")", "->", "None", ":", "\n", "        ", "image_bgr", "=", "self", ".", "get_image_bgr_from_context", "(", "context", ")", "\n", "segm", "=", "_extract_i_from_iuvarr", "(", "iuv_arr", ")", "\n", "u", "=", "_extract_u_from_iuvarr", "(", "iuv_arr", ")", ".", "astype", "(", "float", ")", "/", "255.0", "\n", "v", "=", "_extract_v_from_iuvarr", "(", "iuv_arr", ")", ".", "astype", "(", "float", ")", "/", "255.0", "\n", "self", ".", "_contours", "(", "image_bgr", ",", "u", ",", "segm", ",", "bbox_xywh", ")", "\n", "self", ".", "_contours", "(", "image_bgr", ",", "v", ",", "segm", ",", "bbox_xywh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._contours": [[167, 212], ["range", "numpy.amin", "numpy.amax", "numpy.nonzero", "numpy.amin", "numpy.amin", "enumerate", "numpy.any", "numpy.amax", "numpy.amax", "numpy.nditer", "numpy.nditer.iternext", "densepose_results.DensePoseResultsCustomContourVisualizer._draw_line"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._draw_line"], ["", "def", "_contours", "(", "self", ",", "image_bgr", ",", "arr", ",", "segm", ",", "bbox_xywh", ")", ":", "\n", "        ", "for", "part_idx", "in", "range", "(", "1", ",", "DensePoseDataRelative", ".", "N_PART_LABELS", "+", "1", ")", ":", "\n", "            ", "mask", "=", "segm", "==", "part_idx", "\n", "if", "not", "np", ".", "any", "(", "mask", ")", ":", "\n", "                ", "continue", "\n", "", "arr_min", "=", "np", ".", "amin", "(", "arr", "[", "mask", "]", ")", "\n", "arr_max", "=", "np", ".", "amax", "(", "arr", "[", "mask", "]", ")", "\n", "I", ",", "J", "=", "np", ".", "nonzero", "(", "mask", ")", "\n", "i0", "=", "np", ".", "amin", "(", "I", ")", "\n", "i1", "=", "np", ".", "amax", "(", "I", ")", "+", "1", "\n", "j0", "=", "np", ".", "amin", "(", "J", ")", "\n", "j1", "=", "np", ".", "amax", "(", "J", ")", "+", "1", "\n", "if", "(", "j1", "==", "j0", "+", "1", ")", "or", "(", "i1", "==", "i0", "+", "1", ")", ":", "\n", "                ", "continue", "\n", "", "Nw", "=", "arr", ".", "shape", "[", "1", "]", "-", "1", "\n", "Nh", "=", "arr", ".", "shape", "[", "0", "]", "-", "1", "\n", "for", "level_idx", ",", "level", "in", "enumerate", "(", "self", ".", "levels", ")", ":", "\n", "                ", "if", "(", "level", "<", "arr_min", ")", "or", "(", "level", ">", "arr_max", ")", ":", "\n", "                    ", "continue", "\n", "", "vp", "=", "arr", "[", "i0", ":", "i1", ",", "j0", ":", "j1", "]", ">=", "level", "\n", "bin_codes", "=", "vp", "[", ":", "-", "1", ",", ":", "-", "1", "]", "+", "vp", "[", "1", ":", ",", ":", "-", "1", "]", "*", "2", "+", "vp", "[", "1", ":", ",", "1", ":", "]", "*", "4", "+", "vp", "[", ":", "-", "1", ",", "1", ":", "]", "*", "8", "\n", "mp", "=", "mask", "[", "i0", ":", "i1", ",", "j0", ":", "j1", "]", "\n", "bin_mask_codes", "=", "mp", "[", ":", "-", "1", ",", ":", "-", "1", "]", "+", "mp", "[", "1", ":", ",", ":", "-", "1", "]", "*", "2", "+", "mp", "[", "1", ":", ",", "1", ":", "]", "*", "4", "+", "mp", "[", ":", "-", "1", ",", "1", ":", "]", "*", "8", "\n", "it", "=", "np", ".", "nditer", "(", "bin_codes", ",", "flags", "=", "[", "\"multi_index\"", "]", ")", "\n", "color_bgr", "=", "self", ".", "level_colors_bgr", "[", "level_idx", "]", "\n", "linewidth", "=", "self", ".", "linewidths", "[", "level_idx", "]", "\n", "while", "not", "it", ".", "finished", ":", "\n", "                    ", "if", "(", "it", "[", "0", "]", "!=", "0", ")", "and", "(", "it", "[", "0", "]", "!=", "15", ")", ":", "\n", "                        ", "i", ",", "j", "=", "it", ".", "multi_index", "\n", "if", "bin_mask_codes", "[", "i", ",", "j", "]", "!=", "0", ":", "\n", "                            ", "self", ".", "_draw_line", "(", "\n", "image_bgr", ",", "\n", "arr", ",", "\n", "mask", ",", "\n", "level", ",", "\n", "color_bgr", ",", "\n", "linewidth", ",", "\n", "it", "[", "0", "]", ",", "\n", "it", ".", "multi_index", ",", "\n", "bbox_xywh", ",", "\n", "Nw", ",", "\n", "Nh", ",", "\n", "(", "i0", ",", "j0", ")", ",", "\n", ")", "\n", "", "", "it", ".", "iternext", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._draw_line": [[213, 238], ["densepose_results.DensePoseResultsCustomContourVisualizer._bin_code_2_lines", "cv2.line", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._bin_code_2_lines"], ["", "", "", "", "def", "_draw_line", "(", "\n", "self", ",", "\n", "image_bgr", ",", "\n", "arr", ",", "\n", "mask", ",", "\n", "v", ",", "\n", "color_bgr", ",", "\n", "linewidth", ",", "\n", "bin_code", ",", "\n", "multi_idx", ",", "\n", "bbox_xywh", ",", "\n", "Nw", ",", "\n", "Nh", ",", "\n", "offset", ",", "\n", ")", ":", "\n", "        ", "lines", "=", "self", ".", "_bin_code_2_lines", "(", "arr", ",", "v", ",", "bin_code", ",", "multi_idx", ",", "Nw", ",", "Nh", ",", "offset", ")", "\n", "x0", ",", "y0", ",", "w", ",", "h", "=", "bbox_xywh", "\n", "x1", "=", "x0", "+", "w", "\n", "y1", "=", "y0", "+", "h", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "x0r", ",", "y0r", "=", "line", "[", "0", "]", "\n", "x1r", ",", "y1r", "=", "line", "[", "1", "]", "\n", "pt0", "=", "(", "int", "(", "x0", "+", "x0r", "*", "(", "x1", "-", "x0", ")", ")", ",", "int", "(", "y0", "+", "y0r", "*", "(", "y1", "-", "y0", ")", ")", ")", "\n", "pt1", "=", "(", "int", "(", "x0", "+", "x1r", "*", "(", "x1", "-", "x0", ")", ")", ",", "int", "(", "y0", "+", "y1r", "*", "(", "y1", "-", "y0", ")", ")", ")", "\n", "cv2", ".", "line", "(", "image_bgr", ",", "pt0", ",", "pt1", ",", "color_bgr", ",", "linewidth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsCustomContourVisualizer._bin_code_2_lines": [[239, 306], ["float", "float"], "methods", ["None"], ["", "", "def", "_bin_code_2_lines", "(", "self", ",", "arr", ",", "v", ",", "bin_code", ",", "multi_idx", ",", "Nw", ",", "Nh", ",", "offset", ")", ":", "\n", "        ", "i0", ",", "j0", "=", "offset", "\n", "i", ",", "j", "=", "multi_idx", "\n", "i", "+=", "i0", "\n", "j", "+=", "j0", "\n", "v0", ",", "v1", ",", "v2", ",", "v3", "=", "arr", "[", "i", ",", "j", "]", ",", "arr", "[", "i", "+", "1", ",", "j", "]", ",", "arr", "[", "i", "+", "1", ",", "j", "+", "1", "]", ",", "arr", "[", "i", ",", "j", "+", "1", "]", "\n", "x0i", "=", "float", "(", "j", ")", "/", "Nw", "\n", "y0j", "=", "float", "(", "i", ")", "/", "Nh", "\n", "He", "=", "1.0", "/", "Nh", "\n", "We", "=", "1.0", "/", "Nw", "\n", "if", "(", "bin_code", "==", "1", ")", "or", "(", "bin_code", "==", "14", ")", ":", "\n", "            ", "a", "=", "(", "v", "-", "v0", ")", "/", "(", "v1", "-", "v0", ")", "\n", "b", "=", "(", "v", "-", "v0", ")", "/", "(", "v3", "-", "v0", ")", "\n", "pt1", "=", "(", "x0i", ",", "y0j", "+", "a", "*", "He", ")", "\n", "pt2", "=", "(", "x0i", "+", "b", "*", "We", ",", "y0j", ")", "\n", "return", "[", "(", "pt1", ",", "pt2", ")", "]", "\n", "", "elif", "(", "bin_code", "==", "2", ")", "or", "(", "bin_code", "==", "13", ")", ":", "\n", "            ", "a", "=", "(", "v", "-", "v0", ")", "/", "(", "v1", "-", "v0", ")", "\n", "b", "=", "(", "v", "-", "v1", ")", "/", "(", "v2", "-", "v1", ")", "\n", "pt1", "=", "(", "x0i", ",", "y0j", "+", "a", "*", "He", ")", "\n", "pt2", "=", "(", "x0i", "+", "b", "*", "We", ",", "y0j", "+", "He", ")", "\n", "return", "[", "(", "pt1", ",", "pt2", ")", "]", "\n", "", "elif", "(", "bin_code", "==", "3", ")", "or", "(", "bin_code", "==", "12", ")", ":", "\n", "            ", "a", "=", "(", "v", "-", "v0", ")", "/", "(", "v3", "-", "v0", ")", "\n", "b", "=", "(", "v", "-", "v1", ")", "/", "(", "v2", "-", "v1", ")", "\n", "pt1", "=", "(", "x0i", "+", "a", "*", "We", ",", "y0j", ")", "\n", "pt2", "=", "(", "x0i", "+", "b", "*", "We", ",", "y0j", "+", "He", ")", "\n", "return", "[", "(", "pt1", ",", "pt2", ")", "]", "\n", "", "elif", "(", "bin_code", "==", "4", ")", "or", "(", "bin_code", "==", "11", ")", ":", "\n", "            ", "a", "=", "(", "v", "-", "v1", ")", "/", "(", "v2", "-", "v1", ")", "\n", "b", "=", "(", "v", "-", "v3", ")", "/", "(", "v2", "-", "v3", ")", "\n", "pt1", "=", "(", "x0i", "+", "a", "*", "We", ",", "y0j", "+", "He", ")", "\n", "pt2", "=", "(", "x0i", "+", "We", ",", "y0j", "+", "b", "*", "He", ")", "\n", "return", "[", "(", "pt1", ",", "pt2", ")", "]", "\n", "", "elif", "(", "bin_code", "==", "6", ")", "or", "(", "bin_code", "==", "9", ")", ":", "\n", "            ", "a", "=", "(", "v", "-", "v0", ")", "/", "(", "v1", "-", "v0", ")", "\n", "b", "=", "(", "v", "-", "v3", ")", "/", "(", "v2", "-", "v3", ")", "\n", "pt1", "=", "(", "x0i", ",", "y0j", "+", "a", "*", "He", ")", "\n", "pt2", "=", "(", "x0i", "+", "We", ",", "y0j", "+", "b", "*", "He", ")", "\n", "return", "[", "(", "pt1", ",", "pt2", ")", "]", "\n", "", "elif", "(", "bin_code", "==", "7", ")", "or", "(", "bin_code", "==", "8", ")", ":", "\n", "            ", "a", "=", "(", "v", "-", "v0", ")", "/", "(", "v3", "-", "v0", ")", "\n", "b", "=", "(", "v", "-", "v3", ")", "/", "(", "v2", "-", "v3", ")", "\n", "pt1", "=", "(", "x0i", "+", "a", "*", "We", ",", "y0j", ")", "\n", "pt2", "=", "(", "x0i", "+", "We", ",", "y0j", "+", "b", "*", "He", ")", "\n", "return", "[", "(", "pt1", ",", "pt2", ")", "]", "\n", "", "elif", "bin_code", "==", "5", ":", "\n", "            ", "a1", "=", "(", "v", "-", "v0", ")", "/", "(", "v1", "-", "v0", ")", "\n", "b1", "=", "(", "v", "-", "v1", ")", "/", "(", "v2", "-", "v1", ")", "\n", "pt11", "=", "(", "x0i", ",", "y0j", "+", "a1", "*", "He", ")", "\n", "pt12", "=", "(", "x0i", "+", "b1", "*", "We", ",", "y0j", "+", "He", ")", "\n", "a2", "=", "(", "v", "-", "v0", ")", "/", "(", "v3", "-", "v0", ")", "\n", "b2", "=", "(", "v", "-", "v3", ")", "/", "(", "v2", "-", "v3", ")", "\n", "pt21", "=", "(", "x0i", "+", "a2", "*", "We", ",", "y0j", ")", "\n", "pt22", "=", "(", "x0i", "+", "We", ",", "y0j", "+", "b2", "*", "He", ")", "\n", "return", "[", "(", "pt11", ",", "pt12", ")", ",", "(", "pt21", ",", "pt22", ")", "]", "\n", "", "elif", "bin_code", "==", "10", ":", "\n", "            ", "a1", "=", "(", "v", "-", "v0", ")", "/", "(", "v3", "-", "v0", ")", "\n", "b1", "=", "(", "v", "-", "v0", ")", "/", "(", "v1", "-", "v0", ")", "\n", "pt11", "=", "(", "x0i", "+", "a1", "*", "We", ",", "y0j", ")", "\n", "pt12", "=", "(", "x0i", ",", "y0j", "+", "b1", "*", "He", ")", "\n", "a2", "=", "(", "v", "-", "v1", ")", "/", "(", "v2", "-", "v1", ")", "\n", "b2", "=", "(", "v", "-", "v3", ")", "/", "(", "v2", "-", "v3", ")", "\n", "pt21", "=", "(", "x0i", "+", "a2", "*", "We", ",", "y0j", "+", "He", ")", "\n", "pt22", "=", "(", "x0i", "+", "We", ",", "y0j", "+", "b2", "*", "He", ")", "\n", "return", "[", "(", "pt11", ",", "pt12", ")", ",", "(", "pt21", ",", "pt22", ")", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsFineSegmentationVisualizer.__init__": [[320, 329], ["densepose_results.DensePoseMaskedColormapResultsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DensePoseResultsFineSegmentationVisualizer", ",", "self", ")", ".", "__init__", "(", "\n", "_extract_i_from_iuvarr", ",", "\n", "_extract_i_from_iuvarr", ",", "\n", "inplace", ",", "\n", "cmap", ",", "\n", "alpha", ",", "\n", "val_scale", "=", "255.0", "/", "DensePoseDataRelative", ".", "N_PART_LABELS", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsUVisualizer.__init__": [[333, 342], ["densepose_results.DensePoseMaskedColormapResultsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DensePoseResultsUVisualizer", ",", "self", ")", ".", "__init__", "(", "\n", "_extract_u_from_iuvarr", ",", "\n", "_extract_i_from_iuvarr", ",", "\n", "inplace", ",", "\n", "cmap", ",", "\n", "alpha", ",", "\n", "val_scale", "=", "1.0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results.DensePoseResultsVVisualizer.__init__": [[346, 355], ["densepose_results.DensePoseMaskedColormapResultsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DensePoseResultsVVisualizer", ",", "self", ")", ".", "__init__", "(", "\n", "_extract_v_from_iuvarr", ",", "\n", "_extract_i_from_iuvarr", ",", "\n", "inplace", ",", "\n", "cmap", ",", "\n", "alpha", ",", "\n", "val_scale", "=", "1.0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_i_from_iuvarr": [[76, 78], ["None"], "function", ["None"], ["", "", "def", "_extract_i_from_iuvarr", "(", "iuv_arr", ")", ":", "\n", "    ", "return", "iuv_arr", "[", "0", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_u_from_iuvarr": [[80, 82], ["None"], "function", ["None"], ["", "def", "_extract_u_from_iuvarr", "(", "iuv_arr", ")", ":", "\n", "    ", "return", "iuv_arr", "[", "1", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_results._extract_v_from_iuvarr": [[84, 86], ["None"], "function", ["None"], ["", "def", "_extract_v_from_iuvarr", "(", "iuv_arr", ")", ":", "\n", "    ", "return", "iuv_arr", "[", "2", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataCoarseSegmentationVisualizer.__init__": [[16, 22], ["base.MatrixVisualizer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "inplace", "=", "True", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "alpha", "=", "0.7", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "mask_visualizer", "=", "MatrixVisualizer", "(", "\n", "inplace", "=", "inplace", ",", "\n", "cmap", "=", "cmap", ",", "\n", "val_scale", "=", "255.0", "/", "DensePoseDataRelative", ".", "N_BODY_PARTS", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataCoarseSegmentationVisualizer.visualize": [[24, 37], ["zip", "densepose_data.segm.numpy", "numpy.zeros", "densepose_data_points.DensePoseDataCoarseSegmentationVisualizer.mask_visualizer.visualize", "bbox_xywh.numpy"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize"], ["", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "bbox_densepose_datas", ":", "Optional", "[", "Tuple", "[", "Iterable", "[", "Boxes", "]", ",", "Iterable", "[", "DensePoseDataRelative", "]", "]", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "if", "bbox_densepose_datas", "is", "None", ":", "\n", "            ", "return", "image_bgr", "\n", "", "for", "bbox_xywh", ",", "densepose_data", "in", "zip", "(", "*", "bbox_densepose_datas", ")", ":", "\n", "            ", "matrix", "=", "densepose_data", ".", "segm", ".", "numpy", "(", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "matrix", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "mask", "[", "matrix", ">", "0", "]", "=", "1", "\n", "image_bgr", "=", "self", ".", "mask_visualizer", ".", "visualize", "(", "image_bgr", ",", "mask", ",", "matrix", ",", "bbox_xywh", ".", "numpy", "(", ")", ")", "\n", "", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.__init__": [[40, 44], ["base.PointsVisualizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "densepose_data_to_value_fn", "=", "None", ",", "cmap", "=", "cv2", ".", "COLORMAP_PARULA", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "points_visualizer", "=", "PointsVisualizer", "(", ")", "\n", "self", ".", "densepose_data_to_value_fn", "=", "densepose_data_to_value_fn", "\n", "self", ".", "cmap", "=", "cmap", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize": [[45, 67], ["zip", "bbox_xywh.numpy", "zip", "densepose_data_points.DensePoseDataPointsVisualizer.points_visualizer.visualize", "densepose_data_points.DensePoseDataPointsVisualizer.densepose_data_to_value_fn", "cv2.applyColorMap", "densepose_data_points.DensePoseDataPointsVisualizer.points_visualizer.visualize", "densepose_data.x.numpy", "densepose_data.y.numpy", "int", "img_color_bgr.ravel"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVisualizer.visualize"], ["", "def", "visualize", "(", "\n", "self", ",", "\n", "image_bgr", ":", "Image", ",", "\n", "bbox_densepose_datas", ":", "Optional", "[", "Tuple", "[", "Iterable", "[", "Boxes", "]", ",", "Iterable", "[", "DensePoseDataRelative", "]", "]", "]", ",", "\n", ")", "->", "Image", ":", "\n", "        ", "if", "bbox_densepose_datas", "is", "None", ":", "\n", "            ", "return", "image_bgr", "\n", "", "for", "bbox_xywh", ",", "densepose_data", "in", "zip", "(", "*", "bbox_densepose_datas", ")", ":", "\n", "            ", "x0", ",", "y0", ",", "w", ",", "h", "=", "bbox_xywh", ".", "numpy", "(", ")", "\n", "x", "=", "densepose_data", ".", "x", ".", "numpy", "(", ")", "*", "w", "/", "255.0", "+", "x0", "\n", "y", "=", "densepose_data", ".", "y", ".", "numpy", "(", ")", "*", "h", "/", "255.0", "+", "y0", "\n", "pts_xy", "=", "zip", "(", "x", ",", "y", ")", "\n", "if", "self", ".", "densepose_data_to_value_fn", "is", "None", ":", "\n", "                ", "image_bgr", "=", "self", ".", "points_visualizer", ".", "visualize", "(", "image_bgr", ",", "pts_xy", ")", "\n", "", "else", ":", "\n", "                ", "v", "=", "self", ".", "densepose_data_to_value_fn", "(", "densepose_data", ")", "\n", "img_colors_bgr", "=", "cv2", ".", "applyColorMap", "(", "v", ",", "self", ".", "cmap", ")", "\n", "colors_bgr", "=", "[", "\n", "[", "int", "(", "v", ")", "for", "v", "in", "img_color_bgr", ".", "ravel", "(", ")", "]", "for", "img_color_bgr", "in", "img_colors_bgr", "\n", "]", "\n", "image_bgr", "=", "self", ".", "points_visualizer", ".", "visualize", "(", "image_bgr", ",", "pts_xy", ",", "colors_bgr", ")", "\n", "", "", "return", "image_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsUVisualizer.__init__": [[89, 92], ["densepose_data_points.DensePoseDataPointsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DensePoseDataPointsUVisualizer", ",", "self", ")", ".", "__init__", "(", "\n", "densepose_data_to_value_fn", "=", "_densepose_data_u_for_cmap", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsVVisualizer.__init__": [[96, 99], ["densepose_data_points.DensePoseDataPointsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DensePoseDataPointsVVisualizer", ",", "self", ")", ".", "__init__", "(", "\n", "densepose_data_to_value_fn", "=", "_densepose_data_v_for_cmap", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points.DensePoseDataPointsIVisualizer.__init__": [[103, 106], ["densepose_data_points.DensePoseDataPointsVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DensePoseDataPointsIVisualizer", ",", "self", ")", ".", "__init__", "(", "\n", "densepose_data_to_value_fn", "=", "_densepose_data_i_for_cmap", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points._densepose_data_u_for_cmap": [[69, 72], ["u.astype", "numpy.clip", "densepose_data.u.numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "", "def", "_densepose_data_u_for_cmap", "(", "densepose_data", ")", ":", "\n", "    ", "u", "=", "np", ".", "clip", "(", "densepose_data", ".", "u", ".", "numpy", "(", ")", ",", "0", ",", "1", ")", "*", "255.0", "\n", "return", "u", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points._densepose_data_v_for_cmap": [[74, 77], ["v.astype", "numpy.clip", "densepose_data.v.numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "_densepose_data_v_for_cmap", "(", "densepose_data", ")", ":", "\n", "    ", "v", "=", "np", ".", "clip", "(", "densepose_data", ".", "v", ".", "numpy", "(", ")", ",", "0", ",", "1", ")", "*", "255.0", "\n", "return", "v", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.vis.densepose_data_points._densepose_data_i_for_cmap": [[79, 86], ["i.astype", "numpy.clip", "densepose_data.i.numpy"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "_densepose_data_i_for_cmap", "(", "densepose_data", ")", ":", "\n", "    ", "i", "=", "(", "\n", "np", ".", "clip", "(", "densepose_data", ".", "i", ".", "numpy", "(", ")", ",", "0.0", ",", "DensePoseDataRelative", ".", "N_PART_LABELS", ")", "\n", "*", "255.0", "\n", "/", "DensePoseDataRelative", ".", "N_PART_LABELS", "\n", ")", "\n", "return", "i", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TridentNet.train_net.Trainer.build_evaluator": [[21, 26], ["detectron2.evaluation.COCOEvaluator", "os.path.join"], "methods", ["None"], ["from", "maskrcnn_benchmark", ".", "utils", ".", "checkpoint", "import", "DetectronCheckpointer", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "collect_env", "import", "collect_env_info", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "comm", "import", "synchronize", ",", "get_rank", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "imports", "import", "import_file", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "logger", "import", "setup_logger", "\n", "from", "maskrcnn_benchmark", ".", "utils", ".", "miscellaneous", "import", "mkdir", ",", "save_config", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TridentNet.train_net.setup": [[28, 39], ["detectron2.config.get_cfg", "tridentnet.add_tridentnet_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.config.add_tridentnet_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["# See if we can use apex.DistributedDataParallel instead of the torch default,", "\n", "# and enable mixed-precision via apex.amp", "\n", "try", ":", "\n", "    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for multi-precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n", "    ", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.TridentNet.train_net.main": [[41, 55], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test"], ["optimizer", "=", "make_optimizer", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "make_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Initialize mixed-precision training", "\n", "use_mixed_precision", "=", "cfg", ".", "DTYPE", "==", "\"float16\"", "\n", "amp_opt_level", "=", "'O1'", "if", "use_mixed_precision", "else", "'O0'", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "amp_opt_level", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ",", "\n", "# this should be removed if we update BatchNorm stats", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.config.add_tridentnet_config": [[7, 27], ["detectron2.config.CfgNode"], "function", ["None"], ["from", "fvcore", ".", "common", ".", "config", "import", "CfgNode", "as", "_CfgNode", "\n", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    ", "\"\"\"\n    The same as `fvcore.common.config.CfgNode`, but different in:\n\n    1. Use unsafe yaml loading by default.\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    2. Support config versioning.\n       When attempting to merge an old config, it will convert the old config automatically.\n    \"\"\"", "\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rpn.TridentRPN.__init__": [[15, 20], ["detectron2.modeling.proposal_generator.rpn.RPN.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", "TridentRPN", ",", "self", ")", ".", "__init__", "(", "cfg", ",", "input_shape", ")", "\n", "\n", "self", ".", "num_branch", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "NUM_BRANCH", "\n", "self", ".", "trident_fast", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "TEST_BRANCH_IDX", "!=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rpn.TridentRPN.forward": [[21, 33], ["detectron2.structures.ImageList", "super().forward", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "gt_instances", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :class:`RPN.forward`.\n        \"\"\"", "\n", "num_branch", "=", "self", ".", "num_branch", "if", "self", ".", "training", "or", "not", "self", ".", "trident_fast", "else", "1", "\n", "# Duplicate images and gt_instances for all branches in TridentNet.", "\n", "all_images", "=", "ImageList", "(", "\n", "torch", ".", "cat", "(", "[", "images", ".", "tensor", "]", "*", "num_branch", ")", ",", "images", ".", "image_sizes", "*", "num_branch", "\n", ")", "\n", "all_gt_instances", "=", "gt_instances", "*", "num_branch", "if", "gt_instances", "is", "not", "None", "else", "None", "\n", "\n", "return", "super", "(", "TridentRPN", ",", "self", ")", ".", "forward", "(", "all_images", ",", "features", ",", "all_gt_instances", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_conv.TridentConv.__init__": [[11, 57], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "isinstance", "isinstance", "torch.nn.Parameter", "torch.nn.init.kaiming_uniform_", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "len", "torch.Tensor", "torch.nn.Parameter", "torch.nn.init.constant_", "torch.Tensor", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "paddings", "=", "0", ",", "\n", "dilations", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "num_branch", "=", "1", ",", "\n", "test_branch_idx", "=", "-", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "TridentConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "num_branch", "=", "num_branch", "\n", "self", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "with_bias", "=", "bias", "\n", "if", "isinstance", "(", "paddings", ",", "int", ")", ":", "\n", "            ", "paddings", "=", "[", "paddings", "]", "*", "self", ".", "num_branch", "\n", "", "if", "isinstance", "(", "dilations", ",", "int", ")", ":", "\n", "            ", "dilations", "=", "[", "dilations", "]", "*", "self", ".", "num_branch", "\n", "", "self", ".", "paddings", "=", "[", "_pair", "(", "padding", ")", "for", "padding", "in", "paddings", "]", "\n", "self", ".", "dilations", "=", "[", "_pair", "(", "dilation", ")", "for", "dilation", "in", "dilations", "]", "\n", "self", ".", "test_branch_idx", "=", "test_branch_idx", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "assert", "len", "(", "{", "self", ".", "num_branch", ",", "len", "(", "self", ".", "paddings", ")", ",", "len", "(", "self", ".", "dilations", ")", "}", ")", "==", "1", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "self", ".", "kernel_size", ")", "\n", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_conv.TridentConv.forward": [[58, 95], ["len", "inputs[].numel", "detectron2.layers.wrappers._NewEmptyTensorOp.apply", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "trident_conv.TridentConv.norm", "trident_conv.TridentConv.activation", "zip", "zip"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "num_branch", "=", "self", ".", "num_branch", "if", "self", ".", "training", "or", "self", ".", "test_branch_idx", "==", "-", "1", "else", "1", "\n", "assert", "len", "(", "inputs", ")", "==", "num_branch", "\n", "\n", "if", "inputs", "[", "0", "]", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "s", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "s", "in", "zip", "(", "\n", "inputs", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "input", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "[", "_NewEmptyTensorOp", ".", "apply", "(", "input", ",", "output_shape", ")", "for", "input", "in", "inputs", "]", "\n", "\n", "", "if", "self", ".", "training", "or", "self", ".", "test_branch_idx", "==", "-", "1", ":", "\n", "            ", "outputs", "=", "[", "\n", "F", ".", "conv2d", "(", "input", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "padding", ",", "dilation", ",", "self", ".", "groups", ")", "\n", "for", "input", ",", "dilation", ",", "padding", "in", "zip", "(", "inputs", ",", "self", ".", "dilations", ",", "self", ".", "paddings", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "[", "\n", "F", ".", "conv2d", "(", "\n", "inputs", "[", "0", "]", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "paddings", "[", "self", ".", "test_branch_idx", "]", ",", "\n", "self", ".", "dilations", "[", "self", ".", "test_branch_idx", "]", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "]", "\n", "\n", "", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "[", "self", ".", "norm", "(", "x", ")", "for", "x", "in", "outputs", "]", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "[", "self", ".", "activation", "(", "x", ")", "for", "x", "in", "outputs", "]", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_conv.TridentConv.extra_repr": [[96, 108], ["str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "\"in_channels=\"", "+", "str", "(", "self", ".", "in_channels", ")", "\n", "tmpstr", "+=", "\", out_channels=\"", "+", "str", "(", "self", ".", "out_channels", ")", "\n", "tmpstr", "+=", "\", kernel_size=\"", "+", "str", "(", "self", ".", "kernel_size", ")", "\n", "tmpstr", "+=", "\", num_branch=\"", "+", "str", "(", "self", ".", "num_branch", ")", "\n", "tmpstr", "+=", "\", test_branch_idx=\"", "+", "str", "(", "self", ".", "test_branch_idx", ")", "\n", "tmpstr", "+=", "\", stride=\"", "+", "str", "(", "self", ".", "stride", ")", "\n", "tmpstr", "+=", "\", paddings=\"", "+", "str", "(", "self", ".", "paddings", ")", "\n", "tmpstr", "+=", "\", dilations=\"", "+", "str", "(", "self", ".", "dilations", ")", "\n", "tmpstr", "+=", "\", groups=\"", "+", "str", "(", "self", ".", "groups", ")", "\n", "tmpstr", "+=", "\", bias=\"", "+", "str", "(", "self", ".", "with_bias", ")", "\n", "return", "tmpstr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_backbone.TridentBottleneckBlock.__init__": [[16, 94], ["detectron2.modeling.ResNetBlockBase.__init__", "detectron2.layers.Conv2d", "trident_conv.TridentConv", "detectron2.layers.Conv2d", "len", "detectron2.layers.Conv2d", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "detectron2.layers.get_norm", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.get_norm"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "*", ",", "\n", "bottleneck_channels", ",", "\n", "stride", "=", "1", ",", "\n", "num_groups", "=", "1", ",", "\n", "norm", "=", "\"BN\"", ",", "\n", "stride_in_1x1", "=", "False", ",", "\n", "num_branch", "=", "3", ",", "\n", "dilations", "=", "(", "1", ",", "2", ",", "3", ")", ",", "\n", "concat_output", "=", "False", ",", "\n", "test_branch_idx", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_branch (int): the number of branches in TridentNet.\n            dilations (tuple): the dilations of multiple branches in TridentNet.\n            concat_output (bool): if concatenate outputs of multiple branches in TridentNet.\n                Use 'True' for the last trident block.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "stride", ")", "\n", "\n", "assert", "num_branch", "==", "len", "(", "dilations", ")", "\n", "\n", "self", ".", "num_branch", "=", "num_branch", "\n", "self", ".", "concat_output", "=", "concat_output", "\n", "self", ".", "test_branch_idx", "=", "test_branch_idx", "\n", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "shortcut", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "None", "\n", "\n", "", "stride_1x1", ",", "stride_3x3", "=", "(", "stride", ",", "1", ")", "if", "stride_in_1x1", "else", "(", "1", ",", "stride", ")", "\n", "\n", "self", ".", "conv1", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride_1x1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "bottleneck_channels", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv2", "=", "TridentConv", "(", "\n", "bottleneck_channels", ",", "\n", "bottleneck_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride_3x3", ",", "\n", "paddings", "=", "dilations", ",", "\n", "bias", "=", "False", ",", "\n", "groups", "=", "num_groups", ",", "\n", "dilations", "=", "dilations", ",", "\n", "num_branch", "=", "num_branch", ",", "\n", "test_branch_idx", "=", "test_branch_idx", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "bottleneck_channels", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv3", "=", "Conv2d", "(", "\n", "bottleneck_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "\n", "for", "layer", "in", "[", "self", ".", "conv1", ",", "self", ".", "conv2", ",", "self", ".", "conv3", ",", "self", ".", "shortcut", "]", ":", "\n", "            ", "if", "layer", "is", "not", "None", ":", "# shortcut can be None", "\n", "                ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_backbone.TridentBottleneckBlock.forward": [[95, 117], ["trident_backbone.TridentBottleneckBlock.conv2", "isinstance", "trident_backbone.TridentBottleneckBlock.conv1", "torch.relu_", "torch.relu_", "torch.relu_", "torch.relu_", "trident_backbone.TridentBottleneckBlock.conv3", "torch.relu_", "torch.relu_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "trident_backbone.TridentBottleneckBlock.shortcut", "zip"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "num_branch", "=", "self", ".", "num_branch", "if", "self", ".", "training", "or", "self", ".", "test_branch_idx", "==", "-", "1", "else", "1", "\n", "if", "not", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "x", "=", "[", "x", "]", "*", "num_branch", "\n", "", "out", "=", "[", "self", ".", "conv1", "(", "b", ")", "for", "b", "in", "x", "]", "\n", "out", "=", "[", "F", ".", "relu_", "(", "b", ")", "for", "b", "in", "out", "]", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "[", "F", ".", "relu_", "(", "b", ")", "for", "b", "in", "out", "]", "\n", "\n", "out", "=", "[", "self", ".", "conv3", "(", "b", ")", "for", "b", "in", "out", "]", "\n", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "[", "self", ".", "shortcut", "(", "b", ")", "for", "b", "in", "x", "]", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "[", "out_b", "+", "shortcut_b", "for", "out_b", ",", "shortcut_b", "in", "zip", "(", "out", ",", "shortcut", ")", "]", "\n", "out", "=", "[", "F", ".", "relu_", "(", "b", ")", "for", "b", "in", "out", "]", "\n", "if", "self", ".", "concat_output", ":", "\n", "            ", "out", "=", "torch", ".", "cat", "(", "out", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_backbone.make_trident_stage": [[119, 126], ["detectron2.modeling.ResNet.make_stage"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage"], ["", "", "def", "make_trident_stage", "(", "block_class", ",", "num_blocks", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Create a resnet stage by creating many blocks for TridentNet.\n    \"\"\"", "\n", "concat_output", "=", "[", "False", "]", "*", "(", "num_blocks", "-", "1", ")", "+", "[", "True", "]", "\n", "kwargs", "[", "\"concat_output_per_block\"", "]", "=", "concat_output", "\n", "return", "ResNet", ".", "make_stage", "(", "block_class", ",", "num_blocks", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_backbone.build_trident_resnet_backbone": [[128, 221], ["detectron2.modeling.BACKBONE_REGISTRY.register", "detectron2.modeling.backbone.resnet.BasicStem", "max", "enumerate", "detectron2.modeling.ResNet", "FrozenBatchNorm2d.convert_frozen_batchnorm.parameters", "detectron2.layers.FrozenBatchNorm2d.convert_frozen_batchnorm", "range", "stages.append", "stage_kargs.pop", "trident_backbone.make_trident_stage", "detectron2.modeling.ResNet.make_stage", "block.freeze"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.converters.base.BaseConverter.register", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.batch_norm.FrozenBatchNorm2d.convert_frozen_batchnorm", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_backbone.make_trident_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.backbone.resnet.make_stage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_trident_resnet_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a ResNet instance from config for TridentNet.\n\n    Returns:\n        ResNet: a :class:`ResNet` instance.\n    \"\"\"", "\n", "# need registration of new blocks/stems?", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NORM", "\n", "stem", "=", "BasicStem", "(", "\n", "in_channels", "=", "input_shape", ".", "channels", ",", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", ",", "\n", "norm", "=", "norm", ",", "\n", ")", "\n", "freeze_at", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", "\n", "\n", "if", "freeze_at", ">=", "1", ":", "\n", "        ", "for", "p", "in", "stem", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "stem", "=", "FrozenBatchNorm2d", ".", "convert_frozen_batchnorm", "(", "stem", ")", "\n", "\n", "# fmt: off", "\n", "", "out_features", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "OUT_FEATURES", "\n", "depth", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEPTH", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n", "width_per_group", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "\n", "bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "in_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "stride_in_1x1", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", "\n", "res5_dilation", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES5_DILATION", "\n", "deform_on_per_stage", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_ON_PER_STAGE", "\n", "deform_modulated", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_MODULATED", "\n", "deform_num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_NUM_GROUPS", "\n", "num_branch", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "NUM_BRANCH", "\n", "branch_dilations", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "BRANCH_DILATIONS", "\n", "trident_stage", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "TRIDENT_STAGE", "\n", "test_branch_idx", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "TEST_BRANCH_IDX", "\n", "# fmt: on", "\n", "assert", "res5_dilation", "in", "{", "1", ",", "2", "}", ",", "\"res5_dilation cannot be {}.\"", ".", "format", "(", "res5_dilation", ")", "\n", "\n", "num_blocks_per_stage", "=", "{", "50", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "101", ":", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "152", ":", "[", "3", ",", "8", ",", "36", ",", "3", "]", "}", "[", "depth", "]", "\n", "\n", "stages", "=", "[", "]", "\n", "\n", "res_stage_idx", "=", "{", "\"res2\"", ":", "2", ",", "\"res3\"", ":", "3", ",", "\"res4\"", ":", "4", ",", "\"res5\"", ":", "5", "}", "\n", "out_stage_idx", "=", "[", "res_stage_idx", "[", "f", "]", "for", "f", "in", "out_features", "]", "\n", "trident_stage_idx", "=", "res_stage_idx", "[", "trident_stage", "]", "\n", "max_stage_idx", "=", "max", "(", "out_stage_idx", ")", "\n", "for", "idx", ",", "stage_idx", "in", "enumerate", "(", "range", "(", "2", ",", "max_stage_idx", "+", "1", ")", ")", ":", "\n", "        ", "dilation", "=", "res5_dilation", "if", "stage_idx", "==", "5", "else", "1", "\n", "first_stride", "=", "1", "if", "idx", "==", "0", "or", "(", "stage_idx", "==", "5", "and", "dilation", "==", "2", ")", "else", "2", "\n", "stage_kargs", "=", "{", "\n", "\"num_blocks\"", ":", "num_blocks_per_stage", "[", "idx", "]", ",", "\n", "\"stride_per_block\"", ":", "[", "first_stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks_per_stage", "[", "idx", "]", "-", "1", ")", ",", "\n", "\"in_channels\"", ":", "in_channels", ",", "\n", "\"bottleneck_channels\"", ":", "bottleneck_channels", ",", "\n", "\"out_channels\"", ":", "out_channels", ",", "\n", "\"num_groups\"", ":", "num_groups", ",", "\n", "\"norm\"", ":", "norm", ",", "\n", "\"stride_in_1x1\"", ":", "stride_in_1x1", ",", "\n", "\"dilation\"", ":", "dilation", ",", "\n", "}", "\n", "if", "stage_idx", "==", "trident_stage_idx", ":", "\n", "            ", "assert", "not", "deform_on_per_stage", "[", "\n", "idx", "\n", "]", ",", "\"Not support deformable conv in Trident blocks yet.\"", "\n", "stage_kargs", "[", "\"block_class\"", "]", "=", "TridentBottleneckBlock", "\n", "stage_kargs", "[", "\"num_branch\"", "]", "=", "num_branch", "\n", "stage_kargs", "[", "\"dilations\"", "]", "=", "branch_dilations", "\n", "stage_kargs", "[", "\"test_branch_idx\"", "]", "=", "test_branch_idx", "\n", "stage_kargs", ".", "pop", "(", "\"dilation\"", ")", "\n", "", "elif", "deform_on_per_stage", "[", "idx", "]", ":", "\n", "            ", "stage_kargs", "[", "\"block_class\"", "]", "=", "DeformBottleneckBlock", "\n", "stage_kargs", "[", "\"deform_modulated\"", "]", "=", "deform_modulated", "\n", "stage_kargs", "[", "\"deform_num_groups\"", "]", "=", "deform_num_groups", "\n", "", "else", ":", "\n", "            ", "stage_kargs", "[", "\"block_class\"", "]", "=", "BottleneckBlock", "\n", "", "blocks", "=", "(", "\n", "make_trident_stage", "(", "**", "stage_kargs", ")", "\n", "if", "stage_idx", "==", "trident_stage_idx", "\n", "else", "ResNet", ".", "make_stage", "(", "**", "stage_kargs", ")", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "out_channels", "*=", "2", "\n", "bottleneck_channels", "*=", "2", "\n", "\n", "if", "freeze_at", ">=", "stage_idx", ":", "\n", "            ", "for", "block", "in", "blocks", ":", "\n", "                ", "block", ".", "freeze", "(", ")", "\n", "", "", "stages", ".", "append", "(", "blocks", ")", "\n", "", "return", "ResNet", "(", "stem", ",", "stages", ",", "out_features", "=", "out_features", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.TridentRes5ROIHeads.__init__": [[54, 59], ["detectron2.modeling.roi_heads.roi_heads.Res5ROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "input_shape", ")", "\n", "\n", "self", ".", "num_branch", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "NUM_BRANCH", "\n", "self", ".", "trident_fast", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "TEST_BRANCH_IDX", "!=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.TridentRes5ROIHeads.forward": [[60, 80], ["super().forward", "trident_rcnn.merge_branch_instances"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.merge_branch_instances"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :class:`Res5ROIHeads.forward`.\n        \"\"\"", "\n", "num_branch", "=", "self", ".", "num_branch", "if", "self", ".", "training", "or", "not", "self", ".", "trident_fast", "else", "1", "\n", "all_targets", "=", "targets", "*", "num_branch", "if", "targets", "is", "not", "None", "else", "None", "\n", "pred_instances", ",", "losses", "=", "super", "(", ")", ".", "forward", "(", "images", ",", "features", ",", "proposals", ",", "all_targets", ")", "\n", "del", "images", ",", "all_targets", ",", "targets", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "pred_instances", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", "=", "merge_branch_instances", "(", "\n", "pred_instances", ",", "\n", "num_branch", ",", "\n", "self", ".", "box_predictor", ".", "test_nms_thresh", ",", "\n", "self", ".", "box_predictor", ".", "test_topk_per_image", ",", "\n", ")", "\n", "\n", "return", "pred_instances", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.TridentStandardROIHeads.__init__": [[89, 94], ["detectron2.modeling.StandardROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", "TridentStandardROIHeads", ",", "self", ")", ".", "__init__", "(", "cfg", ",", "input_shape", ")", "\n", "\n", "self", ".", "num_branch", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "NUM_BRANCH", "\n", "self", ".", "trident_fast", "=", "cfg", ".", "MODEL", ".", "TRIDENT", ".", "TEST_BRANCH_IDX", "!=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.TridentStandardROIHeads.forward": [[95, 117], ["super().forward", "trident_rcnn.merge_branch_instances"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.merge_branch_instances"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :class:`Res5ROIHeads.forward`.\n        \"\"\"", "\n", "# Use 1 branch if using trident_fast during inference.", "\n", "num_branch", "=", "self", ".", "num_branch", "if", "self", ".", "training", "or", "not", "self", ".", "trident_fast", "else", "1", "\n", "# Duplicate targets for all branches in TridentNet.", "\n", "all_targets", "=", "targets", "*", "num_branch", "if", "targets", "is", "not", "None", "else", "None", "\n", "pred_instances", ",", "losses", "=", "super", "(", ")", ".", "forward", "(", "images", ",", "features", ",", "proposals", ",", "all_targets", ")", "\n", "del", "images", ",", "all_targets", ",", "targets", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "pred_instances", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", "=", "merge_branch_instances", "(", "\n", "pred_instances", ",", "\n", "num_branch", ",", "\n", "self", ".", "box_predictor", ".", "test_nms_thresh", ",", "\n", "self", ".", "box_predictor", ".", "test_topk_per_image", ",", "\n", ")", "\n", "\n", "return", "pred_instances", ",", "{", "}", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.tridentnet.trident_rcnn.merge_branch_instances": [[8, 45], ["range", "len", "detectron2.structures.Instances.cat", "detectron2.layers.batched_nms", "results.append", "range"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.nms.batched_nms"], ["def", "merge_branch_instances", "(", "instances", ",", "num_branch", ",", "nms_thresh", ",", "topk_per_image", ")", ":", "\n", "    ", "\"\"\"\n    Merge detection results from different branches of TridentNet.\n    Return detection results by applying non-maximum suppression (NMS) on bounding boxes\n    and keep the unsuppressed boxes and other instances (e.g mask) if any.\n\n    Args:\n        instances (list[Instances]): A list of N * num_branch instances that store detection\n            results. Contain N images and each image has num_branch instances.\n        num_branch (int): Number of branches used for merging detection results for each image.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        results: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections after merging results from multiple\n            branches.\n    \"\"\"", "\n", "if", "num_branch", "==", "1", ":", "\n", "        ", "return", "instances", "\n", "\n", "", "batch_size", "=", "len", "(", "instances", ")", "//", "num_branch", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "instance", "=", "Instances", ".", "cat", "(", "[", "instances", "[", "i", "+", "batch_size", "*", "j", "]", "for", "j", "in", "range", "(", "num_branch", ")", "]", ")", "\n", "\n", "# Apply per-class NMS", "\n", "keep", "=", "batched_nms", "(", "\n", "instance", ".", "pred_boxes", ".", "tensor", ",", "instance", ".", "scores", ",", "instance", ".", "pred_classes", ",", "nms_thresh", "\n", ")", "\n", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "result", "=", "instance", "[", "keep", "]", "\n", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_evaluator": [[60, 101], ["detectron2.evaluation.DatasetEvaluators", "detectron2.evaluation.DatasetEvaluators", "os.path.join", "detectron2.data.MetadataCatalog.get", "detectron2.data.MetadataCatalog.get", "detectron2.evaluation.LVISEvaluator", "detectron2.evaluation.LVISEvaluator", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.SemSegEvaluator", "detectron2.evaluation.SemSegEvaluator", "detectron2.evaluation.CityscapesInstanceEvaluator", "detectron2.evaluation.CityscapesInstanceEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "detectron2.evaluation.CityscapesSemSegEvaluator", "len", "NotImplementedError", "len", "torch.cuda.device_count", "detectron2.get_rank", "detectron2.get_rank", "torch.cuda.device_count", "detectron2.get_rank", "detectron2.get_rank"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.get_rank"], ["\n", "save_to_disk", "=", "get_rank", "(", ")", "==", "0", "\n", "checkpointer", "=", "DetectronCheckpointer", "(", "\n", "cfg", ",", "model", ",", "optimizer", ",", "scheduler", ",", "output_dir", ",", "save_to_disk", "\n", ")", "\n", "extra_checkpoint_data", "=", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHT", ")", "\n", "arguments", ".", "update", "(", "extra_checkpoint_data", ")", "\n", "\n", "if", "search", ":", "\n", "        ", "arguments", "[", "\"iteration\"", "]", "=", "0", "\n", "\n", "", "data_loader", "=", "make_data_loader", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "is_distributed", "=", "distributed", ",", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", ",", "\n", ")", "\n", "\n", "test_period", "=", "cfg", ".", "SOLVER", ".", "TEST_PERIOD", "\n", "if", "test_period", ">", "0", ":", "\n", "        ", "data_loader_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ",", "is_for_period", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_val", "=", "None", "\n", "\n", "", "checkpoint_period", "=", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", "\n", "loss_hist", "=", "do_train", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "data_loader", ",", "\n", "data_loader_val", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "checkpointer", ",", "\n", "device", ",", "\n", "checkpoint_period", ",", "\n", "test_period", ",", "\n", "arguments", ",", "\n", "search", ",", "\n", ")", "\n", "\n", "return", "model", ",", "loss_hist", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.Trainer.build_train_loader": [[102, 109], ["detectron2.data.build_detection_train_loader", "detectron2.data.build_detection_train_loader", "detectron2.data.DatasetMapper", "detectron2.data.DatasetMapper", "train_net.build_sem_seg_train_aug"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.build.build_detection_train_loader", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.build_sem_seg_train_aug"], ["\n", "\n", "", "def", "run_test", "(", "cfg", ",", "model", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "# TODO check if it helps", "\n", "iou_types", "=", "(", "\"bbox\"", ",", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.build_sem_seg_train_aug": [[31, 50], ["augs.append", "detectron2.ResizeShortestEdge", "augs.append", "augs.append", "detectron2.RandomFlip", "detectron2.RandomCrop_CategoryAreaConstraint", "detectron2.projects.point_rend.ColorAugSSDTransform"], "function", ["None"], ["    ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "    ", "raise", "ImportError", "(", "'Use APEX for multi-precision via apex.amp'", ")", "\n", "\n", "\n", "", "def", "train", "(", "cfg", ",", "local_rank", ",", "distributed", ",", "search", "=", "None", ")", ":", "\n", "    ", "model", "=", "build_detection_model", "(", "cfg", ")", "\n", "device", "=", "torch", ".", "device", "(", "cfg", ".", "MODEL", ".", "DEVICE", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "make_optimizer", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "make_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Initialize mixed-precision training", "\n", "use_mixed_precision", "=", "cfg", ".", "DTYPE", "==", "\"float16\"", "\n", "amp_opt_level", "=", "'O1'", "if", "use_mixed_precision", "else", "'O0'", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "amp_opt_level", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup": [[111, 122], ["detectron2.config.get_cfg", "detectron2.projects.point_rend.add_pointrend_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.get_cfg", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.config.add_pointrend_config", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.config.config.CfgNode.merge_from_file", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.default_setup"], ["", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "        ", "iou_types", "=", "iou_types", "+", "(", "\"keypoints\"", ",", ")", "\n", "", "output_folders", "=", "[", "None", "]", "*", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "\n", "dataset_names", "=", "cfg", ".", "DATASETS", ".", "TEST", "\n", "if", "cfg", ".", "OUTPUT_DIR", ":", "\n", "        ", "for", "idx", ",", "dataset_name", "in", "enumerate", "(", "dataset_names", ")", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "mkdir", "(", "output_folder", ")", "\n", "output_folders", "[", "idx", "]", "=", "output_folder", "\n", "", "", "data_loaders_val", "=", "make_data_loader", "(", "cfg", ",", "is_train", "=", "False", ",", "is_distributed", "=", "distributed", ")", "\n", "for", "output_folder", ",", "dataset_name", ",", "data_loader_val", "in", "zip", "(", "output_folders", ",", "dataset_names", ",", "data_loaders_val", ")", ":", "\n", "        ", "results", "=", "inference", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.main": [[124, 140], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.is_main_process", "detectron2.evaluation.verify_results", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.PointRend.train_net.setup", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.train_loop.TrainerBase.train", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.meta_arch.build.build_model", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.defaults.DefaultTrainer.resume_or_load", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.engine.trainer.Trainer.test", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.comm.is_main_process", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.evaluation.testing.verify_results"], ["data_loader_val", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "iou_types", "=", "iou_types", ",", "\n", "box_only", "=", "False", "if", "cfg", ".", "MODEL", ".", "ATSS_ON", "or", "cfg", ".", "MODEL", ".", "FCOS_ON", "or", "cfg", ".", "MODEL", ".", "RETINANET_ON", "else", "cfg", ".", "MODEL", ".", "RPN_ONLY", ",", "\n", "device", "=", "cfg", ".", "MODEL", ".", "DEVICE", ",", "\n", "expected_results", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS", ",", "\n", "expected_results_sigma_tol", "=", "cfg", ".", "TEST", ".", "EXPECTED_RESULTS_SIGMA_TOL", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", ")", "\n", "synchronize", "(", ")", "\n", "\n", "", "if", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "return", "results", "\n", "\n", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"PyTorch Object Detection Training\"", ")", "\n", "parser", ".", "add_argument", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.CoarseMaskHead.__init__": [[56, 116], ["torch.nn.Module.__init__", "detectron2.layers.Conv2d", "mask_head.CoarseMaskHead.conv_layers.append", "range", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.constant_", "detectron2.layers.Conv2d", "mask_head.CoarseMaskHead.conv_layers.append", "torch.nn.Linear", "mask_head.CoarseMaskHead.add_module", "mask_head.CoarseMaskHead.fcs.append", "fvcore.c2_msra_fill", "fvcore.c2_xavier_fill"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["\n", "\n", "if", "self", ".", "training", ":", "\n", "# during training, only focus on positive boxes", "\n", "            ", "all_proposals", "=", "proposals", "\n", "proposals", ",", "positive_inds", "=", "keep_only_positive_boxes", "(", "proposals", ")", "\n", "", "if", "self", ".", "training", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "x", "=", "features", "\n", "x", "=", "x", "[", "torch", ".", "cat", "(", "positive_inds", ",", "dim", "=", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "feature_extractor", "(", "features", ",", "proposals", ")", "\n", "", "mask_logits", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "result", "=", "self", ".", "post_processor", "(", "mask_logits", ",", "proposals", ")", "\n", "return", "x", ",", "result", ",", "{", "}", "\n", "\n", "", "loss_mask", "=", "self", ".", "loss_evaluator", "(", "proposals", ",", "mask_logits", ",", "targets", ")", "\n", "\n", "return", "x", ",", "all_proposals", ",", "dict", "(", "loss_mask", "=", "loss_mask", ")", "\n", "\n", "\n", "", "", "def", "build_roi_mask_head", "(", "cfg", ",", "in_channels", ")", ":", "\n", "    ", "return", "ROIMaskHead", "(", "cfg", ",", "in_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.CoarseMaskHead.forward": [[117, 126], ["torch.flatten", "mask_head.CoarseMaskHead.prediction().view", "layer", "torch.nn.functional.relu", "layer", "mask_head.CoarseMaskHead.prediction"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.export.flatten.TensorWrapSchema.flatten"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead.__init__": [[131, 149], ["torch.nn.Module.__init__", "numpy.sum", "mask_head.CoarseMaskHead", "mask_head.PointRendMaskHead._init_point_head", "detectron2.layers.ShapeSpec", "input_shape.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead._init_point_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._init_point_head": [[150, 177], ["numpy.sum", "point_head.build_point_head", "detectron2.layers.ShapeSpec"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.build_point_head"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead.forward": [[178, 199], ["mask_head.PointRendMaskHead.coarse_head", "losses.update", "mask_head.PointRendMaskHead.coarse_head", "mask_head.PointRendMaskHead._forward_mask_point", "detectron2.modeling.roi_heads.mask_head.mask_rcnn_inference", "mask_head.PointRendMaskHead._roi_pooler", "detectron2.modeling.roi_heads.mask_head.mask_rcnn_loss", "mask_head.PointRendMaskHead._forward_mask_point", "mask_head.PointRendMaskHead._roi_pooler"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.coco.coco_eval.COCOResults.update", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._forward_mask_point", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_inference", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._roi_pooler", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.roi_heads.mask_head.mask_rcnn_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._forward_mask_point", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._roi_pooler"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._roi_pooler": [[200, 223], ["sum", "point_features.generate_regular_grid_point_coords", "point_features.point_sample_fine_grained_features", "roi_features.view", "x.tensor.size"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.generate_regular_grid_point_coords", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample_fine_grained_features"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.PointRendMaskHead._forward_mask_point": [[224, 313], ["detectron2.layers.cat", "point_features.point_sample_fine_grained_features", "point_features.point_sample", "mask_head.PointRendMaskHead.point_head", "detectron2.layers.cat", "range", "torch.no_grad", "point_features.get_uncertain_point_coords_with_randomness", "point_head.roi_mask_point_loss", "len", "point_features.point_sample_fine_grained_features", "point_features.point_sample", "mask_head.PointRendMaskHead.point_head", "point_features.generate_regular_grid_point_coords", "detectron2.layers.interpolate", "mask_head.calculate_uncertainty", "point_features.get_uncertain_point_coords_on_grid", "mask_head.PointRendMaskHead.reshape", "point_indices.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "mask_logits.reshape().scatter_().view.reshape().scatter_().view.reshape().scatter_().view", "mask_head.calculate_uncertainty", "detectron2.layers.cat.size", "point_indices.unsqueeze().expand.unsqueeze().expand.unsqueeze", "mask_logits.reshape().scatter_().view.reshape().scatter_().view.reshape().scatter_", "mask_logits.reshape().scatter_().view.reshape().scatter_().view.reshape"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample_fine_grained_features", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_uncertain_point_coords_with_randomness", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.roi_mask_point_loss", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample_fine_grained_features", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.generate_regular_grid_point_coords", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.calculate_uncertainty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_uncertain_point_coords_on_grid", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.calculate_uncertainty"], []], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.mask_head.calculate_uncertainty": [[24, 47], ["logits.clone", "logits[].unsqueeze", "torch.abs", "torch.arange"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["positive_boxes", "=", "[", "]", "\n", "positive_inds", "=", "[", "]", "\n", "num_boxes", "=", "0", "\n", "for", "boxes_per_image", "in", "boxes", ":", "\n", "        ", "labels", "=", "boxes_per_image", ".", "get_field", "(", "\"labels\"", ")", "\n", "inds_mask", "=", "labels", ">", "0", "\n", "inds", "=", "inds_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "positive_boxes", ".", "append", "(", "boxes_per_image", "[", "inds", "]", ")", "\n", "positive_inds", ".", "append", "(", "inds_mask", ")", "\n", "", "return", "positive_boxes", ",", "positive_inds", "\n", "\n", "\n", "", "class", "ROIMaskHead", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "ROIMaskHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "self", ".", "feature_extractor", "=", "make_roi_mask_feature_extractor", "(", "cfg", ",", "in_channels", ")", "\n", "self", ".", "predictor", "=", "make_roi_mask_predictor", "(", "\n", "cfg", ",", "self", ".", "feature_extractor", ".", "out_channels", ")", "\n", "self", ".", "post_processor", "=", "make_roi_mask_post_processor", "(", "cfg", ")", "\n", "self", ".", "loss_evaluator", "=", "make_roi_mask_loss_evaluator", "(", "cfg", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.config.add_pointrend_config": [[7, 49], ["detectron2.config.CfgNode"], "function", ["None"], ["from", "fvcore", ".", "common", ".", "config", "import", "CfgNode", "as", "_CfgNode", "\n", "\n", "from", "detectron2", ".", "utils", ".", "file_io", "import", "PathManager", "\n", "\n", "\n", "class", "CfgNode", "(", "_CfgNode", ")", ":", "\n", "    ", "\"\"\"\n    The same as `fvcore.common.config.CfgNode`, but different in:\n\n    1. Use unsafe yaml loading by default.\n       Note that this may lead to arbitrary code execution: you must not\n       load a config file from untrusted sources before manually inspecting\n       the content of the file.\n    2. Support config versioning.\n       When attempting to merge an old config, it will convert the old config automatically.\n    \"\"\"", "\n", "\n", "@", "classmethod", "\n", "def", "_open_cfg", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "filename", ",", "\"r\"", ")", "\n", "\n", "# Note that the default value of allow_unsafe is changed to True", "\n", "", "def", "merge_from_file", "(", "self", ",", "cfg_filename", ":", "str", ",", "allow_unsafe", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "assert", "PathManager", ".", "isfile", "(", "cfg_filename", ")", ",", "f\"Config file '{cfg_filename}' does not exist!\"", "\n", "loaded_cfg", "=", "self", ".", "load_yaml_with_base", "(", "cfg_filename", ",", "allow_unsafe", "=", "allow_unsafe", ")", "\n", "loaded_cfg", "=", "type", "(", "self", ")", "(", "loaded_cfg", ")", "\n", "\n", "# defaults.py needs to import CfgNode", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "latest_ver", "=", "_C", ".", "VERSION", "\n", "assert", "(", "\n", "latest_ver", "==", "self", ".", "VERSION", "\n", ")", ",", "\"CfgNode.merge_from_file is only allowed on a config object of latest version!\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "loaded_ver", "=", "loaded_cfg", ".", "get", "(", "\"VERSION\"", ",", "None", ")", "\n", "if", "loaded_ver", "is", "None", ":", "\n", "            ", "from", ".", "compat", "import", "guess_version", "\n", "\n", "loaded_ver", "=", "guess_version", "(", "loaded_cfg", ",", "cfg_filename", ")", "\n", "", "assert", "loaded_ver", "<=", "self", ".", "VERSION", ",", "\"Cannot merge a v{} config into a v{} config.\"", ".", "format", "(", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.roi_heads.PointRendROIHeads._load_from_state_dict": [[16, 35], ["local_metadata.get", "logging.getLogger", "logging.getLogger.warning", "list", "state_dict.keys", "k.startswith", "k.startswith", "k.replace", "k.replace"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.data.catalog._MetadataCatalog.list"], ["        ", "super", "(", "CombinedROIHeads", ",", "self", ")", ".", "__init__", "(", "heads", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "if", "cfg", ".", "MODEL", ".", "MASK_ON", "and", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "self", ".", "mask", ".", "feature_extractor", "=", "self", ".", "box", ".", "feature_extractor", "\n", "", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "and", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", ":", "\n", "            ", "self", ".", "keypoint", ".", "feature_extractor", "=", "self", ".", "box", ".", "feature_extractor", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "features", ",", "proposals", ",", "targets", "=", "None", ")", ":", "\n", "        ", "losses", "=", "{", "}", "\n", "# TODO rename x to roi_box_features, if it doesn't increase memory consumption", "\n", "x", ",", "detections", ",", "loss_box", "=", "self", ".", "box", "(", "features", ",", "proposals", ",", "targets", ")", "\n", "losses", ".", "update", "(", "loss_box", ")", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "MASK_ON", ":", "\n", "            ", "mask_features", "=", "features", "\n", "# optimization: during training, if we share the feature extractor between", "\n", "# the box and the mask heads, then we can reuse the features already computed", "\n", "if", "(", "\n", "self", ".", "training", "\n", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_MASK_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.roi_heads.PointRendROIHeads._init_mask_head": [[36, 50], ["super()._init_mask_head", "logging.getLogger", "logging.getLogger.warning", "cfg.defrost", "cfg.freeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.roi_heads.PointRendROIHeads._init_mask_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.blocks.CNNBlockBase.freeze"], ["                ", "mask_features", "=", "x", "\n", "# During training, self.box() will return the unaltered proposals as \"detections\"", "\n", "# this makes the API consistent during training and testing", "\n", "", "x", ",", "detections", ",", "loss_mask", "=", "self", ".", "mask", "(", "mask_features", ",", "detections", ",", "targets", ")", "\n", "losses", ".", "update", "(", "loss_mask", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ":", "\n", "            ", "keypoint_features", "=", "features", "\n", "# optimization: during training, if we share the feature extractor between", "\n", "# the box and the mask heads, then we can reuse the features already computed", "\n", "if", "(", "\n", "self", ".", "training", "\n", "and", "self", ".", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "SHARE_BOX_FEATURE_EXTRACTOR", "\n", ")", ":", "\n", "                ", "keypoint_features", "=", "x", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features._as_tensor": [[19, 26], ["torch.as_tensor", "isinstance", "all", "torch.stack", "isinstance"], "function", ["None"], ["def", "_as_tensor", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    An equivalent of `torch.as_tensor`, but works under tracing.\n    \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "[", "isinstance", "(", "t", ",", "torch", ".", "Tensor", ")", "for", "t", "in", "x", "]", ")", ":", "\n", "        ", "return", "torch", ".", "stack", "(", "x", ")", "\n", "", "return", "torch", ".", "as_tensor", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample": [[28, 52], ["torch.nn.functional.grid_sample", "point_coords.unsqueeze.dim", "point_coords.unsqueeze.unsqueeze", "output.squeeze.squeeze"], "function", ["None"], ["", "def", "point_sample", "(", "input", ",", "point_coords", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    A wrapper around :function:`torch.nn.functional.grid_sample` to support 3D point_coords tensors.\n    Unlike :function:`torch.nn.functional.grid_sample` it assumes `point_coords` to lie inside\n    [0, 1] x [0, 1] square.\n\n    Args:\n        input (Tensor): A tensor of shape (N, C, H, W) that contains features map on a H x W grid.\n        point_coords (Tensor): A tensor of shape (N, P, 2) or (N, Hgrid, Wgrid, 2) that contains\n        [0, 1] x [0, 1] normalized point coordinates.\n\n    Returns:\n        output (Tensor): A tensor of shape (N, C, P) or (N, C, Hgrid, Wgrid) that contains\n            features for points in `point_coords`. The features are obtained via bilinear\n            interplation from `input` the same way as :function:`torch.nn.functional.grid_sample`.\n    \"\"\"", "\n", "add_dim", "=", "False", "\n", "if", "point_coords", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "add_dim", "=", "True", "\n", "point_coords", "=", "point_coords", ".", "unsqueeze", "(", "2", ")", "\n", "", "output", "=", "F", ".", "grid_sample", "(", "input", ",", "2.0", "*", "point_coords", "-", "1.0", ",", "**", "kwargs", ")", "\n", "if", "add_dim", ":", "\n", "        ", "output", "=", "output", ".", "squeeze", "(", "3", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.generate_regular_grid_point_coords": [[54, 70], ["torch.tensor", "torch.nn.functional.affine_grid", "F.affine_grid.view().expand", "torch.Size", "F.affine_grid.view"], "function", ["None"], ["", "def", "generate_regular_grid_point_coords", "(", "R", ",", "side_size", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Generate regular square grid of points in [0, 1] x [0, 1] coordinate space.\n\n    Args:\n        R (int): The number of grids to sample, one for each region.\n        side_size (int): The side size of the regular grid.\n        device (torch.device): Desired device of returned tensor.\n\n    Returns:\n        (Tensor): A tensor of shape (R, side_size^2, 2) that contains coordinates\n            for the regular grids.\n    \"\"\"", "\n", "aff", "=", "torch", ".", "tensor", "(", "[", "[", "[", "0.5", ",", "0", ",", "0.5", "]", ",", "[", "0", ",", "0.5", ",", "0.5", "]", "]", "]", ",", "device", "=", "device", ")", "\n", "r", "=", "F", ".", "affine_grid", "(", "aff", ",", "torch", ".", "Size", "(", "(", "1", ",", "1", ",", "side_size", ",", "side_size", ")", ")", ",", "align_corners", "=", "False", ")", "\n", "return", "r", ".", "view", "(", "1", ",", "-", "1", ",", "2", ")", ".", "expand", "(", "R", ",", "-", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_uncertain_point_coords_with_randomness": [[72, 126], ["int", "torch.rand", "point_features.point_sample", "uncertainty_func", "int", "[].view", "torch.topk", "torch.arange", "detectron2.layers.cat", "detectron2.layers.cat.view", "torch.rand", "idx.view"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "def", "get_uncertain_point_coords_with_randomness", "(", "\n", "coarse_logits", ",", "uncertainty_func", ",", "num_points", ",", "oversample_ratio", ",", "importance_sample_ratio", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Sample points in [0, 1] x [0, 1] coordinate space based on their uncertainty. The unceratinties\n        are calculated for each point using 'uncertainty_func' function that takes point's logit\n        prediction as input.\n    See PointRend paper for details.\n\n    Args:\n        coarse_logits (Tensor): A tensor of shape (N, C, Hmask, Wmask) or (N, 1, Hmask, Wmask) for\n            class-specific or class-agnostic prediction.\n        uncertainty_func: A function that takes a Tensor of shape (N, C, P) or (N, 1, P) that\n            contains logit predictions for P points and returns their uncertainties as a Tensor of\n            shape (N, 1, P).\n        num_points (int): The number of points P to sample.\n        oversample_ratio (int): Oversampling parameter.\n        importance_sample_ratio (float): Ratio of points that are sampled via importnace sampling.\n\n    Returns:\n        point_coords (Tensor): A tensor of shape (N, P, 2) that contains the coordinates of P\n            sampled points.\n    \"\"\"", "\n", "assert", "oversample_ratio", ">=", "1", "\n", "assert", "importance_sample_ratio", "<=", "1", "and", "importance_sample_ratio", ">=", "0", "\n", "num_boxes", "=", "coarse_logits", ".", "shape", "[", "0", "]", "\n", "num_sampled", "=", "int", "(", "num_points", "*", "oversample_ratio", ")", "\n", "point_coords", "=", "torch", ".", "rand", "(", "num_boxes", ",", "num_sampled", ",", "2", ",", "device", "=", "coarse_logits", ".", "device", ")", "\n", "point_logits", "=", "point_sample", "(", "coarse_logits", ",", "point_coords", ",", "align_corners", "=", "False", ")", "\n", "# It is crucial to calculate uncertainty based on the sampled prediction value for the points.", "\n", "# Calculating uncertainties of the coarse predictions first and sampling them for points leads", "\n", "# to incorrect results.", "\n", "# To illustrate this: assume uncertainty_func(logits)=-abs(logits), a sampled point between", "\n", "# two coarse predictions with -1 and 1 logits has 0 logits, and therefore 0 uncertainty value.", "\n", "# However, if we calculate uncertainties for the coarse predictions first,", "\n", "# both will have -1 uncertainty, and the sampled point will get -1 uncertainty.", "\n", "point_uncertainties", "=", "uncertainty_func", "(", "point_logits", ")", "\n", "num_uncertain_points", "=", "int", "(", "importance_sample_ratio", "*", "num_points", ")", "\n", "num_random_points", "=", "num_points", "-", "num_uncertain_points", "\n", "idx", "=", "torch", ".", "topk", "(", "point_uncertainties", "[", ":", ",", "0", ",", ":", "]", ",", "k", "=", "num_uncertain_points", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "shift", "=", "num_sampled", "*", "torch", ".", "arange", "(", "num_boxes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "coarse_logits", ".", "device", ")", "\n", "idx", "+=", "shift", "[", ":", ",", "None", "]", "\n", "point_coords", "=", "point_coords", ".", "view", "(", "-", "1", ",", "2", ")", "[", "idx", ".", "view", "(", "-", "1", ")", ",", ":", "]", ".", "view", "(", "\n", "num_boxes", ",", "num_uncertain_points", ",", "2", "\n", ")", "\n", "if", "num_random_points", ">", "0", ":", "\n", "        ", "point_coords", "=", "cat", "(", "\n", "[", "\n", "point_coords", ",", "\n", "torch", ".", "rand", "(", "num_boxes", ",", "num_random_points", ",", "2", ",", "device", "=", "coarse_logits", ".", "device", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "", "return", "point_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_uncertain_point_coords_on_grid": [[128, 153], ["min", "torch.zeros", "float", "float", "torch.topk", "uncertainty_map.view"], "function", ["None"], ["", "def", "get_uncertain_point_coords_on_grid", "(", "uncertainty_map", ",", "num_points", ")", ":", "\n", "    ", "\"\"\"\n    Find `num_points` most uncertain points from `uncertainty_map` grid.\n\n    Args:\n        uncertainty_map (Tensor): A tensor of shape (N, 1, H, W) that contains uncertainty\n            values for a set of points on a regular H x W grid.\n        num_points (int): The number of points P to select.\n\n    Returns:\n        point_indices (Tensor): A tensor of shape (N, P) that contains indices from\n            [0, H x W) of the most uncertain points.\n        point_coords (Tensor): A tensor of shape (N, P, 2) that contains [0, 1] x [0, 1] normalized\n            coordinates of the most uncertain points from the H x W grid.\n    \"\"\"", "\n", "R", ",", "_", ",", "H", ",", "W", "=", "uncertainty_map", ".", "shape", "\n", "h_step", "=", "1.0", "/", "float", "(", "H", ")", "\n", "w_step", "=", "1.0", "/", "float", "(", "W", ")", "\n", "\n", "num_points", "=", "min", "(", "H", "*", "W", ",", "num_points", ")", "\n", "point_indices", "=", "torch", ".", "topk", "(", "uncertainty_map", ".", "view", "(", "R", ",", "H", "*", "W", ")", ",", "k", "=", "num_points", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "point_coords", "=", "torch", ".", "zeros", "(", "R", ",", "num_points", ",", "2", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "uncertainty_map", ".", "device", ")", "\n", "point_coords", "[", ":", ",", ":", ",", "0", "]", "=", "w_step", "/", "2.0", "+", "(", "point_indices", "%", "W", ")", ".", "to", "(", "torch", ".", "float", ")", "*", "w_step", "\n", "point_coords", "[", ":", ",", ":", ",", "1", "]", "=", "h_step", "/", "2.0", "+", "(", "point_indices", "//", "W", ")", ".", "to", "(", "torch", ".", "float", ")", "*", "h_step", "\n", "return", "point_indices", ",", "point_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample_fine_grained_features": [[155, 199], ["detectron2.structures.Boxes.cat", "point_features.get_point_coords_wrt_image", "torch.split", "enumerate", "b.tensor.size", "enumerate", "point_features.append", "detectron2.layers.cat", "point_features_per_image.append", "detectron2.layers.cat", "point_features._as_tensor", "scale.to", "point_sample().squeeze().transpose", "point_sample().squeeze", "point_features.point_sample", "feature_map[].unsqueeze", "point_coords_scaled.unsqueeze"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_point_coords_wrt_image", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features._as_tensor", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.keypoint.Keypoints.transpose", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample"], ["", "def", "point_sample_fine_grained_features", "(", "features_list", ",", "feature_scales", ",", "boxes", ",", "point_coords", ")", ":", "\n", "    ", "\"\"\"\n    Get features from feature maps in `features_list` that correspond to specific point coordinates\n        inside each bounding box from `boxes`.\n\n    Args:\n        features_list (list[Tensor]): A list of feature map tensors to get features from.\n        feature_scales (list[float]): A list of scales for tensors in `features_list`.\n        boxes (list[Boxes]): A list of I Boxes  objects that contain R_1 + ... + R_I = R boxes all\n            together.\n        point_coords (Tensor): A tensor of shape (R, P, 2) that contains\n            [0, 1] x [0, 1] box-normalized coordinates of the P sampled points.\n\n    Returns:\n        point_features (Tensor): A tensor of shape (R, C, P) that contains features sampled\n            from all features maps in feature_list for P sampled points for all R boxes in `boxes`.\n        point_coords_wrt_image (Tensor): A tensor of shape (R, P, 2) that contains image-level\n            coordinates of P points.\n    \"\"\"", "\n", "cat_boxes", "=", "Boxes", ".", "cat", "(", "boxes", ")", "\n", "num_boxes", "=", "[", "b", ".", "tensor", ".", "size", "(", "0", ")", "for", "b", "in", "boxes", "]", "\n", "\n", "point_coords_wrt_image", "=", "get_point_coords_wrt_image", "(", "cat_boxes", ".", "tensor", ",", "point_coords", ")", "\n", "split_point_coords_wrt_image", "=", "torch", ".", "split", "(", "point_coords_wrt_image", ",", "num_boxes", ")", "\n", "\n", "point_features", "=", "[", "]", "\n", "for", "idx_img", ",", "point_coords_wrt_image_per_image", "in", "enumerate", "(", "split_point_coords_wrt_image", ")", ":", "\n", "        ", "point_features_per_image", "=", "[", "]", "\n", "for", "idx_feature", ",", "feature_map", "in", "enumerate", "(", "features_list", ")", ":", "\n", "            ", "h", ",", "w", "=", "feature_map", ".", "shape", "[", "-", "2", ":", "]", "\n", "scale", "=", "_as_tensor", "(", "[", "w", ",", "h", "]", ")", "/", "feature_scales", "[", "idx_feature", "]", "\n", "point_coords_scaled", "=", "point_coords_wrt_image_per_image", "/", "scale", ".", "to", "(", "feature_map", ".", "device", ")", "\n", "point_features_per_image", ".", "append", "(", "\n", "point_sample", "(", "\n", "feature_map", "[", "idx_img", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "point_coords_scaled", ".", "unsqueeze", "(", "0", ")", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n", ".", "squeeze", "(", "0", ")", "\n", ".", "transpose", "(", "1", ",", "0", ")", "\n", ")", "\n", "", "point_features", ".", "append", "(", "cat", "(", "point_features_per_image", ",", "dim", "=", "1", ")", ")", "\n", "\n", "", "return", "cat", "(", "point_features", ",", "dim", "=", "0", ")", ",", "point_coords_wrt_image", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_point_coords_wrt_image": [[201, 226], ["torch.no_grad", "point_coords.clone"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone"], ["", "def", "get_point_coords_wrt_image", "(", "boxes_coords", ",", "point_coords", ")", ":", "\n", "    ", "\"\"\"\n    Convert box-normalized [0, 1] x [0, 1] point cooordinates to image-level coordinates.\n\n    Args:\n        boxes_coords (Tensor): A tensor of shape (R, 4) that contains bounding boxes.\n            coordinates.\n        point_coords (Tensor): A tensor of shape (R, P, 2) that contains\n            [0, 1] x [0, 1] box-normalized coordinates of the P sampled points.\n\n    Returns:\n        point_coords_wrt_image (Tensor): A tensor of shape (R, P, 2) that contains\n            image-normalized coordinates of P sampled points.\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "point_coords_wrt_image", "=", "point_coords", ".", "clone", "(", ")", "\n", "point_coords_wrt_image", "[", ":", ",", ":", ",", "0", "]", "=", "point_coords_wrt_image", "[", ":", ",", ":", ",", "0", "]", "*", "(", "\n", "boxes_coords", "[", ":", ",", "None", ",", "2", "]", "-", "boxes_coords", "[", ":", ",", "None", ",", "0", "]", "\n", ")", "\n", "point_coords_wrt_image", "[", ":", ",", ":", ",", "1", "]", "=", "point_coords_wrt_image", "[", ":", ",", ":", ",", "1", "]", "*", "(", "\n", "boxes_coords", "[", ":", ",", "None", ",", "3", "]", "-", "boxes_coords", "[", ":", ",", "None", ",", "1", "]", "\n", ")", "\n", "point_coords_wrt_image", "[", ":", ",", ":", ",", "0", "]", "+=", "boxes_coords", "[", ":", ",", "None", ",", "0", "]", "\n", "point_coords_wrt_image", "[", ":", ",", ":", ",", "1", "]", "+=", "boxes_coords", "[", ":", ",", "None", ",", "1", "]", "\n", "", "return", "point_coords_wrt_image", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.StandardPointHead.__init__": [[106, 142], ["torch.nn.Module.__init__", "range", "torch.nn.Conv1d", "torch.nn.init.normal_", "torch.nn.Conv1d", "point_head.StandardPointHead.add_module", "point_head.StandardPointHead.fc_layers.append", "fvcore.c2_msra_fill", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "        ", "\"\"\"\n        The following attributes are parsed from config:\n            fc_dim: the output dimension of each FC layers\n            num_fc: the number of FC layers\n            coarse_pred_each_layer: if True, coarse prediction features are concatenated to each\n                layer's input\n        \"\"\"", "\n", "super", "(", "StandardPointHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# fmt: off", "\n", "num_classes", "=", "cfg", ".", "MODEL", ".", "POINT_HEAD", ".", "NUM_CLASSES", "\n", "fc_dim", "=", "cfg", ".", "MODEL", ".", "POINT_HEAD", ".", "FC_DIM", "\n", "num_fc", "=", "cfg", ".", "MODEL", ".", "POINT_HEAD", ".", "NUM_FC", "\n", "cls_agnostic_mask", "=", "cfg", ".", "MODEL", ".", "POINT_HEAD", ".", "CLS_AGNOSTIC_MASK", "\n", "self", ".", "coarse_pred_each_layer", "=", "cfg", ".", "MODEL", ".", "POINT_HEAD", ".", "COARSE_PRED_EACH_LAYER", "\n", "input_channels", "=", "input_shape", ".", "channels", "\n", "# fmt: on", "\n", "\n", "fc_dim_in", "=", "input_channels", "+", "num_classes", "\n", "self", ".", "fc_layers", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "num_fc", ")", ":", "\n", "            ", "fc", "=", "nn", ".", "Conv1d", "(", "fc_dim_in", ",", "fc_dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "self", ".", "add_module", "(", "\"fc{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "fc", ")", "\n", "self", ".", "fc_layers", ".", "append", "(", "fc", ")", "\n", "fc_dim_in", "=", "fc_dim", "\n", "fc_dim_in", "+=", "num_classes", "if", "self", ".", "coarse_pred_each_layer", "else", "0", "\n", "\n", "", "num_mask_classes", "=", "1", "if", "cls_agnostic_mask", "else", "num_classes", "\n", "self", ".", "predictor", "=", "nn", ".", "Conv1d", "(", "fc_dim_in", ",", "num_mask_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "for", "layer", "in", "self", ".", "fc_layers", ":", "\n", "            ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "# use normal distribution initialization for mask prediction layer", "\n", "", "nn", ".", "init", ".", "normal_", "(", "self", ".", "predictor", ".", "weight", ",", "std", "=", "0.001", ")", "\n", "if", "self", ".", "predictor", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "predictor", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.StandardPointHead.forward": [[143, 150], ["torch.cat", "point_head.StandardPointHead.predictor", "torch.nn.functional.relu", "layer", "detectron2.layers.cat"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat"], ["", "", "def", "forward", "(", "self", ",", "fine_grained_features", ",", "coarse_features", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "fine_grained_features", ",", "coarse_features", ")", ",", "dim", "=", "1", ")", "\n", "for", "layer", "in", "self", ".", "fc_layers", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "layer", "(", "x", ")", ")", "\n", "if", "self", ".", "coarse_pred_each_layer", ":", "\n", "                ", "x", "=", "cat", "(", "(", "x", ",", "coarse_features", ")", ",", "dim", "=", "1", ")", "\n", "", "", "return", "self", ".", "predictor", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.roi_mask_point_loss": [[22, 97], ["detectron2.layers.cat", "detectron2.utils.events.get_event_storage().put_scalar", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.no_grad", "mask_logits.size", "len", "detectron2.layers.cat.numel", "torch.arange", "detectron2.layers.cat", "detectron2.layers.cat.to", "mask_accurate.nonzero().size", "mask_accurate.numel", "detectron2.layers.cat.to", "mask_logits.size", "isinstance", "torch.tensor", "len", "detectron2.layers.cat.append", "mask_logits.sum", "detectron2.utils.events.get_event_storage", "len", "instances_per_image.gt_classes.to", "detectron2.layers.cat.append", "point_features.point_sample().squeeze", "mask_accurate.nonzero", "point_features.point_sample", "len", "gt_bit_masks.to().unsqueeze", "gt_bit_masks.to"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.utils.events.get_event_storage", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "roi_mask_point_loss", "(", "mask_logits", ",", "instances", ",", "points_coord", ")", ":", "\n", "    ", "\"\"\"\n    Compute the point-based loss for instance segmentation mask predictions.\n\n    Args:\n        mask_logits (Tensor): A tensor of shape (R, C, P) or (R, 1, P) for class-specific or\n            class-agnostic, where R is the total number of predicted masks in all images, C is the\n            number of foreground classes, and P is the number of points sampled for each mask.\n            The values are logits.\n        instances (list[Instances]): A list of N Instances, where N is the number of images\n            in the batch. These instances are in 1:1 correspondence with the `mask_logits`. So, i_th\n            elememt of the list contains R_i objects and R_1 + ... + R_N is equal to R.\n            The ground-truth labels (class, box, mask, ...) associated with each instance are stored\n            in fields.\n        points_coords (Tensor): A tensor of shape (R, P, 2), where R is the total number of\n            predicted masks and P is the number of points for each mask. The coordinates are in\n            the image pixel coordinate space, i.e. [0, H] x [0, W].\n    Returns:\n        point_loss (Tensor): A scalar tensor containing the loss.\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "cls_agnostic_mask", "=", "mask_logits", ".", "size", "(", "1", ")", "==", "1", "\n", "total_num_masks", "=", "mask_logits", ".", "size", "(", "0", ")", "\n", "\n", "gt_classes", "=", "[", "]", "\n", "gt_mask_logits", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "instances_per_image", "in", "instances", ":", "\n", "            ", "if", "len", "(", "instances_per_image", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "assert", "isinstance", "(", "\n", "instances_per_image", ".", "gt_masks", ",", "BitMasks", "\n", ")", ",", "\"Point head works with GT in 'bitmask' format. Set INPUT.MASK_FORMAT to 'bitmask'.\"", "\n", "\n", "if", "not", "cls_agnostic_mask", ":", "\n", "                ", "gt_classes_per_image", "=", "instances_per_image", ".", "gt_classes", ".", "to", "(", "dtype", "=", "torch", ".", "int64", ")", "\n", "gt_classes", ".", "append", "(", "gt_classes_per_image", ")", "\n", "\n", "", "gt_bit_masks", "=", "instances_per_image", ".", "gt_masks", ".", "tensor", "\n", "h", ",", "w", "=", "instances_per_image", ".", "gt_masks", ".", "image_size", "\n", "scale", "=", "torch", ".", "tensor", "(", "[", "w", ",", "h", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "gt_bit_masks", ".", "device", ")", "\n", "points_coord_grid_sample_format", "=", "(", "\n", "points_coord", "[", "idx", ":", "idx", "+", "len", "(", "instances_per_image", ")", "]", "/", "scale", "\n", ")", "\n", "idx", "+=", "len", "(", "instances_per_image", ")", "\n", "gt_mask_logits", ".", "append", "(", "\n", "point_sample", "(", "\n", "gt_bit_masks", ".", "to", "(", "torch", ".", "float32", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "points_coord_grid_sample_format", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ".", "squeeze", "(", "1", ")", "\n", ")", "\n", "\n", "", "", "if", "len", "(", "gt_mask_logits", ")", "==", "0", ":", "\n", "        ", "return", "mask_logits", ".", "sum", "(", ")", "*", "0", "\n", "\n", "", "gt_mask_logits", "=", "cat", "(", "gt_mask_logits", ")", "\n", "assert", "gt_mask_logits", ".", "numel", "(", ")", ">", "0", ",", "gt_mask_logits", ".", "shape", "\n", "\n", "if", "cls_agnostic_mask", ":", "\n", "        ", "mask_logits", "=", "mask_logits", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "indices", "=", "torch", ".", "arange", "(", "total_num_masks", ")", "\n", "gt_classes", "=", "cat", "(", "gt_classes", ",", "dim", "=", "0", ")", "\n", "mask_logits", "=", "mask_logits", "[", "indices", ",", "gt_classes", "]", "\n", "\n", "# Log the training accuracy (using gt classes and 0.0 threshold for the logits)", "\n", "", "mask_accurate", "=", "(", "mask_logits", ">", "0.0", ")", "==", "gt_mask_logits", ".", "to", "(", "dtype", "=", "torch", ".", "uint8", ")", "\n", "mask_accuracy", "=", "mask_accurate", ".", "nonzero", "(", ")", ".", "size", "(", "0", ")", "/", "mask_accurate", ".", "numel", "(", ")", "\n", "get_event_storage", "(", ")", ".", "put_scalar", "(", "\"point_rend/accuracy\"", ",", "mask_accuracy", ")", "\n", "\n", "point_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "mask_logits", ",", "gt_mask_logits", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ",", "reduction", "=", "\"mean\"", "\n", ")", "\n", "return", "point_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.build_point_head": [[152, 158], ["POINT_HEAD_REGISTRY.get"], "function", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["", "", "def", "build_point_head", "(", "cfg", ",", "input_channels", ")", ":", "\n", "    ", "\"\"\"\n    Build a point head defined by `cfg.MODEL.POINT_HEAD.NAME`.\n    \"\"\"", "\n", "head_name", "=", "cfg", ".", "MODEL", ".", "POINT_HEAD", ".", "NAME", "\n", "return", "POINT_HEAD_REGISTRY", ".", "get", "(", "head_name", ")", "(", "cfg", ",", "input_channels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.__init__": [[43, 52], ["torch.nn.Module.__init__", "semantic_seg.PointRendSemSegHead._init_point_head", "detectron2.modeling.SEM_SEG_HEADS_REGISTRY.get"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead._init_point_head", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.model_zoo.model_zoo.get"], ["        ", "\"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            sem_seg_head: a module that predicts semantic segmentation from backbone features\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "sem_seg_head", "=", "sem_seg_head", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead._init_point_head": [[53, 67], ["numpy.sum", "point_head.build_point_head", "detectron2.layers.ShapeSpec", "input_shape.items"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_head.build_point_head"], ["self", ".", "register_buffer", "(", "\"pixel_mean\"", ",", "torch", ".", "Tensor", "(", "pixel_mean", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "self", ".", "register_buffer", "(", "\"pixel_std\"", ",", "torch", ".", "Tensor", "(", "pixel_std", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ",", "False", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "sem_seg_head", "=", "build_sem_seg_head", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"sem_seg_head\"", ":", "sem_seg_head", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "}", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.PointRendSemSegHead.forward": [[68, 136], ["semantic_seg.PointRendSemSegHead.coarse_sem_seg_head.layers", "semantic_seg.PointRendSemSegHead.coarse_sem_seg_head.losses", "point_features.point_sample", "detectron2.layers.cat", "semantic_seg.PointRendSemSegHead.point_head", "point_features.point_sample().squeeze().to", "torch.nn.functional.cross_entropy", "semantic_seg.PointRendSemSegHead.clone", "range", "torch.no_grad", "point_features.get_uncertain_point_coords_with_randomness", "torch.nn.functional.interpolate", "semantic_seg.calculate_uncertainty", "point_features.get_uncertain_point_coords_on_grid", "detectron2.layers.cat", "point_features.point_sample", "semantic_seg.PointRendSemSegHead.point_head", "point_indices.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "sem_seg_logits.reshape().scatter_().view.reshape().scatter_().view.reshape().scatter_().view", "point_features.point_sample", "point_features.point_sample().squeeze", "point_features.point_sample", "point_indices.unsqueeze().expand.unsqueeze().expand.unsqueeze", "sem_seg_logits.reshape().scatter_().view.reshape().scatter_().view.reshape().scatter_", "point_features.point_sample", "targets.unsqueeze().to", "sem_seg_logits.reshape().scatter_().view.reshape().scatter_().view.reshape", "targets.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3PlusHead.layers", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.deeplab.semantic_seg.DeepLabV3Head.losses", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cross_entropy", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clone", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_uncertain_point_coords_with_randomness", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.misc.interpolate", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.calculate_uncertainty", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.get_uncertain_point_coords_on_grid", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.layers.wrappers.cat", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.point_features.point_sample", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.chart_result.DensePoseChartResultQuantized.to"], ["def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pixel_mean", ".", "device", "\n", "\n", "", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper`.\n                Each item in the list contains the inputs for one image.\n\n                For now, each item in the list is a dict that contains:\n\n                   * \"image\": Tensor, image in (C, H, W) format.\n                   * \"sem_seg\": semantic segmentation ground truth\n                   * Other information that's included in the original dicts, such as:\n                     \"height\", \"width\" (int): the output resolution of the model (may be different\n                     from input resolution), used in inference.\n\n\n        Returns:\n            list[dict]:\n              Each dict is the output for one input image.\n              The dict contains one key \"sem_seg\" whose value is a\n              Tensor that represents the\n              per-pixel segmentation prediced by the head.\n              The prediction has shape KxHxW that represents the logits of\n              each class for each pixel.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "\"sem_seg\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "targets", "=", "[", "x", "[", "\"sem_seg\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "targets", "=", "ImageList", ".", "from_tensors", "(", "\n", "targets", ",", "self", ".", "backbone", ".", "size_divisibility", ",", "self", ".", "sem_seg_head", ".", "ignore_value", "\n", ")", ".", "tensor", "\n", "", "else", ":", "\n", "            ", "targets", "=", "None", "\n", "", "results", ",", "losses", "=", "self", ".", "sem_seg_head", "(", "features", ",", "targets", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "losses", "\n", "\n", "", "processed_results", "=", "[", "]", "\n", "for", "result", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ")", "\n", "r", "=", "sem_seg_postprocess", "(", "result", ",", "image_size", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"sem_seg\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "\n", "\n", "", "", "def", "build_sem_seg_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a semantic segmentation head from `cfg.MODEL.SEM_SEG_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "SEM_SEG_HEAD", ".", "NAME", "\n", "return", "SEM_SEG_HEADS_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "\n", "\n", "", "@", "SEM_SEG_HEADS_REGISTRY", ".", "register", "(", ")", "\n", "class", "SemSegFPNHead", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.semantic_seg.calculate_uncertainty": [[19, 34], ["torch.topk"], "function", ["None"], ["\n", "\n", "SEM_SEG_HEADS_REGISTRY", "=", "Registry", "(", "\"SEM_SEG_HEADS\"", ")", "\n", "SEM_SEG_HEADS_REGISTRY", ".", "__doc__", "=", "\"\"\"\nRegistry for semantic segmentation heads, which make semantic segmentation predictions\nfrom feature maps.\n\"\"\"", "\n", "\n", "\n", "@", "META_ARCH_REGISTRY", ".", "register", "(", ")", "\n", "class", "SemanticSegmentor", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Main class for semantic segmentation architectures.\n    \"\"\"", "\n", "\n", "@", "configurable", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__": [[27, 42], ["fvcore.transforms.transform.Transform.__init__", "color_augmentation.ColorAugSSDTransform._set_attributes", "locals"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "img_format", ",", "\n", "brightness_delta", "=", "32", ",", "\n", "contrast_low", "=", "0.5", ",", "\n", "contrast_high", "=", "1.5", ",", "\n", "saturation_low", "=", "0.5", ",", "\n", "saturation_high", "=", "1.5", ",", "\n", "hue_delta", "=", "18", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "img_format", "in", "[", "\"BGR\"", ",", "\"RGB\"", "]", "\n", "self", ".", "is_rgb", "=", "img_format", "==", "\"RGB\"", "\n", "del", "img_format", "\n", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_coords": [[43, 45], ["None"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_segmentation": [[46, 48], ["None"], "methods", ["None"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.apply_image": [[49, 64], ["color_augmentation.ColorAugSSDTransform.brightness", "random.randrange", "color_augmentation.ColorAugSSDTransform.contrast", "color_augmentation.ColorAugSSDTransform.saturation", "color_augmentation.ColorAugSSDTransform.hue", "color_augmentation.ColorAugSSDTransform.saturation", "color_augmentation.ColorAugSSDTransform.hue", "color_augmentation.ColorAugSSDTransform.contrast"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.brightness", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.contrast", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.saturation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.hue", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.saturation", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.hue", "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.contrast"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "is_rgb", ":", "\n", "            ", "img", "=", "img", "[", ":", ",", ":", ",", "[", "2", ",", "1", ",", "0", "]", "]", "\n", "", "img", "=", "self", ".", "brightness", "(", "img", ")", "\n", "if", "random", ".", "randrange", "(", "2", ")", ":", "\n", "            ", "img", "=", "self", ".", "contrast", "(", "img", ")", "\n", "img", "=", "self", ".", "saturation", "(", "img", ")", "\n", "img", "=", "self", ".", "hue", "(", "img", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "self", ".", "saturation", "(", "img", ")", "\n", "img", "=", "self", ".", "hue", "(", "img", ")", "\n", "img", "=", "self", ".", "contrast", "(", "img", ")", "\n", "", "if", "self", ".", "is_rgb", ":", "\n", "            ", "img", "=", "img", "[", ":", ",", ":", ",", "[", "2", ",", "1", ",", "0", "]", "]", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert": [[65, 69], ["numpy.clip", "numpy.clip.astype", "numpy.clip.astype"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.structures.boxes.Boxes.clip"], ["", "def", "convert", "(", "self", ",", "img", ",", "alpha", "=", "1", ",", "beta", "=", "0", ")", ":", "\n", "        ", "img", "=", "img", ".", "astype", "(", "np", ".", "float32", ")", "*", "alpha", "+", "beta", "\n", "img", "=", "np", ".", "clip", "(", "img", ",", "0", ",", "255", ")", "\n", "return", "img", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.brightness": [[70, 76], ["random.randrange", "color_augmentation.ColorAugSSDTransform.convert", "random.uniform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "brightness", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "random", ".", "randrange", "(", "2", ")", ":", "\n", "            ", "return", "self", ".", "convert", "(", "\n", "img", ",", "beta", "=", "random", ".", "uniform", "(", "-", "self", ".", "brightness_delta", ",", "self", ".", "brightness_delta", ")", "\n", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.contrast": [[77, 81], ["random.randrange", "color_augmentation.ColorAugSSDTransform.convert", "random.uniform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "contrast", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "random", ".", "randrange", "(", "2", ")", ":", "\n", "            ", "return", "self", ".", "convert", "(", "img", ",", "alpha", "=", "random", ".", "uniform", "(", "self", ".", "contrast_low", ",", "self", ".", "contrast_high", ")", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.saturation": [[82, 90], ["random.randrange", "cv2.cvtColor", "color_augmentation.ColorAugSSDTransform.convert", "cv2.cvtColor", "random.uniform"], "methods", ["home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.convert"], ["", "def", "saturation", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "random", ".", "randrange", "(", "2", ")", ":", "\n", "            ", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2HSV", ")", "\n", "img", "[", ":", ",", ":", ",", "1", "]", "=", "self", ".", "convert", "(", "\n", "img", "[", ":", ",", ":", ",", "1", "]", ",", "alpha", "=", "random", ".", "uniform", "(", "self", ".", "saturation_low", ",", "self", ".", "saturation_high", ")", "\n", ")", "\n", "return", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_HSV2BGR", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.point_rend.color_augmentation.ColorAugSSDTransform.hue": [[91, 99], ["random.randrange", "cv2.cvtColor", "cv2.cvtColor", "img[].astype", "random.randint"], "methods", ["None"], ["", "def", "hue", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "random", ".", "randrange", "(", "2", ")", ":", "\n", "            ", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2HSV", ")", "\n", "img", "[", ":", ",", ":", ",", "0", "]", "=", "(", "\n", "img", "[", ":", ",", ":", ",", "0", "]", ".", "astype", "(", "int", ")", "+", "random", ".", "randint", "(", "-", "self", ".", "hue_delta", ",", "self", ".", "hue_delta", ")", "\n", ")", "%", "180", "\n", "return", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_HSV2BGR", ")", "\n", "", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Jia-Research-Lab_SA-AutoAug.FCOS.setup.get_extensions": [[27, 64], ["os.path.join", "glob.glob", "glob.glob", "glob.glob", "os.path.join", "os.path.join", "os.path.join", "extension", "torch.cuda.is_available", "os.getenv"], "function", ["None"], ["\n", "extra_compile_args", "=", "{", "\"cxx\"", ":", "[", "]", "}", "\n", "define_macros", "=", "[", "]", "\n", "\n", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "CUDA_HOME", "is", "not", "None", ")", "or", "os", ".", "getenv", "(", "\"FORCE_CUDA\"", ",", "\"0\"", ")", "==", "\"1\"", ":", "\n", "        ", "extension", "=", "CUDAExtension", "\n", "sources", "+=", "source_cuda", "\n", "define_macros", "+=", "[", "(", "\"WITH_CUDA\"", ",", "None", ")", "]", "\n", "extra_compile_args", "[", "\"nvcc\"", "]", "=", "[", "\n", "\"-DCUDA_HAS_FP16=1\"", ",", "\n", "\"-D__CUDA_NO_HALF_OPERATORS__\"", ",", "\n", "\"-D__CUDA_NO_HALF_CONVERSIONS__\"", ",", "\n", "\"-D__CUDA_NO_HALF2_OPERATORS__\"", ",", "\n", "]", "\n", "\n", "", "sources", "=", "[", "os", ".", "path", ".", "join", "(", "extensions_dir", ",", "s", ")", "for", "s", "in", "sources", "]", "\n", "\n", "include_dirs", "=", "[", "extensions_dir", "]", "\n", "\n", "ext_modules", "=", "[", "\n", "extension", "(", "\n", "\"maskrcnn_benchmark._C\"", ",", "\n", "sources", ",", "\n", "include_dirs", "=", "include_dirs", ",", "\n", "define_macros", "=", "define_macros", ",", "\n", "extra_compile_args", "=", "extra_compile_args", ",", "\n", ")", "\n", "]", "\n", "\n", "return", "ext_modules", "\n", "\n", "\n", "", "setup", "(", "\n", "name", "=", "\"maskrcnn_benchmark\"", ",", "\n", "version", "=", "\"0.1\"", ",", "\n", "author", "=", "\"fmassa\"", ",", "\n", "url", "=", "\"https://github.com/facebookresearch/maskrcnn-benchmark\"", ",", "\n", "description", "=", "\"object detection in pytorch\"", ",", "\n"]]}