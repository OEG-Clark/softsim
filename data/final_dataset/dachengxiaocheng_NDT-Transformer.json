{"home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.config.cfg_str": [[54, 62], ["globals", "name.startswith", "name.__contains__", "str", "globals"], "function", ["None"], ["def", "cfg_str", "(", ")", ":", "\n", "    ", "out_string", "=", "\"\"", "\n", "for", "name", "in", "globals", "(", ")", ":", "\n", "        ", "if", "not", "name", ".", "startswith", "(", "\"__\"", ")", "and", "not", "name", ".", "__contains__", "(", "\"cfg_str\"", ")", ":", "\n", "#print(name, \"=\", globals()[name])", "\n", "            ", "out_string", "=", "out_string", "+", "\"cfg.\"", "+", "name", "+", "\"=\"", "+", "str", "(", "globals", "(", ")", "[", "name", "]", ")", "+", "\"\\n\"", "\n", "", "", "return", "out_string", "\n", "", ""]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_queries_dict": [[9, 15], ["open", "pickle.load", "print"], "function", ["None"], ["def", "get_queries_dict", "(", "filename", ")", ":", "\n", "# key:{'query':file,'positives':[files],'negatives:[files], 'neighbors':[keys]}", "\n", "    ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "handle", ":", "\n", "        ", "queries", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "print", "(", "\"Queries Loaded.\"", ")", "\n", "return", "queries", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_sets_dict": [[17, 23], ["open", "pickle.load", "print"], "function", ["None"], ["", "", "def", "get_sets_dict", "(", "filename", ")", ":", "\n", "#[key_dataset:{key_pointcloud:{'query':file,'northing':value,'easting':value}},key_dataset:{key_pointcloud:{'query':file,'northing':value,'easting':value}}, ...}", "\n", "    ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "handle", ":", "\n", "        ", "trajectories", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "print", "(", "\"Trajectories Loaded.\"", ")", "\n", "return", "trajectories", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file": [[26, 37], ["numpy.fromfile", "numpy.reshape", "os.path.join", "scipy.ndimage.zoom", "float"], "function", ["None"], ["", "", "def", "load_pc_file", "(", "filename", ",", "number_points", "=", "2000", ")", ":", "\n", "#pc = np.loadtxt(os.path.join(cfg.DATASET_FOLDER, filename), delimiter=\",\", dtype=float)", "\n", "    ", "pc", "=", "np", ".", "fromfile", "(", "os", ".", "path", ".", "join", "(", "cfg", ".", "DATASET_FOLDER", ",", "filename", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "pc", "=", "np", ".", "reshape", "(", "pc", ",", "(", "pc", ".", "shape", "[", "0", "]", "//", "12", ",", "12", ")", ")", "\n", "\n", "if", "(", "pc", ".", "shape", "[", "0", "]", "!=", "number_points", ")", ":", "\n", "        ", "zoom", "=", "number_points", "/", "float", "(", "pc", ".", "shape", "[", "0", "]", ")", "\n", "pc", "=", "scipy", ".", "ndimage", ".", "zoom", "(", "pc", ",", "[", "zoom", ",", "1", "]", ",", "order", "=", "3", ",", "mode", "=", "'constant'", ",", "cval", "=", "0.0", ",", "prefilter", "=", "True", ")", "\n", "\n", "", "pc", "[", ":", ",", "3", ":", "12", "]", "=", "pc", "[", ":", ",", "3", ":", "12", "]", "*", "1000", "\n", "return", "pc", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files": [[39, 47], ["numpy.array", "loading_pointclouds.load_pc_file", "np.array.append"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file"], ["", "def", "load_pc_files", "(", "filenames", ")", ":", "\n", "    ", "pcs", "=", "[", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "# print(filename)", "\n", "        ", "pc", "=", "load_pc_file", "(", "filename", ")", "\n", "pcs", ".", "append", "(", "pc", ")", "\n", "", "pcs", "=", "np", ".", "array", "(", "pcs", ")", "\n", "return", "pcs", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.rotate_point_cloud": [[49, 71], ["numpy.zeros", "range", "numpy.cos", "numpy.sin", "numpy.array", "numpy.dot", "shape_pc.reshape", "numpy.random.uniform"], "function", ["None"], ["", "def", "rotate_point_cloud", "(", "batch_data", ")", ":", "\n", "    ", "\"\"\" Randomly rotate the point clouds to augument the dataset\n        rotation is per shape based along up direction\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    \"\"\"", "\n", "rotated_data", "=", "np", ".", "zeros", "(", "batch_data", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "k", "in", "range", "(", "batch_data", ".", "shape", "[", "0", "]", ")", ":", "\n", "#rotation_angle = np.random.uniform() * 2 * np.pi", "\n", "#-90 to 90", "\n", "        ", "rotation_angle", "=", "(", "np", ".", "random", ".", "uniform", "(", ")", "*", "np", ".", "pi", ")", "-", "np", ".", "pi", "/", "2.0", "\n", "cosval", "=", "np", ".", "cos", "(", "rotation_angle", ")", "\n", "sinval", "=", "np", ".", "sin", "(", "rotation_angle", ")", "\n", "rotation_matrix", "=", "np", ".", "array", "(", "[", "[", "cosval", ",", "-", "sinval", ",", "0", "]", ",", "\n", "[", "sinval", ",", "cosval", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "shape_pc", "=", "batch_data", "[", "k", ",", "...", "]", "\n", "rotated_data", "[", "k", ",", "...", "]", "=", "np", ".", "dot", "(", "\n", "shape_pc", ".", "reshape", "(", "(", "-", "1", ",", "3", ")", ")", ",", "rotation_matrix", ")", "\n", "", "return", "rotated_data", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.jitter_point_cloud": [[73, 85], ["numpy.clip", "numpy.random.randn"], "function", ["None"], ["", "def", "jitter_point_cloud", "(", "batch_data", ",", "sigma", "=", "0.005", ",", "clip", "=", "0.05", ")", ":", "\n", "    ", "\"\"\" Randomly jitter points. jittering is per point.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, jittered batch of point clouds\n    \"\"\"", "\n", "B", ",", "N", ",", "C", "=", "batch_data", ".", "shape", "\n", "assert", "(", "clip", ">", "0", ")", "\n", "jittered_data", "=", "np", ".", "clip", "(", "sigma", "*", "np", ".", "random", ".", "randn", "(", "B", ",", "N", ",", "C", ")", ",", "-", "1", "*", "clip", ",", "clip", ")", "\n", "jittered_data", "+=", "batch_data", "\n", "return", "jittered_data", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_query_tuple": [[87, 145], ["loading_pointclouds.load_pc_file", "random.shuffle", "range", "loading_pointclouds.load_pc_files", "loading_pointclouds.load_pc_files", "pos_files.append", "len", "random.shuffle", "range", "random.shuffle", "list", "random.shuffle", "loading_pointclouds.load_pc_file", "neg_files.append", "neg_indices.append", "neg_files.append", "neg_indices.append", "len", "neighbors.append", "len", "neg_files.append", "neg_indices.append", "neighbors.append", "set", "set", "numpy.array", "QUERY_DICT.keys"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file"], ["", "def", "get_query_tuple", "(", "dict_value", ",", "num_pos", ",", "num_neg", ",", "QUERY_DICT", ",", "hard_neg", "=", "[", "]", ",", "other_neg", "=", "False", ")", ":", "\n", "# get query tuple for dictionary entry", "\n", "# return list [query,positives,negatives]", "\n", "\n", "    ", "query", "=", "load_pc_file", "(", "dict_value", "[", "\"query\"", "]", ")", "# Nx3", "\n", "\n", "random", ".", "shuffle", "(", "dict_value", "[", "\"positives\"", "]", ")", "\n", "pos_files", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_pos", ")", ":", "\n", "        ", "pos_files", ".", "append", "(", "QUERY_DICT", "[", "dict_value", "[", "\"positives\"", "]", "[", "i", "]", "]", "[", "\"query\"", "]", ")", "\n", "#positives= load_pc_files(dict_value[\"positives\"][0:num_pos])", "\n", "", "positives", "=", "load_pc_files", "(", "pos_files", ")", "\n", "\n", "neg_files", "=", "[", "]", "\n", "neg_indices", "=", "[", "]", "\n", "if", "(", "len", "(", "hard_neg", ")", "==", "0", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "dict_value", "[", "\"negatives\"", "]", ")", "\n", "for", "i", "in", "range", "(", "num_neg", ")", ":", "\n", "            ", "neg_files", ".", "append", "(", "QUERY_DICT", "[", "dict_value", "[", "\"negatives\"", "]", "[", "i", "]", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "dict_value", "[", "\"negatives\"", "]", "[", "i", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "random", ".", "shuffle", "(", "dict_value", "[", "\"negatives\"", "]", ")", "\n", "for", "i", "in", "hard_neg", ":", "\n", "            ", "neg_files", ".", "append", "(", "QUERY_DICT", "[", "i", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "i", ")", "\n", "", "j", "=", "0", "\n", "while", "(", "len", "(", "neg_files", ")", "<", "num_neg", ")", ":", "\n", "\n", "            ", "if", "not", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", "in", "hard_neg", ":", "\n", "                ", "neg_files", ".", "append", "(", "\n", "QUERY_DICT", "[", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", ")", "\n", "", "j", "+=", "1", "\n", "\n", "", "", "negatives", "=", "load_pc_files", "(", "neg_files", ")", "\n", "\n", "if", "other_neg", "is", "False", ":", "\n", "        ", "return", "[", "query", ",", "positives", ",", "negatives", "]", "\n", "# For Quadruplet Loss", "\n", "", "else", ":", "\n", "# get neighbors of negatives and query", "\n", "        ", "neighbors", "=", "[", "]", "\n", "for", "pos", "in", "dict_value", "[", "\"positives\"", "]", ":", "\n", "            ", "neighbors", ".", "append", "(", "pos", ")", "\n", "", "for", "neg", "in", "neg_indices", ":", "\n", "            ", "for", "pos", "in", "QUERY_DICT", "[", "neg", "]", "[", "\"positives\"", "]", ":", "\n", "                ", "neighbors", ".", "append", "(", "pos", ")", "\n", "", "", "possible_negs", "=", "list", "(", "set", "(", "QUERY_DICT", ".", "keys", "(", ")", ")", "-", "set", "(", "neighbors", ")", ")", "\n", "random", ".", "shuffle", "(", "possible_negs", ")", "\n", "\n", "if", "(", "len", "(", "possible_negs", ")", "==", "0", ")", ":", "\n", "            ", "return", "[", "query", ",", "positives", ",", "negatives", ",", "np", ".", "array", "(", "[", "]", ")", "]", "\n", "\n", "", "neg2", "=", "load_pc_file", "(", "QUERY_DICT", "[", "possible_negs", "[", "0", "]", "]", "[", "\"query\"", "]", ")", "\n", "\n", "return", "[", "query", ",", "positives", ",", "negatives", ",", "neg2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_rotated_tuple": [[147, 205], ["loading_pointclouds.load_pc_file", "loading_pointclouds.rotate_point_cloud", "numpy.squeeze", "random.shuffle", "range", "loading_pointclouds.load_pc_files", "loading_pointclouds.rotate_point_cloud", "loading_pointclouds.load_pc_files", "loading_pointclouds.rotate_point_cloud", "numpy.expand_dims", "pos_files.append", "len", "random.shuffle", "range", "random.shuffle", "list", "random.shuffle", "loading_pointclouds.load_pc_file", "loading_pointclouds.rotate_point_cloud", "numpy.squeeze", "neg_files.append", "neg_indices.append", "neg_files.append", "neg_indices.append", "len", "neighbors.append", "len", "numpy.expand_dims", "neg_files.append", "neg_indices.append", "neighbors.append", "set", "set", "numpy.array", "QUERY_DICT.keys"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.rotate_point_cloud", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.rotate_point_cloud", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.rotate_point_cloud", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.rotate_point_cloud"], ["", "", "def", "get_rotated_tuple", "(", "dict_value", ",", "num_pos", ",", "num_neg", ",", "QUERY_DICT", ",", "hard_neg", "=", "[", "]", ",", "other_neg", "=", "False", ")", ":", "\n", "    ", "query", "=", "load_pc_file", "(", "dict_value", "[", "\"query\"", "]", ")", "# Nx3", "\n", "q_rot", "=", "rotate_point_cloud", "(", "np", ".", "expand_dims", "(", "query", ",", "axis", "=", "0", ")", ")", "\n", "q_rot", "=", "np", ".", "squeeze", "(", "q_rot", ")", "\n", "\n", "random", ".", "shuffle", "(", "dict_value", "[", "\"positives\"", "]", ")", "\n", "pos_files", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_pos", ")", ":", "\n", "        ", "pos_files", ".", "append", "(", "QUERY_DICT", "[", "dict_value", "[", "\"positives\"", "]", "[", "i", "]", "]", "[", "\"query\"", "]", ")", "\n", "#positives= load_pc_files(dict_value[\"positives\"][0:num_pos])", "\n", "", "positives", "=", "load_pc_files", "(", "pos_files", ")", "\n", "p_rot", "=", "rotate_point_cloud", "(", "positives", ")", "\n", "\n", "neg_files", "=", "[", "]", "\n", "neg_indices", "=", "[", "]", "\n", "if", "(", "len", "(", "hard_neg", ")", "==", "0", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "dict_value", "[", "\"negatives\"", "]", ")", "\n", "for", "i", "in", "range", "(", "num_neg", ")", ":", "\n", "            ", "neg_files", ".", "append", "(", "QUERY_DICT", "[", "dict_value", "[", "\"negatives\"", "]", "[", "i", "]", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "dict_value", "[", "\"negatives\"", "]", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "random", ".", "shuffle", "(", "dict_value", "[", "\"negatives\"", "]", ")", "\n", "for", "i", "in", "hard_neg", ":", "\n", "            ", "neg_files", ".", "append", "(", "QUERY_DICT", "[", "i", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "i", ")", "\n", "", "j", "=", "0", "\n", "while", "(", "len", "(", "neg_files", ")", "<", "num_neg", ")", ":", "\n", "            ", "if", "not", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", "in", "hard_neg", ":", "\n", "                ", "neg_files", ".", "append", "(", "\n", "QUERY_DICT", "[", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", ")", "\n", "", "j", "+=", "1", "\n", "", "", "negatives", "=", "load_pc_files", "(", "neg_files", ")", "\n", "n_rot", "=", "rotate_point_cloud", "(", "negatives", ")", "\n", "\n", "if", "other_neg", "is", "False", ":", "\n", "        ", "return", "[", "q_rot", ",", "p_rot", ",", "n_rot", "]", "\n", "\n", "# For Quadruplet Loss", "\n", "", "else", ":", "\n", "# get neighbors of negatives and query", "\n", "        ", "neighbors", "=", "[", "]", "\n", "for", "pos", "in", "dict_value", "[", "\"positives\"", "]", ":", "\n", "            ", "neighbors", ".", "append", "(", "pos", ")", "\n", "", "for", "neg", "in", "neg_indices", ":", "\n", "            ", "for", "pos", "in", "QUERY_DICT", "[", "neg", "]", "[", "\"positives\"", "]", ":", "\n", "                ", "neighbors", ".", "append", "(", "pos", ")", "\n", "", "", "possible_negs", "=", "list", "(", "set", "(", "QUERY_DICT", ".", "keys", "(", ")", ")", "-", "set", "(", "neighbors", ")", ")", "\n", "random", ".", "shuffle", "(", "possible_negs", ")", "\n", "\n", "if", "(", "len", "(", "possible_negs", ")", "==", "0", ")", ":", "\n", "            ", "return", "[", "q_jit", ",", "p_jit", ",", "n_jit", ",", "np", ".", "array", "(", "[", "]", ")", "]", "\n", "\n", "", "neg2", "=", "load_pc_file", "(", "QUERY_DICT", "[", "possible_negs", "[", "0", "]", "]", "[", "\"query\"", "]", ")", "\n", "n2_rot", "=", "rotate_point_cloud", "(", "np", ".", "expand_dims", "(", "neg2", ",", "axis", "=", "0", ")", ")", "\n", "n2_rot", "=", "np", ".", "squeeze", "(", "n2_rot", ")", "\n", "\n", "return", "[", "q_rot", ",", "p_rot", ",", "n_rot", ",", "n2_rot", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_jittered_tuple": [[207, 266], ["loading_pointclouds.load_pc_file", "loading_pointclouds.jitter_point_cloud", "numpy.squeeze", "random.shuffle", "range", "loading_pointclouds.load_pc_files", "loading_pointclouds.jitter_point_cloud", "loading_pointclouds.load_pc_files", "loading_pointclouds.jitter_point_cloud", "numpy.expand_dims", "pos_files.append", "len", "random.shuffle", "range", "random.shuffle", "list", "random.shuffle", "loading_pointclouds.load_pc_file", "loading_pointclouds.jitter_point_cloud", "numpy.squeeze", "neg_files.append", "neg_indices.append", "neg_files.append", "neg_indices.append", "len", "neighbors.append", "len", "numpy.expand_dims", "neg_files.append", "neg_indices.append", "neighbors.append", "set", "set", "numpy.array", "QUERY_DICT.keys"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.jitter_point_cloud", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.jitter_point_cloud", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.jitter_point_cloud", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.jitter_point_cloud"], ["", "", "def", "get_jittered_tuple", "(", "dict_value", ",", "num_pos", ",", "num_neg", ",", "QUERY_DICT", ",", "hard_neg", "=", "[", "]", ",", "other_neg", "=", "False", ")", ":", "\n", "    ", "query", "=", "load_pc_file", "(", "dict_value", "[", "\"query\"", "]", ")", "# Nx3", "\n", "#q_rot= rotate_point_cloud(np.expand_dims(query, axis=0))", "\n", "q_jit", "=", "jitter_point_cloud", "(", "np", ".", "expand_dims", "(", "query", ",", "axis", "=", "0", ")", ")", "\n", "q_jit", "=", "np", ".", "squeeze", "(", "q_jit", ")", "\n", "\n", "random", ".", "shuffle", "(", "dict_value", "[", "\"positives\"", "]", ")", "\n", "pos_files", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_pos", ")", ":", "\n", "        ", "pos_files", ".", "append", "(", "QUERY_DICT", "[", "dict_value", "[", "\"positives\"", "]", "[", "i", "]", "]", "[", "\"query\"", "]", ")", "\n", "#positives= load_pc_files(dict_value[\"positives\"][0:num_pos])", "\n", "", "positives", "=", "load_pc_files", "(", "pos_files", ")", "\n", "p_jit", "=", "jitter_point_cloud", "(", "positives", ")", "\n", "\n", "neg_files", "=", "[", "]", "\n", "neg_indices", "=", "[", "]", "\n", "if", "(", "len", "(", "hard_neg", ")", "==", "0", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "dict_value", "[", "\"negatives\"", "]", ")", "\n", "for", "i", "in", "range", "(", "num_neg", ")", ":", "\n", "            ", "neg_files", ".", "append", "(", "QUERY_DICT", "[", "dict_value", "[", "\"negatives\"", "]", "[", "i", "]", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "dict_value", "[", "\"negatives\"", "]", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "random", ".", "shuffle", "(", "dict_value", "[", "\"negatives\"", "]", ")", "\n", "for", "i", "in", "hard_neg", ":", "\n", "            ", "neg_files", ".", "append", "(", "QUERY_DICT", "[", "i", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "i", ")", "\n", "", "j", "=", "0", "\n", "while", "(", "len", "(", "neg_files", ")", "<", "num_neg", ")", ":", "\n", "            ", "if", "not", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", "in", "hard_neg", ":", "\n", "                ", "neg_files", ".", "append", "(", "\n", "QUERY_DICT", "[", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", "]", "[", "\"query\"", "]", ")", "\n", "neg_indices", ".", "append", "(", "dict_value", "[", "\"negatives\"", "]", "[", "j", "]", ")", "\n", "", "j", "+=", "1", "\n", "", "", "negatives", "=", "load_pc_files", "(", "neg_files", ")", "\n", "n_jit", "=", "jitter_point_cloud", "(", "negatives", ")", "\n", "\n", "if", "other_neg", "is", "False", ":", "\n", "        ", "return", "[", "q_jit", ",", "p_jit", ",", "n_jit", "]", "\n", "\n", "# For Quadruplet Loss", "\n", "", "else", ":", "\n", "# get neighbors of negatives and query", "\n", "        ", "neighbors", "=", "[", "]", "\n", "for", "pos", "in", "dict_value", "[", "\"positives\"", "]", ":", "\n", "            ", "neighbors", ".", "append", "(", "pos", ")", "\n", "", "for", "neg", "in", "neg_indices", ":", "\n", "            ", "for", "pos", "in", "QUERY_DICT", "[", "neg", "]", "[", "\"positives\"", "]", ":", "\n", "                ", "neighbors", ".", "append", "(", "pos", ")", "\n", "", "", "possible_negs", "=", "list", "(", "set", "(", "QUERY_DICT", ".", "keys", "(", ")", ")", "-", "set", "(", "neighbors", ")", ")", "\n", "random", ".", "shuffle", "(", "possible_negs", ")", "\n", "\n", "if", "(", "len", "(", "possible_negs", ")", "==", "0", ")", ":", "\n", "            ", "return", "[", "q_jit", ",", "p_jit", ",", "n_jit", ",", "np", ".", "array", "(", "[", "]", ")", "]", "\n", "\n", "", "neg2", "=", "load_pc_file", "(", "QUERY_DICT", "[", "possible_negs", "[", "0", "]", "]", "[", "\"query\"", "]", ")", "\n", "n2_jit", "=", "jitter_point_cloud", "(", "np", ".", "expand_dims", "(", "neg2", ",", "axis", "=", "0", ")", ")", "\n", "n2_jit", "=", "np", ".", "squeeze", "(", "n2_jit", ")", "\n", "\n", "return", "[", "q_jit", ",", "p_jit", ",", "n_jit", ",", "n2_jit", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.evaluate": [[36, 52], ["models.NDTNetVlad", "nn.DataParallel.to", "print", "torch.load", "torch.load", "nn.DataParallel.load_state_dict", "torch.DataParallel", "print", "evaluate.evaluate_model"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.evaluate_model"], ["def", "evaluate", "(", ")", ":", "\n", "# model = PNV.PointNetVlad(global_feat=True, feature_transform=True, max_pool=False,", "\n", "#                                   output_dim=cfg.FEATURE_OUTPUT_DIM, num_points=cfg.NUM_POINTS)", "\n", "\n", "    ", "model", "=", "PNV", ".", "NDTNetVlad", "(", "num_points", "=", "cfg", ".", "NUM_POINTS", ",", "output_dim", "=", "cfg", ".", "FEATURE_OUTPUT_DIM", ",", "emb_dims", "=", "cfg", ".", "EMB_DIMS", ",", "layer_number", "=", "cfg", ".", "LAYER_NUMBER", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "resume_filename", "=", "cfg", ".", "LOG_DIR", "+", "\"Transformer_skip.pth.tar\"", "\n", "print", "(", "\"Resuming From \"", ",", "resume_filename", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "resume_filename", ")", "\n", "saved_state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "model", ".", "load_state_dict", "(", "saved_state_dict", ")", "\n", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "print", "(", "evaluate_model", "(", "model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.evaluate_model": [[54, 109], ["loading_pointclouds.get_sets_dict", "loading_pointclouds.get_sets_dict", "numpy.zeros", "range", "range", "range", "print", "numpy.mean", "numpy.mean", "os.path.exists", "os.path.exists", "os.mkdir", "os.mkdir", "len", "DATABASE_VECTORS.append", "len", "QUERY_VECTORS.append", "len", "range", "open", "output.write", "output.write", "output.write", "output.write", "output.write", "output.write", "output.write", "output.write", "evaluate.get_latent_vectors", "evaluate.get_latent_vectors", "len", "evaluate.get_recall", "numpy.array", "one_percent_recall.append", "str", "str", "str", "similarity.append"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_sets_dict", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_sets_dict", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_latent_vectors", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_latent_vectors", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.get_recall"], ["", "def", "evaluate_model", "(", "model", ")", ":", "\n", "    ", "DATABASE_SETS", "=", "get_sets_dict", "(", "cfg", ".", "EVAL_DATABASE_FILE", ")", "\n", "QUERY_SETS", "=", "get_sets_dict", "(", "cfg", ".", "EVAL_QUERY_FILE", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg", ".", "RESULTS_FOLDER", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "cfg", ".", "RESULTS_FOLDER", ")", "\n", "\n", "", "recall", "=", "np", ".", "zeros", "(", "25", ")", "\n", "count", "=", "0", "\n", "similarity", "=", "[", "]", "\n", "one_percent_recall", "=", "[", "]", "\n", "\n", "DATABASE_VECTORS", "=", "[", "]", "\n", "QUERY_VECTORS", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "DATABASE_SETS", ")", ")", ":", "\n", "        ", "DATABASE_VECTORS", ".", "append", "(", "get_latent_vectors", "(", "model", ",", "DATABASE_SETS", "[", "i", "]", ")", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "len", "(", "QUERY_SETS", ")", ")", ":", "\n", "        ", "QUERY_VECTORS", ".", "append", "(", "get_latent_vectors", "(", "model", ",", "QUERY_SETS", "[", "j", "]", ")", ")", "\n", "\n", "", "for", "m", "in", "range", "(", "len", "(", "QUERY_SETS", ")", ")", ":", "\n", "        ", "for", "n", "in", "range", "(", "len", "(", "QUERY_SETS", ")", ")", ":", "\n", "            ", "if", "(", "m", "==", "n", ")", ":", "\n", "                ", "continue", "\n", "", "pair_recall", ",", "pair_similarity", ",", "pair_opr", "=", "get_recall", "(", "\n", "m", ",", "n", ",", "DATABASE_VECTORS", ",", "QUERY_VECTORS", ",", "QUERY_SETS", ")", "\n", "recall", "+=", "np", ".", "array", "(", "pair_recall", ")", "\n", "count", "+=", "1", "\n", "one_percent_recall", ".", "append", "(", "pair_opr", ")", "\n", "for", "x", "in", "pair_similarity", ":", "\n", "                ", "similarity", ".", "append", "(", "x", ")", "\n", "\n", "", "", "", "print", "(", ")", "\n", "ave_recall", "=", "recall", "/", "count", "\n", "# print(ave_recall)", "\n", "\n", "# print(similarity)", "\n", "average_similarity", "=", "np", ".", "mean", "(", "similarity", ")", "\n", "# print(average_similarity)", "\n", "\n", "ave_one_percent_recall", "=", "np", ".", "mean", "(", "one_percent_recall", ")", "\n", "# print(ave_one_percent_recall)", "\n", "\n", "with", "open", "(", "cfg", ".", "OUTPUT_FILE", ",", "\"w\"", ")", "as", "output", ":", "\n", "        ", "output", ".", "write", "(", "\"Average Recall @N:\\n\"", ")", "\n", "output", ".", "write", "(", "str", "(", "ave_recall", ")", ")", "\n", "output", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "output", ".", "write", "(", "\"Average Similarity:\\n\"", ")", "\n", "output", ".", "write", "(", "str", "(", "average_similarity", ")", ")", "\n", "output", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "output", ".", "write", "(", "\"Average Top 1% Recall:\\n\"", ")", "\n", "output", ".", "write", "(", "str", "(", "ave_one_percent_recall", ")", ")", "\n", "\n", "", "return", "ave_one_percent_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.get_latent_vectors": [[111, 168], ["model.eval", "numpy.arange", "range", "numpy.array", "model.train", "len", "loading_pointclouds.load_pc_files", "model.detach().cpu().numpy", "numpy.squeeze", "np.vstack.append", "len", "np.vstack.reshape", "len", "loading_pointclouds.load_pc_files", "model.detach().cpu().numpy", "numpy.squeeze", "dict_to_process.keys", "len", "file_names.append", "torch.no_grad", "torch.no_grad", "torch.from_numpy().float", "torch.from_numpy().float", "feed_tensor.to.unsqueeze", "feed_tensor.to.to", "model", "len", "dict_to_process.keys", "file_names.append", "torch.no_grad", "torch.no_grad", "torch.from_numpy().float", "torch.from_numpy().float", "feed_tensor.to.unsqueeze", "feed_tensor.to.to", "model", "numpy.vstack", "model.detach().cpu", "len", "model.detach().cpu", "torch.from_numpy", "torch.from_numpy", "dict_to_process.keys", "torch.from_numpy", "torch.from_numpy", "model.detach", "model.detach"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files"], ["", "def", "get_latent_vectors", "(", "model", ",", "dict_to_process", ")", ":", "\n", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "is_training", "=", "False", "\n", "train_file_idxs", "=", "np", ".", "arange", "(", "0", ",", "len", "(", "dict_to_process", ".", "keys", "(", ")", ")", ")", "\n", "\n", "batch_num", "=", "cfg", ".", "EVAL_BATCH_SIZE", "*", "(", "1", "+", "cfg", ".", "EVAL_POSITIVES_PER_QUERY", "+", "cfg", ".", "EVAL_NEGATIVES_PER_QUERY", ")", "\n", "q_output", "=", "[", "]", "\n", "for", "q_index", "in", "range", "(", "len", "(", "train_file_idxs", ")", "//", "batch_num", ")", ":", "\n", "        ", "file_indices", "=", "train_file_idxs", "[", "q_index", "*", "batch_num", ":", "(", "q_index", "+", "1", ")", "*", "(", "batch_num", ")", "]", "\n", "file_names", "=", "[", "]", "\n", "for", "index", "in", "file_indices", ":", "\n", "            ", "file_names", ".", "append", "(", "dict_to_process", "[", "index", "]", "[", "\"query\"", "]", ")", "\n", "", "queries", "=", "load_pc_files", "(", "file_names", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "feed_tensor", "=", "torch", ".", "from_numpy", "(", "queries", ")", ".", "float", "(", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "unsqueeze", "(", "1", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "to", "(", "device", ")", "\n", "out", "=", "model", "(", "feed_tensor", ")", "\n", "\n", "", "out", "=", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out", "=", "np", ".", "squeeze", "(", "out", ")", "\n", "\n", "#out = np.vstack((o1, o2, o3, o4))", "\n", "q_output", ".", "append", "(", "out", ")", "\n", "\n", "", "q_output", "=", "np", ".", "array", "(", "q_output", ")", "\n", "if", "(", "len", "(", "q_output", ")", "!=", "0", ")", ":", "\n", "        ", "q_output", "=", "q_output", ".", "reshape", "(", "-", "1", ",", "q_output", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# handle edge case", "\n", "", "index_edge", "=", "len", "(", "train_file_idxs", ")", "//", "batch_num", "*", "batch_num", "\n", "if", "index_edge", "<", "len", "(", "dict_to_process", ".", "keys", "(", ")", ")", ":", "\n", "        ", "file_indices", "=", "train_file_idxs", "[", "index_edge", ":", "len", "(", "dict_to_process", ".", "keys", "(", ")", ")", "]", "\n", "file_names", "=", "[", "]", "\n", "for", "index", "in", "file_indices", ":", "\n", "            ", "file_names", ".", "append", "(", "dict_to_process", "[", "index", "]", "[", "\"query\"", "]", ")", "\n", "", "queries", "=", "load_pc_files", "(", "file_names", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "feed_tensor", "=", "torch", ".", "from_numpy", "(", "queries", ")", ".", "float", "(", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "unsqueeze", "(", "1", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "to", "(", "device", ")", "\n", "o1", "=", "model", "(", "feed_tensor", ")", "\n", "\n", "", "output", "=", "o1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "output", "=", "np", ".", "squeeze", "(", "output", ")", "\n", "if", "(", "q_output", ".", "shape", "[", "0", "]", "!=", "0", ")", ":", "\n", "            ", "q_output", "=", "np", ".", "vstack", "(", "(", "q_output", ",", "output", ")", ")", "\n", "", "else", ":", "\n", "            ", "q_output", "=", "output", "\n", "\n", "", "", "model", ".", "train", "(", ")", "\n", "# print(q_output.shape)", "\n", "return", "q_output", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.get_recall": [[170, 211], ["sklearn.neighbors.KDTree", "max", "range", "int", "len", "sklearn.neighbors.KDTree.query", "range", "round", "len", "numpy.array", "len", "len", "float", "numpy.cumsum", "float", "list", "len", "numpy.dot", "top1_similarity_score.append", "set().intersection", "set", "set"], "function", ["None"], ["", "def", "get_recall", "(", "m", ",", "n", ",", "DATABASE_VECTORS", ",", "QUERY_VECTORS", ",", "QUERY_SETS", ")", ":", "\n", "\n", "    ", "database_output", "=", "DATABASE_VECTORS", "[", "m", "]", "\n", "queries_output", "=", "QUERY_VECTORS", "[", "n", "]", "\n", "\n", "# print(len(queries_output))", "\n", "database_nbrs", "=", "KDTree", "(", "database_output", ")", "\n", "\n", "num_neighbors", "=", "25", "\n", "recall", "=", "[", "0", "]", "*", "num_neighbors", "\n", "\n", "top1_similarity_score", "=", "[", "]", "\n", "one_percent_retrieved", "=", "0", "\n", "threshold", "=", "max", "(", "int", "(", "round", "(", "len", "(", "database_output", ")", "/", "100.0", ")", ")", ",", "1", ")", "\n", "\n", "num_evaluated", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "queries_output", ")", ")", ":", "\n", "        ", "true_neighbors", "=", "QUERY_SETS", "[", "n", "]", "[", "i", "]", "[", "m", "]", "\n", "if", "(", "len", "(", "true_neighbors", ")", "==", "0", ")", ":", "\n", "            ", "continue", "\n", "", "num_evaluated", "+=", "1", "\n", "distances", ",", "indices", "=", "database_nbrs", ".", "query", "(", "\n", "np", ".", "array", "(", "[", "queries_output", "[", "i", "]", "]", ")", ",", "k", "=", "num_neighbors", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "indices", "[", "0", "]", ")", ")", ":", "\n", "            ", "if", "indices", "[", "0", "]", "[", "j", "]", "in", "true_neighbors", ":", "\n", "                ", "if", "(", "j", "==", "0", ")", ":", "\n", "                    ", "similarity", "=", "np", ".", "dot", "(", "\n", "queries_output", "[", "i", "]", ",", "database_output", "[", "indices", "[", "0", "]", "[", "j", "]", "]", ")", "\n", "top1_similarity_score", ".", "append", "(", "similarity", ")", "\n", "", "recall", "[", "j", "]", "+=", "1", "\n", "break", "\n", "\n", "", "", "if", "len", "(", "list", "(", "set", "(", "indices", "[", "0", "]", "[", "0", ":", "threshold", "]", ")", ".", "intersection", "(", "set", "(", "true_neighbors", ")", ")", ")", ")", ">", "0", ":", "\n", "            ", "one_percent_retrieved", "+=", "1", "\n", "\n", "", "", "one_percent_recall", "=", "(", "one_percent_retrieved", "/", "float", "(", "num_evaluated", ")", ")", "*", "100", "\n", "recall", "=", "(", "np", ".", "cumsum", "(", "recall", ")", "/", "float", "(", "num_evaluated", ")", ")", "*", "100", "\n", "# print(recall)", "\n", "# print(np.mean(top1_similarity_score))", "\n", "# print(one_percent_recall)", "\n", "return", "recall", ",", "top1_similarity_score", ",", "one_percent_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_bn_decay": [[120, 125], ["min"], "function", ["None"], ["def", "get_bn_decay", "(", "batch", ")", ":", "\n", "    ", "bn_momentum", "=", "cfg", ".", "BN_INIT_DECAY", "*", "(", "cfg", ".", "BN_DECAY_DECAY_RATE", "**", "\n", "(", "batch", "*", "cfg", ".", "BATCH_NUM_QUERIES", "//", "BN_DECAY_DECAY_STEP", ")", ")", "\n", "return", "min", "(", "cfg", ".", "BN_DECAY_CLIP", ",", "1", "-", "bn_momentum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string": [[127, 131], ["LOG_FOUT.write", "LOG_FOUT.flush", "print"], "function", ["None"], ["", "def", "log_string", "(", "out_str", ")", ":", "\n", "    ", "LOG_FOUT", ".", "write", "(", "out_str", "+", "'\\n'", ")", "\n", "LOG_FOUT", ".", "flush", "(", ")", "\n", "print", "(", "out_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_learning_rate": [[135, 139], ["max"], "function", ["None"], ["", "def", "get_learning_rate", "(", "epoch", ")", ":", "\n", "    ", "learning_rate", "=", "cfg", ".", "BASE_LEARNING_RATE", "*", "(", "(", "0.9", ")", "**", "(", "epoch", "//", "5", ")", ")", "\n", "learning_rate", "=", "max", "(", "learning_rate", ",", "0.00001", ")", "# CLIP THE LEARNING RATE!", "\n", "return", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train": [[141, 212], ["train.get_bn_decay", "print", "torch.utils.tensorboard.SummaryWriter", "models.NDTNetVlad", "nn.DataParallel.to", "filter", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.DataParallel", "LOG_FOUT.write", "LOG_FOUT.write", "LOG_FOUT.flush", "range", "os.path.join", "nn.DataParallel.parameters", "torch.optim.SGD", "torch.optim.SGD", "print", "torch.load", "torch.load", "nn.DataParallel.load_state_dict", "torch.optim.Adam.load_state_dict", "config.cfg_str", "print", "train.log_string", "sys.stdout.flush", "train.train_one_epoch", "train.log_string", "evaluate.evaluate_model", "train.log_string", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.optim.lr_scheduler.MultiStepLR.step", "torch.optim.Adam", "torch.optim.Adam", "exit", "len", "str", "str"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_bn_decay", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.config.cfg_str", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train_one_epoch", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.evaluate.evaluate_model", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string"], ["", "def", "train", "(", ")", ":", "\n", "    ", "global", "HARD_NEGATIVES", ",", "TOTAL_ITERATIONS", "\n", "bn_decay", "=", "get_bn_decay", "(", "0", ")", "\n", "#tf.summary.scalar('bn_decay', bn_decay)", "\n", "\n", "#loss = lazy_quadruplet_loss(q_vec, pos_vecs, neg_vecs, other_neg_vec, MARGIN1, MARGIN2)", "\n", "if", "cfg", ".", "LOSS_FUNCTION", "==", "'quadruplet'", ":", "\n", "        ", "loss_function", "=", "PNV_loss", ".", "quadruplet_loss", "\n", "# loss_function = PNV_loss.constrastive_memorybank_loss", "\n", "", "else", ":", "\n", "        ", "loss_function", "=", "PNV_loss", ".", "triplet_loss_wrapper", "\n", "\n", "#learning_rate = get_learning_rate(0)", "\n", "", "learning_rate", "=", "cfg", ".", "BASE_LEARNING_RATE", "\n", "print", "(", "'learning_rate:'", ",", "learning_rate", ")", "\n", "\n", "train_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "cfg", ".", "LOG_DIR", ",", "'train'", ")", ")", "\n", "# test_writer = SummaryWriter(os.path.join(cfg.LOG_DIR, 'test'))", "\n", "\n", "# model = PNV.PointNetVlad(global_feat=True, feature_transform=True, max_pool=False, output_dim=cfg.FEATURE_OUTPUT_DIM, num_points=cfg.NUM_POINTS)", "\n", "\n", "model", "=", "PNV", ".", "NDTNetVlad", "(", "num_points", "=", "cfg", ".", "NUM_POINTS", ",", "output_dim", "=", "cfg", ".", "FEATURE_OUTPUT_DIM", ",", "emb_dims", "=", "cfg", ".", "EMB_DIMS", ",", "layer_number", "=", "cfg", ".", "LAYER_NUMBER", ")", "\n", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "cfg", ".", "OPTIMIZER", "==", "'momentum'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "parameters", ",", "learning_rate", ",", "momentum", "=", "cfg", ".", "MOMENTUM", ")", "\n", "", "elif", "cfg", ".", "OPTIMIZER", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ",", "learning_rate", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "None", "\n", "exit", "(", "0", ")", "\n", "\n", "", "if", "FLAGS", ".", "resume", ":", "\n", "        ", "resume_filename", "=", "cfg", ".", "LOG_DIR", "+", "\"checkpoint.pth.tar\"", "\n", "print", "(", "\"Resuming From \"", ",", "resume_filename", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "resume_filename", ")", "\n", "\n", "starting_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "TOTAL_ITERATIONS", "=", "starting_epoch", "*", "len", "(", "TRAINING_QUERIES", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "", "else", ":", "\n", "        ", "starting_epoch", "=", "0", "\n", "\n", "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, last_epoch=-1)", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "milestones", "=", "[", "9", ",", "15", ",", "20", "]", ",", "gamma", "=", "0.1", ",", "last_epoch", "=", "-", "1", ")", "\n", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "LOG_FOUT", ".", "write", "(", "cfg", ".", "cfg_str", "(", ")", ")", "\n", "LOG_FOUT", ".", "write", "(", "\"\\n\"", ")", "\n", "LOG_FOUT", ".", "flush", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "starting_epoch", ",", "cfg", ".", "MAX_EPOCH", ")", ":", "\n", "        ", "print", "(", "epoch", ")", "\n", "log_string", "(", "'**** EPOCH %03d ****'", "%", "(", "epoch", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "train_one_epoch", "(", "model", ",", "optimizer", ",", "loss_function", ",", "epoch", ")", "\n", "\n", "log_string", "(", "'EVALUATING...'", ")", "\n", "cfg", ".", "OUTPUT_FILE", "=", "cfg", ".", "RESULTS_FOLDER", "+", "'results_'", "+", "str", "(", "epoch", ")", "+", "'.txt'", "\n", "eval_recall", "=", "evaluate", ".", "evaluate_model", "(", "model", ")", "\n", "log_string", "(", "'EVAL RECALL: %s'", "%", "str", "(", "eval_recall", ")", ")", "\n", "\n", "train_writer", ".", "add_scalar", "(", "\"Val Recall\"", ",", "eval_recall", ",", "epoch", ")", "\n", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train_one_epoch": [[214, 372], ["np.arange", "np.random.shuffle", "range", "len", "range", "range", "np.array", "np.expand_dims", "np.array", "np.expand_dims", "np.array", "np.array", "train.log_string", "model.train", "optimizer.zero_grad", "train.run_model", "loss_function", "loss_function.backward", "optimizer.step", "train.log_string", "TRAINING_QUERIES.keys", "len", "train.log_string", "train.log_string", "train.log_string", "train.log_string", "len", "np.expand_dims.append", "np.array.append", "np.array.append", "np.expand_dims.append", "len", "train.log_string", "train.get_latent_vectors", "print", "isinstance", "os.path.join", "torch.save", "torch.save", "print", "len", "len", "q_tuples.append", "loading_pointclouds.get_query_tuple", "len", "train.get_feature_representation", "random.shuffle", "train.get_random_hard_negatives", "print", "q_tuples.append", "train.get_feature_representation", "random.shuffle", "train.get_random_hard_negatives", "list", "print", "q_tuples.append", "str", "model_to_save.state_dict", "optimizer.state_dict", "HARD_NEGATIVES.keys", "loading_pointclouds.get_query_tuple", "set().union", "loading_pointclouds.get_query_tuple", "str", "str", "str", "set"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.run_model", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.log_string", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_latent_vectors", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_query_tuple", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_feature_representation", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_random_hard_negatives", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_feature_representation", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_random_hard_negatives", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_query_tuple", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.get_query_tuple"], ["", "", "def", "train_one_epoch", "(", "model", ",", "optimizer", ",", "loss_function", ",", "epoch", ")", ":", "\n", "    ", "global", "HARD_NEGATIVES", "\n", "global", "TRAINING_LATENT_VECTORS", ",", "TOTAL_ITERATIONS", "\n", "\n", "is_training", "=", "True", "\n", "sampled_neg", "=", "4000", "\n", "# number of hard negatives in the training tuple", "\n", "# which are taken from the sampled negatives", "\n", "num_to_take", "=", "10", "\n", "\n", "# Shuffle train files", "\n", "train_file_idxs", "=", "np", ".", "arange", "(", "0", ",", "len", "(", "TRAINING_QUERIES", ".", "keys", "(", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_file_idxs", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "train_file_idxs", ")", "//", "cfg", ".", "BATCH_NUM_QUERIES", ")", ":", "\n", "# for i in range (5):", "\n", "        ", "batch_keys", "=", "train_file_idxs", "[", "i", "*", "cfg", ".", "BATCH_NUM_QUERIES", ":", "(", "i", "+", "1", ")", "*", "cfg", ".", "BATCH_NUM_QUERIES", "]", "\n", "q_tuples", "=", "[", "]", "\n", "\n", "faulty_tuple", "=", "False", "\n", "no_other_neg", "=", "False", "\n", "for", "j", "in", "range", "(", "cfg", ".", "BATCH_NUM_QUERIES", ")", ":", "\n", "            ", "if", "(", "len", "(", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", "[", "\"positives\"", "]", ")", "<", "cfg", ".", "TRAIN_POSITIVES_PER_QUERY", ")", ":", "\n", "                ", "faulty_tuple", "=", "True", "\n", "break", "\n", "\n", "# no cached feature vectors", "\n", "", "if", "(", "len", "(", "TRAINING_LATENT_VECTORS", ")", "==", "0", ")", ":", "\n", "                ", "q_tuples", ".", "append", "(", "\n", "get_query_tuple", "(", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", ",", "cfg", ".", "TRAIN_POSITIVES_PER_QUERY", ",", "cfg", ".", "TRAIN_NEGATIVES_PER_QUERY", ",", "\n", "TRAINING_QUERIES", ",", "hard_neg", "=", "[", "]", ",", "other_neg", "=", "True", ")", ")", "\n", "# q_tuples.append(get_rotated_tuple(TRAINING_QUERIES[batch_keys[j]],POSITIVES_PER_QUERY,NEGATIVES_PER_QUERY, TRAINING_QUERIES, hard_neg=[], other_neg=True))", "\n", "# q_tuples.append(get_jittered_tuple(TRAINING_QUERIES[batch_keys[j]],POSITIVES_PER_QUERY,NEGATIVES_PER_QUERY, TRAINING_QUERIES, hard_neg=[], other_neg=True))", "\n", "\n", "", "elif", "(", "len", "(", "HARD_NEGATIVES", ".", "keys", "(", ")", ")", "==", "0", ")", ":", "\n", "                ", "query", "=", "get_feature_representation", "(", "\n", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", "[", "'query'", "]", ",", "model", ")", "\n", "random", ".", "shuffle", "(", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", "[", "'negatives'", "]", ")", "\n", "negatives", "=", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "\n", "]", "[", "'negatives'", "]", "[", "0", ":", "sampled_neg", "]", "\n", "hard_negs", "=", "get_random_hard_negatives", "(", "\n", "query", ",", "negatives", ",", "num_to_take", ")", "\n", "print", "(", "hard_negs", ")", "\n", "q_tuples", ".", "append", "(", "\n", "get_query_tuple", "(", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", ",", "cfg", ".", "TRAIN_POSITIVES_PER_QUERY", ",", "cfg", ".", "TRAIN_NEGATIVES_PER_QUERY", ",", "\n", "TRAINING_QUERIES", ",", "hard_negs", ",", "other_neg", "=", "True", ")", ")", "\n", "# q_tuples.append(get_rotated_tuple(TRAINING_QUERIES[batch_keys[j]],POSITIVES_PER_QUERY,NEGATIVES_PER_QUERY, TRAINING_QUERIES, hard_negs, other_neg=True))", "\n", "# q_tuples.append(get_jittered_tuple(TRAINING_QUERIES[batch_keys[j]],POSITIVES_PER_QUERY,NEGATIVES_PER_QUERY, TRAINING_QUERIES, hard_negs, other_neg=True))", "\n", "", "else", ":", "\n", "                ", "query", "=", "get_feature_representation", "(", "\n", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", "[", "'query'", "]", ",", "model", ")", "\n", "random", ".", "shuffle", "(", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", "[", "'negatives'", "]", ")", "\n", "negatives", "=", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "\n", "]", "[", "'negatives'", "]", "[", "0", ":", "sampled_neg", "]", "\n", "hard_negs", "=", "get_random_hard_negatives", "(", "\n", "query", ",", "negatives", ",", "num_to_take", ")", "\n", "hard_negs", "=", "list", "(", "set", "(", ")", ".", "union", "(", "\n", "HARD_NEGATIVES", "[", "batch_keys", "[", "j", "]", "]", ",", "hard_negs", ")", ")", "\n", "print", "(", "'hard'", ",", "hard_negs", ")", "\n", "q_tuples", ".", "append", "(", "\n", "get_query_tuple", "(", "TRAINING_QUERIES", "[", "batch_keys", "[", "j", "]", "]", ",", "cfg", ".", "TRAIN_POSITIVES_PER_QUERY", ",", "cfg", ".", "TRAIN_NEGATIVES_PER_QUERY", ",", "\n", "TRAINING_QUERIES", ",", "hard_negs", ",", "other_neg", "=", "True", ")", ")", "\n", "# q_tuples.append(get_rotated_tuple(TRAINING_QUERIES[batch_keys[j]],POSITIVES_PER_QUERY,NEGATIVES_PER_QUERY, TRAINING_QUERIES, hard_negs, other_neg=True))", "\n", "# q_tuples.append(get_jittered_tuple(TRAINING_QUERIES[batch_keys[j]],POSITIVES_PER_QUERY,NEGATIVES_PER_QUERY, TRAINING_QUERIES, hard_negs, other_neg=True))", "\n", "\n", "", "if", "(", "q_tuples", "[", "j", "]", "[", "3", "]", ".", "shape", "[", "0", "]", "!=", "cfg", ".", "NUM_POINTS", ")", ":", "\n", "                ", "no_other_neg", "=", "True", "\n", "break", "\n", "\n", "", "", "if", "(", "faulty_tuple", ")", ":", "\n", "            ", "log_string", "(", "'----'", "+", "str", "(", "i", ")", "+", "'-----'", ")", "\n", "log_string", "(", "'----'", "+", "'FAULTY TUPLE'", "+", "'-----'", ")", "\n", "continue", "\n", "\n", "", "if", "(", "no_other_neg", ")", ":", "\n", "            ", "log_string", "(", "'----'", "+", "str", "(", "i", ")", "+", "'-----'", ")", "\n", "log_string", "(", "'----'", "+", "'NO OTHER NEG'", "+", "'-----'", ")", "\n", "continue", "\n", "\n", "", "queries", "=", "[", "]", "\n", "positives", "=", "[", "]", "\n", "negatives", "=", "[", "]", "\n", "other_neg", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "q_tuples", ")", ")", ":", "\n", "            ", "queries", ".", "append", "(", "q_tuples", "[", "k", "]", "[", "0", "]", ")", "\n", "positives", ".", "append", "(", "q_tuples", "[", "k", "]", "[", "1", "]", ")", "\n", "negatives", ".", "append", "(", "q_tuples", "[", "k", "]", "[", "2", "]", ")", "\n", "other_neg", ".", "append", "(", "q_tuples", "[", "k", "]", "[", "3", "]", ")", "\n", "\n", "", "queries", "=", "np", ".", "array", "(", "queries", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "queries", "=", "np", ".", "expand_dims", "(", "queries", ",", "axis", "=", "1", ")", "\n", "other_neg", "=", "np", ".", "array", "(", "other_neg", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "other_neg", "=", "np", ".", "expand_dims", "(", "other_neg", ",", "axis", "=", "1", ")", "\n", "positives", "=", "np", ".", "array", "(", "positives", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "negatives", "=", "np", ".", "array", "(", "negatives", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "log_string", "(", "'----'", "+", "str", "(", "i", ")", "+", "'-----'", ")", "\n", "if", "(", "len", "(", "queries", ".", "shape", ")", "!=", "4", ")", ":", "\n", "            ", "log_string", "(", "'----'", "+", "'FAULTY QUERY'", "+", "'-----'", ")", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output_queries", ",", "output_positives", ",", "output_negatives", ",", "output_other_neg", "=", "run_model", "(", "\n", "model", ",", "queries", ",", "positives", ",", "negatives", ",", "other_neg", ")", "\n", "loss", "=", "loss_function", "(", "output_queries", ",", "output_positives", ",", "output_negatives", ",", "output_other_neg", ",", "\n", "cfg", ".", "MARGIN_1", ",", "cfg", ".", "MARGIN_2", ",", "use_min", "=", "cfg", ".", "TRIPLET_USE_BEST_POSITIVES", ",", "lazy", "=", "cfg", ".", "LOSS_LAZY", ",", "\n", "ignore_zero_loss", "=", "cfg", ".", "LOSS_IGNORE_ZERO_BATCH", ")", "\n", "\n", "# loss = loss_function(output_queries, output_positives, output_negatives, output_other_neg)", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "log_string", "(", "'batch loss: %f'", "%", "loss", ")", "\n", "# train_writer.add_scalar(\"Loss\", loss.cpu().item(), TOTAL_ITERATIONS)", "\n", "TOTAL_ITERATIONS", "+=", "cfg", ".", "BATCH_NUM_QUERIES", "\n", "\n", "# save_name = os.path.join(cfg.LOG_DIR, datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\") + '_epoch' + str(epoch) + '.pth.tar')", "\n", "# print(save_name)", "\n", "\n", "# EVALLLL", "\n", "\n", "if", "(", "epoch", ">", "5", "and", "i", "%", "(", "1400", "//", "cfg", ".", "BATCH_NUM_QUERIES", ")", "==", "29", ")", ":", "\n", "            ", "TRAINING_LATENT_VECTORS", "=", "get_latent_vectors", "(", "\n", "model", ",", "TRAINING_QUERIES", ")", "\n", "print", "(", "\"Updated cached feature vectors\"", ")", "\n", "\n", "", "if", "(", "i", "%", "(", "6000", "//", "cfg", ".", "BATCH_NUM_QUERIES", ")", "==", "101", ")", ":", "\n", "            ", "if", "isinstance", "(", "model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "                ", "model_to_save", "=", "model", ".", "module", "\n", "", "else", ":", "\n", "                ", "model_to_save", "=", "model", "\n", "\n", "# save_name = cfg.LOG_DIR + cfg.MODEL_FILENAME", "\n", "# save_name = os.path.join(cfg.LOG_DIR, datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\") + '_epoch' + str(epoch) + '.pth.tar')", "\n", "", "save_name", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "LOG_DIR", ",", "'checkpoint_epoch'", "+", "str", "(", "epoch", ")", "+", "'.pth.tar'", ")", "\n", "\n", "# torch.save({", "\n", "#     'epoch': epoch,", "\n", "#     'iter': TOTAL_ITERATIONS,", "\n", "#     'state_dict': model_to_save.state_dict(),", "\n", "#     'optimizer': optimizer.state_dict(),", "\n", "#     },", "\n", "#     save_name)", "\n", "\n", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'iter'", ":", "TOTAL_ITERATIONS", ",", "\n", "'state_dict'", ":", "model_to_save", ".", "state_dict", "(", ")", ",", "\n", "# 'DGCNN_state_dict': model_to_save.DGCNN.state_dict(),", "\n", "# 'AttentionalGNN_state_dict': model_to_save.AttentionalGNN.state_dict(),", "\n", "# 'net_vlad_state_dict': model_to_save.net_vlad.state_dict(),", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", ",", "\n", "save_name", ")", "\n", "\n", "print", "(", "\"Model Saved As \"", "+", "save_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_feature_representation": [[374, 391], ["model.eval", "loading_pointclouds.load_pc_files", "np.expand_dims", "model.detach().cpu().numpy", "np.squeeze", "model.train", "torch.no_grad", "torch.no_grad", "torch.from_numpy().float", "torch.from_numpy().float", "q.to.to", "model", "model.detach().cpu", "torch.from_numpy", "torch.from_numpy", "model.detach"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train"], ["", "", "", "def", "get_feature_representation", "(", "filename", ",", "model", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "queries", "=", "load_pc_files", "(", "[", "filename", "]", ")", "\n", "queries", "=", "np", ".", "expand_dims", "(", "queries", ",", "axis", "=", "1", ")", "\n", "# if(BATCH_NUM_QUERIES-1>0):", "\n", "#    fake_queries=np.zeros((BATCH_NUM_QUERIES-1,1,NUM_POINTS,3))", "\n", "#    q=np.vstack((queries,fake_queries))", "\n", "# else:", "\n", "#    q=queries", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "q", "=", "torch", ".", "from_numpy", "(", "queries", ")", ".", "float", "(", ")", "\n", "q", "=", "q", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "q", ")", "\n", "", "output", "=", "output", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "output", "=", "np", ".", "squeeze", "(", "output", ")", "\n", "model", ".", "train", "(", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_random_hard_negatives": [[393, 406], ["range", "np.array", "sklearn.neighbors.KDTree", "sklearn.neighbors.KDTree.query", "np.squeeze", "hard_negs.tolist.tolist", "len", "np.array.append", "np.array", "np.array"], "function", ["None"], ["", "def", "get_random_hard_negatives", "(", "query_vec", ",", "random_negs", ",", "num_to_take", ")", ":", "\n", "    ", "global", "TRAINING_LATENT_VECTORS", "\n", "\n", "latent_vecs", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "random_negs", ")", ")", ":", "\n", "        ", "latent_vecs", ".", "append", "(", "TRAINING_LATENT_VECTORS", "[", "random_negs", "[", "j", "]", "]", ")", "\n", "\n", "", "latent_vecs", "=", "np", ".", "array", "(", "latent_vecs", ")", "\n", "nbrs", "=", "KDTree", "(", "latent_vecs", ")", "\n", "distances", ",", "indices", "=", "nbrs", ".", "query", "(", "np", ".", "array", "(", "[", "query_vec", "]", ")", ",", "k", "=", "num_to_take", ")", "\n", "hard_negs", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "random_negs", ")", "[", "indices", "[", "0", "]", "]", ")", "\n", "hard_negs", "=", "hard_negs", ".", "tolist", "(", ")", "\n", "return", "hard_negs", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.get_latent_vectors": [[408, 469], ["np.arange", "model.eval", "range", "np.array", "range", "model.train", "print", "len", "loading_pointclouds.load_pc_files", "torch.from_numpy().float", "torch.from_numpy().float", "feed_tensor.to.unsqueeze", "feed_tensor.to.to", "model.detach().cpu().numpy", "np.squeeze", "np.vstack.append", "len", "np.vstack.reshape", "len", "loading_pointclouds.load_pc_files", "np.expand_dims", "model.detach().cpu().numpy", "np.squeeze", "dict_to_process.keys", "len", "file_names.append", "torch.no_grad", "torch.no_grad", "model", "dict_to_process.keys", "torch.no_grad", "torch.no_grad", "torch.from_numpy().float", "torch.from_numpy().float", "model", "np.vstack", "torch.from_numpy", "torch.from_numpy", "model.detach().cpu", "len", "model.detach().cpu", "torch.from_numpy", "torch.from_numpy", "model.detach", "model.detach"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.train", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.loading_pointclouds.load_pc_files"], ["", "def", "get_latent_vectors", "(", "model", ",", "dict_to_process", ")", ":", "\n", "    ", "train_file_idxs", "=", "np", ".", "arange", "(", "0", ",", "len", "(", "dict_to_process", ".", "keys", "(", ")", ")", ")", "\n", "\n", "batch_num", "=", "cfg", ".", "BATCH_NUM_QUERIES", "*", "(", "1", "+", "cfg", ".", "TRAIN_POSITIVES_PER_QUERY", "+", "cfg", ".", "TRAIN_NEGATIVES_PER_QUERY", "+", "1", ")", "\n", "q_output", "=", "[", "]", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "q_index", "in", "range", "(", "len", "(", "train_file_idxs", ")", "//", "batch_num", ")", ":", "\n", "        ", "file_indices", "=", "train_file_idxs", "[", "q_index", "*", "batch_num", ":", "(", "q_index", "+", "1", ")", "*", "(", "batch_num", ")", "]", "\n", "file_names", "=", "[", "]", "\n", "for", "index", "in", "file_indices", ":", "\n", "            ", "file_names", ".", "append", "(", "dict_to_process", "[", "index", "]", "[", "\"query\"", "]", ")", "\n", "", "queries", "=", "load_pc_files", "(", "file_names", ")", "\n", "\n", "feed_tensor", "=", "torch", ".", "from_numpy", "(", "queries", ")", ".", "float", "(", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "unsqueeze", "(", "1", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "to", "(", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "out", "=", "model", "(", "feed_tensor", ")", "\n", "\n", "", "out", "=", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out", "=", "np", ".", "squeeze", "(", "out", ")", "\n", "\n", "q_output", ".", "append", "(", "out", ")", "\n", "\n", "", "q_output", "=", "np", ".", "array", "(", "q_output", ")", "\n", "if", "(", "len", "(", "q_output", ")", "!=", "0", ")", ":", "\n", "        ", "q_output", "=", "q_output", ".", "reshape", "(", "-", "1", ",", "q_output", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# handle edge case", "\n", "", "for", "q_index", "in", "range", "(", "(", "len", "(", "train_file_idxs", ")", "//", "batch_num", "*", "batch_num", ")", ",", "len", "(", "dict_to_process", ".", "keys", "(", ")", ")", ")", ":", "\n", "        ", "index", "=", "train_file_idxs", "[", "q_index", "]", "\n", "queries", "=", "load_pc_files", "(", "[", "dict_to_process", "[", "index", "]", "[", "\"query\"", "]", "]", ")", "\n", "queries", "=", "np", ".", "expand_dims", "(", "queries", ",", "axis", "=", "1", ")", "\n", "\n", "# if (BATCH_NUM_QUERIES - 1 > 0):", "\n", "#    fake_queries = np.zeros((BATCH_NUM_QUERIES - 1, 1, NUM_POINTS, 3))", "\n", "#    q = np.vstack((queries, fake_queries))", "\n", "# else:", "\n", "#    q = queries", "\n", "\n", "#fake_pos = np.zeros((BATCH_NUM_QUERIES, POSITIVES_PER_QUERY, NUM_POINTS, 3))", "\n", "#fake_neg = np.zeros((BATCH_NUM_QUERIES, NEGATIVES_PER_QUERY, NUM_POINTS, 3))", "\n", "#fake_other_neg = np.zeros((BATCH_NUM_QUERIES, 1, NUM_POINTS, 3))", "\n", "#o1, o2, o3, o4 = run_model(model, q, fake_pos, fake_neg, fake_other_neg)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "queries_tensor", "=", "torch", ".", "from_numpy", "(", "queries", ")", ".", "float", "(", ")", "\n", "o1", "=", "model", "(", "queries_tensor", ")", "\n", "\n", "", "output", "=", "o1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "output", "=", "np", ".", "squeeze", "(", "output", ")", "\n", "if", "(", "q_output", ".", "shape", "[", "0", "]", "!=", "0", ")", ":", "\n", "            ", "q_output", "=", "np", ".", "vstack", "(", "(", "q_output", ",", "output", ")", ")", "\n", "", "else", ":", "\n", "            ", "q_output", "=", "output", "\n", "\n", "", "", "model", ".", "train", "(", ")", "\n", "print", "(", "q_output", ".", "shape", ")", "\n", "return", "q_output", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.None.train.run_model": [[471, 491], ["torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.cat", "torch.cat", "feed_tensor.to.view", "feed_tensor.to.requires_grad_", "feed_tensor.to.to", "model.view", "torch.split", "torch.split", "model", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.no_grad", "torch.no_grad", "model"], "function", ["None"], ["", "def", "run_model", "(", "model", ",", "queries", ",", "positives", ",", "negatives", ",", "other_neg", ",", "require_grad", "=", "True", ")", ":", "\n", "    ", "queries_tensor", "=", "torch", ".", "from_numpy", "(", "queries", ")", ".", "float", "(", ")", "\n", "positives_tensor", "=", "torch", ".", "from_numpy", "(", "positives", ")", ".", "float", "(", ")", "\n", "negatives_tensor", "=", "torch", ".", "from_numpy", "(", "negatives", ")", ".", "float", "(", ")", "\n", "other_neg_tensor", "=", "torch", ".", "from_numpy", "(", "other_neg", ")", ".", "float", "(", ")", "\n", "feed_tensor", "=", "torch", ".", "cat", "(", "(", "queries_tensor", ",", "positives_tensor", ",", "negatives_tensor", ",", "other_neg_tensor", ")", ",", "1", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "view", "(", "(", "-", "1", ",", "1", ",", "cfg", ".", "NUM_POINTS", ",", "12", ")", ")", "\n", "\n", "feed_tensor", ".", "requires_grad_", "(", "require_grad", ")", "\n", "feed_tensor", "=", "feed_tensor", ".", "to", "(", "device", ")", "\n", "if", "require_grad", ":", "\n", "        ", "output", "=", "model", "(", "feed_tensor", ")", "\n", "", "else", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "feed_tensor", ")", "\n", "", "", "output", "=", "output", ".", "view", "(", "cfg", ".", "BATCH_NUM_QUERIES", ",", "-", "1", ",", "cfg", ".", "FEATURE_OUTPUT_DIM", ")", "\n", "o1", ",", "o2", ",", "o3", ",", "o4", "=", "torch", ".", "split", "(", "\n", "output", ",", "[", "1", ",", "cfg", ".", "TRAIN_POSITIVES_PER_QUERY", ",", "cfg", ".", "TRAIN_NEGATIVES_PER_QUERY", ",", "1", "]", ",", "dim", "=", "1", ")", "\n", "\n", "return", "o1", ",", "o2", ",", "o3", ",", "o4", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.Transformer.STN3d.__init__": [[11, 35], ["torch.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "Transformer.STN3d.fc3.weight.data.zero_", "Transformer.STN3d.fc3.bias.data.zero_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_points", "=", "2500", ",", "k", "=", "3", ",", "use_bn", "=", "True", ")", ":", "\n", "        ", "super", "(", "STN3d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "kernel_size", "=", "3", "if", "k", "==", "3", "else", "1", "\n", "self", ".", "channels", "=", "1", "if", "k", "==", "3", "else", "k", "\n", "self", ".", "num_points", "=", "num_points", "\n", "self", ".", "use_bn", "=", "use_bn", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "self", ".", "channels", ",", "64", ",", "(", "1", ",", "self", ".", "kernel_size", ")", ")", "\n", "self", ".", "conv2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "conv3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "128", ",", "1024", ",", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "mp1", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "(", "num_points", ",", "1", ")", ",", "1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1024", ",", "512", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "512", ",", "256", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "256", ",", "k", "*", "k", ")", "\n", "self", ".", "fc3", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "fc3", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "if", "use_bn", ":", "\n", "            ", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "1024", ")", "\n", "self", ".", "bn4", "=", "nn", ".", "BatchNorm1d", "(", "512", ")", "\n", "self", ".", "bn5", "=", "nn", ".", "BatchNorm1d", "(", "256", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.Transformer.STN3d.forward": [[36, 63], ["Transformer.STN3d.mp1", "torch.relu.view", "Transformer.STN3d.fc3", "torch.autograd.Variable().view().repeat", "torch.autograd.Variable().view().repeat", "torch.autograd.Variable().view().repeat", "torch.relu.view", "torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "iden.cuda.cuda.cuda", "Transformer.STN3d.bn1", "Transformer.STN3d.bn2", "Transformer.STN3d.bn3", "Transformer.STN3d.conv1", "Transformer.STN3d.conv2", "Transformer.STN3d.conv3", "Transformer.STN3d.bn4", "Transformer.STN3d.bn5", "Transformer.STN3d.fc1", "Transformer.STN3d.fc2", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "Transformer.STN3d.conv1", "Transformer.STN3d.conv2", "Transformer.STN3d.conv3", "Transformer.STN3d.fc1", "Transformer.STN3d.fc2", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.eye().astype", "numpy.eye"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batchsize", "=", "x", ".", "size", "(", ")", "[", "0", "]", "\n", "if", "self", ".", "use_bn", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "", "x", "=", "self", ".", "mp1", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1024", ")", "\n", "\n", "if", "self", ".", "use_bn", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "bn4", "(", "self", ".", "fc1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn5", "(", "self", ".", "fc2", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "\n", "iden", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "np", ".", "eye", "(", "self", ".", "k", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ")", ".", "view", "(", "1", ",", "self", ".", "k", "*", "self", ".", "k", ")", ".", "repeat", "(", "batchsize", ",", "1", ")", "\n", "if", "x", ".", "is_cuda", ":", "\n", "            ", "iden", "=", "iden", ".", "cuda", "(", ")", "\n", "", "x", "=", "x", "+", "iden", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "k", ",", "self", ".", "k", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.Transformer.Transformer.__init__": [[66, 82], ["torch.Module.__init__", "Transformer.STN3d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder"], "methods", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_points", "=", "2000", ",", "emb_dims", "=", "1024", ",", "layer_number", "=", "3", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "point_trans", "=", "STN3d", "(", "num_points", "=", "num_points", ",", "k", "=", "3", ",", "use_bn", "=", "False", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "12", ",", "256", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "256", "*", "2", ",", "emb_dims", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "emb_dims", ")", "\n", "\n", "encoder_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "d_model", "=", "256", ",", "nhead", "=", "4", ",", "dim_feedforward", "=", "1024", ",", "activation", "=", "'relu'", ")", "\n", "self", ".", "transformer_encoder", "=", "torch", ".", "nn", ".", "TransformerEncoder", "(", "encoder_layer", ",", "num_layers", "=", "layer_number", ")", "\n", "\n", "\n", "self", ".", "point_transform", "=", "True", "\n", "self", ".", "convariance_transform", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.Transformer.Transformer.forward": [[83, 125], ["torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.unsqueeze.size", "torch.unsqueeze.size", "torch.unsqueeze.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.relu", "torch.relu", "torch.relu", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "Transformer.Transformer.transformer_encoder", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "Transformer.Transformer.point_trans", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.unsqueeze.view", "torch.unsqueeze.view", "torch.unsqueeze.view", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze.permute", "torch.unsqueeze.view", "torch.unsqueeze.view", "torch.unsqueeze.view", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "Transformer.Transformer.bn1", "Transformer.Transformer.bn2", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "Transformer.Transformer.transpose().contiguous", "Transformer.Transformer.conv1", "Transformer.Transformer.conv2", "Transformer.Transformer.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# print('x.size', x.size())", "\n", "        ", "x", ",", "y", "=", "torch", ".", "split", "(", "x", ",", "[", "3", ",", "9", "]", ",", "dim", "=", "3", ")", "\n", "batch_size", ",", "_", ",", "num_points", ",", "num_dims", "=", "x", ".", "size", "(", ")", "\n", "\n", "if", "self", ".", "point_transform", ":", "\n", "# print(\"Using point propagation!\")", "\n", "            ", "trans", "=", "self", ".", "point_trans", "(", "x", ")", "\n", "x", "=", "torch", ".", "matmul", "(", "torch", ".", "squeeze", "(", "x", ")", ",", "trans", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "self", ".", "convariance_transform", ":", "\n", "# print(\"Using convariance propagation!\")", "\n", "            ", "y", "=", "torch", ".", "squeeze", "(", "y", ",", "dim", "=", "1", ")", "\n", "y", "=", "y", ".", "view", "(", "batch_size", ",", "num_points", ",", "num_dims", ",", "num_dims", ")", "\n", "y", "=", "y", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "y", "=", "torch", ".", "matmul", "(", "trans", ".", "transpose", "(", "2", ",", "1", ")", ".", "contiguous", "(", ")", ",", "y", ")", "\n", "y", "=", "torch", ".", "matmul", "(", "y", ",", "trans", ")", "\n", "\n", "# y = torch.matmul(trans, y) ", "\n", "# y = torch.matmul(y, trans.transpose(2, 1).contiguous())  ", "\n", "\n", "y", "=", "y", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "y", "=", "y", ".", "view", "(", "batch_size", ",", "num_points", ",", "num_dims", "*", "num_dims", ")", "\n", "y", "=", "torch", ".", "unsqueeze", "(", "y", ",", "dim", "=", "1", ")", "\n", "\n", "", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "y", ")", ",", "dim", "=", "3", ")", "\n", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "2", ",", "1", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "\n", "x", "=", "torch", ".", "squeeze", "(", "x1", ",", "dim", "=", "3", ")", "\n", "x", "=", "x", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "x", "=", "self", ".", "transformer_encoder", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "dim", "=", "3", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x1", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "\n", "return", "x2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NDTNetVlad.NDTNetVlad.__init__": [[12, 18], ["torch.Module.__init__", "Transformer.Transformer.Transformer", "NetVLAD.NetVLADLoupe"], "methods", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_points", "=", "2000", ",", "output_dim", "=", "256", ",", "emb_dims", "=", "1024", ",", "layer_number", "=", "3", ")", ":", "\n", "        ", "super", "(", "NDTNetVlad", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Transformer", "=", "Transformer", "(", "num_points", "=", "num_points", ",", "emb_dims", "=", "emb_dims", ",", "layer_number", "=", "layer_number", ")", "\n", "self", ".", "net_vlad", "=", "NetVLADLoupe", "(", "feature_size", "=", "1024", ",", "max_samples", "=", "num_points", ",", "cluster_size", "=", "64", ",", "\n", "output_dim", "=", "output_dim", ",", "gating", "=", "True", ",", "add_batch_norm", "=", "True", ",", "\n", "is_training", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NDTNetVlad.NDTNetVlad.forward": [[19, 23], ["NDTNetVlad.NDTNetVlad.Transformer", "NDTNetVlad.NDTNetVlad.net_vlad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "Transformer", "(", "x", ")", "\n", "x", "=", "self", ".", "net_vlad", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.NetVLADLoupe.__init__": [[8, 40], ["torch.Module.__init__", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "NetVLAD.GatingContext", "math.sqrt", "math.sqrt", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feature_size", ",", "max_samples", ",", "cluster_size", ",", "output_dim", ",", "\n", "gating", "=", "True", ",", "add_batch_norm", "=", "True", ",", "is_training", "=", "True", ")", ":", "\n", "        ", "super", "(", "NetVLADLoupe", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "max_samples", "=", "max_samples", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "gating", "=", "gating", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "cluster_size", "=", "cluster_size", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "cluster_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "\n", "feature_size", ",", "cluster_size", ")", "*", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", "\n", "self", ".", "cluster_weights2", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "\n", "1", ",", "feature_size", ",", "cluster_size", ")", "*", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", "\n", "self", ".", "hidden1_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "\n", "cluster_size", "*", "feature_size", ",", "output_dim", ")", "*", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "self", ".", "cluster_biases", "=", "None", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "cluster_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cluster_biases", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "\n", "cluster_size", ")", "*", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", "\n", "self", ".", "bn1", "=", "None", "\n", "\n", "", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "output_dim", ")", "\n", "\n", "if", "gating", ":", "\n", "            ", "self", ".", "context_gating", "=", "GatingContext", "(", "\n", "output_dim", ",", "add_batch_norm", "=", "add_batch_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.NetVLADLoupe.forward": [[41, 78], ["x.view.view.transpose().contiguous", "x.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "NetVLAD.NetVLADLoupe.softmax", "activation.view.view.view", "activation.view.view.sum", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "x.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.normalize", "torch.normalize", "torch.normalize", "NetVLAD.NetVLADLoupe.reshape", "torch.normalize", "torch.normalize", "torch.normalize", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "NetVLAD.NetVLADLoupe.bn2", "activation.view.view.view", "NetVLAD.NetVLADLoupe.bn1", "activation.view.view.view", "NetVLAD.NetVLADLoupe.context_gating", "x.view.view.transpose"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "transpose", "(", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "(", "-", "1", ",", "self", ".", "max_samples", ",", "self", ".", "feature_size", ")", ")", "\n", "activation", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "cluster_weights", ")", "\n", "if", "self", ".", "add_batch_norm", ":", "\n", "# activation = activation.transpose(1,2).contiguous()", "\n", "            ", "activation", "=", "activation", ".", "view", "(", "-", "1", ",", "self", ".", "cluster_size", ")", "\n", "activation", "=", "self", ".", "bn1", "(", "activation", ")", "\n", "activation", "=", "activation", ".", "view", "(", "-", "1", ",", "self", ".", "max_samples", ",", "self", ".", "cluster_size", ")", "\n", "# activation = activation.transpose(1,2).contiguous()", "\n", "", "else", ":", "\n", "            ", "activation", "=", "activation", "+", "self", ".", "cluster_biases", "\n", "", "activation", "=", "self", ".", "softmax", "(", "activation", ")", "\n", "activation", "=", "activation", ".", "view", "(", "(", "-", "1", ",", "self", ".", "max_samples", ",", "self", ".", "cluster_size", ")", ")", "\n", "\n", "a_sum", "=", "activation", ".", "sum", "(", "-", "2", ",", "keepdim", "=", "True", ")", "\n", "a", "=", "a_sum", "*", "self", ".", "cluster_weights2", "\n", "\n", "activation", "=", "torch", ".", "transpose", "(", "activation", ",", "2", ",", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "(", "-", "1", ",", "self", ".", "max_samples", ",", "self", ".", "feature_size", ")", ")", "\n", "vlad", "=", "torch", ".", "matmul", "(", "activation", ",", "x", ")", "\n", "vlad", "=", "torch", ".", "transpose", "(", "vlad", ",", "2", ",", "1", ")", "\n", "vlad", "=", "vlad", "-", "a", "\n", "\n", "vlad", "=", "F", ".", "normalize", "(", "vlad", ",", "dim", "=", "1", ",", "p", "=", "2", ")", "\n", "# vlad = vlad.view((-1, self.cluster_size * self.feature_size))", "\n", "vlad", "=", "vlad", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", ")", ")", "\n", "vlad", "=", "F", ".", "normalize", "(", "vlad", ",", "dim", "=", "1", ",", "p", "=", "2", ")", "\n", "\n", "vlad", "=", "torch", ".", "matmul", "(", "vlad", ",", "self", ".", "hidden1_weights", ")", "\n", "\n", "vlad", "=", "self", ".", "bn2", "(", "vlad", ")", "\n", "\n", "if", "self", ".", "gating", ":", "\n", "            ", "vlad", "=", "self", ".", "context_gating", "(", "vlad", ")", "\n", "\n", "", "return", "vlad", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.__init__": [[81, 96], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "add_batch_norm", "=", "True", ")", ":", "\n", "        ", "super", "(", "GatingContext", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "gating_weights", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "dim", ",", "dim", ")", "*", "1", "/", "math", ".", "sqrt", "(", "dim", ")", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "self", ".", "gating_biases", "=", "None", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gating_biases", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "dim", ")", "*", "1", "/", "math", ".", "sqrt", "(", "dim", ")", ")", "\n", "self", ".", "bn1", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.models.NetVLAD.GatingContext.forward": [[97, 110], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "NetVLAD.GatingContext.sigmoid", "NetVLAD.GatingContext.bn1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "gates", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "gating_weights", ")", "\n", "\n", "if", "self", ".", "add_batch_norm", ":", "\n", "            ", "gates", "=", "self", ".", "bn1", "(", "gates", ")", "\n", "", "else", ":", "\n", "            ", "gates", "=", "gates", "+", "self", ".", "gating_biases", "\n", "\n", "", "gates", "=", "self", ".", "sigmoid", "(", "gates", ")", "\n", "\n", "activation", "=", "x", "*", "gates", "\n", "\n", "return", "activation", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_training_tuples_baseline.check_in_test_set": [[37, 45], ["None"], "function", ["None"], ["def", "check_in_test_set", "(", "northing", ",", "easting", ",", "points", ",", "x_width", ",", "y_width", ")", ":", "\n", "    ", "in_test_set", "=", "False", "\n", "for", "point", "in", "points", ":", "\n", "        ", "if", "northing", "+", "x_width", ">", "point", "[", "0", "]", ">", "northing", "-", "x_width", "and", "easting", "-", "y_width", "<", "point", "[", "1", "]", "<", "easting", "+", "y_width", ":", "\n", "            ", "in_test_set", "=", "True", "\n", "break", "\n", "", "", "return", "in_test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_training_tuples_baseline.construct_query_dict": [[46, 63], ["sklearn.neighbors.KDTree", "sklearn.neighbors.KDTree.query_radius", "sklearn.neighbors.KDTree.query_radius", "range", "print", "len", "numpy.setdiff1d().tolist", "numpy.setdiff1d().tolist", "random.shuffle", "open", "pickle.dump", "numpy.setdiff1d", "numpy.setdiff1d", "df_centroids.index.values.tolist"], "function", ["None"], ["", "def", "construct_query_dict", "(", "df_centroids", ",", "filename", ")", ":", "\n", "    ", "tree", "=", "KDTree", "(", "df_centroids", "[", "[", "'northing'", ",", "'easting'", "]", "]", ")", "\n", "# index", "\n", "ind_nn", "=", "tree", ".", "query_radius", "(", "df_centroids", "[", "[", "'northing'", ",", "'easting'", "]", "]", ",", "r", "=", "10", ")", "\n", "ind_r", "=", "tree", ".", "query_radius", "(", "df_centroids", "[", "[", "'northing'", ",", "'easting'", "]", "]", ",", "r", "=", "50", ")", "\n", "queries", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "ind_nn", ")", ")", ":", "\n", "        ", "query", "=", "df_centroids", ".", "iloc", "[", "i", "]", "[", "\"file\"", "]", "\n", "# np.setdiff1d: Return the unique values in ar1 that are not in ar2.", "\n", "positives", "=", "np", ".", "setdiff1d", "(", "ind_nn", "[", "i", "]", ",", "[", "i", "]", ")", ".", "tolist", "(", ")", "\n", "negatives", "=", "np", ".", "setdiff1d", "(", "df_centroids", ".", "index", ".", "values", ".", "tolist", "(", ")", ",", "ind_r", "[", "i", "]", ")", ".", "tolist", "(", ")", "\n", "random", ".", "shuffle", "(", "negatives", ")", "\n", "queries", "[", "i", "]", "=", "{", "\"query\"", ":", "query", ",", "\"positives\"", ":", "positives", ",", "\"negatives\"", ":", "negatives", "}", "\n", "", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "queries", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "print", "(", "\"Done \"", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.check_in_test_set": [[22, 30], ["None"], "function", ["None"], ["def", "check_in_test_set", "(", "northing", ",", "easting", ",", "points", ",", "x_width", ",", "y_width", ")", ":", "\n", "    ", "in_test_set", "=", "False", "\n", "for", "point", "in", "points", ":", "\n", "        ", "if", "(", "point", "[", "0", "]", "-", "x_width", "<", "northing", "and", "northing", "<", "point", "[", "0", "]", "+", "x_width", "and", "point", "[", "\n", "1", "]", "-", "y_width", "<", "easting", "and", "easting", "<", "point", "[", "1", "]", "+", "y_width", ")", ":", "\n", "            ", "in_test_set", "=", "True", "\n", "break", "\n", "", "", "return", "in_test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.output_to_file": [[34, 38], ["print", "open", "pickle.dump"], "function", ["None"], ["", "def", "output_to_file", "(", "output", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "output", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "print", "(", "\"Done \"", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.construct_query_and_database_sets": [[40, 100], ["print", "print", "print", "print", "range", "generate_test_sets.output_to_file", "generate_test_sets.output_to_file", "pandas.DataFrame", "pandas.DataFrame", "pandas.read_csv", "df_locations.rename.iterrows", "sklearn.neighbors.KDTree", "sklearn.neighbors.KDTree", "database_trees.append", "test_trees.append", "print", "pandas.read_csv", "df_locations.rename.rename", "df_locations.rename.iterrows", "database_sets.append", "test_sets.append", "len", "len", "len", "range", "os.path.join", "df_database.append.append", "os.path.join", "len", "range", "df_test.append.append", "generate_test_sets.check_in_test_set", "generate_test_sets.check_in_test_set", "len", "numpy.array", "tree.query_radius", "index[].tolist", "df_test.append.append", "str", "len", "test_sets[].keys", "len", "database.keys", "test.keys", "len", "test.keys"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.output_to_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.output_to_file", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.check_in_test_set", "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.generating_queries.generate_test_sets.check_in_test_set"], ["", "def", "construct_query_and_database_sets", "(", "base_path", ",", "runs_folder", ",", "folders", ",", "pointcloud_fols", ",", "filename", ",", "p", ",", "output_name", ")", ":", "\n", "    ", "database_trees", "=", "[", "]", "\n", "test_trees", "=", "[", "]", "\n", "count", "=", "0", "\n", "count_2", "=", "0", "\n", "for", "folder", "in", "folders", ":", "\n", "        ", "df_database", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'timestamp'", ",", "'northing'", ",", "'easting'", "]", ")", "\n", "df_test", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'timestamp'", ",", "'northing'", ",", "'easting'", "]", ")", "\n", "\n", "df_locations", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "base_path", ",", "runs_folder", ",", "folder", ",", "filename", ")", ",", "sep", "=", "','", ")", "\n", "for", "_", ",", "row", "in", "df_locations", ".", "iterrows", "(", ")", ":", "\n", "# entire business district is in the test set", "\n", "            ", "if", "output_name", "==", "\"business\"", ":", "\n", "                ", "df_test", "=", "df_test", ".", "append", "(", "row", ",", "ignore_index", "=", "True", ")", "\n", "", "elif", "check_in_test_set", "(", "row", "[", "'northing'", "]", ",", "row", "[", "'easting'", "]", ",", "p", ",", "x_width", ",", "y_width", ")", ":", "\n", "                ", "df_test", "=", "df_test", ".", "append", "(", "row", ",", "ignore_index", "=", "True", ")", "\n", "count_2", "+=", "1", "\n", "", "df_database", "=", "df_database", ".", "append", "(", "row", ",", "ignore_index", "=", "True", ")", "\n", "count", "+=", "1", "\n", "", "database_tree", "=", "KDTree", "(", "df_database", "[", "[", "'northing'", ",", "'easting'", "]", "]", ")", "\n", "test_tree", "=", "KDTree", "(", "df_test", "[", "[", "'northing'", ",", "'easting'", "]", "]", ")", "\n", "database_trees", ".", "append", "(", "database_tree", ")", "\n", "test_trees", ".", "append", "(", "test_tree", ")", "\n", "", "print", "(", "count", ")", "\n", "print", "(", "count_2", ")", "\n", "test_sets", "=", "[", "]", "\n", "database_sets", "=", "[", "]", "\n", "for", "folder", "in", "folders", ":", "\n", "        ", "print", "(", "folder", ")", "\n", "database", "=", "{", "}", "\n", "test", "=", "{", "}", "\n", "df_locations", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "base_path", ",", "runs_folder", ",", "folder", ",", "filename", ")", ",", "sep", "=", "','", ")", "\n", "df_locations", "=", "df_locations", ".", "rename", "(", "columns", "=", "{", "'timestamp'", ":", "'file'", "}", ")", "\n", "for", "index", ",", "row", "in", "df_locations", ".", "iterrows", "(", ")", ":", "\n", "            ", "row", "[", "'file'", "]", "=", "runs_folder", "+", "folder", "+", "pointcloud_fols", "+", "\"cloud_\"", "+", "str", "(", "index", ")", "+", "\"_ndt.bin\"", "\n", "if", "output_name", "==", "\"business\"", ":", "\n", "                ", "test", "[", "len", "(", "test", ".", "keys", "(", ")", ")", "]", "=", "{", "'query'", ":", "row", "[", "'file'", "]", ",", "'northing'", ":", "row", "[", "'northing'", "]", ",", "'easting'", ":", "row", "[", "'easting'", "]", "}", "\n", "", "elif", "check_in_test_set", "(", "row", "[", "'northing'", "]", ",", "row", "[", "'easting'", "]", ",", "p", ",", "x_width", ",", "y_width", ")", ":", "\n", "                ", "test", "[", "len", "(", "test", ".", "keys", "(", ")", ")", "]", "=", "{", "'query'", ":", "row", "[", "'file'", "]", ",", "'northing'", ":", "row", "[", "'northing'", "]", ",", "'easting'", ":", "row", "[", "'easting'", "]", "}", "\n", "", "database", "[", "len", "(", "database", ".", "keys", "(", ")", ")", "]", "=", "{", "'query'", ":", "row", "[", "'file'", "]", ",", "'northing'", ":", "row", "[", "'northing'", "]", ",", "\n", "'easting'", ":", "row", "[", "'easting'", "]", "}", "\n", "\n", "", "database_sets", ".", "append", "(", "database", ")", "\n", "test_sets", ".", "append", "(", "test", ")", "\n", "", "print", "(", "len", "(", "database_sets", ")", ")", "\n", "print", "(", "len", "(", "test_sets", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "database_sets", ")", ")", ":", "\n", "        ", "tree", "=", "database_trees", "[", "i", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "test_sets", ")", ")", ":", "\n", "            ", "if", "(", "i", "==", "j", ")", ":", "\n", "                ", "continue", "\n", "", "for", "key", "in", "range", "(", "len", "(", "test_sets", "[", "j", "]", ".", "keys", "(", ")", ")", ")", ":", "\n", "                ", "coor", "=", "np", ".", "array", "(", "[", "[", "test_sets", "[", "j", "]", "[", "key", "]", "[", "\"northing\"", "]", ",", "test_sets", "[", "j", "]", "[", "key", "]", "[", "\"easting\"", "]", "]", "]", ")", "\n", "\n", "index", "=", "tree", ".", "query_radius", "(", "coor", ",", "r", "=", "25", ")", "\n", "# indices of the positive matches in database i of each query (key) in test set j", "\n", "test_sets", "[", "j", "]", "[", "key", "]", "[", "i", "]", "=", "index", "[", "0", "]", ".", "tolist", "(", ")", "\n", "", "", "", "output_to_file", "(", "database_sets", ",", "output_name", "+", "'_evaluation_database.pickle'", ")", "\n", "output_to_file", "(", "test_sets", ",", "output_name", "+", "'_evaluation_query.pickle'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.best_pos_distance": [[14, 21], ["query.repeat", "diff.min", "diff.max", "int"], "function", ["None"], ["def", "best_pos_distance", "(", "query", ",", "pos_vecs", ")", ":", "\n", "    ", "num_pos", "=", "pos_vecs", ".", "shape", "[", "1", "]", "\n", "query_copies", "=", "query", ".", "repeat", "(", "1", ",", "int", "(", "num_pos", ")", ",", "1", ")", "\n", "diff", "=", "(", "(", "pos_vecs", "-", "query_copies", ")", "**", "2", ")", ".", "sum", "(", "2", ")", "\n", "min_pos", ",", "_", "=", "diff", ".", "min", "(", "1", ")", "\n", "max_pos", ",", "_", "=", "diff", ".", "max", "(", "1", ")", "\n", "return", "min_pos", ",", "max_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.triplet_loss": [[23, 51], ["loss.best_pos_distance", "q_vec.repeat", "positive.repeat.view", "positive.repeat.repeat", "loss.clamp.clamp", "int", "int", "loss.clamp.sum", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.sum", "torch.sum", "torch.sum", "triplet_loss.mean.mean", "loss.clamp.max", "triplet_loss.mean.sum", "torch.gt", "torch.gt", "torch.gt"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.best_pos_distance"], ["", "def", "triplet_loss", "(", "q_vec", ",", "pos_vecs", ",", "neg_vecs", ",", "margin", ",", "use_min", "=", "False", ",", "lazy", "=", "False", ",", "ignore_zero_loss", "=", "False", ")", ":", "\n", "    ", "min_pos", ",", "max_pos", "=", "best_pos_distance", "(", "q_vec", ",", "pos_vecs", ")", "\n", "\n", "# PointNetVLAD official code use min_pos, but i think max_pos should be used", "\n", "if", "use_min", ":", "\n", "        ", "positive", "=", "min_pos", "\n", "", "else", ":", "\n", "        ", "positive", "=", "max_pos", "\n", "\n", "", "num_neg", "=", "neg_vecs", ".", "shape", "[", "1", "]", "\n", "batch", "=", "q_vec", ".", "shape", "[", "0", "]", "\n", "query_copies", "=", "q_vec", ".", "repeat", "(", "1", ",", "int", "(", "num_neg", ")", ",", "1", ")", "\n", "positive", "=", "positive", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "positive", "=", "positive", ".", "repeat", "(", "1", ",", "int", "(", "num_neg", ")", ")", "\n", "\n", "loss", "=", "margin", "+", "positive", "-", "(", "(", "neg_vecs", "-", "query_copies", ")", "**", "2", ")", ".", "sum", "(", "2", ")", "\n", "loss", "=", "loss", ".", "clamp", "(", "min", "=", "0.0", ")", "\n", "if", "lazy", ":", "\n", "        ", "triplet_loss", "=", "loss", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "triplet_loss", "=", "loss", ".", "sum", "(", "1", ")", "\n", "", "if", "ignore_zero_loss", ":", "\n", "        ", "hard_triplets", "=", "torch", ".", "gt", "(", "triplet_loss", ",", "1e-16", ")", ".", "float", "(", ")", "\n", "num_hard_triplets", "=", "torch", ".", "sum", "(", "hard_triplets", ")", "\n", "triplet_loss", "=", "triplet_loss", ".", "sum", "(", ")", "/", "(", "num_hard_triplets", "+", "1e-16", ")", "\n", "", "else", ":", "\n", "        ", "triplet_loss", "=", "triplet_loss", ".", "mean", "(", ")", "\n", "", "return", "triplet_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.triplet_loss_wrapper": [[53, 55], ["loss.triplet_loss"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.triplet_loss"], ["", "def", "triplet_loss_wrapper", "(", "q_vec", ",", "pos_vecs", ",", "neg_vecs", ",", "other_neg", ",", "m1", ",", "m2", ",", "use_min", "=", "False", ",", "lazy", "=", "False", ",", "ignore_zero_loss", "=", "False", ")", ":", "\n", "    ", "return", "triplet_loss", "(", "q_vec", ",", "pos_vecs", ",", "neg_vecs", ",", "m1", ",", "use_min", ",", "lazy", ",", "ignore_zero_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.quadruplet_loss": [[57, 102], ["loss.best_pos_distance", "q_vec.repeat", "positive.repeat.view", "positive.repeat.repeat", "loss.clamp.clamp", "other_neg.repeat", "second_loss.mean.clamp", "int", "int", "loss.clamp.sum", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.sum", "torch.sum", "torch.sum", "triplet_loss.mean.mean", "int", "second_loss.mean.sum", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.sum", "torch.sum", "torch.sum", "second_loss.mean.mean", "loss.clamp.max", "triplet_loss.mean.sum", "second_loss.mean.max", "second_loss.mean.sum", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt"], "function", ["home.repos.pwc.inspect_result.dachengxiaocheng_NDT-Transformer.loss.loss.best_pos_distance"], ["", "def", "quadruplet_loss", "(", "q_vec", ",", "pos_vecs", ",", "neg_vecs", ",", "other_neg", ",", "m1", ",", "m2", ",", "use_min", "=", "False", ",", "lazy", "=", "False", ",", "ignore_zero_loss", "=", "False", ")", ":", "\n", "    ", "min_pos", ",", "max_pos", "=", "best_pos_distance", "(", "q_vec", ",", "pos_vecs", ")", "\n", "\n", "# PointNetVLAD official code use min_pos, but i think max_pos should be used", "\n", "if", "use_min", ":", "\n", "        ", "positive", "=", "min_pos", "\n", "", "else", ":", "\n", "        ", "positive", "=", "max_pos", "\n", "\n", "", "num_neg", "=", "neg_vecs", ".", "shape", "[", "1", "]", "\n", "batch", "=", "q_vec", ".", "shape", "[", "0", "]", "\n", "query_copies", "=", "q_vec", ".", "repeat", "(", "1", ",", "int", "(", "num_neg", ")", ",", "1", ")", "\n", "positive", "=", "positive", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "positive", "=", "positive", ".", "repeat", "(", "1", ",", "int", "(", "num_neg", ")", ")", "\n", "\n", "loss", "=", "m1", "+", "positive", "-", "(", "(", "neg_vecs", "-", "query_copies", ")", "**", "2", ")", ".", "sum", "(", "2", ")", "\n", "loss", "=", "loss", ".", "clamp", "(", "min", "=", "0.0", ")", "\n", "if", "lazy", ":", "\n", "        ", "triplet_loss", "=", "loss", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "triplet_loss", "=", "loss", ".", "sum", "(", "1", ")", "\n", "", "if", "ignore_zero_loss", ":", "\n", "        ", "hard_triplets", "=", "torch", ".", "gt", "(", "triplet_loss", ",", "1e-16", ")", ".", "float", "(", ")", "\n", "num_hard_triplets", "=", "torch", ".", "sum", "(", "hard_triplets", ")", "\n", "triplet_loss", "=", "triplet_loss", ".", "sum", "(", ")", "/", "(", "num_hard_triplets", "+", "1e-16", ")", "\n", "", "else", ":", "\n", "        ", "triplet_loss", "=", "triplet_loss", ".", "mean", "(", ")", "\n", "\n", "", "other_neg_copies", "=", "other_neg", ".", "repeat", "(", "1", ",", "int", "(", "num_neg", ")", ",", "1", ")", "\n", "second_loss", "=", "m2", "+", "positive", "-", "(", "(", "neg_vecs", "-", "other_neg_copies", ")", "**", "2", ")", ".", "sum", "(", "2", ")", "\n", "second_loss", "=", "second_loss", ".", "clamp", "(", "min", "=", "0.0", ")", "\n", "if", "lazy", ":", "\n", "        ", "second_loss", "=", "second_loss", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "second_loss", "=", "second_loss", ".", "sum", "(", "1", ")", "\n", "\n", "", "if", "ignore_zero_loss", ":", "\n", "        ", "hard_second", "=", "torch", ".", "gt", "(", "second_loss", ",", "1e-16", ")", ".", "float", "(", ")", "\n", "num_hard_second", "=", "torch", ".", "sum", "(", "hard_second", ")", "\n", "second_loss", "=", "second_loss", ".", "sum", "(", ")", "/", "(", "num_hard_second", "+", "1e-16", ")", "\n", "", "else", ":", "\n", "        ", "second_loss", "=", "second_loss", ".", "mean", "(", ")", "\n", "\n", "", "total_loss", "=", "triplet_loss", "+", "second_loss", "\n", "return", "total_loss", "", "", ""]]}