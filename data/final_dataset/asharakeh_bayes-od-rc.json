{"home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils._check_config_name": [[7, 13], ["os.path.splitext", "ValueError", "os.path.basename"], "function", ["None"], ["def", "_check_config_name", "(", "config", ",", "yaml_path", ")", ":", "\n", "# Check if config and checkpoint name match", "\n", "    ", "checkpoint_name", "=", "config", "[", "'checkpoint_name'", "]", "\n", "config_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "yaml_path", ")", ")", "[", "0", "]", "\n", "if", "config_name", "!=", "checkpoint_name", ":", "\n", "        ", "raise", "ValueError", "(", "'Config and checkpoint names must match.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils._add_ckpt_paths": [[15, 34], ["os.path.join", "src.data_dir", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir"], ["", "", "def", "_add_ckpt_paths", "(", "config", ")", ":", "\n", "    ", "\"\"\"Adds new entries to the config for the checkpoint path\n        checkpoint_dir - output checkpoint directory\n        checkpoint_path - output checkpoint path\n    \"\"\"", "\n", "checkpoint_name", "=", "config", "[", "'checkpoint_name'", "]", "\n", "\n", "# Make checkpoint directories", "\n", "config", "[", "'checkpoint_dir'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "config", "[", "'checkpoint_name'", "]", ",", "\n", "'checkpoints'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "'checkpoint_dir'", "]", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", "[", "'checkpoint_dir'", "]", ")", "\n", "\n", "# Determine checkpoint path", "\n", "", "config", "[", "'checkpoint_path'", "]", "=", "config", "[", "'checkpoint_dir'", "]", "+", "'/'", "+", "checkpoint_name", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils._setup_output_dir": [[36, 52], ["os.path.join", "os.path.join", "shutil.copy", "src.data_dir", "os.path.exists", "os.makedirs", "src.data_dir"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir"], ["", "def", "_setup_output_dir", "(", "config", ",", "yaml_path", ")", ":", "\n", "    ", "\"\"\"Creates the output directory and copies the config there\n    \"\"\"", "\n", "checkpoint_name", "=", "config", "[", "'checkpoint_name'", "]", "\n", "\n", "# Make log directories", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "'outputs'", ",", "\n", "checkpoint_name", ",", "'logs'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "logdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "logdir", ")", "\n", "\n", "", "config", "[", "'logs_dir'", "]", "=", "logdir", "\n", "# Save config to experiments folder for bookkeeping", "\n", "experiment_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "'outputs'", ",", "\n", "checkpoint_name", ",", "checkpoint_name", "+", "'.yaml'", ")", "\n", "shutil", ".", "copy", "(", "yaml_path", ",", "experiment_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils.setup": [[54, 97], ["config_utils._check_config_name", "config_utils._add_ckpt_paths", "len", "len", "len", "config_utils._setup_output_dir"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils._check_config_name", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils._add_ckpt_paths", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils._setup_output_dir"], ["", "def", "setup", "(", "config", ",", "args", ")", ":", "\n", "    ", "\"\"\"Ensures config and checkpoint names match and creates the log and\n    checkpoint directories.\n\n    Args:\n        config: Configuration dictionary\n        args: args object from an experiment script containing data_split and yaml_path\n\n\n    Returns:\n        config: Configuration dictionary with new entries:\n            checkpoint_dir - output checkpoint directory\n            checkpoint_path - output checkpoint path\n            dataset_config/data_split - dataset data split\n    \"\"\"", "\n", "\n", "# Check that config name matches checkpoint name", "\n", "_check_config_name", "(", "config", ",", "args", ".", "yaml_path", ")", "\n", "\n", "# Add checkpoint path to the config", "\n", "_add_ckpt_paths", "(", "config", ")", "\n", "\n", "# Add data split to dataset config", "\n", "# RetinaNet Specific", "\n", "dataset_name", "=", "config", "[", "'dataset_config'", "]", "[", "'dataset'", "]", "\n", "num_classes", "=", "len", "(", "config", "[", "'dataset_config'", "]", "[", "dataset_name", "]", "[", "'training_data_config'", "]", "[", "'categories'", "]", ")", "\n", "\n", "num_scales", "=", "len", "(", "config", "[", "'dataset_config'", "]", "[", "'anchor_generator'", "]", "[", "'scales'", "]", ")", "\n", "num_aspect_ratios", "=", "len", "(", "config", "[", "'dataset_config'", "]", "[", "'anchor_generator'", "]", "[", "'aspect_ratios'", "]", ")", "\n", "\n", "anchors_per_location", "=", "num_scales", "*", "num_aspect_ratios", "\n", "\n", "config", "[", "'model_config'", "]", "[", "'header'", "]", "[", "'num_classes'", "]", "=", "num_classes", "\n", "config", "[", "'model_config'", "]", "[", "'header'", "]", "[", "'anchors_per_location'", "]", "=", "anchors_per_location", "\n", "\n", "config", "[", "'dataset_config'", "]", "[", "'num_classes'", "]", "=", "num_classes", "\n", "\n", "config", "[", "'dataset_config'", "]", "[", "'data_split'", "]", "=", "args", ".", "data_split", "\n", "\n", "# Setup the output directory", "\n", "_setup_output_dir", "(", "config", ",", "args", ".", "yaml_path", ")", "\n", "\n", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.anchor_generation_demo.main": [[19, 151], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "src.retina_net.config_utils.setup", "src.retina_net.builders.dataset_handler_builder.build_dataset", "dataset_handler_builder.build_dataset.create_dataset", "dataset.prefetch.repeat", "dataset.prefetch.batch", "dataset.prefetch.prefetch", "dataset.prefetch.take", "open", "yaml.load", "os.listdir", "random.randint", "print", "dataset_handler_builder.build_dataset.set_paths", "tensorflow.reduce_sum", "src.box_from_anchor_and_target", "tensorflow.where", "tensorflow.gather", "tensorflow.reshape", "src.vuhw_to_vuvu", "src.vuhw_to_vuvu", "tensorflow.gather", "tensorflow.gather", "tensorflow.reshape", "tensorflow.reshape", "print", "numpy.squeeze", "cv2.cvtColor", "demos.demo_utils.vis_utils.draw_box_2d", "demos.demo_utils.vis_utils.draw_box_2d", "cv2.imshow", "cv2.waitKey", "len", "os.listdir", "random.randint", "print", "dataset_handler_builder.build_dataset.set_sample_id", "tensorflow.cast", "cv2.cvtColor", "cv2.cvtColor.astype", "numpy.copy", "box_utils.vuhw_to_vuvu.numpy", "tf.reshape.numpy", "tf.reshape.numpy", "src.model_dir", "len", "str", "tensorflow.shape", "tf.reduce_sum.numpy"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils.setup", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.builders.dataset_handler_builder.build_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.create_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler.set_paths", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler.set_sample_id", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.model_dir"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Anchor Generator Demo\n    \"\"\"", "\n", "\n", "# Defaults", "\n", "default_gpu_device", "=", "'0'", "\n", "dataset_name", "=", "'bdd'", "\n", "default_config_path", "=", "core", ".", "model_dir", "(", "\n", "'retina_net'", ")", "+", "'/configs/retinanet_'", "+", "dataset_name", "+", "'.yaml'", "\n", "\n", "default_data_split", "=", "'train'", "\n", "\n", "# Parse input", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "# Define argparser object", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'gpu_device'", ",", "\n", "default", "=", "default_gpu_device", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--yaml_path'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'yaml_path'", ",", "\n", "default", "=", "default_config_path", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--data_split'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'data_split'", ",", "\n", "default", "=", "default_data_split", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Set CUDA device id", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "args", ".", "gpu_device", "\n", "\n", "# Load in configuration file as python dictionary", "\n", "with", "open", "(", "args", ".", "yaml_path", ",", "'r'", ")", "as", "yaml_file", ":", "\n", "        ", "config_raw", "=", "yaml", ".", "load", "(", "yaml_file", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "\n", "# Make necessary directories, update config with checkpoint path and data", "\n", "# split", "\n", "", "config", "=", "config_utils", ".", "setup", "(", "config_raw", ",", "args", ")", "\n", "\n", "# Create dataset class", "\n", "dataset_config", "=", "config", "[", "'dataset_config'", "]", "\n", "dataset_handler", "=", "dataset_handler_builder", ".", "build_dataset", "(", "\n", "dataset_config", ",", "'train'", ")", "\n", "\n", "# Set which frame to show", "\n", "if", "dataset_name", "==", "'kitti'", ":", "\n", "        ", "frames_list", "=", "os", ".", "listdir", "(", "dataset_handler", ".", "gt_label_dir", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "frames_list", ")", ")", "\n", "frame_id", "=", "frames_list", "[", "index", "]", "[", "0", ":", "6", "]", "\n", "print", "(", "'Showing Frame: '", "+", "frame_id", ")", "\n", "dataset_handler", ".", "set_paths", "(", "frame_id", ")", "\n", "", "elif", "dataset_name", "==", "'bdd'", ":", "\n", "        ", "frames_list", "=", "os", ".", "listdir", "(", "dataset_handler", ".", "im_dir", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "frames_list", ")", ")", "\n", "frame_id", "=", "frames_list", "[", "index", "]", "\n", "print", "(", "'Showing Frame: '", "+", "frame_id", ")", "\n", "dataset_handler", ".", "set_sample_id", "(", "index", ")", "\n", "\n", "", "dataset", "=", "dataset_handler", ".", "create_dataset", "(", ")", "\n", "\n", "# Setting a shuffle buffer size as large as the dataset ensures that the data is", "\n", "# completely shuffled.", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "1", ")", "\n", "\n", "# `prefetch` lets the dataset fetch batches, in the background while the model is training.", "\n", "dataset", "=", "dataset", ".", "prefetch", "(", "buffer_size", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "############################", "\n", "# Get anchors and GT boxes #", "\n", "############################", "\n", "for", "sample_dict", "in", "dataset", ".", "take", "(", "1", ")", ":", "\n", "        ", "anchors", "=", "sample_dict", "[", "constants", ".", "ANCHORS_KEY", "]", "[", "0", "]", "\n", "\n", "positive_mask", "=", "sample_dict", "[", "constants", ".", "POSITIVE_ANCHORS_MASK_KEY", "]", "[", "0", "]", "\n", "\n", "num_positives", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "positive_mask", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "anchor_box_targets", "=", "sample_dict", "[", "constants", ".", "ANCHORS_BOX_TARGETS_KEY", "]", "[", "0", "]", "\n", "\n", "anchor_class_targets", "=", "sample_dict", "[", "constants", ".", "ANCHORS_CLASS_TARGETS_KEY", "]", "[", "0", "]", "\n", "\n", "# Reconstruct anchors from gt box targets", "\n", "gt_2d_boxes", "=", "box_utils", ".", "box_from_anchor_and_target", "(", "\n", "anchors", ",", "anchor_box_targets", ")", "\n", "\n", "positive_anchor_inds", "=", "tf", ".", "where", "(", "positive_mask", ")", "\n", "positive_anchors", "=", "tf", ".", "gather", "(", "anchors", ",", "positive_anchor_inds", ",", "axis", "=", "0", ")", "\n", "positive_anchors", "=", "tf", ".", "reshape", "(", "positive_anchors", ",", "[", "-", "1", ",", "4", "]", ")", "\n", "positive_anchors_corners", "=", "box_utils", ".", "vuhw_to_vuvu", "(", "positive_anchors", ")", "\n", "\n", "gt_2d_boxes_corner", "=", "box_utils", ".", "vuhw_to_vuvu", "(", "gt_2d_boxes", ")", "\n", "\n", "gt_2d_boxes_corner", "=", "tf", ".", "gather", "(", "\n", "gt_2d_boxes_corner", ",", "positive_anchor_inds", ",", "axis", "=", "0", ")", "\n", "gt_classes", "=", "tf", ".", "gather", "(", "\n", "anchor_class_targets", ",", "\n", "positive_anchor_inds", ",", "\n", "axis", "=", "0", ")", "\n", "\n", "gt_2d_boxes_corner", "=", "tf", ".", "reshape", "(", "gt_2d_boxes_corner", ",", "[", "-", "1", ",", "4", "]", ")", "\n", "gt_classes", "=", "tf", ".", "reshape", "(", "gt_classes", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "gt_classes", ")", "[", "2", "]", "]", ")", "\n", "\n", "print", "(", "'Number of Positive Anchors: '", "+", "str", "(", "num_positives", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "image_normalized", "=", "np", ".", "squeeze", "(", "\n", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", ")", "\n", "\n", "rgb_means", "=", "constants", ".", "MEANS_DICT", "[", "'ImageNet'", "]", "\n", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image_normalized", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "+", "rgb_means", "\n", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ".", "astype", "(", "np", ".", "uint8", ")", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "\n", "#########################################", "\n", "# Create Images and Draw Bounding Boxes #", "\n", "#########################################", "\n", "image_out", "=", "draw_box_2d", "(", "np", ".", "copy", "(", "image", ")", ",", "\n", "positive_anchors_corners", ".", "numpy", "(", ")", ",", "\n", "line_width", "=", "2", ",", "\n", "is_gt", "=", "False", ")", "\n", "\n", "image_out", "=", "draw_box_2d", "(", "image_out", ",", "\n", "gt_2d_boxes_corner", ".", "numpy", "(", ")", ",", "\n", "gt_classes", ".", "numpy", "(", ")", ",", "\n", "line_width", "=", "2", ",", "\n", "is_gt", "=", "True", ")", "\n", "\n", "cv2", ".", "imshow", "(", "'Positive Anchors and Ground Truth'", ",", "image_out", ")", "\n", "cv2", ".", "waitKey", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs": [[7, 17], ["os.path.exists", "FileNotFoundError"], "function", ["None"], ["def", "check_data_dirs", "(", "folders", ")", ":", "\n", "    ", "\"\"\"Checks that the dataset directories exist in the file system\n    :param folders:\n    :return:  FileNotFoundError: if a folder is missing\n    \"\"\"", "\n", "\n", "for", "folder", "in", "folders", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folder", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "'Folder does not exist: {}'", ".", "format", "(", "folder", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction": [[19, 30], ["tensorflow.constant", "tensorflow.reshape"], "function", ["None"], ["", "", "", "def", "mean_image_subtraction", "(", "image", ",", "channel_means", ")", ":", "\n", "    ", "\"\"\"\n    Normalizes image by subtracting image mean.\n\n    :param image: image in RGB format\n    :param channel_means: channel_means dict\n    :return: normalized image\n    \"\"\"", "\n", "channel_means", "=", "tf", ".", "constant", "(", "channel_means", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "channel_means", "=", "tf", ".", "reshape", "(", "channel_means", ",", "[", "1", ",", "1", ",", "3", "]", ")", "\n", "return", "image", "-", "channel_means", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d": [[35, 61], ["numpy.array", "len", "numpy.array", "float", "float", "float", "float", "boxes_2d.append", "np.array.tolist"], "function", ["None"], ["", "def", "kitti_labels_to_boxes_2d", "(", "labels", ")", ":", "\n", "    ", "\"\"\"\n    Transforms labels to 2D box format.\n\n    Args:\n        labels: input kitti_obj labels (see kitti_obj utils)\n\n\n    Returns:\n        boxes_2d: n x 4 array representing 2d boxes represented as\n        [y1, x1, y2, x2]\n    \"\"\"", "\n", "boxes_2d", "=", "[", "]", "\n", "\n", "if", "len", "(", "labels", ".", "shape", ")", "<", "2", ":", "\n", "        ", "labels", "=", "np", ".", "array", "(", "[", "labels", ".", "tolist", "(", ")", "]", ")", "\n", "\n", "", "for", "label", "in", "labels", ":", "\n", "        ", "x1", "=", "float", "(", "label", "[", "4", "]", ")", "\n", "y1", "=", "float", "(", "label", "[", "5", "]", ")", "\n", "x2", "=", "float", "(", "label", "[", "6", "]", ")", "\n", "y2", "=", "float", "(", "label", "[", "7", "]", ")", "\n", "box_2d", "=", "[", "y1", ",", "x1", ",", "y2", ",", "x2", "]", "\n", "boxes_2d", ".", "append", "(", "box_2d", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "boxes_2d", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler.__init__": [[18, 74], ["src.core.abstract_classes.dataset_handler.DatasetHandler.__init__", "os.path.expanduser", "os.path.join", "os.path.join", "src.check_data_dirs", "src.check_data_dirs", "src.check_data_dirs", "glob.glob", "kitti_dataset_handler.KittiDatasetHandler._load_sample_ids", "len", "kitti_dataset_handler.KittiDatasetHandler._create_sample_paths", "ValueError", "random.shuffle", "os.path.expanduser", "os.path.splitext", "os.path.basename"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler._load_sample_ids", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler._create_sample_paths"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "train_val_test", ")", ":", "\n", "        ", "\"\"\"\n        Initializes directories, and loads the sample list\n\n        :param config: configuration dictionary\n        :param train_val_test (string): 'train', 'val', or 'test'\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "# Define Dicts", "\n", "self", ".", "_MEANS_DICT", "=", "constants", ".", "MEANS_DICT", "\n", "self", ".", "_DIFF_DICTS", "=", "constants", ".", "KITTI_DIFF_DICTS", "\n", "self", ".", "resize_shape", "=", "config", "[", "'kitti'", "]", "[", "'resize_shape'", "]", "\n", "\n", "# Load configs", "\n", "self", ".", "training_data_config", "=", "config", "[", "'kitti'", "]", "[", "'training_data_config'", "]", "\n", "self", ".", "anchor_gen_config", "=", "config", "[", "'anchor_generator'", "]", "\n", "\n", "# Define paths to dataset", "\n", "paths_config", "=", "config", "[", "'kitti'", "]", "[", "'paths_config'", "]", "\n", "self", ".", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "paths_config", "[", "'dataset_dir'", "]", ")", "\n", "self", ".", "data_split_dir", "=", "paths_config", "[", "'data_split_dir'", "]", "\n", "\n", "self", ".", "im_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "dataset_dir", ",", "self", ".", "data_split_dir", ",", "'image_2'", ")", "\n", "self", ".", "gt_label_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "dataset_dir", ",", "self", ".", "data_split_dir", ",", "'label_2'", ")", "\n", "\n", "# Make sure dataset directories exist", "\n", "dataset_utils", ".", "check_data_dirs", "(", "[", "self", ".", "im_dir", ",", "self", ".", "gt_label_dir", "]", ")", "\n", "\n", "# Make sure training-validation data split exists", "\n", "txt_files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "expanduser", "(", "self", ".", "dataset_dir", ")", "+", "'/*.txt'", ")", "\n", "possible_splits", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "[", "\n", "0", "]", "for", "path", "in", "txt_files", "]", "\n", "if", "self", ".", "data_split", "not", "in", "possible_splits", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Invalid dataset_split: {}. Possible splits include: {}'", ".", "format", "(", "\n", "self", ".", "data_split", ",", "possible_splits", ")", ")", "\n", "\n", "# Load sample paths for the chosen split", "\n", "", "self", ".", "sample_ids", "=", "self", ".", "_load_sample_ids", "(", ")", "\n", "\n", "# Random shuffle here is much more computationally efficient than", "\n", "# randomly shuffling a dataset iterator.", "\n", "if", "train_val_test", "==", "'train'", ":", "\n", "            ", "random", ".", "shuffle", "(", "self", ".", "sample_ids", ")", "\n", "\n", "", "self", ".", "epoch_size", "=", "len", "(", "self", ".", "sample_ids", ")", "\n", "self", ".", "_create_sample_paths", "(", "self", ".", "sample_ids", ")", "\n", "\n", "# Create placeholder for dataset", "\n", "self", ".", "dataset", "=", "None", "\n", "\n", "# Create flag if train\\val or just inference", "\n", "self", ".", "is_testing", "=", "(", "train_val_test", "==", "'test'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler.set_paths": [[75, 84], ["None"], "methods", ["None"], ["", "def", "set_paths", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Function to set sample paths, in the case of usage for a demo\n\n        :param sample: kitti sample name\n        :return: None\n        \"\"\"", "\n", "self", ".", "im_paths", "=", "[", "self", ".", "im_dir", "+", "'/'", "+", "sample", "+", "'.png'", "]", "\n", "self", ".", "label_paths", "=", "[", "self", ".", "gt_label_dir", "+", "'/'", "+", "sample", "+", "'.txt'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler.create_dataset": [[85, 105], ["tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices.map"], "methods", ["None"], ["", "def", "create_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Create dataset using tf.dataset API\n\n        :return: dataset : dataset object\n        \"\"\"", "\n", "# Set data path lists", "\n", "im_paths", "=", "self", ".", "im_paths", "\n", "label_paths", "=", "self", ".", "label_paths", "\n", "\n", "# Create dataset using API", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "im_paths", ",", "\n", "label_paths", ")", ")", "\n", "\n", "# Create sample dictionary", "\n", "self", ".", "dataset", "=", "dataset", ".", "map", "(", "\n", "self", ".", "create_sample_dict", ",", "\n", "num_parallel_calls", "=", "10", ")", "\n", "\n", "return", "self", ".", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler.create_sample_dict": [[106, 204], ["tensorflow.name_scope", "tensorflow.io.read_file", "tensorflow.image.decode_png", "tensorflow.image.resize", "tensorflow.image.resize_with_crop_or_pad", "tensorflow.py_function", "src.normalize_2d_bounding_boxes", "src.normalize_2d_bounding_boxes", "src.normalize_2d_bounding_boxes", "src.expand_2d_bounding_boxes", "src.expand_2d_bounding_boxes", "src.expand_2d_bounding_boxes", "src.mean_image_subtraction", "src.mean_image_subtraction", "src.mean_image_subtraction", "tensorflow.unstack", "tensorflow.stack", "dict", "dict.update", "dict.update", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator", "src.vuvu_to_vuhw", "src.vuvu_to_vuhw", "src.vuvu_to_vuhw", "dict.update", "tensorflow.shape", "tensorflow.shape", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors", "anchors_list.append", "dict.update", "tensorflow.shape", "tensorflow.shape", "src.vuhw_to_vuvu", "src.vuhw_to_vuvu", "src.vuhw_to_vuvu", "src.bbox_iou_vuvu", "src.bbox_iou_vuvu", "src.bbox_iou_vuvu", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "anchors_positive_mask_list.append", "anchors_negative_mask_list.append", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "anchors_box_target_list.append", "anchors_class_target_list.append", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.normalize_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.normalize_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.normalize_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.expand_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.expand_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.expand_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets"], ["", "@", "tf", ".", "function", "\n", "def", "create_sample_dict", "(", "\n", "self", ",", "\n", "im_path", ",", "\n", "label_path", ")", ":", "\n", "        ", "\"\"\"\n        Creates sample dictionary for a single sample\n\n        :param im_path: left image path\n        :param label_path: ground truth label path\n\n        :return: sample_dict: Sample dictionary filled with input tensors\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'input_data'", ")", ":", "\n", "# Read left and right images", "\n", "            ", "image_as_string", "=", "tf", ".", "io", ".", "read_file", "(", "im_path", ")", "\n", "image", "=", "tf", ".", "image", ".", "decode_png", "(", "image_as_string", ",", "channels", "=", "3", ")", "\n", "\n", "# Resize images", "\n", "image_resized", "=", "tf", ".", "image", ".", "resize", "(", "\n", "image", ",", "\n", "self", ".", "resize_shape", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "\n", "preserve_aspect_ratio", "=", "True", ")", "\n", "\n", "image_resized", "=", "tf", ".", "image", ".", "resize_with_crop_or_pad", "(", "\n", "image_resized", ",", "self", ".", "resize_shape", "[", "0", "]", ",", "self", ".", "resize_shape", "[", "1", "]", ")", "\n", "\n", "boxes_class_gt", ",", "boxes_2d_gt", ",", "no_gt", "=", "tf", ".", "py_function", "(", "\n", "self", ".", "_read_labels", ",", "[", "label_path", "]", ",", "[", "\n", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "tf", ".", "bool", "]", ")", "\n", "\n", "# Rescale 2D GT bounding boxes to accommodate image resize", "\n", "boxes_2d_norm", "=", "box_utils", ".", "normalize_2d_bounding_boxes", "(", "\n", "boxes_2d_gt", ",", "tf", ".", "shape", "(", "image", ")", ")", "\n", "boxes_2d_gt", "=", "box_utils", ".", "expand_2d_bounding_boxes", "(", "\n", "boxes_2d_norm", ",", "tf", ".", "shape", "(", "image_resized", ")", ")", "\n", "\n", "# Normalize Images In Preparation For Feature Extractor", "\n", "image_norm", "=", "dataset_utils", ".", "mean_image_subtraction", "(", "\n", "image_resized", ",", "self", ".", "_MEANS_DICT", "[", "self", ".", "im_normalization", "]", ")", "\n", "\n", "# Flip channels to BGR since pretrained weights use this", "\n", "# configuration.", "\n", "channels", "=", "tf", ".", "unstack", "(", "image_norm", ",", "axis", "=", "-", "1", ")", "\n", "image_norm", "=", "tf", ".", "stack", "(", "\n", "[", "channels", "[", "2", "]", ",", "channels", "[", "1", "]", ",", "channels", "[", "0", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Create_sample_dict", "\n", "sample_dict", "=", "dict", "(", ")", "\n", "sample_dict", ".", "update", "(", "{", "constants", ".", "IMAGE_NORMALIZED_KEY", ":", "image_norm", "}", ")", "\n", "sample_dict", ".", "update", "(", "\n", "{", "constants", ".", "ORIGINAL_IM_SIZE_KEY", ":", "tf", ".", "shape", "(", "image", ")", "}", ")", "\n", "\n", "# Create prior anchors and anchor targets", "\n", "generator", "=", "FpnAnchorGenerator", "(", "self", ".", "anchor_gen_config", ")", "\n", "boxes_2d_gt_vuhw", "=", "box_utils", ".", "vuvu_to_vuhw", "(", "boxes_2d_gt", ")", "\n", "\n", "anchors_list", "=", "[", "]", "\n", "anchors_class_target_list", "=", "[", "]", "\n", "anchors_box_target_list", "=", "[", "]", "\n", "anchors_positive_mask_list", "=", "[", "]", "\n", "anchors_negative_mask_list", "=", "[", "]", "\n", "\n", "for", "layer_number", "in", "self", ".", "anchor_gen_config", "[", "'layers'", "]", ":", "\n", "                ", "anchors", "=", "generator", ".", "generate_anchors", "(", "\n", "tf", ".", "shape", "(", "image_norm", ")", ",", "layer_number", ")", "\n", "anchors_list", ".", "append", "(", "anchors", ")", "\n", "\n", "if", "not", "self", ".", "is_testing", ":", "\n", "                    ", "anchor_corners", "=", "box_utils", ".", "vuhw_to_vuvu", "(", "anchors", ")", "\n", "ious", "=", "box_utils", ".", "bbox_iou_vuvu", "(", "anchor_corners", ",", "boxes_2d_gt", ")", "\n", "\n", "positive_anchor_mask", ",", "negative_anchor_mask", ",", "max_ious", "=", "generator", ".", "positive_negative_batching", "(", "\n", "ious", ",", "self", ".", "anchor_gen_config", "[", "'min_positive_iou'", "]", ",", "self", ".", "anchor_gen_config", "[", "'max_negative_iou'", "]", ")", "\n", "\n", "anchors_positive_mask_list", ".", "append", "(", "positive_anchor_mask", ")", "\n", "anchors_negative_mask_list", ".", "append", "(", "negative_anchor_mask", ")", "\n", "\n", "anchor_box_targets", ",", "anchor_class_targets", "=", "generator", ".", "generate_anchor_targets", "(", "\n", "anchors", ",", "boxes_2d_gt_vuhw", ",", "boxes_class_gt", ",", "max_ious", ",", "positive_anchor_mask", ")", "\n", "anchors_box_target_list", ".", "append", "(", "anchor_box_targets", ")", "\n", "anchors_class_target_list", ".", "append", "(", "anchor_class_targets", ")", "\n", "\n", "# Sample dict is stacked from p3 --> p7, this is essential to", "\n", "# memorize for stacking the predictions later on", "\n", "", "", "sample_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_KEY", ":", "tf", ".", "concat", "(", "anchors_list", ",", "axis", "=", "0", ")", "}", ")", "\n", "if", "not", "self", ".", "is_testing", ":", "\n", "                ", "sample_dict", ".", "update", "(", "{", "constants", ".", "ANCHORS_BOX_TARGETS_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_box_target_list", ",", "axis", "=", "0", ")", ",", "\n", "constants", ".", "ANCHORS_CLASS_TARGETS_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_class_target_list", ",", "axis", "=", "0", ")", ",", "\n", "constants", ".", "POSITIVE_ANCHORS_MASK_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_positive_mask_list", ",", "axis", "=", "0", ")", ",", "\n", "constants", ".", "NEGATIVE_ANCHOR_MASK_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_negative_mask_list", ",", "axis", "=", "0", ")", "}", ")", "\n", "", "", "return", "sample_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler._load_sample_ids": [[205, 220], ["os.path.join", "numpy.array", "open", "csv.reader", "paths.append"], "methods", ["None"], ["", "def", "_load_sample_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load the sample ids listed in the data split file (e.g. train.txt, val.txt, test.txt, train_mini.txt ..)\n\n        :return: paths: A list of sample ids read from the .txt file corresponding to the data split\n        \"\"\"", "\n", "paths", "=", "[", "]", "\n", "split_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dataset_dir", ",", "self", ".", "data_split", "+", "'.txt'", ")", "\n", "with", "open", "(", "split_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "csv_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "' '", ")", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                ", "for", "sample", "in", "row", ":", "\n", "                    ", "paths", ".", "append", "(", "sample", ")", "\n", "\n", "", "", "", "return", "np", ".", "array", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler._create_sample_paths": [[221, 233], ["None"], "methods", ["None"], ["", "def", "_create_sample_paths", "(", "self", ",", "sample_ids", ")", ":", "\n", "        ", "\"\"\"\n        Creates sample paths\n        \"\"\"", "\n", "self", ".", "im_paths", "=", "[", "\n", "self", ".", "im_dir", "+", "\n", "'/'", "+", "\n", "sample", "+", "\n", "'.png'", "for", "sample", "in", "sample_ids", "]", "\n", "\n", "self", ".", "label_paths", "=", "[", "self", ".", "gt_label_dir", "+", "'/'", "+", "\n", "sample", "+", "'.txt'", "for", "sample", "in", "sample_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.kitti_dataset_handler.KittiDatasetHandler._read_labels": [[234, 298], ["label_path.decode.decode.numpy", "label_path.decode.decode.decode", "numpy.loadtxt", "numpy.asarray", "numpy.array", "src.kitti_labels_to_boxes_2d", "src.kitti_labels_to_boxes_2d", "src.kitti_labels_to_boxes_2d", "len", "numpy.array", "labels[].astype", "labels[].astype", "labels[].astype", "labels[].astype", "numpy.array", "boxes_class_gt.append", "len", "numpy.expand_dims", "numpy.array().astype", "numpy.array().astype", "numpy.arange", "difficulty.lower", "numpy.array.tolist", "inst.lower", "elem.lower", "boxes_class_gt.append", "numpy.array", "numpy.array", "elem.lower", "boxes_class_gt.append", "elem.lower", "boxes_class_gt.append"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d"], ["", "def", "_read_labels", "(", "self", ",", "label_path", ")", ":", "\n", "        ", "\"\"\"\n        Reads ground truth labels and parses them into one hot class representation and groundtruth 2D bounding box.\n        \"\"\"", "\n", "label_path", "=", "label_path", ".", "numpy", "(", ")", "\n", "\n", "# Extract the list", "\n", "no_gt", "=", "False", "\n", "\n", "difficulty", "=", "self", ".", "training_data_config", "[", "'difficulty'", "]", "\n", "categories", "=", "self", ".", "training_data_config", "[", "'categories'", "]", "\n", "\n", "label_path", "=", "label_path", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "labels", "=", "np", ".", "loadtxt", "(", "label_path", ",", "\n", "delimiter", "=", "' '", ",", "\n", "dtype", "=", "str", ",", "\n", "usecols", "=", "np", ".", "arange", "(", "start", "=", "0", ",", "step", "=", "1", ",", "stop", "=", "15", ")", ")", "\n", "\n", "if", "len", "(", "labels", ".", "shape", ")", "==", "1", ":", "\n", "            ", "labels", "=", "np", ".", "array", "(", "[", "labels", ".", "tolist", "(", ")", "]", ")", "\n", "\n", "# Filter labels", "\n", "", "diff_dict", "=", "self", ".", "_DIFF_DICTS", "[", "difficulty", ".", "lower", "(", ")", "]", "\n", "min_height", "=", "diff_dict", "[", "'min_height'", "]", "\n", "max_truncation", "=", "diff_dict", "[", "'max_truncation'", "]", "\n", "max_occlusion", "=", "diff_dict", "[", "'max_occlusion'", "]", "\n", "\n", "heights", "=", "labels", "[", ":", ",", "7", "]", ".", "astype", "(", "\n", "np", ".", "float32", ")", "-", "labels", "[", ":", ",", "5", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "class_filter", "=", "np", ".", "asarray", "(", "\n", "[", "inst", ".", "lower", "(", ")", "in", "categories", "for", "inst", "in", "labels", "[", ":", ",", "0", "]", "]", ")", "\n", "\n", "height_filter", "=", "heights", ">=", "min_height", "\n", "truncation_filter", "=", "labels", "[", ":", ",", "1", "]", ".", "astype", "(", "np", ".", "float", ")", "<=", "max_truncation", "\n", "occlusion_filter", "=", "labels", "[", ":", ",", "2", "]", ".", "astype", "(", "np", ".", "float", ")", "<=", "max_occlusion", "\n", "\n", "final_filter", "=", "class_filter", "&", "height_filter", "&", "truncation_filter", "&", "occlusion_filter", "\n", "\n", "labels", "=", "np", ".", "array", "(", "labels", "[", "final_filter", "]", ")", "\n", "\n", "boxes_2d_gt", "=", "dataset_utils", ".", "kitti_labels_to_boxes_2d", "(", "labels", ")", "\n", "boxes_class_gt", "=", "[", "]", "\n", "\n", "if", "boxes_2d_gt", ".", "size", "==", "0", ":", "\n", "            ", "boxes_2d_gt", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "boxes_class_gt", ".", "append", "(", "[", "0", ",", "0", ",", "0", ",", "1", "]", ")", "\n", "no_gt", "=", "True", "\n", "", "else", ":", "\n", "            ", "for", "elem", "in", "labels", "[", ":", ",", "0", "]", ":", "\n", "                ", "if", "elem", ".", "lower", "(", ")", "==", "'car'", ":", "\n", "                    ", "boxes_class_gt", ".", "append", "(", "[", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "elem", ".", "lower", "(", ")", "==", "'pedestrian'", ":", "\n", "                    ", "boxes_class_gt", ".", "append", "(", "[", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "elem", ".", "lower", "(", ")", "==", "'cyclist'", ":", "\n", "                    ", "boxes_class_gt", ".", "append", "(", "[", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "\n", "", "", "", "if", "len", "(", "boxes_2d_gt", ".", "shape", ")", "==", "1", ":", "\n", "            ", "boxes_2d_gt", "=", "np", ".", "expand_dims", "(", "boxes_2d_gt", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "[", "np", ".", "array", "(", "boxes_class_gt", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "np", ".", "array", "(", "boxes_2d_gt", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "no_gt", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.compute_uncertainty_error.main": [[10, 146], ["os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "evaluate_u_error", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "print", "print", "print", "os.path.join", "src.data_dir", "src.data_dir", "src.data_dir", "int", "demos.demo_utils.kitti_demo_utils.read_labels", "demos.demo_utils.kitti_demo_utils.read_predictions", "print", "np.load", "np.load", "zip", "zip", "str", "str", "os.path.join", "os.path.join", "np.argmax", "gt_dict_list.append", "np.argmax", "prediction_dict_list.append", "len", "np.mean", "compute_gaussian_entropy_np", "str", "len", "str", "compute_categorical_entropy_np"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.evaluate_u_error", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_predictions", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_gaussian_entropy_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_categorical_entropy_np"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "difficulty", "=", "'all'", "\n", "categories", "=", "[", "'car'", ",", "'pedestrian'", "]", "\n", "\n", "# Specify whether the validation or inference results need to be evaluated.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "entropy_method", "=", "'categorical'", "# evaluate using gaussian or categorical entropy", "\n", "\n", "# All or per category. Note that if per category is used, out of", "\n", "# distribution detections are ignored. Results in overestimation of", "\n", "# performance.", "\n", "compute_method", "=", "'category'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "\n", "cov_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cat_param'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "\n", "id", "=", "0", "\n", "gt_dict_list", "=", "[", "]", "\n", "prediction_dict_list", "=", "[", "]", "\n", "for", "frame", "in", "frames_list", ":", "\n", "        ", "frame_id", "=", "int", "(", "frame", "[", "0", ":", "6", "]", ")", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes", ",", "gt_boxes", "=", "read_labels", "(", "\n", "label_path", ",", "difficulty", "=", "difficulty", ",", "categories", "=", "categories", ")", "\n", "\n", "prediction_path", "=", "prediction_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", "=", "read_predictions", "(", "\n", "prediction_path", ",", "categories", "=", "categories", ")", "\n", "\n", "if", "gt_boxes", ".", "size", ">", "0", "and", "prediction_boxes", ".", "size", ">", "0", ":", "\n", "            ", "prediction_box_cat_params", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "cat_param_dir", ",", "'{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", ")", "\n", "prediction_box_covs", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "cov_dir", ",", "'{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", ")", "\n", "\n", "if", "entropy_method", "==", "'gaussian'", ":", "\n", "                ", "ranking_entropies", "=", "[", "compute_gaussian_entropy_np", "(", "\n", "cov", ")", "for", "cov", "in", "prediction_box_covs", "]", "\n", "", "elif", "entropy_method", "==", "'categorical'", ":", "\n", "                ", "ranking_entropies", "=", "[", "compute_categorical_entropy_np", "(", "\n", "cat_vect", ")", "for", "cat_vect", "in", "prediction_box_cat_params", "]", "\n", "\n", "", "for", "gt_class", ",", "gt_box", "in", "zip", "(", "gt_classes", ",", "gt_boxes", ")", ":", "\n", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "gt_class", ")", "\n", "gt_box_list", "=", "[", "gt_box", "[", "1", "]", ",", "gt_box", "[", "0", "]", ",", "gt_box", "[", "3", "]", ",", "gt_box", "[", "2", "]", "]", "\n", "if", "compute_method", "==", "'All'", ":", "\n", "                    ", "category_name", "=", "'All'", "\n", "", "else", ":", "\n", "                    ", "category_name", "=", "categories", "[", "ind", "]", "\n", "", "gt_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "category_name", ",", "\n", "'bbox'", ":", "gt_box_list", ",", "\n", "'score'", ":", "1", "}", "\n", "gt_dict_list", ".", "append", "(", "gt_dict", ")", "\n", "\n", "", "for", "pred_class", ",", "pred_box", ",", "ranking_entropy", "in", "zip", "(", "\n", "prediction_classes", ",", "prediction_boxes", ",", "ranking_entropies", ")", ":", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "pred_class", ")", "\n", "if", "ind", ">=", "len", "(", "categories", ")", ":", "\n", "                    ", "continue", "\n", "", "pred_box_list", "=", "[", "\n", "pred_box", "[", "1", "]", ",", "\n", "pred_box", "[", "0", "]", ",", "\n", "pred_box", "[", "3", "]", ",", "\n", "pred_box", "[", "2", "]", "]", "\n", "if", "compute_method", "==", "'All'", ":", "\n", "                    ", "category_name", "=", "'All'", "\n", "", "else", ":", "\n", "                    ", "category_name", "=", "categories", "[", "ind", "]", "\n", "", "pred_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "category_name", ",", "\n", "'bbox'", ":", "pred_box_list", ",", "\n", "'entropy_score'", ":", "ranking_entropy", "}", "\n", "\n", "prediction_dict_list", ".", "append", "(", "pred_dict", ")", "\n", "", "", "id", "+=", "1", "\n", "print", "(", "'Computed {} / {} frames.'", ".", "format", "(", "id", ",", "len", "(", "frames_list", ")", ")", ")", "\n", "\n", "", "mean_u_error_list", ",", "mean_u_error", ",", "cat_list", ",", "scores_at_min_u_error", "=", "evaluate_u_error", "(", "\n", "gt_dict_list", ",", "prediction_dict_list", ",", "iou_thresholds", "=", "[", "0.5", "]", ")", "\n", "\n", "table", "=", "PrettyTable", "(", "cat_list", ")", "\n", "table", ".", "add_row", "(", "mean_u_error_list", ")", "\n", "print", "(", "\"Average \"", "+", "entropy_method", "+", "\" MUE: \"", "+", "str", "(", "mean_u_error", ")", ")", "\n", "print", "(", "\"Average \"", "+", "entropy_method", "+", "\" Score: \"", "+", "str", "(", "np", ".", "mean", "(", "scores_at_min_u_error", ")", ")", ")", "\n", "\n", "print", "(", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.compute_pdq.main": [[16, 188], ["os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "print", "print", "src.retina_net.offline_eval.pdq.PDQ", "pdq.PDQ.get_assignment_counts", "pdq.PDQ.get_avg_spatial_score", "pdq.PDQ.get_avg_label_score", "pdq.PDQ.get_avg_overall_quality_score", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "print", "os.path.join", "os.path.join", "src.data_dir", "src.data_dir", "src.data_dir", "src.data_dir", "int", "demos.demo_utils.kitti_demo_utils.read_labels", "numpy.load", "numpy.load", "match_list.append", "print", "pdq.PDQ.score", "src.data_dir", "open", "print", "zip", "numpy.load", "numpy.stack", "numpy.array", "numpy.matmul", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu_np", "zip", "numpy.zeros", "box_2d_gt.astype().tolist", "numpy.array", "numpy.clip().astype", "numpy.argmax", "src.retina_net.offline_eval.pdq_data_holders.GroundTruthInstance", "gt_instance_list.append", "numpy.matmul", "len", "numpy.max", "numpy.array().astype", "src.retina_net.offline_eval.pdq_data_holders.PBoxDetInst", "det_instance_list.append", "box_2d_gt.astype", "numpy.clip", "numpy.array"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_assignment_counts", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_spatial_score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_label_score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_overall_quality_score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "difficulty", "=", "'all'", "\n", "categories", "=", "[", "'car'", ",", "'pedestrian'", "]", "\n", "\n", "# Specify whether the validation or inference results need to be evaluated.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "# sample_free, anchor_redundancy, black_box,naive_aleatoric_epistemic  bayes_od_none,", "\n", "# bayes_od_ci_fast. bayes_od_ci,or bayes_od_ici", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "mean_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'mean'", ")", "\n", "\n", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "\n", "cov_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cat_param'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "\n", "id", "=", "0", "\n", "gt_dict_list", "=", "[", "]", "\n", "prediction_dict_list", "=", "[", "]", "\n", "print", "(", "\"PDQ evaluation starting:\"", ")", "\n", "match_list", "=", "[", "]", "\n", "for", "frame", "in", "frames_list", ":", "\n", "        ", "frame_id", "=", "int", "(", "frame", "[", "0", ":", "6", "]", ")", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes", ",", "gt_boxes", "=", "read_labels", "(", "\n", "label_path", ",", "difficulty", "=", "difficulty", ",", "categories", "=", "categories", ")", "\n", "\n", "# Create GT list", "\n", "gt_instance_list", "=", "[", "]", "\n", "if", "gt_boxes", ".", "size", ">", "0", ":", "\n", "            ", "for", "cat_gt", ",", "box_2d_gt", "in", "zip", "(", "gt_classes", ",", "gt_boxes", ")", ":", "\n", "                ", "seg_mask", "=", "np", ".", "zeros", "(", "[", "375", ",", "1300", "]", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "box_inds", "=", "box_2d_gt", ".", "astype", "(", "np", ".", "int32", ")", ".", "tolist", "(", ")", "\n", "box_inds", "=", "np", ".", "array", "(", "\n", "[", "box_inds", "[", "1", "]", ",", "box_inds", "[", "0", "]", ",", "box_inds", "[", "3", "]", ",", "box_inds", "[", "2", "]", "]", ")", "\n", "\n", "box_inds", "=", "np", ".", "clip", "(", "\n", "box_inds", ",", "\n", "a_min", "=", "0.0", ",", "\n", "a_max", "=", "1300", ")", ".", "astype", "(", "\n", "np", ".", "int32", ")", "\n", "\n", "seg_mask", "[", "box_inds", "[", "1", "]", ":", "box_inds", "[", "3", "]", ",", "\n", "box_inds", "[", "0", "]", ":", "box_inds", "[", "2", "]", "]", "=", "True", "\n", "gt_index", "=", "np", ".", "argmax", "(", "cat_gt", ")", "\n", "gt_instance", "=", "pdq_data_holders", ".", "GroundTruthInstance", "(", "\n", "seg_mask", ",", "gt_index", ",", "0", ",", "0", ",", "bounding_box", "=", "box_inds", ")", "\n", "gt_instance_list", ".", "append", "(", "gt_instance", ")", "\n", "\n", "", "", "prediction_boxes_mean", "=", "np", ".", "load", "(", "\n", "mean_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "load", "(", "\n", "cov_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "*", "70", "\n", "prediction_boxes_cat_params", "=", "np", ".", "load", "(", "\n", "cat_param_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "\n", "det_instance_list", "=", "[", "]", "\n", "if", "prediction_boxes_cov", ".", "size", ":", "\n", "            ", "prediction_boxes_cat_params", "=", "np", ".", "stack", "(", "\n", "[", "prediction_boxes_cat_params", "[", ":", ",", "0", "]", ",", "prediction_boxes_cat_params", "[", ":", ",", "3", "]", "]", ",", "axis", "=", "1", ")", "\n", "transformation_mat", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "0", ",", "-", "0.5", "]", ",", "\n", "[", "1", ",", "0", ",", "-", "0.5", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0.5", "]", ",", "\n", "[", "1", ",", "0", ",", "0.5", ",", "0", "]", "]", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "matmul", "(", "\n", "np", ".", "matmul", "(", "\n", "transformation_mat", ",", "\n", "prediction_boxes_cov", ")", ",", "\n", "transformation_mat", ".", "T", ")", "\n", "prediction_boxes_mean", "=", "vuhw_to_vuvu_np", "(", "prediction_boxes_mean", ")", "\n", "for", "cat_det", ",", "box_mean", ",", "cov_det", "in", "zip", "(", "\n", "prediction_boxes_cat_params", ",", "prediction_boxes_mean", ",", "prediction_boxes_cov", ")", ":", "\n", "                ", "if", "np", ".", "max", "(", "cat_det", ")", ">=", "0.5", ":", "\n", "                    ", "box_processed", "=", "np", ".", "array", "(", "\n", "[", "box_mean", "[", "1", "]", ",", "box_mean", "[", "0", "]", ",", "box_mean", "[", "3", "]", ",", "box_mean", "[", "2", "]", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "cov_processed", "=", "[", "cov_det", "[", "0", ":", "2", ",", "0", ":", "2", "]", ",", "cov_det", "[", "2", ":", "4", ",", "2", ":", "4", "]", "]", "\n", "det_instance", "=", "pdq_data_holders", ".", "PBoxDetInst", "(", "\n", "cat_det", ",", "box_processed", ",", "cov_processed", ")", "\n", "det_instance_list", ".", "append", "(", "det_instance", ")", "\n", "", "", "", "match_list", ".", "append", "(", "(", "gt_instance_list", ",", "det_instance_list", ")", ")", "\n", "\n", "id", "+=", "1", "\n", "print", "(", "'Computed {} / {} frames.'", ".", "format", "(", "id", ",", "len", "(", "frames_list", ")", ")", ")", "\n", "\n", "", "print", "(", "\"PDQ Ended\"", ")", "\n", "evaluator", "=", "pdq", ".", "PDQ", "(", ")", "\n", "score", "=", "evaluator", ".", "score", "(", "match_list", ")", "*", "100", "\n", "TP", ",", "FP", ",", "FN", "=", "evaluator", ".", "get_assignment_counts", "(", ")", "\n", "avg_spatial_quality", "=", "evaluator", ".", "get_avg_spatial_score", "(", ")", "\n", "avg_label_quality", "=", "evaluator", ".", "get_avg_label_score", "(", ")", "\n", "avg_overall_quality", "=", "evaluator", ".", "get_avg_overall_quality_score", "(", ")", "\n", "\n", "table", "=", "PrettyTable", "(", "[", "'score'", ",", "\n", "'True Positives'", ",", "\n", "'False Positives'", ",", "\n", "'False Negatives'", ",", "\n", "'Average Spatial Quality'", ",", "\n", "'Average Label Quality'", ",", "\n", "'Average Overall Quality'", "]", ")", "\n", "\n", "table", ".", "add_row", "(", "[", "score", ",", "TP", ",", "FP", ",", "FN", ",", "avg_spatial_quality", ",", "\n", "avg_label_quality", ",", "avg_overall_quality", "]", ")", "\n", "\n", "print", "(", "table", ")", "\n", "\n", "text_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'pdq_res.txt'", ")", "\n", "\n", "with", "open", "(", "text_file_name", ",", "\"w\"", ")", "as", "text_file", ":", "\n", "        ", "print", "(", "table", ",", "file", "=", "text_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.kitti.compute_ap.main": [[10, 122], ["os.path.expanduser", "os.listdir", "evaluate_detection", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "prettytable.PrettyTable.add_row", "print", "print", "print", "np.array", "print", "print", "os.path.join", "os.path.join", "os.path.join", "int", "demos.demo_utils.kitti_demo_utils.read_labels", "demos.demo_utils.kitti_demo_utils.read_predictions", "print", "src.data_dir", "src.data_dir", "zip", "zip", "np.argmax", "gt_dict_list.append", "np.argmax", "prediction_dict_list.append", "len", "str", "str", "str", "str", "str", "str", "np.mean", "np.mean", "np.array", "np.array", "np.sum", "len"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.evaluate_detection", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_predictions", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "difficulty", "=", "'all'", "\n", "categories", "=", "[", "'car'", ",", "'pedestrian'", "]", "\n", "\n", "# Specify whether the validation or inference results need to be evaluated.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "# sample_free, anchor_redundancy, black_box,  naive_aleatoric_epistemic,  bayes_od_none,", "\n", "# bayes_od_ci_fast. bayes_od_ci,or bayes_od_ici", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd_covar'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "", "else", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "checkpoint_number", ",", "\n", "'data'", ")", "\n", "\n", "", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "\n", "id", "=", "0", "\n", "gt_dict_list", "=", "[", "]", "\n", "prediction_dict_list", "=", "[", "]", "\n", "for", "frame", "in", "frames_list", ":", "\n", "        ", "frame_id", "=", "int", "(", "frame", "[", "0", ":", "6", "]", ")", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes", ",", "gt_boxes", "=", "read_labels", "(", "\n", "label_path", ",", "difficulty", "=", "difficulty", ",", "categories", "=", "categories", ")", "\n", "\n", "prediction_path", "=", "prediction_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", "=", "read_predictions", "(", "\n", "prediction_path", ",", "categories", "=", "categories", ")", "\n", "\n", "if", "gt_boxes", ".", "size", ">", "0", "and", "prediction_boxes", ".", "size", ">", "0", ":", "\n", "\n", "            ", "for", "gt_class", ",", "gt_box", "in", "zip", "(", "gt_classes", ",", "gt_boxes", ")", ":", "\n", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "gt_class", ")", "\n", "gt_box_list", "=", "[", "gt_box", "[", "1", "]", ",", "gt_box", "[", "0", "]", ",", "gt_box", "[", "3", "]", ",", "gt_box", "[", "2", "]", "]", "\n", "gt_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "categories", "[", "ind", "]", ",", "\n", "'bbox'", ":", "gt_box_list", ",", "\n", "'score'", ":", "1", "}", "\n", "gt_dict_list", ".", "append", "(", "gt_dict", ")", "\n", "\n", "", "for", "pred_class", ",", "pred_box", ",", "pred_score", "in", "zip", "(", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", ")", ":", "\n", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "pred_class", ")", "\n", "pred_box_list", "=", "[", "\n", "pred_box", "[", "1", "]", ",", "\n", "pred_box", "[", "0", "]", ",", "\n", "pred_box", "[", "3", "]", ",", "\n", "pred_box", "[", "2", "]", "]", "\n", "pred_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "categories", "[", "ind", "]", ",", "\n", "'bbox'", ":", "pred_box_list", ",", "\n", "'score'", ":", "pred_score", "}", "\n", "\n", "prediction_dict_list", ".", "append", "(", "pred_dict", ")", "\n", "", "", "id", "+=", "1", "\n", "print", "(", "'Computed {} / {} frames.'", ".", "format", "(", "id", ",", "len", "(", "frames_list", ")", ")", ")", "\n", "\n", "", "mean", ",", "breakdown", ",", "cat_list", ",", "optimal_score_thresholds", ",", "maximum_f_scores", "=", "evaluate_detection", "(", "\n", "gt_dict_list", ",", "prediction_dict_list", ",", "iou_thresholds", "=", "[", "0.5", "]", ")", "\n", "\n", "table", "=", "PrettyTable", "(", "cat_list", ")", "\n", "table", ".", "add_row", "(", "breakdown", ")", "\n", "table", ".", "add_row", "(", "optimal_score_thresholds", ")", "\n", "\n", "print", "(", "'Mean AP: '", "+", "str", "(", "mean", ")", "+", "'\\n'", ")", "\n", "print", "(", "'Mean Optimal Score Threshold: '", "+", "\n", "str", "(", "np", ".", "mean", "(", "np", ".", "array", "(", "optimal_score_thresholds", ")", ")", ")", "+", "'\\n'", ")", "\n", "print", "(", "'Mean Maximum F-score: '", "+", "\n", "str", "(", "np", ".", "mean", "(", "np", ".", "array", "(", "maximum_f_scores", ")", ")", ")", "+", "'\\n'", ")", "\n", "\n", "# Compute number of Out of Distribution predictions. Predicitions that do", "\n", "# not exist in GT data but where classified as such.", "\n", "num_od", "=", "np", ".", "array", "(", "[", "0", "if", "prediction", "[", "'category'", "]", "\n", "in", "cat_list", "else", "1", "for", "prediction", "in", "prediction_dict_list", "]", ")", "\n", "\n", "print", "(", "'Ratio of Out of Distribution Predictions: '", "+", "\n", "str", "(", "np", ".", "sum", "(", "num_od", ")", "/", "len", "(", "prediction_dict_list", ")", ")", "+", "'\\n'", ")", "\n", "print", "(", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler.__init__": [[17, 65], ["src.core.abstract_classes.dataset_handler.DatasetHandler.__init__", "os.path.expanduser", "os.path.join", "os.path.join", "src.check_data_dirs", "src.check_data_dirs", "src.check_data_dirs", "bdd_dataset_handler.BddDatasetHandler._load_sample_ids", "len", "json.load", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.check_data_dirs", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler._load_sample_ids"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "train_val_test", ")", ":", "\n", "        ", "\"\"\"\n        Initializes directories, and loads the sample list\n\n        :param config: configuration dictionary\n        :param train_val_test (string): 'train', 'val', or 'test'\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "# Define Dicts", "\n", "self", ".", "_MEANS_DICT", "=", "constants", ".", "MEANS_DICT", "\n", "\n", "# Load configs", "\n", "self", ".", "anchor_gen_config", "=", "config", "[", "'anchor_generator'", "]", "\n", "self", ".", "training_data_config", "=", "config", "[", "'bdd'", "]", "[", "'training_data_config'", "]", "\n", "# Define paths to dataset", "\n", "paths_config", "=", "config", "[", "'bdd'", "]", "[", "'paths_config'", "]", "\n", "self", ".", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "paths_config", "[", "'dataset_dir'", "]", ")", "\n", "data_set_size", "=", "paths_config", "[", "'100k_or_10k'", "]", "\n", "\n", "if", "train_val_test", "==", "'train'", ":", "\n", "            ", "self", ".", "data_split_dir", "=", "train_val_test", "\n", "self", ".", "label_file_name", "=", "'train.json'", "\n", "self", ".", "frac_training_data", "=", "self", ".", "training_data_config", "[", "'frac_training_data'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "data_split_dir", "=", "'val'", "\n", "self", ".", "label_file_name", "=", "'val.json'", "\n", "self", ".", "frac_training_data", "=", "1.0", "\n", "\n", "", "self", ".", "im_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "dataset_dir", ",", "'images'", ",", "data_set_size", ",", "self", ".", "data_split_dir", ")", "\n", "self", ".", "gt_label_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "dataset_dir", ",", "'labels'", ")", "\n", "\n", "# Make sure dataset directories exist", "\n", "dataset_utils", ".", "check_data_dirs", "(", "[", "self", ".", "im_dir", ",", "self", ".", "gt_label_dir", "]", ")", "\n", "\n", "# Get sample ids", "\n", "self", ".", "_load_sample_ids", "(", ")", "\n", "self", ".", "epoch_size", "=", "len", "(", "self", ".", "sample_ids", ")", "\n", "self", ".", "labels", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "gt_label_dir", ",", "self", ".", "label_file_name", ")", ",", "'r'", ")", ")", "\n", "\n", "# Create placeholder for dataset", "\n", "self", ".", "dataset", "=", "None", "\n", "\n", "# Create flag if train\\val or just inference", "\n", "self", ".", "is_testing", "=", "(", "train_val_test", "==", "'test'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler._load_sample_ids": [[66, 89], ["os.listdir", "int", "numpy.random.choice", "len", "random.shuffle", "len"], "methods", ["None"], ["", "def", "_load_sample_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        loads sample ids to read dataset\n        \"\"\"", "\n", "sample_ids", "=", "os", ".", "listdir", "(", "self", ".", "im_dir", ")", "\n", "\n", "# Random shuffle here is much more computationally efficient than randomly shuffling a dataset iterator.", "\n", "if", "self", ".", "frac_training_data", "!=", "1.0", "and", "self", ".", "data_split_dir", "==", "'train'", ":", "\n", "            ", "percent_samples", "=", "int", "(", "len", "(", "sample_ids", ")", "*", "self", ".", "frac_training_data", ")", "\n", "inds", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "sample_ids", ")", ",", "percent_samples", ",", "replace", "=", "False", ")", "\n", "self", ".", "sample_ids", "=", "[", "sample_ids", "[", "ind", "]", "for", "ind", "in", "inds", "]", "\n", "", "elif", "self", ".", "data_split_dir", "==", "'train'", ":", "\n", "            ", "random", ".", "shuffle", "(", "sample_ids", ")", "\n", "self", ".", "sample_ids", "=", "sample_ids", "\n", "", "else", ":", "\n", "            ", "self", ".", "sample_ids", "=", "sample_ids", "\n", "\n", "# Create a list of image paths from sample ids", "\n", "", "self", ".", "im_paths", "=", "[", "\n", "self", ".", "im_dir", "+", "\n", "'/'", "+", "\n", "sample", "for", "sample", "in", "self", ".", "sample_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler.set_sample_id": [[90, 93], ["None"], "methods", ["None"], ["", "def", "set_sample_id", "(", "self", ",", "sample_index", ")", ":", "\n", "        ", "self", ".", "im_paths", "=", "[", "self", ".", "im_paths", "[", "sample_index", "]", "]", "\n", "self", ".", "sample_ids", "=", "[", "self", ".", "sample_ids", "[", "sample_index", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler.create_dataset": [[94, 113], ["tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices.map"], "methods", ["None"], ["", "def", "create_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Create dataset using tf.dataset API\n\n        :return: dataset : dataset object\n        \"\"\"", "\n", "# Set data path lists", "\n", "im_paths", "=", "self", ".", "im_paths", "\n", "sample_ids", "=", "self", ".", "sample_ids", "\n", "\n", "# Create dataset using API", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "im_paths", ",", "sample_ids", ")", ")", "\n", "\n", "# Create sample dictionary", "\n", "self", ".", "dataset", "=", "dataset", ".", "map", "(", "\n", "self", ".", "create_sample_dict", ",", "\n", "num_parallel_calls", "=", "10", ")", "\n", "\n", "return", "self", ".", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler.create_sample_dict": [[114, 198], ["dict", "dict.update", "dict.update", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator", "src.vuvu_to_vuhw", "src.vuvu_to_vuhw", "src.vuvu_to_vuhw", "dict.update", "tensorflow.name_scope", "tensorflow.io.read_file", "tensorflow.image.decode_jpeg", "tensorflow.cast", "src.mean_image_subtraction", "src.mean_image_subtraction", "src.mean_image_subtraction", "tensorflow.unstack", "tensorflow.stack", "tensorflow.py_function", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors", "anchors_list.append", "dict.update", "tensorflow.shape", "tensorflow.shape", "src.vuhw_to_vuvu", "src.vuhw_to_vuvu", "src.vuhw_to_vuvu", "src.bbox_iou_vuvu", "src.bbox_iou_vuvu", "src.bbox_iou_vuvu", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "anchors_positive_mask_list.append", "anchors_negative_mask_list.append", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "src.retina_net.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "anchors_box_target_list.append", "anchors_class_target_list.append", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.mean_image_subtraction", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets"], ["", "def", "create_sample_dict", "(", "\n", "self", ",", "\n", "im_path", ",", "\n", "sample_id", ")", ":", "\n", "        ", "\"\"\"\n        Creates sample dictionary for a single sample\n\n        :param im_path: left image path\n        :param sample_id: ground truth sample id\n\n        :return: sample_dict: Sample dictionary filled with input tensors\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'input_data'", ")", ":", "\n", "# Read image", "\n", "            ", "image_as_string", "=", "tf", ".", "io", ".", "read_file", "(", "im_path", ")", "\n", "image", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "image_as_string", ",", "channels", "=", "3", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "\n", "image_norm", "=", "dataset_utils", ".", "mean_image_subtraction", "(", "\n", "image", ",", "self", ".", "_MEANS_DICT", "[", "self", ".", "im_normalization", "]", ")", "\n", "\n", "# Flip channels to BGR since pretrained weights use this", "\n", "# configuration.", "\n", "channels", "=", "tf", ".", "unstack", "(", "image_norm", ",", "axis", "=", "-", "1", ")", "\n", "image_norm", "=", "tf", ".", "stack", "(", "\n", "[", "channels", "[", "2", "]", ",", "channels", "[", "1", "]", ",", "channels", "[", "0", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "boxes_class_gt", ",", "boxes_2d_gt", ",", "no_gt", "=", "tf", ".", "py_function", "(", "\n", "self", ".", "_read_labels", ",", "[", "sample_id", "]", ",", "[", "\n", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "tf", ".", "bool", "]", ")", "\n", "\n", "# Create_sample_dict", "\n", "", "sample_dict", "=", "dict", "(", ")", "\n", "sample_dict", ".", "update", "(", "{", "constants", ".", "IMAGE_NORMALIZED_KEY", ":", "image_norm", "}", ")", "\n", "sample_dict", ".", "update", "(", "\n", "{", "constants", ".", "ORIGINAL_IM_SIZE_KEY", ":", "tf", ".", "shape", "(", "image", ")", "}", ")", "\n", "\n", "# Create prior anchors and anchor targets", "\n", "generator", "=", "FpnAnchorGenerator", "(", "self", ".", "anchor_gen_config", ")", "\n", "boxes_2d_gt_vuhw", "=", "box_utils", ".", "vuvu_to_vuhw", "(", "boxes_2d_gt", ")", "\n", "\n", "anchors_list", "=", "[", "]", "\n", "anchors_class_target_list", "=", "[", "]", "\n", "anchors_box_target_list", "=", "[", "]", "\n", "anchors_positive_mask_list", "=", "[", "]", "\n", "anchors_negative_mask_list", "=", "[", "]", "\n", "\n", "for", "layer_number", "in", "self", ".", "anchor_gen_config", "[", "'layers'", "]", ":", "\n", "            ", "anchors", "=", "generator", ".", "generate_anchors", "(", "\n", "tf", ".", "shape", "(", "image_norm", ")", ",", "layer_number", ")", "\n", "anchors_list", ".", "append", "(", "anchors", ")", "\n", "\n", "if", "not", "self", ".", "is_testing", ":", "\n", "                ", "anchor_corners", "=", "box_utils", ".", "vuhw_to_vuvu", "(", "anchors", ")", "\n", "ious", "=", "box_utils", ".", "bbox_iou_vuvu", "(", "anchor_corners", ",", "boxes_2d_gt", ")", "\n", "\n", "positive_anchor_mask", ",", "negative_anchor_mask", ",", "max_ious", "=", "generator", ".", "positive_negative_batching", "(", "\n", "ious", ",", "self", ".", "anchor_gen_config", "[", "'min_positive_iou'", "]", ",", "\n", "self", ".", "anchor_gen_config", "[", "'max_negative_iou'", "]", ")", "\n", "\n", "anchors_positive_mask_list", ".", "append", "(", "positive_anchor_mask", ")", "\n", "anchors_negative_mask_list", ".", "append", "(", "negative_anchor_mask", ")", "\n", "\n", "anchor_box_targets", ",", "anchor_class_targets", "=", "generator", ".", "generate_anchor_targets", "(", "\n", "anchors", ",", "boxes_2d_gt_vuhw", ",", "boxes_class_gt", ",", "max_ious", ",", "\n", "positive_anchor_mask", ")", "\n", "anchors_box_target_list", ".", "append", "(", "anchor_box_targets", ")", "\n", "anchors_class_target_list", ".", "append", "(", "anchor_class_targets", ")", "\n", "\n", "# Sample dict is stacked from p3 --> p7, this is essential to", "\n", "# memorize for stacking the predictions later on", "\n", "", "", "sample_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_KEY", ":", "tf", ".", "concat", "(", "anchors_list", ",", "axis", "=", "0", ")", "}", ")", "\n", "if", "not", "self", ".", "is_testing", ":", "\n", "            ", "sample_dict", ".", "update", "(", "{", "constants", ".", "ANCHORS_BOX_TARGETS_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_box_target_list", ",", "axis", "=", "0", ")", ",", "\n", "constants", ".", "ANCHORS_CLASS_TARGETS_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_class_target_list", ",", "axis", "=", "0", ")", ",", "\n", "constants", ".", "POSITIVE_ANCHORS_MASK_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_positive_mask_list", ",", "axis", "=", "0", ")", ",", "\n", "constants", ".", "NEGATIVE_ANCHOR_MASK_KEY", ":", "tf", ".", "concat", "(", "\n", "anchors_negative_mask_list", ",", "axis", "=", "0", ")", "}", ")", "\n", "\n", "", "return", "sample_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.bdd_dataset_handler.BddDatasetHandler._read_labels": [[199, 243], ["sample_id.decode.decode.numpy", "sample_id.decode.decode.decode", "numpy.array", "numpy.array", "boxes_class_gt.append", "len", "numpy.expand_dims", "numpy.array().astype", "numpy.array().astype", "categories.index", "boxes_class_gt.append", "range", "elem.lower", "numpy.array", "numpy.array", "range", "len", "len"], "methods", ["None"], ["", "def", "_read_labels", "(", "self", ",", "sample_id", ")", ":", "\n", "        ", "\"\"\"\n        Reads ground truth labels and parses them into one hot class representation and groundtruth 2D bounding box.\n        \"\"\"", "\n", "sample_id", "=", "sample_id", ".", "numpy", "(", ")", "\n", "\n", "# Extract the list", "\n", "no_gt", "=", "False", "\n", "categories", "=", "self", ".", "training_data_config", "[", "'categories'", "]", "\n", "boxes_class_gt", "=", "[", "]", "\n", "\n", "sample_id", "=", "sample_id", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "frame_labels", "=", "[", "label", "for", "label", "in", "self", ".", "labels", "if", "\n", "label", "[", "'name'", "]", "==", "sample_id", "and", "label", "[", "\n", "'category'", "]", "in", "categories", "]", "\n", "\n", "boxes_2d_gt", "=", "np", ".", "array", "(", "[", "[", "label", "[", "'bbox'", "]", "[", "1", "]", ",", "\n", "label", "[", "'bbox'", "]", "[", "0", "]", ",", "\n", "label", "[", "'bbox'", "]", "[", "3", "]", ",", "\n", "label", "[", "'bbox'", "]", "[", "2", "]", "]", "for", "label", "in", "frame_labels", "]", ")", "\n", "\n", "categories_gt", "=", "[", "label", "[", "'category'", "]", "for", "label", "in", "frame_labels", "]", "\n", "\n", "if", "boxes_2d_gt", ".", "size", "==", "0", ":", "\n", "            ", "cat_one_hot", "=", "[", "0", "for", "e", "in", "range", "(", "len", "(", "categories", ")", "+", "1", ")", "]", "\n", "boxes_2d_gt", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "boxes_class_gt", ".", "append", "(", "cat_one_hot", ")", "\n", "no_gt", "=", "True", "\n", "", "else", ":", "\n", "            ", "for", "elem", "in", "categories_gt", ":", "\n", "                ", "cat_one_hot", "=", "[", "0", "for", "e", "in", "range", "(", "len", "(", "categories", ")", "+", "1", ")", "]", "\n", "\n", "cat_idx", "=", "categories", ".", "index", "(", "elem", ".", "lower", "(", ")", ")", "\n", "cat_one_hot", "[", "cat_idx", "]", "=", "1", "\n", "boxes_class_gt", ".", "append", "(", "cat_one_hot", ")", "\n", "\n", "# one-hot representation dependent on config file", "\n", "\n", "", "", "if", "len", "(", "boxes_2d_gt", ".", "shape", ")", "==", "1", ":", "\n", "            ", "boxes_2d_gt", "=", "np", ".", "expand_dims", "(", "boxes_2d_gt", ",", "axis", "=", "0", ")", "\n", "", "return", "[", "np", ".", "array", "(", "boxes_class_gt", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "np", ".", "array", "(", "boxes_2d_gt", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "no_gt", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.compute_uncertainty_error.main": [[11, 138], ["os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "json.load", "os.listdir", "evaluate_u_error", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "print", "print", "os.path.join", "src.data_dir", "src.data_dir", "src.data_dir", "open", "np.load", "np.load", "np.load", "np.argmax", "zip", "pred_dict_list.extend", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu_np", "frame_preds_list.append", "str", "os.path.join", "os.path.join", "os.path.join", "compute_gaussian_entropy_np", "compute_categorical_entropy_np", "prediction_box_mean.tolist", "prediction_box_mean.tolist", "prediction_box_mean.tolist", "prediction_box_mean.tolist"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.evaluate_u_error", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_gaussian_entropy_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_categorical_entropy_np"], ["#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "difficulty", "=", "'all'", "\n", "categories", "=", "[", "'car'", ",", "'pedestrian'", "]", "\n", "\n", "# Specify whether the validation or inference results need to be evaluated.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "entropy_method", "=", "'categorical'", "# evaluate using gaussian or categorical entropy", "\n", "\n", "# All or per category. Note that if per category is used, out of", "\n", "# distribution detections are ignored. Results in overestimation of", "\n", "# performance.", "\n", "compute_method", "=", "'category'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "\n", "cov_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cat_param'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "\n", "id", "=", "0", "\n", "gt_dict_list", "=", "[", "]", "\n", "prediction_dict_list", "=", "[", "]", "\n", "for", "frame", "in", "frames_list", ":", "\n", "        ", "frame_id", "=", "int", "(", "frame", "[", "0", ":", "6", "]", ")", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes", ",", "gt_boxes", "=", "read_labels", "(", "\n", "label_path", ",", "difficulty", "=", "difficulty", ",", "categories", "=", "categories", ")", "\n", "\n", "prediction_path", "=", "prediction_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", "=", "read_predictions", "(", "\n", "prediction_path", ",", "categories", "=", "categories", ")", "\n", "\n", "if", "gt_boxes", ".", "size", ">", "0", "and", "prediction_boxes", ".", "size", ">", "0", ":", "\n", "            ", "prediction_box_cat_params", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "cat_param_dir", ",", "'{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", ")", "\n", "prediction_box_covs", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "cov_dir", ",", "'{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", ")", "\n", "\n", "if", "entropy_method", "==", "'gaussian'", ":", "\n", "                ", "ranking_entropies", "=", "[", "compute_gaussian_entropy_np", "(", "\n", "cov", ")", "for", "cov", "in", "prediction_box_covs", "]", "\n", "", "elif", "entropy_method", "==", "'categorical'", ":", "\n", "                ", "ranking_entropies", "=", "[", "compute_categorical_entropy_np", "(", "\n", "cat_vect", ")", "for", "cat_vect", "in", "prediction_box_cat_params", "]", "\n", "\n", "", "for", "gt_class", ",", "gt_box", "in", "zip", "(", "gt_classes", ",", "gt_boxes", ")", ":", "\n", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "gt_class", ")", "\n", "gt_box_list", "=", "[", "gt_box", "[", "1", "]", ",", "gt_box", "[", "0", "]", ",", "gt_box", "[", "3", "]", ",", "gt_box", "[", "2", "]", "]", "\n", "if", "compute_method", "==", "'All'", ":", "\n", "                    ", "category_name", "=", "'All'", "\n", "", "else", ":", "\n", "                    ", "category_name", "=", "categories", "[", "ind", "]", "\n", "", "gt_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "category_name", ",", "\n", "'bbox'", ":", "gt_box_list", ",", "\n", "'score'", ":", "1", "}", "\n", "gt_dict_list", ".", "append", "(", "gt_dict", ")", "\n", "\n", "", "for", "pred_class", ",", "pred_box", ",", "ranking_entropy", "in", "zip", "(", "\n", "prediction_classes", ",", "prediction_boxes", ",", "ranking_entropies", ")", ":", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "pred_class", ")", "\n", "if", "ind", ">=", "len", "(", "categories", ")", ":", "\n", "                    ", "continue", "\n", "", "pred_box_list", "=", "[", "\n", "pred_box", "[", "1", "]", ",", "\n", "pred_box", "[", "0", "]", ",", "\n", "pred_box", "[", "3", "]", ",", "\n", "pred_box", "[", "2", "]", "]", "\n", "if", "compute_method", "==", "'All'", ":", "\n", "                    ", "category_name", "=", "'All'", "\n", "", "else", ":", "\n", "                    ", "category_name", "=", "categories", "[", "ind", "]", "\n", "", "pred_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "category_name", ",", "\n", "'bbox'", ":", "pred_box_list", ",", "\n", "'entropy_score'", ":", "ranking_entropy", "}", "\n", "\n", "prediction_dict_list", ".", "append", "(", "pred_dict", ")", "\n", "", "", "id", "+=", "1", "\n", "print", "(", "'Computed {} / {} frames.'", ".", "format", "(", "id", ",", "len", "(", "frames_list", ")", ")", ")", "\n", "\n", "", "mean_u_error_list", ",", "mean_u_error", ",", "cat_list", ",", "scores_at_min_u_error", "=", "evaluate_u_error", "(", "\n", "gt_dict_list", ",", "prediction_dict_list", ",", "iou_thresholds", "=", "[", "0.5", "]", ")", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.compute_pdq.main": [[17, 179], ["os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "json.load", "os.listdir", "sum", "sum", "sum", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "print", "os.path.join", "os.path.join", "src.data_dir", "src.data_dir", "src.data_dir", "open", "print", "src.retina_net.offline_eval.pdq.PDQ", "score.append", "pdq.PDQ.get_assignment_counts", "sum.append", "sum.append", "sum.append", "avg_spatial_quality.append", "avg_label_quality.append", "avg_overall_quality.append", "print", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "src.data_dir", "open", "print", "range", "demos.demo_utils.bdd_demo_utils.read_bdd_format", "numpy.load", "pdq.PDQ.get_avg_spatial_score", "pdq.PDQ.get_avg_label_score", "pdq.PDQ.get_avg_overall_quality_score", "len", "numpy.load", "numpy.load", "numpy.array", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu_np", "zip", "zip", "match_list.append", "pdq.PDQ.score", "os.path.join", "numpy.matmul", "numpy.zeros", "box_2d_gt.astype", "[].item", "src.retina_net.offline_eval.pdq_data_holders.GroundTruthInstance", "gt_instance_list.append", "os.path.join", "os.path.join", "numpy.matmul", "numpy.max", "numpy.array().astype", "src.retina_net.offline_eval.pdq_data_holders.PBoxDetInst", "det_instance_list.append", "numpy.where", "numpy.array"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_assignment_counts", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.bdd_demo_utils.read_bdd_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_spatial_score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_label_score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_overall_quality_score", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.score"], ["#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "difficulty", "=", "'all'", "\n", "categories", "=", "[", "'car'", ",", "'pedestrian'", "]", "\n", "\n", "# Specify whether the validation or inference results need to be evaluated.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "# sample_free, anchor_redundancy, black_box,naive_aleatoric_epistemic  bayes_od_none,", "\n", "# bayes_od_ci_fast. bayes_od_ci,or bayes_od_ici", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "mean_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'mean'", ")", "\n", "\n", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "\n", "cov_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cat_param'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "\n", "id", "=", "0", "\n", "gt_dict_list", "=", "[", "]", "\n", "prediction_dict_list", "=", "[", "]", "\n", "print", "(", "\"PDQ evaluation starting:\"", ")", "\n", "match_list", "=", "[", "]", "\n", "for", "frame", "in", "frames_list", ":", "\n", "        ", "frame_id", "=", "int", "(", "frame", "[", "0", ":", "6", "]", ")", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes", ",", "gt_boxes", "=", "read_labels", "(", "\n", "label_path", ",", "difficulty", "=", "difficulty", ",", "categories", "=", "categories", ")", "\n", "\n", "# Create GT list", "\n", "gt_instance_list", "=", "[", "]", "\n", "if", "gt_boxes", ".", "size", ">", "0", ":", "\n", "            ", "for", "cat_gt", ",", "box_2d_gt", "in", "zip", "(", "gt_classes", ",", "gt_boxes", ")", ":", "\n", "                ", "seg_mask", "=", "np", ".", "zeros", "(", "[", "375", ",", "1300", "]", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "box_inds", "=", "box_2d_gt", ".", "astype", "(", "np", ".", "int32", ")", ".", "tolist", "(", ")", "\n", "box_inds", "=", "np", ".", "array", "(", "\n", "[", "box_inds", "[", "1", "]", ",", "box_inds", "[", "0", "]", ",", "box_inds", "[", "3", "]", ",", "box_inds", "[", "2", "]", "]", ")", "\n", "\n", "box_inds", "=", "np", ".", "clip", "(", "\n", "box_inds", ",", "\n", "a_min", "=", "0.0", ",", "\n", "a_max", "=", "1300", ")", ".", "astype", "(", "\n", "np", ".", "int32", ")", "\n", "\n", "seg_mask", "[", "box_inds", "[", "1", "]", ":", "box_inds", "[", "3", "]", ",", "\n", "box_inds", "[", "0", "]", ":", "box_inds", "[", "2", "]", "]", "=", "True", "\n", "gt_index", "=", "np", ".", "argmax", "(", "cat_gt", ")", "\n", "gt_instance", "=", "pdq_data_holders", ".", "GroundTruthInstance", "(", "\n", "seg_mask", ",", "gt_index", ",", "0", ",", "0", ",", "bounding_box", "=", "box_inds", ")", "\n", "gt_instance_list", ".", "append", "(", "gt_instance", ")", "\n", "\n", "", "", "prediction_boxes_mean", "=", "np", ".", "load", "(", "\n", "mean_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "load", "(", "\n", "cov_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "*", "70", "\n", "prediction_boxes_cat_params", "=", "np", ".", "load", "(", "\n", "cat_param_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "\n", "det_instance_list", "=", "[", "]", "\n", "if", "prediction_boxes_cov", ".", "size", ":", "\n", "            ", "prediction_boxes_cat_params", "=", "np", ".", "stack", "(", "\n", "[", "prediction_boxes_cat_params", "[", ":", ",", "0", "]", ",", "prediction_boxes_cat_params", "[", ":", ",", "3", "]", "]", ",", "axis", "=", "1", ")", "\n", "transformation_mat", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "0", ",", "-", "0.5", "]", ",", "\n", "[", "1", ",", "0", ",", "-", "0.5", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0.5", "]", ",", "\n", "[", "1", ",", "0", ",", "0.5", ",", "0", "]", "]", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "matmul", "(", "\n", "np", ".", "matmul", "(", "\n", "transformation_mat", ",", "\n", "prediction_boxes_cov", ")", ",", "\n", "transformation_mat", ".", "T", ")", "\n", "prediction_boxes_mean", "=", "vuhw_to_vuvu_np", "(", "prediction_boxes_mean", ")", "\n", "for", "cat_det", ",", "box_mean", ",", "cov_det", "in", "zip", "(", "\n", "prediction_boxes_cat_params", ",", "prediction_boxes_mean", ",", "prediction_boxes_cov", ")", ":", "\n", "                ", "if", "np", ".", "max", "(", "cat_det", ")", ">=", "0.5", ":", "\n", "                    ", "box_processed", "=", "np", ".", "array", "(", "\n", "[", "box_mean", "[", "1", "]", ",", "box_mean", "[", "0", "]", ",", "box_mean", "[", "3", "]", ",", "box_mean", "[", "2", "]", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "cov_processed", "=", "[", "cov_det", "[", "0", ":", "2", ",", "0", ":", "2", "]", ",", "cov_det", "[", "2", ":", "4", ",", "2", ":", "4", "]", "]", "\n", "det_instance", "=", "pdq_data_holders", ".", "PBoxDetInst", "(", "\n", "cat_det", ",", "box_processed", ",", "cov_processed", ")", "\n", "det_instance_list", ".", "append", "(", "det_instance", ")", "\n", "", "", "", "match_list", ".", "append", "(", "(", "gt_instance_list", ",", "det_instance_list", ")", ")", "\n", "\n", "id", "+=", "1", "\n", "print", "(", "'Computed {} / {} frames.'", ".", "format", "(", "id", ",", "len", "(", "frames_list", ")", ")", ")", "\n", "\n", "", "print", "(", "\"PDQ Ended\"", ")", "\n", "evaluator", "=", "pdq", ".", "PDQ", "(", ")", "\n", "score", "=", "evaluator", ".", "score", "(", "match_list", ")", "*", "100", "\n", "TP", ",", "FP", ",", "FN", "=", "evaluator", ".", "get_assignment_counts", "(", ")", "\n", "avg_spatial_quality", "=", "evaluator", ".", "get_avg_spatial_score", "(", ")", "\n", "avg_label_quality", "=", "evaluator", ".", "get_avg_label_score", "(", ")", "\n", "avg_overall_quality", "=", "evaluator", ".", "get_avg_overall_quality_score", "(", ")", "\n", "\n", "table", "=", "PrettyTable", "(", "[", "'score'", ",", "\n", "'True Positives'", ",", "\n", "'False Positives'", ",", "\n", "'False Negatives'", ",", "\n", "'Average Spatial Quality'", ",", "\n", "'Average Label Quality'", ",", "\n", "'Average Overall Quality'", "]", ")", "\n", "\n", "table", ".", "add_row", "(", "[", "score", ",", "TP", ",", "FP", ",", "FN", ",", "avg_spatial_quality", ",", "\n", "avg_label_quality", ",", "avg_overall_quality", "]", ")", "\n", "\n", "print", "(", "table", ")", "\n", "\n", "text_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.bdd.compute_ap.main": [[10, 79], ["os.path.expanduser", "os.path.join", "json.load", "json.load", "evaluate_detection", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "np.array", "np.mean", "print", "print", "print", "np.array", "print", "print", "os.path.join", "os.path.join", "os.path.join", "open", "open", "src.data_dir", "src.data_dir", "str", "str", "str", "str", "np.mean", "np.mean", "np.sum", "len", "np.array", "np.array"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.evaluate_detection", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "difficulty", "=", "'all'", "\n", "categories", "=", "[", "'car'", ",", "'pedestrian'", "]", "\n", "\n", "# Specify whether the validation or inference results need to be evaluated.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "# sample_free, anchor_redundancy, black_box,  naive_aleatoric_epistemic,  bayes_od_none,", "\n", "# bayes_od_ci_fast. bayes_od_ci,or bayes_od_ici", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd_covar'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "", "else", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "checkpoint_number", ",", "\n", "'data'", ")", "\n", "\n", "", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "\n", "id", "=", "0", "\n", "gt_dict_list", "=", "[", "]", "\n", "prediction_dict_list", "=", "[", "]", "\n", "for", "frame", "in", "frames_list", ":", "\n", "        ", "frame_id", "=", "int", "(", "frame", "[", "0", ":", "6", "]", ")", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes", ",", "gt_boxes", "=", "read_labels", "(", "\n", "label_path", ",", "difficulty", "=", "difficulty", ",", "categories", "=", "categories", ")", "\n", "\n", "prediction_path", "=", "prediction_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", "=", "read_predictions", "(", "\n", "prediction_path", ",", "categories", "=", "categories", ")", "\n", "\n", "if", "gt_boxes", ".", "size", ">", "0", "and", "prediction_boxes", ".", "size", ">", "0", ":", "\n", "\n", "            ", "for", "gt_class", ",", "gt_box", "in", "zip", "(", "gt_classes", ",", "gt_boxes", ")", ":", "\n", "\n", "                ", "ind", "=", "np", ".", "argmax", "(", "gt_class", ")", "\n", "gt_box_list", "=", "[", "gt_box", "[", "1", "]", ",", "gt_box", "[", "0", "]", ",", "gt_box", "[", "3", "]", ",", "gt_box", "[", "2", "]", "]", "\n", "gt_dict", "=", "{", "'name'", ":", "str", "(", "id", ")", ",", "\n", "'category'", ":", "categories", "[", "ind", "]", ",", "\n", "'bbox'", ":", "gt_box_list", ",", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_inference.test_model": [[23, 252], ["src.retina_net.builders.dataset_handler_builder.build_dataset", "keras.backend.set_learning_phase", "print", "os.path.join", "os.path.join", "os.makedirs", "int", "dataset_handler_builder.build_dataset.create_dataset", "dataset_handler.create_dataset.repeat().batch", "batched_dataset.prefetch.prefetch", "print", "tensorflow.train.Checkpoint", "time.time", "src.strip_checkpoint_id", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "print", "tf.train.Checkpoint.restore().expect_partial", "enumerate", "print", "tensorflow.name_scope", "src.retina_net.models.retinanet_model.RetinaNetModel", "src.data_dir", "src.data_dir", "os.path.exists", "ValueError", "tensorflow.train.get_checkpoint_state", "str", "os.path.join", "os.path.join", "src.retina_net.experiments.inference_utils.bayes_od_inference", "output_class_counts.numpy.numpy", "np.squeeze.numpy", "output_covs.numpy.numpy", "nms_indices.numpy.numpy", "predicted_boxes_iou_mat.numpy.numpy", "sys.stdout.write", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "time.time", "str", "dataset_handler.create_dataset.repeat", "time.strftime", "tensorflow.Variable", "tf.train.Checkpoint.restore", "os.path.join", "src.retina_net.experiments.inference_utils.bayes_od_clustering", "src.retina_net.experiments.inference_utils.map_dataset_classes", "src.predictions_to_kitti_format", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "open", "json.dump", "keras.backend.learning_phase", "time.gmtime", "str", "os.path.join", "numpy.squeeze", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu_np", "numpy.savetxt", "numpy.savetxt", "src.predictions_to_bdd_format", "final_results_list.extend", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.builders.dataset_handler_builder.build_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.create_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.strip_checkpoint_id", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.bayes_od_inference", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.bayes_od_clustering", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.map_dataset_classes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_kitti_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_bdd_format"], ["def", "test_model", "(", "config", ")", ":", "\n", "# Get testing config", "\n", "    ", "test_config", "=", "config", "[", "'testing_config'", "]", "\n", "ckpt_idx", "=", "test_config", "[", "'ckpt_idx'", "]", "\n", "uncertainty_method", "=", "test_config", "[", "'uncertainty_method'", "]", "\n", "use_full_covar", "=", "test_config", "[", "'use_full_covar'", "]", "\n", "nms_config", "=", "test_config", "[", "'nms_config'", "]", "\n", "\n", "# Create dataset class", "\n", "dataset_config", "=", "config", "[", "'dataset_config'", "]", "\n", "training_dataset", "=", "dataset_config", "[", "'dataset'", "]", "\n", "dataset_config", "[", "'dataset'", "]", "=", "test_config", "[", "'test_dataset'", "]", "\n", "dataset_handler", "=", "dataset_handler_builder", ".", "build_dataset", "(", "\n", "dataset_config", ",", "'test'", ")", "\n", "\n", "# Set keras training phase", "\n", "keras", ".", "backend", ".", "set_learning_phase", "(", "0", ")", "\n", "print", "(", "\"Keras Learning Phase Set to: \"", "+", "\n", "str", "(", "keras", ".", "backend", ".", "learning_phase", "(", ")", ")", ")", "\n", "\n", "# Create Model", "\n", "with", "tf", ".", "name_scope", "(", "\"retinanet_model\"", ")", ":", "\n", "        ", "model", "=", "RetinaNetModel", "(", "config", "[", "'model_config'", "]", ")", "\n", "\n", "# Initialize the model from a saved checkpoint", "\n", "", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "'outputs'", ",", "\n", "config", "[", "'checkpoint_name'", "]", ",", "'checkpoints'", ",", "config", "[", "'checkpoint_name'", "]", ")", "\n", "predictions_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "'outputs'", ",", "\n", "config", "[", "'checkpoint_name'", "]", ",", "'predictions'", ")", "\n", "os", ".", "makedirs", "(", "predictions_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'{} must have at least one checkpoint entry.'", "\n", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "\n", "# Instantiate mini-batch and epoch size", "\n", "", "epoch_size", "=", "int", "(", "dataset_handler", ".", "epoch_size", ")", "\n", "\n", "# Create Dataset", "\n", "# Main function to create dataset", "\n", "dataset", "=", "dataset_handler", ".", "create_dataset", "(", ")", "\n", "\n", "# Batch size goes in parenthesis.", "\n", "batched_dataset", "=", "dataset", ".", "repeat", "(", "1", ")", ".", "batch", "(", "1", ")", "\n", "\n", "# `prefetch` lets the dataset fetch batches, in the background while the model is validating.", "\n", "batched_dataset", "=", "batched_dataset", ".", "prefetch", "(", "\n", "buffer_size", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "print", "(", "'Starting inference at '", "+", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d-%H:%M:%S'", ",", "time", ".", "gmtime", "(", ")", ")", ")", "\n", "\n", "# Initialize the model checkpoint manager", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "step", "=", "tf", ".", "Variable", "(", "0", ")", ",", "net", "=", "model", ")", "\n", "\n", "# Begin inference loop", "\n", "all_checkpoint_states", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "\n", "checkpoint_dir", ")", ".", "all_model_checkpoint_paths", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "checkpoint_to_restore", "=", "all_checkpoint_states", "[", "ckpt_idx", "-", "1", "]", "\n", "ckpt_id", "=", "val_utils", ".", "strip_checkpoint_id", "(", "checkpoint_to_restore", ")", "\n", "\n", "# Make directories if these dont exist", "\n", "predictions_dir_ckpt", "=", "os", ".", "path", ".", "join", "(", "predictions_dir", ",", "\n", "'testing'", ",", "\n", "dataset_config", "[", "'dataset'", "]", ",", "\n", "str", "(", "ckpt_id", ")", ",", "\n", "uncertainty_method", ")", "\n", "if", "dataset_config", "[", "'dataset'", "]", "==", "'rvc'", ":", "\n", "        ", "predictions_dir_ckpt", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "\n", "dataset_config", "[", "'rvc'", "]", "[", "'paths_config'", "]", "[", "'sequence_dir'", "]", ")", "\n", "\n", "", "if", "uncertainty_method", "==", "'bayes_od'", ":", "\n", "        ", "predictions_dir_ckpt", "+=", "'_'", "+", "test_config", "[", "'bayes_od_config'", "]", "[", "'fusion_method'", "]", "\n", "\n", "", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "predictions_dir_ckpt", ",", "'data'", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "loc_mean_dir", "=", "os", ".", "path", ".", "join", "(", "predictions_dir_ckpt", ",", "'mean'", ")", "\n", "loc_cov_dir", "=", "os", ".", "path", ".", "join", "(", "predictions_dir_ckpt", ",", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "predictions_dir_ckpt", ",", "'cat_param'", ")", "\n", "cat_count_dir", "=", "os", ".", "path", ".", "join", "(", "predictions_dir_ckpt", ",", "'cat_count'", ")", "\n", "\n", "os", ".", "makedirs", "(", "loc_mean_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "loc_cov_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "cat_param_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "cat_count_dir", ",", "exist_ok", "=", "True", ")", "\n", "print", "(", "'\\nRunning checkpoint '", "+", "str", "(", "ckpt_id", ")", "+", "'\\n'", ")", "\n", "\n", "# Restore checkpoint. expect_partial is needed to get rid of", "\n", "# optimizer/loss graph elements.", "\n", "ckpt", ".", "restore", "(", "checkpoint_to_restore", ")", ".", "expect_partial", "(", ")", "\n", "\n", "# Perform dataset-specific setup of result output", "\n", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "        ", "pass", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'bdd'", "or", "dataset_config", "[", "'dataset'", "]", "==", "'coco'", "or", "dataset_config", "[", "'dataset'", "]", "==", "'pascal'", ":", "\n", "        ", "final_results_list", "=", "[", "]", "\n", "# Single json file for bdd dataset", "\n", "prediction_json_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "'data'", ",", "'predictions.json'", ")", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'rvc'", ":", "\n", "        ", "final_results_list", "=", "[", "]", "\n", "# Single json file for bdd dataset", "\n", "prediction_json_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "'data'", ",", "'predictions.json'", ")", "\n", "\n", "# Inference loop starts here. Iterate over samples once.", "\n", "", "for", "counter", ",", "sample_dict", "in", "enumerate", "(", "batched_dataset", ")", ":", "\n", "        ", "output_class_counts", ",", "output_boxes_vuhw", ",", "output_covs", ",", "nms_indices", ",", "predicted_boxes_iou_mat", "=", "inference_utils", ".", "bayes_od_inference", "(", "\n", "model", ",", "sample_dict", ",", "test_config", "[", "'bayes_od_config'", "]", ",", "nms_config", ",", "dataset_name", "=", "dataset_config", "[", "'dataset'", "]", ",", "use_full_covar", "=", "use_full_covar", ")", "\n", "\n", "output_class_counts", "=", "output_class_counts", ".", "numpy", "(", ")", "\n", "output_boxes_vuhw", "=", "output_boxes_vuhw", ".", "numpy", "(", ")", "\n", "output_covs", "=", "output_covs", ".", "numpy", "(", ")", "\n", "nms_indices", "=", "nms_indices", ".", "numpy", "(", ")", "\n", "predicted_boxes_iou_mat", "=", "predicted_boxes_iou_mat", ".", "numpy", "(", ")", "\n", "\n", "if", "output_boxes_vuhw", ".", "size", ">", "0", ":", "\n", "            ", "output_classes", ",", "output_boxes_vuhw", ",", "output_covs", ",", "output_counts", "=", "inference_utils", ".", "bayes_od_clustering", "(", "\n", "output_class_counts", ",", "output_boxes_vuhw", ",", "output_covs", ",", "nms_indices", ",", "predicted_boxes_iou_mat", ",", "affinity_threshold", "=", "nms_config", "[", "'iou_threshold'", "]", ")", "\n", "if", "output_boxes_vuhw", ".", "size", ">", "0", ":", "\n", "                ", "output_boxes_vuhw", "=", "np", ".", "squeeze", "(", "output_boxes_vuhw", ",", "axis", "=", "2", ")", "\n", "output_boxes", "=", "box_utils", ".", "vuhw_to_vuvu_np", "(", "output_boxes_vuhw", ")", "\n", "", "else", ":", "\n", "                ", "output_boxes_vuhw", "=", "output_boxes_vuhw", "\n", "output_boxes", "=", "output_boxes_vuhw", "\n", "output_counts", "=", "output_boxes_vuhw", "\n", "", "", "else", ":", "\n", "            ", "output_classes", "=", "output_boxes_vuhw", "\n", "output_boxes", "=", "output_boxes_vuhw", "\n", "output_covs", "=", "output_boxes_vuhw", "\n", "output_counts", "=", "output_boxes_vuhw", "\n", "\n", "# Perform index mapping in case training and testing datasets are not", "\n", "# the same", "\n", "", "if", "training_dataset", "!=", "dataset_config", "[", "'dataset'", "]", "and", "output_boxes", ".", "size", ">", "0", ":", "\n", "            ", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti_tracking'", ":", "\n", "                ", "dataset_config", "[", "'dataset'", "]", "=", "'kitti'", "\n", "", "output_classes_mapped", "=", "inference_utils", ".", "map_dataset_classes", "(", "\n", "training_dataset", ",", "dataset_config", "[", "'dataset'", "]", ",", "output_classes", ")", "\n", "", "else", ":", "\n", "            ", "output_classes_mapped", "=", "output_classes", "\n", "\n", "# Perform dataset-specific saving of outputs", "\n", "", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "            ", "predictions_kitti_format", "=", "val_utils", ".", "predictions_to_kitti_format", "(", "\n", "output_boxes", ",", "output_classes_mapped", ")", "\n", "\n", "prediction_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "\n", "'data'", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.txt'", ")", "\n", "\n", "mean_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "loc_mean_dir", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "covar_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "loc_cov_dir", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "cat_param_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "cat_param_dir", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "cat_count_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "cat_count_dir", ",", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "if", "predictions_kitti_format", ".", "size", "==", "0", ":", "\n", "                ", "np", ".", "savetxt", "(", "prediction_file_name", ",", "[", "]", ")", "\n", "", "else", ":", "\n", "                ", "np", ".", "savetxt", "(", "\n", "prediction_file_name", ",", "\n", "predictions_kitti_format", ",", "\n", "newline", "=", "'\\r\\n'", ",", "\n", "fmt", "=", "'%s'", ")", "\n", "\n", "", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'bdd'", ":", "\n", "            ", "predictions_bdd_format", "=", "val_utils", ".", "predictions_to_bdd_format", "(", "\n", "output_boxes", ",", "\n", "output_classes_mapped", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", ",", "\n", "category_list", "=", "dataset_handler", ".", "training_data_config", "[", "'categories'", "]", ")", "\n", "final_results_list", ".", "extend", "(", "predictions_bdd_format", ")", "\n", "\n", "mean_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "loc_mean_dir", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "covar_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "loc_cov_dir", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "cat_param_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "cat_param_dir", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "cat_count_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "cat_count_dir", ",", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.npy'", ")", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\n", "'\\r{}'", ".", "format", "(", "counter", "+", "1", ")", "+", "' /'", "+", "str", "(", "epoch_size", ")", ")", "\n", "\n", "np", ".", "save", "(", "mean_file_name", ",", "output_boxes_vuhw", ")", "\n", "np", ".", "save", "(", "covar_file_name", ",", "output_covs", ")", "\n", "np", ".", "save", "(", "cat_param_file_name", ",", "output_classes", ")", "\n", "np", ".", "save", "(", "cat_count_file_name", ",", "output_counts", ")", "\n", "\n", "", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "time_per_sample", "=", "elapsed_time", "/", "dataset_handler", ".", "epoch_size", "\n", "frame_rate", "=", "1.0", "/", "time_per_sample", "\n", "\n", "print", "(", "\"\\nMean frame rate: \"", "+", "str", "(", "frame_rate", ")", ")", "\n", "\n", "# Final dataset-specific wrap up work for checkpoint", "\n", "# results", "\n", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "prediction_json_file_name", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "final_results_list", ",", "fp", ",", "indent", "=", "4", ",", "\n", "separators", "=", "(", "','", ",", "': '", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_inference.main": [[254, 300], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "tensorflow.config.experimental.list_physical_devices", "tensorflow.config.experimental.set_memory_growth", "src.retina_net.config_utils.setup", "run_inference.test_model", "src.model_dir", "open", "yaml.load"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils.setup", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_inference.test_model", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.model_dir"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Object Detection Model Validator\n    \"\"\"", "\n", "\n", "# Defaults", "\n", "default_gpu_device", "=", "'0'", "\n", "default_config_path", "=", "core", ".", "model_dir", "(", "\n", "'retina_net'", ")", "+", "'/configs/retinanet_bdd.yaml'", "\n", "# Allowed data splits are 'train','train_mini', 'val', 'val_half',", "\n", "# 'val_mini'", "\n", "default_data_split", "=", "'val'", "\n", "\n", "# Parse input", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "# Define argparser object", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'gpu_device'", ",", "\n", "default", "=", "default_gpu_device", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--yaml_path'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'yaml_path'", ",", "\n", "default", "=", "default_config_path", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--data_split'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'data_split'", ",", "\n", "default", "=", "default_data_split", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Set CUDA device id", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "args", ".", "gpu_device", "\n", "\n", "physical_devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_physical_devices", "(", "'GPU'", ")", "\n", "tf", ".", "config", ".", "experimental", ".", "set_memory_growth", "(", "physical_devices", "[", "0", "]", ",", "True", ")", "\n", "\n", "# Load in configuration file as python dictionary", "\n", "with", "open", "(", "args", ".", "yaml_path", ",", "'r'", ")", "as", "yaml_file", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "yaml_file", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "\n", "# Make necessary directories, update config with checkpoint path and data", "\n", "# split", "\n", "", "config", "=", "config_utils", ".", "setup", "(", "config", ",", "args", ")", "\n", "\n", "# Go to inference function", "\n", "test_model", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.bayes_od_inference": [[13, 218], ["model", "src.retina_net.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "tensorflow.nn.softmax", "tensorflow_probability.distributions.Categorical", "tensorflow.reduce_sum", "tensorflow.not_equal", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "inference_utils.compute_mean_covariance_tf", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu", "tensorflow.image.non_max_suppression_with_scores", "src.retina_net.anchor_generator.box_utils.bbox_iou_vuvu", "tensorflow.shape", "tensorflow.one_hot", "tensorflow.argmax", "tensorflow.cast", "model.keys", "tensorflow.reduce_mean", "tensorflow.boolean_mask", "tensorflow.linalg.diag_part", "tensorflow.zeros_like", "tensorflow.linalg.set_diag", "tensorflow.zeros_like", "tensorflow.reduce_sum", "tensorflow.linalg.inv", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.linalg.inv", "tensorflow.boolean_mask", "tensorflow.expand_dims", "tensorflow.linalg.inv", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.cast", "tensorflow.matmul", "tensorflow.matmul", "inference_utils.compute_gaussian_entropy_tf", "inference_utils.compute_gaussian_entropy_tf", "inference_utils.compute_categorical_entropy_tf", "tensorflow.tile", "inference_utils.compute_categorical_entropy_tf", "tensorflow.reduce_max", "tensorflow.squeeze", "tensorflow.reduce_mean", "tfp.distributions.Categorical.sample", "tensorflow.exp", "tensorflow.linalg.inv", "tensorflow.matmul", "tensorflow.cast", "tensorflow.linalg.tensor_diag", "tensorflow.shape", "tensorflow.linalg.tensor_diag", "tensorflow.matmul", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.equal", "tensorflow.linalg.set_diag", "tensorflow.matmul", "tensorflow.reduce_min", "tensorflow.reduce_min", "tensorflow.shape", "tensorflow.size", "tensorflow.ones_like", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_mean_covariance_tf", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_gaussian_entropy_tf", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_gaussian_entropy_tf", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_categorical_entropy_tf", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_categorical_entropy_tf"], ["@", "tf", ".", "function", "\n", "def", "bayes_od_inference", "(", "model", ",", "\n", "sample_dict", ",", "\n", "bayes_od_config", ",", "\n", "nms_config", ",", "\n", "use_full_covar", "=", "False", ",", "\n", "dataset_name", "=", "'bdd'", ")", ":", "\n", "\n", "# Get prediction from model", "\n", "    ", "prediction_dict", "=", "model", "(", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", ",", "\n", "train_val_test", "=", "'testing'", ")", "\n", "\n", "anchors", "=", "sample_dict", "[", "constants", ".", "ANCHORS_KEY", "]", "\n", "predicted_box_targets", "=", "prediction_dict", "[", "\n", "constants", ".", "ANCHORS_BOX_PREDICTIONS_KEY", "]", "\n", "predicted_boxes", "=", "box_utils", ".", "box_from_anchor_and_target_bnms", "(", "\n", "anchors", ",", "predicted_box_targets", ")", "\n", "\n", "predicted_boxes_classes", "=", "tf", ".", "nn", ".", "softmax", "(", "\n", "prediction_dict", "[", "constants", ".", "ANCHORS_CLASS_PREDICTIONS_KEY", "]", ",", "axis", "=", "2", ")", "\n", "\n", "num_classes", "=", "tf", ".", "shape", "(", "predicted_boxes_classes", ")", "[", "2", "]", "\n", "\n", "# Get categorical likelihood", "\n", "categorical_likelihood_distribution", "=", "tfp", ".", "distributions", ".", "Categorical", "(", "\n", "probs", "=", "tf", ".", "reduce_mean", "(", "predicted_boxes_classes", ",", "axis", "=", "0", ")", ")", "\n", "\n", "categorical_samples", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "one_hot", "(", "\n", "# Go up to 100 if possible for best results", "\n", "categorical_likelihood_distribution", ".", "sample", "(", "30", ")", ",", "\n", "num_classes", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "axis", "=", "None", ")", ",", "axis", "=", "0", ")", "\n", "\n", "category_filter", "=", "tf", ".", "not_equal", "(", "\n", "tf", ".", "argmax", "(", "\n", "categorical_samples", ",", "axis", "=", "1", ")", ",", "tf", ".", "cast", "(", "\n", "tf", ".", "shape", "(", "predicted_boxes_classes", ")", "[", "2", "]", "-", "1", ",", "tf", ".", "int64", ")", ")", "\n", "\n", "categorical_likelihood_samples", "=", "tf", ".", "boolean_mask", "(", "\n", "categorical_samples", ",", "category_filter", ")", "\n", "\n", "# Get gaussian likelihood", "\n", "predicted_boxes", "=", "tf", ".", "boolean_mask", "(", "predicted_boxes", ",", "category_filter", ",", "axis", "=", "1", ")", "\n", "\n", "gaussian_likelihood_means", ",", "gaussian_likelihood_covs", "=", "compute_mean_covariance_tf", "(", "\n", "predicted_boxes", ")", "\n", "\n", "if", "constants", ".", "ANCHORS_COVAR_PREDICTIONS_KEY", "in", "prediction_dict", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "aleatoric_covs", "=", "tf", ".", "reduce_mean", "(", "\n", "prediction_dict", "[", "constants", ".", "ANCHORS_COVAR_PREDICTIONS_KEY", "]", ",", "axis", "=", "0", ")", "\n", "\n", "aleatoric_covs", "=", "tf", ".", "boolean_mask", "(", "\n", "aleatoric_covs", ",", "category_filter", ",", "axis", "=", "0", ")", "\n", "\n", "D_diag", "=", "tf", ".", "linalg", ".", "diag_part", "(", "tf", ".", "exp", "(", "aleatoric_covs", ")", ")", "\n", "aleatoric_var_mats", "=", "tf", ".", "zeros_like", "(", "aleatoric_covs", ")", "\n", "aleatoric_var_mats", "=", "tf", ".", "linalg", ".", "set_diag", "(", "\n", "aleatoric_var_mats", ",", "D_diag", ")", "\n", "if", "use_full_covar", "and", "not", "tf", ".", "equal", "(", "tf", ".", "size", "(", "aleatoric_var_mats", ")", ",", "0", ")", ":", "\n", "            ", "L", "=", "tf", ".", "linalg", ".", "inv", "(", "\n", "tf", ".", "linalg", ".", "set_diag", "(", "\n", "aleatoric_covs", ",", "\n", "tf", ".", "ones_like", "(", "D_diag", ")", ")", ")", "\n", "aleatoric_cov_mats", "=", "tf", ".", "matmul", "(", "\n", "tf", ".", "matmul", "(", "L", ",", "aleatoric_var_mats", ")", ",", "L", ",", "transpose_b", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "aleatoric_cov_mats", "=", "aleatoric_var_mats", "\n", "", "", "else", ":", "\n", "        ", "aleatoric_cov_mats", "=", "tf", ".", "zeros_like", "(", "gaussian_likelihood_covs", ")", "\n", "\n", "", "gaussian_likelihood_covs", "=", "(", "\n", "10.0", "*", "aleatoric_cov_mats", "+", "1.0", "*", "gaussian_likelihood_covs", ")", "/", "11.0", "\n", "\n", "# Incorporate dirichlet priors if applicable", "\n", "if", "bayes_od_config", "[", "'dirichlet_prior'", "]", "[", "'type'", "]", "==", "'non_informative'", ":", "\n", "        ", "dirich_prior_alphas", "=", "1.0", "/", "tf", ".", "cast", "(", "num_classes", ",", "tf", ".", "float32", ")", "\n", "dirichlit_posterior_count", "=", "categorical_likelihood_samples", "+", "dirich_prior_alphas", "\n", "", "else", ":", "\n", "        ", "dirichlit_posterior_count", "=", "categorical_likelihood_samples", "\n", "\n", "", "categorical_posterior_score", "=", "dirichlit_posterior_count", "/", "tf", ".", "reduce_sum", "(", "\n", "dirichlit_posterior_count", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "# Incorporate gaussian priors if applicable", "\n", "if", "bayes_od_config", "[", "'gaussian_prior'", "]", "[", "'type'", "]", "==", "'isotropic'", ":", "\n", "        ", "gaussian_likelihood_precisions", "=", "tf", ".", "linalg", ".", "inv", "(", "\n", "gaussian_likelihood_covs", ")", "\n", "\n", "gaussian_prior_variance", "=", "[", "\n", "bayes_od_config", "[", "'gaussian_prior'", "]", "[", "'isotropic_variance'", "]", "]", "\n", "\n", "gaussian_prior_var", "=", "tf", ".", "tile", "(", "\n", "gaussian_prior_variance", ",", "[", "\n", "tf", ".", "shape", "(", "gaussian_likelihood_precisions", ")", "[", "2", "]", "]", ")", "\n", "\n", "# Update means and covariances to get the sufficient statistics", "\n", "# of the post-mc dropout posterior means and covariances", "\n", "\n", "# Compute prior mean and covariance", "\n", "gaussian_prior_covs", "=", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "linalg", ".", "tensor_diag", "(", "gaussian_prior_var", ")", ",", "axis", "=", "0", ")", "\n", "gaussian_prior_covs", "=", "tf", ".", "tile", "(", "\n", "gaussian_prior_covs", ",", "[", "\n", "tf", ".", "shape", "(", "gaussian_likelihood_precisions", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "gaussian_prior_precision", "=", "tf", ".", "linalg", ".", "inv", "(", "gaussian_prior_covs", ")", "\n", "\n", "gaussian_prior_means", "=", "tf", ".", "boolean_mask", "(", "anchors", "[", "0", "]", ",", "category_filter", ")", "\n", "gaussian_prior_means", "=", "tf", ".", "expand_dims", "(", "gaussian_prior_means", ",", "axis", "=", "2", ")", "\n", "\n", "# Compute posterior covariance matrices using the update equation", "\n", "# in the paper", "\n", "gaussian_posterior_precisions", "=", "gaussian_likelihood_precisions", "+", "gaussian_prior_precision", "\n", "gaussian_posterior_covs", "=", "tf", ".", "linalg", ".", "inv", "(", "gaussian_posterior_precisions", ")", "\n", "\n", "# Compute posterior means using the update equation in the paper", "\n", "prior_mean_weights", "=", "tf", ".", "matmul", "(", "\n", "gaussian_prior_precision", ",", "gaussian_prior_means", ")", "\n", "\n", "gaussian_likelihood_means", "=", "tf", ".", "expand_dims", "(", "\n", "gaussian_likelihood_means", ",", "axis", "=", "2", ")", "\n", "gaussian_likelihood_mean_weights", "=", "tf", ".", "matmul", "(", "\n", "gaussian_likelihood_precisions", ",", "gaussian_likelihood_means", ")", "\n", "\n", "intermediate_value", "=", "prior_mean_weights", "+", "gaussian_likelihood_mean_weights", "\n", "gaussian_posterior_means", "=", "tf", ".", "matmul", "(", "\n", "gaussian_posterior_covs", ",", "intermediate_value", ")", "\n", "", "else", ":", "\n", "        ", "gaussian_posterior_covs", "=", "gaussian_likelihood_covs", "\n", "gaussian_posterior_means", "=", "gaussian_likelihood_means", "\n", "\n", "", "if", "dataset_name", "==", "'kitti'", ":", "\n", "# Scaling is required on both mean and covariance, as the neural", "\n", "# network estimates values in a scaled version of the input dataset", "\n", "# image for the KITTI dataset only", "\n", "        ", "scale", "=", "sample_dict", "[", "constants", ".", "ORIGINAL_IM_SIZE_KEY", "]", "[", "0", "]", "/", "tf", ".", "shape", "(", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", "[", "0", "]", ")", "\n", "scale", "=", "tf", ".", "tile", "(", "scale", "[", "0", ":", "2", "]", ",", "[", "tf", ".", "shape", "(", "aleatoric_cov_mats", ")", "[", "2", "]", "/", "2", "]", ")", "\n", "scale_mat", "=", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "linalg", ".", "tensor_diag", "(", "scale", ")", ",", "axis", "=", "0", ")", "\n", "scale_mat", "=", "tf", ".", "tile", "(", "\n", "scale_mat", ",", "[", "\n", "tf", ".", "shape", "(", "aleatoric_cov_mats", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "scale_mat", "=", "tf", ".", "cast", "(", "scale_mat", ",", "tf", ".", "float32", ")", "\n", "gaussian_posterior_means", "=", "tf", ".", "matmul", "(", "scale_mat", ",", "\n", "gaussian_posterior_means", ")", "\n", "gaussian_posterior_covs", "=", "tf", ".", "matmul", "(", "\n", "tf", ".", "matmul", "(", "\n", "scale_mat", ",", "\n", "gaussian_posterior_covs", ")", ",", "\n", "scale_mat", ",", "\n", "transpose_b", "=", "True", ")", "\n", "\n", "", "if", "bayes_od_config", "[", "'ranking_method'", "]", "==", "'joint_entropy'", "and", "bayes_od_config", "[", "'gaussian_prior'", "]", "[", "\n", "'type'", "]", "!=", "'None'", "and", "bayes_od_config", "[", "'dirichlet_prior'", "]", "[", "'type'", "]", "!=", "'None'", ":", "\n", "        ", "gaussian_entropy_posterior", "=", "compute_gaussian_entropy_tf", "(", "\n", "gaussian_posterior_covs", ")", "\n", "\n", "gaussian_entropy_prior", "=", "compute_gaussian_entropy_tf", "(", "\n", "gaussian_prior_covs", ")", "\n", "\n", "gaussian_info_gain", "=", "gaussian_entropy_prior", "-", "gaussian_entropy_posterior", "\n", "\n", "gaussian_info_gain", "=", "(", "\n", "gaussian_info_gain", "-", "tf", ".", "reduce_min", "(", "gaussian_info_gain", ")", ")", "/", "tf", ".", "maximum", "(", "\n", "1.0", ",", "tf", ".", "reduce_max", "(", "gaussian_info_gain", ")", "-", "tf", ".", "reduce_min", "(", "gaussian_info_gain", ")", ")", "\n", "\n", "categorical_entropy_posterior", "=", "compute_categorical_entropy_tf", "(", "\n", "categorical_posterior_score", ")", "\n", "\n", "categorical_prior_score", "=", "tf", ".", "tile", "(", "[", "[", "dirich_prior_alphas", "]", "]", ",", "[", "\n", "1", ",", "num_classes", "]", ")", "\n", "categorical_prior_score", "=", "categorical_prior_score", "/", "tf", ".", "reduce_sum", "(", "categorical_prior_score", ")", "\n", "\n", "categorical_entropy_prior", "=", "compute_categorical_entropy_tf", "(", "\n", "categorical_prior_score", ")", "\n", "\n", "categorical_info_gain", "=", "categorical_entropy_prior", "-", "categorical_entropy_posterior", "\n", "\n", "categorical_info_gain", "=", "(", "\n", "categorical_info_gain", "-", "tf", ".", "reduce_min", "(", "categorical_info_gain", ")", ")", "/", "tf", ".", "maximum", "(", "\n", "0.001", ",", "\n", "tf", ".", "reduce_max", "(", "categorical_info_gain", ")", "-", "tf", ".", "reduce_min", "(", "categorical_info_gain", ")", ")", "\n", "ranking_scores", "=", "categorical_info_gain", "+", "gaussian_info_gain", "\n", "", "else", ":", "\n", "        ", "ranking_scores", "=", "tf", ".", "reduce_max", "(", "categorical_posterior_score", ",", "axis", "=", "1", ")", "\n", "\n", "", "predicted_boxes_corners", "=", "box_utils", ".", "vuhw_to_vuvu", "(", "\n", "tf", ".", "squeeze", "(", "gaussian_posterior_means", ",", "axis", "=", "2", ")", ")", "\n", "\n", "nms_indices", ",", "_", "=", "tf", ".", "image", ".", "non_max_suppression_with_scores", "(", "\n", "predicted_boxes_corners", ",", "\n", "ranking_scores", ",", "\n", "max_output_size", "=", "nms_config", "[", "'max_output_size'", "]", ",", "\n", "iou_threshold", "=", "nms_config", "[", "'iou_threshold'", "]", ",", "\n", "soft_nms_sigma", "=", "nms_config", "[", "'soft_nms_sigma'", "]", ")", "\n", "\n", "predicted_boxes_iou_mat", "=", "box_utils", ".", "bbox_iou_vuvu", "(", "\n", "predicted_boxes_corners", ",", "predicted_boxes_corners", ")", "\n", "\n", "return", "dirichlit_posterior_count", ",", "gaussian_posterior_means", ",", "gaussian_posterior_covs", ",", "nms_indices", ",", "predicted_boxes_iou_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_mean_covariance_tf": [[220, 245], ["tensorflow.reduce_mean", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.cast", "tensorflow.shape"], "function", ["None"], ["", "def", "compute_mean_covariance_tf", "(", "output_boxes", ")", ":", "\n", "    ", "\"\"\"\n    Given the inference results from M runs of MC dropout,\n     computes the mean and covariance of every anchor\n\n    :param output_boxes: MxNx4 tensor containing inference results from M runs of MC dropout\n\n    :return: mean: Nx4 tensor containing the per anchor mean\n    :return: cov: Nx4x4 tensor containing the per anchor covariance matrix\n\n    \"\"\"", "\n", "\n", "# Compute mean", "\n", "mean", "=", "tf", ".", "reduce_mean", "(", "output_boxes", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "# Compute Covariance Matrix", "\n", "intermediate_compute", "=", "output_boxes", "-", "mean", "\n", "intermediate_compute", "=", "tf", ".", "matmul", "(", "\n", "tf", ".", "transpose", "(", "intermediate_compute", ",", "[", "1", ",", "2", ",", "0", "]", ")", ",", "\n", "tf", ".", "transpose", "(", "intermediate_compute", ",", "[", "1", ",", "0", ",", "2", "]", ")", ")", "\n", "\n", "cov", "=", "intermediate_compute", "/", "(", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "output_boxes", ")", "[", "0", "]", ",", "tf", ".", "float32", ")", "-", "1.0", ")", "\n", "\n", "return", "mean", "[", "0", "]", ",", "cov", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_gaussian_entropy_tf": [[247, 264], ["tensorflow.cast", "tensorflow.linalg.det", "tensorflow.cast", "tensorflow.math.log", "tensorflow.shape", "tensorflow.math.log"], "function", ["None"], ["", "def", "compute_gaussian_entropy_tf", "(", "cov", ")", ":", "\n", "    ", "\"\"\"\n    Computes the differential entropy of gaussian distributions parameterized\n    by their covariance matrices\n\n    :param cov: Nx4x4 tensor of covarience matrices\n    :return: entropy: Nx1 tensor of differential entropies\n    \"\"\"", "\n", "\n", "dims_constant", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "cov", ")", "[", "2", "]", "/", "2", ",", "tf", ".", "float32", ")", "\n", "\n", "determinant", "=", "tf", ".", "linalg", ".", "det", "(", "cov", ")", "\n", "\n", "entropy", "=", "dims_constant", "+", "dims_constant", "*", "tf", ".", "math", ".", "log", "(", "2.0", "*", "np", ".", "pi", ")", "+", "0.5", "*", "tf", ".", "math", ".", "log", "(", "determinant", ")", "\n", "\n", "return", "tf", ".", "cast", "(", "entropy", ",", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.compute_categorical_entropy_tf": [[266, 278], ["tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.math.log"], "function", ["None"], ["", "def", "compute_categorical_entropy_tf", "(", "cat_params", ")", ":", "\n", "    ", "\"\"\"\n    Computes the shannon entropy of categorical distributions parameterized\n    by parameters p_1..p_k\n\n    :param cat_params: NxK tensor containing the parameters p_1...p_k of the categorical distribution per anchor\n    :return: entropy: Nx1 tensor of shannon entropies\n    \"\"\"", "\n", "\n", "entropy", "=", "-", "tf", ".", "reduce_sum", "(", "cat_params", "*", "tf", ".", "math", ".", "log", "(", "cat_params", ")", ",", "axis", "=", "1", ")", "\n", "\n", "return", "tf", ".", "cast", "(", "entropy", ",", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.bayes_od_clustering": [[285, 365], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.linalg.inv", "final_box_covs.append", "numpy.array", "numpy.sum", "np.array.append", "numpy.mean", "numpy.sum", "np.array.append", "np.array.append", "numpy.array", "numpy.sum", "numpy.matmul", "numpy.expand_dims", "numpy.expand_dims", "numpy.repeat", "scipy.stats.entropy", "numpy.linalg.inv", "numpy.matmul", "numpy.sum", "numpy.argpartition", "zip", "numpy.sum"], "function", ["None"], ["def", "bayes_od_clustering", "(", "\n", "predicted_boxes_class_counts", ",", "\n", "predicted_boxes_means", ",", "\n", "predicted_boxes_covs", ",", "\n", "cluster_centers", ",", "\n", "affinity_matrix", ",", "\n", "affinity_threshold", "=", "0.7", ")", ":", "\n", "    ", "\"\"\"\n    Bayesian NMS clustering to output a single probability distribution per object in the scene.\n\n    :param predicted_boxes_means: Nx4x1 tensor containing resulting means from mc_dropout. N is the number of anchors processed by the model.\n    :param predicted_boxes_covs: Nx4x4 tensor containing resulting covariance matrices from mc_dropout.\n    :param cat_count_res: NxC tensor containing the alpha counts from mc dropout. C is the number of categories.\n    :param cluster_centers: Kx1 tensor containing the indices of centers of clusters based on minimum entropy. K is the number of clusters.\n    :param affinity_matrix: NxN matrix containing affinity measures between bounding boxes.\n    :param affinity_threshold: scalar to determine the minimum affinity for clustering.\n\n    :return: final_scores: Kx4 tensor containing the parameters of the final categorical posterior distribution describing the objects' categories.\n    :return: final_means: Kx4x1 tensor containing the mean vectors of the posterior gaussian distribution describing objects' location in the scene.\n    :return: final_covs: Kx4x4 tensor containing the covariance matrices of the posterior gaussian distribution describing objects' location in the scene.\n    \"\"\"", "\n", "\n", "# Initialize lists to save per cluster results", "\n", "final_box_means", "=", "[", "]", "\n", "final_box_covs", "=", "[", "]", "\n", "final_box_class_scores", "=", "[", "]", "\n", "final_box_class_counts", "=", "[", "]", "\n", "for", "cluster_center", "in", "cluster_centers", ":", "\n", "\n", "# Get bounding boxes with affinity > threshold with the center of the", "\n", "# cluster", "\n", "        ", "cluster_inds", "=", "affinity_matrix", "[", ":", ",", "cluster_center", "]", ">", "affinity_threshold", "\n", "cluster_means", "=", "predicted_boxes_means", "[", "cluster_inds", ",", ":", ",", ":", "]", "\n", "cluster_covs", "=", "predicted_boxes_covs", "[", "cluster_inds", ",", ":", ",", ":", "]", "\n", "\n", "# Compute mean and covariance of the final posterior distribution", "\n", "cluster_precs", "=", "np", ".", "array", "(", "\n", "[", "np", ".", "linalg", ".", "inv", "(", "member_cov", ")", "for", "member_cov", "in", "cluster_covs", "]", ")", "\n", "\n", "final_cov", "=", "np", ".", "linalg", ".", "inv", "(", "np", ".", "sum", "(", "cluster_precs", ",", "axis", "=", "0", ")", ")", "\n", "final_box_covs", ".", "append", "(", "final_cov", ")", "\n", "\n", "mean_temp", "=", "np", ".", "array", "(", "[", "np", ".", "matmul", "(", "member_prec", ",", "member_mean", ")", "for", "\n", "member_prec", ",", "member_mean", "in", "\n", "zip", "(", "cluster_precs", ",", "cluster_means", ")", "]", ")", "\n", "mean_temp", "=", "np", ".", "sum", "(", "mean_temp", ",", "axis", "=", "0", ")", "\n", "final_box_means", ".", "append", "(", "np", ".", "matmul", "(", "final_cov", ",", "mean_temp", ")", ")", "\n", "\n", "# Compute the updated parameters of the categorical distribution", "\n", "final_counts", "=", "predicted_boxes_class_counts", "[", "cluster_inds", ",", ":", "]", "\n", "final_score", "=", "(", "final_counts", ")", "/", "np", ".", "expand_dims", "(", "np", ".", "sum", "(", "final_counts", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "\n", "if", "final_score", ".", "shape", "[", "0", "]", ">", "3", ":", "\n", "            ", "cluster_center_score", "=", "np", ".", "expand_dims", "(", "predicted_boxes_class_counts", "[", "cluster_center", ",", ":", "]", "/", "np", ".", "sum", "(", "\n", "predicted_boxes_class_counts", "[", "cluster_center", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "cluster_center_score", "=", "np", ".", "repeat", "(", "\n", "cluster_center_score", ",", "final_score", ".", "shape", "[", "0", "]", ",", "axis", "=", "0", ")", "\n", "\n", "cat_ent", "=", "entropy", "(", "cluster_center_score", ".", "T", ",", "final_score", ".", "T", ")", "\n", "\n", "inds", "=", "np", ".", "argpartition", "(", "cat_ent", ",", "3", ")", "[", ":", "3", "]", "\n", "\n", "final_score", "=", "final_score", "[", "inds", "]", "\n", "final_counts", "=", "final_counts", "[", "inds", "]", "\n", "\n", "", "final_score", "=", "np", ".", "mean", "(", "final_score", ",", "axis", "=", "0", ")", "\n", "final_counts", "=", "np", ".", "sum", "(", "final_counts", ",", "axis", "=", "0", ")", "\n", "final_box_class_scores", ".", "append", "(", "final_score", ")", "\n", "final_box_class_counts", ".", "append", "(", "final_counts", ")", "\n", "\n", "", "final_box_means", "=", "np", ".", "array", "(", "final_box_means", ")", "\n", "final_box_class_scores", "=", "np", ".", "array", "(", "final_box_class_scores", ")", "\n", "\n", "# 70 is a calibration parameter specific to BDD and KITTI datasets. It", "\n", "# gives the best PDQ. It does not affect AP or MUE.", "\n", "final_box_covs", "=", "np", ".", "array", "(", "final_box_covs", ")", "*", "70", "\n", "final_box_class_counts", "=", "np", ".", "array", "(", "final_box_class_counts", ")", "\n", "\n", "return", "final_box_class_scores", ",", "final_box_means", ",", "final_box_covs", ",", "final_box_class_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.inference_utils.map_dataset_classes": [[372, 405], ["numpy.zeros", "numpy.argmax", "list", "list", "numpy.take", "numpy.take", "numpy.amax", "zip", "len", "numpy.expand_dims", "input_class_to_idx_mapping_dict.keys", "input_class_to_idx_mapping_dict.values", "len"], "function", ["None"], ["def", "map_dataset_classes", "(", "input_dataset", ",", "target_dataset", ",", "output_classes", ")", ":", "\n", "    ", "set_to_set_mapping_dict", "=", "constants", ".", "SET_TO_SET_MAPPING_DICTS", "[", "\n", "input_dataset", "+", "'_'", "+", "target_dataset", "]", "\n", "if", "set_to_set_mapping_dict", ":", "\n", "        ", "input_class_to_idx_mapping_dict", "=", "constants", ".", "CATEGORY_IDX_MAPPING_DICTS", "[", "input_dataset", "]", "\n", "target_class_to_idx_mapping_dict", "=", "constants", ".", "CATEGORY_IDX_MAPPING_DICTS", "[", "target_dataset", "]", "\n", "\n", "output_classes_mapped", "=", "np", ".", "zeros", "(", "\n", "[", "output_classes", ".", "shape", "[", "0", "]", ",", "len", "(", "target_class_to_idx_mapping_dict", ")", "+", "1", "]", ")", "\n", "if", "len", "(", "output_classes", ".", "shape", ")", "==", "1", ":", "\n", "            ", "output_classes", "=", "np", ".", "expand_dims", "(", "output_classes", ",", "axis", "=", "1", ")", "\n", "", "max_idxs", "=", "np", ".", "argmax", "(", "output_classes", ",", "axis", "=", "1", ")", "\n", "\n", "mapping_categories", "=", "list", "(", "input_class_to_idx_mapping_dict", ".", "keys", "(", ")", ")", "\n", "mapping_idxs", "=", "list", "(", "input_class_to_idx_mapping_dict", ".", "values", "(", ")", ")", "\n", "\n", "mapping_idxs", "=", "np", ".", "take", "(", "mapping_idxs", ",", "max_idxs", ")", "\n", "mapping_categories", "=", "np", ".", "take", "(", "mapping_categories", ",", "mapping_idxs", ")", "\n", "\n", "mapped_categories", "=", "[", "set_to_set_mapping_dict", "[", "mapping_category", "]", "\n", "for", "mapping_category", "in", "mapping_categories", "]", "\n", "mapped_idxs", "=", "[", "target_class_to_idx_mapping_dict", "[", "mapped_category", "]", "\n", "for", "mapped_category", "in", "mapped_categories", "]", "\n", "\n", "max_scores", "=", "np", ".", "amax", "(", "output_classes", ",", "axis", "=", "1", ")", "\n", "\n", "for", "score", ",", "mapped_idx", ",", "mapped_row", "in", "zip", "(", "\n", "max_scores", ",", "mapped_idxs", ",", "output_classes_mapped", ")", ":", "\n", "            ", "mapped_row", "[", "mapped_idx", "]", "=", "score", "\n", "\n", "", "return", "output_classes_mapped", "\n", "", "else", ":", "\n", "        ", "return", "output_classes", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.post_process_predictions": [[10, 78], ["src.retina_net.anchor_generator.box_utils.box_from_anchor_and_target", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu", "tensorflow.nn.softmax", "tensorflow.cast", "tensorflow.not_equal", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.reduce_max", "tensorflow.image.non_max_suppression_with_scores", "tensorflow.gather", "tensorflow.gather", "tensorflow.argmax", "src.retina_net.anchor_generator.box_utils.normalize_2d_bounding_boxes", "src.retina_net.anchor_generator.box_utils.expand_2d_bounding_boxes", "tensorflow.shape", "tensorflow.shape", "src.retina_net.anchor_generator.box_utils.normalize_2d_bounding_boxes", "src.retina_net.anchor_generator.box_utils.expand_2d_bounding_boxes", "tensorflow.cast", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.normalize_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.expand_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.normalize_2d_bounding_boxes", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.expand_2d_bounding_boxes"], ["@", "tf", ".", "function", "\n", "def", "post_process_predictions", "(", "sample_dict", ",", "prediction_dict", ",", "dataset_name", "=", "'bdd'", ")", ":", "\n", "    ", "\"\"\"\n    Prepares predictions to be written into file. Also applies non-maximum suppression.\n    :param sample_dict: input dictionary generated from dataset.\n    If element sizes in this dictionary are variable, remove tf.function decorator.\n\n    :param prediction_dict: Dictionary containing neural network predictions\n    :param dataset_name: Name of dataset, to be used to apply dataset specific post processing.\n    :return:\n    \"\"\"", "\n", "\n", "anchors", "=", "sample_dict", "[", "constants", ".", "ANCHORS_KEY", "]", "[", "0", "]", "\n", "predicted_box_targets", "=", "prediction_dict", "[", "constants", ".", "ANCHORS_BOX_PREDICTIONS_KEY", "]", "[", "0", "]", "\n", "\n", "predicted_boxes", "=", "box_utils", ".", "box_from_anchor_and_target", "(", "\n", "anchors", ",", "predicted_box_targets", ")", "\n", "\n", "predicted_boxes_corners", "=", "box_utils", ".", "vuhw_to_vuvu", "(", "predicted_boxes", ")", "\n", "predicted_boxes_classes", "=", "tf", ".", "nn", ".", "softmax", "(", "\n", "prediction_dict", "[", "constants", ".", "ANCHORS_CLASS_PREDICTIONS_KEY", "]", "[", "0", "]", ",", "axis", "=", "1", ")", "\n", "\n", "num_classes", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "predicted_boxes_classes", ")", "[", "1", "]", ",", "tf", ".", "int64", ")", "\n", "\n", "category_filter", "=", "tf", ".", "not_equal", "(", "\n", "tf", ".", "argmax", "(", "\n", "predicted_boxes_classes", ",", "\n", "axis", "=", "1", ")", ",", "\n", "num_classes", "-", "1", ")", "\n", "\n", "predicted_boxes_corners", "=", "tf", ".", "boolean_mask", "(", "predicted_boxes_corners", ",", "\n", "category_filter", ")", "\n", "predicted_boxes_classes", "=", "tf", ".", "boolean_mask", "(", "predicted_boxes_classes", ",", "\n", "category_filter", ")", "\n", "\n", "top_scores", "=", "tf", ".", "reduce_max", "(", "predicted_boxes_classes", ",", "axis", "=", "1", ")", "\n", "\n", "nms_indices", ",", "_", "=", "tf", ".", "image", ".", "non_max_suppression_with_scores", "(", "\n", "predicted_boxes_corners", ",", "\n", "top_scores", ",", "\n", "max_output_size", "=", "100", ",", "\n", "iou_threshold", "=", "0.5", ",", "\n", "soft_nms_sigma", "=", "0.5", ")", "\n", "\n", "if", "dataset_name", "==", "'kitti'", ":", "\n", "        ", "predicted_boxes_corners_normalized", "=", "box_utils", ".", "normalize_2d_bounding_boxes", "(", "\n", "predicted_boxes_corners", ",", "\n", "tf", ".", "shape", "(", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", "[", "0", "]", ")", ")", "\n", "predicted_boxes_corners_scaled", "=", "box_utils", ".", "expand_2d_bounding_boxes", "(", "\n", "predicted_boxes_corners_normalized", ",", "sample_dict", "[", "constants", ".", "ORIGINAL_IM_SIZE_KEY", "]", "[", "0", "]", ")", "\n", "", "elif", "dataset_name", "==", "'coco'", ":", "\n", "        ", "predicted_boxes_corners_shifted", "=", "predicted_boxes_corners", "-", "sample_dict", "[", "constants", ".", "IMAGE_PADDING_KEY", "]", "[", "0", "]", "\n", "predicted_boxes_corners_normalized", "=", "box_utils", ".", "normalize_2d_bounding_boxes", "(", "predicted_boxes_corners_shifted", ",", "tf", ".", "shape", "(", "\n", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", "[", "0", "]", ")", "[", "0", ":", "2", "]", "-", "tf", ".", "cast", "(", "2", "*", "sample_dict", "[", "constants", ".", "IMAGE_PADDING_KEY", "]", "[", "0", ",", "0", ":", "2", "]", ",", "tf", ".", "int32", ")", ")", "\n", "predicted_boxes_corners_scaled", "=", "box_utils", ".", "expand_2d_bounding_boxes", "(", "\n", "predicted_boxes_corners_normalized", ",", "sample_dict", "[", "constants", ".", "ORIGINAL_IM_SIZE_KEY", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "predicted_boxes_corners_scaled", "=", "predicted_boxes_corners", "\n", "\n", "", "predicted_boxes_classes_out", "=", "tf", ".", "gather", "(", "predicted_boxes_classes", ",", "\n", "nms_indices", ",", "\n", "axis", "=", "0", ")", "\n", "predicted_boxes_corners_out", "=", "tf", ".", "gather", "(", "predicted_boxes_corners_scaled", ",", "\n", "nms_indices", ",", "\n", "axis", "=", "0", ")", "\n", "\n", "return", "predicted_boxes_classes_out", ",", "predicted_boxes_corners_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.get_evaluated_ckpts": [[80, 94], ["os.path.exists", "numpy.loadtxt", "numpy.isscalar", "numpy.asarray", "numpy.asarray"], "function", ["None"], ["", "def", "get_evaluated_ckpts", "(", "prediction_dir", ")", ":", "\n", "    ", "already_evaluated_ckpts", "=", "[", "]", "\n", "file_path", "=", "prediction_dir", "+", "'/evaluated_ckpts.txt'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "file_path", ")", ":", "\n", "        ", "evaluated_ckpts", "=", "np", ".", "loadtxt", "(", "file_path", ",", "dtype", "=", "np", ".", "int", ")", "\n", "if", "np", ".", "isscalar", "(", "evaluated_ckpts", ")", ":", "\n", "# one entry", "\n", "            ", "already_evaluated_ckpts", "=", "np", ".", "asarray", "(", "\n", "[", "evaluated_ckpts", "]", ",", "np", ".", "int32", ")", "\n", "", "else", ":", "\n", "            ", "already_evaluated_ckpts", "=", "np", ".", "asarray", "(", "evaluated_ckpts", ",", "\n", "np", ".", "int32", ")", "\n", "", "", "return", "already_evaluated_ckpts", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.strip_checkpoint_id": [[96, 108], ["int", "checkpoint_dir.split"], "function", ["None"], ["", "def", "strip_checkpoint_id", "(", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Helper function to return the checkpoint index number.\n\n    Args:\n        checkpoint_dir: Path directory of the checkpoints\n\n    Returns:\n        checkpoint_id: An int representing the checkpoint index\n    \"\"\"", "\n", "\n", "checkpoint_name", "=", "checkpoint_dir", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "return", "int", "(", "checkpoint_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.write_evaluated_ckpts": [[110, 115], ["os.path.join", "open", "numpy.savetxt"], "function", ["None"], ["", "def", "write_evaluated_ckpts", "(", "predictions_dir", ",", "ckpt_name", ")", ":", "\n", "    ", "file_path", "=", "os", ".", "path", ".", "join", "(", "predictions_dir", ",", "'evaluated_ckpts.txt'", ")", "\n", "with", "open", "(", "file_path", ",", "'ba'", ")", "as", "fp", ":", "\n", "        ", "np", ".", "savetxt", "(", "fp", ",", "ckpt_name", ",", "fmt", "=", "'%d'", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_rvc_format": [[117, 148], ["zip", "dict", "numpy.argmax", "dict.update", "bdd_boxes_list.append", "box_class[].tolist", "float", "float", "float", "float"], "function", ["None"], ["", "def", "predictions_to_rvc_format", "(", "\n", "output_boxes", ",", "\n", "output_classes", ",", "\n", "image_id", ",", "\n", "training_data_categories", ")", ":", "\n", "    ", "\"\"\"\n    Writes detections in coco format\n\n    :param output_boxes: output bounding boxes\n    :param output_classes: output class scores\n\n    :return: Array of predictions ready to be written to file.\n    \"\"\"", "\n", "bdd_boxes_list", "=", "[", "]", "\n", "for", "box_2d", ",", "box_class", ",", "in", "zip", "(", "output_boxes", ",", "output_classes", ")", ":", "\n", "\n", "        ", "bdd_box_dict", "=", "dict", "(", ")", "\n", "\n", "max_ind", "=", "np", ".", "argmax", "(", "box_class", ")", "\n", "\n", "if", "max_ind", "<", "(", "output_classes", ".", "shape", "[", "1", "]", "-", "1", ")", ":", "\n", "            ", "bdd_box_dict", ".", "update", "(", "{", "\"image_id\"", ":", "image_id", ",", "\n", "\"category_id\"", ":", "training_data_categories", "[", "max_ind", "]", ",", "\n", "\"bbox\"", ":", "[", "float", "(", "box_2d", "[", "0", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "1", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "2", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "3", "]", ")", "]", ",", "\n", "\"score\"", ":", "box_class", "[", "max_ind", "]", ".", "tolist", "(", ")", "}", ")", "\n", "bdd_boxes_list", ".", "append", "(", "bdd_box_dict", ")", "\n", "\n", "", "", "return", "bdd_boxes_list", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_coco_format": [[150, 181], ["zip", "dict", "numpy.argmax", "dict.update", "bdd_boxes_list.append", "box_class[].tolist", "float", "float", "float", "float"], "function", ["None"], ["", "def", "predictions_to_coco_format", "(", "\n", "output_boxes", ",", "\n", "output_classes", ",", "\n", "image_id", ",", "\n", "training_data_to_coco_category_ids", ")", ":", "\n", "    ", "\"\"\"\n    Writes detections in coco format\n\n    :param output_boxes: output bounding boxes\n    :param output_classes: output class scores\n\n    :return: Array of predictions ready to be written to file.\n    \"\"\"", "\n", "bdd_boxes_list", "=", "[", "]", "\n", "for", "box_2d", ",", "box_class", ",", "in", "zip", "(", "output_boxes", ",", "output_classes", ")", ":", "\n", "\n", "        ", "bdd_box_dict", "=", "dict", "(", ")", "\n", "\n", "max_ind", "=", "np", ".", "argmax", "(", "box_class", ")", "\n", "\n", "if", "max_ind", "<", "(", "output_classes", ".", "shape", "[", "1", "]", "-", "1", ")", ":", "\n", "            ", "bdd_box_dict", ".", "update", "(", "{", "\"image_id\"", ":", "image_id", ",", "\n", "\"category_id\"", ":", "training_data_to_coco_category_ids", "[", "max_ind", "]", ",", "\n", "\"bbox\"", ":", "[", "float", "(", "box_2d", "[", "1", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "0", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "3", "]", "-", "box_2d", "[", "1", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "2", "]", "-", "box_2d", "[", "0", "]", ")", "]", ",", "\n", "\"score\"", ":", "box_class", "[", "max_ind", "]", ".", "tolist", "(", ")", "}", ")", "\n", "bdd_boxes_list", ".", "append", "(", "bdd_box_dict", ")", "\n", "\n", "", "", "return", "bdd_boxes_list", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_bdd_format": [[183, 215], ["zip", "dict", "numpy.argmax", "len", "dict.update", "bdd_boxes_list.append", "box_class[].tolist", "float", "float", "float", "float"], "function", ["None"], ["", "def", "predictions_to_bdd_format", "(", "\n", "output_boxes", ",", "\n", "output_classes", ",", "\n", "frame_name", ",", "\n", "category_list", ")", ":", "\n", "    ", "\"\"\"\n    Writes detections in BDD format\n\n    :param output_boxes: output bounding boxes\n    :param output_classes: output classes\n\n    :return: Array of predictions ready to be written to file.\n    \"\"\"", "\n", "bdd_boxes_list", "=", "[", "]", "\n", "for", "box_2d", ",", "box_class", ",", "in", "zip", "(", "output_boxes", ",", "output_classes", ")", ":", "\n", "\n", "        ", "bdd_box_dict", "=", "dict", "(", ")", "\n", "\n", "max_ind", "=", "np", ".", "argmax", "(", "box_class", ")", "\n", "\n", "if", "max_ind", "<", "len", "(", "category_list", ")", ":", "\n", "            ", "bdd_box_dict", ".", "update", "(", "{", "\"name\"", ":", "frame_name", ",", "\n", "\"timestep\"", ":", "1000", ",", "\n", "\"category\"", ":", "category_list", "[", "max_ind", "]", ",", "\n", "\"bbox\"", ":", "[", "float", "(", "box_2d", "[", "1", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "0", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "3", "]", ")", ",", "\n", "float", "(", "box_2d", "[", "2", "]", ")", "]", ",", "\n", "\"score\"", ":", "box_class", "[", "max_ind", "]", ".", "tolist", "(", ")", "}", ")", "\n", "bdd_boxes_list", ".", "append", "(", "bdd_box_dict", ")", "\n", "\n", "", "", "return", "bdd_boxes_list", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_kitti_format": [[217, 273], ["zip", "numpy.asarray", "numpy.copy", "numpy.argmax", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.append", "kitti_boxes_array.append", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.extend", "kitti_box_array.append", "kitti_boxes_array.append"], "function", ["None"], ["", "def", "predictions_to_kitti_format", "(", "output_boxes", ",", "output_classes", ")", ":", "\n", "    ", "\"\"\"\n    Writes detections in KITTI format\n\n    :param output_boxes: output bounding boxes\n    :param output_classes: output classes\n\n    :return: Array of predictions ready to be written to file.\n    \"\"\"", "\n", "kitti_boxes_array", "=", "[", "]", "\n", "\n", "for", "box_2d", ",", "box_class", ",", "in", "zip", "(", "output_boxes", ",", "output_classes", ")", ":", "\n", "\n", "        ", "kitti_box_array", "=", "[", "]", "\n", "box_2d", "=", "np", ".", "copy", "(", "box_2d", "[", ":", ":", "-", "1", "]", ")", "\n", "\n", "max_ind", "=", "np", ".", "argmax", "(", "box_class", ")", "\n", "\n", "if", "max_ind", "==", "0", ":", "\n", "            ", "kitti_box_array", ".", "extend", "(", "[", "'Car'", ",", "-", "1", ",", "-", "1", ",", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "box_2d", "[", "2", ":", "4", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "box_2d", "[", "0", ":", "2", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "[", "-", "10", ",", "-", "10", ",", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "[", "-", "10", ",", "-", "10", ",", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "[", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "append", "(", "box_class", "[", "max_ind", "]", ")", "\n", "kitti_boxes_array", ".", "append", "(", "kitti_box_array", ")", "\n", "", "elif", "max_ind", "==", "1", ":", "\n", "            ", "kitti_box_array", ".", "extend", "(", "[", "'Pedestrian'", ",", "-", "1", ",", "-", "1", ",", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "box_2d", "[", "2", ":", "4", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "box_2d", "[", "0", ":", "2", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "[", "-", "10", ",", "-", "10", ",", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "[", "-", "10", ",", "-", "10", ",", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "extend", "(", "[", "-", "10", "]", ")", "\n", "kitti_box_array", ".", "append", "(", "box_class", "[", "max_ind", "]", ")", "\n", "kitti_boxes_array", ".", "append", "(", "kitti_box_array", ")", "\n", "# elif max_ind == 2:", "\n", "#    kitti_box_array.extend(['Cyclist', -1, -1, -10])", "\n", "#    kitti_box_array.extend(box_2d[2:4])", "\n", "#    kitti_box_array.extend(box_2d[0:2])", "\n", "#    kitti_box_array.extend([-10, -10, -10])", "\n", "#    kitti_box_array.extend([-10, -10, -10])", "\n", "#    kitti_box_array.extend([-10])", "\n", "#    kitti_box_array.append(box_class[max_ind])", "\n", "#    kitti_boxes_array.append(kitti_box_array)", "\n", "# else:", "\n", "#    kitti_box_array.extend(['DontCare', -1, -1, -10])", "\n", "#    kitti_box_array.extend(box_2d[2:4])", "\n", "#    kitti_box_array.extend(box_2d[0:2])", "\n", "#    kitti_box_array.extend([-10, -10, -10])", "\n", "#    kitti_box_array.extend([-10, -10, -10])", "\n", "#    kitti_box_array.extend([-10])", "\n", "#    kitti_box_array.append(box_class[max_ind])", "\n", "#    kitti_boxes_array.append(kitti_box_array)", "\n", "\n", "", "", "return", "np", ".", "asarray", "(", "kitti_boxes_array", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_validation.validate_model": [[23, 229], ["src.retina_net.builders.dataset_handler_builder.build_dataset", "keras.backend.set_learning_phase", "print", "os.path.join", "os.path.join", "os.makedirs", "src.get_evaluated_ckpts", "int", "dataset_handler_builder.build_dataset.create_dataset", "dataset_handler.create_dataset.repeat().batch", "batched_dataset.prefetch.prefetch", "tensorflow.summary.create_file_writer", "print", "tensorflow.train.Checkpoint", "tensorflow.name_scope", "src.retina_net.models.retinanet_model.RetinaNetModel", "src.data_dir", "src.data_dir", "os.path.exists", "ValueError", "str", "len", "print", "time.time", "str", "dataset_handler.create_dataset.repeat", "datetime.datetime.now", "time.strftime", "tensorflow.Variable", "tensorflow.train.get_checkpoint_state", "print", "range", "time.time", "time.sleep", "keras.backend.learning_phase", "time.gmtime", "src.strip_checkpoint_id", "os.path.join", "os.makedirs", "print", "tf.train.Checkpoint.restore", "max", "str", "tf.summary.create_file_writer.as_default", "enumerate", "src.write_evaluated_ckpts", "os.path.join", "run_validation.val_single_step", "src.post_process_predictions", "output_boxes.numpy.numpy", "output_classes.numpy.numpy", "tensorflow.summary.scalar", "tf.summary.create_file_writer.flush", "sys.stdout.write", "numpy.array", "str", "os.path.join", "os.makedirs", "os.path.join", "src.predictions_to_kitti_format", "os.path.join", "tensorflow.name_scope", "loss_dict.keys", "open", "json.dump", "numpy.savetxt", "numpy.savetxt", "src.predictions_to_bdd_format", "final_results_list.extend", "tensorflow.summary.scalar", "int", "str", "src.predictions_to_coco_format", "final_results_list.extend", "int", "src.predictions_to_rvc_format", "final_results_list.extend", "int"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.builders.dataset_handler_builder.build_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.get_evaluated_ckpts", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.create_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.strip_checkpoint_id", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.write_evaluated_ckpts", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_validation.val_single_step", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.post_process_predictions", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_kitti_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_bdd_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_coco_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.validation_utils.predictions_to_rvc_format"], ["def", "validate_model", "(", "config", ")", ":", "\n", "# Get validation config", "\n", "    ", "val_config", "=", "config", "[", "'validation_config'", "]", "\n", "eval_wait_interval", "=", "val_config", "[", "'eval_wait_interval'", "]", "\n", "\n", "# Create dataset class", "\n", "dataset_config", "=", "config", "[", "'dataset_config'", "]", "\n", "dataset_handler", "=", "dataset_handler_builder", ".", "build_dataset", "(", "\n", "dataset_config", ",", "'val'", ")", "\n", "\n", "# Set keras training phase", "\n", "keras", ".", "backend", ".", "set_learning_phase", "(", "0", ")", "\n", "print", "(", "\"Keras Learning Phase Set to: \"", "+", "\n", "str", "(", "keras", ".", "backend", ".", "learning_phase", "(", ")", ")", ")", "\n", "\n", "# Create Model", "\n", "with", "tf", ".", "name_scope", "(", "\"retinanet_model\"", ")", ":", "\n", "        ", "model", "=", "RetinaNetModel", "(", "config", "[", "'model_config'", "]", ")", "\n", "\n", "# Initialize the model from a saved checkpoint", "\n", "", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "'outputs'", ",", "\n", "config", "[", "'checkpoint_name'", "]", ",", "'checkpoints'", ",", "config", "[", "'checkpoint_name'", "]", ")", "\n", "predictions_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "'outputs'", ",", "\n", "config", "[", "'checkpoint_name'", "]", ",", "'predictions'", ")", "\n", "os", ".", "makedirs", "(", "predictions_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'{} must have at least one checkpoint entry.'", "\n", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "\n", "", "already_evaluated_ckpts", "=", "val_utils", ".", "get_evaluated_ckpts", "(", "predictions_dir", ")", "\n", "\n", "# Instantiate mini-batch and epoch size", "\n", "epoch_size", "=", "int", "(", "dataset_handler", ".", "epoch_size", ")", "\n", "\n", "# Create Dataset", "\n", "# Main function to create dataset", "\n", "dataset", "=", "dataset_handler", ".", "create_dataset", "(", ")", "\n", "\n", "# Batch size goes in parenthesis.", "\n", "batched_dataset", "=", "dataset", ".", "repeat", "(", "1", ")", ".", "batch", "(", "1", ")", "\n", "\n", "# `prefetch` lets the dataset fetch batches, in the background while the model is validating.", "\n", "batched_dataset", "=", "batched_dataset", ".", "prefetch", "(", "\n", "buffer_size", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "log_file", "=", "config", "[", "'logs_dir'", "]", "+", "'/validation/'", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "log_file", ")", "\n", "\n", "print", "(", "'Starting evaluation at '", "+", "\n", "time", ".", "strftime", "(", "'%Y-%m-%d-%H:%M:%S'", ",", "time", ".", "gmtime", "(", ")", ")", ")", "\n", "\n", "# Repeated checkpoint run", "\n", "last_checkpoint_id", "=", "-", "1", "\n", "number_of_evaluations", "=", "0", "\n", "\n", "# Initialize the model checkpoint manager", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "step", "=", "tf", ".", "Variable", "(", "0", ")", ",", "net", "=", "model", ")", "\n", "\n", "# Begin validation loop", "\n", "while", "True", ":", "\n", "        ", "all_checkpoint_states", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "\n", "checkpoint_dir", ")", ".", "all_model_checkpoint_paths", "\n", "num_checkpoints", "=", "len", "(", "all_checkpoint_states", ")", "\n", "print", "(", "\"Total Checkpoints: \"", ",", "num_checkpoints", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "if", "number_of_evaluations", ">=", "num_checkpoints", ":", "\n", "            ", "print", "(", "'\\nNo new checkpoints found in %s. '", "\n", "'Will try again in %d seconds.'", "\n", "%", "(", "checkpoint_dir", ",", "eval_wait_interval", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "ckpt_idx", "in", "range", "(", "num_checkpoints", ")", ":", "\n", "                ", "checkpoint_to_restore", "=", "all_checkpoint_states", "[", "ckpt_idx", "]", "\n", "ckpt_id", "=", "val_utils", ".", "strip_checkpoint_id", "(", "checkpoint_to_restore", ")", "\n", "\n", "# Check if checkpoint has been evaluated already", "\n", "already_evaluated", "=", "ckpt_id", "in", "already_evaluated_ckpts", "\n", "if", "already_evaluated", "or", "ckpt_id", "<=", "last_checkpoint_id", "or", "ckpt_id", "==", "1", ":", "\n", "                    ", "number_of_evaluations", "=", "max", "(", "(", "ckpt_idx", "+", "1", ",", "\n", "number_of_evaluations", ")", ")", "\n", "continue", "\n", "\n", "# run_checkpoint_once", "\n", "", "predictions_dir_ckpt", "=", "os", ".", "path", ".", "join", "(", "predictions_dir", ",", "\n", "'validation'", ",", "\n", "str", "(", "ckpt_id", ")", ",", "\n", "'data'", ")", "\n", "\n", "os", ".", "makedirs", "(", "predictions_dir_ckpt", ",", "exist_ok", "=", "True", ")", "\n", "print", "(", "'\\nRunning checkpoint '", "+", "str", "(", "ckpt_id", ")", "+", "'\\n'", ")", "\n", "\n", "ckpt", ".", "restore", "(", "checkpoint_to_restore", ")", "\n", "\n", "# Perform dataset-specific setup of result output", "\n", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "                    ", "pass", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'bdd'", "or", "dataset_config", "[", "'dataset'", "]", "==", "'coco'", ":", "\n", "                    ", "final_results_list", "=", "[", "]", "\n", "# Single json file for bdd or coco dataset", "\n", "prediction_json_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "'predictions.json'", ")", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'rvc'", ":", "\n", "                    ", "final_results_list", "=", "[", "]", "\n", "# Single json file for bdd dataset", "\n", "predictions_dir_ckpt", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "dataset_config", "[", "'rvc'", "]", "[", "'paths_config'", "]", "[", "'sequence_dir'", "]", ")", "\n", "os", ".", "makedirs", "(", "predictions_dir_ckpt", ",", "exist_ok", "=", "True", ")", "\n", "prediction_json_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "\n", "'predictions.json'", ")", "\n", "\n", "", "with", "summary_writer", ".", "as_default", "(", ")", ":", "\n", "                    ", "for", "counter", ",", "sample_dict", "in", "enumerate", "(", "batched_dataset", ")", ":", "\n", "\n", "                        ", "total_loss", ",", "loss_dict", ",", "prediction_dict", "=", "val_single_step", "(", "\n", "model", ",", "sample_dict", ")", "\n", "\n", "output_classes", ",", "output_boxes", "=", "val_utils", ".", "post_process_predictions", "(", "\n", "sample_dict", ",", "prediction_dict", ",", "dataset_name", "=", "dataset_config", "[", "'dataset'", "]", ")", "\n", "\n", "output_boxes", "=", "output_boxes", ".", "numpy", "(", ")", "\n", "output_classes", "=", "output_classes", ".", "numpy", "(", ")", "\n", "\n", "# Perform dataset-specific saving of outputs", "\n", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "                            ", "predictions_kitti_format", "=", "val_utils", ".", "predictions_to_kitti_format", "(", "\n", "output_boxes", ",", "output_classes", ")", "\n", "\n", "prediction_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "predictions_dir_ckpt", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "+", "'.txt'", ")", "\n", "\n", "if", "predictions_kitti_format", ".", "size", "==", "0", ":", "\n", "                                ", "np", ".", "savetxt", "(", "prediction_file_name", ",", "[", "]", ")", "\n", "", "else", ":", "\n", "                                ", "np", ".", "savetxt", "(", "\n", "prediction_file_name", ",", "\n", "predictions_kitti_format", ",", "\n", "newline", "=", "'\\r\\n'", ",", "\n", "fmt", "=", "'%s'", ")", "\n", "", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'bdd'", ":", "\n", "                            ", "predictions_bdd_format", "=", "val_utils", ".", "predictions_to_bdd_format", "(", "\n", "output_boxes", ",", "\n", "output_classes", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", ",", "\n", "category_list", "=", "dataset_handler", ".", "training_data_config", "[", "'categories'", "]", ")", "\n", "final_results_list", ".", "extend", "(", "predictions_bdd_format", ")", "\n", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'coco'", ":", "\n", "                            ", "predictions_coco_format", "=", "val_utils", ".", "predictions_to_coco_format", "(", "\n", "output_boxes", ",", "\n", "output_classes", ",", "\n", "int", "(", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "[", ":", "-", "4", "]", ")", ",", "\n", "dataset_handler", ".", "training_data_to_coco_category_ids", ")", "\n", "final_results_list", ".", "extend", "(", "predictions_coco_format", ")", "\n", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'rvc'", ":", "\n", "                            ", "predictions_rvc_format", "=", "val_utils", ".", "predictions_to_rvc_format", "(", "\n", "output_boxes", ",", "\n", "output_classes", ",", "\n", "dataset_handler", ".", "sample_ids", "[", "counter", "]", "[", ":", "-", "4", "]", ",", "\n", "dataset_handler", ".", "training_data_categories", ")", "\n", "final_results_list", ".", "extend", "(", "predictions_rvc_format", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'losses'", ")", ":", "\n", "                            ", "for", "loss_name", "in", "loss_dict", ".", "keys", "(", ")", ":", "\n", "                                ", "tf", ".", "summary", ".", "scalar", "(", "loss_name", ",", "\n", "loss_dict", "[", "loss_name", "]", ",", "\n", "step", "=", "int", "(", "ckpt", ".", "step", ")", ")", "\n", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\n", "'Total Loss'", ",", "\n", "total_loss", ",", "\n", "step", "=", "int", "(", "\n", "ckpt", ".", "step", ")", ")", "\n", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "\n", "'\\r{}'", ".", "format", "(", "\n", "counter", "+", "\n", "1", ")", "+", "\n", "' /'", "+", "\n", "str", "(", "epoch_size", ")", ")", "\n", "\n", "# Final dataset-specific wrap up work for checkpoint", "\n", "# results", "\n", "", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "                        ", "pass", "\n", "", "else", ":", "\n", "                        ", "with", "open", "(", "prediction_json_file_name", ",", "'w'", ")", "as", "fp", ":", "\n", "                            ", "json", ".", "dump", "(", "final_results_list", ",", "fp", ",", "indent", "=", "4", ",", "\n", "separators", "=", "(", "','", ",", "': '", ")", ")", "\n", "\n", "", "", "number_of_evaluations", "+=", "1", "\n", "val_utils", ".", "write_evaluated_ckpts", "(", "\n", "predictions_dir", ",", "np", ".", "array", "(", "[", "ckpt_id", "]", ")", ")", "\n", "# Save the id of the latest evaluated checkpoint", "\n", "last_checkpoint_id", "=", "ckpt_id", "\n", "\n", "", "", "", "time_to_next_eval", "=", "start", "+", "eval_wait_interval", "-", "time", ".", "time", "(", ")", "\n", "if", "time_to_next_eval", ">", "0", ":", "\n", "            ", "time", ".", "sleep", "(", "time_to_next_eval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_validation.val_single_step": [[231, 261], ["model", "model.get_loss", "tensorflow.reduce_sum", "loss_dict.update", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.retinanet_model.RetinaNetModel.get_loss"], ["", "", "", "@", "tf", ".", "function", "\n", "def", "val_single_step", "(", "\n", "model", ",", "\n", "sample_dict", ")", ":", "\n", "    ", "\"\"\"\n    :param model: keras retinanet model\n    :param sample_dict: input dictionary generated from dataset.\n    If element sizes in this dictionary are variable, remove tf.function decorator.\n\n    :return total_loss: Sum of all losses.\n    :return cls_loss: classification loss.\n    :return reg_loss: regression loss.\n    :return regularization_loss: regularization_loss\n    :return prediction_dict: Dictionary containing neural network predictions\n    \"\"\"", "\n", "\n", "prediction_dict", "=", "model", "(", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", ",", "\n", "train_val_test", "=", "'validation'", ")", "\n", "\n", "total_loss", ",", "loss_dict", "=", "model", ".", "get_loss", "(", "sample_dict", ",", "prediction_dict", ")", "\n", "\n", "# Get any regularization loss in the model and add it to total loss", "\n", "regularization_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "concat", "(", "[", "layer", ".", "losses", "for", "layer", "in", "model", ".", "layers", "]", ",", "axis", "=", "0", ")", ")", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "REGULARIZATION_LOSS_KEY", ":", "regularization_loss", "}", ")", "\n", "\n", "total_loss", "+=", "regularization_loss", "\n", "\n", "return", "total_loss", ",", "loss_dict", ",", "prediction_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_validation.main": [[263, 310], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "tensorflow.config.experimental.list_physical_devices", "tensorflow.config.experimental.set_memory_growth", "src.retina_net.config_utils.setup", "run_validation.validate_model", "src.model_dir", "open", "yaml.load"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils.setup", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_validation.validate_model", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.model_dir"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Object Detection Model Validator\n    \"\"\"", "\n", "\n", "# Defaults", "\n", "default_gpu_device", "=", "'0'", "\n", "default_config_path", "=", "core", ".", "model_dir", "(", "\n", "'retina_net'", ")", "+", "'/configs/retinanet_bdd.yaml'", "\n", "# Allowed data splits are 'train','train_mini', 'val', 'val_half',", "\n", "# 'val_mini'", "\n", "default_data_split", "=", "'val'", "\n", "\n", "# Parse input", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "# Define argparser object", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'gpu_device'", ",", "\n", "default", "=", "default_gpu_device", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--yaml_path'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'yaml_path'", ",", "\n", "default", "=", "default_config_path", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--data_split'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'data_split'", ",", "\n", "default", "=", "default_data_split", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Set CUDA device id", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "args", ".", "gpu_device", "\n", "\n", "# Allow GPU memory growth", "\n", "physical_devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_physical_devices", "(", "'GPU'", ")", "\n", "tf", ".", "config", ".", "experimental", ".", "set_memory_growth", "(", "physical_devices", "[", "0", "]", ",", "True", ")", "\n", "\n", "# Load in configuration file as python dictionary", "\n", "with", "open", "(", "args", ".", "yaml_path", ",", "'r'", ")", "as", "yaml_file", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "yaml_file", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "\n", "# Make necessary directories, update config with checkpoint path and data", "\n", "# split", "\n", "", "config", "=", "config_utils", ".", "setup", "(", "config", ",", "args", ")", "\n", "\n", "# Go to validation function", "\n", "validate_model", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_training.train_model": [[19, 207], ["src.retina_net.builders.dataset_handler_builder.build_dataset", "keras.backend.set_learning_phase", "print", "int", "tensorflow.keras.optimizers.schedules.PiecewiseConstantDecay", "keras.optimizers.Adam", "tensorflow.summary.create_file_writer", "tensorflow.train.Checkpoint", "tensorflow.train.CheckpointManager", "tf.train.Checkpoint.restore", "dataset_handler_builder.build_dataset.create_dataset().repeat", "dataset_handler.create_dataset().repeat.batch", "batched_dataset.prefetch.take", "print", "batched_dataset.prefetch.prefetch", "time.time", "tensorflow.name_scope", "src.retina_net.models.retinanet_model.RetinaNetModel", "numpy.round", "str", "print", "tf.train.Checkpoint.step.assign_add", "str", "range", "datetime.datetime.now", "tensorflow.Variable", "keras.layers.Input", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor", "keras.utils.get_file", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.conv_block_2a.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.conv_block_3a.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.conv_block_4a.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.conv_block_5a.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_2b.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_2c.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_3b.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_3c.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_3d.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_4b.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_4c.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_4d.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_4e.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_4f.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_5b.load_weights", "src.retina_net.models.retinanet_model.RetinaNetModel.feature_extractor.identity_block_5c.load_weights", "print", "print", "dataset_handler_builder.build_dataset.create_dataset", "tensorflow.data.experimental.cardinality", "tensorflow.cast", "str", "tf.summary.create_file_writer.as_default", "tensorflow.summary.trace_on", "run_training.train_single_step", "tensorflow.summary.trace_export", "tensorflow.summary.scalar", "tf.summary.create_file_writer.flush", "keras.backend.learning_phase", "tensorflow.data.experimental.cardinality().numpy", "tensorflow.name_scope", "loss_dict.keys", "tensorflow.name_scope", "tensorflow.summary.scalar", "time.time", "time.time", "print", "tf.train.CheckpointManager.save", "print", "print", "tf.train.Checkpoint.step.assign_add", "tf.train.Checkpoint.step.assign_add", "len", "tensorflow.summary.scalar", "tf.keras.optimizers.schedules.PiecewiseConstantDecay.", "int", "int", "int", "int", "tensorflow.data.experimental.cardinality", "int", "int", "int", "total_loss.numpy", "int", "total_loss.numpy", "int"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.builders.dataset_handler_builder.build_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.create_dataset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_training.train_single_step"], ["def", "train_model", "(", "config", ")", ":", "\n", "    ", "\"\"\"\n    Training function.\n    :param config: config file\n    \"\"\"", "\n", "# Get training config", "\n", "training_config", "=", "config", "[", "'training_config'", "]", "\n", "# Create dataset class", "\n", "dataset_config", "=", "config", "[", "'dataset_config'", "]", "\n", "dataset_handler", "=", "dataset_handler_builder", ".", "build_dataset", "(", "\n", "dataset_config", ",", "'train'", ")", "\n", "\n", "# Set keras training phase", "\n", "keras", ".", "backend", ".", "set_learning_phase", "(", "1", ")", "\n", "print", "(", "\"Keras Learning Phase Set to: \"", "+", "\n", "str", "(", "keras", ".", "backend", ".", "learning_phase", "(", ")", ")", ")", "\n", "\n", "# Create Model", "\n", "with", "tf", ".", "name_scope", "(", "\"retinanet_model\"", ")", ":", "\n", "        ", "model", "=", "RetinaNetModel", "(", "config", "[", "'model_config'", "]", ")", "\n", "\n", "# Instantiate an optimizer.", "\n", "", "minibatch_size", "=", "training_config", "[", "'minibatch_size'", "]", "\n", "\n", "epoch_size", "=", "int", "(", "dataset_handler", ".", "epoch_size", "/", "minibatch_size", ")", "\n", "\n", "initial_learning_rate", "=", "training_config", "[", "'initial_learning_rate'", "]", "\n", "decay_factor", "=", "training_config", "[", "'decay_factor'", "]", "\n", "\n", "decay_boundaries", "=", "[", "\n", "boundary", "*", "\n", "epoch_size", "for", "boundary", "in", "training_config", "[", "'decay_boundaries'", "]", "]", "\n", "decay_factors", "=", "[", "decay_factor", "**", "i", "for", "i", "in", "range", "(", "0", ",", "len", "(", "decay_boundaries", ")", "+", "1", ")", "]", "\n", "learning_rate_values", "=", "[", "\n", "np", ".", "round", "(", "\n", "initial_learning_rate", "*", "\n", "decay_factor", ",", "\n", "8", ")", "for", "decay_factor", "in", "decay_factors", "]", "\n", "\n", "lr_schedule", "=", "tf", ".", "keras", ".", "optimizers", ".", "schedules", ".", "PiecewiseConstantDecay", "(", "\n", "decay_boundaries", ",", "learning_rate_values", ")", "\n", "\n", "optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "lr_schedule", ",", "epsilon", "=", "1e-2", ")", "\n", "\n", "# Create summary writer", "\n", "log_file", "=", "config", "[", "'logs_dir'", "]", "+", "'/training/'", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "log_file", ")", "\n", "\n", "# Load checkpoint weights if training folder exists", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "step", "=", "tf", ".", "Variable", "(", "0", ")", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "net", "=", "model", ")", "\n", "manager", "=", "tf", ".", "train", ".", "CheckpointManager", "(", "\n", "ckpt", ",", "\n", "config", "[", "'checkpoint_path'", "]", ",", "\n", "max_to_keep", "=", "training_config", "[", "'max_checkpoints_to_keep'", "]", ")", "\n", "\n", "ckpt", ".", "restore", "(", "manager", ".", "latest_checkpoint", ")", "\n", "\n", "# If no checkpoints exist, intialize either from imagenet or from scratch", "\n", "if", "manager", ".", "latest_checkpoint", ":", "\n", "        ", "print", "(", "\"Restored from {}\"", ".", "format", "(", "manager", ".", "latest_checkpoint", ")", ")", "\n", "ckpt", ".", "step", ".", "assign_add", "(", "1", ")", "\n", "", "elif", "config", "[", "'model_config'", "]", "[", "'feature_extractor'", "]", "[", "'pretrained_initialization'", "]", ":", "\n", "# Load resnet-50 imagenet pretrained weights if set in config file.", "\n", "# Dummy input required to define graph.", "\n", "        ", "input_shape", "=", "(", "224", ",", "224", ",", "3", ")", "\n", "dummy_input", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "input_shape", ")", "\n", "model", ".", "feature_extractor", "(", "dummy_input", ")", "\n", "\n", "weights_path", "=", "keras", ".", "utils", ".", "get_file", "(", "\n", "'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'", ",", "\n", "(", "'https://github.com/fchollet/deep-learning-models/'", "\n", "'releases/download/v0.2/'", "\n", "'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'", ")", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "md5_hash", "=", "'a268eb855778b3df3c7506639542a6af'", ")", "\n", "model", ".", "feature_extractor", ".", "load_weights", "(", "weights_path", ",", "by_name", "=", "True", ")", "\n", "# Tensorflow 2.0 bug with loading weights in nested models. Might get", "\n", "# fixed later.", "\n", "model", ".", "feature_extractor", ".", "conv_block_2a", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "conv_block_3a", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "conv_block_4a", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "conv_block_5a", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "\n", "model", ".", "feature_extractor", ".", "identity_block_2b", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_2c", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "\n", "model", ".", "feature_extractor", ".", "identity_block_3b", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_3c", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_3d", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "\n", "model", ".", "feature_extractor", ".", "identity_block_4b", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_4c", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_4d", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_4e", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_4f", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "\n", "model", ".", "feature_extractor", ".", "identity_block_5b", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "model", ".", "feature_extractor", ".", "identity_block_5c", ".", "load_weights", "(", "\n", "weights_path", ",", "by_name", "=", "True", ")", "\n", "print", "(", "\"Initializing from ImageNet weights.\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Initializing from scratch.\"", ")", "\n", "\n", "# Create Dataset", "\n", "# Skip already passed elements in dataset, in case of resuming training.", "\n", "", "dataset", "=", "dataset_handler", ".", "create_dataset", "(", ")", ".", "repeat", "(", "\n", "training_config", "[", "'max_epochs'", "]", ")", "\n", "\n", "# Batch size goes in parenthesis.", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "minibatch_size", ")", "\n", "\n", "batched_dataset", "=", "batched_dataset", ".", "take", "(", "tf", ".", "data", ".", "experimental", ".", "cardinality", "(", "\n", "batched_dataset", ")", "-", "tf", ".", "cast", "(", "ckpt", ".", "step", "+", "1", ",", "tf", ".", "int64", ")", ")", "\n", "print", "(", "\"Remaining iterations:\"", "+", "\n", "str", "(", "tf", ".", "data", ".", "experimental", ".", "cardinality", "(", "batched_dataset", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "# `prefetch` lets the dataset fetch batches, in the background while the model is training.", "\n", "batched_dataset", "=", "batched_dataset", ".", "prefetch", "(", "\n", "buffer_size", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "for", "sample_dict", "in", "batched_dataset", ":", "\n", "        ", "with", "summary_writer", ".", "as_default", "(", ")", ":", "\n", "# Turn on both graph and profiler for debugging the graph in", "\n", "# tensorboard", "\n", "            ", "tf", ".", "summary", ".", "trace_on", "(", "graph", "=", "False", ",", "profiler", "=", "False", ")", "\n", "total_loss", ",", "loss_dict", "=", "train_single_step", "(", "\n", "model", ",", "optimizer", ",", "sample_dict", ")", "\n", "tf", ".", "summary", ".", "trace_export", "(", "\n", "name", "=", "\"training_trace\"", ",", "\n", "step", "=", "0", ",", "\n", "profiler_outdir", "=", "log_file", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'losses'", ")", ":", "\n", "                ", "for", "loss_name", "in", "loss_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "tf", ".", "summary", ".", "scalar", "(", "loss_name", ",", "\n", "loss_dict", "[", "loss_name", "]", ",", "\n", "step", "=", "int", "(", "ckpt", ".", "step", ")", ")", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'optimizer'", ")", ":", "\n", "                ", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "\n", "lr_schedule", "(", "int", "(", "ckpt", ".", "step", ")", ")", ",", "\n", "step", "=", "int", "(", "ckpt", ".", "step", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\n", "'Total Loss'", ",", "\n", "total_loss", ",", "\n", "step", "=", "int", "(", "\n", "ckpt", ".", "step", ")", ")", "\n", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Write summary", "\n", "if", "int", "(", "ckpt", ".", "step", ")", "%", "training_config", "[", "'summary_interval'", "]", "==", "0", ":", "\n", "                ", "current_time", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "current_time", "-", "last_time", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\n", "'Step {}, Total Loss {:0.3f}, Time Elapsed {:0.3f} s'", ".", "format", "(", "\n", "int", "(", "ckpt", ".", "step", ")", ",", "total_loss", ".", "numpy", "(", ")", ",", "time_elapsed", ")", ")", "\n", "\n", "# Saving checkpoint", "\n", "", "if", "int", "(", "ckpt", ".", "step", ")", "%", "int", "(", "\n", "epoch_size", "*", "training_config", "[", "'checkpoint_interval'", "]", ")", "==", "0", ":", "\n", "                ", "save_path", "=", "manager", ".", "save", "(", "checkpoint_number", "=", "ckpt", ".", "save_counter", ")", "\n", "print", "(", "\"Saved checkpoint for step {}: {}\"", ".", "format", "(", "\n", "int", "(", "ckpt", ".", "step", ")", ",", "save_path", ")", ")", "\n", "print", "(", "\"loss {:1.2f}\"", ".", "format", "(", "total_loss", ".", "numpy", "(", ")", ")", ")", "\n", "ckpt", ".", "step", ".", "assign_add", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "ckpt", ".", "step", ".", "assign_add", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_training.train_single_step": [[208, 248], ["tensorflow.GradientTape", "model", "model.get_loss", "tensorflow.reduce_sum", "loss_dict.update", "tensorflow.name_scope", "tape.gradient", "tensorflow.clip_by_global_norm", "optimizer.apply_gradients", "tensorflow.concat", "zip"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.retinanet_model.RetinaNetModel.get_loss"], ["", "", "", "", "@", "tf", ".", "function", "\n", "def", "train_single_step", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "sample_dict", ")", ":", "\n", "    ", "\"\"\"\n    :param model: keras retinanet model\n    :param optimizer: keras optimizer\n    :param sample_dict: input dictionary generated from dataset.\n    If element sizes in this dictionary are variable, remove tf.function decorator.\n\n    :return total_loss: Sum of all losses.\n    :return cls_loss: classification loss.\n    :return reg_loss: regression loss.\n    :return regularization_loss: regularization_loss\n    :return prediction_dict: Dictionary containing neural network predictions\n    \"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "        ", "prediction_dict", "=", "model", "(", "sample_dict", "[", "constants", ".", "IMAGE_NORMALIZED_KEY", "]", ",", "\n", "train_val_test", "=", "'training'", ")", "\n", "\n", "total_loss", ",", "loss_dict", "=", "model", ".", "get_loss", "(", "sample_dict", ",", "prediction_dict", ")", "\n", "\n", "# Get any regularization loss in the model and add it to total loss", "\n", "regularization_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "concat", "(", "[", "layer", ".", "losses", "for", "layer", "in", "model", ".", "layers", "]", ",", "axis", "=", "0", ")", ")", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "REGULARIZATION_LOSS_KEY", ":", "regularization_loss", "}", ")", "\n", "\n", "total_loss", "+=", "regularization_loss", "\n", "\n", "# Compute the gradient which respect to the loss", "\n", "", "with", "tf", ".", "name_scope", "(", "\"grad_ops\"", ")", ":", "\n", "        ", "gradients", "=", "tape", ".", "gradient", "(", "total_loss", ",", "model", ".", "trainable_variables", ")", "\n", "clipped_gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "\n", "optimizer", ".", "apply_gradients", "(", "\n", "zip", "(", "clipped_gradients", ",", "model", ".", "trainable_variables", ")", ")", "\n", "\n", "", "return", "total_loss", ",", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_training.main": [[250, 297], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "tensorflow.config.experimental.list_physical_devices", "tensorflow.config.experimental.set_memory_growth", "src.retina_net.config_utils.setup", "run_training.train_model", "src.model_dir", "open", "yaml.load"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.retina_net.config_utils.setup", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.experiments.run_training.train_model", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.model_dir"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Object Detection Model Trainer\n    \"\"\"", "\n", "\n", "# Defaults", "\n", "default_gpu_device", "=", "'1'", "\n", "default_config_path", "=", "core", ".", "model_dir", "(", "\n", "'retina_net'", ")", "+", "'/configs/retinanet_bdd.yaml'", "\n", "# Allowed data splits are 'train','train_mini', 'val', 'val_half',", "\n", "# 'val_mini'", "\n", "default_data_split", "=", "'train'", "\n", "\n", "# Parse input", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "# Define argparser object", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'gpu_device'", ",", "\n", "default", "=", "default_gpu_device", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--yaml_path'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'yaml_path'", ",", "\n", "default", "=", "default_config_path", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--data_split'", ",", "\n", "type", "=", "str", ",", "\n", "dest", "=", "'data_split'", ",", "\n", "default", "=", "default_data_split", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Set CUDA device id", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "args", ".", "gpu_device", "\n", "\n", "# Allow GPU memory growth", "\n", "physical_devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_physical_devices", "(", "'GPU'", ")", "\n", "tf", ".", "config", ".", "experimental", ".", "set_memory_growth", "(", "physical_devices", "[", "0", "]", ",", "True", ")", "\n", "\n", "# Load in configuration file as python dictionary", "\n", "with", "open", "(", "args", ".", "yaml_path", ",", "'r'", ")", "as", "yaml_file", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "yaml_file", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "\n", "# Make necessary directories, update config with checkpoint path and data", "\n", "# split", "\n", "", "config", "=", "config_utils", ".", "setup", "(", "config", ",", "args", ")", "\n", "\n", "# Go to training function", "\n", "train_model", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.builders.dataset_handler_builder.build_dataset": [[5, 26], ["src.retina_net.datasets.kitti.kitti_dataset_handler.KittiDatasetHandler", "src.retina_net.datasets.bdd.bdd_dataset_handler.BddDatasetHandler", "ValueError"], "function", ["None"], ["def", "build_dataset", "(", "dataset_config", ",", "train_val_test", ")", ":", "\n", "    ", "\"\"\"\n    Builds dataset handler based on which dataset is currently being used.\n\n    :param dataset_config: dataset configuration dict.\n    :param train_val_test: datasplit to determine what needs to be loaded.\n\n    :return: dataset_handler: dataset handler class instance\n    \"\"\"", "\n", "\n", "if", "dataset_config", "[", "'dataset'", "]", "==", "'kitti'", ":", "\n", "        ", "dataset_handler", "=", "KittiDatasetHandler", "(", "dataset_config", ",", "train_val_test", ")", "\n", "", "elif", "dataset_config", "[", "'dataset'", "]", "==", "'bdd'", ":", "\n", "        ", "dataset_handler", "=", "BddDatasetHandler", "(", "\n", "dataset_config", ",", "train_val_test", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'Invalid dataset type {}'", ".", "format", "(", "\n", "dataset_config", "[", "'dataset'", "]", ")", ")", "\n", "\n", "", "return", "dataset_handler", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu": [[5, 24], ["tensorflow.stack"], "function", ["None"], ["def", "vuhw_to_vuvu", "(", "vuhw", ")", ":", "\n", "    ", "\"\"\"\n    Function to transform between center_dimensions box representation (vuhw) to\n    top left and bottom right corner box representation (vuvu).\n\n    :param vuhw: N x 4 tensor representing the v, u, width and height of bounding boxes\n    :return: vuvu: N x 4 tensor represeting v_min, u_min, v_max, u_max, the corners of the bounding boxes.\n    \"\"\"", "\n", "v", "=", "vuhw", "[", ":", ",", "0", "]", "\n", "u", "=", "vuhw", "[", ":", ",", "1", "]", "\n", "h", "=", "vuhw", "[", ":", ",", "2", "]", "\n", "w", "=", "vuhw", "[", ":", ",", "3", "]", "\n", "\n", "v_min", "=", "v", "-", "h", "/", "2.0", "\n", "u_min", "=", "u", "-", "w", "/", "2.0", "\n", "v_max", "=", "v", "+", "h", "/", "2.0", "\n", "u_max", "=", "u", "+", "w", "/", "2.0", "\n", "\n", "return", "tf", ".", "stack", "(", "(", "v_min", ",", "u_min", ",", "v_max", ",", "u_max", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw": [[26, 46], ["tensorflow.stack"], "function", ["None"], ["", "def", "vuvu_to_vuhw", "(", "vuvu", ")", ":", "\n", "    ", "\"\"\"\n    Function to transform between top left and bottom right corner box representation (vuvu) to\n     center_dimensions box representation (vuhw) .\n\n    :param vuvu: N x 4 tensor represeting v_min, u_min, v_max, u_max, the corners of the bounding boxes.\n    :return: vuhw: N x 4 tensor representing the v, u, width and height of bounding boxes\n    \"\"\"", "\n", "\n", "v_min", "=", "vuvu", "[", ":", ",", "0", "]", "\n", "u_min", "=", "vuvu", "[", ":", ",", "1", "]", "\n", "v_max", "=", "vuvu", "[", ":", ",", "2", "]", "\n", "u_max", "=", "vuvu", "[", ":", ",", "3", "]", "\n", "\n", "v", "=", "(", "v_max", "+", "v_min", ")", "/", "2.0", "\n", "u", "=", "(", "u_max", "+", "u_min", ")", "/", "2.0", "\n", "h", "=", "v_max", "-", "v_min", "\n", "w", "=", "u_max", "-", "u_min", "\n", "\n", "return", "tf", ".", "stack", "(", "(", "v", ",", "u", ",", "h", ",", "w", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuvu_to_vuhw_np": [[48, 68], ["numpy.stack"], "function", ["None"], ["", "def", "vuvu_to_vuhw_np", "(", "vuvu", ")", ":", "\n", "    ", "\"\"\"\n    Function to transform between top left and bottom right corner box representation (vuvu) to\n     center_dimensions box representation (vuhw) .\n\n    :param vuvu: N x 4 tensor represeting v_min, u_min, v_max, u_max, the corners of the bounding boxes.\n    :return: vuhw: N x 4 tensor representing the v, u, width and height of bounding boxes\n    \"\"\"", "\n", "\n", "v_min", "=", "vuvu", "[", ":", ",", "0", "]", "\n", "u_min", "=", "vuvu", "[", ":", ",", "1", "]", "\n", "v_max", "=", "vuvu", "[", ":", ",", "2", "]", "\n", "u_max", "=", "vuvu", "[", ":", ",", "3", "]", "\n", "\n", "v", "=", "(", "v_max", "+", "v_min", ")", "/", "2.0", "\n", "u", "=", "(", "u_max", "+", "u_min", ")", "/", "2.0", "\n", "h", "=", "v_max", "-", "v_min", "\n", "w", "=", "u_max", "-", "u_min", "\n", "\n", "return", "np", ".", "stack", "(", "(", "v", ",", "u", ",", "h", ",", "w", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np": [[70, 89], ["numpy.stack"], "function", ["None"], ["", "def", "vuhw_to_vuvu_np", "(", "vuhw", ")", ":", "\n", "    ", "\"\"\"\n    Function to transform between center_dimensions box representation (vuhw) to\n    top left and bottom right corner box representation (vuvu).\n\n    :param vuhw: N x 4 tensor representing the v, u, width and height of bounding boxes\n    :return: vuvu: N x 4 tensor representing v_min, u_min, v_max, u_max, the corners of the bounding boxes.\n    \"\"\"", "\n", "v", "=", "vuhw", "[", ":", ",", "0", "]", "\n", "u", "=", "vuhw", "[", ":", ",", "1", "]", "\n", "h", "=", "vuhw", "[", ":", ",", "2", "]", "\n", "w", "=", "vuhw", "[", ":", ",", "3", "]", "\n", "\n", "v_min", "=", "v", "-", "h", "/", "2.0", "\n", "u_min", "=", "u", "-", "w", "/", "2.0", "\n", "v_max", "=", "v", "+", "h", "/", "2.0", "\n", "u_max", "=", "u", "+", "w", "/", "2.0", "\n", "\n", "return", "np", ".", "stack", "(", "(", "v_min", ",", "u_min", ",", "v_max", ",", "u_max", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.crop_vuvu_to_image_shape": [[91, 115], ["tensorflow.cast", "tensorflow.minimum", "tensorflow.minimum", "tensorflow.minimum", "tensorflow.minimum", "tensorflow.stack", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum"], "function", ["None"], ["", "def", "crop_vuvu_to_image_shape", "(", "vuvu", ",", "im_shape", ")", ":", "\n", "    ", "\"\"\"\n    Crop bounding boxes with (vuvu) representation to fit in image space.\n\n    :param vuvu: N x 4 tensor represeting v_min, u_min, v_max, u_max, the corners of the bounding boxes.\n    :param im_shape: Shape of image as [batch, height, width, depth]\n\n    :return: Cropped 2D bounding box\n    \"\"\"", "\n", "im_shape", "=", "tf", ".", "cast", "(", "im_shape", ",", "tf", ".", "float32", ")", "\n", "im_height", "=", "im_shape", "[", "1", "]", "\n", "im_width", "=", "im_shape", "[", "2", "]", "\n", "\n", "v_min", "=", "vuvu", "[", ":", ",", "0", "]", "\n", "u_min", "=", "vuvu", "[", ":", ",", "1", "]", "\n", "v_max", "=", "vuvu", "[", ":", ",", "2", "]", "\n", "u_max", "=", "vuvu", "[", ":", ",", "3", "]", "\n", "\n", "v_min", "=", "tf", ".", "minimum", "(", "im_height", "-", "1", ",", "tf", ".", "maximum", "(", "0.0", ",", "v_min", ")", ")", "\n", "u_min", "=", "tf", ".", "minimum", "(", "im_width", "-", "1", ",", "tf", ".", "maximum", "(", "0.0", ",", "u_min", ")", ")", "\n", "v_max", "=", "tf", ".", "minimum", "(", "im_height", "-", "1", ",", "tf", ".", "maximum", "(", "0.0", ",", "v_max", ")", ")", "\n", "u_max", "=", "tf", ".", "minimum", "(", "im_width", "-", "1", ",", "tf", ".", "maximum", "(", "0.0", ",", "u_max", ")", ")", "\n", "\n", "return", "tf", ".", "stack", "(", "(", "v_min", ",", "u_min", ",", "v_max", ",", "u_max", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.bbox_iou_vuvu": [[117, 147], ["tensorflow.split", "tensorflow.split", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.minimum", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.transpose"], "function", ["None"], ["", "def", "bbox_iou_vuvu", "(", "bboxes1", ",", "bboxes2", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        bboxes1: shape (total_bboxes1, 4)\n            with v1, u1, v2, u2  point order.\n        bboxes2: shape (total_bboxes2, 4)\n            with v1, u1, v2, u2  point order.\n        p1 *-----\n           |     |\n           |_____* p2\n    Returns:\n        Tensor with shape (total_bboxes1, total_bboxes2)\n        with the IoU (intersection over union) of bboxes1[i] and bboxes2[j]\n        in [i, j].\n    \"\"\"", "\n", "y11", ",", "x11", ",", "y12", ",", "x12", "=", "tf", ".", "split", "(", "bboxes1", ",", "4", ",", "axis", "=", "1", ")", "\n", "y21", ",", "x21", ",", "y22", ",", "x22", "=", "tf", ".", "split", "(", "bboxes2", ",", "4", ",", "axis", "=", "1", ")", "\n", "xI1", "=", "tf", ".", "maximum", "(", "x11", ",", "tf", ".", "transpose", "(", "x21", ")", ")", "\n", "yI1", "=", "tf", ".", "maximum", "(", "y11", ",", "tf", ".", "transpose", "(", "y21", ")", ")", "\n", "xI2", "=", "tf", ".", "minimum", "(", "x12", ",", "tf", ".", "transpose", "(", "x22", ")", ")", "\n", "yI2", "=", "tf", ".", "minimum", "(", "y12", ",", "tf", ".", "transpose", "(", "y22", ")", ")", "\n", "inter_area", "=", "tf", ".", "maximum", "(", "(", "xI2", "-", "xI1", "+", "1.0", ")", ",", "0.0", ")", "*", "tf", ".", "maximum", "(", "(", "yI2", "-", "yI1", "+", "1.0", ")", ",", "0.0", ")", "\n", "bboxes1_area", "=", "(", "x11", "-", "x12", "+", "1.0", ")", "*", "(", "y11", "-", "y12", "+", "1.0", ")", "\n", "bboxes2_area", "=", "(", "x21", "-", "x22", "+", "1.0", ")", "*", "(", "y21", "-", "y22", "+", "1.0", ")", "\n", "union", "=", "(", "bboxes1_area", "+", "tf", ".", "transpose", "(", "bboxes2_area", ")", ")", "-", "inter_area", "\n", "# some invalid boxes should have iou of 0 instead of NaN", "\n", "# If inter_area is 0, then this result will be 0; if inter_area is", "\n", "# not 0, then union is not too, therefore adding a epsilon is OK.", "\n", "return", "inter_area", "/", "(", "union", "+", "0.00001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target": [[149, 169], ["tensorflow.stack", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.exp", "tensorflow.exp"], "function", ["None"], ["", "def", "box_from_anchor_and_target", "(", "anchors", ",", "regressed_targets", ")", ":", "\n", "    ", "\"\"\"\n    Get bounding box from anchor and target through transformation provided in the paper.\n    :param anchors: Nx4 anchor boxes\n    :param regressed_targets: Nx4 regression targets\n    :return:\n    \"\"\"", "\n", "\n", "boxes_v", "=", "anchors", "[", ":", ",", "2", "]", "*", "regressed_targets", "[", ":", ",", "0", "]", "/", "10.0", "+", "anchors", "[", ":", ",", "0", "]", "\n", "boxes_u", "=", "anchors", "[", ":", ",", "3", "]", "*", "regressed_targets", "[", ":", ",", "1", "]", "/", "10.0", "+", "anchors", "[", ":", ",", "1", "]", "\n", "\n", "boxes_h", "=", "anchors", "[", ":", ",", "2", "]", "*", "tf", ".", "clip_by_value", "(", "tf", ".", "exp", "(", "regressed_targets", "[", ":", ",", "2", "]", "/", "5.0", ")", ",", "1e-4", ",", "1e4", ")", "\n", "boxes_w", "=", "anchors", "[", ":", ",", "3", "]", "*", "tf", ".", "clip_by_value", "(", "tf", ".", "exp", "(", "regressed_targets", "[", ":", ",", "3", "]", "/", "5.0", ")", ",", "1e-4", ",", "1e4", ")", "\n", "\n", "return", "tf", ".", "stack", "(", "[", "boxes_v", ",", "\n", "boxes_u", ",", "\n", "boxes_h", ",", "\n", "boxes_w", "]", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target_bnms": [[171, 193], ["tensorflow.stack", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.exp", "tensorflow.exp"], "function", ["None"], ["", "def", "box_from_anchor_and_target_bnms", "(", "anchors", ",", "regressed_targets", ")", ":", "\n", "    ", "\"\"\"\n    Batch version of the above function. For usage with MC-Dropout.\n\n    :param anchors: MxNx4 anchor boxes where M is the batch size.\n    :param regressed_targets: MxNx4 regression targets\n    :return:\n    \"\"\"", "\n", "boxes_v", "=", "anchors", "[", ":", ",", ":", ",", "2", "]", "*", "regressed_targets", "[", ":", ",", ":", ",", "0", "]", "/", "10.0", "+", "anchors", "[", ":", ",", ":", ",", "0", "]", "\n", "boxes_u", "=", "anchors", "[", ":", ",", ":", ",", "3", "]", "*", "regressed_targets", "[", ":", ",", ":", ",", "1", "]", "/", "10.0", "+", "anchors", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "boxes_h", "=", "anchors", "[", ":", ",", ":", ",", "2", "]", "*", "tf", ".", "clip_by_value", "(", "tf", ".", "exp", "(", "regressed_targets", "[", ":", ",", ":", ",", "2", "]", "/", "5.0", ")", ",", "1e-4", ",", "1e4", ")", "\n", "boxes_w", "=", "anchors", "[", ":", ",", ":", ",", "3", "]", "*", "tf", ".", "clip_by_value", "(", "tf", ".", "exp", "(", "regressed_targets", "[", ":", ",", ":", ",", "3", "]", "/", "5.0", ")", ",", "1e-4", ",", "1e4", ")", "\n", "\n", "return", "tf", ".", "stack", "(", "[", "boxes_v", ",", "\n", "boxes_u", ",", "\n", "boxes_h", ",", "\n", "boxes_w", "]", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.normalize_2d_bounding_boxes": [[195, 206], ["tensorflow.cast", "tensorflow.cast", "tensorflow.stack"], "function", ["None"], ["", "def", "normalize_2d_bounding_boxes", "(", "boxes_2", ",", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Produces bounding boxes as a fraction of the total image shape. Useful for crop-and-resize\n    :param boxes_2: 2D bounding box\n    :param shape: Image shape\n    :return: Normalized 2D bounding box\n    \"\"\"", "\n", "height", "=", "tf", ".", "cast", "(", "shape", "[", "0", "]", ",", "tf", ".", "float32", ")", "\n", "width", "=", "tf", ".", "cast", "(", "shape", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "normalizer", "=", "tf", ".", "stack", "(", "[", "height", ",", "width", ",", "height", ",", "width", "]", ",", "axis", "=", "0", ")", "\n", "return", "boxes_2", "/", "normalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.expand_2d_bounding_boxes": [[208, 221], ["tensorflow.cast", "tensorflow.cast", "tensorflow.stack"], "function", ["None"], ["", "def", "expand_2d_bounding_boxes", "(", "boxes_2", ",", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Produces bounding boxes by multiplying normalized boxes with new image shape.\n     Usefull for handling image resize\n\n    :param boxes_2: 2D bounding box\n    :param shape: Image shape\n    :return: scaled 2D bounding box\n    \"\"\"", "\n", "height", "=", "tf", ".", "cast", "(", "shape", "[", "0", "]", ",", "tf", ".", "float32", ")", "\n", "width", "=", "tf", ".", "cast", "(", "shape", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "scale", "=", "tf", ".", "stack", "(", "[", "height", ",", "width", ",", "height", ",", "width", "]", ",", "axis", "=", "0", ")", "\n", "return", "boxes_2", "*", "scale", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.__init__": [[12, 20], ["src.core.abstract_classes.anchor_generator.AnchorGenerator.__init__", "tensorflow.constant", "numpy.size", "numpy.size"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["def", "__init__", "(", "self", ",", "generator_config", ")", ":", "\n", "# Parse Generator Config", "\n", "        ", "super", "(", "FpnAnchorGenerator", ",", "self", ")", ".", "__init__", "(", "generator_config", ")", "\n", "\n", "self", ".", "aspect_ratios", "=", "self", ".", "config", "[", "'aspect_ratios'", "]", "\n", "self", ".", "scales", "=", "self", ".", "config", "[", "'scales'", "]", "\n", "self", ".", "anchors_per_location", "=", "tf", ".", "constant", "(", "\n", "np", ".", "size", "(", "self", ".", "aspect_ratios", ",", "axis", "=", "0", ")", "*", "np", ".", "size", "(", "self", ".", "scales", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchors": [[21, 60], ["tensorflow.cast", "tensorflow.pow", "tensorflow.meshgrid", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.stack", "tensorflow.pow", "tensorflow.cast", "fpn_anchor_generator.tf_repeat", "tensorflow.tile", "tensorflow.concat", "tensorflow.stack", "tensorflow.range", "tensorflow.range", "tensorflow.shape", "tensorflow.tile.append", "tensorflow.sqrt", "tensorflow.tile.append", "tensorflow.pow", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.tf_repeat"], ["", "def", "generate_anchors", "(", "self", ",", "im_shape", ",", "layer_number", ")", ":", "\n", "        ", "aspect_ratios", "=", "self", ".", "aspect_ratios", "\n", "scales", "=", "self", ".", "scales", "\n", "\n", "im_shape", "=", "tf", ".", "cast", "(", "im_shape", ",", "tf", ".", "float32", ")", "\n", "\n", "stride", "=", "tf", ".", "pow", "(", "2.0", ",", "layer_number", ")", "\n", "u_pos", "=", "(", "tf", ".", "range", "(", "0", ",", "im_shape", "[", "1", "]", "/", "stride", ")", "+", "0.5", ")", "*", "stride", "\n", "v_pos", "=", "(", "tf", ".", "range", "(", "0", ",", "im_shape", "[", "0", "]", "/", "stride", ")", "+", "0.5", ")", "*", "stride", "\n", "u", ",", "v", "=", "tf", ".", "meshgrid", "(", "u_pos", ",", "v_pos", ")", "\n", "u", "=", "tf", ".", "reshape", "(", "u", ",", "[", "-", "1", "]", ")", "\n", "v", "=", "tf", ".", "reshape", "(", "v", ",", "[", "-", "1", "]", ")", "\n", "spatial_locations", "=", "tf", ".", "stack", "(", "(", "v", ",", "u", ")", ",", "axis", "=", "1", ")", "\n", "\n", "anchor_side_shape", "=", "tf", ".", "pow", "(", "2.0", ",", "layer_number", "+", "2.0", ")", "\n", "anchor_dims", "=", "[", "]", "\n", "for", "aspect_ratio", "in", "aspect_ratios", ":", "\n", "            ", "for", "scale", "in", "scales", ":", "\n", "                ", "if", "aspect_ratio", "[", "0", "]", "==", "1", "and", "aspect_ratio", "[", "1", "]", "==", "1", ":", "\n", "                    ", "anchor_dims", ".", "append", "(", "\n", "aspect_ratio", "*", "anchor_side_shape", "*", "scale", ")", "\n", "", "else", ":", "\n", "                    ", "dim_solution", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "pow", "(", "\n", "anchor_side_shape", ",", "\n", "2.0", ")", "/", "\n", "np", ".", "prod", "(", "aspect_ratio", ")", ")", "\n", "anchor_dims", ".", "append", "(", "aspect_ratio", "*", "dim_solution", "*", "scale", ")", "\n", "\n", "", "", "", "num_of_locations", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "spatial_locations", ")", "[", "\n", "0", "]", ",", "tf", ".", "int32", ")", "\n", "\n", "anchor_locations", "=", "tf_repeat", "(", "spatial_locations", ",", "\n", "[", "self", ".", "anchors_per_location", ",", "1", "]", ")", "\n", "anchor_dims", "=", "tf", ".", "tile", "(", "tf", ".", "stack", "(", "anchor_dims", ")", ",", "[", "num_of_locations", ",", "1", "]", ")", "\n", "\n", "anchor_grid", "=", "tf", ".", "concat", "(", "(", "anchor_locations", ",", "anchor_dims", ")", ",", "axis", "=", "1", ")", "\n", "\n", "return", "anchor_grid", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.positive_negative_batching": [[61, 80], ["tensorflow.greater_equal", "tensorflow.reduce_any", "tensorflow.less_equal", "tensorflow.reduce_all", "tensorflow.argmax"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positive_negative_batching", "(", "\n", "ious", ",", "\n", "min_positive_iou", "=", "0.5", ",", "\n", "max_negative_iou", "=", "0.4", ")", ":", "\n", "        ", "\"\"\"\n        Generates positive and negative anchors using min and max iou thresholds.\n        :param ious: Batch x N x M matrix containing the iou of every anchor with every groundtruth target\n        :param min_positive_iou: minimum threshold for an anchor to be positive\n        :param max_negative_iou: maximum threshold for an anchor to be negative\n        :return:\n        \"\"\"", "\n", "positive_mask", "=", "tf", ".", "greater_equal", "(", "ious", ",", "min_positive_iou", ")", "\n", "positive_mask", "=", "tf", ".", "reduce_any", "(", "positive_mask", ",", "axis", "=", "1", ")", "\n", "negative_mask", "=", "tf", ".", "less_equal", "(", "ious", ",", "max_negative_iou", ")", "\n", "negative_mask", "=", "tf", ".", "reduce_all", "(", "negative_mask", ",", "axis", "=", "1", ")", "\n", "\n", "max_iou", "=", "tf", ".", "argmax", "(", "ious", ",", "axis", "=", "1", ",", "name", "=", "None", ")", "\n", "return", "positive_mask", ",", "negative_mask", ",", "max_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.FpnAnchorGenerator.generate_anchor_targets": [[81, 138], ["tensorflow.gather", "tensorflow.math.log", "tensorflow.math.log", "tensorflow.stack", "tensorflow.gather", "tensorflow.one_hot", "tensorflow.broadcast_to", "tensorflow.where", "tensorflow.shape", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "generate_anchor_targets", "(", "\n", "anchors", ",", "\n", "gt_boxes", ",", "\n", "gt_classes", ",", "\n", "max_ious", ",", "\n", "positive_anchor_mask", ")", ":", "\n", "        ", "\"\"\"\n        Generates anchor targets to be fed into the loss function computation.\n\n        :param anchors: N x 4 tensor of anchors\n        :param gt_boxes: M x 4 tensor of GT boxes\n        :param gt_classes: M x K tensor of classes in one-hot format\n        :param max_ious: N x 1 tensor of indexes of the gt which the anchor has max iou\n        :param positive_anchor_mask: N x 1 tensor signifying which anchor is positive.\n\n        :return: anchor_box_targets: N x 4 anchor regression targets\n        :return: anchor_class_targets: N x k anchor classification targets\n        \"\"\"", "\n", "\n", "anchor_box_gt", "=", "tf", ".", "gather", "(", "gt_boxes", ",", "max_ious", ",", "axis", "=", "0", ")", "\n", "\n", "anchor_box_pos_v_targets", "=", "(", "\n", "anchor_box_gt", "[", ":", ",", "0", "]", "-", "anchors", "[", ":", ",", "0", "]", ")", "/", "anchors", "[", ":", ",", "2", "]", "\n", "anchor_box_pos_u_targets", "=", "(", "\n", "anchor_box_gt", "[", ":", ",", "1", "]", "-", "anchors", "[", ":", ",", "1", "]", ")", "/", "anchors", "[", ":", ",", "3", "]", "\n", "\n", "anchor_box_pos_v_targets", "*=", "10.0", "\n", "anchor_box_pos_u_targets", "*=", "10.0", "\n", "\n", "anchor_box_dim_h_targets", "=", "tf", ".", "math", ".", "log", "(", "\n", "anchor_box_gt", "[", ":", ",", "2", "]", "/", "anchors", "[", ":", ",", "2", "]", ")", "\n", "anchor_box_dim_w_targets", "=", "tf", ".", "math", ".", "log", "(", "\n", "anchor_box_gt", "[", ":", ",", "3", "]", "/", "anchors", "[", ":", ",", "3", "]", ")", "\n", "\n", "anchor_box_dim_h_targets", "*=", "5.0", "\n", "anchor_box_dim_w_targets", "*=", "5.0", "\n", "\n", "anchor_box_targets", "=", "tf", ".", "stack", "(", "[", "anchor_box_pos_v_targets", ",", "\n", "anchor_box_pos_u_targets", ",", "\n", "anchor_box_dim_h_targets", ",", "\n", "anchor_box_dim_w_targets", "]", ",", "axis", "=", "1", ")", "\n", "\n", "class_targets", "=", "tf", ".", "gather", "(", "gt_classes", ",", "max_ious", ",", "axis", "=", "0", ")", "\n", "\n", "num_classes", "=", "tf", ".", "shape", "(", "gt_classes", ")", "[", "1", "]", "\n", "negative_label", "=", "tf", ".", "one_hot", "(", "\n", "num_classes", "-", "1", ",", "num_classes", ",", "on_value", "=", "1.0", ",", "off_value", "=", "0.0", ")", "\n", "\n", "negative_targets", "=", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "anchors", ")", "[", "0", "]", ",", "1", "]", ")", "*", "negative_label", "\n", "\n", "positive_anchor_mask", "=", "tf", ".", "broadcast_to", "(", "tf", ".", "expand_dims", "(", "positive_anchor_mask", ",", "-", "1", ")", ",", "tf", ".", "shape", "(", "class_targets", ")", ")", "\n", "\n", "anchor_class_targets", "=", "tf", ".", "where", "(", "\n", "positive_anchor_mask", ",", "class_targets", ",", "negative_targets", ")", "\n", "\n", "return", "anchor_box_targets", ",", "anchor_class_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.fpn_anchor_generator.tf_repeat": [[140, 157], ["tensorflow.name_scope", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reshape", "tensorflow.shape"], "function", ["None"], ["", "", "def", "tf_repeat", "(", "tensor", ",", "repeats", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n\n    input: A Tensor. 1-D or higher.\n    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n\n    Returns:\n\n    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"repeat\"", ")", ":", "\n", "        ", "expanded_tensor", "=", "tf", ".", "expand_dims", "(", "tensor", ",", "-", "1", ")", "\n", "multiples", "=", "[", "1", "]", "+", "repeats", "\n", "tiled_tensor", "=", "tf", ".", "tile", "(", "expanded_tensor", ",", "multiples", "=", "multiples", ")", "\n", "repeated_tensor", "=", "tf", ".", "reshape", "(", "tiled_tensor", ",", "tf", ".", "shape", "(", "tensor", ")", "*", "repeats", ")", "\n", "", "return", "repeated_tensor", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.__init__": [[16, 24], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PDQ", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_tot_overall_quality", "=", "0.0", "\n", "self", ".", "_tot_spatial_quality", "=", "0.0", "\n", "self", ".", "_tot_label_quality", "=", "0.0", "\n", "self", ".", "_tot_TP", "=", "0", "\n", "self", ".", "_tot_FP", "=", "0", "\n", "self", ".", "_tot_FN", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.add_img_eval": [[25, 39], ["pdq._calc_qual_img"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_qual_img"], ["", "def", "add_img_eval", "(", "self", ",", "gt_instances", ",", "det_instances", ")", ":", "\n", "        ", "\"\"\"\n        Adds a single image's detections and ground-truth to the overall evaluation analysis.\n        :param gt_instances: list of GroundTruthInstance objects present in the given image.\n        :param det_instances: list of DetectionInstance objects provided for the given image\n        :return: None\n        \"\"\"", "\n", "results", "=", "_calc_qual_img", "(", "gt_instances", ",", "det_instances", ")", "\n", "self", ".", "_tot_overall_quality", "+=", "results", "[", "'overall'", "]", "\n", "self", ".", "_tot_spatial_quality", "+=", "results", "[", "'spatial'", "]", "\n", "self", ".", "_tot_label_quality", "+=", "results", "[", "'label'", "]", "\n", "self", ".", "_tot_TP", "+=", "results", "[", "'TP'", "]", "\n", "self", ".", "_tot_FP", "+=", "results", "[", "'FP'", "]", "\n", "self", ".", "_tot_FN", "+=", "results", "[", "'FN'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_pdq_score": [[40, 47], ["None"], "methods", ["None"], ["", "def", "get_pdq_score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the current PDQ score for all frames analysed at the current time.\n        :return: The average PDQ across all images as a float.\n        \"\"\"", "\n", "tot_pairs", "=", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", "+", "self", ".", "_tot_FN", "\n", "return", "self", ".", "_tot_overall_quality", "/", "tot_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.reset": [[48, 59], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all internally stored evaluation measures to zero.\n        :return: None\n        \"\"\"", "\n", "self", ".", "_tot_overall_quality", "=", "0.0", "\n", "self", ".", "_tot_spatial_quality", "=", "0.0", "\n", "self", ".", "_tot_label_quality", "=", "0.0", "\n", "self", ".", "_tot_TP", "=", "0", "\n", "self", ".", "_tot_FP", "=", "0", "\n", "self", ".", "_tot_FN", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.score": [[60, 87], ["pdq.PDQ.reset", "multiprocessing.Pool", "multiprocessing.Pool.imap_unordered", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "pdq.PDQ.get_pdq_score", "multiprocessing.cpu_count"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.reset", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_pdq_score"], ["", "def", "score", "(", "self", ",", "matches", ")", ":", "\n", "        ", "\"\"\"\n        Calculates the average probabilistic detection quality for a set of detections on\n        a set of ground truth objects over a series of images.\n        The average is calculated as the average pairwise quality over the number of object-detection pairs observed.\n        Note that this removes any evaluation information that had been stored for previous images.\n        Assumes you want to score just the full list you are given.\n        :param matches: A list of tuples where each tuple holds a list of GroundTruthInstances and\n        DetectionInstances respectively, describing the ground truth objects and detections for a given image.\n        Each image observed is an entry in the main list.\n        :return: The average PDQ across all images as a float.\n        \"\"\"", "\n", "self", ".", "reset", "(", ")", "\n", "pool", "=", "Pool", "(", "processes", "=", "cpu_count", "(", ")", ")", "\n", "for", "img_results", "in", "pool", ".", "imap_unordered", "(", "_get_image_evals", ",", "\n", "iterable", "=", "matches", ")", ":", "\n", "            ", "self", ".", "_tot_overall_quality", "+=", "img_results", "[", "'overall'", "]", "\n", "self", ".", "_tot_spatial_quality", "+=", "img_results", "[", "'spatial'", "]", "\n", "self", ".", "_tot_label_quality", "+=", "img_results", "[", "'label'", "]", "\n", "self", ".", "_tot_TP", "+=", "img_results", "[", "'TP'", "]", "\n", "self", ".", "_tot_FP", "+=", "img_results", "[", "'FP'", "]", "\n", "self", ".", "_tot_FN", "+=", "img_results", "[", "'FN'", "]", "\n", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "return", "self", ".", "get_pdq_score", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_spatial_score": [[88, 99], ["float"], "methods", ["None"], ["", "def", "get_avg_spatial_score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the average spatial quality score for all assigned detections in all frames analysed at the current time.\n        Note that this is averaged over the number of assigned detections (TPs) and not the full set of TPs, FPs,\n        and FNs like the final PDQ score.\n        :return: average spatial quality of every detection\n        \"\"\"", "\n", "if", "(", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", ")", ">", "0.0", ":", "\n", "            ", "return", "self", ".", "_tot_spatial_quality", "/", "float", "(", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", ")", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_label_score": [[100, 110], ["float"], "methods", ["None"], ["", "def", "get_avg_label_score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the average label quality score for all assigned detections in all frames analysed at the current time.\n        Note that this is averaged over the number of assigned detections (TPs) and not the full set of TPs, FPs,\n        and FNs like the final PDQ score.\n        :return: average label quality of every detection\n        \"\"\"", "\n", "if", "(", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", ")", ">", "0.0", ":", "\n", "            ", "return", "self", ".", "_tot_label_quality", "/", "float", "(", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", ")", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_avg_overall_quality_score": [[111, 123], ["float"], "methods", ["None"], ["", "def", "get_avg_overall_quality_score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the average overall pairwise quality score for all assigned detections\n        in all frames analysed at the current time.\n        Note that this is averaged over the number of assigned detections (TPs) and not the full set of TPs, FPs,\n        and FNs like the final PDQ score.\n        :return: average overall pairwise quality of every  detection\n        \"\"\"", "\n", "if", "(", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", ")", ">", "0.0", ":", "\n", "            ", "return", "self", ".", "_tot_overall_quality", "/", "float", "(", "self", ".", "_tot_TP", "+", "self", ".", "_tot_FP", ")", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq.PDQ.get_assignment_counts": [[124, 130], ["None"], "methods", ["None"], ["", "def", "get_assignment_counts", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the total number of TP, FP, and FN detections across all frames analysed at the current time.\n        :return: tuple containing (TP, FP, FN)\n        \"\"\"", "\n", "return", "self", ".", "_tot_TP", ",", "self", ".", "_tot_FP", ",", "self", ".", "_tot_FN", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._get_image_evals": [[132, 145], ["pdq._calc_qual_img"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_qual_img"], ["", "", "def", "_get_image_evals", "(", "pair", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate the results for a given image\n    :param pair: tuple containing list of GroundTruthInstances and DetectionInstances for the given image respectively\n    :return: results dictionary containing total overall spatial quality, total spatial quality on positively assigned\n    detections, total label quality on positively assigned detections, number of true positives,\n    number of false positives, and number false negatives for the given image.\n    Format {'overall':<tot_overall_quality>, 'spatial': <tot_tp_spatial_quality>, 'label': <tot_tp_label_quality>,\n    'TP': <num_true_positives>, 'FP': <num_false_positives>, 'FN': <num_false_positives>}\n    \"\"\"", "\n", "gt_instances", ",", "det_instances", "=", "pair", "\n", "results", "=", "_calc_qual_img", "(", "gt_instances", ",", "det_instances", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._vectorize_img_gts": [[147, 177], ["numpy.stack", "numpy.array", "numpy.array", "numpy.ones", "enumerate", "len"], "function", ["None"], ["", "def", "_vectorize_img_gts", "(", "gt_instances", ",", "img_shape", ")", ":", "\n", "    ", "\"\"\"\n    Vectorizes the required elements for all GroundTruthInstances as necessary for a given image.\n    These elements are the segmentation mask, background mask, number of foreground pixels, and label for each.\n    :param gt_instances: list of all GroundTruthInstances for a given image\n    :param img_shape: shape of the image that the GroundTruthInstances lie within\n    :return: (gt_seg_mat, bg_seg_mat, num_fg_pixels_vec, gt_label_vec).\n    gt_seg_mat: h x w x g boolean numpy array depicting the ground truth pixels for each of the g GroundTruthInstances\n    within an h x w image.\n    bg_seg_mat: h x w x g boolean numpy array depicting the background pixels for each of the g GroundTruthInstances\n    (pixels outside the bounding box) within an h x w image.\n    num_fg_pixels_vec: g x 1 int numpy array containing the number of foreground (object) pixels for each of\n    the g GroundTruthInstances.\n    gt_label_vec: g, numpy array containing the class label as an integer for each of the g GroundTruthInstances\n    \"\"\"", "\n", "gt_seg_mat", "=", "np", ".", "stack", "(", "\n", "[", "gt_instance", ".", "segmentation_mask", "for", "gt_instance", "in", "gt_instances", "]", ",", "axis", "=", "2", ")", "# h x w x g", "\n", "num_fg_pixels_vec", "=", "np", ".", "array", "(", "[", "[", "gt_instance", ".", "num_pixels", "]", "\n", "for", "gt_instance", "in", "gt_instances", "]", ",", "dtype", "=", "np", ".", "int", ")", "# g x 1", "\n", "gt_label_vec", "=", "np", ".", "array", "(", "\n", "[", "gt_instance", ".", "class_label", "for", "gt_instance", "in", "gt_instances", "]", ",", "dtype", "=", "np", ".", "int", ")", "# g,", "\n", "\n", "bg_seg_mat", "=", "np", ".", "ones", "(", "img_shape", "+", "(", "len", "(", "gt_instances", ")", ",", ")", ",", "\n", "dtype", "=", "np", ".", "bool", ")", "# h x w x g", "\n", "for", "gt_idx", ",", "gt_instance", "in", "enumerate", "(", "gt_instances", ")", ":", "\n", "        ", "gt_box", "=", "gt_instance", ".", "bounding_box", "\n", "bg_seg_mat", "[", "gt_box", "[", "1", "]", ":", "gt_box", "[", "3", "]", "+", "1", ",", "\n", "gt_box", "[", "0", "]", ":", "gt_box", "[", "2", "]", "+", "1", ",", "gt_idx", "]", "=", "False", "\n", "\n", "", "return", "gt_seg_mat", ",", "bg_seg_mat", ",", "num_fg_pixels_vec", ",", "gt_label_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._vectorize_img_dets": [[179, 196], ["numpy.stack", "numpy.stack", "det_instance.calc_heatmap"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.calc_heatmap"], ["", "def", "_vectorize_img_dets", "(", "det_instances", ",", "img_shape", ")", ":", "\n", "    ", "\"\"\"\n    Vectorize the required elements for all DetectionInstances as necessary for a given image.\n    These elements are the thresholded detection heatmap, and the detection label list for each.\n    :param det_instances: list of all DetectionInstances for a given image.\n    :param img_shape: shape of the image that the DetectionInstances lie within.\n    :return: (det_seg_heatmap_mat, det_label_prob_mat)\n    det_seg_heatmap_mat: h x w x d float32 numpy array depciting the probability that each pixel is part of the\n    detection within an h x w image. Note that this is thresholded so pixels with particularly low probabilities instead\n    have a probability in the heatmap of zero.\n    det_label_prob_mat: d x c numpy array of label probability scores across all c classes for each of the d detections\n    \"\"\"", "\n", "det_label_prob_mat", "=", "np", ".", "stack", "(", "\n", "[", "det_instance", ".", "class_list", "for", "det_instance", "in", "det_instances", "]", ",", "axis", "=", "0", ")", "# d x c", "\n", "det_seg_heatmap_mat", "=", "np", ".", "stack", "(", "[", "det_instance", ".", "calc_heatmap", "(", "\n", "img_shape", ")", "for", "det_instance", "in", "det_instances", "]", ",", "axis", "=", "2", ")", "\n", "return", "det_seg_heatmap_mat", ",", "det_label_prob_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_bg_loss": [[198, 213], ["numpy.tensordot", "pdq._safe_log"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._safe_log"], ["", "def", "_calc_bg_loss", "(", "bg_seg_mat", ",", "det_seg_heatmap_mat", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the background pixel loss for all detections on all ground truth objects for a given image.\n    :param bg_seg_mat: h x w x g vectorized background masks for each ground truth object in the image.\n    :param det_seg_heatmap_mat: h x w x d vectorized segmented heatmaps for each detection in the image.\n    :return: (bg_loss_sum, num_bg_pixels_mat)\n    bg_loss_sum: g x d total background loss between each of the g ground truth objects and d detections.\n    num_bg_pixels_mat: g x d number of background pixels examined for each combination of g ground truth objects and d\n    detections.\n    \"\"\"", "\n", "bg_log_loss_mat", "=", "_safe_log", "(", "\n", "1", "-", "det_seg_heatmap_mat", ")", "*", "(", "det_seg_heatmap_mat", ">", "0", ")", "\n", "bg_loss_sum", "=", "np", ".", "tensordot", "(", "\n", "bg_seg_mat", ",", "bg_log_loss_mat", ",", "axes", "=", "(", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", ")", ")", "# g x d", "\n", "return", "bg_loss_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_fg_loss": [[215, 226], ["pdq._safe_log", "numpy.tensordot"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._safe_log"], ["", "def", "_calc_fg_loss", "(", "gt_seg_mat", ",", "det_seg_heatmap_mat", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the foreground pixel loss for all detections on all ground truth objects for a given image.\n    :param gt_seg_mat: h x w x g vectorized segmentation masks for each ground truth object in the image.\n    :param det_seg_heatmap_mat: h x w x d vectorized segmented heatmaps for each detection in the image.\n    :return: fg_loss_sum: g x d total foreground loss between each of the g ground truth objects and d detections.\n    \"\"\"", "\n", "log_heatmap_mat", "=", "_safe_log", "(", "det_seg_heatmap_mat", ")", "\n", "fg_loss_sum", "=", "np", ".", "tensordot", "(", "\n", "gt_seg_mat", ",", "log_heatmap_mat", ",", "axes", "=", "(", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", ")", ")", "# g x d", "\n", "return", "fg_loss_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._safe_log": [[228, 230], ["numpy.log"], "function", ["None"], ["", "def", "_safe_log", "(", "mat", ")", ":", "\n", "    ", "return", "np", ".", "log", "(", "mat", "+", "_SMALL_VAL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_spatial_qual": [[232, 253], ["numpy.exp", "numpy.isclose", "numpy.isclose"], "function", ["None"], ["", "def", "_calc_spatial_qual", "(", "fg_loss_sum", ",", "bg_loss_sum", ",", "num_fg_pixels_vec", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the spatial quality for all detections on all ground truth objects for a given image.\n    :param fg_loss_sum: g x d total foreground loss between each of the g ground truth objects and d detections.\n    :param bg_loss_sum: g x d total background loss between each of the g ground truth objects and d detections.\n    :param num_fg_pixels_vec: g x 1 number of pixels for each of the g ground truth objects.\n    :return: spatial_quality: g x d spatial quality score between zero and one for each possible combination of\n    g ground truth objects and d detections.\n    \"\"\"", "\n", "total_loss", "=", "fg_loss_sum", "+", "bg_loss_sum", "\n", "\n", "loss_per_gt_pixel", "=", "total_loss", "/", "num_fg_pixels_vec", "\n", "\n", "spatial_quality", "=", "np", ".", "exp", "(", "loss_per_gt_pixel", ")", "\n", "\n", "# Deal with tiny floating point errors or tiny errors caused by _SMALL_VAL", "\n", "# that prevent perfect 0 or 1 scores", "\n", "spatial_quality", "[", "np", ".", "isclose", "(", "spatial_quality", ",", "0", ")", "]", "=", "0", "\n", "spatial_quality", "[", "np", ".", "isclose", "(", "spatial_quality", ",", "1", ")", "]", "=", "1", "\n", "\n", "return", "spatial_quality", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_label_qual": [[255, 267], ["det_label_prob_mat[].T.astype"], "function", ["None"], ["", "def", "_calc_label_qual", "(", "gt_label_vec", ",", "det_label_prob_mat", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the label quality for all detections on all ground truth objects for a given image.\n    :param gt_label_vec:  g, numpy array containing the class label as an integer for each object.\n    :param det_label_prob_mat: d x c numpy array of label probability scores across all c classes\n    for each of the d detections.\n    :return: label_qual_mat: g x d label quality score between zero and one for each possible combination of\n    g ground truth objects and d detections.\n    \"\"\"", "\n", "label_qual_mat", "=", "det_label_prob_mat", "[", ":", ",", "gt_label_vec", "]", ".", "T", ".", "astype", "(", "\n", "np", ".", "float32", ")", "# g x d", "\n", "return", "label_qual_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_overall_qual": [[269, 288], ["numpy.dstack", "numpy.errstate", "scipy.stats.gmean"], "function", ["None"], ["", "def", "_calc_overall_qual", "(", "label_qual", ",", "spatial_qual", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the overall quality for all detections on all ground truth objects for a given image\n    :param label_qual: g x d label quality score between zero and one for each possible combination of\n    g ground truth objects and d detections.\n    :param spatial_qual: g x d spatial quality score between zero and one for each possible combination of\n    g ground truth objects and d detections.\n    :return: overall_qual_mat: g x d overall label quality between zero and one for each possible combination of\n    g ground truth objects and d detections.\n    \"\"\"", "\n", "combined_mat", "=", "np", ".", "dstack", "(", "(", "label_qual", ",", "spatial_qual", ")", ")", "\n", "\n", "# Calculate the geometric mean between label quality and spatial quality.", "\n", "# Note we ignore divide by zero warnings here for log(0) calculations", "\n", "# internally.", "\n", "with", "np", ".", "errstate", "(", "divide", "=", "'ignore'", ")", ":", "\n", "        ", "overall_qual_mat", "=", "gmean", "(", "combined_mat", ",", "axis", "=", "2", ")", "\n", "\n", "", "return", "overall_qual_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._gen_cost_tables": [[290, 327], ["max", "numpy.ones", "numpy.ones", "numpy.ones", "pdq._vectorize_img_gts", "pdq._vectorize_img_dets", "pdq._calc_label_qual", "pdq._calc_fg_loss", "pdq._calc_bg_loss", "pdq._calc_spatial_qual", "pdq._calc_overall_qual", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._vectorize_img_gts", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._vectorize_img_dets", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_label_qual", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_fg_loss", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_bg_loss", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_spatial_qual", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_overall_qual"], ["", "def", "_gen_cost_tables", "(", "gt_instances", ",", "det_instances", ")", ":", "\n", "    ", "\"\"\"\n    Generate the cost tables containing the cost values (1 - quality) for each combination of ground truth objects and\n    detections within a given image.\n    :param gt_instances: list of all GroundTruthInstances for a given image.\n    :param det_instances: list of all DetectionInstances for a given image.\n    :return: g x d overall cost table for each combination of ground truth objects and detections\n    \"\"\"", "\n", "n_pairs", "=", "max", "(", "len", "(", "gt_instances", ")", ",", "len", "(", "det_instances", ")", ")", "\n", "overall_cost_table", "=", "np", ".", "ones", "(", "(", "n_pairs", ",", "n_pairs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "spatial_cost_table", "=", "np", ".", "ones", "(", "(", "n_pairs", ",", "n_pairs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "label_cost_table", "=", "np", ".", "ones", "(", "(", "n_pairs", ",", "n_pairs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "img_shape", "=", "gt_instances", "[", "0", "]", ".", "segmentation_mask", ".", "shape", "\n", "\n", "# Generate all the matrices needed", "\n", "gt_seg_mat", ",", "bg_seg_mat", ",", "num_fg_pixels_vec", ",", "gt_label_vec", "=", "_vectorize_img_gts", "(", "\n", "gt_instances", ",", "img_shape", ")", "\n", "img_shape", "=", "gt_instances", "[", "0", "]", ".", "segmentation_mask", ".", "shape", "\n", "det_seg_heatmap_mat", ",", "det_label_prob_mat", "=", "_vectorize_img_dets", "(", "\n", "det_instances", ",", "img_shape", ")", "\n", "\n", "# Calculate all qualities", "\n", "label_qual_mat", "=", "_calc_label_qual", "(", "gt_label_vec", ",", "det_label_prob_mat", ")", "\n", "fg_loss", "=", "_calc_fg_loss", "(", "gt_seg_mat", ",", "det_seg_heatmap_mat", ")", "\n", "bg_loss", "=", "_calc_bg_loss", "(", "bg_seg_mat", ",", "det_seg_heatmap_mat", ")", "\n", "spatial_qual", "=", "_calc_spatial_qual", "(", "fg_loss", ",", "bg_loss", ",", "num_fg_pixels_vec", ")", "\n", "\n", "# Generate the overall cost table (1 - overall quality)", "\n", "overall_cost_table", "[", ":", "len", "(", "gt_instances", ")", ",", ":", "len", "(", "\n", "det_instances", ")", "]", "-=", "_calc_overall_qual", "(", "label_qual_mat", ",", "spatial_qual", ")", "\n", "\n", "# Generate the spatial and label cost tables", "\n", "spatial_cost_table", "[", ":", "len", "(", "gt_instances", ")", ",", ":", "len", "(", "det_instances", ")", "]", "-=", "spatial_qual", "\n", "label_cost_table", "[", ":", "len", "(", "gt_instances", ")", ",", ":", "len", "(", "det_instances", ")", "]", "-=", "label_qual_mat", "\n", "\n", "return", "{", "'overall'", ":", "overall_cost_table", ",", "'spatial'", ":", "spatial_cost_table", ",", "'label'", ":", "label_cost_table", "}", ",", "{", "\n", "'det_seg_heatmap_mat'", ":", "det_seg_heatmap_mat", ",", "'det_label_prob_mat'", ":", "det_label_prob_mat", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_qual_img": [[329, 452], ["pdq._gen_cost_tables", "scipy.optimize.linear_sum_assignment", "enumerate", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.array", "numpy.sum", "numpy.array", "zip", "numpy.array", "numpy.exp", "numpy.sum", "numpy.sum", "len", "len", "len", "enumerate", "len", "pdq._calc_overall_qual", "pdq._is_gt_included", "pdq._is_gt_included", "pdq._is_gt_included", "len", "false_positives_col_id.append", "numpy.max", "pdq._compute_bb_area", "numpy.sum", "len", "len", "pdq._safe_log"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._gen_cost_tables", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._calc_overall_qual", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._is_gt_included", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._is_gt_included", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._is_gt_included", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._compute_bb_area", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._safe_log"], ["", "def", "_calc_qual_img", "(", "gt_instances", ",", "det_instances", ")", ":", "\n", "    ", "\"\"\"\n    Calculates the sum of qualities for the best matches between ground truth objects and detections for an image.\n    Each ground truth object can only be matched to a single detection and vice versa as an object-detection pair.\n    Note that if a ground truth object or detection does not have a match, the quality is counted as zero.\n    This represents a theoretical object-detection pair with the object or detection and a counterpart which\n    does not describe it at all.\n    Any provided detection with a zero-quality match will be counted as a false positive (FP).\n    Any ground-truth object with a zero-quality match will be counted as a false negative (FN).\n    All other matches are counted as \"true positives\" (TP)\n    If there are no ground truth objects or detections for the image, the system returns zero and this image\n    will not contribute to average_PDQ.\n    :param gt_instances: list of GroundTruthInstance objects describing the ground truth objects in the current image.\n    :param det_instances: list of DetectionInstance objects describing the detections for the current image.\n    :return: results dictionary containing total overall spatial quality, total spatial quality on positively assigned\n    detections, total label quality on positively assigned detections, number of true positives,\n    number of false positives, and number false negatives for the given image.\n    Format {'overall':<tot_overall_quality>, 'spatial': <tot_tp_spatial_quality>, 'label': <tot_tp_label_quality>,\n    'TP': <num_true_positives>, 'FP': <num_false_positives>, 'FN': <num_false_positives>}\n    \"\"\"", "\n", "# if there are no detections or gt instances respectively the quality is", "\n", "# zero", "\n", "if", "len", "(", "gt_instances", ")", "==", "0", "or", "len", "(", "det_instances", ")", "==", "0", ":", "\n", "        ", "FN", "=", "0", "\n", "\n", "# Filter out GT instances which are to be ignored because they are too", "\n", "# small", "\n", "if", "len", "(", "gt_instances", ")", ">", "0", ":", "\n", "            ", "for", "gt_idx", ",", "gt_instance", "in", "enumerate", "(", "gt_instances", ")", ":", "\n", "                ", "if", "_is_gt_included", "(", "gt_instance", ")", ":", "\n", "                    ", "FN", "+=", "1", "\n", "\n", "", "", "", "return", "{", "\n", "'overall'", ":", "0.0", ",", "\n", "'spatial'", ":", "0.0", ",", "\n", "'label'", ":", "0.0", ",", "\n", "'TP'", ":", "0", ",", "\n", "'FP'", ":", "len", "(", "det_instances", ")", ",", "\n", "'FN'", ":", "FN", "}", "\n", "\n", "# For each possible pairing, calculate the quality of that pairing and convert it to a cost", "\n", "# to enable use of the Hungarian algorithm.", "\n", "", "cost_tables", ",", "detection_properties", "=", "_gen_cost_tables", "(", "\n", "gt_instances", ",", "det_instances", ")", "\n", "\n", "# Use the Hungarian algorithm with the cost table to find the best match between ground truth", "\n", "# object and detection (lowest overall cost representing highest overall", "\n", "# pairwise quality)", "\n", "row_idxs", ",", "col_idxs", "=", "linear_sum_assignment", "(", "cost_tables", "[", "'overall'", "]", ")", "\n", "\n", "# Transform the loss tables back into quality tables with values between 0", "\n", "# and 1", "\n", "overall_quality_table", "=", "1", "-", "cost_tables", "[", "'overall'", "]", "\n", "spatial_quality_table", "=", "1", "-", "cost_tables", "[", "'spatial'", "]", "\n", "label_quality_table", "=", "1", "-", "cost_tables", "[", "'label'", "]", "\n", "\n", "# Calculate the number of TPs, FPs, and FNs for the image.", "\n", "true_positives", "=", "0", "\n", "false_positives", "=", "0", "\n", "false_negatives", "=", "0", "\n", "false_positives_col_id", "=", "[", "]", "\n", "for", "match_idx", ",", "match", "in", "enumerate", "(", "zip", "(", "row_idxs", ",", "col_idxs", ")", ")", ":", "\n", "        ", "row_id", ",", "col_id", "=", "match", "\n", "if", "overall_quality_table", "[", "row_id", ",", "col_id", "]", ">", "0", ":", "\n", "            ", "if", "row_id", "<", "len", "(", "gt_instances", ")", "and", "_is_gt_included", "(", "\n", "gt_instances", "[", "row_id", "]", ")", ":", "\n", "                ", "true_positives", "+=", "1", "\n", "", "else", ":", "\n", "# ignore detections on samples which are too small to be", "\n", "# considered a valid object", "\n", "                ", "overall_quality_table", "[", "row_id", ",", "col_id", "]", "=", "0.0", "\n", "", "", "else", ":", "\n", "            ", "if", "row_id", "<", "len", "(", "gt_instances", ")", "and", "_is_gt_included", "(", "\n", "gt_instances", "[", "row_id", "]", ")", ":", "\n", "                ", "false_negatives", "+=", "1", "\n", "", "if", "col_id", "<", "len", "(", "det_instances", ")", ":", "\n", "                ", "false_positives", "+=", "1", "\n", "false_positives_col_id", ".", "append", "(", "col_id", ")", "\n", "\n", "# Calculate the sum of quality at the best matching pairs to calculate", "\n", "# total qualities for the image", "\n", "", "", "", "tot_tp_overall_img_quality", "=", "np", ".", "sum", "(", "\n", "overall_quality_table", "[", "row_idxs", ",", "col_idxs", "]", ")", "\n", "\n", "# Calculate the sum of spatial and label qualities only for TP samples", "\n", "spatial_quality_table", "[", "overall_quality_table", "==", "0", "]", "=", "0.0", "\n", "label_quality_table", "[", "overall_quality_table", "==", "0", "]", "=", "0.0", "\n", "tot_tp_spatial_quality", "=", "np", ".", "sum", "(", "spatial_quality_table", "[", "row_idxs", ",", "col_idxs", "]", ")", "\n", "tot_tp_label_quality", "=", "np", ".", "sum", "(", "label_quality_table", "[", "row_idxs", ",", "col_idxs", "]", ")", "\n", "\n", "# Calculate the penalty for assigning a high probability to false positives", "\n", "fp_label_quality_table", "=", "np", ".", "array", "(", "\n", "[", "1.0", "-", "np", ".", "max", "(", "detection_properties", "[", "'det_label_prob_mat'", "]", "[", "i", "]", ")", "for", "i", "in", "false_positives_col_id", "]", ")", "\n", "tot_fp_label_quality", "=", "np", ".", "sum", "(", "fp_label_quality_table", ")", "\n", "\n", "fp_heat_maps", "=", "np", ".", "array", "(", "\n", "[", "detection_properties", "[", "'det_seg_heatmap_mat'", "]", "[", ":", ",", ":", ",", "i", "]", "for", "i", "in", "false_positives_col_id", "]", ")", "\n", "if", "fp_label_quality_table", ".", "size", ":", "\n", "        ", "fp_det_area", "=", "np", ".", "array", "(", "[", "_compute_bb_area", "(", "det_instances", "[", "i", "]", ")", "\n", "for", "i", "in", "false_positives_col_id", "]", ")", "\n", "fp_spatial_quality_table", "=", "np", ".", "exp", "(", "np", ".", "sum", "(", "_safe_log", "(", "\n", "1", "-", "fp_heat_maps", ")", "*", "(", "fp_heat_maps", ">", "0", ")", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "/", "fp_det_area", ")", "\n", "\n", "tot_fp_spatial_quality", "=", "np", ".", "sum", "(", "fp_spatial_quality_table", ")", "\n", "tot_fp_overall_img_quality", "=", "np", ".", "sum", "(", "\n", "_calc_overall_qual", "(", "\n", "fp_spatial_quality_table", ",", "\n", "fp_label_quality_table", ")", ")", "\n", "", "else", ":", "\n", "        ", "tot_fp_spatial_quality", "=", "0.0", "\n", "tot_fp_overall_img_quality", "=", "0.0", "\n", "\n", "", "tot_label_quality", "=", "tot_tp_label_quality", "+", "tot_fp_label_quality", "\n", "tot_spatial_quality", "=", "tot_tp_spatial_quality", "+", "tot_fp_spatial_quality", "\n", "tot_overall_img_quality", "=", "tot_tp_overall_img_quality", "+", "tot_fp_overall_img_quality", "\n", "\n", "return", "{", "\n", "'overall'", ":", "tot_overall_img_quality", ",", "\n", "'spatial'", ":", "tot_spatial_quality", ",", "\n", "'label'", ":", "tot_label_quality", ",", "\n", "'TP'", ":", "true_positives", ",", "\n", "'FP'", ":", "false_positives", ",", "\n", "'FN'", ":", "false_negatives", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._compute_bb_area": [[454, 458], ["None"], "function", ["None"], ["", "def", "_compute_bb_area", "(", "det_instance", ")", ":", "\n", "    ", "bbox", "=", "det_instance", ".", "box", "\n", "area", "=", "(", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ")", "*", "(", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ")", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq._is_gt_included": [[460, 472], ["numpy.count_nonzero"], "function", ["None"], ["", "def", "_is_gt_included", "(", "gt_instance", ")", ":", "\n", "    ", "\"\"\"\n    Determines if a ground-truth instance is large enough to be considered valid for detection\n    :param gt_instance: GroundTruthInstance object being evaluated\n    :return: Boolean describing if the object is valid for detection\n    \"\"\"", "\n", "return", "(", "\n", "gt_instance", ".", "bounding_box", "[", "2", "]", "-", "\n", "gt_instance", ".", "bounding_box", "[", "0", "]", ">", "10", ")", "and", "(", "\n", "gt_instance", ".", "bounding_box", "[", "3", "]", "-", "\n", "gt_instance", ".", "bounding_box", "[", "1", "]", ">", "10", ")", "and", "np", ".", "count_nonzero", "(", "\n", "gt_instance", ".", "segmentation_mask", ")", ">", "100", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.GroundTruthInstance.__init__": [[14, 39], ["pdq_data_holders.generate_bounding_box_from_mask", "numpy.count_nonzero", "len"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.generate_bounding_box_from_mask"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "segmentation_mask", ",", "\n", "true_class_label", ",", "\n", "image_id", ",", "\n", "instance_id", ",", "\n", "bounding_box", "=", "None", ",", "\n", "num_pixels", "=", "None", ")", ":", "\n", "        ", "self", ".", "segmentation_mask", "=", "segmentation_mask", "\n", "self", ".", "class_label", "=", "true_class_label", "\n", "self", ".", "image_id", "=", "image_id", "\n", "self", ".", "instance_id", "=", "instance_id", "\n", "\n", "if", "bounding_box", "is", "not", "None", "and", "len", "(", "bounding_box", ")", ">", "0", ":", "\n", "            ", "self", ".", "bounding_box", "=", "bounding_box", "\n", "", "else", ":", "\n", "            ", "self", ".", "bounding_box", "=", "generate_bounding_box_from_mask", "(", "\n", "segmentation_mask", ")", "\n", "", "if", "num_pixels", "is", "not", "None", "and", "num_pixels", ">", "0", ":", "\n", "            ", "self", ".", "num_pixels", "=", "num_pixels", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_pixels", "=", "np", ".", "count_nonzero", "(", "segmentation_mask", ")", "\n", "# Calculate the number of pixels in the ground-truth bounding box (length x height)", "\n", "", "self", ".", "num_bbox_pixels", "=", "(", "self", ".", "bounding_box", "[", "2", "]", "+", "1", "-", "self", ".", "bounding_box", "[", "0", "]", ")", "*", "(", "self", ".", "bounding_box", "[", "3", "]", "+", "1", "-", "self", ".", "bounding_box", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.DetectionInstance.__init__": [[41, 44], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "class_list", ",", "heatmap", "=", "None", ")", ":", "\n", "        ", "self", ".", "_heatmap", "=", "heatmap", "\n", "self", ".", "class_list", "=", "class_list", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.DetectionInstance.calc_heatmap": [[45, 47], ["None"], "methods", ["None"], ["", "def", "calc_heatmap", "(", "self", ",", "img_size", ")", ":", "\n", "        ", "return", "self", ".", "_heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.DetectionInstance.get_max_class": [[48, 50], ["numpy.argmax"], "methods", ["None"], ["", "def", "get_max_class", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "argmax", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.DetectionInstance.get_max_score": [[51, 53], ["numpy.amax"], "methods", ["None"], ["", "def", "get_max_score", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "amax", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.BBoxDetInst.__init__": [[56, 67], ["pdq_data_holders.DetectionInstance.__init__"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "class_list", ",", "box", ",", "pos_prob", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Initialisation function for a BBox detection instance\n        :param class_list: list of class probabilities for the detection\n        :param box: list of box corners that contain the object detected (inclusively).\n        Formatted [x1, y1, x2, y2]\n        :param pos_prob: float depicting the positional confidence\n        \"\"\"", "\n", "super", "(", "BBoxDetInst", ",", "self", ")", ".", "__init__", "(", "class_list", ")", "\n", "self", ".", "box", "=", "box", "\n", "self", ".", "pos_prob", "=", "pos_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.BBoxDetInst.calc_heatmap": [[68, 90], ["numpy.zeros", "numpy.ceil().astype", "numpy.floor().astype", "numpy.ceil", "numpy.floor", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min"], "methods", ["None"], ["", "def", "calc_heatmap", "(", "self", ",", "img_size", ")", ":", "\n", "        ", "heatmap", "=", "np", ".", "zeros", "(", "img_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "self", ".", "box", "\n", "x1_c", ",", "y1_c", "=", "np", ".", "ceil", "(", "self", ".", "box", "[", "0", ":", "2", "]", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "x2_f", ",", "y2_f", "=", "np", ".", "floor", "(", "self", ".", "box", "[", "2", ":", "]", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "# Even if the cordinates are integers, there should always be a range", "\n", "x1_f", "=", "x1_c", "-", "1", "\n", "y1_f", "=", "y1_c", "-", "1", "\n", "x2_c", "=", "x2_f", "+", "1", "\n", "y2_c", "=", "y2_f", "+", "1", "\n", "\n", "heatmap", "[", "max", "(", "y1_f", ",", "0", ")", ":", "min", "(", "y2_c", "+", "1", ",", "img_size", "[", "0", "]", ")", ",", "\n", "max", "(", "x1_f", ",", "0", ")", ":", "min", "(", "x2_c", "+", "1", ",", "img_size", "[", "1", "]", ")", "]", "=", "self", ".", "pos_prob", "\n", "if", "y1_f", ">=", "0", ":", "\n", "            ", "heatmap", "[", "y1_f", ",", "max", "(", "x1_f", ",", "0", ")", ":", "min", "(", "x2_c", "+", "1", ",", "img_size", "[", "1", "]", ")", "]", "*=", "y1_c", "-", "y1", "\n", "", "if", "y2_c", "<", "img_size", "[", "0", "]", ":", "\n", "            ", "heatmap", "[", "y2_c", ",", "max", "(", "x1_f", ",", "0", ")", ":", "min", "(", "x2_c", "+", "1", ",", "img_size", "[", "1", "]", ")", "]", "*=", "y2", "-", "y2_f", "\n", "", "if", "x1_f", ">=", "0", ":", "\n", "            ", "heatmap", "[", "max", "(", "y1_f", ",", "0", ")", ":", "min", "(", "y2_c", "+", "1", ",", "img_size", "[", "0", "]", ")", ",", "x1_f", "]", "*=", "x1_c", "-", "x1", "\n", "", "if", "x2_c", "<", "img_size", "[", "1", "]", ":", "\n", "            ", "heatmap", "[", "max", "(", "y1_f", ",", "0", ")", ":", "min", "(", "y2_c", "+", "1", ",", "img_size", "[", "0", "]", ")", ",", "x2_c", "]", "*=", "x2", "-", "x2_f", "\n", "", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.PBoxDetInst.__init__": [[93, 105], ["pdq_data_holders.DetectionInstance.__init__"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "class_list", ",", "box", ",", "covs", ")", ":", "\n", "        ", "\"\"\"\n        Initialisation function for a PBox detection instance\n        :param class_list: list of class probabilities for the detection\n        :param box: list of BBox corners, used to define the Gaussian corner mean locations for the box.\n        Formatted [x1, y1, x2, y2]\n        :param covs: list of two 2D covariance matrices used to define the covariances of the Gaussian corners.\n        Formatted [cov1, cov2] where cov1 and cov2 are formatted [[var_x, corr], [corr, var_y]]\n        \"\"\"", "\n", "super", "(", "PBoxDetInst", ",", "self", ")", ".", "__init__", "(", "class_list", ")", "\n", "self", ".", "box", "=", "box", "\n", "self", ".", "covs", "=", "covs", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.PBoxDetInst.calc_heatmap": [[106, 131], ["pdq_data_holders.gen_single_heatmap", "pdq_data_holders.gen_single_heatmap", "numpy.fliplr", "numpy.flipud", "numpy.flipud", "numpy.fliplr", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.gen_single_heatmap", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.gen_single_heatmap"], ["", "def", "calc_heatmap", "(", "self", ",", "img_size", ")", ":", "\n", "\n", "# get all covs in format (y,x) to match matrix ordering", "\n", "        ", "covs2", "=", "[", "np", ".", "flipud", "(", "np", ".", "fliplr", "(", "cov", ")", ")", "for", "cov", "in", "self", ".", "covs", "]", "\n", "\n", "prob1", "=", "gen_single_heatmap", "(", "\n", "img_size", ",", "[", "self", ".", "box", "[", "1", "]", ",", "self", ".", "box", "[", "0", "]", "]", ",", "covs2", "[", "0", "]", ")", "\n", "prob2", "=", "gen_single_heatmap", "(", "img_size", ",", "\n", "[", "img_size", "[", "0", "]", "-", "(", "self", ".", "box", "[", "3", "]", "+", "1", ")", ",", "\n", "img_size", "[", "1", "]", "-", "(", "self", ".", "box", "[", "2", "]", "+", "1", ")", "]", ",", "\n", "np", ".", "array", "(", "covs2", "[", "1", "]", ")", ".", "T", ")", "\n", "# flip left-right and up-down to provide probability in from", "\n", "# bottom-right corner", "\n", "prob2", "=", "np", ".", "fliplr", "(", "np", ".", "flipud", "(", "prob2", ")", ")", "\n", "\n", "# generate final heatmap", "\n", "heatmap", "=", "prob1", "*", "prob2", "\n", "\n", "# Hack to enforce that there are no pixels with probs greater than 1", "\n", "# due to floating point errors", "\n", "heatmap", "[", "heatmap", ">", "1", "]", "=", "1", "\n", "\n", "heatmap", "[", "heatmap", "<", "_HEATMAP_THRESH", "]", "=", "0", "\n", "\n", "return", "heatmap", "\n", "", "", "1", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.find_roi": [[133, 193], ["int", "int", "int", "int", "numpy.indices().T.reshape", "scipy.spatial.distance.cdist", "max", "max", "pdq_data_holders.generate_bounding_box_from_mask", "max", "max", "min", "min", "numpy.abs", "max", "max", "numpy.array", "scipy.spatial.distance.cdist.reshape", "min", "min", "max", "numpy.linalg.det", "max", "max", "numpy.linalg.inv", "int", "int", "numpy.indices"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.generate_bounding_box_from_mask"], ["def", "find_roi", "(", "img_size", ",", "mean", ",", "cov", ")", ":", "\n", "    ", "\"\"\"\n    Function for finding the region of interest for a probability heatmap generated by a Gaussian corner.\n    This region of interest is the area with most change therein, with probabilities above 0.0027 and below 0.9973\n    :param img_size: tuple: formatted (n_rows, n_cols) depicting the size of the image\n    :param mean: list: formatted [mu_y, mu_x] describes the location of the mean of the Gaussian corner.\n    :param cov: 2D array: formatted [[var_y, corr], [corr, var_x]] describes the covariance of the Gaussian corner.\n    :return: roi_box formatted [x1, y1, x2, y2] depicting the corners of the region of interest (inclusive)\n    \"\"\"", "\n", "\n", "# Calculate approximate ROI", "\n", "stdy", "=", "cov", "[", "0", ",", "0", "]", "**", "0.5", "\n", "stdx", "=", "cov", "[", "1", ",", "1", "]", "**", "0.5", "\n", "\n", "minx", "=", "int", "(", "max", "(", "mean", "[", "1", "]", "-", "stdx", "*", "5", ",", "0", ")", ")", "\n", "miny", "=", "int", "(", "max", "(", "mean", "[", "0", "]", "-", "stdy", "*", "5", ",", "0", ")", ")", "\n", "maxx", "=", "int", "(", "min", "(", "mean", "[", "1", "]", "+", "stdx", "*", "5", ",", "img_size", "[", "1", "]", "-", "1", ")", ")", "\n", "maxy", "=", "int", "(", "min", "(", "mean", "[", "0", "]", "+", "stdy", "*", "5", ",", "img_size", "[", "0", "]", "-", "1", ")", ")", "\n", "\n", "# If the covariance is singular, we can't do any better in our estimate.", "\n", "if", "np", ".", "abs", "(", "np", ".", "linalg", ".", "det", "(", "cov", ")", ")", "<", "1e-8", ":", "\n", "        ", "return", "minx", ",", "miny", ",", "max", "(", "0", ",", "maxx", ")", ",", "max", "(", "0", ",", "maxy", ")", "\n", "\n", "# produce list of positions [y,x] to compare to the given mean location", "\n", "", "approx_roi_shape", "=", "(", "max", "(", "maxy", "+", "1", "-", "miny", ",", "1", ")", ",", "max", "(", "maxx", "+", "1", "-", "minx", ",", "1", ")", ")", "\n", "positions", "=", "np", ".", "indices", "(", "approx_roi_shape", ")", ".", "T", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "positions", "[", ":", ",", "0", "]", "+=", "miny", "\n", "positions", "[", ":", ",", "1", "]", "+=", "minx", "\n", "# Calculate the mahalanobis distances to those locations (number of standard deviations)", "\n", "# Can only do this for non-singular matrices", "\n", "mdists", "=", "cdist", "(", "\n", "positions", ",", "\n", "np", ".", "array", "(", "\n", "[", "mean", "]", ")", ",", "\n", "metric", "=", "'mahalanobis'", ",", "\n", "VI", "=", "np", ".", "linalg", ".", "inv", "(", "cov", ")", ")", "\n", "mdists", "=", "mdists", ".", "reshape", "(", "approx_roi_shape", "[", "1", "]", ",", "approx_roi_shape", "[", "0", "]", ")", ".", "T", "\n", "\n", "# Shift around the mean to change which corner of the pixel we're using", "\n", "# for the mahalanobis distance", "\n", "dist_meany", "=", "max", "(", "min", "(", "int", "(", "mean", "[", "0", "]", "-", "miny", ")", ",", "img_size", "[", "0", "]", "-", "1", ")", ",", "0", ")", "\n", "dist_meanx", "=", "max", "(", "min", "(", "int", "(", "mean", "[", "1", "]", "-", "minx", ")", ",", "img_size", "[", "1", "]", "-", "1", ")", ",", "0", ")", "\n", "if", "0", "<", "dist_meany", "<", "img_size", "[", "0", "]", "-", "1", ":", "\n", "        ", "mdists", "[", ":", "dist_meany", ",", ":", "]", "=", "mdists", "[", "1", ":", "dist_meany", "+", "1", ",", ":", "]", "\n", "", "if", "0", "<", "dist_meanx", "<", "img_size", "[", "1", "]", "-", "1", ":", "\n", "        ", "mdists", "[", ":", ",", ":", "dist_meanx", "]", "=", "mdists", "[", ":", ",", "1", ":", "dist_meanx", "+", "1", "]", "\n", "\n", "# Mask out samples that are outside the desired distance (extremely low", "\n", "# probability points)", "\n", "", "mask", "=", "mdists", "<=", "_2D_MAH_DIST_THRESH", "\n", "# Force the pixel containing the mean to be true, we always care about that", "\n", "mask", "[", "dist_meany", ",", "dist_meanx", "]", "=", "True", "\n", "roi_box", "=", "generate_bounding_box_from_mask", "(", "mask", ")", "\n", "\n", "roi_box_out", "=", "[", "roi_box", "[", "0", "]", "+", "minx", ",", "roi_box", "[", "1", "]", "+", "miny", ",", "roi_box", "[", "2", "]", "+", "minx", ",", "roi_box", "[", "3", "]", "+", "miny", "]", "\n", "\n", "roi_box_out", "=", "[", "max", "(", "0", ",", "roi_dim", ")", "for", "roi_dim", "in", "roi_box_out", "]", "\n", "\n", "return", "roi_box_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.gen_single_heatmap": [[195, 257], ["numpy.zeros", "scipy.stats.multivariate_normal", "pdq_data_holders.find_roi", "scipy.stats.multivariate_normal.cdf", "numpy.array", "numpy.dstack", "len", "numpy.array", "numpy.zeros", "scipy.stats.multivariate_normal.cdf", "numpy.zeros", "scipy.stats.multivariate_normal.cdf", "scipy.stats.multivariate_normal.cdf", "numpy.dstack", "numpy.dstack", "numpy.np.array().T"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.find_roi"], ["", "def", "gen_single_heatmap", "(", "img_size", ",", "mean", ",", "cov", ")", ":", "\n", "    ", "\"\"\"\n    Function for generating the heatmap for a given Gaussian corner.\n    :param img_size: tuple: formatted (n_rows, n_cols) depicting the size of the image\n    :param mean: list: formatted [mu_y, mu_x] describes the location of the mean of the Gaussian corner.\n    :param cov: 2D array: formatted [[var_y, corr], [corr, var_x]] describes the covariance of the Gaussian corner.\n    :return: heatmap image of size <img_size> with spatial probabilities between 0 and 1.\n    \"\"\"", "\n", "heatmap", "=", "np", ".", "zeros", "(", "img_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "g", "=", "multivariate_normal", "(", "mean", "=", "mean", ",", "cov", "=", "cov", ",", "allow_singular", "=", "True", ")", "\n", "\n", "roi_box", "=", "find_roi", "(", "img_size", ",", "mean", ",", "cov", ")", "\n", "# Note that we subtract small value to avoid fencepost issues with", "\n", "# extremely low covariances.", "\n", "positions", "=", "np", ".", "dstack", "(", "\n", "np", ".", "mgrid", "[", "roi_box", "[", "1", "]", "+", "1", ":", "roi_box", "[", "3", "]", "+", "2", ",", "roi_box", "[", "0", "]", "+", "1", ":", "roi_box", "[", "2", "]", "+", "2", "]", ")", "-", "_SMALL_VAL", "\n", "\n", "prob", "=", "g", ".", "cdf", "(", "positions", ")", "\n", "\n", "if", "len", "(", "prob", ".", "shape", ")", "==", "1", ":", "\n", "        ", "prob", ".", "shape", "=", "(", "roi_box", "[", "3", "]", "+", "1", "-", "roi_box", "[", "1", "]", ",", "roi_box", "[", "2", "]", "+", "1", "-", "roi_box", "[", "0", "]", ")", "\n", "\n", "", "heatmap", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "1", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", "=", "prob", "\n", "heatmap", "[", "roi_box", "[", "3", "]", ":", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", "=", "np", ".", "array", "(", "heatmap", "[", "roi_box", "[", "3", "]", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", ",", "ndmin", "=", "2", ")", "\n", "heatmap", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "\n", "1", ",", "roi_box", "[", "2", "]", ":", "]", "=", "np", ".", "array", "(", "heatmap", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "\n", "1", ",", "roi_box", "[", "2", "]", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "heatmap", "[", "roi_box", "[", "3", "]", "+", "1", ":", ",", "roi_box", "[", "2", "]", "+", "1", ":", "]", "=", "1.0", "\n", "\n", "# If your region of interest includes outside the main image, remove probability of existing outside the image", "\n", "# Remove probability of being outside in the x direction", "\n", "if", "roi_box", "[", "0", "]", "==", "0", ":", "\n", "# points left of the image", "\n", "        ", "pos_outside_x", "=", "np", ".", "dstack", "(", "\n", "np", ".", "mgrid", "[", "roi_box", "[", "1", "]", "+", "1", ":", "roi_box", "[", "3", "]", "+", "2", ",", "0", ":", "1", "]", ")", "-", "_SMALL_VAL", "\n", "prob_outside_x", "=", "np", ".", "zeros", "(", "(", "img_size", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "prob_outside_x", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "1", ",", "0", "]", "=", "g", ".", "cdf", "(", "pos_outside_x", ")", "\n", "prob_outside_x", "[", "roi_box", "[", "3", "]", "+", "1", ":", ",", "0", "]", "=", "prob_outside_x", "[", "roi_box", "[", "3", "]", ",", "0", "]", "\n", "# Final probability is your overall cdf minus the probability in-line with that point along", "\n", "# the border for both dimensions plus the cdf at (-1, -1) which has", "\n", "# points counted twice otherwise", "\n", "heatmap", "-=", "prob_outside_x", "\n", "\n", "# Remove probability of being outside in the x direction", "\n", "", "if", "roi_box", "[", "1", "]", "==", "0", ":", "\n", "# points above the image", "\n", "        ", "pos_outside_y", "=", "np", ".", "dstack", "(", "\n", "np", ".", "mgrid", "[", "0", ":", "1", ",", "roi_box", "[", "0", "]", "+", "1", ":", "roi_box", "[", "2", "]", "+", "2", "]", ")", "-", "_SMALL_VAL", "\n", "prob_outside_y", "=", "np", ".", "zeros", "(", "(", "1", ",", "img_size", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "prob_outside_y", "[", "0", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", "=", "g", ".", "cdf", "(", "pos_outside_y", ")", "\n", "prob_outside_y", "[", "0", ",", "roi_box", "[", "2", "]", "+", "1", ":", "]", "=", "prob_outside_y", "[", "0", ",", "roi_box", "[", "2", "]", "]", "\n", "heatmap", "-=", "prob_outside_y", "\n", "\n", "# If we've subtracted twice, we need to re-add the probability of the far", "\n", "# corner", "\n", "", "if", "roi_box", "[", "0", "]", "==", "0", "and", "roi_box", "[", "1", "]", "==", "0", ":", "\n", "        ", "heatmap", "+=", "g", ".", "cdf", "(", "[", "[", "[", "0", "-", "_SMALL_VAL", ",", "0", "-", "_SMALL_VAL", "]", "]", "]", ")", "\n", "\n", "", "heatmap", "[", "heatmap", "<", "_HEATMAP_THRESH", "]", "=", "0", "\n", "\n", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.generate_bounding_box_from_mask": [[259, 270], ["numpy.any", "numpy.any", "numpy.argmax", "numpy.argmax", "ValueError", "numpy.argmax", "numpy.argmax", "numpy.any", "numpy.any", "len", "len"], "function", ["None"], ["", "def", "generate_bounding_box_from_mask", "(", "mask", ")", ":", "\n", "    ", "flat_x", "=", "np", ".", "any", "(", "mask", ",", "axis", "=", "0", ")", "\n", "flat_y", "=", "np", ".", "any", "(", "mask", ",", "axis", "=", "1", ")", "\n", "if", "not", "np", ".", "any", "(", "flat_x", ")", "and", "not", "np", ".", "any", "(", "flat_y", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"No positive pixels found, cannot compute bounding box\"", ")", "\n", "", "xmin", "=", "np", ".", "argmax", "(", "flat_x", ")", "\n", "ymin", "=", "np", ".", "argmax", "(", "flat_y", ")", "\n", "xmax", "=", "len", "(", "flat_x", ")", "-", "1", "-", "np", ".", "argmax", "(", "flat_x", "[", ":", ":", "-", "1", "]", ")", "\n", "ymax", "=", "len", "(", "flat_y", ")", "-", "1", "-", "np", ".", "argmax", "(", "flat_y", "[", ":", ":", "-", "1", "]", ")", "\n", "return", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.bb_iou": [[272, 298], ["max", "max", "min", "min", "max", "max", "float"], "function", ["None"], ["", "def", "bb_iou", "(", "boxA", ",", "boxB", ")", ":", "\n", "# Code from online source", "\n", "# https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "\n", "\n", "# determine the (x, y)-coordinates of the intersection rectangle", "\n", "# Assumes boxes input in format [[xmin,ymin],[xmax,ymax]]", "\n", "    ", "xA", "=", "max", "(", "boxA", "[", "0", "]", ",", "boxB", "[", "0", "]", ")", "\n", "yA", "=", "max", "(", "boxA", "[", "1", "]", ",", "boxB", "[", "1", "]", ")", "\n", "xB", "=", "min", "(", "boxA", "[", "2", "]", ",", "boxB", "[", "2", "]", ")", "\n", "yB", "=", "min", "(", "boxA", "[", "3", "]", ",", "boxB", "[", "3", "]", ")", "\n", "\n", "# compute the area of intersection rectangle", "\n", "interArea", "=", "max", "(", "0", ",", "(", "xB", "-", "xA", ")", "+", "1", ")", "*", "max", "(", "0", ",", "(", "yB", "-", "yA", ")", "+", "1", ")", "\n", "\n", "# compute the area of both the prediction and ground-truth", "\n", "# rectangles", "\n", "boxAArea", "=", "(", "(", "boxA", "[", "2", "]", "-", "boxA", "[", "0", "]", ")", "+", "1", ")", "*", "(", "(", "boxA", "[", "3", "]", "-", "boxA", "[", "1", "]", ")", "+", "1", ")", "\n", "boxBArea", "=", "(", "(", "boxB", "[", "2", "]", "-", "boxB", "[", "0", "]", ")", "+", "1", ")", "*", "(", "(", "boxB", "[", "3", "]", "-", "boxB", "[", "1", "]", ")", "+", "1", ")", "\n", "\n", "# compute the intersection over union by taking the intersection", "\n", "# area and dividing it by the sum of prediction + ground-truth", "\n", "# areas - the interesection area", "\n", "iou", "=", "interArea", "/", "float", "(", "boxAArea", "+", "boxBArea", "-", "interArea", ")", "\n", "\n", "# return the intersection over union value", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.put_image_in_centre_of_other_image": [[300, 324], ["int", "int", "int", "int", "img1.copy"], "function", ["None"], ["", "def", "put_image_in_centre_of_other_image", "(", "img1", ",", "img2", ",", "add", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Code to add a mask to the centre of a given image (both 2D at the moment)\n    :param img1: image to be putting other image in the centre of\n    :param img2: image to put in the centre of another image\n    :param add: flag as to whether to add the image to the centre of the other one or replace all pixels\n    :return: Final image with img2 now in the centre of img1\n    \"\"\"", "\n", "\n", "borderx_size", "=", "(", "img1", ".", "shape", "[", "1", "]", "-", "img2", ".", "shape", "[", "1", "]", ")", "/", "2", "\n", "bordery_size", "=", "(", "img1", ".", "shape", "[", "0", "]", "-", "img2", ".", "shape", "[", "0", "]", ")", "/", "2", "\n", "\n", "x1", "=", "int", "(", "borderx_size", ")", "\n", "x2", "=", "int", "(", "borderx_size", "+", "img2", ".", "shape", "[", "1", "]", ")", "\n", "y1", "=", "int", "(", "bordery_size", ")", "\n", "y2", "=", "int", "(", "bordery_size", "+", "img2", ".", "shape", "[", "0", "]", ")", "\n", "\n", "new_img", "=", "img1", ".", "copy", "(", ")", "\n", "if", "add", ":", "\n", "        ", "new_img", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "+=", "img2", "\n", "", "else", ":", "\n", "        ", "new_img", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "=", "img2", "\n", "\n", "", "return", "new_img", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.getFromDict": [[326, 328], ["functools.reduce"], "function", ["None"], ["", "def", "getFromDict", "(", "dataDict", ",", "mapList", ")", ":", "\n", "    ", "return", "reduce", "(", "operator", ".", "getitem", ",", "mapList", ",", "dataDict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.setInDict": [[330, 332], ["pdq_data_holders.getFromDict"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.offline_eval.pdq_data_holders.getFromDict"], ["", "def", "setInDict", "(", "dataDict", ",", "mapList", ",", "value", ")", ":", "\n", "    ", "getFromDict", "(", "dataDict", ",", "mapList", "[", ":", "-", "1", "]", ")", "[", "mapList", "[", "-", "1", "]", "]", "=", "value", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.retinanet_model.RetinaNetModel.__init__": [[19, 66], ["keras.Model.__init__", "src.core.losses.SoftmaxFocalLoss", "keras.losses.Huber", "tensorflow.name_scope", "src.retina_net.models.feature_extractor.FeatureExtractor", "tensorflow.name_scope", "src.retina_net.models.feature_decoder.FeatureDecoder", "tensorflow.name_scope", "src.retina_net.models.multitask_headers.ClsHeader", "tensorflow.name_scope", "src.retina_net.models.multitask_headers.RegHeader", "tensorflow.name_scope", "src.retina_net.models.multitask_headers.CovHeader"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_config", ")", ":", "\n", "        ", "super", "(", "RetinaNetModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "prediction_dict", "=", "None", "\n", "\n", "# Create loss instants", "\n", "loss_config", "=", "model_config", "[", "'losses'", "]", "\n", "self", ".", "focal_loss", "=", "SoftmaxFocalLoss", "(", "\n", "gamma", "=", "2.0", ",", "\n", "label_smoothing_epsilon", "=", "loss_config", "[", "'label_smoothing_epsilon'", "]", ",", "\n", "reduction", "=", "keras", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "\n", "self", ".", "huber_loss", "=", "keras", ".", "losses", ".", "Huber", "(", "\n", "reduction", "=", "keras", ".", "losses", ".", "Reduction", ".", "NONE", ",", "name", "=", "'huber_loss'", ")", "\n", "\n", "self", ".", "loss_names", "=", "loss_config", "[", "'loss_names'", "]", "\n", "self", ".", "loss_weights", "=", "loss_config", "[", "'loss_weights'", "]", "\n", "\n", "# Feature Extractor", "\n", "with", "tf", ".", "name_scope", "(", "model_config", "[", "'feature_extractor'", "]", "[", "'name'", "]", ")", ":", "\n", "            ", "self", ".", "feature_extractor", "=", "FeatureExtractor", "(", "\n", "model_config", "[", "'feature_extractor'", "]", ")", "\n", "\n", "# Feature Decoder", "\n", "", "with", "tf", ".", "name_scope", "(", "model_config", "[", "'feature_extractor'", "]", "[", "'name'", "]", ")", ":", "\n", "            ", "self", ".", "feature_decoder", "=", "FeatureDecoder", "(", "\n", "model_config", "[", "'feature_decoder'", "]", ")", "\n", "\n", "# Headers", "\n", "", "self", ".", "compute_cls", "=", "'classification'", "in", "model_config", "[", "'output_names'", "]", "\n", "self", ".", "compute_reg", "=", "'regression'", "in", "model_config", "[", "'output_names'", "]", "\n", "self", ".", "compute_covar", "=", "'regression_covar'", "in", "model_config", "[", "'output_names'", "]", "\n", "\n", "if", "self", ".", "compute_cls", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'classification_header'", ")", ":", "\n", "                ", "self", ".", "cls_header", "=", "ClsHeader", "(", "\n", "model_config", "[", "'header'", "]", ")", "\n", "", "", "if", "self", ".", "compute_reg", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'regression_header'", ")", ":", "\n", "                ", "self", ".", "reg_header", "=", "RegHeader", "(", "\n", "model_config", "[", "'header'", "]", ")", "\n", "", "", "if", "self", ".", "compute_covar", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'covariance_header'", ")", ":", "\n", "                ", "self", ".", "cov_header", "=", "CovHeader", "(", "\n", "model_config", "[", "'header'", "]", ")", "\n", "\n", "", "", "self", ".", "mc_dropout_samples", "=", "model_config", "[", "'mc_dropout_samples'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.retinanet_model.RetinaNetModel.call": [[67, 150], ["dict", "retinanet_model.RetinaNetModel.feature_extractor", "retinanet_model.RetinaNetModel.feature_decoder", "tensorflow.tile", "tensorflow.concat", "retinanet_model.RetinaNetModel.prediction_dict.update", "tensorflow.concat", "retinanet_model.RetinaNetModel.prediction_dict.update", "tensorflow.concat", "tensorflow_probability.math.fill_triangular", "retinanet_model.RetinaNetModel.prediction_dict.update", "tensorflow.concat", "retinanet_model.RetinaNetModel.prediction_dict.update", "tensorflow.concat", "retinanet_model.RetinaNetModel.prediction_dict.update", "tensorflow.concat", "tensorflow_probability.math.fill_triangular", "retinanet_model.RetinaNetModel.prediction_dict.update", "retinanet_model.RetinaNetModel.cls_header", "retinanet_model.RetinaNetModel.reg_header", "retinanet_model.RetinaNetModel.cov_header", "retinanet_model.RetinaNetModel.cls_header", "retinanet_model.RetinaNetModel.reg_header", "retinanet_model.RetinaNetModel.cov_header"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "train_val_test", "=", "'training'", ")", ":", "\n", "\n", "        ", "self", ".", "prediction_dict", "=", "dict", "(", ")", "\n", "map_5", ",", "map_4", ",", "map_3", "=", "self", ".", "feature_extractor", "(", "input_tensor", ")", "\n", "decoder_pyramid_layers", "=", "self", ".", "feature_decoder", "(", "map_5", ",", "map_4", ",", "map_3", ")", "\n", "\n", "if", "train_val_test", "==", "'testing'", ":", "\n", "            ", "if", "self", ".", "mc_dropout_samples", ">", "1.0", ":", "\n", "                ", "mc_dropout_enabled", "=", "True", "\n", "", "else", ":", "\n", "                ", "mc_dropout_enabled", "=", "False", "\n", "", "decoder_pyramid_layers", "=", "[", "\n", "tf", ".", "tile", "(", "\n", "layer", ",", "[", "\n", "self", ".", "mc_dropout_samples", ",", "1", ",", "1", ",", "1", "]", ")", "for", "layer", "in", "decoder_pyramid_layers", "]", "\n", "if", "self", ".", "compute_cls", ":", "\n", "                ", "cls_out_list", "=", "[", "\n", "self", ".", "cls_header", "(", "\n", "pyramid_layer", ",", "\n", "mc_dropout_enabled", ")", "for", "pyramid_layer", "in", "\n", "decoder_pyramid_layers", "]", "\n", "\n", "cls_out", "=", "tf", ".", "concat", "(", "cls_out_list", ",", "axis", "=", "1", ")", "\n", "self", ".", "prediction_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_CLASS_PREDICTIONS_KEY", ":", "cls_out", "}", ")", "\n", "\n", "", "if", "self", ".", "compute_reg", ":", "\n", "                ", "reg_out_list", "=", "[", "\n", "self", ".", "reg_header", "(", "\n", "pyramid_layer", ",", "\n", "mc_dropout_enabled", ")", "for", "pyramid_layer", "in", "\n", "decoder_pyramid_layers", "]", "\n", "reg_out", "=", "tf", ".", "concat", "(", "reg_out_list", ",", "axis", "=", "1", ")", "\n", "self", ".", "prediction_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_BOX_PREDICTIONS_KEY", ":", "reg_out", "}", ")", "\n", "\n", "", "if", "self", ".", "compute_covar", ":", "\n", "                ", "covar_out_list", "=", "[", "\n", "self", ".", "cov_header", "(", "\n", "pyramid_layer", ",", "\n", "mc_dropout_enabled", ")", "for", "pyramid_layer", "in", "\n", "decoder_pyramid_layers", "]", "\n", "covar_out", "=", "tf", ".", "concat", "(", "covar_out_list", ",", "axis", "=", "1", ")", "\n", "covar_out", "=", "tfp", ".", "math", ".", "fill_triangular", "(", "covar_out", ")", "\n", "self", ".", "prediction_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_COVAR_PREDICTIONS_KEY", ":", "covar_out", "}", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "train_val_test", "==", "'training'", ":", "\n", "                ", "mc_dropout_enabled", "=", "True", "\n", "", "else", ":", "\n", "                ", "mc_dropout_enabled", "=", "False", "\n", "\n", "", "if", "self", ".", "compute_cls", ":", "\n", "                ", "cls_out_list", "=", "[", "\n", "self", ".", "cls_header", "(", "\n", "pyramid_layer", ",", "\n", "mc_dropout_enabled", ")", "for", "pyramid_layer", "in", "decoder_pyramid_layers", "]", "\n", "\n", "cls_out", "=", "tf", ".", "concat", "(", "cls_out_list", ",", "axis", "=", "1", ")", "\n", "self", ".", "prediction_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_CLASS_PREDICTIONS_KEY", ":", "cls_out", "}", ")", "\n", "\n", "", "if", "self", ".", "compute_reg", ":", "\n", "                ", "reg_out_list", "=", "[", "\n", "self", ".", "reg_header", "(", "\n", "pyramid_layer", ",", "\n", "mc_dropout_enabled", ")", "for", "pyramid_layer", "in", "decoder_pyramid_layers", "]", "\n", "reg_out", "=", "tf", ".", "concat", "(", "reg_out_list", ",", "axis", "=", "1", ")", "\n", "self", ".", "prediction_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_BOX_PREDICTIONS_KEY", ":", "reg_out", "}", ")", "\n", "\n", "", "if", "self", ".", "compute_covar", ":", "\n", "                ", "covar_out_list", "=", "[", "\n", "self", ".", "cov_header", "(", "\n", "pyramid_layer", ",", "\n", "mc_dropout_enabled", ")", "for", "pyramid_layer", "in", "decoder_pyramid_layers", "]", "\n", "covar_out", "=", "tf", ".", "concat", "(", "covar_out_list", ",", "axis", "=", "1", ")", "\n", "covar_out", "=", "tfp", ".", "math", ".", "fill_triangular", "(", "covar_out", ")", "\n", "\n", "self", ".", "prediction_dict", ".", "update", "(", "\n", "{", "constants", ".", "ANCHORS_COVAR_PREDICTIONS_KEY", ":", "covar_out", "}", ")", "\n", "\n", "", "", "return", "self", ".", "prediction_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.retinanet_model.RetinaNetModel.get_loss": [[151, 329], ["tensorflow.name_scope", "tensorflow.constant", "dict", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.name_scope", "retinanet_model.RetinaNetModel.focal_loss", "dict.update", "retinanet_model.RetinaNetModel.huber_loss", "dict.update", "retinanet_model.RetinaNetModel.loss_names.index", "tensorflow.reduce_sum", "tensorflow.maximum", "src.retina_net.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "src.retina_net.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "tensorflow.linalg.diag_part", "retinanet_model.RetinaNetModel.huber_loss", "tensorflow.reduce_sum", "dict.update", "dict.update", "retinanet_model.RetinaNetModel.loss_names.index", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.maximum", "src.retina_net.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "src.retina_net.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "tensorflow.linalg.diag_part", "tensorflow.linalg.set_diag", "tensorflow.linalg.norm", "retinanet_model.RetinaNetModel.huber_loss", "dict.update", "dict.update", "ValueError", "retinanet_model.RetinaNetModel.loss_names.index", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.ones_like", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_mean", "retinanet_model.RetinaNetModel.loss_names.index", "tensorflow.reduce_sum", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target_bnms", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.box_from_anchor_and_target_bnms"], ["", "def", "get_loss", "(", "self", ",", "\n", "sample_dict", ",", "\n", "prediction_dict", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"loss_computation\"", ")", ":", "\n", "# Initialize total loss to 0.0", "\n", "            ", "total_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "loss_dict", "=", "dict", "(", ")", "\n", "\n", "# Get ground truth tensors", "\n", "anchors", "=", "sample_dict", "[", "constants", ".", "ANCHORS_KEY", "]", "\n", "anchor_positive_mask", "=", "sample_dict", "[", "constants", ".", "POSITIVE_ANCHORS_MASK_KEY", "]", "\n", "anchor_positive_mask", "=", "tf", ".", "cast", "(", "\n", "anchor_positive_mask", ",", "\n", "tf", ".", "float32", ")", "\n", "num_positives", "=", "tf", ".", "reduce_sum", "(", "anchor_positive_mask", ")", "\n", "\n", "anchor_negative_mask", "=", "sample_dict", "[", "constants", ".", "NEGATIVE_ANCHOR_MASK_KEY", "]", "\n", "anchor_negative_mask", "=", "tf", ".", "cast", "(", "\n", "anchor_negative_mask", ",", "\n", "tf", ".", "float32", ")", "\n", "\n", "classification_loss_mask", "=", "anchor_positive_mask", "+", "anchor_negative_mask", "\n", "\n", "target_anchor_classes", "=", "sample_dict", "[", "constants", ".", "ANCHORS_CLASS_TARGETS_KEY", "]", "\n", "target_anchor_boxes", "=", "sample_dict", "[", "constants", ".", "ANCHORS_BOX_TARGETS_KEY", "]", "\n", "\n", "# Get prediction tensors", "\n", "predicted_anchor_classes", "=", "prediction_dict", "[", "constants", ".", "ANCHORS_CLASS_PREDICTIONS_KEY", "]", "\n", "predicted_anchor_boxes", "=", "prediction_dict", "[", "constants", ".", "ANCHORS_BOX_PREDICTIONS_KEY", "]", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'total_loss'", ")", ":", "\n", "                ", "for", "loss", "in", "self", ".", "loss_names", ":", "\n", "                    ", "if", "loss", "==", "'classification'", ":", "\n", "# Get loss weights", "\n", "                        ", "loss_weight", "=", "self", ".", "loss_weights", "[", "self", ".", "loss_names", ".", "index", "(", "\n", "loss", ")", "]", "\n", "\n", "# Compute Loss", "\n", "anchorwise_cls_loss", "=", "self", ".", "focal_loss", "(", "\n", "target_anchor_classes", ",", "predicted_anchor_classes", ")", "\n", "\n", "# Normalize Loss By Number Of Anchors and multiply by loss", "\n", "# weight", "\n", "normalized_cls_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "anchorwise_cls_loss", "*", "classification_loss_mask", ")", "/", "tf", ".", "maximum", "(", "\n", "num_positives", ",", "1", ")", "*", "loss_weight", "\n", "\n", "# Update dictionary for summaries", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "CLS_LOSS_KEY", ":", "normalized_cls_loss", "}", ")", "\n", "\n", "# Update total loss", "\n", "total_loss", "+=", "normalized_cls_loss", "\n", "\n", "", "elif", "loss", "==", "'regression'", ":", "\n", "                        ", "loss_weight", "=", "self", ".", "loss_weights", "[", "self", ".", "loss_names", ".", "index", "(", "\n", "loss", ")", "]", "\n", "\n", "# Compute Loss", "\n", "element_wise_reg_loss", "=", "self", ".", "huber_loss", "(", "\n", "target_anchor_boxes", ",", "predicted_anchor_boxes", ")", "\n", "\n", "# Normalize Loss By Number Of Anchors and multiply by loss", "\n", "# weight", "\n", "normalized_reg_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reduce_mean", "(", "\n", "element_wise_reg_loss", ",", "\n", "axis", "=", "2", ")", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "\n", "num_positives", ",", "\n", "1", ")", "*", "loss_weight", "\n", "\n", "# Update dictionary for summaries", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "REG_LOSS_KEY", ":", "normalized_reg_loss", "}", ")", "\n", "\n", "total_loss", "+=", "normalized_reg_loss", "\n", "\n", "", "elif", "loss", "==", "'regression_var'", ":", "\n", "                        ", "loss_weight", "=", "self", ".", "loss_weights", "[", "self", ".", "loss_names", ".", "index", "(", "\n", "loss", ")", "]", "\n", "\n", "# Get predictions", "\n", "predicted_boxes", "=", "box_utils", ".", "box_from_anchor_and_target_bnms", "(", "\n", "anchors", ",", "predicted_anchor_boxes", ")", "\n", "\n", "# Get Ground truth", "\n", "target_boxes", "=", "box_utils", ".", "box_from_anchor_and_target_bnms", "(", "\n", "anchors", ",", "target_anchor_boxes", ")", "\n", "\n", "# Get estimated inverse of the cholskey decomposition", "\n", "anchorwise_covar_predictions", "=", "prediction_dict", "[", "\n", "constants", ".", "ANCHORS_COVAR_PREDICTIONS_KEY", "]", "\n", "log_D", "=", "tf", ".", "linalg", ".", "diag_part", "(", "\n", "anchorwise_covar_predictions", ")", "\n", "\n", "# Compute Loss", "\n", "element_wise_reg_loss", "=", "self", ".", "huber_loss", "(", "\n", "target_boxes", ",", "predicted_boxes", ")", "\n", "\n", "covar_compute_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "exp", "(", "-", "log_D", ")", "*", "element_wise_reg_loss", ",", "axis", "=", "2", ")", "\n", "covar_reg_loss", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "log_D", ",", "axis", "=", "2", ")", "\n", "\n", "covar_final_loss", "=", "covar_compute_loss", "+", "covar_reg_loss", "\n", "\n", "# Normalize Loss By Number Of Anchors and multiply by loss", "\n", "# weight", "\n", "normalized_reg_loss", "=", "loss_weight", "*", "tf", ".", "reduce_sum", "(", "covar_final_loss", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "1.0", ",", "num_positives", ")", "\n", "\n", "# Update dictionary for summaries", "\n", "regression_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "covar_compute_loss", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "1.0", ",", "num_positives", ")", "\n", "regularization_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "covar_reg_loss", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "1.0", ",", "num_positives", ")", "\n", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "REG_LOSS_KEY", ":", "regression_loss", "}", ")", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "COV_LOSS_KEY", ":", "regularization_loss", "}", ")", "\n", "\n", "total_loss", "=", "total_loss", "+", "normalized_reg_loss", "\n", "\n", "", "elif", "loss", "==", "'regression_covar'", ":", "\n", "                        ", "loss_weight", "=", "self", ".", "loss_weights", "[", "self", ".", "loss_names", ".", "index", "(", "\n", "loss", ")", "]", "\n", "\n", "# Get predictions", "\n", "predicted_boxes", "=", "box_utils", ".", "box_from_anchor_and_target_bnms", "(", "\n", "anchors", ",", "predicted_anchor_boxes", ")", "\n", "\n", "# Get Ground truth", "\n", "target_boxes", "=", "box_utils", ".", "box_from_anchor_and_target_bnms", "(", "\n", "anchors", ",", "target_anchor_boxes", ")", "\n", "\n", "# Get estimated inverse of the cholskey decomposition", "\n", "anchorwise_covar_predictions", "=", "prediction_dict", "[", "\n", "constants", ".", "ANCHORS_COVAR_PREDICTIONS_KEY", "]", "\n", "log_D", "=", "tf", ".", "linalg", ".", "diag_part", "(", "\n", "anchorwise_covar_predictions", ")", "\n", "\n", "L_inv", "=", "tf", ".", "linalg", ".", "set_diag", "(", "\n", "anchorwise_covar_predictions", ",", "tf", ".", "ones_like", "(", "log_D", ")", ")", "\n", "\n", "fro_norm", "=", "tf", ".", "linalg", ".", "norm", "(", "L_inv", ",", "axis", "=", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "# Compute Loss", "\n", "element_wise_reg_loss", "=", "self", ".", "huber_loss", "(", "\n", "target_boxes", ",", "predicted_boxes", ")", "\n", "\n", "covar_compute_loss", "=", "fro_norm", "*", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "exp", "(", "-", "log_D", ")", "*", "element_wise_reg_loss", ",", "axis", "=", "2", ")", "\n", "covar_reg_loss", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "log_D", ",", "axis", "=", "2", ")", "\n", "\n", "covar_final_loss", "=", "covar_compute_loss", "+", "covar_reg_loss", "\n", "\n", "# Normalize Loss By Number Of Anchors and multiply by loss", "\n", "# weight", "\n", "normalized_reg_loss", "=", "loss_weight", "*", "tf", ".", "reduce_sum", "(", "covar_final_loss", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "1.0", ",", "num_positives", ")", "\n", "\n", "# Update dictionary for summaries", "\n", "regression_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "covar_compute_loss", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "1.0", ",", "num_positives", ")", "\n", "regularization_loss", "=", "tf", ".", "reduce_sum", "(", "\n", "covar_reg_loss", "*", "anchor_positive_mask", ")", "/", "tf", ".", "maximum", "(", "1.0", ",", "num_positives", ")", "\n", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "REG_LOSS_KEY", ":", "regression_loss", "}", ")", "\n", "loss_dict", ".", "update", "(", "\n", "{", "constants", ".", "COV_LOSS_KEY", ":", "regularization_loss", "}", ")", "\n", "\n", "total_loss", "=", "total_loss", "+", "normalized_reg_loss", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "'Invalid Loss! Not implemented yet.'", ",", "loss", ")", "\n", "\n", "", "", "", "return", "total_loss", ",", "loss_dict", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_extractor.FeatureExtractor.__init__": [[11, 103], ["keras.Model.__init__", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.ZeroPadding2D", "keras.layers.MaxPooling2D", "feature_extractor.ConvBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.ConvBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.ConvBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "feature_extractor.ConvBlock", "feature_extractor.IdentityBlock", "feature_extractor.IdentityBlock", "keras.layers.ReLU", "keras.regularizers.l2"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["def", "__init__", "(", "self", ",", "feature_extractor_config", ")", ":", "\n", "        ", "super", "(", "FeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "l2_norm_rate", "=", "feature_extractor_config", "[", "'l2_norm_rate'", "]", "\n", "use_bias", "=", "feature_extractor_config", "[", "'use_bias'", "]", "\n", "\n", "self", ".", "conv_1", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "64", ",", "\n", "(", "7", ",", "\n", "7", ")", ",", "\n", "strides", "=", "(", "\n", "2", ",", "\n", "2", ")", ",", "\n", "padding", "=", "'valid'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'conv1'", ")", "\n", "\n", "self", ".", "bn_1", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "'bn_conv1'", ")", "\n", "self", ".", "pool_1_pad", "=", "keras", ".", "layers", ".", "ZeroPadding2D", "(", "\n", "padding", "=", "(", "1", ",", "2", ")", ",", "name", "=", "'pool1_pad'", ")", "\n", "self", ".", "pool_1", "=", "keras", ".", "layers", ".", "MaxPooling2D", "(", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "# Stage 2", "\n", "self", ".", "conv_block_2a", "=", "ConvBlock", "(", "3", ",", "\n", "[", "64", ",", "\n", "64", ",", "\n", "256", "]", ",", "\n", "stage", "=", "2", ",", "\n", "block", "=", "'a'", ",", "\n", "l2_norm_rate", "=", "l2_norm_rate", ",", "\n", "strides", "=", "(", "1", ",", "\n", "1", ")", ",", "\n", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_2b", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "64", ",", "64", ",", "256", "]", ",", "stage", "=", "2", ",", "block", "=", "'b'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_2c", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "64", ",", "64", ",", "256", "]", ",", "stage", "=", "2", ",", "block", "=", "'c'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "\n", "# Stage 3", "\n", "self", ".", "conv_block_3a", "=", "ConvBlock", "(", "3", ",", "\n", "[", "128", ",", "\n", "128", ",", "\n", "512", "]", ",", "\n", "stage", "=", "3", ",", "\n", "block", "=", "'a'", ",", "\n", "l2_norm_rate", "=", "l2_norm_rate", ",", "\n", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_3b", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "128", ",", "128", ",", "512", "]", ",", "stage", "=", "3", ",", "block", "=", "'b'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_3c", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "128", ",", "128", ",", "512", "]", ",", "stage", "=", "3", ",", "block", "=", "'c'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_3d", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "128", ",", "128", ",", "512", "]", ",", "stage", "=", "3", ",", "block", "=", "'d'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "\n", "# Stage 4", "\n", "self", ".", "conv_block_4a", "=", "ConvBlock", "(", "3", ",", "\n", "[", "256", ",", "\n", "256", ",", "\n", "1024", "]", ",", "\n", "stage", "=", "4", ",", "\n", "block", "=", "'a'", ",", "\n", "l2_norm_rate", "=", "l2_norm_rate", ",", "\n", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_4b", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "256", ",", "256", ",", "1024", "]", ",", "stage", "=", "4", ",", "block", "=", "'b'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_4c", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "256", ",", "256", ",", "1024", "]", ",", "stage", "=", "4", ",", "block", "=", "'c'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_4d", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "256", ",", "256", ",", "1024", "]", ",", "stage", "=", "4", ",", "block", "=", "'d'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_4e", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "256", ",", "256", ",", "1024", "]", ",", "stage", "=", "4", ",", "block", "=", "'e'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_4f", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "256", ",", "256", ",", "1024", "]", ",", "stage", "=", "4", ",", "block", "=", "'f'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "\n", "# Stage 5", "\n", "self", ".", "conv_block_5a", "=", "ConvBlock", "(", "3", ",", "\n", "[", "512", ",", "\n", "512", ",", "\n", "2048", "]", ",", "\n", "stage", "=", "5", ",", "\n", "block", "=", "'a'", ",", "\n", "l2_norm_rate", "=", "l2_norm_rate", ",", "\n", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_5b", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "512", ",", "512", ",", "2048", "]", ",", "stage", "=", "5", ",", "block", "=", "'b'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "identity_block_5c", "=", "IdentityBlock", "(", "\n", "3", ",", "[", "512", ",", "512", ",", "2048", "]", ",", "stage", "=", "5", ",", "block", "=", "'c'", ",", "l2_norm_rate", "=", "l2_norm_rate", ",", "use_bias", "=", "use_bias", ")", "\n", "\n", "# Activation", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_extractor.FeatureExtractor.call": [[104, 140], ["feature_extractor.FeatureExtractor.conv_1", "feature_extractor.FeatureExtractor.bn_1", "feature_extractor.FeatureExtractor.relu", "feature_extractor.FeatureExtractor.pool_1_pad", "feature_extractor.FeatureExtractor.pool_1", "feature_extractor.FeatureExtractor.conv_block_2a", "feature_extractor.FeatureExtractor.identity_block_2b", "feature_extractor.FeatureExtractor.identity_block_2c", "feature_extractor.FeatureExtractor.conv_block_3a", "tensorflow.identity", "feature_extractor.FeatureExtractor.identity_block_3b", "feature_extractor.FeatureExtractor.identity_block_3c", "feature_extractor.FeatureExtractor.identity_block_3d", "feature_extractor.FeatureExtractor.conv_block_4a", "tensorflow.identity", "feature_extractor.FeatureExtractor.identity_block_4b", "feature_extractor.FeatureExtractor.identity_block_4c", "feature_extractor.FeatureExtractor.identity_block_4d", "feature_extractor.FeatureExtractor.identity_block_4e", "feature_extractor.FeatureExtractor.identity_block_4f", "feature_extractor.FeatureExtractor.conv_block_5a", "feature_extractor.FeatureExtractor.identity_block_5b", "feature_extractor.FeatureExtractor.identity_block_5c"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ")", ":", "\n", "\n", "# Stage 1", "\n", "        ", "x", "=", "self", ".", "conv_1", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "bn_1", "(", "x", ",", "training", "=", "False", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "pool_1_pad", "(", "x", ")", "\n", "x", "=", "self", ".", "pool_1", "(", "x", ")", "\n", "\n", "# Stage 2", "\n", "x", "=", "self", ".", "conv_block_2a", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_2b", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_2c", "(", "x", ")", "\n", "\n", "# Stage 3", "\n", "x", "=", "self", ".", "conv_block_3a", "(", "x", ")", "\n", "map_3", "=", "tf", ".", "identity", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_3b", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_3c", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_3d", "(", "x", ")", "\n", "\n", "# Stage 4", "\n", "x", "=", "self", ".", "conv_block_4a", "(", "x", ")", "\n", "map_4", "=", "tf", ".", "identity", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_4b", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_4c", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_4d", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_4e", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_4f", "(", "x", ")", "\n", "\n", "# Stage 5", "\n", "x", "=", "self", ".", "conv_block_5a", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_5b", "(", "x", ")", "\n", "x", "=", "self", ".", "identity_block_5c", "(", "x", ")", "\n", "\n", "return", "x", ",", "map_4", ",", "map_3", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_extractor.IdentityBlock.__init__": [[144, 194], ["keras.Model.__init__", "keras.backend.learning_phase", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.ReLU", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "str", "str"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "kernel_size", ",", "\n", "filters", ",", "\n", "stage", ",", "\n", "block", ",", "\n", "l2_norm_rate", ",", "\n", "use_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "IdentityBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "conv_name_base", "=", "'res'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "bn_name_base", "=", "'bn'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "\n", "self", ".", "is_training", "=", "keras", ".", "backend", ".", "learning_phase", "(", ")", "\n", "\n", "filters1", ",", "filters2", ",", "filters3", "=", "filters", "\n", "\n", "self", ".", "conv_1", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters1", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2a'", ")", "\n", "\n", "self", ".", "bn_1", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "bn_name_base", "+", "'2a'", ")", "\n", "\n", "self", ".", "conv_2", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters2", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2b'", ")", "\n", "\n", "self", ".", "bn_2", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "bn_name_base", "+", "'2b'", ")", "\n", "\n", "self", ".", "conv_3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters3", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2c'", ")", "\n", "self", ".", "bn_3", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "bn_name_base", "+", "'2c'", ")", "\n", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_extractor.IdentityBlock.call": [[195, 214], ["feature_extractor.IdentityBlock.conv_1", "feature_extractor.IdentityBlock.bn_1", "feature_extractor.IdentityBlock.relu", "feature_extractor.IdentityBlock.conv_2", "feature_extractor.IdentityBlock.bn_2", "feature_extractor.IdentityBlock.relu", "feature_extractor.IdentityBlock.conv_3", "feature_extractor.IdentityBlock.bn_3", "keras.layers.add", "feature_extractor.IdentityBlock.relu"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ")", ":", "\n", "        ", "\"\"\"The identity block is the block that has no conv layer at shortcut.\n        # Arguments\n            input_tensor: input tensor\n            kernel_size: default 3, the kernel size of\n                middle conv layer at main path\n            filters: list of integers, the filters of 3 conv layer at main path\n        \"\"\"", "\n", "x", "=", "self", ".", "conv_1", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "bn_1", "(", "x", ",", "training", "=", "False", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_2", "(", "x", ",", "training", "=", "False", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_3", "(", "x", ",", "training", "=", "False", ")", "\n", "x", "=", "keras", ".", "layers", ".", "add", "(", "[", "x", ",", "input_tensor", "]", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_extractor.ConvBlock.__init__": [[218, 282], ["keras.Model.__init__", "keras.backend.learning_phase", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.ReLU", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "str", "str"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "kernel_size", ",", "\n", "filters", ",", "\n", "stage", ",", "\n", "block", ",", "\n", "l2_norm_rate", ",", "\n", "strides", "=", "(", "\n", "2", ",", "\n", "2", ")", ",", "\n", "use_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "ConvBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "conv_name_base", "=", "'res'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "bn_name_base", "=", "'bn'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "\n", "self", ".", "is_training", "=", "keras", ".", "backend", ".", "learning_phase", "(", ")", "\n", "filters1", ",", "filters2", ",", "filters3", "=", "filters", "\n", "\n", "self", ".", "conv_1", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters1", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2a'", ")", "\n", "self", ".", "bn_1", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "bn_name_base", "+", "'2a'", ")", "\n", "\n", "self", ".", "conv_2", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters2", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2b'", ")", "\n", "self", ".", "bn_2", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "bn_name_base", "+", "'2b'", ")", "\n", "\n", "self", ".", "conv_3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters3", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2c'", ")", "\n", "self", ".", "bn_3", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "bn_name_base", "+", "'2c'", ")", "\n", "\n", "self", ".", "shortcut", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters3", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "use_bias", "=", "use_bias", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'1'", ")", "\n", "\n", "self", ".", "bn_shortcut", "=", "keras", ".", "layers", ".", "BatchNormalization", "(", "\n", "name", "=", "bn_name_base", "+", "'1'", ")", "\n", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_extractor.ConvBlock.call": [[283, 310], ["feature_extractor.ConvBlock.conv_1", "feature_extractor.ConvBlock.bn_1", "feature_extractor.ConvBlock.relu", "feature_extractor.ConvBlock.conv_2", "feature_extractor.ConvBlock.bn_2", "feature_extractor.ConvBlock.relu", "feature_extractor.ConvBlock.conv_3", "feature_extractor.ConvBlock.bn_3", "feature_extractor.ConvBlock.shortcut", "feature_extractor.ConvBlock.bn_shortcut", "keras.layers.add", "feature_extractor.ConvBlock.relu"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ")", ":", "\n", "        ", "\"\"\"A block that has a conv layer at shortcut.\n        # Arguments\n            input_tensor: input tensor\n            kernel_size: default 3, the kernel size of\n                middle conv layer at main path\n            filters: list of integers, the filters of 3 conv layer at main path\n            stage: integer, current stage label, used for generating layer names\n        # Returns\n            Output tensor for the block.\n        Note that from stage 3,\n        the second conv layer at main path is with strides=(2, 2)\n        And the shortcut should have strides=(2, 2) as well\n        \"\"\"", "\n", "x", "=", "self", ".", "conv_1", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "bn_1", "(", "x", ",", "training", "=", "False", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_2", "(", "x", ",", "training", "=", "False", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_3", "(", "x", ",", "training", "=", "False", ")", "\n", "x_shortcut", "=", "self", ".", "shortcut", "(", "input_tensor", ")", "\n", "x_shortcut", "=", "self", ".", "bn_shortcut", "(", "x_shortcut", ",", "training", "=", "False", ")", "\n", "x", "=", "keras", ".", "layers", ".", "add", "(", "[", "x", ",", "x_shortcut", "]", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_decoder.FeatureDecoder.__init__": [[8, 135], ["keras.Model.__init__", "keras.backend.learning_phase", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.ReLU", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feature_decoder_config", ")", ":", "\n", "        ", "super", "(", "FeatureDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_training", "=", "keras", ".", "backend", ".", "learning_phase", "(", ")", "\n", "l2_norm_rate", "=", "feature_decoder_config", "[", "'l2_norm_rate'", "]", "\n", "\n", "###########################################################", "\n", "# Highest Pyramid Layers  p5-p7 as generated by retinanet #", "\n", "###########################################################", "\n", "self", ".", "c5_reduced", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'C5_reduced'", ")", "\n", "\n", "self", ".", "p5", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'P5'", ")", "\n", "\n", "self", ".", "p6", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "2", ",", "\n", "2", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'P6'", ")", "\n", "\n", "self", ".", "p7", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "2", ",", "\n", "2", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'P7'", ")", "\n", "\n", "#######################", "\n", "# Second Pyramid Layer#", "\n", "#######################", "\n", "self", ".", "c4_reduced", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'C4_reduced'", ")", "\n", "\n", "self", ".", "p4", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'P4'", ")", "\n", "\n", "#######################", "\n", "# Third Pyramid Layer #", "\n", "#######################", "\n", "self", ".", "c3_reduced", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'C3_reduced'", ")", "\n", "\n", "self", ".", "p3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "256", ",", "\n", "kernel_size", "=", "(", "\n", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'P3'", ")", "\n", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.feature_decoder.FeatureDecoder.call": [[136, 172], ["feature_decoder.FeatureDecoder.c5_reduced", "feature_decoder.FeatureDecoder.p5", "feature_decoder.FeatureDecoder.p6", "feature_decoder.FeatureDecoder.p7", "feature_decoder.FeatureDecoder.c4_reduced", "tensorflow.image.resize", "keras.layers.add", "feature_decoder.FeatureDecoder.p4", "feature_decoder.FeatureDecoder.c3_reduced", "tensorflow.image.resize", "keras.layers.add", "feature_decoder.FeatureDecoder.p3", "feature_decoder.FeatureDecoder.relu", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "map_5", ",", "map_4", ",", "map_3", ")", ":", "\n", "###########################################################", "\n", "# Highest Pyramid Layers  p5-p7 as generated by retinanet #", "\n", "###########################################################", "\n", "        ", "c5_reduced", "=", "self", ".", "c5_reduced", "(", "map_5", ")", "\n", "p5", "=", "self", ".", "p5", "(", "c5_reduced", ")", "\n", "p6", "=", "self", ".", "p6", "(", "map_5", ")", "\n", "p7", "=", "self", ".", "p7", "(", "self", ".", "relu", "(", "p6", ")", ")", "\n", "\n", "###########################", "\n", "# Second Pyramid Layer p4 #", "\n", "###########################", "\n", "c4_reduced", "=", "self", ".", "c4_reduced", "(", "map_4", ")", "\n", "up4", "=", "tf", ".", "image", ".", "resize", "(", "\n", "c5_reduced", ",", "\n", "tf", ".", "shape", "(", "c4_reduced", ")", "[", "\n", "1", ":", "3", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ",", "\n", "name", "=", "'P5_upsampled'", ")", "\n", "m4", "=", "keras", ".", "layers", ".", "add", "(", "[", "up4", ",", "c4_reduced", "]", ",", "name", "=", "'P4_merged'", ")", "\n", "p4", "=", "self", ".", "p4", "(", "m4", ")", "\n", "\n", "#######################", "\n", "# Third Pyramid Layer #", "\n", "#######################", "\n", "c3_reduced", "=", "self", ".", "c3_reduced", "(", "map_3", ")", "\n", "up3", "=", "tf", ".", "image", ".", "resize", "(", "\n", "m4", ",", "\n", "tf", ".", "shape", "(", "c3_reduced", ")", "[", "\n", "1", ":", "3", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ",", "\n", "name", "=", "'P4_upsampled'", ")", "\n", "m3", "=", "keras", ".", "layers", ".", "add", "(", "[", "up3", ",", "c3_reduced", "]", ",", "name", "=", "'P3_merged'", ")", "\n", "p3", "=", "self", ".", "p3", "(", "m3", ")", "\n", "\n", "return", "p3", ",", "p4", ",", "p5", ",", "p6", ",", "p7", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.multitask_headers.ClsHeader.__init__": [[9, 97], ["keras.Model.__init__", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "numpy.zeros", "numpy.tile", "keras.layers.Conv2D", "keras.layers.ReLU", "numpy.log", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.initializers.constant"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "header_config", ")", ":", "\n", "        ", "super", "(", "ClsHeader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "anchors_per_location", "=", "header_config", "[", "'anchors_per_location'", "]", "\n", "self", ".", "num_classes", "=", "header_config", "[", "'num_classes'", "]", "\n", "\n", "dropout_rate", "=", "header_config", "[", "'dropout_rate'", "]", "\n", "\n", "l2_norm_rate", "=", "header_config", "[", "'l2_norm_rate'", "]", "\n", "\n", "# Classification Header (Naming convention compatible with fizyr", "\n", "# keras-retinanet)", "\n", "self", ".", "conv_1", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_classification_0'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "self", ".", "drop_1", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop1'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_2", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_classification_1'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "self", ".", "drop_2", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop2'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_classification_2'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "\n", "self", ".", "drop_3", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop3'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_4", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_classification_3'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "\n", "self", ".", "drop_4", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop4'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "cls_bias_initializer", "=", "np", ".", "zeros", "(", "self", ".", "num_classes", "+", "1", ")", "\n", "cls_bias_initializer", "[", ":", "-", "1", "]", "=", "-", "np", ".", "log", "(", "(", "1.0", "-", "0.01", ")", "/", "0.01", ")", "\n", "cls_bias_initializer", "=", "np", ".", "tile", "(", "\n", "cls_bias_initializer", ",", "\n", "self", ".", "anchors_per_location", ")", "\n", "\n", "self", ".", "cls_out", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "self", ".", "anchors_per_location", "*", "(", "\n", "self", ".", "num_classes", "+", "1", ")", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "constant", "(", "cls_bias_initializer", ")", ",", "\n", "name", "=", "'pyramid_classification'", ")", "\n", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.multitask_headers.ClsHeader.call": [[98, 124], ["multitask_headers.ClsHeader.conv_1", "multitask_headers.ClsHeader.relu", "multitask_headers.ClsHeader.drop_1", "multitask_headers.ClsHeader.conv_2", "multitask_headers.ClsHeader.relu", "multitask_headers.ClsHeader.drop_2", "multitask_headers.ClsHeader.conv_3", "multitask_headers.ClsHeader.relu", "multitask_headers.ClsHeader.drop_3", "multitask_headers.ClsHeader.conv_4", "multitask_headers.ClsHeader.relu", "multitask_headers.ClsHeader.drop_4", "multitask_headers.ClsHeader.cls_out", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "mc_dropout_enabled", ")", ":", "\n", "        ", "num_input_pixels", "=", "tf", ".", "shape", "(", "input_tensor", ")", "[", "\n", "1", "]", "*", "tf", ".", "shape", "(", "input_tensor", ")", "[", "2", "]", "\n", "\n", "x", "=", "self", ".", "conv_1", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_1", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_2", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_3", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_3", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_4", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_4", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "cls_out", "=", "self", ".", "cls_out", "(", "x", ")", "\n", "cls_out", "=", "tf", ".", "reshape", "(", "\n", "cls_out", ",", "\n", "[", "-", "1", ",", "self", ".", "anchors_per_location", "*", "num_input_pixels", ",", "self", ".", "num_classes", "+", "1", "]", ")", "\n", "\n", "return", "cls_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.multitask_headers.RegHeader.__init__": [[128, 208], ["keras.Model.__init__", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.ReLU", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "header_config", ")", ":", "\n", "        ", "super", "(", "RegHeader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "anchors_per_location", "=", "header_config", "[", "'anchors_per_location'", "]", "\n", "\n", "dropout_rate", "=", "header_config", "[", "'dropout_rate'", "]", "\n", "\n", "l2_norm_rate", "=", "header_config", "[", "'l2_norm_rate'", "]", "\n", "\n", "# Regression Header", "\n", "self", ".", "conv_1", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_regression_0'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "self", ".", "drop_1", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop1'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_2", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_regression_1'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "self", ".", "drop_2", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop2'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_regression_2'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "\n", "self", ".", "drop_3", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop3'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_4", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_regression_3'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "\n", "self", ".", "drop_4", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop4'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "reg_out", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "self", ".", "anchors_per_location", "*", "4", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_regression'", ")", "\n", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.multitask_headers.RegHeader.call": [[209, 231], ["multitask_headers.RegHeader.conv_1", "multitask_headers.RegHeader.relu", "multitask_headers.RegHeader.drop_1", "multitask_headers.RegHeader.conv_2", "multitask_headers.RegHeader.relu", "multitask_headers.RegHeader.drop_2", "multitask_headers.RegHeader.conv_3", "multitask_headers.RegHeader.relu", "multitask_headers.RegHeader.drop_3", "multitask_headers.RegHeader.reg_out", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "mc_dropout_enabled", ")", ":", "\n", "        ", "num_input_pixels", "=", "tf", ".", "shape", "(", "input_tensor", ")", "[", "\n", "1", "]", "*", "tf", ".", "shape", "(", "input_tensor", ")", "[", "2", "]", "\n", "\n", "x", "=", "self", ".", "conv_1", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_1", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_2", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_3", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_3", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "reg_out", "=", "self", ".", "reg_out", "(", "x", ")", "\n", "reg_out", "=", "tf", ".", "reshape", "(", "\n", "reg_out", ",", "\n", "[", "-", "1", ",", "self", ".", "anchors_per_location", "*", "num_input_pixels", ",", "4", "]", ")", "\n", "\n", "return", "reg_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.multitask_headers.CovHeader.__init__": [[235, 317], ["keras.Model.__init__", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Dropout", "keras.initializers.TruncatedNormal", "keras.layers.Conv2D", "keras.layers.ReLU", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2", "keras.regularizers.l2"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "header_config", ")", ":", "\n", "        ", "super", "(", "CovHeader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "anchors_per_location", "=", "header_config", "[", "'anchors_per_location'", "]", "\n", "\n", "dropout_rate", "=", "header_config", "[", "'dropout_rate'", "]", "\n", "l2_norm_rate", "=", "header_config", "[", "'l2_norm_rate'", "]", "\n", "\n", "# Covariance Header", "\n", "self", ".", "conv_1", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_cov_0'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "self", ".", "drop_1", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop1'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_2", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_cov_1'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "self", ".", "drop_2", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop2'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_cov_2'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "\n", "self", ".", "drop_3", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop3'", ",", "rate", "=", "dropout_rate", ")", "\n", "\n", "self", ".", "conv_4", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "256", ",", "\n", "(", "3", ",", "\n", "3", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "name", "=", "'pyramid_cov_3'", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ")", "\n", "\n", "self", ".", "drop_4", "=", "keras", ".", "layers", ".", "Dropout", "(", "\n", "name", "=", "'drop4'", ",", "rate", "=", "dropout_rate", ")", "\n", "# Number of elements required to describe an NxN covariance matrix is", "\n", "# computed as:  (N * (N + 1)) / 2", "\n", "\n", "cov_init", "=", "keras", ".", "initializers", ".", "TruncatedNormal", "(", "mean", "=", "0.0", ",", "stddev", "=", "1e-6", ")", "\n", "self", ".", "cov_out", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "self", ".", "anchors_per_location", "*", "10", ",", "\n", "(", "1", ",", "\n", "1", ")", ",", "\n", "strides", "=", "(", "\n", "1", ",", "\n", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "cov_init", ",", "\n", "kernel_regularizer", "=", "keras", ".", "regularizers", ".", "l2", "(", "l2_norm_rate", ")", ",", "\n", "name", "=", "'pyramid_cov'", ")", "\n", "\n", "self", ".", "relu", "=", "keras", ".", "layers", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.models.multitask_headers.CovHeader.call": [[318, 343], ["multitask_headers.CovHeader.conv_1", "multitask_headers.CovHeader.relu", "multitask_headers.CovHeader.drop_1", "multitask_headers.CovHeader.conv_2", "multitask_headers.CovHeader.relu", "multitask_headers.CovHeader.drop_2", "multitask_headers.CovHeader.conv_3", "multitask_headers.CovHeader.relu", "multitask_headers.CovHeader.drop_3", "multitask_headers.CovHeader.conv_4", "multitask_headers.CovHeader.relu", "multitask_headers.CovHeader.drop_4", "multitask_headers.CovHeader.cov_out", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "mc_dropout_enabled", ")", ":", "\n", "        ", "num_input_pixels", "=", "tf", ".", "shape", "(", "input_tensor", ")", "[", "\n", "1", "]", "*", "tf", ".", "shape", "(", "input_tensor", ")", "[", "2", "]", "\n", "\n", "x", "=", "self", ".", "conv_1", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_1", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_2", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_3", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_3", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "x", "=", "self", ".", "conv_4", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_4", "(", "x", ",", "training", "=", "mc_dropout_enabled", ")", "\n", "\n", "cov_out", "=", "self", ".", "cov_out", "(", "x", ")", "\n", "cov_out", "=", "tf", ".", "reshape", "(", "\n", "cov_out", ",", "[", "-", "1", ",", "self", ".", "anchors_per_location", "*", "num_input_pixels", ",", "10", "]", ")", "\n", "\n", "return", "cov_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.two_d_iou": [[12, 48], ["numpy.zeros", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.logical_and", "np.logical_and.any", "np.zeros.round", "len", "numpy.multiply", "numpy.multiply"], "function", ["None"], ["def", "two_d_iou", "(", "box", ",", "boxes", ")", ":", "\n", "    ", "\"\"\"Compute 2D IOU between a 2D bounding box 'box' and a list\n    :param box: a numpy array in the form of [x1, y1, x2, y2] where (x1,y1) are\n    image coordinates of the top-left corner of the bounding box, and (x2,y2)\n    are the image coordinates of the bottom-right corner of the bounding box.\n    :param boxes: a numpy array formed as a list of boxes in the form\n    [[x1, y1, x2, y2], [x1, y1, x2, y2]].\n    :return iou: a numpy array containing 2D IOUs between box and every element\n    in numpy array boxes.\n    \"\"\"", "\n", "iou", "=", "np", ".", "zeros", "(", "len", "(", "boxes", ")", ",", "np", ".", "float64", ")", "\n", "\n", "x1_int", "=", "np", ".", "maximum", "(", "box", "[", "0", "]", ",", "boxes", "[", ":", ",", "0", "]", ")", "\n", "y1_int", "=", "np", ".", "maximum", "(", "box", "[", "1", "]", ",", "boxes", "[", ":", ",", "1", "]", ")", "\n", "x2_int", "=", "np", ".", "minimum", "(", "box", "[", "2", "]", ",", "boxes", "[", ":", ",", "2", "]", ")", "\n", "y2_int", "=", "np", ".", "minimum", "(", "box", "[", "3", "]", ",", "boxes", "[", ":", ",", "3", "]", ")", "\n", "\n", "w_int", "=", "np", ".", "maximum", "(", "x2_int", "-", "x1_int", "+", "1.", ",", "0.", ")", "\n", "h_int", "=", "np", ".", "maximum", "(", "y2_int", "-", "y1_int", "+", "1.", ",", "0.", ")", "\n", "\n", "non_empty", "=", "np", ".", "logical_and", "(", "w_int", ">", "0", ",", "h_int", ">", "0", ")", "\n", "\n", "if", "non_empty", ".", "any", "(", ")", ":", "\n", "        ", "intersection_area", "=", "np", ".", "multiply", "(", "w_int", "[", "non_empty", "]", ",", "h_int", "[", "non_empty", "]", ")", "\n", "\n", "box_area", "=", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1.", ")", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1.", ")", "\n", "\n", "boxes_area", "=", "np", ".", "multiply", "(", "\n", "boxes", "[", "non_empty", ",", "2", "]", "-", "boxes", "[", "non_empty", ",", "0", "]", "+", "1.", ",", "\n", "boxes", "[", "non_empty", ",", "3", "]", "-", "boxes", "[", "non_empty", ",", "1", "]", "+", "1.", ")", "\n", "\n", "union_area", "=", "box_area", "+", "boxes_area", "-", "intersection_area", "\n", "\n", "iou", "[", "non_empty", "]", "=", "intersection_area", "/", "union_area", "\n", "\n", "", "return", "iou", ".", "round", "(", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.cat_pc": [[52, 127], ["len", "evaluation_utils_2d.group_by_key", "sorted", "len", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.cumsum", "numpy.cumsum", "numpy.zeros", "range", "numpy.array", "numpy.zeros", "enumerate", "float", "numpy.maximum", "len", "len", "evaluation_utils_2d.get_ap", "group_by_key.items", "group_by_key.items", "len", "len", "len", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.max", "numpy.argmax", "len", "len", "numpy.finfo", "numpy.argmax", "numpy.argmax", "float"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.get_ap"], ["", "def", "cat_pc", "(", "gt", ",", "predictions", ",", "thresholds", ")", ":", "\n", "    ", "\"\"\"\n    Implementation refers to https://github.com/rbgirshick/py-faster-rcnn\n    \"\"\"", "\n", "num_gts", "=", "len", "(", "gt", ")", "\n", "image_gts", "=", "group_by_key", "(", "gt", ",", "'name'", ")", "\n", "image_gt_boxes", "=", "{", "k", ":", "np", ".", "array", "(", "[", "[", "float", "(", "z", ")", "for", "z", "in", "b", "[", "'bbox'", "]", "]", "\n", "for", "b", "in", "boxes", "]", ")", "\n", "for", "k", ",", "boxes", "in", "image_gts", ".", "items", "(", ")", "}", "\n", "image_gt_checked", "=", "{", "k", ":", "np", ".", "zeros", "(", "(", "len", "(", "boxes", ")", ",", "len", "(", "thresholds", ")", ")", ")", "\n", "for", "k", ",", "boxes", "in", "image_gts", ".", "items", "(", ")", "}", "\n", "predictions", "=", "sorted", "(", "predictions", ",", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "# go down dets and mark TPs and FPs", "\n", "nd", "=", "len", "(", "predictions", ")", "\n", "tp", "=", "np", ".", "zeros", "(", "(", "nd", ",", "len", "(", "thresholds", ")", ")", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "(", "nd", ",", "len", "(", "thresholds", ")", ")", ")", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "box", "=", "p", "[", "'bbox'", "]", "\n", "ovmax", "=", "-", "np", ".", "inf", "\n", "jmax", "=", "-", "1", "\n", "try", ":", "\n", "            ", "gt_boxes", "=", "image_gt_boxes", "[", "p", "[", "'name'", "]", "]", "\n", "gt_checked", "=", "image_gt_checked", "[", "p", "[", "'name'", "]", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "gt_boxes", "=", "[", "]", "\n", "gt_checked", "=", "None", "\n", "\n", "", "if", "len", "(", "gt_boxes", ")", ">", "0", ":", "\n", "# compute overlaps", "\n", "# intersection", "\n", "            ", "ixmin", "=", "np", ".", "maximum", "(", "gt_boxes", "[", ":", ",", "0", "]", ",", "box", "[", "0", "]", ")", "\n", "iymin", "=", "np", ".", "maximum", "(", "gt_boxes", "[", ":", ",", "1", "]", ",", "box", "[", "1", "]", ")", "\n", "ixmax", "=", "np", ".", "minimum", "(", "gt_boxes", "[", ":", ",", "2", "]", ",", "box", "[", "2", "]", ")", "\n", "iymax", "=", "np", ".", "minimum", "(", "gt_boxes", "[", ":", ",", "3", "]", ",", "box", "[", "3", "]", ")", "\n", "iw", "=", "np", ".", "maximum", "(", "ixmax", "-", "ixmin", "+", "1.", ",", "0.", ")", "\n", "ih", "=", "np", ".", "maximum", "(", "iymax", "-", "iymin", "+", "1.", ",", "0.", ")", "\n", "inters", "=", "iw", "*", "ih", "\n", "\n", "# union", "\n", "uni", "=", "(", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1.", ")", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1.", ")", "+", "\n", "(", "gt_boxes", "[", ":", ",", "2", "]", "-", "gt_boxes", "[", ":", ",", "0", "]", "+", "1.", ")", "*", "\n", "(", "gt_boxes", "[", ":", ",", "3", "]", "-", "gt_boxes", "[", ":", ",", "1", "]", "+", "1.", ")", "-", "inters", ")", "\n", "\n", "overlaps", "=", "inters", "/", "uni", "\n", "ovmax", "=", "np", ".", "max", "(", "overlaps", ")", "\n", "jmax", "=", "np", ".", "argmax", "(", "overlaps", ")", "\n", "\n", "", "for", "t", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "            ", "if", "ovmax", ">", "threshold", ":", "\n", "                ", "if", "gt_checked", "[", "jmax", ",", "t", "]", "==", "0", ":", "\n", "                    ", "tp", "[", "i", ",", "t", "]", "=", "1.", "\n", "gt_checked", "[", "jmax", ",", "t", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "fp", "[", "i", ",", "t", "]", "=", "1.", "\n", "", "", "else", ":", "\n", "                ", "fp", "[", "i", ",", "t", "]", "=", "1.", "\n", "\n", "# compute precision recall", "\n", "", "", "", "fp", "=", "np", ".", "cumsum", "(", "fp", ",", "axis", "=", "0", ")", "\n", "tp", "=", "np", ".", "cumsum", "(", "tp", ",", "axis", "=", "0", ")", "\n", "recalls", "=", "tp", "/", "float", "(", "num_gts", ")", "\n", "# avoid divide by zero in case the first detection matches a difficult", "\n", "# ground truth", "\n", "precisions", "=", "tp", "/", "np", ".", "maximum", "(", "tp", "+", "fp", ",", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", ")", "\n", "ap", "=", "np", ".", "zeros", "(", "len", "(", "thresholds", ")", ")", "\n", "for", "t", "in", "range", "(", "len", "(", "thresholds", ")", ")", ":", "\n", "        ", "ap", "[", "t", "]", "=", "get_ap", "(", "recalls", "[", ":", ",", "t", "]", ",", "precisions", "[", ":", ",", "t", "]", ")", "\n", "\n", "", "f_score", "=", "2", "*", "(", "precisions", "*", "recalls", ")", "/", "(", "precisions", "+", "recalls", "+", "1e-6", ")", "\n", "\n", "optimal_threshold", "=", "predictions", "[", "np", ".", "argmax", "(", "f_score", ")", "]", "[", "'score'", "]", "\n", "\n", "return", "recalls", ",", "precisions", ",", "ap", ",", "optimal_threshold", ",", "f_score", "[", "np", ".", "argmax", "(", "\n", "f_score", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_mu_error": [[129, 213], ["len", "evaluation_utils_2d.group_by_key", "sorted", "len", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.where", "numpy.where", "numpy.sum", "numpy.sum", "numpy.cumsum", "numpy.cumsum", "numpy.min", "numpy.array", "numpy.array", "numpy.zeros", "enumerate", "group_by_key.items", "group_by_key.items", "len", "len", "len", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.max", "numpy.argmax", "numpy.maximum", "numpy.maximum", "numpy.argmin", "len", "len", "float"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key"], ["", "def", "compute_mu_error", "(", "gt", ",", "predictions", ",", "thresholds", ")", ":", "\n", "    ", "num_gts", "=", "len", "(", "gt", ")", "\n", "image_gts", "=", "group_by_key", "(", "gt", ",", "'name'", ")", "\n", "image_gt_boxes", "=", "{", "k", ":", "np", ".", "array", "(", "[", "[", "float", "(", "z", ")", "for", "z", "in", "b", "[", "'bbox'", "]", "]", "\n", "for", "b", "in", "boxes", "]", ")", "\n", "for", "k", ",", "boxes", "in", "image_gts", ".", "items", "(", ")", "}", "\n", "image_gt_checked", "=", "{", "k", ":", "np", ".", "zeros", "(", "(", "len", "(", "boxes", ")", ",", "len", "(", "thresholds", ")", ")", ")", "\n", "for", "k", ",", "boxes", "in", "image_gts", ".", "items", "(", ")", "}", "\n", "\n", "# rank based on entropy:", "\n", "predictions", "=", "sorted", "(", "\n", "predictions", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "'entropy_score'", "]", ",", "\n", "reverse", "=", "False", ")", "\n", "\n", "# go down dets and mark TPs and FPs", "\n", "nd", "=", "len", "(", "predictions", ")", "\n", "tp", "=", "np", ".", "zeros", "(", "(", "nd", ",", "len", "(", "thresholds", ")", ")", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "(", "nd", ",", "len", "(", "thresholds", ")", ")", ")", "\n", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "box", "=", "p", "[", "'bbox'", "]", "\n", "ovmax", "=", "-", "np", ".", "inf", "\n", "jmax", "=", "-", "1", "\n", "try", ":", "\n", "            ", "gt_boxes", "=", "image_gt_boxes", "[", "p", "[", "'name'", "]", "]", "\n", "gt_checked", "=", "image_gt_checked", "[", "p", "[", "'name'", "]", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "gt_boxes", "=", "[", "]", "\n", "gt_checked", "=", "None", "\n", "\n", "", "p", "[", "'iou'", "]", "=", "0.0", "\n", "if", "len", "(", "gt_boxes", ")", ">", "0", ":", "\n", "# compute overlaps", "\n", "# intersection", "\n", "            ", "ixmin", "=", "np", ".", "maximum", "(", "gt_boxes", "[", ":", ",", "0", "]", ",", "box", "[", "0", "]", ")", "\n", "iymin", "=", "np", ".", "maximum", "(", "gt_boxes", "[", ":", ",", "1", "]", ",", "box", "[", "1", "]", ")", "\n", "ixmax", "=", "np", ".", "minimum", "(", "gt_boxes", "[", ":", ",", "2", "]", ",", "box", "[", "2", "]", ")", "\n", "iymax", "=", "np", ".", "minimum", "(", "gt_boxes", "[", ":", ",", "3", "]", ",", "box", "[", "3", "]", ")", "\n", "iw", "=", "np", ".", "maximum", "(", "ixmax", "-", "ixmin", "+", "1.", ",", "0.", ")", "\n", "ih", "=", "np", ".", "maximum", "(", "iymax", "-", "iymin", "+", "1.", ",", "0.", ")", "\n", "inters", "=", "iw", "*", "ih", "\n", "\n", "# union", "\n", "uni", "=", "(", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1.", ")", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1.", ")", "+", "\n", "(", "gt_boxes", "[", ":", ",", "2", "]", "-", "gt_boxes", "[", ":", ",", "0", "]", "+", "1.", ")", "*", "\n", "(", "gt_boxes", "[", ":", ",", "3", "]", "-", "gt_boxes", "[", ":", ",", "1", "]", "+", "1.", ")", "-", "inters", ")", "\n", "\n", "overlaps", "=", "inters", "/", "uni", "\n", "ovmax", "=", "np", ".", "max", "(", "overlaps", ")", "\n", "jmax", "=", "np", ".", "argmax", "(", "overlaps", ")", "\n", "p", "[", "'iou'", "]", "=", "ovmax", "\n", "\n", "", "for", "t", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "            ", "if", "ovmax", ">", "threshold", ":", "\n", "                ", "if", "gt_checked", "[", "jmax", ",", "t", "]", "==", "0", ":", "\n", "                    ", "p", "[", "'is_tp'", "]", "=", "1", "\n", "tp", "[", "i", ",", "t", "]", "=", "1.", "\n", "gt_checked", "[", "jmax", ",", "t", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "p", "[", "'is_tp'", "]", "=", "0", "\n", "fp", "[", "i", ",", "t", "]", "=", "1.", "\n", "", "", "else", ":", "\n", "                ", "p", "[", "'is_tp'", "]", "=", "0", "\n", "fp", "[", "i", ",", "t", "]", "=", "1.", "\n", "\n", "", "", "", "tp_ind", ",", "_", "=", "np", ".", "where", "(", "tp", "==", "1", ")", "\n", "fp_ind", ",", "_", "=", "np", ".", "where", "(", "fp", "==", "1", ")", "\n", "\n", "total_tp", "=", "np", ".", "sum", "(", "tp", ",", "axis", "=", "0", ")", "\n", "total_fp", "=", "np", ".", "sum", "(", "fp", ",", "axis", "=", "0", ")", "\n", "\n", "fp", "=", "np", ".", "cumsum", "(", "fp", ",", "axis", "=", "0", ")", "\n", "tp", "=", "np", ".", "cumsum", "(", "tp", ",", "axis", "=", "0", ")", "\n", "\n", "u_error", "=", "0.5", "*", "(", "total_tp", "-", "tp", ")", "/", "np", ".", "maximum", "(", "total_tp", ",", "\n", "1.0", ")", "+", "0.5", "*", "fp", "/", "np", ".", "maximum", "(", "total_fp", ",", "1.0", ")", "\n", "min_u_error", "=", "np", ".", "min", "(", "u_error", ")", "\n", "\n", "scores", "=", "np", ".", "array", "(", "[", "prediction", "[", "'entropy_score'", "]", "\n", "for", "prediction", "in", "predictions", "]", ")", "\n", "score_at_min_u_error", "=", "scores", "[", "np", ".", "argmin", "(", "u_error", ")", "]", "\n", "\n", "return", "min_u_error", ",", "score_at_min_u_error", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.evaluate_detection": [[215, 234], ["evaluation_utils_2d.group_by_key", "evaluation_utils_2d.group_by_key", "sorted", "numpy.zeros", "numpy.zeros_like", "numpy.zeros_like", "enumerate", "numpy.mean", "group_by_key.keys", "np.zeros.flatten().tolist", "np.zeros_like.flatten().tolist", "np.zeros_like.flatten().tolist", "len", "len", "evaluation_utils_2d.cat_pc", "np.zeros.flatten", "np.zeros_like.flatten", "np.zeros_like.flatten"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.cat_pc"], ["", "def", "evaluate_detection", "(", "gt", ",", "pred", ",", "iou_thresholds", "=", "[", "0.5", "]", ")", ":", "\n", "\n", "    ", "cat_gt", "=", "group_by_key", "(", "gt", ",", "'category'", ")", "\n", "cat_pred", "=", "group_by_key", "(", "pred", ",", "'category'", ")", "\n", "cat_list", "=", "sorted", "(", "cat_gt", ".", "keys", "(", ")", ")", "\n", "aps", "=", "np", ".", "zeros", "(", "(", "len", "(", "iou_thresholds", ")", ",", "len", "(", "cat_list", ")", ")", ")", "\n", "optimal_score_thresholds", "=", "np", ".", "zeros_like", "(", "aps", ")", "\n", "maximum_f_scores", "=", "np", ".", "zeros_like", "(", "aps", ")", "\n", "for", "i", ",", "cat", "in", "enumerate", "(", "cat_list", ")", ":", "\n", "        ", "if", "cat", "in", "cat_pred", ":", "\n", "            ", "r", ",", "p", ",", "ap", ",", "optimal_score_threshold", ",", "maximum_f_score", "=", "cat_pc", "(", "\n", "cat_gt", "[", "cat", "]", ",", "cat_pred", "[", "cat", "]", ",", "iou_thresholds", ")", "\n", "aps", "[", ":", ",", "i", "]", "=", "ap", "\n", "optimal_score_thresholds", "[", ":", ",", "i", "]", "=", "optimal_score_threshold", "\n", "maximum_f_scores", "[", ":", ",", "i", "]", "=", "maximum_f_score", "\n", "", "", "aps", "*=", "100", "\n", "mAP", "=", "np", ".", "mean", "(", "aps", ")", "\n", "return", "mAP", ",", "aps", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ",", "cat_list", ",", "optimal_score_thresholds", ".", "flatten", "(", "\n", ")", ".", "tolist", "(", ")", ",", "maximum_f_scores", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.evaluate_u_error": [[236, 251], ["evaluation_utils_2d.group_by_key", "evaluation_utils_2d.group_by_key", "sorted", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.mean", "group_by_key.keys", "np.zeros.flatten().tolist", "np.zeros.flatten().tolist", "len", "len", "len", "len", "evaluation_utils_2d.compute_mu_error", "np.zeros.flatten", "np.zeros.flatten"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_mu_error"], ["", "def", "evaluate_u_error", "(", "gt", ",", "pred", ",", "iou_thresholds", "=", "[", "0.5", "]", ")", ":", "\n", "    ", "cat_gt", "=", "group_by_key", "(", "gt", ",", "'category'", ")", "\n", "cat_pred", "=", "group_by_key", "(", "pred", ",", "'category'", ")", "\n", "cat_list", "=", "sorted", "(", "cat_gt", ".", "keys", "(", ")", ")", "\n", "min_u_errors", "=", "np", ".", "zeros", "(", "(", "len", "(", "iou_thresholds", ")", ",", "len", "(", "cat_list", ")", ")", ")", "\n", "scores_at_min_u_errors", "=", "np", ".", "zeros", "(", "(", "len", "(", "iou_thresholds", ")", ",", "len", "(", "cat_list", ")", ")", ")", "\n", "\n", "for", "i", ",", "cat", "in", "enumerate", "(", "cat_list", ")", ":", "\n", "        ", "if", "cat", "in", "cat_pred", ":", "\n", "            ", "min_u_errors", "[", ":", ",", "i", "]", ",", "scores_at_min_u_errors", "[", ":", ",", "i", "]", "=", "compute_mu_error", "(", "\n", "cat_gt", "[", "cat", "]", ",", "cat_pred", "[", "cat", "]", ",", "iou_thresholds", ")", "\n", "\n", "", "", "min_u_error", "=", "np", ".", "mean", "(", "min_u_errors", ")", "\n", "return", "min_u_errors", ".", "flatten", "(", ")", ".", "tolist", "(", "\n", ")", ",", "min_u_error", ",", "cat_list", ",", "scores_at_min_u_errors", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.get_ap": [[253, 270], ["numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "numpy.maximum", "numpy.where"], "function", ["None"], ["", "def", "get_ap", "(", "recalls", ",", "precisions", ")", ":", "\n", "# correct AP calculation", "\n", "# first append sentinel values at the end", "\n", "    ", "recalls", "=", "np", ".", "concatenate", "(", "(", "[", "0.", "]", ",", "recalls", ",", "[", "1.", "]", ")", ")", "\n", "precisions", "=", "np", ".", "concatenate", "(", "(", "[", "0.", "]", ",", "precisions", ",", "[", "0.", "]", ")", ")", "\n", "\n", "# compute the precision envelope", "\n", "for", "i", "in", "range", "(", "precisions", ".", "size", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "        ", "precisions", "[", "i", "-", "1", "]", "=", "np", ".", "maximum", "(", "precisions", "[", "i", "-", "1", "]", ",", "precisions", "[", "i", "]", ")", "\n", "\n", "# to calculate area under PR curve, look for points", "\n", "# where X axis (recall) changes value", "\n", "", "i", "=", "np", ".", "where", "(", "recalls", "[", "1", ":", "]", "!=", "recalls", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# and sum (\\Delta recall) * prec", "\n", "ap", "=", "np", ".", "sum", "(", "(", "recalls", "[", "i", "+", "1", "]", "-", "recalls", "[", "i", "]", ")", "*", "precisions", "[", "i", "+", "1", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.group_by_key": [[272, 277], ["collections.defaultdict", "groups[].append"], "function", ["None"], ["", "def", "group_by_key", "(", "detections", ",", "key", ")", ":", "\n", "    ", "groups", "=", "defaultdict", "(", "list", ")", "\n", "for", "d", "in", "detections", ":", "\n", "        ", "groups", "[", "d", "[", "key", "]", "]", ".", "append", "(", "d", ")", "\n", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_gaussian_entropy_np": [[280, 286], ["numpy.round", "numpy.linalg.det", "numpy.log", "numpy.log"], "function", ["None"], ["", "def", "compute_gaussian_entropy_np", "(", "cov", ")", ":", "\n", "    ", "dims_constant", "=", "cov", ".", "shape", "[", "1", "]", "/", "2.0", "\n", "determinant", "=", "np", ".", "round", "(", "np", ".", "linalg", ".", "det", "(", "cov", ")", ",", "5", ")", "+", "1e-12", "\n", "entropy", "=", "dims_constant", "+", "dims_constant", "*", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "+", "0.5", "*", "np", ".", "log", "(", "determinant", ")", "\n", "return", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.compute_categorical_entropy_np": [[288, 291], ["numpy.sum", "numpy.log"], "function", ["None"], ["", "def", "compute_categorical_entropy_np", "(", "cat_params", ")", ":", "\n", "    ", "entropy", "=", "-", "np", ".", "sum", "(", "cat_params", "*", "np", ".", "log", "(", "cat_params", ")", ")", "\n", "return", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.calc_heatmap": [[293, 330], ["numpy.array", "evaluation_utils_2d.gen_single_heatmap", "evaluation_utils_2d.gen_single_heatmap", "numpy.fliplr", "numpy.flipud", "numpy.flipud", "numpy.fliplr", "numpy.array"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.gen_single_heatmap", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.gen_single_heatmap"], ["", "def", "calc_heatmap", "(", "box", ",", "covs", ",", "img_size", ")", ":", "\n", "    ", "\"\"\"\n    :param box: list of BBox corners, used to define the Gaussian corner mean locations for the box.\n        Formatted [x1, y1, x2, y2]\n    :param covs: list of two 2D covariance matrices used to define the covariances of the Gaussian corners.\n        Formatted [cov1, cov2] where cov1 and cov2 are formatted [[var_x, corr], [corr, var_y]]\n    :param img_size: size of the input image\n    \"\"\"", "\n", "\n", "# get all covs in format (y,x) to match matrix ordering", "\n", "covs_processed", "=", "[", "covs", "[", "2", ":", "4", ",", "2", ":", "4", "]", ",", "covs", "[", "0", ":", "2", ",", "0", ":", "2", "]", "]", "\n", "covs2", "=", "[", "np", ".", "flipud", "(", "np", ".", "fliplr", "(", "cov", ")", ")", "for", "cov", "in", "covs_processed", "]", "\n", "\n", "box_processed", "=", "np", ".", "array", "(", "[", "box", "[", "1", "]", ",", "box", "[", "0", "]", ",", "box", "[", "3", "]", ",", "box", "[", "2", "]", "]", ")", "\n", "\n", "prob1", "=", "gen_single_heatmap", "(", "\n", "img_size", ",", "[", "\n", "box_processed", "[", "1", "]", ",", "box_processed", "[", "0", "]", "]", ",", "covs2", "[", "0", "]", ")", "\n", "\n", "prob2", "=", "gen_single_heatmap", "(", "img_size", ",", "\n", "[", "img_size", "[", "0", "]", "-", "(", "box_processed", "[", "3", "]", "+", "1", ")", ",", "\n", "img_size", "[", "1", "]", "-", "(", "box_processed", "[", "2", "]", "+", "1", ")", "]", ",", "\n", "np", ".", "array", "(", "covs2", "[", "1", "]", ")", ".", "T", ")", "\n", "# flip left-right and up-down to provide probability in from bottom-right", "\n", "# corner", "\n", "prob2", "=", "np", ".", "fliplr", "(", "np", ".", "flipud", "(", "prob2", ")", ")", "\n", "\n", "# generate final heatmap", "\n", "heatmap", "=", "prob1", "*", "prob2", "\n", "\n", "# Hack to enforce that there are no pixels with probs greater than 1 due", "\n", "# to floating point errors", "\n", "heatmap", "[", "heatmap", ">", "1", "]", "=", "1", "\n", "\n", "heatmap", "[", "heatmap", "<", "_HEATMAP_THRESH", "]", "=", "0", "\n", "\n", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.gen_single_heatmap": [[332, 394], ["numpy.zeros", "scipy.stats.multivariate_normal", "evaluation_utils_2d.find_roi", "scipy.stats.multivariate_normal.cdf", "numpy.array", "numpy.dstack", "len", "numpy.array", "numpy.zeros", "scipy.stats.multivariate_normal.cdf", "numpy.zeros", "scipy.stats.multivariate_normal.cdf", "scipy.stats.multivariate_normal.cdf", "numpy.dstack", "numpy.dstack", "numpy.np.array().T"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.find_roi"], ["", "def", "gen_single_heatmap", "(", "img_size", ",", "mean", ",", "cov", ")", ":", "\n", "    ", "\"\"\"\n    Function for generating the heatmap for a given Gaussian corner.\n    :param img_size: tuple: formatted (n_rows, n_cols) depicting the size of the image\n    :param mean: list: formatted [mu_y, mu_x] describes the location of the mean of the Gaussian corner.\n    :param cov: 2D array: formatted [[var_y, corr], [corr, var_x]] describes the covariance of the Gaussian corner.\n    :return: heatmap image of size <img_size> with spatial probabilities between 0 and 1.\n    \"\"\"", "\n", "heatmap", "=", "np", ".", "zeros", "(", "img_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "g", "=", "multivariate_normal", "(", "mean", "=", "mean", ",", "cov", "=", "cov", ",", "allow_singular", "=", "True", ")", "\n", "\n", "roi_box", "=", "find_roi", "(", "img_size", ",", "mean", ",", "cov", ")", "\n", "# Note that we subtract small value to avoid fencepost issues with", "\n", "# extremely low covariances.", "\n", "positions", "=", "np", ".", "dstack", "(", "\n", "np", ".", "mgrid", "[", "roi_box", "[", "1", "]", "+", "1", ":", "roi_box", "[", "3", "]", "+", "2", ",", "roi_box", "[", "0", "]", "+", "1", ":", "roi_box", "[", "2", "]", "+", "2", "]", ")", "-", "_SMALL_VAL", "\n", "\n", "prob", "=", "g", ".", "cdf", "(", "positions", ")", "\n", "\n", "if", "len", "(", "prob", ".", "shape", ")", "==", "1", ":", "\n", "        ", "prob", ".", "shape", "=", "(", "roi_box", "[", "3", "]", "+", "1", "-", "roi_box", "[", "1", "]", ",", "roi_box", "[", "2", "]", "+", "1", "-", "roi_box", "[", "0", "]", ")", "\n", "\n", "", "heatmap", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "1", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", "=", "prob", "\n", "heatmap", "[", "roi_box", "[", "3", "]", ":", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", "=", "np", ".", "array", "(", "heatmap", "[", "roi_box", "[", "3", "]", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", ",", "ndmin", "=", "2", ")", "\n", "heatmap", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "\n", "1", ",", "roi_box", "[", "2", "]", ":", "]", "=", "np", ".", "array", "(", "heatmap", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "\n", "1", ",", "roi_box", "[", "2", "]", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "heatmap", "[", "roi_box", "[", "3", "]", "+", "1", ":", ",", "roi_box", "[", "2", "]", "+", "1", ":", "]", "=", "1.0", "\n", "\n", "# If your region of interest includes outside the main image, remove probability of existing outside the image", "\n", "# Remove probability of being outside in the x direction", "\n", "if", "roi_box", "[", "0", "]", "==", "0", ":", "\n", "# points left of the image", "\n", "        ", "pos_outside_x", "=", "np", ".", "dstack", "(", "\n", "np", ".", "mgrid", "[", "roi_box", "[", "1", "]", "+", "1", ":", "roi_box", "[", "3", "]", "+", "2", ",", "0", ":", "1", "]", ")", "-", "_SMALL_VAL", "\n", "prob_outside_x", "=", "np", ".", "zeros", "(", "(", "img_size", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "prob_outside_x", "[", "roi_box", "[", "1", "]", ":", "roi_box", "[", "3", "]", "+", "1", ",", "0", "]", "=", "g", ".", "cdf", "(", "pos_outside_x", ")", "\n", "prob_outside_x", "[", "roi_box", "[", "3", "]", "+", "1", ":", ",", "0", "]", "=", "prob_outside_x", "[", "roi_box", "[", "3", "]", ",", "0", "]", "\n", "# Final probability is your overall cdf minus the probability in-line with that point along", "\n", "# the border for both dimensions plus the cdf at (-1, -1) which has", "\n", "# points counted twice otherwise", "\n", "heatmap", "-=", "prob_outside_x", "\n", "\n", "# Remove probability of being outside in the x direction", "\n", "", "if", "roi_box", "[", "1", "]", "==", "0", ":", "\n", "# points above the image", "\n", "        ", "pos_outside_y", "=", "np", ".", "dstack", "(", "\n", "np", ".", "mgrid", "[", "0", ":", "1", ",", "roi_box", "[", "0", "]", "+", "1", ":", "roi_box", "[", "2", "]", "+", "2", "]", ")", "-", "_SMALL_VAL", "\n", "prob_outside_y", "=", "np", ".", "zeros", "(", "(", "1", ",", "img_size", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "prob_outside_y", "[", "0", ",", "roi_box", "[", "0", "]", ":", "roi_box", "[", "2", "]", "+", "1", "]", "=", "g", ".", "cdf", "(", "pos_outside_y", ")", "\n", "prob_outside_y", "[", "0", ",", "roi_box", "[", "2", "]", "+", "1", ":", "]", "=", "prob_outside_y", "[", "0", ",", "roi_box", "[", "2", "]", "]", "\n", "heatmap", "-=", "prob_outside_y", "\n", "\n", "# If we've subtracted twice, we need to re-add the probability of the far", "\n", "# corner", "\n", "", "if", "roi_box", "[", "0", "]", "==", "0", "and", "roi_box", "[", "1", "]", "==", "0", ":", "\n", "        ", "heatmap", "+=", "g", ".", "cdf", "(", "[", "[", "[", "0", "-", "_SMALL_VAL", ",", "0", "-", "_SMALL_VAL", "]", "]", "]", ")", "\n", "\n", "", "heatmap", "[", "heatmap", "<", "_HEATMAP_THRESH", "]", "=", "0", "\n", "\n", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.find_roi": [[396, 452], ["int", "int", "int", "int", "numpy.indices().T.reshape", "scipy.spatial.distance.cdist", "max", "max", "evaluation_utils_2d.generate_bounding_box_from_mask", "max", "max", "min", "min", "numpy.abs", "numpy.array", "scipy.spatial.distance.cdist.reshape", "min", "min", "numpy.linalg.det", "numpy.linalg.inv", "int", "int", "numpy.indices"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.generate_bounding_box_from_mask"], ["", "def", "find_roi", "(", "img_size", ",", "mean", ",", "cov", ")", ":", "\n", "    ", "\"\"\"\n    Function for finding the region of interest for a probability heatmap generated by a Gaussian corner.\n    This region of interest is the area with most change therein, with probabilities above 0.0027 and below 0.9973\n    :param img_size: tuple: formatted (n_rows, n_cols) depicting the size of the image\n    :param mean: list: formatted [mu_y, mu_x] describes the location of the mean of the Gaussian corner.\n    :param cov: 2D array: formatted [[var_y, corr], [corr, var_x]] describes the covariance of the Gaussian corner.\n    :return: roi_box formatted [x1, y1, x2, y2] depicting the corners of the region of interest (inclusive)\n    \"\"\"", "\n", "\n", "# Calculate approximate ROI", "\n", "stdy", "=", "cov", "[", "0", ",", "0", "]", "**", "0.5", "\n", "stdx", "=", "cov", "[", "1", ",", "1", "]", "**", "0.5", "\n", "\n", "minx", "=", "int", "(", "max", "(", "mean", "[", "1", "]", "-", "stdx", "*", "5", ",", "0", ")", ")", "\n", "miny", "=", "int", "(", "max", "(", "mean", "[", "0", "]", "-", "stdy", "*", "5", ",", "0", ")", ")", "\n", "maxx", "=", "int", "(", "min", "(", "mean", "[", "1", "]", "+", "stdx", "*", "5", ",", "img_size", "[", "1", "]", "-", "1", ")", ")", "\n", "maxy", "=", "int", "(", "min", "(", "mean", "[", "0", "]", "+", "stdy", "*", "5", ",", "img_size", "[", "0", "]", "-", "1", ")", ")", "\n", "\n", "# If the covariance is singular, we can't do any better in our estimate.", "\n", "if", "np", ".", "abs", "(", "np", ".", "linalg", ".", "det", "(", "cov", ")", ")", "<", "1e-8", ":", "\n", "        ", "return", "minx", ",", "miny", ",", "maxx", ",", "maxy", "\n", "\n", "# produce list of positions [y,x] to compare to the given mean location", "\n", "", "approx_roi_shape", "=", "(", "maxy", "+", "1", "-", "miny", ",", "maxx", "+", "1", "-", "minx", ")", "\n", "positions", "=", "np", ".", "indices", "(", "approx_roi_shape", ")", ".", "T", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "positions", "[", ":", ",", "0", "]", "+=", "miny", "\n", "positions", "[", ":", ",", "1", "]", "+=", "minx", "\n", "# Calculate the mahalanobis distances to those locations (number of standard deviations)", "\n", "# Can only do this for non-singular matrices", "\n", "mdists", "=", "cdist", "(", "\n", "positions", ",", "\n", "np", ".", "array", "(", "\n", "[", "mean", "]", ")", ",", "\n", "metric", "=", "'mahalanobis'", ",", "\n", "VI", "=", "np", ".", "linalg", ".", "inv", "(", "cov", ")", ")", "\n", "mdists", "=", "mdists", ".", "reshape", "(", "approx_roi_shape", "[", "1", "]", ",", "approx_roi_shape", "[", "0", "]", ")", ".", "T", "\n", "\n", "# Shift around the mean to change which corner of the pixel we're using", "\n", "# for the mahalanobis distance", "\n", "dist_meany", "=", "max", "(", "min", "(", "int", "(", "mean", "[", "0", "]", "-", "miny", ")", ",", "img_size", "[", "0", "]", "-", "1", ")", ",", "0", ")", "\n", "dist_meanx", "=", "max", "(", "min", "(", "int", "(", "mean", "[", "1", "]", "-", "minx", ")", ",", "img_size", "[", "1", "]", "-", "1", ")", ",", "0", ")", "\n", "if", "0", "<", "dist_meany", "<", "img_size", "[", "0", "]", "-", "1", ":", "\n", "        ", "mdists", "[", ":", "dist_meany", ",", ":", "]", "=", "mdists", "[", "1", ":", "dist_meany", "+", "1", ",", ":", "]", "\n", "", "if", "0", "<", "dist_meanx", "<", "img_size", "[", "1", "]", "-", "1", ":", "\n", "        ", "mdists", "[", ":", ",", ":", "dist_meanx", "]", "=", "mdists", "[", ":", ",", "1", ":", "dist_meanx", "+", "1", "]", "\n", "\n", "# Mask out samples that are outside the desired distance (extremely low", "\n", "# probability points)", "\n", "", "mask", "=", "mdists", "<=", "_2D_MAH_DIST_THRESH", "\n", "# Force the pixel containing the mean to be true, we always care about that", "\n", "mask", "[", "dist_meany", ",", "dist_meanx", "]", "=", "True", "\n", "roi_box", "=", "generate_bounding_box_from_mask", "(", "mask", ")", "\n", "\n", "return", "roi_box", "[", "0", "]", "+", "minx", ",", "roi_box", "[", "1", "]", "+", "miny", ",", "roi_box", "[", "2", "]", "+", "minx", ",", "roi_box", "[", "3", "]", "+", "miny", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.generate_bounding_box_from_mask": [[454, 465], ["numpy.any", "numpy.any", "numpy.argmax", "numpy.argmax", "ValueError", "numpy.argmax", "numpy.argmax", "numpy.any", "numpy.any", "len", "len"], "function", ["None"], ["", "def", "generate_bounding_box_from_mask", "(", "mask", ")", ":", "\n", "    ", "flat_x", "=", "np", ".", "any", "(", "mask", ",", "axis", "=", "0", ")", "\n", "flat_y", "=", "np", ".", "any", "(", "mask", ",", "axis", "=", "1", ")", "\n", "if", "not", "np", ".", "any", "(", "flat_x", ")", "and", "not", "np", ".", "any", "(", "flat_y", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"No positive pixels found, cannot compute bounding box\"", ")", "\n", "", "xmin", "=", "np", ".", "argmax", "(", "flat_x", ")", "\n", "ymin", "=", "np", ".", "argmax", "(", "flat_y", ")", "\n", "xmax", "=", "len", "(", "flat_x", ")", "-", "1", "-", "np", ".", "argmax", "(", "flat_x", "[", ":", ":", "-", "1", "]", ")", "\n", "ymax", "=", "len", "(", "flat_y", ")", "-", "1", "-", "np", ".", "argmax", "(", "flat_y", "[", ":", ":", "-", "1", "]", ")", "\n", "return", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.root_dir": [[4, 6], ["os.path.dirname", "os.path.realpath"], "function", ["None"], []], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.model_dir": [[8, 10], ["os.sep.join", "__init__.top_dir"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.top_dir"], []], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.top_dir": [[12, 14], ["os.sep.join", "root_dir().split", "__init__.root_dir"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.root_dir"], []], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir": [[16, 18], ["__init__.top_dir"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.top_dir"], []], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.losses.SoftmaxFocalLoss.__init__": [[11, 29], ["super().__init__", "keras.losses.CategoricalCrossentropy"], "methods", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "gamma", "=", "2", ",", "\n", "alpha", "=", "0.5", ",", "\n", "temperature", "=", "1.0", ",", "\n", "label_smoothing_epsilon", "=", "0.001", ",", "\n", "reduction", "=", "keras", ".", "losses", ".", "Reduction", ".", "NONE", ")", ":", "\n", "        ", "super", "(", "SoftmaxFocalLoss", ",", "self", ")", ".", "__init__", "(", "reduction", "=", "reduction", ",", "\n", "name", "=", "'focal_loss'", ")", "\n", "\n", "self", ".", "cross_entropy", "=", "keras", ".", "losses", ".", "CategoricalCrossentropy", "(", "\n", "from_logits", "=", "True", ",", "\n", "label_smoothing", "=", "label_smoothing_epsilon", ",", "\n", "reduction", "=", "self", ".", "reduction", ")", "\n", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.losses.SoftmaxFocalLoss.call": [[30, 62], ["tensorflow.divide", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "losses.SoftmaxFocalLoss.cross_entropy", "tensorflow.pow", "tensorflow.reduce_max"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "target_tensor", ",", "prediction_tensor", ")", ":", "\n", "# Divide logits by temperature.", "\n", "# A temperature value > 1.0 defuses predictions, making the network less confident.", "\n", "# A temperature value < 1.0 but > 0.0 peaks predictions, making the", "\n", "# network more confident.", "\n", "        ", "prediction_tensor", "=", "tf", ".", "divide", "(", "prediction_tensor", ",", "\n", "self", ".", "temperature", ",", "\n", "name", "=", "'scale_logit'", ")", "\n", "\n", "# Compute background and positive targets to get weighting_factor.", "\n", "# This is not the exact formulation in the paper, but a workable", "\n", "# approximation.", "\n", "\n", "stable_prediction", "=", "prediction_tensor", "-", "tf", ".", "reduce_max", "(", "prediction_tensor", ",", "axis", "=", "2", ",", "keepdims", "=", "True", ")", "\n", "stable_softmax", "=", "tf", ".", "nn", ".", "softmax", "(", "stable_prediction", ")", "\n", "stable_softmax", "=", "tf", ".", "reduce_sum", "(", "stable_softmax", "*", "target_tensor", ",", "axis", "=", "2", ")", "\n", "\n", "per_row_cross_ent", "=", "self", ".", "cross_entropy", "(", "target_tensor", ",", "\n", "prediction_tensor", ")", "\n", "# Gamma modulating factor", "\n", "focusing_factor", "=", "tf", ".", "pow", "(", "\n", "(", "1", "-", "stable_softmax", ")", ",", "self", ".", "gamma", ")", "\n", "\n", "# Alpha factor, shared among all classes", "\n", "negative_mask", "=", "target_tensor", "[", ":", ",", ":", ",", "-", "1", "]", "\n", "positive_mask", "=", "1", "-", "negative_mask", "\n", "\n", "alpha_modulating_factor", "=", "self", ".", "alpha", "*", "positive_mask", "+", "(", "1", "-", "self", ".", "alpha", ")", "*", "negative_mask", "\n", "\n", "return", "alpha_modulating_factor", "*", "focusing_factor", "*", "per_row_cross_ent", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.__init__": [[8, 10], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "generator_config", ")", ":", "\n", "        ", "self", ".", "config", "=", "generator_config", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.anchor_generator.AnchorGenerator.generate_anchors": [[11, 14], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "generate_anchors", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.__init__": [[9, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset_config", ")", ":", "\n", "\n", "# Parse dataset config shared params", "\n", "        ", "self", ".", "data_split", "=", "dataset_config", "[", "'data_split'", "]", "\n", "self", ".", "im_normalization", "=", "dataset_config", "[", "'im_normalization'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.abstract_classes.dataset_handler.DatasetHandler.create_dataset": [[15, 18], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "create_dataset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.bdd_demo_utils.read_bdd_format": [[4, 62], ["numpy.array", "numpy.array", "numpy.array", "boxes_class_one_hot.append", "len", "numpy.expand_dims", "numpy.array().astype", "numpy.array().astype", "categories.index", "boxes_class_one_hot.append", "range", "len", "cat.lower", "numpy.array", "numpy.array", "range", "len", "len"], "function", ["None"], ["def", "read_bdd_format", "(", "\n", "sample_id", ",", "\n", "bdd_dict", ",", "\n", "categories", "=", "(", "'car'", ",", "'truck'", ",", "'bus'", ",", "'person'", ",", "'rider'", ",", "'bike'", ",", "'motor'", ")", ",", "\n", "pdq_eval", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Reads bdd format from json file output.\n\n    output format is described in bdd dataset as:\n    {\n      \"name\": str,\n      \"timestamp\": 1000,\n      \"category\": str,\n      \"bbox\": [x1, y1, x2, y2],\n      \"score\": float\n   }\n\n\n    \"\"\"", "\n", "# Define constants", "\n", "no_elem", "=", "False", "\n", "boxes_class_one_hot", "=", "[", "]", "\n", "\n", "# Extract the list", "\n", "frame_elements", "=", "[", "elem", "for", "elem", "in", "bdd_dict", "if", "\n", "elem", "[", "'name'", "]", "==", "sample_id", "and", "elem", "[", "\n", "'category'", "]", "in", "categories", "]", "\n", "\n", "if", "pdq_eval", ":", "\n", "        ", "boxes_2d", "=", "np", ".", "array", "(", "[", "label", "[", "'bbox'", "]", "for", "label", "in", "frame_elements", "]", ")", "\n", "", "else", ":", "\n", "        ", "boxes_2d", "=", "np", ".", "array", "(", "[", "[", "label", "[", "'bbox'", "]", "[", "1", "]", ",", "\n", "label", "[", "'bbox'", "]", "[", "0", "]", ",", "\n", "label", "[", "'bbox'", "]", "[", "3", "]", ",", "\n", "label", "[", "'bbox'", "]", "[", "2", "]", "]", "for", "label", "in", "frame_elements", "]", ")", "\n", "\n", "", "boxes_cat", "=", "[", "elem", "[", "'category'", "]", "for", "elem", "in", "frame_elements", "]", "\n", "\n", "if", "boxes_2d", ".", "size", "==", "0", ":", "\n", "        ", "cat_one_hot", "=", "[", "0", "for", "i", "in", "range", "(", "len", "(", "categories", ")", "+", "1", ")", "]", "\n", "cat_one_hot", "[", "len", "(", "categories", ")", "]", "=", "1", "\n", "boxes_2d", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "boxes_class_one_hot", ".", "append", "(", "cat_one_hot", ")", "\n", "no_elem", "=", "True", "\n", "", "else", ":", "\n", "        ", "for", "cat", "in", "boxes_cat", ":", "\n", "            ", "cat_one_hot", "=", "[", "0", "for", "i", "in", "range", "(", "len", "(", "categories", ")", "+", "1", ")", "]", "\n", "cat_idx", "=", "categories", ".", "index", "(", "cat", ".", "lower", "(", ")", ")", "\n", "cat_one_hot", "[", "cat_idx", "]", "=", "1", "\n", "boxes_class_one_hot", ".", "append", "(", "cat_one_hot", ")", "\n", "\n", "# one-hot representation: ['car', 'truck', 'bus', 'person', 'rider', 'bike', 'motor', background]", "\n", "", "", "if", "len", "(", "boxes_2d", ".", "shape", ")", "==", "1", ":", "\n", "        ", "boxes_2d", "=", "np", ".", "expand_dims", "(", "boxes_2d", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "[", "np", ".", "array", "(", "boxes_class_one_hot", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "np", ".", "array", "(", "boxes_2d", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "no_elem", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels": [[8, 69], ["numpy.loadtxt", "numpy.asarray", "numpy.array", "src.kitti_labels_to_boxes_2d", "len", "numpy.array", "labels[].astype", "labels[].astype", "labels[].astype", "labels[].astype", "numpy.array", "boxes_class_gt.append", "len", "numpy.expand_dims", "numpy.array().astype", "numpy.array().astype", "numpy.arange", "difficulty.lower", "np.array.tolist", "inst.lower", "elem.lower", "boxes_class_gt.append", "numpy.array", "numpy.array", "boxes_class_gt.append", "elem.lower", "elem.lower", "elem.lower", "boxes_class_gt.append"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d"], ["def", "read_labels", "(", "\n", "label_path", ",", "\n", "difficulty", "=", "'hard'", ",", "\n", "categories", "=", "(", "\n", "'car'", ",", "\n", "'pedestrian'", ",", "\n", "'cyclist'", ")", ")", ":", "\n", "    ", "\"\"\"\n    Reads ground truth labels and parses them into one hot class representation and groundtruth 2D bounding box.\n\n    \"\"\"", "\n", "# Extract the list", "\n", "labels", "=", "np", ".", "loadtxt", "(", "label_path", ",", "\n", "delimiter", "=", "' '", ",", "\n", "dtype", "=", "str", ",", "\n", "usecols", "=", "np", ".", "arange", "(", "start", "=", "0", ",", "step", "=", "1", ",", "stop", "=", "15", ")", ")", "\n", "\n", "if", "len", "(", "labels", ".", "shape", ")", "==", "1", ":", "\n", "        ", "labels", "=", "np", ".", "array", "(", "[", "labels", ".", "tolist", "(", ")", "]", ")", "\n", "\n", "# Filter labels", "\n", "", "diff_dict", "=", "constants", ".", "KITTI_DIFF_DICTS", "[", "difficulty", ".", "lower", "(", ")", "]", "\n", "min_height", "=", "diff_dict", "[", "'min_height'", "]", "\n", "max_truncation", "=", "diff_dict", "[", "'max_truncation'", "]", "\n", "max_occlusion", "=", "diff_dict", "[", "'max_occlusion'", "]", "\n", "\n", "heights", "=", "labels", "[", ":", ",", "7", "]", ".", "astype", "(", "\n", "np", ".", "float32", ")", "-", "labels", "[", ":", ",", "5", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "class_filter", "=", "np", ".", "asarray", "(", "\n", "[", "inst", ".", "lower", "(", ")", "in", "categories", "for", "inst", "in", "labels", "[", ":", ",", "0", "]", "]", ")", "\n", "\n", "height_filter", "=", "heights", ">=", "min_height", "\n", "truncation_filter", "=", "labels", "[", ":", ",", "1", "]", ".", "astype", "(", "np", ".", "float", ")", "<=", "max_truncation", "\n", "occlusion_filter", "=", "labels", "[", ":", ",", "2", "]", ".", "astype", "(", "np", ".", "float", ")", "<=", "max_occlusion", "\n", "\n", "final_filter", "=", "class_filter", "&", "height_filter", "&", "truncation_filter", "&", "occlusion_filter", "\n", "\n", "labels", "=", "np", ".", "array", "(", "labels", "[", "final_filter", "]", ")", "\n", "\n", "boxes_2d_gt", "=", "dataset_utils", ".", "kitti_labels_to_boxes_2d", "(", "labels", ")", "\n", "boxes_class_gt", "=", "[", "]", "\n", "\n", "if", "boxes_2d_gt", ".", "size", "==", "0", ":", "\n", "        ", "boxes_2d_gt", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "boxes_class_gt", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "        ", "for", "elem", "in", "labels", "[", ":", ",", "0", "]", ":", "\n", "            ", "if", "elem", ".", "lower", "(", ")", "==", "'car'", ":", "\n", "                ", "boxes_class_gt", ".", "append", "(", "[", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "elem", ".", "lower", "(", ")", "==", "'pedestrian'", "or", "elem", ".", "lower", "(", ")", "==", "'person_sitting'", ":", "\n", "                ", "boxes_class_gt", ".", "append", "(", "[", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "elem", ".", "lower", "(", ")", "==", "'cyclist'", ":", "\n", "                ", "boxes_class_gt", ".", "append", "(", "[", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "\n", "", "", "", "if", "len", "(", "boxes_2d_gt", ".", "shape", ")", "==", "1", ":", "\n", "        ", "boxes_2d_gt", "=", "np", ".", "expand_dims", "(", "boxes_2d_gt", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "boxes_class_gt", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", ",", "np", ".", "array", "(", "boxes_2d_gt", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_predictions": [[71, 128], ["numpy.asarray", "numpy.array", "src.kitti_labels_to_boxes_2d", "warnings.catch_warnings", "warnings.simplefilter", "numpy.loadtxt", "len", "len", "numpy.array", "numpy.array", "boxes_class.append", "len", "numpy.expand_dims", "numpy.expand_dims", "numpy.array().astype", "numpy.array().astype", "numpy.array().astype", "numpy.array", "numpy.array", "numpy.array", "numpy.arange", "np.array.tolist", "inst.lower", "elem.lower", "boxes_class.append", "numpy.array", "numpy.array", "numpy.array", "elem.lower", "boxes_class.append", "elem.lower", "boxes_class.append", "boxes_class.append"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d"], ["", "def", "read_predictions", "(", "\n", "prediction_path", ",", "\n", "categories", "=", "(", "\n", "'car'", ",", "\n", "'pedestrian'", ",", "\n", "'cyclist'", ",", "\n", "'dontcare'", ")", ")", ":", "\n", "    ", "\"\"\"\n    Reads predictions from text file\n\n    \"\"\"", "\n", "# Extract the list", "\n", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "        ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ")", "\n", "predictions", "=", "np", ".", "loadtxt", "(", "prediction_path", ",", "\n", "delimiter", "=", "' '", ",", "\n", "dtype", "=", "str", ",", "\n", "usecols", "=", "np", ".", "arange", "(", "start", "=", "0", ",", "step", "=", "1", ",", "stop", "=", "16", ")", ")", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "]", ")", ",", "np", ".", "array", "(", "[", "]", ")", ",", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "", "if", "len", "(", "predictions", ".", "shape", ")", "==", "1", ":", "\n", "        ", "predictions", "=", "np", ".", "array", "(", "[", "predictions", ".", "tolist", "(", ")", "]", ")", "\n", "\n", "# Filter labels", "\n", "", "class_filter", "=", "np", ".", "asarray", "(", "\n", "[", "inst", ".", "lower", "(", ")", "in", "categories", "for", "inst", "in", "predictions", "[", ":", ",", "0", "]", "]", ")", "\n", "\n", "predictions", "=", "np", ".", "array", "(", "predictions", "[", "class_filter", "]", ")", "\n", "\n", "boxes_2d", "=", "dataset_utils", ".", "kitti_labels_to_boxes_2d", "(", "predictions", ")", "\n", "boxes_score", "=", "predictions", "[", ":", ",", "15", "]", "\n", "boxes_class", "=", "[", "]", "\n", "\n", "if", "boxes_2d", ".", "size", "==", "0", ":", "\n", "        ", "boxes_2d", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "boxes_class", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "        ", "for", "elem", "in", "predictions", "[", ":", ",", "0", "]", ":", "\n", "            ", "if", "elem", ".", "lower", "(", ")", "==", "'car'", ":", "\n", "                ", "boxes_class", ".", "append", "(", "[", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "elem", ".", "lower", "(", ")", "==", "'pedestrian'", ":", "\n", "                ", "boxes_class", ".", "append", "(", "[", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "elem", ".", "lower", "(", ")", "==", "'cyclist'", ":", "\n", "                ", "boxes_class", ".", "append", "(", "[", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "boxes_class", ".", "append", "(", "[", "0", ",", "0", ",", "0", ",", "1", "]", ")", "\n", "\n", "", "", "", "if", "len", "(", "boxes_2d", ".", "shape", ")", "==", "1", ":", "\n", "        ", "boxes_2d", "=", "np", ".", "expand_dims", "(", "boxes_2d", ",", "axis", "=", "0", ")", "\n", "boxes_score", "=", "np", ".", "expand_dims", "(", "boxes_score", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "boxes_class", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", ",", "np", ".", "array", "(", "boxes_2d", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", ",", "np", ".", "array", "(", "boxes_score", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels_tracking": [[130, 187], ["numpy.loadtxt", "numpy.asarray", "numpy.array", "dict", "range", "len", "numpy.array", "labels[].astype", "labels[].astype", "labels[].astype", "labels[].astype", "frame_labels[].astype", "src.kitti_labels_to_boxes_2d", "dict.update", "numpy.arange", "difficulty.lower", "labels[].astype", "np.array.tolist", "inst.lower"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.datasets.dataset_utils.kitti_labels_to_boxes_2d"], ["", "def", "read_labels_tracking", "(", "\n", "label_path", ",", "\n", "num_elems", ",", "\n", "difficulty", "=", "'hard'", ",", "\n", "categories", "=", "(", "\n", "'car'", ",", "\n", "'pedestrian'", ",", "\n", "'cyclist'", ")", ")", ":", "\n", "    ", "\"\"\"\n    Reads ground truth labels and parses them into one hot class representation and groundtruth 2D bounding box.\n\n    \"\"\"", "\n", "# Extract the list", "\n", "labels", "=", "np", ".", "loadtxt", "(", "label_path", ",", "\n", "delimiter", "=", "' '", ",", "\n", "dtype", "=", "str", ",", "\n", "usecols", "=", "np", ".", "arange", "(", "start", "=", "0", ",", "step", "=", "1", ",", "stop", "=", "15", ")", ")", "\n", "\n", "if", "len", "(", "labels", ".", "shape", ")", "==", "1", ":", "\n", "        ", "labels", "=", "np", ".", "array", "(", "[", "labels", ".", "tolist", "(", ")", "]", ")", "\n", "\n", "# Filter labels", "\n", "", "diff_dict", "=", "constants", ".", "KITTI_DIFF_DICTS", "[", "difficulty", ".", "lower", "(", ")", "]", "\n", "min_height", "=", "diff_dict", "[", "'min_height'", "]", "\n", "max_truncation", "=", "diff_dict", "[", "'max_truncation'", "]", "\n", "max_occlusion", "=", "diff_dict", "[", "'max_occlusion'", "]", "\n", "\n", "heights", "=", "labels", "[", ":", ",", "9", "]", ".", "astype", "(", "\n", "np", ".", "float32", ")", "-", "labels", "[", ":", ",", "7", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "class_filter", "=", "np", ".", "asarray", "(", "\n", "[", "inst", ".", "lower", "(", ")", "in", "categories", "for", "inst", "in", "labels", "[", ":", ",", "2", "]", "]", ")", "\n", "\n", "height_filter", "=", "heights", ">=", "min_height", "\n", "truncation_filter", "=", "labels", "[", ":", ",", "3", "]", ".", "astype", "(", "np", ".", "float", ")", "<=", "max_truncation", "\n", "occlusion_filter", "=", "labels", "[", ":", ",", "4", "]", ".", "astype", "(", "np", ".", "float", ")", "<=", "max_occlusion", "\n", "\n", "final_filter", "=", "class_filter", "&", "height_filter", "&", "truncation_filter", "&", "occlusion_filter", "\n", "\n", "labels", "=", "np", ".", "array", "(", "labels", "[", "final_filter", "]", ")", "\n", "\n", "frame_dict", "=", "dict", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_elems", ")", ":", "\n", "        ", "frame_fitler", "=", "labels", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "float", ")", "==", "i", "\n", "frame_labels", "=", "labels", "[", "frame_fitler", "]", "\n", "\n", "obj_id", "=", "frame_labels", "[", ":", ",", "1", "]", ".", "astype", "(", "np", ".", "float", ")", "\n", "boxes_class_gt", "=", "frame_labels", "[", ":", ",", "2", "]", "\n", "boxes_2d_gt", "=", "dataset_utils", ".", "kitti_labels_to_boxes_2d", "(", "\n", "frame_labels", "[", ":", ",", "2", ":", "]", ")", "\n", "\n", "frame_dict", ".", "update", "(", "{", "i", ":", "{", "'boxes_2d_gt'", ":", "boxes_2d_gt", ",", "\n", "'boxes_class_gt'", ":", "boxes_class_gt", ",", "\n", "'obj_id'", ":", "obj_id", "}", "}", ")", "\n", "\n", "", "return", "frame_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d": [[33, 152], ["numpy.ndarray.astype", "len", "numpy.expand_dims", "zip", "zip", "cv2.rectangle", "color_index_list.extend", "cv2.rectangle", "list().index", "color_index_list.extend", "cv2.rectangle", "isinstance", "numpy.int", "numpy.int", "cv2.rectangle", "cv2.putText", "cv2.rectangle", "str", "cv2.getTextSize", "list", "numpy.round"], "function", ["None"], ["def", "draw_box_2d", "(", "\n", "image", ",", "\n", "boxes_2d", ",", "\n", "obj_classes", "=", "None", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "is_gt", "=", "False", ",", "\n", "plot_text", "=", "False", ",", "\n", "text_to_plot", "=", "None", ",", "\n", "line_width", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n\n    :param image: input m x n image\n    :param boxes_2d: 2D bounding boxes, k x 4 represented as [v_min u_min v_max u_max]\n    :param obj_classes: Categorization of object, to be used to determine colour\n    :param plot_text: boolean to indicate if any form of text (Score or IOU for example) needs to be ploted\n    :param text_to_plot: 1 text entry per bounding box\n    :param line_width: Box line width\n    :param is_gt: boolean indicator if ground truth\n    :return:\n    \"\"\"", "\n", "\n", "if", "dataset", "==", "'bdd'", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_BDD", "\n", "", "elif", "dataset", "==", "'kitti'", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_KITTI", "\n", "", "else", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_COCO", "\n", "\n", "", "if", "boxes_2d", ".", "size", "==", "0", ":", "\n", "        ", "return", "image", "[", ":", "]", "\n", "\n", "", "if", "len", "(", "boxes_2d", ".", "shape", ")", "==", "1", ":", "\n", "        ", "boxes_2d", "=", "np", ".", "expand_dims", "(", "boxes_2d", ",", "axis", "=", "0", ")", "\n", "\n", "", "boxes_2d", "=", "np", ".", "ndarray", ".", "astype", "(", "boxes_2d", ",", "np", ".", "int32", ")", "\n", "\n", "image_out", "=", "image", "[", ":", "]", "\n", "color_index_list", "=", "[", "]", "\n", "if", "boxes_2d", ".", "size", ":", "\n", "        ", "if", "obj_classes", "is", "not", "None", ":", "\n", "            ", "for", "box_2d", ",", "obj_class", "in", "zip", "(", "boxes_2d", ",", "obj_classes", ")", ":", "\n", "                ", "if", "is_gt", ":", "\n", "                    ", "color_index_list", ".", "extend", "(", "[", "1", "]", ")", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_2d", "[", "1", "]", ",", "box_2d", "[", "0", "]", ")", ",", "\n", "(", "box_2d", "[", "3", "]", ",", "box_2d", "[", "2", "]", ")", ",", "\n", "(", "0", ",", "255", ",", "0", ")", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "color_index", "=", "list", "(", "obj_class", "==", "1", ")", ".", "index", "(", "True", ")", "\n", "color_index_list", ".", "extend", "(", "[", "color_index", "]", ")", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_2d", "[", "1", "]", ",", "\n", "box_2d", "[", "0", "]", ")", ",", "\n", "(", "box_2d", "[", "3", "]", ",", "\n", "box_2d", "[", "2", "]", ")", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "", "", "if", "plot_text", ":", "\n", "                ", "for", "txt", ",", "box", ",", "color_index", "in", "zip", "(", "\n", "text_to_plot", ",", "boxes_2d", ",", "color_index_list", ")", ":", "\n", "\n", "                    ", "if", "isinstance", "(", "txt", ",", "np", ".", "float", ")", ":", "\n", "                        ", "txt", "=", "str", "(", "np", ".", "round", "(", "txt", ",", "3", ")", ")", "\n", "\n", "", "coordinate_v", "=", "np", ".", "int", "(", "box", "[", "0", "]", ")", "\n", "coordinate_u", "=", "np", ".", "int", "(", "box", "[", "1", "]", ")", "\n", "if", "is_gt", ":", "\n", "                        ", "color", "=", "(", "0", ",", "255", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "color", "=", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", "\n", "\n", "", "(", "text_width", ",", "text_height", ")", "=", "cv2", ".", "getTextSize", "(", "\n", "txt", ",", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "fontScale", "=", "0.5", ",", "thickness", "=", "2", ")", "[", "0", "]", "\n", "text_offset_x", "=", "coordinate_u", "\n", "text_offset_y", "=", "coordinate_v", "+", "15", "\n", "\n", "box_coords", "=", "(", "\n", "(", "text_offset_x", ",", "text_offset_y", ")", ",", "\n", "(", "text_offset_x", "+", "text_width", "-", "2", ",", "text_offset_y", "-", "text_height", "-", "2", ")", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "\n", "image_out", ",", "box_coords", "[", "0", "]", ",", "box_coords", "[", "1", "]", ",", "(", "0", ",", "0", ",", "0", ")", ",", "cv2", ".", "FILLED", ")", "\n", "\n", "cv2", ".", "putText", "(", "\n", "image_out", ",", "\n", "txt", ",", "\n", "(", "coordinate_u", ",", "\n", "coordinate_v", "+", "10", ")", ",", "\n", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "\n", "0.5", ",", "\n", "color", ",", "\n", "2", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "for", "box_2d", "in", "boxes_2d", ":", "\n", "                ", "color_index", "=", "0", "\n", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_2d", "[", "1", "]", ",", "box_2d", "[", "0", "]", ")", ",", "(", "box_2d", "[", "3", "]", ",", "box_2d", "[", "2", "]", ")", ",", "\n", "_COLOUR_SCHEME_ANCHORS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "if", "is_gt", ":", "\n", "                    ", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_2d", "[", "1", "]", "-", "(", "line_width", "+", "2", ")", ",", "\n", "box_2d", "[", "0", "]", "-", "(", "line_width", "+", "2", ")", ")", ",", "\n", "(", "box_2d", "[", "3", "]", "+", "line_width", "+", "2", ",", "\n", "box_2d", "[", "2", "]", "+", "line_width", "+", "2", ")", ",", "\n", "_COLOUR_SCHEME_ANCHORS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "", "", "", "", "return", "image_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_ellipse_2d": [[154, 257], ["numpy.expand_dims", "numpy.expand_dims", "zip", "list().index", "mean.astype.astype", "vis_utils.cov_ellipse", "scipy.stats.norm.interval", "scipy.stats.norm.interval", "numpy.int32", "numpy.int32", "numpy.int32", "numpy.int32", "cv2.rectangle", "numpy.int32", "numpy.int32", "numpy.int32", "numpy.int32", "cv2.rectangle", "numpy.int32", "numpy.int32", "numpy.int32", "numpy.int32", "cv2.rectangle", "width.astype.astype", "height.astype.astype", "cv2.ellipse", "list", "numpy.isnan", "numpy.isnan", "numpy.isnan", "rotation.astype", "numpy.sqrt", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.cov_ellipse"], ["", "def", "draw_ellipse_2d", "(", "\n", "image", ",", "\n", "prediction_boxes_mean", ",", "\n", "prediction_boxes_cov", ",", "\n", "obj_classes", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "line_width", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    :param image: input m x n image\n    :param prediction_boxes_mean: 2D bounding boxes, k x 4 represented as [v u h w]\n    :param prediction_boxes_cov: 2D box covariance matrix, k x 4 x 4\n    :param obj_classes: Categorization of object, to be used to determine colour\n    :param line_width: Box line width\n    :return:\n    \"\"\"", "\n", "if", "dataset", "==", "'bdd'", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_BDD", "\n", "", "elif", "dataset", "==", "'kitti'", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_KITTI", "\n", "", "else", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_COCO", "\n", "\n", "", "if", "prediction_boxes_mean", ".", "size", "==", "0", ":", "\n", "        ", "return", "image", "[", ":", "]", "\n", "\n", "", "if", "prediction_boxes_mean", ".", "size", "==", "1", ":", "\n", "        ", "prediction_boxes_mean", "=", "np", ".", "expand_dims", "(", "prediction_boxes_mean", ",", "axis", "=", "0", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "expand_dims", "(", "prediction_boxes_cov", ",", "axis", "=", "0", ")", "\n", "\n", "", "image_out", "=", "image", "[", ":", "]", "\n", "if", "prediction_boxes_mean", ".", "size", ":", "\n", "        ", "for", "mean", ",", "cov", ",", "obj_class", "in", "zip", "(", "\n", "prediction_boxes_mean", ",", "prediction_boxes_cov", ",", "obj_classes", ")", ":", "\n", "            ", "color_index", "=", "list", "(", "obj_class", "==", "1", ")", ".", "index", "(", "True", ")", "\n", "\n", "mean", "=", "mean", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "# Draw position uncertainty ellipse", "\n", "width", ",", "height", ",", "rotation", "=", "cov_ellipse", "(", "cov", "[", "0", ":", "2", ",", "0", ":", "2", "]", ")", "\n", "\n", "width", "[", "width", "<", "0", "]", "=", "0", "\n", "height", "[", "height", "<", "0", "]", "=", "0", "\n", "if", "not", "(", "np", ".", "isnan", "(", "width", ")", "or", "np", ".", "isnan", "(", "height", ")", "or", "np", ".", "isnan", "(", "rotation", ")", ")", ":", "\n", "                ", "width", "=", "width", ".", "astype", "(", "np", ".", "int32", ")", "\n", "height", "=", "height", ".", "astype", "(", "np", ".", "int32", ")", "\n", "rotation", "=", "rotation", ".", "astype", "(", "np", ".", "int32", ")", "+", "180", "\n", "\n", "image_out", "=", "cv2", ".", "ellipse", "(", "\n", "image_out", ",", "\n", "(", "mean", "[", "1", "]", ",", "\n", "mean", "[", "0", "]", ")", ",", "\n", "(", "height", "/", "2", ",", "\n", "width", "/", "2", ")", ",", "\n", "rotation", ",", "\n", "0.0", ",", "\n", "360.0", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "# Draw 95% confidence for width and height", "\n", "", "conf_int_h", "=", "norm", ".", "interval", "(", "\n", "0.95", ",", "loc", "=", "mean", "[", "2", "]", ",", "scale", "=", "np", ".", "sqrt", "(", "cov", "[", "2", ",", "2", "]", ")", ")", "\n", "conf_int_w", "=", "norm", ".", "interval", "(", "\n", "0.95", ",", "loc", "=", "mean", "[", "3", "]", ",", "scale", "=", "np", ".", "sqrt", "(", "cov", "[", "3", ",", "3", "]", ")", ")", "\n", "\n", "box_u_min_low", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", "-", "conf_int_w", "[", "0", "]", "/", "2", ")", "\n", "box_v_min_low", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", "-", "conf_int_h", "[", "0", "]", "/", "2", ")", "\n", "box_u_max_low", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", "+", "conf_int_w", "[", "0", "]", "/", "2", ")", "\n", "box_v_max_low", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", "+", "conf_int_h", "[", "0", "]", "/", "2", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_u_min_low", ",", "box_v_min_low", ")", ",", "\n", "(", "box_u_max_low", ",", "box_v_max_low", ")", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "box_u_min_high", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", "-", "conf_int_w", "[", "1", "]", "/", "2", ")", "\n", "box_v_min_high", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", "-", "conf_int_h", "[", "1", "]", "/", "2", ")", "\n", "box_u_max_high", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", "+", "conf_int_w", "[", "1", "]", "/", "2", ")", "\n", "box_v_max_high", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", "+", "conf_int_h", "[", "1", "]", "/", "2", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_u_min_high", ",", "box_v_min_high", ")", ",", "\n", "(", "box_u_max_high", ",", "box_v_max_high", ")", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "box_u_min_mean", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", "-", "mean", "[", "3", "]", "/", "2", ")", "\n", "box_v_min_mean", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", "-", "mean", "[", "2", "]", "/", "2", ")", "\n", "box_u_max_mean", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", "+", "mean", "[", "3", "]", "/", "2", ")", "\n", "box_v_max_mean", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", "+", "mean", "[", "2", "]", "/", "2", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_u_min_mean", ",", "box_v_min_mean", ")", ",", "\n", "(", "box_u_max_mean", ",", "box_v_max_mean", ")", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", "-", "1", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "", "", "return", "image_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_ellipse_2d_corners": [[259, 355], ["numpy.expand_dims", "numpy.expand_dims", "zip", "list().index", "mean.astype.astype", "vis_utils.cov_ellipse", "vis_utils.cov_ellipse", "numpy.int32", "numpy.int32", "numpy.int32", "numpy.int32", "cv2.rectangle", "width.astype.astype", "height.astype.astype", "cv2.ellipse", "width.astype.astype", "height.astype.astype", "cv2.ellipse", "list", "numpy.isnan", "numpy.isnan", "numpy.isnan", "rotation.astype", "numpy.isnan", "numpy.isnan", "numpy.isnan", "rotation.astype"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.cov_ellipse", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.cov_ellipse"], ["", "def", "draw_ellipse_2d_corners", "(", "\n", "image", ",", "\n", "prediction_boxes_mean", ",", "\n", "prediction_boxes_cov", ",", "\n", "obj_classes", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "line_width", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    :param image: input m x n image\n    :param prediction_boxes_mean: 2D bounding boxes, k x 4 represented as [v_min u_min v_max u_max]\n    :param prediction_boxes_cov: 2D box covariance matrix, k x 4 x 4\n    :param obj_classes: Categorization of object, to be used to determine colour\n    :param line_width: Box line width\n    :return:\n    \"\"\"", "\n", "if", "dataset", "==", "'bdd'", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_BDD", "\n", "", "elif", "dataset", "==", "'kitti'", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_KITTI", "\n", "", "else", ":", "\n", "        ", "_COLOUR_SCHEME_PREDICTIONS", "=", "_COLOUR_SCHEME_PREDICTIONS_COCO", "\n", "\n", "", "if", "prediction_boxes_mean", ".", "size", "==", "0", ":", "\n", "        ", "return", "image", "[", ":", "]", "\n", "\n", "", "if", "prediction_boxes_mean", ".", "size", "==", "1", ":", "\n", "        ", "prediction_boxes_mean", "=", "np", ".", "expand_dims", "(", "prediction_boxes_mean", ",", "axis", "=", "0", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "expand_dims", "(", "prediction_boxes_cov", ",", "axis", "=", "0", ")", "\n", "\n", "", "image_out", "=", "image", "[", ":", "]", "\n", "if", "prediction_boxes_mean", ".", "size", ":", "\n", "        ", "for", "mean", ",", "cov", ",", "obj_class", "in", "zip", "(", "\n", "prediction_boxes_mean", ",", "prediction_boxes_cov", ",", "obj_classes", ")", ":", "\n", "            ", "color_index", "=", "list", "(", "obj_class", "==", "1", ")", ".", "index", "(", "True", ")", "\n", "\n", "mean", "=", "mean", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "# Draw position uncertainty ellipse", "\n", "width", ",", "height", ",", "rotation", "=", "cov_ellipse", "(", "cov", "[", "0", ":", "2", ",", "0", ":", "2", "]", ")", "\n", "\n", "width", "[", "width", "<", "0", "]", "=", "0", "\n", "height", "[", "height", "<", "0", "]", "=", "0", "\n", "if", "not", "(", "np", ".", "isnan", "(", "width", ")", "or", "np", ".", "isnan", "(", "height", ")", "or", "np", ".", "isnan", "(", "rotation", ")", ")", ":", "\n", "                ", "width", "=", "width", ".", "astype", "(", "np", ".", "int32", ")", "\n", "height", "=", "height", ".", "astype", "(", "np", ".", "int32", ")", "\n", "rotation", "=", "rotation", ".", "astype", "(", "np", ".", "int32", ")", "+", "180", "\n", "\n", "image_out", "=", "cv2", ".", "ellipse", "(", "\n", "image_out", ",", "\n", "(", "mean", "[", "1", "]", ",", "\n", "mean", "[", "0", "]", ")", ",", "\n", "(", "height", "/", "2", ",", "\n", "width", "/", "2", ")", ",", "\n", "rotation", ",", "\n", "0.0", ",", "\n", "360.0", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "# Draw position uncertainty ellipse", "\n", "", "width", ",", "height", ",", "rotation", "=", "cov_ellipse", "(", "cov", "[", "2", ":", "4", ",", "2", ":", "4", "]", ")", "\n", "\n", "width", "[", "width", "<", "0", "]", "=", "0", "\n", "height", "[", "height", "<", "0", "]", "=", "0", "\n", "if", "not", "(", "np", ".", "isnan", "(", "width", ")", "or", "np", ".", "isnan", "(", "height", ")", "or", "np", ".", "isnan", "(", "rotation", ")", ")", ":", "\n", "                ", "width", "=", "width", ".", "astype", "(", "np", ".", "int32", ")", "\n", "height", "=", "height", ".", "astype", "(", "np", ".", "int32", ")", "\n", "rotation", "=", "rotation", ".", "astype", "(", "np", ".", "int32", ")", "+", "180", "\n", "\n", "image_out", "=", "cv2", ".", "ellipse", "(", "\n", "image_out", ",", "\n", "(", "mean", "[", "3", "]", ",", "\n", "mean", "[", "2", "]", ")", ",", "\n", "(", "height", "/", "2", ",", "\n", "width", "/", "2", ")", ",", "\n", "rotation", ",", "\n", "0.0", ",", "\n", "360.0", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "", "box_u_min_mean", "=", "np", ".", "int32", "(", "mean", "[", "1", "]", ")", "\n", "box_v_min_mean", "=", "np", ".", "int32", "(", "mean", "[", "0", "]", ")", "\n", "box_u_max_mean", "=", "np", ".", "int32", "(", "mean", "[", "3", "]", ")", "\n", "box_v_max_mean", "=", "np", ".", "int32", "(", "mean", "[", "2", "]", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "image_out", ",", "\n", "(", "box_u_min_mean", ",", "box_v_min_mean", ")", ",", "\n", "(", "box_u_max_mean", ",", "box_v_max_mean", ")", ",", "\n", "_COLOUR_SCHEME_PREDICTIONS", "[", "color_index", "]", ",", "\n", "line_width", "-", "1", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "", "", "return", "image_out", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.cov_ellipse": [[357, 389], ["scipy.stats.chi2.ppf", "numpy.linalg.eigh", "numpy.degrees", "numpy.asarray", "numpy.sqrt", "numpy.arctan2", "ValueError", "scipy.stats.norm.cdf"], "function", ["None"], ["", "def", "cov_ellipse", "(", "cov", ",", "q", "=", "None", ",", "nsig", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    Parameters\n    ----------\n    cov : (2, 2) array\n        Covariance matrix.\n    q : float, optional\n        Confidence level, should be in (0, 1)\n    nsig : int, optional\n        Confidence level in unit of standard deviations.\n        E.g. 1 stands for 68.3% and 2 stands for 95.4%.\n\n    Returns\n    -------\n    width, height, rotation :\n         The lengths of two axises and the rotation angle in degree\n    for the ellipse.\n    \"\"\"", "\n", "\n", "if", "q", "is", "not", "None", ":", "\n", "        ", "q", "=", "np", ".", "asarray", "(", "q", ")", "\n", "", "elif", "nsig", "is", "not", "None", ":", "\n", "        ", "q", "=", "2", "*", "norm", ".", "cdf", "(", "nsig", ")", "-", "1", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'One of `q` and `nsig` should be specified.'", ")", "\n", "", "r2", "=", "chi2", ".", "ppf", "(", "q", ",", "2", ")", "\n", "\n", "val", ",", "vec", "=", "np", ".", "linalg", ".", "eigh", "(", "cov", ")", "\n", "width", ",", "height", "=", "2", "*", "np", ".", "sqrt", "(", "val", "[", ":", ",", "None", "]", "*", "r2", ")", "\n", "rotation", "=", "np", ".", "degrees", "(", "np", ".", "arctan2", "(", "*", "vec", "[", ":", ":", "-", "1", ",", "0", "]", ")", ")", "\n", "\n", "return", "width", ",", "height", ",", "rotation", "\n", "", ""]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.show_predictions.bdd_show_predictions_2d.main": [[15, 119], ["os.path.expanduser", "os.path.join", "os.path.join", "os.listdir", "random.randint", "print", "cv2.imread", "json.load", "demos.demo_utils.bdd_demo_utils.read_bdd_format", "json.load", "demos.demo_utils.bdd_demo_utils.read_bdd_format", "numpy.zeros", "demos.demo_utils.vis_utils.draw_box_2d", "demos.demo_utils.vis_utils.draw_box_2d", "cv2.waitKey", "os.path.join", "os.path.join", "os.path.join", "len", "open", "open", "range", "cv2.imshow", "cv2.imshow", "core.data_dir", "core.data_dir", "core.evaluation_utils_2d.two_d_iou", "numpy.amax"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.bdd_demo_utils.read_bdd_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.bdd_demo_utils.read_bdd_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.two_d_iou"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'val'", "\n", "\n", "# Specify whether the validation or inference results need to be", "\n", "# visualized.", "\n", "# results_dir = 'validation'  # Or testing", "\n", "results_dir", "=", "'testing'", "\n", "\n", "# sample_free, anchor_redundancy, black_box,  bayes_od_none,", "\n", "# bayes_od_ci_fast. bayes_od_ci,or bayes_od_ici", "\n", "uncertainty_method", "=", "'bayes_od_ci_fast'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/bdd100k'", ")", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'images'", ",", "'100k'", ",", "data_split_dir", ")", "\n", "label_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "dataset_dir", ",", "'labels'", ",", "data_split_dir", ")", "+", "'.json'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'bdd'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "", "else", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "checkpoint_number", ",", "\n", "'data'", ")", "\n", "", "prediction_file_name", "=", "os", ".", "path", ".", "join", "(", "prediction_dir", ",", "'predictions.json'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "image_dir", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "frames_list", ")", ")", "\n", "frame_id", "=", "frames_list", "[", "index", "]", "\n", "\n", "print", "(", "'Showing Frame ID:'", "+", "frame_id", ")", "\n", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "im_path", "=", "image_dir", "+", "'/'", "+", "frame_id", "\n", "image", "=", "cv2", ".", "imread", "(", "im_path", ")", "\n", "\n", "all_labels", "=", "json", ".", "load", "(", "open", "(", "label_file_name", ",", "'r'", ")", ")", "\n", "category_gt", ",", "boxes_2d_gt", ",", "_", "=", "read_bdd_format", "(", "\n", "frame_id", ",", "all_labels", ",", "categories", "=", "[", "\n", "'car'", ",", "'truck'", ",", "'bus'", ",", "'person'", ",", "'rider'", ",", "'bike'", ",", "'motor'", "]", ")", "\n", "\n", "all_predictions", "=", "json", ".", "load", "(", "open", "(", "prediction_file_name", ",", "'r'", ")", ")", "\n", "category_pred", ",", "boxes_2d_pred", ",", "_", "=", "read_bdd_format", "(", "\n", "frame_id", ",", "all_predictions", ",", "categories", "=", "[", "\n", "'car'", ",", "'truck'", ",", "'bus'", ",", "'person'", ",", "'rider'", ",", "'bike'", ",", "'motor'", "]", ")", "\n", "\n", "max_ious", "=", "np", ".", "zeros", "(", "boxes_2d_pred", ".", "shape", "[", "0", "]", ")", "\n", "# Compute IOU between each prediction and the ground truth boxes", "\n", "if", "boxes_2d_gt", ".", "size", ">", "0", "and", "boxes_2d_pred", ".", "size", ">", "0", ":", "\n", "        ", "for", "obj_idx", "in", "range", "(", "boxes_2d_pred", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "obj_iou_fmt", "=", "boxes_2d_pred", "[", "obj_idx", "]", "\n", "\n", "ious_2d", "=", "two_d_iou", "(", "obj_iou_fmt", ",", "boxes_2d_gt", ")", "\n", "\n", "max_iou", "=", "np", ".", "amax", "(", "ious_2d", ")", "\n", "max_ious", "[", "obj_idx", "]", "=", "max_iou", "\n", "\n", "#########################################################", "\n", "# Draw GT and Prediction Boxes", "\n", "#########################################################", "\n", "# Transform Predictions to left and right images", "\n", "", "", "image_out", "=", "draw_box_2d", "(", "image", ",", "\n", "boxes_2d_gt", ",", "\n", "category_gt", ",", "\n", "line_width", "=", "2", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "is_gt", "=", "True", ")", "\n", "\n", "image_out", "=", "draw_box_2d", "(", "image_out", ",", "\n", "boxes_2d_pred", ",", "\n", "category_pred", ",", "\n", "line_width", "=", "2", ",", "\n", "is_gt", "=", "False", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "text_to_plot", "=", "max_ious", ",", "\n", "plot_text", "=", "True", ")", "\n", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "cv2", ".", "imshow", "(", "'Detections from '", "+", "uncertainty_method", ",", "image_out", ")", "\n", "", "else", ":", "\n", "        ", "cv2", ".", "imshow", "(", "'Validation Set Detections'", ",", "image_out", ")", "\n", "\n", "", "cv2", ".", "waitKey", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.show_predictions.kitti_show_predictions_2d.main": [[15, 129], ["os.path.expanduser", "os.listdir", "random.randint", "int", "print", "cv2.imread", "demos.demo_utils.kitti_demo_utils.read_labels", "demos.demo_utils.kitti_demo_utils.read_predictions", "numpy.zeros", "demos.demo_utils.vis_utils.draw_box_2d", "demos.demo_utils.vis_utils.draw_box_2d", "cv2.waitKey", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "range", "cv2.imshow", "cv2.imshow", "core.data_dir", "core.data_dir", "len", "core.evaluation_utils_2d.two_d_iou", "numpy.amax"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_predictions", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.two_d_iou"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "\n", "# Specify whether the validation or inference results need to be", "\n", "# visualized.", "\n", "#results_dir = 'validation'", "\n", "results_dir", "=", "'testing'", "\n", "\n", "# sample_free, anchor_redundancy, black_box,  bayes_od_none,", "\n", "# bayes_od_ci_fast. bayes_od_ci,or bayes_od_ici", "\n", "uncertainty_method", "=", "'bayes_od'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/image_2'", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "", "else", ":", "\n", "        ", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "checkpoint_number", ",", "\n", "'data'", ")", "\n", "\n", "", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "frames_list", ")", "-", "1", ")", "\n", "frame_id", "=", "int", "(", "frames_list", "[", "index", "]", "[", "0", ":", "6", "]", ")", "\n", "\n", "# frame_id = 27  # Out of distribution example", "\n", "frame_id", "=", "4079", "\n", "# frame_id = 169   # Many Cars, Hard", "\n", "# frame_id = 2290  # Many Cars, Occlusions", "\n", "# frame_id = 1941  # Many Cars, Horizontal Direction", "\n", "# frame_id = 4032  # Orientation", "\n", "# frame_id = 104   # Weird Orientation", "\n", "# frame_id = 7047  # Weird Orientation", "\n", "# frame_id = 6632 # Very hard orientations", "\n", "\n", "# frame_id = 195  # Single Pedestrian", "\n", "# frame_id = 1574  # Single Pedestrian", "\n", "# frame_id = 332  # Multiple Hard Pedestrians", "\n", "# frame_id = 1193 # Multiple Hard Pedestrians", "\n", "\n", "# frame_id = 1274 # Multiple Cyclists", "\n", "\n", "print", "(", "'Showing Frame: %d'", "%", "frame_id", ")", "\n", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "im_path", "=", "image_dir", "+", "'/{:06d}.png'", ".", "format", "(", "frame_id", ")", "\n", "image", "=", "cv2", ".", "imread", "(", "im_path", ")", "\n", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes_hard", ",", "gt_boxes_hard", "=", "read_labels", "(", "label_path", ")", "\n", "\n", "prediction_path", "=", "prediction_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", "=", "read_predictions", "(", "\n", "prediction_path", ")", "\n", "\n", "max_ious", "=", "np", ".", "zeros", "(", "prediction_boxes", ".", "shape", "[", "0", "]", ")", "\n", "# Compute IOU between each prediction and the ground truth boxes", "\n", "if", "gt_boxes_hard", ".", "size", ">", "0", "and", "prediction_boxes", ".", "size", ">", "0", ":", "\n", "        ", "for", "obj_idx", "in", "range", "(", "prediction_boxes", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "obj_iou_fmt", "=", "prediction_boxes", "[", "obj_idx", "]", "\n", "\n", "ious_2d", "=", "two_d_iou", "(", "obj_iou_fmt", ",", "gt_boxes_hard", ")", "\n", "\n", "max_iou", "=", "np", ".", "amax", "(", "ious_2d", ")", "\n", "max_ious", "[", "obj_idx", "]", "=", "max_iou", "\n", "#########################################################", "\n", "# Draw GT and Prediction Boxes", "\n", "#########################################################", "\n", "# Transform Predictions to left and right images", "\n", "", "", "image_out", "=", "draw_box_2d", "(", "image", ",", "\n", "gt_boxes_hard", ",", "\n", "gt_classes_hard", ",", "\n", "line_width", "=", "2", ",", "\n", "dataset", "=", "'kitti'", ",", "\n", "is_gt", "=", "True", ")", "\n", "\n", "image_out", "=", "draw_box_2d", "(", "image_out", ",", "\n", "prediction_boxes", ",", "\n", "prediction_classes", ",", "\n", "line_width", "=", "2", ",", "\n", "is_gt", "=", "False", ",", "\n", "dataset", "=", "'kitti'", ",", "\n", "text_to_plot", "=", "max_ious", ",", "\n", "plot_text", "=", "True", ")", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "cv2", ".", "imshow", "(", "'Detections from '", "+", "uncertainty_method", ",", "image_out", ")", "\n", "", "else", ":", "\n", "        ", "cv2", ".", "imshow", "(", "'Validation Set Detections'", ",", "image_out", ")", "\n", "\n", "", "cv2", ".", "waitKey", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.show_uncertainty.bdd_show_uncertainty_2d_corners.main": [[28, 165], ["os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "random.randint", "print", "cv2.imread", "json.load", "demos.demo_utils.bdd_demo_utils.read_bdd_format", "numpy.load", "numpy.load", "numpy.load", "numpy.array", "numpy.matmul", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu_np", "numpy.zeros", "numpy.argmax", "numpy.array", "demos.demo_utils.vis_utils.draw_box_2d", "demos.demo_utils.vis_utils.draw_ellipse_2d_corners", "cv2.waitKey", "numpy.zeros", "zip", "cv2.applyColorMap", "cv2.addWeighted", "cv2.imshow", "cv2.waitKey", "os.path.join", "src.data_dir", "src.data_dir", "src.data_dir", "os.listdir", "len", "open", "numpy.matmul", "numpy.copy", "cv2.imshow", "cv2.imshow", "numpy.where", "np.where.astype", "src.core.evaluation_utils_2d.calc_heatmap", "numpy.arange", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.bdd_demo_utils.read_bdd_format", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_ellipse_2d_corners", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.calc_heatmap"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'val'", "\n", "\n", "# Specify whether the validation or inference results need to be", "\n", "# visualized.", "\n", "results_dir", "=", "'testing'", "\n", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/bdd100k'", ")", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'images'", ",", "'100k'", ",", "data_split_dir", ")", "\n", "label_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "dataset_dir", ",", "'labels'", ",", "data_split_dir", ")", "+", "'.json'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "mean_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'bdd'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'mean'", ")", "\n", "\n", "cov_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'bdd'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'bdd'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cat_param'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "image_dir", ")", "[", "0", ":", "100", "]", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "frames_list", ")", ")", "\n", "frame_id", "=", "frames_list", "[", "index", "]", "\n", "\n", "print", "(", "'Showing Frame ID:'", "+", "frame_id", ")", "\n", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "im_path", "=", "image_dir", "+", "'/'", "+", "frame_id", "\n", "image", "=", "cv2", ".", "imread", "(", "im_path", ")", "\n", "\n", "all_labels", "=", "json", ".", "load", "(", "open", "(", "label_file_name", ",", "'r'", ")", ")", "\n", "category_gt", ",", "boxes_2d_gt", ",", "_", "=", "read_bdd_format", "(", "\n", "frame_id", ",", "all_labels", ",", "categories", "=", "[", "\n", "'car'", ",", "'truck'", ",", "'bus'", ",", "'person'", ",", "'rider'", ",", "'bike'", ",", "'motor'", "]", ")", "\n", "\n", "prediction_boxes_mean", "=", "np", ".", "load", "(", "mean_dir", "+", "'/'", "+", "frame_id", "+", "'.npy'", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "load", "(", "cov_dir", "+", "'/'", "+", "frame_id", "+", "'.npy'", ")", "\n", "prediction_boxes_cat_params", "=", "np", ".", "load", "(", "\n", "cat_param_dir", "+", "'/'", "+", "frame_id", "+", "'.npy'", ")", "\n", "\n", "# Read entropy for debugging purposes", "\n", "transformation_mat", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "-", "0.5", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "-", "0.5", "]", ",", "\n", "[", "1", ",", "0", ",", "0.5", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0.5", "]", "]", ")", "\n", "\n", "prediction_boxes_cov", "=", "np", ".", "matmul", "(", "\n", "np", ".", "matmul", "(", "\n", "transformation_mat", ",", "\n", "prediction_boxes_cov", ")", ",", "\n", "transformation_mat", ".", "T", ")", "\n", "\n", "prediction_boxes", "=", "vuhw_to_vuvu_np", "(", "prediction_boxes_mean", ")", "\n", "category_pred", "=", "np", ".", "zeros", "(", "prediction_boxes_cat_params", ".", "shape", ")", "\n", "cat_ind", "=", "np", ".", "argmax", "(", "prediction_boxes_cat_params", ",", "axis", "=", "1", ")", "\n", "category_pred", "[", "np", ".", "arange", "(", "category_pred", ".", "shape", "[", "0", "]", ")", ",", "cat_ind", "]", "=", "1", "\n", "category_names", "=", "np", ".", "array", "(", "[", "categories", "[", "np", ".", "argmax", "(", "cat_param", ")", "]", "\n", "for", "cat_param", "in", "prediction_boxes_cat_params", "]", ")", "\n", "\n", "#########################################################", "\n", "# Draw GT and Prediction Boxes", "\n", "#########################################################", "\n", "# Transform Predictions to left and right images", "\n", "image_out", "=", "draw_box_2d", "(", "\n", "np", ".", "copy", "(", "image", ")", ",", "\n", "prediction_boxes", ",", "\n", "category_pred", ",", "\n", "line_width", "=", "1", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "is_gt", "=", "False", ",", "\n", "plot_text", "=", "True", ",", "\n", "text_to_plot", "=", "category_names", ")", "\n", "\n", "image_out", "=", "draw_ellipse_2d_corners", "(", "image_out", ",", "\n", "prediction_boxes", ",", "\n", "prediction_boxes_cov", "*", "70", ",", "\n", "category_pred", ",", "\n", "dataset", "=", "'bdd'", ",", "\n", "line_width", "=", "3", ")", "\n", "if", "results_dir", "==", "'testing'", ":", "\n", "        ", "cv2", ".", "imshow", "(", "'Detections from '", "+", "uncertainty_method", ",", "image_out", ")", "\n", "", "else", ":", "\n", "        ", "cv2", ".", "imshow", "(", "'Validation Set Detections'", ",", "image_out", ")", "\n", "\n", "", "cv2", ".", "waitKey", "(", ")", "\n", "\n", "heatmap_new", "=", "np", ".", "zeros", "(", "image", ".", "shape", "[", "0", ":", "2", "]", ")", "\n", "for", "prediction_box", ",", "prediction_box_cov", "in", "zip", "(", "\n", "prediction_boxes", ",", "prediction_boxes_cov", "*", "70", ")", ":", "\n", "        ", "heatmap", "=", "calc_heatmap", "(", "\n", "prediction_box", ",", "prediction_box_cov", ",", "image_out", ".", "shape", "[", "0", ":", "2", "]", ")", "*", "255", "\n", "heatmap_new", "=", "np", ".", "where", "(", "heatmap", "!=", "0", ",", "heatmap", ",", "heatmap_new", ")", "\n", "\n", "", "im_color", "=", "cv2", ".", "applyColorMap", "(", "\n", "heatmap_new", ".", "astype", "(", "\n", "np", ".", "uint8", ")", ",", "cv2", ".", "COLORMAP_JET", ")", "\n", "overlayed_im", "=", "cv2", ".", "addWeighted", "(", "image", ",", "0.1", ",", "im_color", ",", "0.9", ",", "0", ")", "\n", "cv2", ".", "imshow", "(", "\n", "'Spatial Heatmap Image from '", "+", "\n", "uncertainty_method", ",", "\n", "overlayed_im", ")", "\n", "\n", "cv2", ".", "waitKey", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.show_uncertainty.kitti_show_uncertainty_2d_corners.main": [[16, 157], ["os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "random.randint", "int", "print", "cv2.imread", "demos.demo_utils.kitti_demo_utils.read_labels", "demos.demo_utils.kitti_demo_utils.read_predictions", "numpy.load", "numpy.load", "numpy.load", "numpy.array", "numpy.matmul", "src.retina_net.anchor_generator.box_utils.vuhw_to_vuvu_np", "numpy.zeros", "numpy.argmax", "demos.demo_utils.vis_utils.draw_box_2d", "demos.demo_utils.vis_utils.draw_ellipse_2d_corners", "cv2.imshow", "cv2.waitKey", "numpy.zeros", "zip", "cv2.applyColorMap", "cv2.addWeighted", "cv2.imshow", "cv2.waitKey", "os.path.join", "os.path.join", "src.data_dir", "src.data_dir", "src.data_dir", "src.data_dir", "len", "numpy.matmul", "numpy.copy", "numpy.where", "np.where.astype", "src.calc_heatmap", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_labels", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.kitti_demo_utils.read_predictions", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.anchor_generator.box_utils.vuhw_to_vuvu_np", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_box_2d", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.demo_utils.vis_utils.draw_ellipse_2d_corners", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.__init__.data_dir", "home.repos.pwc.inspect_result.asharakeh_bayes-od-rc.core.evaluation_utils_2d.calc_heatmap"], ["def", "main", "(", ")", ":", "\n", "#########################################################", "\n", "# Specify Source Folders and Parameters For Frame Reader", "\n", "#########################################################", "\n", "    ", "data_split_dir", "=", "'training'", "\n", "\n", "# Only testing works, since it requires covariance matrices", "\n", "results_dir", "=", "'testing'", "\n", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "'~/Datasets/Kitti/object/'", ")", "# Change this to corresponding dataset directory", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/image_2'", "\n", "label_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "data_split_dir", ")", "+", "'/label_2'", "\n", "\n", "checkpoint_name", "=", "'retinanet_bdd'", "\n", "checkpoint_number", "=", "'101'", "\n", "\n", "uncertainty_method", "=", "'bayes_od_none'", "\n", "\n", "prediction_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'data'", ")", "\n", "\n", "mean_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'mean'", ")", "\n", "\n", "cov_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cov'", ")", "\n", "\n", "cat_param_dir", "=", "os", ".", "path", ".", "join", "(", "core", ".", "data_dir", "(", ")", ",", "\n", "'outputs'", ",", "\n", "checkpoint_name", ",", "\n", "'predictions'", ",", "\n", "results_dir", ",", "\n", "'kitti'", ",", "\n", "checkpoint_number", ",", "\n", "uncertainty_method", ",", "\n", "'cat_param'", ")", "\n", "\n", "frames_list", "=", "os", ".", "listdir", "(", "prediction_dir", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "frames_list", ")", ")", "\n", "frame_id", "=", "int", "(", "frames_list", "[", "index", "]", "[", "0", ":", "6", "]", ")", "\n", "\n", "print", "(", "'Showing Frame: %d'", "%", "frame_id", ")", "\n", "\n", "#############", "\n", "# Read Frame", "\n", "#############", "\n", "im_path", "=", "image_dir", "+", "'/{:06d}.png'", ".", "format", "(", "frame_id", ")", "\n", "image", "=", "cv2", ".", "imread", "(", "im_path", ")", "\n", "\n", "label_path", "=", "label_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "gt_classes_hard", ",", "gt_boxes_hard", "=", "read_labels", "(", "label_path", ")", "\n", "\n", "prediction_path", "=", "prediction_dir", "+", "'/{:06d}.txt'", ".", "format", "(", "frame_id", ")", "\n", "prediction_classes", ",", "prediction_boxes", ",", "prediction_scores", "=", "read_predictions", "(", "\n", "prediction_path", ")", "\n", "\n", "prediction_boxes_mean", "=", "np", ".", "load", "(", "mean_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "prediction_boxes_cov", "=", "np", ".", "load", "(", "cov_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "prediction_boxes_cat_params", "=", "np", ".", "load", "(", "\n", "cat_param_dir", "+", "'/{:06d}.npy'", ".", "format", "(", "frame_id", ")", ")", "\n", "\n", "# Read entropy for debugging purposes", "\n", "transformation_mat", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "-", "0.5", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "-", "0.5", "]", ",", "\n", "[", "1", ",", "0", ",", "0.5", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0.5", "]", "]", ")", "\n", "\n", "prediction_boxes_cov", "=", "np", ".", "matmul", "(", "\n", "np", ".", "matmul", "(", "\n", "transformation_mat", ",", "\n", "prediction_boxes_cov", ")", ",", "\n", "transformation_mat", ".", "T", ")", "\n", "\n", "prediction_boxes", "=", "vuhw_to_vuvu_np", "(", "prediction_boxes_mean", ")", "\n", "category_pred", "=", "np", ".", "zeros", "(", "prediction_boxes_cat_params", ".", "shape", ")", "\n", "cat_ind", "=", "np", ".", "argmax", "(", "prediction_boxes_cat_params", ",", "axis", "=", "1", ")", "\n", "category_pred", "[", "np", ".", "arange", "(", "category_pred", ".", "shape", "[", "0", "]", ")", ",", "cat_ind", "]", "=", "1", "\n", "\n", "#########################################################", "\n", "# Draw GT and Prediction Boxes", "\n", "#########################################################", "\n", "# Transform Predictions to left and right images", "\n", "image_out", "=", "draw_box_2d", "(", "np", ".", "copy", "(", "image", ")", ",", "\n", "gt_boxes_hard", ",", "\n", "gt_classes_hard", ",", "\n", "line_width", "=", "2", ",", "\n", "dataset", "=", "'kitti'", ",", "\n", "is_gt", "=", "True", ")", "\n", "\n", "image_out", "=", "draw_ellipse_2d_corners", "(", "image_out", ",", "\n", "prediction_boxes", ",", "\n", "prediction_boxes_cov", ",", "\n", "prediction_classes", ",", "\n", "dataset", "=", "'kitti'", ",", "\n", "line_width", "=", "3", ")", "\n", "\n", "cv2", ".", "imshow", "(", "'Detections from '", "+", "uncertainty_method", ",", "image_out", ")", "\n", "\n", "cv2", ".", "waitKey", "(", ")", "\n", "heatmap_new", "=", "np", ".", "zeros", "(", "image", ".", "shape", "[", "0", ":", "2", "]", ")", "\n", "\n", "for", "prediction_box", ",", "prediction_box_cov", "in", "zip", "(", "\n", "prediction_boxes", ",", "prediction_boxes_cov", ")", ":", "\n", "        ", "heatmap", "=", "eval_utils", ".", "calc_heatmap", "(", "\n", "prediction_box", ",", "prediction_box_cov", ",", "image_out", ".", "shape", "[", "0", ":", "2", "]", ")", "*", "255", "\n", "heatmap_new", "=", "np", ".", "where", "(", "heatmap", "!=", "0", ",", "heatmap", ",", "heatmap_new", ")", "\n", "\n", "", "im_color", "=", "cv2", ".", "applyColorMap", "(", "\n", "heatmap_new", ".", "astype", "(", "\n", "np", ".", "uint8", ")", ",", "cv2", ".", "COLORMAP_JET", ")", "\n", "overlayed_im", "=", "cv2", ".", "addWeighted", "(", "image", ",", "0.4", ",", "im_color", ",", "0.6", ",", "0", ")", "\n", "cv2", ".", "imshow", "(", "\n", "'Spatial Heatmap Image from '", "+", "\n", "uncertainty_method", ",", "\n", "overlayed_im", ")", "\n", "\n", "cv2", ".", "waitKey", "(", ")", "\n", "\n"]]}