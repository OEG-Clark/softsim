{"home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.__init__": [[40, 64], ["os.path.join", "os.path.join", "os.path.join", "numpy.array", "numpy.array", "numpy.concatenate", "sklearn.preprocessing.LabelEncoder", "txtcls.TxtCls.label_encoder.fit", "os.path.exists", "txtcls.TxtCls.load_data", "txtcls.TxtCls.load_data"], "methods", ["home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.load_data", "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.load_data"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Loads the evaluation dataset in memory\n\n        The raw data is stored as an n x 2 array where the first columns\n        holds the class label string and the second column holds the\n        entire text of the document\n        \"\"\"", "\n", "self", ".", "data_dir", "=", "kwargs", "[", "'data_dir'", "]", "\n", "self", ".", "lang", "=", "kwargs", "[", "'lang'", "]", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "data_dir", ")", ":", "\n", "            ", "raise", "'Please download the dataset first'", "\n", "\n", "", "lang_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "lang", ")", "\n", "train_fname", "=", "os", ".", "path", ".", "join", "(", "lang_dir", ",", "self", ".", "lang", "+", "'-train.csv'", ")", "\n", "test_fname", "=", "os", ".", "path", ".", "join", "(", "lang_dir", ",", "self", ".", "lang", "+", "'-test.csv'", ")", "\n", "\n", "self", ".", "raw_train", "=", "np", ".", "array", "(", "self", ".", "load_data", "(", "train_fname", ")", ")", "\n", "self", ".", "raw_test", "=", "np", ".", "array", "(", "self", ".", "load_data", "(", "test_fname", ")", ")", "\n", "\n", "labels", "=", "np", ".", "concatenate", "(", "(", "self", ".", "raw_train", "[", ":", ",", "0", "]", ",", "self", ".", "raw_test", "[", ":", ",", "0", "]", ")", ")", "\n", "self", ".", "label_encoder", "=", "preprocessing", ".", "LabelEncoder", "(", ")", "\n", "self", ".", "label_encoder", ".", "fit", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.load_data": [[65, 70], ["open", "csv.reader", "list"], "methods", ["None"], ["", "def", "load_data", "(", "self", ",", "fname", ")", ":", "\n", "        ", "with", "open", "(", "fname", ")", "as", "data_file", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "data_file", ",", "delimiter", "=", "','", ")", "\n", "data", "=", "list", "(", "reader", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.evaluate": [[71, 93], ["print", "txtcls.TxtCls.process_dataset", "print", "txtcls.TxtCls.process_dataset", "print", "txtcls.TxtCls.train[].astype", "txtcls.TxtCls.test[].astype", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "faiss.IndexFlatL2.search", "sklearn.metrics.accuracy_score", "preds.append", "max", "set"], "methods", ["home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.process_dataset", "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.process_dataset"], ["", "def", "evaluate", "(", "self", ",", "emb", ")", ":", "\n", "        ", "print", "(", "'Computing document vectors for train set...'", ")", "\n", "self", ".", "train", "=", "self", ".", "process_dataset", "(", "self", ".", "raw_train", ",", "emb", ")", "\n", "\n", "print", "(", "'Computing document vectors for test set...'", ")", "\n", "self", ".", "test", "=", "self", ".", "process_dataset", "(", "self", ".", "raw_test", ",", "emb", ")", "\n", "\n", "k", "=", "4", "\n", "dim", "=", "300", "\n", "print", "(", "'Running KNN with k={}..'", ".", "format", "(", "k", ")", ")", "\n", "database", "=", "self", ".", "train", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "'float32'", ")", "\n", "queries", "=", "self", ".", "test", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "'float32'", ")", "\n", "index", "=", "faiss", ".", "IndexFlatL2", "(", "dim", ")", "\n", "index", ".", "add", "(", "database", ")", "\n", "dist", ",", "idxs", "=", "index", ".", "search", "(", "queries", ",", "k", ")", "\n", "\n", "preds", "=", "[", "]", "\n", "for", "neighbors", "in", "idxs", ":", "\n", "           ", "classes", "=", "[", "self", ".", "train", "[", "n", ",", "0", "]", "for", "n", "in", "neighbors", "]", "\n", "preds", ".", "append", "(", "max", "(", "set", "(", "classes", ")", ",", "key", "=", "classes", ".", "count", ")", ")", "\n", "\n", "", "return", "accuracy_score", "(", "self", ".", "test", "[", ":", ",", "0", "]", ",", "preds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.TxtCls.process_dataset": [[94, 100], ["txtcls.TxtCls.label_encoder.transform", "numpy.expand_dims", "numpy.array", "numpy.hstack", "txtcls.doc2vec", "tqdm.tqdm.tqdm"], "methods", ["home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.doc2vec"], ["", "def", "process_dataset", "(", "self", ",", "data", ",", "emb", ")", ":", "\n", "        ", "label_ids", "=", "self", ".", "label_encoder", ".", "transform", "(", "data", "[", ":", ",", "0", "]", ")", "\n", "label_ids", "=", "np", ".", "expand_dims", "(", "label_ids", ",", "axis", "=", "1", ")", "\n", "doc_vecs", "=", "np", ".", "array", "(", "[", "doc2vec", "(", "txt", ",", "self", ".", "lang", ",", "emb", ")", "for", "txt", "in", "tqdm", "(", "data", "[", ":", ",", "1", "]", ")", "]", ")", "\n", "processed", "=", "np", ".", "hstack", "(", "(", "label_ids", ",", "doc_vecs", ")", ")", "\n", "return", "processed", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.scripts.txtcls.doc2vec": [[22, 36], ["normalizer_factory.get_normalizer", "normalizer_factory.get_normalizer.normalize", "indicnlp.tokenize.indic_tokenize.trivial_tokenize", "txt.replace", "len", "numpy.mean", "numpy.zeros", "numpy.array"], "function", ["None"], ["def", "doc2vec", "(", "txt", ",", "lang", ",", "emb", ")", ":", "\n", "    ", "\"\"\"\n    a doc is represented as the mean of all the words vectors\n    of its constituent words\n    \"\"\"", "\n", "normalizer", "=", "normalizer_factory", ".", "get_normalizer", "(", "lang", ")", "\n", "normed_txt", "=", "normalizer", ".", "normalize", "(", "txt", ".", "replace", "(", "'\\n'", ",", "' '", ")", ")", "\n", "words", "=", "indic_tokenize", ".", "trivial_tokenize", "(", "normed_txt", ",", "lang", ")", "\n", "word_vecs", "=", "[", "emb", "[", "word", "]", "for", "word", "in", "words", "if", "word", "in", "emb", "]", "\n", "if", "len", "(", "word_vecs", ")", ">", "0", ":", "\n", "        ", "doc_vec", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "word_vecs", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "doc_vec", "=", "np", ".", "zeros", "(", "emb", ".", "vector_size", ")", "\n", "", "return", "doc_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_analogy.word_analogy.Params.__init__": [[102, 104], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_analogy.word_analogy.get_wordanalogy_scores_customfname": [[10, 99], ["print", "print", "print", "sorted", "print", "print", "print", "io.open", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.mm().cpu().numpy", "enumerate", "numpy.sum", "scores.keys", "print", "numpy.sqrt", "line.lower.rstrip", "line.lower.split", "src.evaluation.wordsim.get_word_id", "src.evaluation.wordsim.get_word_id", "src.evaluation.wordsim.get_word_id", "src.evaluation.wordsim.get_word_id", "any", "numpy.vstack", "float", "max", "line.lower.lower", "len", "word_ids[].append", "queries[].append", "torch.from_numpy.mm().cpu", "qs.mm().cpu().numpy.argmax", "line.lower.split", "numpy.linalg.norm", "str", "str", "torch.from_numpy.mm"], "function", ["None"], ["def", "get_wordanalogy_scores_customfname", "(", "analogy_fname", ",", "language", ",", "word2id", ",", "embeddings", ",", "lower", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Return (english) word analogy score\n        embeddings must be normalized \n    This is a modification of the MUSE analogy code\n    \"\"\"", "\n", "\n", "# normalize word embeddings", "\n", "embeddings", "=", "embeddings", "/", "np", ".", "sqrt", "(", "(", "embeddings", "**", "2", ")", ".", "sum", "(", "1", ")", ")", "[", ":", ",", "None", "]", "\n", "\n", "# scores by category", "\n", "scores", "=", "{", "}", "\n", "n_found", "=", "0", "\n", "n_not_found", "=", "0", "\n", "\n", "word_ids", "=", "{", "}", "\n", "queries", "=", "{", "}", "\n", "\n", "with", "io", ".", "open", "(", "analogy_fname", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "# new line", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "lower", ":", "\n", "                ", "line", "=", "line", ".", "lower", "(", ")", "\n", "\n", "# new category", "\n", "", "if", "\":\"", "in", "line", ":", "\n", "#                 assert line[1] == ' '", "\n", "                ", "category", "=", "line", "[", "2", ":", "]", "\n", "#                 assert category not in scores", "\n", "scores", "[", "category", "]", "=", "{", "'n_found'", ":", "0", ",", "'n_not_found'", ":", "0", ",", "'n_correct'", ":", "0", "}", "\n", "word_ids", "[", "category", "]", "=", "[", "]", "\n", "queries", "[", "category", "]", "=", "[", "]", "\n", "continue", "\n", "\n", "# get word IDs", "\n", "", "assert", "len", "(", "line", ".", "split", "(", ")", ")", "==", "4", ",", "line", "\n", "word1", ",", "word2", ",", "word3", ",", "word4", "=", "line", ".", "split", "(", ")", "\n", "word_id1", "=", "get_word_id", "(", "word1", ",", "word2id", ",", "lower", ")", "\n", "word_id2", "=", "get_word_id", "(", "word2", ",", "word2id", ",", "lower", ")", "\n", "word_id3", "=", "get_word_id", "(", "word3", ",", "word2id", ",", "lower", ")", "\n", "word_id4", "=", "get_word_id", "(", "word4", ",", "word2id", ",", "lower", ")", "\n", "\n", "# if at least one word is not found", "\n", "if", "any", "(", "x", "is", "None", "for", "x", "in", "[", "word_id1", ",", "word_id2", ",", "word_id3", ",", "word_id4", "]", ")", ":", "\n", "                ", "scores", "[", "category", "]", "[", "'n_not_found'", "]", "+=", "1", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "scores", "[", "category", "]", "[", "'n_found'", "]", "+=", "1", "\n", "word_ids", "[", "category", "]", ".", "append", "(", "[", "word_id1", ",", "word_id2", ",", "word_id3", ",", "word_id4", "]", ")", "\n", "# generate query vector and get nearest neighbors", "\n", "query", "=", "embeddings", "[", "word_id1", "]", "-", "embeddings", "[", "word_id2", "]", "+", "embeddings", "[", "word_id4", "]", "\n", "query", "=", "query", "/", "np", ".", "linalg", ".", "norm", "(", "query", ")", "\n", "\n", "queries", "[", "category", "]", ".", "append", "(", "query", ")", "\n", "\n", "# Compute score for each category", "\n", "", "", "", "for", "cat", "in", "queries", ":", "\n", "        ", "qs", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "queries", "[", "cat", "]", ")", ")", "\n", "keys", "=", "torch", ".", "from_numpy", "(", "embeddings", ".", "T", ")", "\n", "values", "=", "qs", ".", "mm", "(", "keys", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# be sure we do not select input words", "\n", "for", "i", ",", "ws", "in", "enumerate", "(", "word_ids", "[", "cat", "]", ")", ":", "\n", "            ", "for", "wid", "in", "[", "ws", "[", "0", "]", ",", "ws", "[", "1", "]", ",", "ws", "[", "3", "]", "]", ":", "\n", "                ", "values", "[", "i", ",", "wid", "]", "=", "-", "1e9", "\n", "", "", "scores", "[", "cat", "]", "[", "'n_correct'", "]", "=", "np", ".", "sum", "(", "values", ".", "argmax", "(", "axis", "=", "1", ")", "==", "[", "ws", "[", "2", "]", "for", "ws", "in", "word_ids", "[", "cat", "]", "]", ")", "\n", "\n", "# pretty print", "\n", "", "separator", "=", "\"=\"", "*", "(", "30", "+", "1", "+", "10", "+", "1", "+", "13", "+", "1", "+", "12", ")", "\n", "pattern", "=", "\"%30s %10s %13s %12s\"", "\n", "print", "(", "separator", ")", "\n", "print", "(", "pattern", "%", "(", "\"Category\"", ",", "\"Found\"", ",", "\"Not found\"", ",", "\"Accuracy\"", ")", ")", "\n", "print", "(", "separator", ")", "\n", "\n", "# compute and log accuracies", "\n", "accuracies", "=", "{", "}", "\n", "for", "k", "in", "sorted", "(", "scores", ".", "keys", "(", ")", ")", ":", "\n", "        ", "v", "=", "scores", "[", "k", "]", "\n", "accuracies", "[", "k", "]", "=", "float", "(", "v", "[", "'n_correct'", "]", ")", "/", "max", "(", "v", "[", "'n_found'", "]", ",", "1", ")", "\n", "print", "(", "pattern", "%", "(", "k", ",", "str", "(", "v", "[", "'n_found'", "]", ")", ",", "str", "(", "v", "[", "'n_not_found'", "]", ")", ",", "\"%.4f\"", "%", "accuracies", "[", "k", "]", ")", ")", "\n", "n_found", "+=", "v", "[", "'n_found'", "]", "\n", "n_not_found", "+=", "v", "[", "'n_not_found'", "]", "\n", "", "print", "(", "separator", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "'Coverage: {}'", ".", "format", "(", "n_found", "/", "(", "n_found", "+", "n_not_found", ")", ")", ")", "\n", "\n", "return", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_analogy.word_analogy.score_analogy": [[105, 129], ["word_analogy.Params", "src.utils.load_embeddings", "torch.nn.Embedding", "nn.Embedding.weight.data.copy_", "nn.Embedding.weight.data.cpu().numpy", "word_analogy.get_wordanalogy_scores_customfname", "len", "nn.Embedding.cuda", "nn.Embedding.weight.data.cpu"], "function", ["home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_analogy.word_analogy.get_wordanalogy_scores_customfname"], ["", "", "def", "score_analogy", "(", "analogy_fname", ",", "embeddings_path", ",", "lang", ",", "emb_dim", ",", "max_vocab", "=", "200000", ",", "lower", "=", "True", ",", "cuda", "=", "True", ")", ":", "\n", "\n", "# source embeddings", "\n", "    ", "params", "=", "Params", "(", ")", "\n", "params", ".", "src_emb", "=", "embeddings_path", "\n", "params", ".", "tgt_emb", "=", "''", "\n", "params", ".", "max_vocab", "=", "max_vocab", "\n", "params", ".", "emb_dim", "=", "emb_dim", "\n", "params", ".", "cuda", "=", "cuda", "\n", "params", ".", "src_lang", "=", "lang", "\n", "params", ".", "tgt_lang", "=", "''", "\n", "\n", "src_dico", ",", "_src_emb", "=", "load_embeddings", "(", "params", ",", "source", "=", "True", ")", "\n", "word2id", "=", "src_dico", ".", "word2id", "\n", "src_emb", "=", "nn", ".", "Embedding", "(", "len", "(", "src_dico", ")", ",", "params", ".", "emb_dim", ",", "sparse", "=", "True", ")", "\n", "src_emb", ".", "weight", ".", "data", ".", "copy_", "(", "_src_emb", ")", "\n", "\n", "if", "params", ".", "cuda", ":", "\n", "        ", "src_emb", ".", "cuda", "(", ")", "\n", "\n", "", "embeddings", "=", "src_emb", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "word2id", "=", "src_dico", ".", "word2id", "\n", "\n", "return", "get_wordanalogy_scores_customfname", "(", "analogy_fname", ",", "lang", ",", "word2id", ",", "embeddings", ",", "lower", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.read": [[18, 59], ["file.readline().split", "int", "set", "int", "min", "numpy.empty", "range", "range", "file.readline", "int", "numpy.empty", "file.readline().split", "file.readline().split", "words.append", "set.add", "numpy.array", "words.append", "numpy.fromstring", "word.lower", "word.lower", "word.lower", "numpy.fromstring", "file.readline", "words.append", "np.empty.append", "file.readline", "np.empty.append", "numpy.fromstring", "numpy.fromstring"], "function", ["None"], ["def", "read", "(", "file", ",", "max_voc", ",", "threshold", "=", "0", ",", "vocabulary", "=", "None", ",", "dtype", "=", "'float'", ")", ":", "\n", "    ", "header", "=", "file", ".", "readline", "(", ")", ".", "split", "(", "' '", ")", "\n", "count", "=", "int", "(", "header", "[", "0", "]", ")", "if", "threshold", "<=", "0", "else", "min", "(", "threshold", ",", "int", "(", "header", "[", "0", "]", ")", ")", "\n", "dim", "=", "int", "(", "header", "[", "1", "]", ")", "\n", "words", "=", "[", "]", "\n", "wordset", "=", "set", "(", ")", "\n", "if", "count", "<", "max_voc", ":", "\n", "        ", "max_voc", "=", "0", "\n", "", "if", "max_voc", ":", "\n", "        ", "matrix", "=", "np", ".", "empty", "(", "(", "max_voc", ",", "dim", ")", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "        ", "matrix", "=", "np", ".", "empty", "(", "(", "count", ",", "dim", ")", ",", "dtype", "=", "dtype", ")", "if", "vocabulary", "is", "None", "else", "[", "]", "\n", "", "if", "max_voc", "==", "0", ":", "\n", "        ", "for", "i", "in", "range", "(", "count", ")", ":", "\n", "            ", "word", ",", "vec", "=", "file", ".", "readline", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "if", "vocabulary", "is", "None", ":", "\n", "                ", "words", ".", "append", "(", "word", ")", "\n", "matrix", "[", "i", "]", "=", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ",", "dtype", "=", "dtype", ")", "\n", "", "elif", "word", "in", "vocabulary", ":", "\n", "                ", "words", ".", "append", "(", "word", ")", "\n", "matrix", ".", "append", "(", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ",", "dtype", "=", "dtype", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "wc", "=", "0", "\n", "for", "i", "in", "range", "(", "count", ")", ":", "\n", "            ", "if", "wc", "==", "max_voc", ":", "\n", "                ", "break", "\n", "", "word", ",", "vec", "=", "file", ".", "readline", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "\n", "if", "word", ".", "lower", "(", ")", "in", "wordset", ":", "\n", "                ", "continue", "\n", "", "words", ".", "append", "(", "word", ".", "lower", "(", ")", ")", "\n", "wordset", ".", "add", "(", "word", ".", "lower", "(", ")", ")", "\n", "\n", "if", "vocabulary", "is", "None", ":", "\n", "                ", "matrix", "[", "wc", "]", "=", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ",", "dtype", "=", "dtype", ")", "\n", "", "elif", "word", "in", "vocabulary", ":", "\n", "                ", "matrix", ".", "append", "(", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ",", "dtype", "=", "dtype", ")", ")", "\n", "\n", "", "wc", "+=", "1", "\n", "\n", "", "", "return", "(", "words", ",", "matrix", ")", "if", "vocabulary", "is", "None", "else", "(", "words", ",", "np", ".", "array", "(", "matrix", ",", "dtype", "=", "dtype", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.read_vocab": [[60, 80], ["file.readline().split", "int", "int", "range", "range", "file.readline", "file.readline().split", "words.append", "file.readline().split", "words.append", "file.readline", "file.readline"], "function", ["None"], ["", "def", "read_vocab", "(", "file", ",", "max_voc", ")", ":", "\n", "    ", "header", "=", "file", ".", "readline", "(", ")", ".", "split", "(", "' '", ")", "\n", "count", "=", "int", "(", "header", "[", "0", "]", ")", "\n", "dim", "=", "int", "(", "header", "[", "1", "]", ")", "\n", "words", "=", "[", "]", "\n", "if", "count", "<", "max_voc", ":", "\n", "        ", "max_voc", "=", "0", "\n", "", "if", "max_voc", "==", "0", ":", "\n", "        ", "for", "i", "in", "range", "(", "count", ")", ":", "\n", "            ", "word", ",", "vec", "=", "file", ".", "readline", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "", "", "else", ":", "\n", "        ", "wc", "=", "0", "\n", "for", "i", "in", "range", "(", "count", ")", ":", "\n", "            ", "if", "wc", "==", "max_voc", ":", "\n", "                ", "break", "\n", "", "word", ",", "vec", "=", "file", ".", "readline", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "wc", "+=", "1", "\n", "", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.write": [[81, 86], ["numpy.array", "print", "range", "len", "print"], "function", ["None"], ["", "def", "write", "(", "words", ",", "matrix", ",", "file", ")", ":", "\n", "    ", "m", "=", "np", ".", "array", "(", "matrix", ")", "\n", "print", "(", "'%d %d'", "%", "m", ".", "shape", ",", "file", "=", "file", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "        ", "print", "(", "words", "[", "i", "]", "+", "' '", "+", "' '", ".", "join", "(", "[", "'%.6g'", "%", "x", "for", "x", "in", "m", "[", "i", "]", "]", ")", ",", "file", "=", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.length_normalize": [[88, 92], ["numpy.sqrt", "numpy.sum"], "function", ["None"], ["", "", "def", "length_normalize", "(", "matrix", ")", ":", "\n", "    ", "norms", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "matrix", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "norms", "[", "norms", "==", "0", "]", "=", "1", "\n", "return", "matrix", "/", "norms", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.mean_center": [[94, 97], ["numpy.mean"], "function", ["None"], ["", "def", "mean_center", "(", "matrix", ")", ":", "\n", "    ", "avg", "=", "np", ".", "mean", "(", "matrix", ",", "axis", "=", "0", ")", "\n", "return", "matrix", "-", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.length_normalize_dimensionwise": [[99, 103], ["numpy.sqrt", "numpy.sum"], "function", ["None"], ["", "def", "length_normalize_dimensionwise", "(", "matrix", ")", ":", "\n", "    ", "norms", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "matrix", "**", "2", ",", "axis", "=", "0", ")", ")", "\n", "norms", "[", "norms", "==", "0", "]", "=", "1", "\n", "return", "matrix", "/", "norms", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.embeddings.mean_center_embeddingwise": [[105, 108], ["numpy.mean"], "function", ["None"], ["", "def", "mean_center_embeddingwise", "(", "matrix", ")", ":", "\n", "    ", "avg", "=", "np", ".", "mean", "(", "matrix", ",", "axis", "=", "1", ")", "\n", "return", "matrix", "-", "avg", "[", ":", ",", "np", ".", "newaxis", "]", "", "", ""]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.wordsim.read_word_similarity": [[6, 22], ["open", "l.strip().split", "sim_database.append", "l.strip", "float"], "function", ["None"], ["def", "read_word_similarity", "(", "similarity_fname", ",", "delim", "=", "'\\t'", ")", ":", "\n", "    ", "\"\"\"read word similarity information file\n\n    Args:\n        similarity_fname (str): path word similarity database file\n        delim (str): delimiter for each record in word similarity file \n\n    Returns:\n        list of tuples of the form ('word0', 'word1', similarity)\n    \"\"\"", "\n", "sim_database", "=", "[", "]", "\n", "with", "open", "(", "similarity_fname", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "similarity_file", ":", "\n", "        ", "for", "l", "in", "similarity_file", ":", "\n", "            ", "f", "=", "l", ".", "strip", "(", ")", ".", "split", "(", "delim", ")", "\n", "sim_database", ".", "append", "(", "(", "f", "[", "0", "]", ",", "f", "[", "1", "]", ",", "float", "(", "f", "[", "2", "]", ")", ")", ")", "\n", "", "", "return", "sim_database", "\n", "\n"]], "home.repos.pwc.inspect_result.ai4bharat-indicnlp_indicnlp_corpus.word_similarity.wordsim.compute_word_similarity": [[23, 64], ["build_w2i", "set", "set.update", "set.difference", "set.difference", "list", "scipy.stats.spearmanr", "filter", "cos_sims.append", "ref_sims.append", "numpy.array", "numpy.array", "numpy.dot", "numpy.sqrt", "len", "len", "len", "v1.dot", "v2.dot", "sim_words.difference.intersection"], "function", ["None"], ["", "def", "compute_word_similarity", "(", "emb_info", ",", "sim_database", ")", ":", "\n", "    ", "\"\"\"Compute word similarity for the word pair dataset \n\n    Compute word similarity for the word pair dataset using \n    Spearman's correlation coefficient \n\n    Args:\n        emb_info (tuple): tuple of \n        sim_database (list): See return of read_word_similarity \n            for format\n\n    Returns: \n        tuple of (correlation,p_value,coverage)\n        coverage refers to the fraction of the word pairs \n        in the similarity database covered by the embeddings \n        \n    \"\"\"", "\n", "\n", "emb_words", ",", "emb_vectors", "=", "emb_info", "\n", "w2i", "=", "build_w2i", "(", "emb_info", "[", "0", "]", ")", "\n", "\n", "sim_words", "=", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "sim_database", "]", ")", "\n", "sim_words", ".", "update", "(", "[", "x", "[", "1", "]", "for", "x", "in", "sim_database", "]", ")", "\n", "oov_words", "=", "sim_words", ".", "difference", "(", "emb_words", ")", "\n", "non_oov_words", "=", "sim_words", ".", "difference", "(", "oov_words", ")", "\n", "\n", "non_oov_sim_pairs", "=", "list", "(", "filter", "(", "lambda", "x", ":", "len", "(", "oov_words", ".", "intersection", "(", "x", "[", ":", "2", "]", ")", ")", "==", "0", ",", "sim_database", ")", ")", "\n", "\n", "cos_sims", "=", "[", "]", "\n", "ref_sims", "=", "[", "]", "\n", "\n", "for", "w1", ",", "w2", ",", "ref_sim", "in", "non_oov_sim_pairs", ":", "\n", "        ", "v1", "=", "emb_vectors", "[", "w2i", "[", "w1", "]", "]", "\n", "v2", "=", "emb_vectors", "[", "w2i", "[", "w2", "]", "]", "\n", "cos_sim", "=", "np", ".", "dot", "(", "v1", ",", "v2", ")", "/", "np", ".", "sqrt", "(", "v1", ".", "dot", "(", "v1", ")", "*", "v2", ".", "dot", "(", "v2", ")", ")", "\n", "\n", "cos_sims", ".", "append", "(", "cos_sim", ")", "\n", "ref_sims", ".", "append", "(", "ref_sim", ")", "\n", "\n", "", "corr", "=", "scipy", ".", "stats", ".", "spearmanr", "(", "np", ".", "array", "(", "cos_sims", ")", ",", "np", ".", "array", "(", "ref_sims", ")", ")", "\n", "return", "corr", "[", "0", "]", ",", "corr", "[", "1", "]", ",", "len", "(", "non_oov_sim_pairs", ")", "/", "len", "(", "sim_database", ")", "\n", "\n"]]}