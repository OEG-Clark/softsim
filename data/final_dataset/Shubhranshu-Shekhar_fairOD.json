{"home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.RepresentationLearner.__init__": [[25, 47], ["torch.Module.__init__", "list", "enumerate", "torch.Sequential", "torch.Sequential", "torch.Sequential", "enumerate", "f.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "zip", "g.append", "g.append", "f.append", "f.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "list", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "zip"], "methods", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.__init__"], ["def", "__init__", "(", "self", ",", "layer_dims", ")", ":", "\n", "        ", "'''\n        Initializing the autoencoder network structure.\n        '''", "\n", "super", "(", "RepresentationLearner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer_structures", "=", "list", "(", "zip", "(", "layer_dims", ",", "layer_dims", "[", "1", ":", "]", ")", ")", "\n", "g", "=", "[", "]", "\n", "\n", "for", "layer_id", ",", "(", "input_dim", ",", "output_dim", ")", "in", "enumerate", "(", "layer_structures", ")", ":", "\n", "            ", "g", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ",", "bias", "=", "True", ")", ")", "\n", "g", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "self", ".", "g", "=", "nn", ".", "Sequential", "(", "*", "g", ")", "# produces the latent vector", "\n", "\n", "f", "=", "[", "]", "\n", "reverse_layer_structure", "=", "list", "(", "zip", "(", "layer_dims", "[", "1", ":", "]", ",", "layer_dims", ")", ")", "[", ":", ":", "-", "1", "]", "[", "-", "1", "]", "\n", "\n", "for", "layer_id", ",", "(", "input_dim", ",", "output_dim", ")", "in", "enumerate", "(", "reverse_layer_structure", ")", ":", "\n", "            ", "f", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ",", "bias", "=", "True", ")", ")", "\n", "f", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "f", ".", "append", "(", "nn", ".", "Linear", "(", "output_dim", ",", "layer_dims", "[", "0", "]", ",", "bias", "=", "True", ")", ")", "# add linear from send last to input dim", "\n", "\n", "self", ".", "f", "=", "nn", ".", "Sequential", "(", "*", "f", ")", "# reconstructor for input", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.RepresentationLearner.forward": [[48, 52], ["models.RepresentationLearner.g", "models.RepresentationLearner.f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "gx", "=", "self", ".", "g", "(", "x", ")", "\n", "reconstruction", "=", "self", ".", "f", "(", "gx", ")", "\n", "return", "reconstruction", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.FTrainer.__init__": [[61, 106], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "'''\n        Keys in the config:\n        model_type: takes values in [\"base\", \"fairL\", \"fairC\", \"fairOD\"]\n        recon_criterion: loss function for reconstruction error\n        sens_criterion: loss function for correlation based statistical parity\n        group_criterion: loss function for group fidelity. See Eq. 13 in the paper.\n        data: directory path to dataset. Directory contains X.pkl, y.pkl, pv.pkl.\n                The .pkl files should be saved from an input dataset.\n        epochs: training epochs for the learner\n        lr: learning rate used in adam optimizer\n        model_path: path to save the best model\n        base_model_weights: path to saved parameters from the base autoencoder model\n        base_model_scores: anomaly scores from base model. ndarray.\n        niters: number of times repeating the experiment to reduce variation over random initializations\n        n_splits: cross-validation splits\n        n_hidden: number of nodes in a hidden layer\n        params: list of parameter tuples\n        '''", "\n", "self", ".", "model_type", "=", "config", "[", "\"model_type\"", "]", "\n", "self", ".", "recon_criterion", "=", "config", "[", "\"recon_criterion\"", "]", "\n", "self", ".", "sens_criterion", "=", "config", "[", "\"sens_criterion\"", "]", "\n", "self", ".", "group_criterion", "=", "config", "[", "\"group_criterion\"", "]", "\n", "self", ".", "data_path", "=", "config", "[", "\"data\"", "]", "\n", "self", ".", "epochs", "=", "config", "[", "\"epochs\"", "]", "\n", "self", ".", "lr", "=", "config", "[", "\"lr\"", "]", "\n", "self", ".", "model_path", "=", "config", "[", "\"model_path\"", "]", "# if not None, then use this path to save the model", "\n", "self", ".", "base_model_weights", "=", "config", "[", "\n", "\"base_model_weights\"", "]", "# final network weights of base model_type (base_weights.pth)", "\n", "self", ".", "base_model_scores", "=", "config", "[", "\n", "\"base_model_scores\"", "]", "# anomaly scores for each instance by base model", "\n", "\n", "# how many re-runs with random initializations of weights for AE", "\n", "# for fair AE load the final AE weights corresponding to each iteration", "\n", "self", ".", "niters", "=", "config", "[", "\"niters\"", "]", "\n", "\n", "self", ".", "n_splits", "=", "config", "[", "\"n_splits\"", "]", "# for recording cross-validation", "\n", "self", ".", "n_hidden", "=", "config", "[", "\"n_hidden\"", "]", "# network hidden layer nodes", "\n", "\n", "# list of tuples (alpha, gamma). See paper for definition of alpha and gamma", "\n", "# first entry in the list is a string \"base\" to denote no regularization", "\n", "self", ".", "params", "=", "config", "[", "\"params\"", "]", "\n", "\n", "# storing anomaly scores", "\n", "self", ".", "scores", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.FTrainer.train": [[107, 247], ["utility.load_data", "utility.column_wise_norm", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.Tensor().flatten", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "int", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.sum", "numpy.sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "numpy.log2", "numpy.log2", "torch.utils.data.random_split", "torch.utils.data.random_split", "torch.utils.data.random_split", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "models.get_model_object", "get_model_object.load_state_dict", "get_model_object.to", "torch.Adam", "torch.Adam", "torch.Adam", "range", "utility.group_test", "models.get_model_object", "get_model_object.load_state_dict", "get_model_object.to", "torch.Adam", "torch.Adam", "torch.Adam", "utility.group_train", "get_model_object.eval", "get_model_object.", "numpy.linalg.norm", "numpy.power", "numpy.power", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "get_model_object.parameters", "utility.group_train", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "get_model_object.parameters", "os.makedirs", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "utility.column_wise_norm.to", "scipy.stats.rankdata", "scipy.stats.rankdata", "len", "os.path.dirname", "get_model_object.state_dict", "utility.column_wise_norm.cpu().detach().numpy", "get_model_object.cpu().detach().numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "utility.column_wise_norm.cpu().detach", "get_model_object.cpu().detach", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "torch.Tensor().flatten.numpy", "utility.column_wise_norm.cpu", "get_model_object.cpu"], "methods", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.load_data", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.column_wise_norm", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.get_model_object", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_test", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.get_model_object", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_train", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Full training logic\n        \"\"\"", "\n", "# returns anomaly scores from best model", "\n", "residuals", "=", "None", "\n", "\n", "# load dataset -- stored as pickled files", "\n", "X", ",", "S", ",", "y", "=", "load_data", "(", "self", ".", "data_path", ")", "\n", "\n", "X", "=", "column_wise_norm", "(", "torch", ".", "FloatTensor", "(", "X", ")", ")", "\n", "S", "=", "torch", ".", "LongTensor", "(", "S", ")", ".", "flatten", "(", ")", "\n", "\n", "# load scores for each instance from base model as a Tensor", "\n", "AE_scores", "=", "torch", ".", "Tensor", "(", "self", ".", "base_model_scores", ")", ".", "flatten", "(", ")", "\n", "\n", "# create tensor dataset", "\n", "dataset", "=", "TensorDataset", "(", "X", ",", "S", ",", "AE_scores", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "True", ")", "\n", "n_samples", "=", "len", "(", "dataset", ")", "\n", "train_size", "=", "int", "(", "0.8", "*", "n_samples", ")", "# using 80% split in each random cross-validation", "\n", "test_size", "=", "n_samples", "-", "train_size", "\n", "\n", "# if model type is FairOD, the use ndcg normalizer", "\n", "if", "self", ".", "model_type", "==", "\"fairOD\"", ":", "\n", "            ", "ndcg_norm_maj", "=", "np", ".", "sum", "(", "\n", "(", "np", ".", "power", "(", "2.0", ",", "AE_scores", ".", "numpy", "(", ")", "[", "S", "==", "0", "]", ")", "-", "1.0", ")", "/", "np", ".", "log2", "(", "rankdata", "(", "-", "AE_scores", ".", "numpy", "(", ")", "[", "S", "==", "0", "]", ")", "+", "1.0", ")", ")", "\n", "ndcg_norm_min", "=", "np", ".", "sum", "(", "\n", "(", "np", ".", "power", "(", "2.0", ",", "AE_scores", ".", "numpy", "(", ")", "[", "S", "==", "1", "]", ")", "-", "1.0", ")", "/", "np", ".", "log2", "(", "rankdata", "(", "-", "AE_scores", ".", "numpy", "(", ")", "[", "S", "==", "1", "]", ")", "+", "1.0", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "ndcg_norm_maj", ",", "ndcg_norm_min", "=", "None", ",", "None", "\n", "\n", "# record errors for each parameter across iterations", "\n", "", "total_loss", "=", "{", "}", "\n", "construction_loss", "=", "{", "}", "\n", "protected_loss", "=", "{", "}", "\n", "ranking_loss", "=", "{", "}", "\n", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "total_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "construction_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "protected_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "ranking_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "\n", "", "for", "iter_", "in", "range", "(", "self", ".", "niters", ")", ":", "\n", "# best cross validated loss across params", "\n", "            ", "best_test_loss", "=", "1e10", "\n", "\n", "for", "param", "in", "self", ".", "params", ":", "\n", "                ", "alpha", ",", "gamma", "=", "param", "\n", "beta", "=", "1.0", "-", "alpha", "\n", "\n", "avg_split_loss", "=", "0", "\n", "for", "split_", "in", "range", "(", "self", ".", "n_splits", ")", ":", "\n", "                    ", "trainset", ",", "testset", "=", "random_split", "(", "dataset", ",", "[", "train_size", ",", "test_size", "]", ")", "\n", "trainloader", "=", "DataLoader", "(", "trainset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "True", ")", "\n", "testloader", "=", "DataLoader", "(", "testset", ",", "batch_size", "=", "len", "(", "testset", ")", ",", "shuffle", "=", "False", ")", "\n", "\n", "# instantiate model_type weights from the base models", "\n", "model", "=", "get_model_object", "(", "self", ".", "model_type", ",", "layer_dims", "=", "[", "X", ".", "shape", "[", "1", "]", ",", "self", ".", "n_hidden", ",", "\n", "self", ".", "n_hidden", "]", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "base_model_weights", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "# model optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "# train the model_type for given number of epochs", "\n", "                        ", "_", ",", "_", ",", "_", ",", "_", "=", "group_train", "(", "model", "=", "model", ",", "\n", "dataloader", "=", "trainloader", ",", "\n", "device", "=", "device", ",", "\n", "recon_criterion", "=", "self", ".", "recon_criterion", ",", "\n", "sens_croterion", "=", "self", ".", "sens_criterion", ",", "\n", "group_criterion", "=", "self", ".", "group_criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "alpha", "=", "alpha", ",", "\n", "beta", "=", "beta", ",", "\n", "gamma", "=", "gamma", ",", "\n", "ndcg_norm_maj", "=", "ndcg_norm_maj", ",", "\n", "ndcg_norm_min", "=", "ndcg_norm_min", "\n", ")", "\n", "# record test loss for this split", "\n", "", "avg_split_loss", "+=", "group_test", "(", "model", "=", "model", ",", "\n", "dataloader", "=", "testloader", ",", "\n", "device", "=", "device", ",", "\n", "recon_criterion", "=", "self", ".", "recon_criterion", ",", "\n", "sens_criterion", "=", "self", ".", "sens_criterion", ",", "\n", "group_criterion", "=", "self", ".", "group_criterion", ",", "\n", "alpha", "=", "alpha", ",", "\n", "beta", "=", "beta", ",", "\n", "gamma", "=", "gamma", ",", "\n", "ndcg_norm_maj", "=", "ndcg_norm_maj", ",", "\n", "ndcg_norm_min", "=", "ndcg_norm_min", "\n", ")", "\n", "\n", "# average validation loss for this param", "\n", "", "avg_split_loss", "=", "avg_split_loss", "/", "self", ".", "n_splits", "\n", "\n", "# if this param has best loss then train on full data and store the model and record anomaly scores", "\n", "if", "avg_split_loss", "<", "best_test_loss", ":", "\n", "# set new best as avg loss for the current best parameter", "\n", "                    ", "best_test_loss", "=", "avg_split_loss", "\n", "\n", "# instantiate model now that we know the best parameter so far", "\n", "model", "=", "get_model_object", "(", "self", ".", "model_type", ",", "layer_dims", "=", "[", "X", ".", "shape", "[", "1", "]", ",", "self", ".", "n_hidden", ",", "\n", "self", ".", "n_hidden", "]", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "base_model_weights", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "# model optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "\n", "# train on full dataset", "\n", "_", ",", "_", ",", "_", ",", "_", "=", "group_train", "(", "model", "=", "model", ",", "\n", "dataloader", "=", "dataloader", ",", "# full dataset", "\n", "device", "=", "device", ",", "\n", "recon_criterion", "=", "self", ".", "recon_criterion", ",", "\n", "sens_croterion", "=", "self", ".", "sens_criterion", ",", "\n", "group_criterion", "=", "self", ".", "group_criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "alpha", "=", "alpha", ",", "\n", "beta", "=", "beta", ",", "\n", "gamma", "=", "gamma", ",", "\n", "ndcg_norm_maj", "=", "ndcg_norm_maj", ",", "\n", "ndcg_norm_min", "=", "ndcg_norm_min", "\n", ")", "\n", "\n", "# save the best model_type", "\n", "if", "self", ".", "model_path", ":", "\n", "                        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "self", ".", "model_path", ")", "\n", "\n", "# compute anomaly scores", "\n", "", "model", ".", "eval", "(", ")", "\n", "this_X_pred", "=", "model", "(", "X", ".", "to", "(", "device", ")", ")", "\n", "residuals", "=", "np", ".", "linalg", ".", "norm", "(", "X", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "-", "this_X_pred", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "", "", "", "self", ".", "scores", "=", "residuals", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.__init__": [[250, 290], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "'''\n        Keys in the config:\n        model_type: takes values in [\"base\", \"fairL\"]\n        recon_criterion: loss function for reconstruction error\n        sens_criterion: loss function for correlation based statistical parity\n        data: directory path to dataset. Directory contains X.pkl, y.pkl, pv.pkl.\n                The .pkl files should be saved from an input dataset.\n        epochs: training epochs for the learner\n        lr: learning rate used in adam optimizer\n        model_path: path to save the best model\n        base_model_weights: path to saved parameters from the base autoencoder model if model_type=\"fairL\"\n        niters: number of times repeating the experiment to reduce variation over random initializations\n        n_splits: cross-validation splits\n        n_hidden: number of nodes in a hidden layer\n        params: list of parameter values. parameter = alpha\n        '''", "\n", "self", ".", "model_type", "=", "config", "[", "\"model_type\"", "]", "\n", "self", ".", "recon_criterion", "=", "config", "[", "\"recon_criterion\"", "]", "\n", "self", ".", "sens_criterion", "=", "config", "[", "\"sens_criterion\"", "]", "\n", "\n", "self", ".", "data_path", "=", "config", "[", "\"data\"", "]", "\n", "self", ".", "epochs", "=", "config", "[", "\"epochs\"", "]", "\n", "self", ".", "lr", "=", "config", "[", "\"lr\"", "]", "\n", "self", ".", "model_path", "=", "config", "[", "\"model_path\"", "]", "# if not None, then use this path to save the model", "\n", "self", ".", "base_model_weights", "=", "config", "[", "\n", "\"base_model_weights\"", "]", "# final network weights of base model_type (base_weights.pth)", "\n", "\n", "# how many re-runs with random initializations of weights for AE", "\n", "self", ".", "niters", "=", "config", "[", "\"niters\"", "]", "\n", "\n", "self", ".", "n_splits", "=", "config", "[", "\"n_splits\"", "]", "# for recording cross-validation", "\n", "self", ".", "n_hidden", "=", "config", "[", "\"n_hidden\"", "]", "# network hidden layer nodes", "\n", "\n", "# list of tuples (alpha, gamma). See paper for definition of alpha and gamma", "\n", "# first entry in the list is a string \"base\" to denote no regularization", "\n", "self", ".", "params", "=", "config", "[", "\"params\"", "]", "\n", "\n", "# storing anomaly scores", "\n", "self", ".", "scores", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train": [[291, 405], ["utility.load_data", "utility.column_wise_norm", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.LongTensor().flatten", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "int", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.zeros", "numpy.zeros", "numpy.zeros", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "torch.utils.data.random_split", "torch.utils.data.random_split", "torch.utils.data.random_split", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "models.get_model_object", "torch.Adam", "torch.Adam", "torch.Adam", "get_model_object.to", "range", "utility.cor_test", "models.get_model_object", "torch.Adam", "torch.Adam", "torch.Adam", "get_model_object.to", "utility.cor_train", "get_model_object.eval", "get_model_object.", "numpy.linalg.norm", "get_model_object.parameters", "get_model_object.load_state_dict", "utility.cor_train", "get_model_object.parameters", "get_model_object.load_state_dict", "os.makedirs", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "utility.column_wise_norm.to", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.dirname", "get_model_object.state_dict", "utility.column_wise_norm.cpu().detach().numpy", "get_model_object.cpu().detach().numpy", "utility.column_wise_norm.cpu().detach", "get_model_object.cpu().detach", "utility.column_wise_norm.cpu", "get_model_object.cpu"], "methods", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.load_data", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.column_wise_norm", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.get_model_object", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.cor_test", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.get_model_object", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.cor_train", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.cor_train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Full training logic\n        \"\"\"", "\n", "# returns anomaly scores from best model", "\n", "residuals", "=", "None", "\n", "\n", "# load dataset -- stored as pickled files", "\n", "X", ",", "S", ",", "y", "=", "load_data", "(", "self", ".", "data_path", ")", "\n", "\n", "X", "=", "column_wise_norm", "(", "torch", ".", "FloatTensor", "(", "X", ")", ")", "\n", "S", "=", "torch", ".", "LongTensor", "(", "S", ")", ".", "flatten", "(", ")", "\n", "\n", "# create tensor dataset", "\n", "dataset", "=", "TensorDataset", "(", "X", ",", "S", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "True", ")", "\n", "n_samples", "=", "len", "(", "dataset", ")", "\n", "train_size", "=", "int", "(", "0.8", "*", "n_samples", ")", "# using 80% split in each random cross-validation", "\n", "test_size", "=", "n_samples", "-", "train_size", "\n", "\n", "# record errors for each parameter across iterations", "\n", "total_loss", "=", "{", "}", "\n", "construction_loss", "=", "{", "}", "\n", "protected_loss", "=", "{", "}", "\n", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "total_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "construction_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "protected_loss", "[", "param", "]", "=", "np", ".", "zeros", "(", "self", ".", "epochs", ")", "\n", "\n", "", "for", "iter_", "in", "range", "(", "self", ".", "niters", ")", ":", "\n", "# best cross validated loss across params", "\n", "            ", "best_test_loss", "=", "1e10", "\n", "\n", "for", "param", "in", "self", ".", "params", ":", "# here params will only have alpha parameter", "\n", "                ", "alpha", "=", "param", "\n", "beta", "=", "1.0", "-", "alpha", "\n", "\n", "avg_split_loss", "=", "0", "\n", "for", "split_", "in", "range", "(", "self", ".", "n_splits", ")", ":", "\n", "                    ", "trainset", ",", "testset", "=", "random_split", "(", "dataset", ",", "[", "train_size", ",", "test_size", "]", ")", "\n", "trainloader", "=", "DataLoader", "(", "trainset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "True", ")", "\n", "testloader", "=", "DataLoader", "(", "testset", ",", "batch_size", "=", "len", "(", "testset", ")", ",", "shuffle", "=", "False", ")", "\n", "\n", "# instantiate model_type weights from the base models", "\n", "model", "=", "get_model_object", "(", "self", ".", "model_type", ",", "layer_dims", "=", "[", "X", ".", "shape", "[", "1", "]", ",", "self", ".", "n_hidden", ",", "\n", "self", ".", "n_hidden", "]", ")", "\n", "\n", "# get model optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "\n", "if", "self", ".", "base_model_weights", ":", "\n", "                        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "base_model_weights", ")", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "# recon_criterion = nn.MSELoss()", "\n", "# sens_criterion = nn.CrossEntropyLoss()", "\n", "\n", "\n", "for", "epoch", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "# train the model_type for given number of epochs", "\n", "                        ", "_", ",", "_", ",", "_", "=", "cor_train", "(", "model", "=", "model", ",", "\n", "dataloader", "=", "trainloader", ",", "\n", "device", "=", "device", ",", "\n", "recon_criterion", "=", "self", ".", "recon_criterion", ",", "\n", "sens_criterion", "=", "self", ".", "sens_criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "alpha", "=", "alpha", ",", "\n", "beta", "=", "beta", ")", "\n", "# record test loss for this split", "\n", "", "avg_split_loss", "+=", "cor_test", "(", "model", "=", "model", ",", "\n", "dataloader", "=", "testloader", ",", "\n", "device", "=", "device", ",", "\n", "recon_criterion", "=", "self", ".", "recon_criterion", ",", "\n", "sens_criterion", "=", "self", ".", "sens_criterion", ",", "\n", "alpha", "=", "alpha", ",", "\n", "beta", "=", "beta", ")", "\n", "\n", "# average validation loss for this param", "\n", "", "avg_split_loss", "=", "avg_split_loss", "/", "self", ".", "n_splits", "\n", "\n", "# if this param has best loss then store the model and record anomaly scores", "\n", "if", "avg_split_loss", "<", "best_test_loss", ":", "\n", "# set new best as avg loss for the current best parameter", "\n", "                    ", "best_test_loss", "=", "avg_split_loss", "\n", "\n", "# instantiate model now that we know the best parameter so far", "\n", "model", "=", "get_model_object", "(", "self", ".", "model_type", ",", "layer_dims", "=", "[", "X", ".", "shape", "[", "1", "]", ",", "self", ".", "n_hidden", ",", "\n", "self", ".", "n_hidden", "]", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "if", "self", ".", "base_model_weights", ":", "\n", "                        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "base_model_weights", ")", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "# train on full dataset", "\n", "_", ",", "_", ",", "_", "=", "cor_train", "(", "model", "=", "model", ",", "\n", "dataloader", "=", "dataloader", ",", "# full dataset", "\n", "device", "=", "device", ",", "\n", "recon_criterion", "=", "self", ".", "recon_criterion", ",", "\n", "sens_criterion", "=", "self", ".", "sens_criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "alpha", "=", "alpha", ",", "\n", "beta", "=", "beta", ")", "\n", "\n", "# save the best model_type", "\n", "if", "self", ".", "model_path", ":", "\n", "                        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "self", ".", "model_path", ")", "\n", "\n", "# compute anomaly scores", "\n", "", "model", ".", "eval", "(", ")", "\n", "this_X_pred", "=", "model", "(", "X", ".", "to", "(", "device", ")", ")", "\n", "residuals", "=", "np", ".", "linalg", ".", "norm", "(", "X", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "-", "this_X_pred", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "", "", "", "self", ".", "scores", "=", "residuals", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.get_model_object": [[54, 58], ["models.RepresentationLearner"], "function", ["None"], ["", "", "def", "get_model_object", "(", "model_type", ",", "layer_dims", ")", ":", "\n", "# model type is not used. However, in future, we may intend to invoke different structures,", "\n", "# where the model type can help in creating respective network structures", "\n", "    ", "return", "RepresentationLearner", "(", "layer_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.column_wise_norm": [[8, 14], ["x.min", "x.max", "x.min"], "function", ["None"], ["def", "column_wise_norm", "(", "x", ")", ":", "\n", "    ", "'''\n    Returns column wise normalized array\n    '''", "\n", "x_normed", "=", "(", "x", "-", "x", ".", "min", "(", "0", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", "/", "(", "x", ".", "max", "(", "0", ",", "keepdim", "=", "True", ")", "[", "0", "]", "-", "x", ".", "min", "(", "0", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", "\n", "return", "x_normed", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.load_data": [[16, 28], ["open", "pickle.load", "open", "pickle.load", "open", "pickle.load"], "function", ["None"], ["", "def", "load_data", "(", "path", ")", ":", "\n", "    ", "'''\n    Data loading utility. Assumes the directory contain X.pkl, y.pkl, pv.pkl.\n    '''", "\n", "with", "open", "(", "path", "+", "'X.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "X", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "path", "+", "'pv.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "S", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "path", "+", "'y.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "y", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "X", ",", "S", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_train": [[30, 68], ["model.train", "kwargs.get", "kwargs.get", "enumerate", "len", "len", "len", "len", "optimizer.zero_grad", "model", "recon_criterion", "sens_croterion", "loss.backward", "optimizer.step", "recon_criterion.item", "sens_croterion.item", "group_criterion.item", "loss.item", "X_i.to", "S_i.to", "group_criterion", "group_criterion"], "function", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train"], ["", "def", "group_train", "(", "model", ",", "dataloader", ",", "device", ",", "recon_criterion", ",", "sens_croterion", ",", "group_criterion", ",", "\n", "optimizer", ",", "alpha", ",", "beta", ",", "gamma", ",", "**", "kwargs", ")", ":", "\n", "    ", "'''\n    Trainer method for fair representation that uses a group based regulaizer. See Eq. 13, and L_gf for fairOD-C.\n    '''", "\n", "model", ".", "train", "(", ")", "\n", "ndcg_norm_maj", "=", "kwargs", ".", "get", "(", "\"ndcg_norm_maj\"", ")", "\n", "ndcg_norm_min", "=", "kwargs", ".", "get", "(", "\"ndcg_norm_min\"", ")", "\n", "\n", "training_loss", "=", "0", "\n", "recon_loss", "=", "0", "\n", "sens_loss", "=", "0", "\n", "group_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "X_i", ",", "S_i", ",", "A_i", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "X_i", ",", "S_i", "=", "X_i", ".", "to", "(", "device", ")", ",", "S_i", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "recon_output", "=", "model", "(", "X_i", ")", "\n", "r_loss", "=", "recon_criterion", "(", "recon_output", ",", "X_i", ")", "\n", "s_loss", "=", "sens_croterion", "(", "recon_output", ",", "X_i", ",", "S_i", ")", "\n", "if", "ndcg_norm_maj", ":", "\n", "            ", "g_loss", "=", "group_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ",", "A_i", ",", "ndcg_norm_maj", ",", "ndcg_norm_min", ")", "\n", "", "else", ":", "\n", "            ", "g_loss", "=", "group_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ",", "A_i", ")", "\n", "", "loss", "=", "alpha", "*", "r_loss", "+", "beta", "*", "s_loss", "+", "gamma", "*", "g_loss", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "recon_loss", "+=", "r_loss", ".", "item", "(", ")", "\n", "sens_loss", "+=", "s_loss", ".", "item", "(", ")", "\n", "group_loss", "+=", "g_loss", ".", "item", "(", ")", "\n", "training_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "recon_loss", "/=", "len", "(", "dataloader", ")", "\n", "sens_loss", "/=", "len", "(", "dataloader", ")", "\n", "group_loss", "/=", "len", "(", "dataloader", ")", "\n", "training_loss", "/=", "len", "(", "dataloader", ")", "\n", "return", "recon_loss", ",", "sens_loss", ",", "training_loss", ",", "group_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_test": [[70, 95], ["model.eval", "kwargs.get", "kwargs.get", "enumerate", "len", "model", "recon_criterion", "sens_criterion", "loss.item", "X_i.to", "S_i.to", "group_criterion", "group_criterion"], "function", ["None"], ["", "def", "group_test", "(", "model", ",", "dataloader", ",", "device", ",", "recon_criterion", ",", "sens_criterion", ",", "group_criterion", ",", "\n", "alpha", ",", "beta", ",", "gamma", ",", "**", "kwargs", ")", ":", "\n", "    ", "'''\n    Evaluate method for fair representation that uses a group based regulaizer.\n    '''", "\n", "model", ".", "eval", "(", ")", "\n", "ndcg_norm_maj", "=", "kwargs", ".", "get", "(", "\"ndcg_norm_maj\"", ")", "\n", "ndcg_norm_min", "=", "kwargs", ".", "get", "(", "\"ndcg_norm_min\"", ")", "\n", "\n", "testing_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "X_i", ",", "S_i", ",", "A_i", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "X_i", ",", "S_i", "=", "X_i", ".", "to", "(", "device", ")", ",", "S_i", ".", "to", "(", "device", ")", "\n", "recon_output", "=", "model", "(", "X_i", ")", "\n", "recon_loss", "=", "recon_criterion", "(", "recon_output", ",", "X_i", ")", "\n", "sens_loss", "=", "sens_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ")", "\n", "if", "ndcg_norm_maj", ":", "\n", "            ", "group_loss", "=", "group_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ",", "A_i", ",", "ndcg_norm_maj", ",", "ndcg_norm_min", ")", "\n", "", "else", ":", "\n", "            ", "group_loss", "=", "group_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ",", "A_i", ")", "\n", "", "loss", "=", "alpha", "*", "recon_loss", "+", "beta", "*", "sens_loss", "+", "gamma", "*", "group_loss", "\n", "\n", "testing_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "testing_loss", "/=", "len", "(", "dataloader", ")", "\n", "return", "testing_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.cor_train": [[97, 124], ["model.train", "enumerate", "len", "len", "len", "optimizer.zero_grad", "model", "recon_criterion", "sens_criterion", "loss.backward", "optimizer.step", "recon_criterion.item", "sens_criterion.item", "loss.item", "X_i.to", "S_i.to"], "function", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train"], ["", "def", "cor_train", "(", "model", ",", "dataloader", ",", "device", ",", "recon_criterion", ",", "sens_criterion", ",", "optimizer", ",", "alpha", ",", "beta", ")", ":", "\n", "    ", "'''\n    Trainer method for fair representation that does NOT use a group based regulaizer.\n    Only regularizer used is a based on sensitive/protected attribute.\n    '''", "\n", "model", ".", "train", "(", ")", "\n", "training_loss", "=", "0", "\n", "recon_loss", "=", "0", "\n", "sens_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "X_i", ",", "S_i", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "X_i", ",", "S_i", "=", "X_i", ".", "to", "(", "device", ")", ",", "S_i", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "recon_output", "=", "model", "(", "X_i", ")", "\n", "recon_loss", "=", "recon_criterion", "(", "recon_output", ",", "X_i", ")", "\n", "sens_loss", "=", "sens_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ")", "\n", "loss", "=", "alpha", "*", "recon_loss", "+", "beta", "*", "sens_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "recon_loss", "+=", "recon_loss", ".", "item", "(", ")", "\n", "sens_loss", "+=", "sens_loss", ".", "item", "(", ")", "\n", "training_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "recon_loss", "/=", "len", "(", "dataloader", ")", "\n", "sens_loss", "/=", "len", "(", "dataloader", ")", "\n", "training_loss", "/=", "len", "(", "dataloader", ")", "\n", "\n", "return", "recon_loss", ",", "sens_loss", ",", "training_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.cor_test": [[126, 143], ["model.eval", "enumerate", "len", "model", "recon_criterion", "sens_criterion", "loss.item", "X_i.to", "S_i.to"], "function", ["None"], ["", "def", "cor_test", "(", "model", ",", "dataloader", ",", "device", ",", "recon_criterion", ",", "sens_criterion", ",", "alpha", ",", "beta", ")", ":", "\n", "    ", "'''\n    Evaluation method for fair representation that does NOT use a group based regulaizer.\n    '''", "\n", "model", ".", "eval", "(", ")", "\n", "testing_loss", "=", "0", "\n", "\n", "for", "batch_idx", ",", "(", "X_i", ",", "S_i", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "X_i", ",", "S_i", "=", "X_i", ".", "to", "(", "device", ")", ",", "S_i", ".", "to", "(", "device", ")", "\n", "recon_output", "=", "model", "(", "X_i", ")", "\n", "recon_loss", "=", "recon_criterion", "(", "recon_output", ",", "X_i", ")", "\n", "sens_loss", "=", "sens_criterion", "(", "recon_output", ",", "X_i", ",", "S_i", ")", "\n", "loss", "=", "alpha", "*", "recon_loss", "+", "beta", "*", "sens_loss", "\n", "testing_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "testing_loss", "/=", "len", "(", "dataloader", ")", "\n", "return", "testing_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.cor_sens_criterion": [[145, 154], ["torch.pow().sum", "torch.abs", "torch.pow().sum.mean", "S.type", "S.type().mean", "torch.pow", "torch.dot", "torch.sqrt", "S.type", "torch.dot", "torch.dot"], "function", ["None"], ["", "def", "cor_sens_criterion", "(", "X_hat", ",", "X", ",", "S", ")", ":", "\n", "    ", "'''\n    Correlation based regularizer for sensitive/protected attribute.\n    '''", "\n", "ell", "=", "torch", ".", "pow", "(", "X_hat", "-", "X", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "l_centered", "=", "ell", "-", "ell", ".", "mean", "(", ")", "\n", "S_centered", "=", "S", ".", "type", "(", "torch", ".", "FloatTensor", ")", "-", "S", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "mean", "(", ")", "\n", "return", "torch", ".", "abs", "(", "torch", ".", "dot", "(", "l_centered", ",", "S_centered", ")", "/", "torch", ".", "sqrt", "(", "\n", "torch", ".", "dot", "(", "l_centered", ",", "l_centered", ")", "*", "torch", ".", "dot", "(", "S_centered", ",", "S_centered", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_corr_criterion": [[156, 182], ["torch.pow().sum", "ell_1.mean", "scores_1.mean", "ell_0.mean", "scores_0.mean", "torch.dot", "torch.sqrt", "torch.dot", "torch.sqrt", "enumerate", "enumerate", "torch.pow", "list", "list", "torch.dot", "torch.dot", "torch.dot", "torch.dot"], "function", ["None"], ["", "def", "group_corr_criterion", "(", "X_hat", ",", "X", ",", "S", ",", "AE_scores", ")", ":", "\n", "    ", "'''\n    This reguralizer promotes correlation of reconstruction error per-group with\n    corrsponding unregularized autoencoder OD scores_local\n    '''", "\n", "ind_1", "=", "[", "i", "for", "i", ",", "s_i", "in", "enumerate", "(", "list", "(", "S", ")", ")", "if", "s_i", "==", "1", "]", "\n", "ind_0", "=", "[", "i", "for", "i", ",", "s_i", "in", "enumerate", "(", "list", "(", "S", ")", ")", "if", "s_i", "==", "0", "]", "\n", "\n", "ell", "=", "torch", ".", "pow", "(", "X_hat", "-", "X", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ell_1", "=", "ell", "[", "ind_1", "]", "\n", "ell_1_centered", "=", "ell_1", "-", "ell_1", ".", "mean", "(", ")", "\n", "\n", "scores_1", "=", "AE_scores", "[", "ind_1", "]", "\n", "scores_1_centered", "=", "scores_1", "-", "scores_1", ".", "mean", "(", ")", "\n", "\n", "ell_0", "=", "ell", "[", "ind_0", "]", "\n", "ell_0_centered", "=", "ell_0", "-", "ell_0", ".", "mean", "(", ")", "\n", "\n", "scores_0", "=", "AE_scores", "[", "ind_0", "]", "\n", "scores_0_centered", "=", "scores_0", "-", "scores_0", ".", "mean", "(", ")", "\n", "\n", "corr_0", "=", "torch", ".", "dot", "(", "ell_0_centered", ",", "scores_0_centered", ")", "/", "torch", ".", "sqrt", "(", "\n", "torch", ".", "dot", "(", "ell_0_centered", ",", "ell_0_centered", ")", "*", "torch", ".", "dot", "(", "scores_0_centered", ",", "scores_0_centered", ")", ")", "\n", "corr_1", "=", "torch", ".", "dot", "(", "ell_1_centered", ",", "scores_1_centered", ")", "/", "torch", ".", "sqrt", "(", "\n", "torch", ".", "dot", "(", "ell_1_centered", ",", "ell_1_centered", ")", "*", "torch", ".", "dot", "(", "scores_1_centered", ",", "scores_1_centered", ")", ")", "\n", "return", "-", "1.0", "*", "(", "corr_0", "+", "corr_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.approx_ndcg_loss": [[184, 197], ["torch.nn.Sigmoid", "torch.log2", "torch.pow", "torch.nn.Sigmoid.sum", "torch.nn.Sigmoid.", "f.unsqueeze", "torch.ones", "len", "f.unsqueeze", "torch.ones", "len"], "function", ["None"], ["", "def", "approx_ndcg_loss", "(", "f", ",", "s", ",", "p", "=", "2", ",", "scale", "=", "1", ")", ":", "\n", "    ", "'''\n    Computes approx NDCG\n    '''", "\n", "sigm", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "numerator", "=", "torch", ".", "pow", "(", "p", ",", "s", ")", "-", "1.0", "\n", "denominator", "=", "torch", ".", "log2", "(", "1.0", "+", "(", "sigm", "(", "-", "scale", "*", "(", "f", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "torch", ".", "ones", "(", "[", "1", ",", "len", "(", "f", ")", "]", ")", "-", "\n", "(", "f", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "torch", ".", "ones", "(", "[", "1", ",", "len", "(", "f", ")", "]", ")", ")", ".", "transpose", "(", "0", ",", "\n", "1", ")", ")", ")", ")", ".", "sum", "(", "\n", "dim", "=", "1", ")", ")", "\n", "value", "=", "(", "numerator", "/", "denominator", ")", ".", "sum", "(", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.group_ndcg_criterion": [[199, 220], ["torch.pow().sum", "utility.approx_ndcg_loss", "utility.approx_ndcg_loss", "enumerate", "enumerate", "torch.pow", "list", "list"], "function", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.approx_ndcg_loss", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.approx_ndcg_loss"], ["", "def", "group_ndcg_criterion", "(", "X_hat", ",", "X", ",", "S", ",", "AE_scores", ",", "ndcg_majority_const", ",", "ndcg_minority_const", ")", ":", "\n", "    ", "'''\n     This reguralizer promotes rank preservation of reconstruction error per-group with corresponding\n     unregularized autoencoder OD scores.\n     Proposed GroupFidelity criterion.\n    '''", "\n", "ind_1", "=", "[", "i", "for", "i", ",", "s_i", "in", "enumerate", "(", "list", "(", "S", ")", ")", "if", "s_i", "==", "1", "]", "\n", "ind_0", "=", "[", "i", "for", "i", ",", "s_i", "in", "enumerate", "(", "list", "(", "S", ")", ")", "if", "s_i", "==", "0", "]", "\n", "\n", "ell", "=", "torch", ".", "pow", "(", "X_hat", "-", "X", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "ell_1", "=", "ell", "[", "ind_1", "]", "\n", "ell_0", "=", "ell", "[", "ind_0", "]", "\n", "\n", "a_1", "=", "AE_scores", "[", "ind_1", "]", "\n", "a_0", "=", "AE_scores", "[", "ind_0", "]", "\n", "\n", "minority_ndcg", "=", "(", "1.0", "/", "ndcg_minority_const", ")", "*", "approx_ndcg_loss", "(", "ell_1", ",", "a_1", ",", "p", "=", "64", ",", "scale", "=", "100", ")", "\n", "majority_ndcg", "=", "(", "1.0", "/", "ndcg_majority_const", ")", "*", "approx_ndcg_loss", "(", "ell_0", ",", "a_0", ",", "p", "=", "64", ",", "scale", "=", "100", ")", "\n", "return_val", "=", "(", "1", "-", "minority_ndcg", ")", "+", "(", "1", "-", "majority_ndcg", ")", "\n", "return", "return_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.evaluate": [[222, 259], ["sum", "sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_auc_score", "sklearn.metrics.average_precision_score", "sklearn.metrics.average_precision_score", "int", "int", "numpy.argsort", "sum", "sum", "len", "len"], "function", ["None"], ["", "def", "evaluate", "(", "y_true", ",", "S", ",", "scores", ")", ":", "\n", "# store evaluated metrics as a dict", "\n", "    ", "results", "=", "{", "}", "\n", "\n", "# per group true outliers", "\n", "y_true_majority", "=", "y_true", "[", "S", "==", "0", "]", "\n", "y_true_minority", "=", "y_true", "[", "S", "==", "1", "]", "\n", "\n", "# count how many outliers", "\n", "n_flagged", "=", "sum", "(", "y_true", "==", "1", ")", "\n", "\n", "# find top flagged indices", "\n", "top_k", "=", "np", ".", "argsort", "(", "-", "scores", ")", "[", ":", "n_flagged", "]", "\n", "\n", "maj_outliers", "=", "[", "r", "for", "r", "in", "top_k", "if", "S", "[", "r", "]", "==", "0.", "]", "\n", "min_outliers", "=", "[", "r", "for", "r", "in", "top_k", "if", "S", "[", "r", "]", "==", "1.", "]", "\n", "\n", "# evaluate ROC ==> tuple (majority_roc, minority_roc)", "\n", "majority_roc", "=", "roc_auc_score", "(", "y_true_majority", ",", "scores", "[", "S", "==", "0", "]", ")", "\n", "minority_roc", "=", "roc_auc_score", "(", "y_true_minority", ",", "scores", "[", "S", "==", "1", "]", ")", "\n", "results", "[", "\"roc\"", "]", "=", "(", "majority_roc", ",", "minority_roc", ")", "\n", "\n", "# evaluate AP", "\n", "majority_ap", "=", "average_precision_score", "(", "y_true_majority", ",", "scores", "[", "S", "==", "0", "]", ")", "\n", "minority_ap", "=", "average_precision_score", "(", "y_true_minority", ",", "scores", "[", "S", "==", "1", "]", ")", "\n", "results", "[", "\"ap\"", "]", "=", "(", "majority_ap", ",", "minority_ap", ")", "\n", "\n", "# evaluate flag-rates ==> tuple (majority_flag_rate, minority_flag_rate)", "\n", "n_majority", "=", "int", "(", "sum", "(", "S", "==", "0", ")", ")", "\n", "n_minority", "=", "int", "(", "sum", "(", "S", "==", "1", ")", ")", "\n", "\n", "majority_flag", "=", "(", "len", "(", "maj_outliers", ")", "/", "n_flagged", ")", "*", "n_flagged", "/", "n_majority", "\n", "minority_flag", "=", "(", "len", "(", "min_outliers", ")", "/", "n_flagged", ")", "*", "n_flagged", "/", "n_minority", "\n", "\n", "results", "[", "\"flag_rate\"", "]", "=", "(", "majority_flag", ",", "minority_flag", ")", "\n", "\n", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.run.run_demo": [[5, 70], ["models.BTrainer", "models.BTrainer.train", "load_data", "utility.evaluate", "print", "models.BTrainer", "models.BTrainer.train", "utility.evaluate", "print", "models.FTrainer", "models.FTrainer.train", "utility.evaluate", "print", "models.FTrainer", "models.FTrainer.train", "utility.evaluate", "print", "nn.MSELoss", "nn.MSELoss", "nn.MSELoss", "nn.MSELoss"], "function", ["home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.load_data", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.evaluate", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.evaluate", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.evaluate", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.models.BTrainer.train", "home.repos.pwc.inspect_result.Shubhranshu-Shekhar_fairOD.fairod.utility.evaluate"], ["def", "run_demo", "(", ")", ":", "\n", "# edit config to train", "\n", "# 1. let's train and record base autoencoder. It requires alpha = 1", "\n", "    ", "config", "=", "{", "\"group_criterion\"", ":", "None", ",", "\"data\"", ":", "\"../data/synthetic/1/\"", ",", "\"epochs\"", ":", "1", ",", "\"lr\"", ":", "0.001", ",", "\n", "\"base_model_weights\"", ":", "None", ",", "\"base_model_scores\"", ":", "None", ",", "\"niters\"", ":", "1", ",", "\"n_splits\"", ":", "2", ",", "\"n_hidden\"", ":", "2", ",", "\n", "\"model_type\"", ":", "\"base\"", ",", "\"recon_criterion\"", ":", "nn", ".", "MSELoss", "(", ")", ",", "\n", "\"sens_criterion\"", ":", "cor_sens_criterion", ",", "# it doesn't use it, but needs the function", "\n", "\"model_path\"", ":", "\"../model_data/synthetic/1/model_weights.pt\"", ",", "\"params\"", ":", "[", "1.", "]", "}", "\n", "\n", "base_trainer", "=", "BTrainer", "(", "config", "=", "config", ")", "\n", "base_trainer", ".", "train", "(", ")", "\n", "base_scores", "=", "base_trainer", ".", "scores", "\n", "\n", "# evaluate the base performance", "\n", "_", ",", "S", ",", "y_true", "=", "load_data", "(", "config", "[", "\"data\"", "]", ")", "\n", "base_metrics", "=", "evaluate", "(", "y_true", "=", "y_true", ",", "S", "=", "S", ",", "scores", "=", "base_scores", ")", "\n", "print", "(", "base_metrics", ")", "\n", "\n", "# 2. Train and evaluate FairOD-L (L for laziness).", "\n", "config", "=", "{", "\"model_type\"", ":", "\"fairL\"", ",", "\"recon_criterion\"", ":", "nn", ".", "MSELoss", "(", ")", ",", "\"sens_criterion\"", ":", "cor_sens_criterion", ",", "\n", "\"data\"", ":", "\"../data/synthetic/1/\"", ",", "\"epochs\"", ":", "1", ",", "\"lr\"", ":", "0.001", ",", "\n", "\"model_path\"", ":", "None", ",", "\"base_model_weights\"", ":", "\"../model_data/synthetic/1/model_weights.pt\"", ",", "\n", "\"niters\"", ":", "1", ",", "\"n_splits\"", ":", "2", ",", "\"n_hidden\"", ":", "2", ",", "\n", "\"params\"", ":", "[", "0.01", ",", "0.5", ",", "0.9", "]", "}", "\n", "fair_correlation_trainer", "=", "BTrainer", "(", "config", "=", "config", ")", "# fairOD-L", "\n", "fair_correlation_trainer", ".", "train", "(", ")", "\n", "fair_corr_scores", "=", "fair_correlation_trainer", ".", "scores", "\n", "fair_corr_metrics", "=", "evaluate", "(", "y_true", "=", "y_true", ",", "S", "=", "S", ",", "scores", "=", "fair_corr_scores", ")", "\n", "print", "(", "fair_corr_metrics", ")", "\n", "\n", "# 3. Train and evaluate FairOD-C", "\n", "# a group fairness based detector", "\n", "config", "=", "{", "\"model_type\"", ":", "\"fairC\"", ",", "\"recon_criterion\"", ":", "nn", ".", "MSELoss", "(", ")", ",", "\"sens_criterion\"", ":", "cor_sens_criterion", ",", "\n", "\"group_criterion\"", ":", "group_corr_criterion", ",", "\n", "\"data\"", ":", "\"../data/synthetic/1/\"", ",", "\"epochs\"", ":", "1", ",", "\"lr\"", ":", "0.001", ",", "\n", "\"model_path\"", ":", "None", ",", "\n", "\"base_model_weights\"", ":", "\"../model_data/synthetic/1/model_weights.pt\"", ",", "\n", "\"base_model_scores\"", ":", "base_scores", ",", "\n", "\"niters\"", ":", "1", ",", "\"n_splits\"", ":", "2", ",", "\"n_hidden\"", ":", "2", ",", "\n", "\"params\"", ":", "[", "(", "a", ",", "g", ")", "for", "a", "in", "[", "0.01", ",", "0.5", ",", "0.9", "]", "for", "g", "in", "[", "0.01", ",", "1", ",", "10", ",", "100", ",", "10000", "]", "]", "}", "\n", "\n", "# Train requires alpha, gamma parameters", "\n", "fair_group_trainer", "=", "FTrainer", "(", "config", "=", "config", ")", "\n", "fair_group_trainer", ".", "train", "(", ")", "\n", "fair_group_scores", "=", "fair_group_trainer", ".", "scores", "\n", "fair_group_metrics", "=", "evaluate", "(", "y_true", "=", "y_true", ",", "S", "=", "S", ",", "scores", "=", "fair_group_scores", ")", "\n", "print", "(", "fair_group_metrics", ")", "\n", "\n", "# 4. tain and evaluate FairOD. The proposed method.", "\n", "# a group fairness based detector, uses ndcg based criterion", "\n", "config", "=", "{", "\"model_type\"", ":", "\"fairOD\"", ",", "\"recon_criterion\"", ":", "nn", ".", "MSELoss", "(", ")", ",", "\"sens_criterion\"", ":", "cor_sens_criterion", ",", "\n", "\"group_criterion\"", ":", "group_ndcg_criterion", ",", "\n", "\"data\"", ":", "\"../data/synthetic/1/\"", ",", "\"epochs\"", ":", "1", ",", "\"lr\"", ":", "0.001", ",", "\n", "\"model_path\"", ":", "None", ",", "\n", "\"base_model_weights\"", ":", "\"../model_data/synthetic/1/model_weights.pt\"", ",", "\n", "\"base_model_scores\"", ":", "base_scores", ",", "\n", "\"niters\"", ":", "1", ",", "\"n_splits\"", ":", "2", ",", "\"n_hidden\"", ":", "2", ",", "\n", "\"params\"", ":", "[", "(", "a", ",", "g", ")", "for", "a", "in", "[", "0.01", ",", "0.9", "]", "for", "g", "in", "[", "0.01", ",", "1", "]", "]", "}", "\n", "\n", "# Train requires alpha, gamma parameters", "\n", "fairOD_trainer", "=", "FTrainer", "(", "config", "=", "config", ")", "\n", "fairOD_trainer", ".", "train", "(", ")", "\n", "fairOD_scores", "=", "fairOD_trainer", ".", "scores", "\n", "fairOD_metrics", "=", "evaluate", "(", "y_true", "=", "y_true", ",", "S", "=", "S", ",", "scores", "=", "fairOD_scores", ")", "\n", "print", "(", "fairOD_metrics", ")", "\n", "\n"]]}