{"home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.evaluate_model.eval_model": [[40, 84], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "masks_hard[].astype", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "masks_hard[].astype.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax", "model"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "masks_hard", "=", "masks_hard", "[", "0", "]", ".", "astype", "(", "np", ".", "int", ")", "\n", "masks_soft", "=", "masks_soft", "[", "0", "]", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", ",", "masks_soft", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.VGG16features.__init__": [[26, 60], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "hednet.VGG16features.modules", "isinstance", "m.weight.data.normal_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation", "=", "F", ".", "relu", ")", ":", "\n", "        ", "super", "(", "VGG16features", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "conv1_1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "(", "33", ",", "33", ")", ")", "\n", "self", ".", "conv1_2", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv2_1", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv2_2", "=", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv3_1", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv3_2", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv3_3", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool3", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv4_1", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv4_2", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv4_3", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool4", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv5_1", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv5_2", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv5_3", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool5", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", ".5", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.VGG16features.forward": [[61, 104], ["hednet.VGG16features.conv1_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv1_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool1", "hednet.VGG16features.conv2_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv2_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool2", "hednet.VGG16features.conv3_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool3", "hednet.VGG16features.conv4_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool4", "hednet.VGG16features.conv5_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool5"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1_2", "(", "x", ")", "\n", "c1", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool1", "(", "c1", ")", "\n", "\n", "x", "=", "self", ".", "conv2_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_2", "(", "x", ")", "\n", "c2", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool2", "(", "c2", ")", "\n", "\n", "x", "=", "self", ".", "conv3_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_3", "(", "x", ")", "\n", "c3", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool3", "(", "c3", ")", "\n", "\n", "x", "=", "self", ".", "conv4_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_3", "(", "x", ")", "\n", "c4", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool4", "(", "c4", ")", "\n", "\n", "x", "=", "self", ".", "conv5_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_3", "(", "x", ")", "\n", "c5", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool5", "(", "c5", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.VGG16features.forward_hypercol": [[105, 146], ["hednet.VGG16features.conv1_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv1_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool1", "hednet.VGG16features.conv2_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv2_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool2", "hednet.VGG16features.conv3_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool3", "hednet.VGG16features.conv4_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool4", "hednet.VGG16features.conv5_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_3", "hednet.VGG16features.activation"], "methods", ["None"], ["", "def", "forward_hypercol", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1_2", "(", "x", ")", "\n", "c1", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool1", "(", "c1", ")", "\n", "\n", "x", "=", "self", ".", "conv2_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_2", "(", "x", ")", "\n", "c2", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool2", "(", "c2", ")", "\n", "\n", "x", "=", "self", ".", "conv3_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_3", "(", "x", ")", "\n", "c3", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool3", "(", "c3", ")", "\n", "\n", "x", "=", "self", ".", "conv4_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_3", "(", "x", ")", "\n", "c4", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool4", "(", "c4", ")", "\n", "\n", "x", "=", "self", ".", "conv5_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_3", "(", "x", ")", "\n", "c5", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "return", "c1", ",", "c2", ",", "c3", ",", "c4", ",", "c5", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.VGG.__init__": [[150, 163], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "hednet.VGG._initialize_weights", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG._initialize_weights"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "super", "(", "VGG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "features", "=", "features", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "num_classes", ")", ",", "\n", ")", "\n", "self", ".", "_initialize_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.VGG.forward": [[164, 169], ["hednet.VGG.features", "hednet.VGG.view", "hednet.VGG.classifier", "hednet.VGG.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.VGG._initialize_weights": [[170, 183], ["hednet.VGG.modules", "isinstance", "m.weight.data.normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", ".5", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.HNNNet.__init__": [[228, 259], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "hednet.HNNNet.named_modules", "hednet.vgg16", "m[].weight.data.fill_", "isinstance", "m[].weight.data.normal_", "isinstance", "m[].weight.data.fill_", "m[].bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.vgg16"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "True", ",", "class_number", "=", "2", ")", ":", "\n", "# define VGG architecture and layers", "\n", "        ", "super", "(", "HNNNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# define fully-convolutional layers", "\n", "self", ".", "dsn1", "=", "nn", ".", "Conv2d", "(", "64", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn2", "=", "nn", ".", "Conv2d", "(", "128", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn3", "=", "nn", ".", "Conv2d", "(", "256", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn4", "=", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn5", "=", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn6", "=", "nn", ".", "Conv2d", "(", "5", ",", "class_number", ",", "1", ")", "\n", "\n", "# define upsampling/deconvolutional layers", "\n", "self", ".", "upscore2", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "upscore3", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "4", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "upscore4", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "8", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "upscore5", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "16", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "# initialize weights of layers", "\n", "for", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "m", "[", "0", "]", "==", "'dsn6'", ":", "\n", "                ", "m", "[", "1", "]", ".", "weight", ".", "data", ".", "fill_", "(", "0.2", ")", "\n", "", "elif", "isinstance", "(", "m", "[", "1", "]", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", "[", "1", "]", ".", "kernel_size", "[", "0", "]", "*", "m", "[", "1", "]", ".", "kernel_size", "[", "1", "]", "*", "m", "[", "1", "]", ".", "out_channels", "\n", "m", "[", "1", "]", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", ".5", ")", "\n", "", "elif", "isinstance", "(", "m", "[", "1", "]", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", "[", "1", "]", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", "[", "1", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "", "_", ",", "VGG16fs", "=", "vgg16", "(", "pretrained", "=", "pretrained", ")", "\n", "self", ".", "VGG16fs", "=", "VGG16fs", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.HNNNet.forward": [[261, 294], ["hednet.HNNNet.VGG16fs.forward_hypercol", "hednet.HNNNet.upscore5", "hednet.HNNNet.crop", "hednet.HNNNet.upscore4", "hednet.HNNNet.crop", "hednet.HNNNet.upscore3", "hednet.HNNNet.crop", "hednet.HNNNet.upscore2", "hednet.HNNNet.crop", "hednet.HNNNet.dsn1", "hednet.HNNNet.crop", "hednet.HNNNet.dsn6", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "x.size", "hednet.HNNNet.dsn5", "hednet.HNNNet.dsn4", "hednet.HNNNet.dsn3", "hednet.HNNNet.dsn2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG16features.forward_hypercol", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "size", "=", "x", ".", "size", "(", ")", "[", "2", ":", "4", "]", "\n", "\n", "# get output from VGG model", "\n", "conv1", ",", "conv2", ",", "conv3", ",", "conv4", ",", "conv5", "=", "self", ".", "VGG16fs", ".", "forward_hypercol", "(", "x", ")", "\n", "\n", "## side output", "\n", "dsn5_up", "=", "self", ".", "upscore5", "(", "self", ".", "dsn5", "(", "conv5", ")", ")", "\n", "d5", "=", "self", ".", "crop", "(", "dsn5_up", ",", "size", ")", "\n", "\n", "dsn4_up", "=", "self", ".", "upscore4", "(", "self", ".", "dsn4", "(", "conv4", ")", ")", "\n", "d4", "=", "self", ".", "crop", "(", "dsn4_up", ",", "size", ")", "\n", "\n", "dsn3_up", "=", "self", ".", "upscore3", "(", "self", ".", "dsn3", "(", "conv3", ")", ")", "\n", "d3", "=", "self", ".", "crop", "(", "dsn3_up", ",", "size", ")", "\n", "\n", "dsn2_up", "=", "self", ".", "upscore2", "(", "self", ".", "dsn2", "(", "conv2", ")", ")", "\n", "d2", "=", "self", ".", "crop", "(", "dsn2_up", ",", "size", ")", "\n", "\n", "dsn1", "=", "self", ".", "dsn1", "(", "conv1", ")", "\n", "d1", "=", "self", ".", "crop", "(", "dsn1", ",", "size", ")", "\n", "\n", "# weighted fusion (with learning fusion weights)", "\n", "d6", "=", "self", ".", "dsn6", "(", "torch", ".", "cat", "(", "(", "d1", ",", "d2", ",", "d3", ",", "d4", ",", "d5", ")", ",", "1", ")", ")", "\n", "\n", "d1", "=", "F", ".", "sigmoid", "(", "d1", ")", "\n", "d2", "=", "F", ".", "sigmoid", "(", "d2", ")", "\n", "d3", "=", "F", ".", "sigmoid", "(", "d3", ")", "\n", "d4", "=", "F", ".", "sigmoid", "(", "d4", ")", "\n", "d5", "=", "F", ".", "sigmoid", "(", "d5", ")", "\n", "#d6 = F.sigmoid(d6)", "\n", "return", "d1", ",", "d2", ",", "d3", ",", "d4", ",", "d5", ",", "d6", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.HNNNet.crop": [[296, 301], ["d.size", "int", "int", "math.floor", "int", "math.floor", "int", "math.floor", "math.floor"], "methods", ["None"], ["", "def", "crop", "(", "self", ",", "d", ",", "size", ")", ":", "\n", "        ", "d_h", ",", "d_w", "=", "d", ".", "size", "(", ")", "[", "2", ":", "4", "]", "\n", "g_h", ",", "g_w", "=", "size", "[", "0", "]", ",", "size", "[", "1", "]", "\n", "d1", "=", "d", "[", ":", ",", ":", ",", "int", "(", "math", ".", "floor", "(", "(", "d_h", "-", "g_h", ")", "/", "2.0", ")", ")", ":", "int", "(", "math", ".", "floor", "(", "(", "d_h", "-", "g_h", ")", "/", "2.0", ")", ")", "+", "g_h", ",", "int", "(", "math", ".", "floor", "(", "(", "d_w", "-", "g_w", ")", "/", "2.0", ")", ")", ":", "int", "(", "math", ".", "floor", "(", "(", "d_w", "-", "g_w", ")", "/", "2.0", ")", ")", "+", "g_w", "]", "\n", "return", "d1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.hednet.vgg16": [[185, 225], ["hednet.VGG16features", "hednet.VGG", "torch.utils.model_zoo.load_url", "torch.utils.model_zoo.load_url", "torch.utils.model_zoo.load_url", "torch.utils.model_zoo.load_url", "set", "torch.utils.model_zoo.load_url.keys", "sorted", "set", "VGG.state_dict().keys", "sorted", "torch.utils.model_zoo.load_url.items", "VGG.load_state_dict", "list", "list", "VGG.state_dict", "int", "sorted.index", "set.add", "set.add", "key.split", "int", "key.split", "key.split", "key.split"], "function", ["None"], ["", "", "", "", "def", "vgg16", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"VGG 16-layer model (configuration \"D\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "VGG16fs", "=", "VGG16features", "(", ")", "\n", "model", "=", "VGG", "(", "VGG16fs", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "torch", ".", "utils", ".", "model_zoo", ".", "load_url", "(", "torchvision", ".", "models", ".", "vgg", ".", "model_urls", "[", "'vgg16'", "]", ",", "'pre-trained'", ")", "\n", "new_state_dict", "=", "{", "}", "\n", "\n", "original_layer_ids", "=", "set", "(", ")", "\n", "# copy the classifier entries and make a mapping for the feature mappings", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "'classifier'", "in", "key", ":", "\n", "                ", "new_state_dict", "[", "key", "]", "=", "state_dict", "[", "key", "]", "\n", "", "elif", "'features'", "in", "key", ":", "\n", "                ", "original_layer_ids", ".", "add", "(", "int", "(", "key", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", ")", "\n", "", "", "sorted_original_layer_ids", "=", "sorted", "(", "list", "(", "original_layer_ids", ")", ")", "\n", "\n", "layer_ids", "=", "set", "(", ")", "\n", "for", "key", "in", "model", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ":", "\n", "            ", "if", "'classifier'", "in", "key", ":", "\n", "                ", "continue", "\n", "", "elif", "'features'", "in", "key", ":", "\n", "                ", "layer_id", "=", "key", ".", "split", "(", "'.'", ")", "[", "1", "]", "\n", "layer_ids", ".", "add", "(", "layer_id", ")", "\n", "", "", "sorted_layer_ids", "=", "sorted", "(", "list", "(", "layer_ids", ")", ")", "\n", "\n", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "'features'", "in", "key", ":", "\n", "                ", "original_layer_id", "=", "int", "(", "key", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", "\n", "original_param_id", "=", "key", ".", "split", "(", "'.'", ")", "[", "2", "]", "\n", "idx", "=", "sorted_original_layer_ids", ".", "index", "(", "original_layer_id", ")", "\n", "new_layer_id", "=", "sorted_layer_ids", "[", "idx", "]", "\n", "new_key", "=", "'features.'", "+", "new_layer_id", "+", "'.'", "+", "original_param_id", "\n", "new_state_dict", "[", "new_key", "]", "=", "value", "\n", "\n", "", "", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "", "return", "model", ",", "VGG16fs", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.train.eval_model": [[39, 81], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax", "model"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ",", "softmax", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", "[", "0", "]", ",", "masks_soft", "[", "0", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.train.denormalize": [[82, 89], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "denormalize", "(", "inputs", ")", ":", "\n", "    ", "if", "net_name", "==", "'unet'", ":", "\n", "        ", "return", "(", "inputs", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "", "else", ":", "\n", "        ", "mean", "=", "torch", ".", "FloatTensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "(", "inputs", "*", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "+", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.train.generate_log_images": [[90, 106], ["train.denormalize", "masks_pred_softmax_t.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize"], ["", "", "def", "generate_log_images", "(", "inputs_t", ",", "true_masks_t", ",", "masks_pred_softmax_t", ")", ":", "\n", "    ", "true_masks", "=", "(", "true_masks_t", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "masks_pred_softmax", "=", "(", "masks_pred_softmax_t", ".", "detach", "(", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "inputs", "=", "denormalize", "(", "inputs_t", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "pad_size", "=", "5", "\n", "images_batch", "=", "(", "torch", ".", "ones", "(", "(", "bs", ",", "3", ",", "h", ",", "w", "*", "3", "+", "pad_size", "*", "2", ")", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", ":", "w", "]", "=", "inputs", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "true_masks", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "masks_pred_softmax", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "return", "images_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.train.image_to_patch": [[107, 112], ["image.reshape().permute().reshape", "image.reshape().permute", "image.reshape"], "function", ["None"], ["", "def", "image_to_patch", "(", "image", ",", "patch_size", ")", ":", "\n", "    ", "bs", ",", "channel", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "return", "(", "image", ".", "reshape", "(", "(", "bs", ",", "channel", ",", "h", "//", "patch_size", ",", "patch_size", ",", "w", "//", "patch_size", ",", "patch_size", ")", ")", "\n", ".", "permute", "(", "2", ",", "4", ",", "0", ",", "1", ",", "3", ",", "5", ")", "\n", ".", "reshape", "(", "(", "-", "1", ",", "channel", ",", "patch_size", ",", "patch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.train.train_model": [[114, 174], ["torch.Softmax", "model.to", "range", "lesion.lower", "print", "g_scheduler.step", "model.train", "inputs.to.to", "true_masks.to.to", "model.permute", "masks_pred.permute.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.reshape", "criterion", "g_optimizer.zero_grad", "g_loss.backward", "g_optimizer.step", "os.path.exists", "os.mkdir", "train.eval_model", "model", "true_masks_indices.reshape.long", "open", "f.write", "f.write", "f.write", "torch.save", "torch.save", "torch.save", "torch.save", "model.state_dict", "g_optimizer.state_dict", "os.path.join", "model", "str", "str"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model"], ["", "def", "train_model", "(", "model", ",", "lesion", ",", "preprocess", ",", "train_loader", ",", "eval_loader", ",", "criterion", ",", "g_optimizer", ",", "g_scheduler", ",", "\n", "batch_size", ",", "num_epochs", "=", "5", ",", "start_epoch", "=", "0", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "softmax", "=", "nn", ".", "Softmax", "(", "1", ")", "\n", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "tot_step_count", "=", "start_step", "\n", "\n", "best_ap", "=", "0.", "\n", "dir_checkpoint", "=", "'results/models_'", "+", "lesion", ".", "lower", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "start_epoch", "+", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'Starting epoch {}/{}.\\t\\n'", ".", "format", "(", "epoch", "+", "1", ",", "start_epoch", "+", "num_epochs", ")", ")", "\n", "g_scheduler", ".", "step", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "inputs", ",", "true_masks", "in", "train_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                ", "masks_pred", "=", "model", "(", "inputs", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                ", "masks_pred", "=", "model", "(", "inputs", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred_transpose", "=", "masks_pred", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "masks_pred_flat", "=", "masks_pred_transpose", ".", "reshape", "(", "-", "1", ",", "masks_pred_transpose", ".", "shape", "[", "-", "1", "]", ")", "\n", "true_masks_indices", "=", "torch", ".", "argmax", "(", "true_masks", ",", "1", ")", "\n", "true_masks_flat", "=", "true_masks_indices", ".", "reshape", "(", "-", "1", ")", "\n", "loss_ce", "=", "criterion", "(", "masks_pred_flat", ",", "true_masks_flat", ".", "long", "(", ")", ")", "\n", "\n", "ce_weight", "=", "1.", "\n", "g_loss", "=", "loss_ce", "*", "ce_weight", "\n", "\n", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "tot_step_count", "+=", "1", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_checkpoint", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_checkpoint", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "40", "==", "0", ":", "\n", "            ", "eval_ap", "=", "eval_model", "(", "model", ",", "eval_loader", ",", "softmax", ")", "\n", "with", "open", "(", "\"ap_during_learning_\"", "+", "lesion", "+", "preprocess", "+", "\".txt\"", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"epoch: \"", "+", "str", "(", "epoch", ")", ")", "\n", "f", ".", "write", "(", "\"ap: \"", "+", "str", "(", "eval_ap", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "if", "eval_ap", ">", "best_ap", ":", "\n", "                ", "best_ap", "=", "eval_ap", "\n", "\n", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "g_optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "dir_checkpoint", ",", "'model_'", "+", "preprocess", "+", "'.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.dataset.IDRIDDataset.__init__": [[16, 41], ["len", "len", "zip", "dataset.IDRIDDataset.image_paths.append", "dataset.IDRIDDataset.mask_paths.append", "dataset.IDRIDDataset.images.append", "dataset.IDRIDDataset.masks.append", "dataset.IDRIDDataset.pil_loader", "dataset.IDRIDDataset.pil_loader"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader"], ["    ", "def", "__init__", "(", "self", ",", "image_paths", ",", "mask_paths", "=", "None", ",", "class_id", "=", "0", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_paths: paths to the original images []\n            mask_paths: paths to the mask images, [[]]\n            class_id: id of lesions, 0:ex, 1:he, 2:ma, 3:se\n        \"\"\"", "\n", "assert", "len", "(", "image_paths", ")", "==", "len", "(", "mask_paths", ")", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "mask_paths", "=", "[", "]", "\n", "self", ".", "masks", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "if", "self", ".", "mask_paths", "is", "not", "None", ":", "\n", "            ", "for", "image_path", ",", "mask_path4", "in", "zip", "(", "image_paths", ",", "mask_paths", ")", ":", "\n", "                ", "mask_path", "=", "mask_path4", "[", "class_id", "]", "\n", "if", "mask_path", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "self", ".", "image_paths", ".", "append", "(", "image_path", ")", "\n", "self", ".", "mask_paths", ".", "append", "(", "mask_path", ")", "\n", "self", ".", "images", ".", "append", "(", "self", ".", "pil_loader", "(", "image_path", ")", ")", "\n", "self", ".", "masks", ".", "append", "(", "self", ".", "pil_loader", "(", "mask_path", ")", ")", "\n", "\n", "", "", "", "self", ".", "class_id", "=", "class_id", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.dataset.IDRIDDataset.__len__": [[42, 44], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.dataset.IDRIDDataset.pil_loader": [[45, 51], ["open", "PIL.Image.open", "PIL.Image.open.convert"], "methods", ["None"], ["", "def", "pil_loader", "(", "self", ",", "image_path", ")", ":", "\n", "        ", "with", "open", "(", "image_path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "h", ",", "w", "=", "img", ".", "size", "\n", "#return img.resize((h//2, w//2)).convert('RGB')", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.dataset.IDRIDDataset.__getitem__": [[52, 72], ["numpy.array", "dataset.IDRIDDataset.append", "dataset.IDRIDDataset.transform", "numpy.transpose", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "info", "=", "[", "self", ".", "images", "[", "idx", "]", "]", "\n", "if", "self", ".", "mask_paths", ":", "\n", "            ", "info", ".", "append", "(", "self", ".", "masks", "[", "idx", "]", ")", "\n", "", "if", "self", ".", "transform", ":", "\n", "            ", "info", "=", "self", ".", "transform", "(", "info", ")", "\n", "", "inputs", "=", "np", ".", "array", "(", "info", "[", "0", "]", ")", "\n", "if", "inputs", ".", "shape", "[", "2", "]", "==", "3", ":", "\n", "            ", "inputs", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "info", "[", "0", "]", ")", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "inputs", "=", "inputs", "/", "255.", "\n", "\n", "", "if", "len", "(", "info", ")", ">", "1", ":", "\n", "            ", "mask", "=", "np", ".", "array", "(", "np", ".", "array", "(", "info", "[", "1", "]", ")", ")", "[", ":", ",", ":", ",", "0", "]", "/", "255.0", "\n", "empty_mask", "=", "1", "-", "mask", "\n", "masks", "=", "np", ".", "array", "(", "[", "empty_mask", ",", "mask", "]", ")", "\n", "\n", "return", "inputs", ",", "masks", "\n", "", "else", ":", "\n", "            ", "return", "inputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.preprocess.clahe_gridsize": [[15, 50], ["cv2.imread", "cv2.cvtColor", "cv2.imread", "numpy.uint8", "cv2.cvtColor", "cv2.split", "cv2.createCLAHE", "cv2.createCLAHE.apply", "cv2.merge", "cv2.cvtColor", "cv2.fastNlMeansDenoisingColored", "cv2.bilateralFilter", "cv2.cvtColor.sum", "numpy.minimum", "cv2.imread.sum"], "function", ["None"], ["def", "clahe_gridsize", "(", "image_path", ",", "mask_path", ",", "denoise", "=", "False", ",", "contrastenhancement", "=", "False", ",", "brightnessbalance", "=", "None", ",", "cliplimit", "=", "None", ",", "gridsize", "=", "8", ")", ":", "\n", "    ", "\"\"\"This function applies CLAHE to normal RGB images and outputs them.\n    The image is first converted to LAB format and then CLAHE is applied only to the L channel.\n    Inputs:\n      image_path: Absolute path to the image file.\n      mask_path: Absolute path to the mask file.\n      denoise: Toggle to denoise the image or not. Denoising is done after applying CLAHE.\n      cliplimit: The pixel (high contrast) limit applied to CLAHE processing. Read more here: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.html\n      gridsize: Grid/block size the image is divided into for histogram equalization.\n    Returns:\n      bgr: The CLAHE applied image.\n    \"\"\"", "\n", "bgr", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "\n", "# brightness balance.", "\n", "if", "brightnessbalance", ":", "\n", "        ", "gray", "=", "cv2", ".", "cvtColor", "(", "bgr", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "mask_img", "=", "cv2", ".", "imread", "(", "mask_path", ",", "0", ")", "\n", "brightness", "=", "gray", ".", "sum", "(", ")", "/", "(", "mask_img", ".", "shape", "[", "0", "]", "*", "mask_img", ".", "shape", "[", "1", "]", "-", "mask_img", ".", "sum", "(", ")", "/", "255.", ")", "\n", "bgr", "=", "np", ".", "uint8", "(", "np", ".", "minimum", "(", "bgr", "*", "brightnessbalance", "/", "brightness", ",", "255", ")", ")", "\n", "\n", "", "if", "contrastenhancement", ":", "\n", "# illumination correction and contrast enhancement.", "\n", "      ", "lab", "=", "cv2", ".", "cvtColor", "(", "bgr", ",", "cv2", ".", "COLOR_BGR2LAB", ")", "\n", "lab_planes", "=", "cv2", ".", "split", "(", "lab", ")", "\n", "clahe", "=", "cv2", ".", "createCLAHE", "(", "clipLimit", "=", "cliplimit", ",", "tileGridSize", "=", "(", "gridsize", ",", "gridsize", ")", ")", "\n", "lab_planes", "[", "0", "]", "=", "clahe", ".", "apply", "(", "lab_planes", "[", "0", "]", ")", "\n", "lab", "=", "cv2", ".", "merge", "(", "lab_planes", ")", "\n", "bgr", "=", "cv2", ".", "cvtColor", "(", "lab", ",", "cv2", ".", "COLOR_LAB2BGR", ")", "\n", "\n", "", "if", "denoise", ":", "\n", "        ", "bgr", "=", "cv2", ".", "fastNlMeansDenoisingColored", "(", "bgr", ",", "None", ",", "10", ",", "10", ",", "1", ",", "3", ")", "\n", "bgr", "=", "cv2", ".", "bilateralFilter", "(", "bgr", ",", "5", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "bgr", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.utils.initialize_weights": [[15, 26], ["net.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["def", "initialize_weights", "(", "net", ")", ":", "\n", "    ", "for", "m", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet.utils.get_images": [[30, 95], ["glob.glob", "glob.glob.sort", "int", "int", "os.path.join", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "glob.glob", "os.path.join", "zip", "mask_paths.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "glob.glob", "glob.glob.sort", "len", "os.path.join", "os.path.join", "preprocess.clahe_gridsize", "cv2.imwrite", "len", "len", "[].split", "os.path.join", "os.path.exists", "os.path.join", "os.path.join", "cv2.imread", "cv2.imread", "[].split", "os.path.join", "paths.append", "paths.append", "[].split", "cv2.imread.sum", "os.path.split", "os.path.split", "cv2.imread.sum", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.preprocess.clahe_gridsize"], ["def", "get_images", "(", "image_dir", ",", "preprocess", "=", "'0'", ",", "phase", "=", "'train'", ")", ":", "\n", "    ", "if", "phase", "==", "'train'", "or", "phase", "==", "'eval'", ":", "\n", "        ", "setname", "=", "'TrainingSet'", "\n", "", "elif", "phase", "==", "'test'", ":", "\n", "        ", "setname", "=", "'TestingSet'", "\n", "\n", "", "limit", "=", "2", "\n", "grid_size", "=", "8", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ")", ")", "\n", "\n", "# compute mean brightess", "\n", "meanbright", "=", "0.", "\n", "images_number", "=", "0", "\n", "for", "tempsetname", "in", "[", "'TrainingSet'", ",", "'TestingSet'", "]", ":", "\n", "            ", "imgs_ori", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'OriginalImages/'", "+", "tempsetname", "+", "'/*.jpg'", ")", ")", "\n", "imgs_ori", ".", "sort", "(", ")", "\n", "images_number", "+=", "len", "(", "imgs_ori", ")", "\n", "# mean brightness.", "\n", "for", "img_path", "in", "imgs_ori", ":", "\n", "                ", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "tempsetname", ",", "'Mask'", ",", "img_name", "+", "'_MASK.tif'", ")", "\n", "gray", "=", "cv2", ".", "imread", "(", "img_path", ",", "0", ")", "\n", "mask_img", "=", "cv2", ".", "imread", "(", "mask_path", ",", "0", ")", "\n", "brightness", "=", "gray", ".", "sum", "(", ")", "/", "(", "mask_img", ".", "shape", "[", "0", "]", "*", "mask_img", ".", "shape", "[", "1", "]", "-", "mask_img", ".", "sum", "(", ")", "/", "255.", ")", "\n", "meanbright", "+=", "brightness", "\n", "", "", "meanbright", "/=", "images_number", "\n", "\n", "imgs_ori", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'OriginalImages/'", "+", "setname", "+", "'/*.jpg'", ")", ")", "\n", "\n", "preprocess_dict", "=", "{", "'0'", ":", "[", "False", ",", "False", ",", "None", "]", ",", "'1'", ":", "[", "False", ",", "False", ",", "meanbright", "]", ",", "'2'", ":", "[", "False", ",", "True", ",", "None", "]", ",", "'3'", ":", "[", "False", ",", "True", ",", "meanbright", "]", ",", "'4'", ":", "[", "True", ",", "False", ",", "None", "]", ",", "'5'", ":", "[", "True", ",", "False", ",", "meanbright", "]", ",", "'6'", ":", "[", "True", ",", "True", ",", "None", "]", ",", "'7'", ":", "[", "True", ",", "True", ",", "meanbright", "]", "}", "\n", "for", "img_path", "in", "imgs_ori", ":", "\n", "            ", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "setname", ",", "'Mask'", ",", "img_name", "+", "'_MASK.tif'", ")", "\n", "clahe_img", "=", "clahe_gridsize", "(", "img_path", ",", "mask_path", ",", "denoise", "=", "preprocess_dict", "[", "preprocess", "]", "[", "0", "]", ",", "contrastenhancement", "=", "preprocess_dict", "[", "preprocess", "]", "[", "1", "]", ",", "brightnessbalance", "=", "preprocess_dict", "[", "preprocess", "]", "[", "2", "]", ",", "cliplimit", "=", "limit", ",", "gridsize", "=", "grid_size", ")", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ",", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ")", ",", "clahe_img", ")", "\n", "\n", "", "", "imgs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ",", "'*.jpg'", ")", ")", "\n", "\n", "imgs", ".", "sort", "(", ")", "\n", "mask_paths", "=", "[", "]", "\n", "train_number", "=", "int", "(", "len", "(", "imgs", ")", "*", "train_ratio", ")", "\n", "eval_number", "=", "int", "(", "len", "(", "imgs", ")", "*", "eval_ratio", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "        ", "image_paths", "=", "imgs", "[", ":", "train_number", "]", "\n", "", "elif", "phase", "==", "'eval'", ":", "\n", "        ", "image_paths", "=", "imgs", "[", "train_number", ":", "]", "\n", "", "else", ":", "\n", "        ", "image_paths", "=", "imgs", "\n", "", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "setname", ")", "\n", "lesions", "=", "[", "'HardExudates'", ",", "'Haemorrhages'", ",", "'Microaneurysms'", ",", "'SoftExudates'", ",", "'Mask'", "]", "\n", "lesion_abbvs", "=", "[", "'EX'", ",", "'HE'", ",", "'MA'", ",", "'SE'", ",", "'MASK'", "]", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "        ", "paths", "=", "[", "]", "\n", "name", "=", "os", ".", "path", ".", "split", "(", "image_path", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "for", "lesion", ",", "lesion_abbv", "in", "zip", "(", "lesions", ",", "lesion_abbvs", ")", ":", "\n", "            ", "candidate_path", "=", "os", ".", "path", ".", "join", "(", "mask_path", ",", "lesion", ",", "name", "+", "'_'", "+", "lesion_abbv", "+", "'.tif'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "candidate_path", ")", ":", "\n", "                ", "paths", ".", "append", "(", "candidate_path", ")", "\n", "", "else", ":", "\n", "                ", "paths", ".", "append", "(", "None", ")", "\n", "", "", "mask_paths", ".", "append", "(", "paths", ")", "\n", "", "return", "image_paths", ",", "mask_paths", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image": [[24, 29], ["isinstance", "isinstance"], "function", ["None"], ["def", "_is_pil_image", "(", "img", ")", ":", "\n", "    ", "if", "accimage", "is", "not", "None", ":", "\n", "        ", "return", "isinstance", "(", "img", ",", "(", "Image", ".", "Image", ",", "accimage", ".", "Image", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "isinstance", "(", "img", ",", "Image", ".", "Image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_tensor_image": [[31, 33], ["torch.is_tensor", "img.ndimension"], "function", ["None"], ["", "", "def", "_is_tensor_image", "(", "img", ")", ":", "\n", "    ", "return", "torch", ".", "is_tensor", "(", "img", ")", "and", "img", ".", "ndimension", "(", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_numpy_image": [[35, 37], ["isinstance"], "function", ["None"], ["", "def", "_is_numpy_image", "(", "img", ")", ":", "\n", "    ", "return", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", "and", "(", "img", ".", "ndim", "in", "{", "2", ",", "3", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_tensor": [[39, 93], ["isinstance", "torch.ByteTensor.view", "torch.ByteTensor.transpose().transpose().contiguous", "isinstance", "TypeError", "torch.from_numpy", "isinstance", "isinstance", "numpy.zeros", "pic.copyto", "torch.from_numpy", "torch.from_numpy", "torch.ByteTensor.float().div", "functional._is_pil_image", "functional._is_numpy_image", "pic.transpose", "torch.ByteTensor.float().div", "numpy.array", "torch.from_numpy", "len", "torch.ByteTensor.transpose().transpose", "type", "numpy.array", "torch.from_numpy", "torch.ByteTensor.float", "torch.ByteTensor.float", "numpy.array", "torch.ByteTensor", "torch.ByteTensor.transpose", "torch.from_numpy", "torch.ByteStorage.from_buffer", "numpy.array", "pic.tobytes"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_numpy_image"], ["", "def", "to_tensor", "(", "pic", ")", ":", "\n", "    ", "\"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n\n    See ``ToTensor`` for more details.\n\n    Args:\n        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n\n    Returns:\n        Tensor: Converted image.\n    \"\"\"", "\n", "if", "not", "(", "_is_pil_image", "(", "pic", ")", "or", "_is_numpy_image", "(", "pic", ")", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'pic should be PIL Image or ndarray. Got {}'", ".", "format", "(", "type", "(", "pic", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "pic", ",", "np", ".", "ndarray", ")", ":", "\n", "# handle numpy array", "\n", "        ", "img", "=", "torch", ".", "from_numpy", "(", "pic", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "# backward compatibility", "\n", "if", "isinstance", "(", "img", ",", "torch", ".", "ByteTensor", ")", ":", "\n", "            ", "return", "img", ".", "float", "(", ")", ".", "div", "(", "255", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n", "", "", "if", "accimage", "is", "not", "None", "and", "isinstance", "(", "pic", ",", "accimage", ".", "Image", ")", ":", "\n", "        ", "nppic", "=", "np", ".", "zeros", "(", "[", "pic", ".", "channels", ",", "pic", ".", "height", ",", "pic", ".", "width", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "pic", ".", "copyto", "(", "nppic", ")", "\n", "return", "torch", ".", "from_numpy", "(", "nppic", ")", "\n", "\n", "# handle PIL Image", "\n", "", "if", "pic", ".", "mode", "==", "'I'", ":", "\n", "        ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pic", ",", "np", ".", "int32", ",", "copy", "=", "False", ")", ")", "\n", "", "elif", "pic", ".", "mode", "==", "'I;16'", ":", "\n", "        ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pic", ",", "np", ".", "int16", ",", "copy", "=", "False", ")", ")", "\n", "", "elif", "pic", ".", "mode", "==", "'F'", ":", "\n", "        ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pic", ",", "np", ".", "float32", ",", "copy", "=", "False", ")", ")", "\n", "", "elif", "pic", ".", "mode", "==", "'1'", ":", "\n", "        ", "img", "=", "255", "*", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pic", ",", "np", ".", "uint8", ",", "copy", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "        ", "img", "=", "torch", ".", "ByteTensor", "(", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "pic", ".", "tobytes", "(", ")", ")", ")", "\n", "# PIL image mode: L, P, I, F, RGB, YCbCr, RGBA, CMYK", "\n", "", "if", "pic", ".", "mode", "==", "'YCbCr'", ":", "\n", "        ", "nchannel", "=", "3", "\n", "", "elif", "pic", ".", "mode", "==", "'I;16'", ":", "\n", "        ", "nchannel", "=", "1", "\n", "", "else", ":", "\n", "        ", "nchannel", "=", "len", "(", "pic", ".", "mode", ")", "\n", "", "img", "=", "img", ".", "view", "(", "pic", ".", "size", "[", "1", "]", ",", "pic", ".", "size", "[", "0", "]", ",", "nchannel", ")", "\n", "# put it from HWC to CHW format", "\n", "# yikes, this transpose takes 80% of the loading time/CPU", "\n", "img", "=", "img", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "if", "isinstance", "(", "img", ",", "torch", ".", "ByteTensor", ")", ":", "\n", "        ", "return", "img", ".", "float", "(", ")", ".", "div", "(", "255", ")", "\n", "", "else", ":", "\n", "        ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_pil_image": [[95, 156], ["isinstance", "torch.is_tensor", "PIL.Image.fromarray", "TypeError", "pic.mul().byte.mul().byte", "numpy.transpose", "isinstance", "TypeError", "TypeError", "functional._is_numpy_image", "functional._is_tensor_image", "pic.mul().byte.numpy", "ValueError", "type", "pic.mul().byte.mul", "ValueError", "ValueError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_numpy_image", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_tensor_image"], ["", "", "def", "to_pil_image", "(", "pic", ",", "mode", "=", "None", ")", ":", "\n", "    ", "\"\"\"Convert a tensor or an ndarray to PIL Image.\n\n    See :class:`~torchvision.transforms.ToPILImage` for more details.\n\n    Args:\n        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\n        mode (`PIL.Image mode`_): color space and pixel depth of input data (optional).\n\n    .. _PIL.Image mode: https://pillow.readthedocs.io/en/latest/handbook/concepts.html#concept-modes\n\n    Returns:\n        PIL Image: Image converted to PIL Image.\n    \"\"\"", "\n", "if", "not", "(", "_is_numpy_image", "(", "pic", ")", "or", "_is_tensor_image", "(", "pic", ")", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'pic should be Tensor or ndarray. Got {}.'", ".", "format", "(", "type", "(", "pic", ")", ")", ")", "\n", "\n", "", "npimg", "=", "pic", "\n", "if", "isinstance", "(", "pic", ",", "torch", ".", "FloatTensor", ")", ":", "\n", "        ", "pic", "=", "pic", ".", "mul", "(", "255", ")", ".", "byte", "(", ")", "\n", "", "if", "torch", ".", "is_tensor", "(", "pic", ")", ":", "\n", "        ", "npimg", "=", "np", ".", "transpose", "(", "pic", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "npimg", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Input pic must be a torch.Tensor or NumPy ndarray, '", "+", "\n", "'not {}'", ".", "format", "(", "type", "(", "npimg", ")", ")", ")", "\n", "\n", "", "if", "npimg", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "expected_mode", "=", "None", "\n", "npimg", "=", "npimg", "[", ":", ",", ":", ",", "0", "]", "\n", "if", "npimg", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "            ", "expected_mode", "=", "'L'", "\n", "", "elif", "npimg", ".", "dtype", "==", "np", ".", "int16", ":", "\n", "            ", "expected_mode", "=", "'I;16'", "\n", "", "elif", "npimg", ".", "dtype", "==", "np", ".", "int32", ":", "\n", "            ", "expected_mode", "=", "'I'", "\n", "", "elif", "npimg", ".", "dtype", "==", "np", ".", "float32", ":", "\n", "            ", "expected_mode", "=", "'F'", "\n", "", "if", "mode", "is", "not", "None", "and", "mode", "!=", "expected_mode", ":", "\n", "            ", "raise", "ValueError", "(", "\"Incorrect mode ({}) supplied for input type {}. Should be {}\"", "\n", ".", "format", "(", "mode", ",", "np", ".", "dtype", ",", "expected_mode", ")", ")", "\n", "", "mode", "=", "expected_mode", "\n", "\n", "", "elif", "npimg", ".", "shape", "[", "2", "]", "==", "4", ":", "\n", "        ", "permitted_4_channel_modes", "=", "[", "'RGBA'", ",", "'CMYK'", "]", "\n", "if", "mode", "is", "not", "None", "and", "mode", "not", "in", "permitted_4_channel_modes", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only modes {} are supported for 4D inputs\"", ".", "format", "(", "permitted_4_channel_modes", ")", ")", "\n", "\n", "", "if", "mode", "is", "None", "and", "npimg", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "            ", "mode", "=", "'RGBA'", "\n", "", "", "else", ":", "\n", "        ", "permitted_3_channel_modes", "=", "[", "'RGB'", ",", "'YCbCr'", ",", "'HSV'", "]", "\n", "if", "mode", "is", "not", "None", "and", "mode", "not", "in", "permitted_3_channel_modes", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only modes {} are supported for 3D inputs\"", ".", "format", "(", "permitted_3_channel_modes", ")", ")", "\n", "", "if", "mode", "is", "None", "and", "npimg", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "            ", "mode", "=", "'RGB'", "\n", "\n", "", "", "if", "mode", "is", "None", ":", "\n", "        ", "raise", "TypeError", "(", "'Input type {} is not supported'", ".", "format", "(", "npimg", ".", "dtype", ")", ")", "\n", "\n", "", "return", "Image", ".", "fromarray", "(", "npimg", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.normalize": [[158, 181], ["zip", "functional._is_tensor_image", "TypeError", "t.sub_().div_", "t.sub_"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_tensor_image"], ["", "def", "normalize", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "    ", "\"\"\"Normalize a tensor image with mean and standard deviation.\n\n    .. note::\n        This transform acts in-place, i.e., it mutates the input tensor.\n\n    See :class:`~torchvision.transforms.Normalize` for more details.\n\n    Args:\n        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        mean (sequence): Sequence of means for each channel.\n        std (sequence): Sequence of standard deviations for each channely.\n\n    Returns:\n        Tensor: Normalized Tensor image.\n    \"\"\"", "\n", "if", "not", "_is_tensor_image", "(", "tensor", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'tensor is not a torch image.'", ")", "\n", "\n", "# This is faster than using broadcasting, don't change without benchmarking", "\n", "", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "        ", "t", ".", "sub_", "(", "m", ")", ".", "div_", "(", "s", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize": [[183, 218], ["isinstance", "functional._is_pil_image", "TypeError", "TypeError", "img.resize", "isinstance", "int", "img.resize", "int", "img.resize", "type", "isinstance", "len"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize"], ["", "def", "resize", "(", "img", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "    ", "r\"\"\"Resize the input PIL Image to the given size.\n\n    Args:\n        img (PIL Image): Image to be resized.\n        size (sequence or int): Desired output size. If size is a sequence like\n            (h, w), the output size will be matched to this. If size is an int,\n            the smaller edge of the image will be matched to this number maintaing\n            the aspect ratio. i.e, if height > width, then image will be rescaled to\n            :math:`\\left(\\text{size} \\times \\frac{\\text{height}}{\\text{width}}, \\text{size}\\right)`\n        interpolation (int, optional): Desired interpolation. Default is\n            ``PIL.Image.BILINEAR``\n\n    Returns:\n        PIL Image: Resized image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "", "if", "not", "(", "isinstance", "(", "size", ",", "int", ")", "or", "(", "isinstance", "(", "size", ",", "collections", ".", "Iterable", ")", "and", "len", "(", "size", ")", "==", "2", ")", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Got inappropriate size arg: {}'", ".", "format", "(", "size", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "        ", "w", ",", "h", "=", "img", ".", "size", "\n", "if", "(", "w", "<=", "h", "and", "w", "==", "size", ")", "or", "(", "h", "<=", "w", "and", "h", "==", "size", ")", ":", "\n", "            ", "return", "img", "\n", "", "if", "w", "<", "h", ":", "\n", "            ", "ow", "=", "size", "\n", "oh", "=", "int", "(", "size", "*", "h", "/", "w", ")", "\n", "return", "img", ".", "resize", "(", "(", "ow", ",", "oh", ")", ",", "interpolation", ")", "\n", "", "else", ":", "\n", "            ", "oh", "=", "size", "\n", "ow", "=", "int", "(", "size", "*", "w", "/", "h", ")", "\n", "return", "img", ".", "resize", "(", "(", "ow", ",", "oh", ")", ",", "interpolation", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "img", ".", "resize", "(", "size", "[", ":", ":", "-", "1", "]", ",", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.scale": [[220, 224], ["warnings.warn", "functional.resize"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize"], ["", "", "def", "scale", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "warnings", ".", "warn", "(", "\"The use of the transforms.Scale transform is deprecated, \"", "+", "\n", "\"please use transforms.Resize instead.\"", ")", "\n", "return", "resize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad": [[226, 298], ["functional._is_pil_image", "TypeError", "isinstance", "TypeError", "isinstance", "TypeError", "isinstance", "TypeError", "isinstance", "ValueError", "PIL.ImageOps.expand", "isinstance", "numpy.asarray", "PIL.Image.fromarray", "len", "isinstance", "isinstance", "len", "numpy.pad", "len", "numpy.pad", "type", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad"], ["", "def", "pad", "(", "img", ",", "padding", ",", "fill", "=", "0", ",", "padding_mode", "=", "'constant'", ")", ":", "\n", "    ", "r\"\"\"Pad the given PIL Image on all sides with specified padding mode and fill value.\n\n    Args:\n        img (PIL Image): Image to be padded.\n        padding (int or tuple): Padding on each border. If a single int is provided this\n            is used to pad all borders. If tuple of length 2 is provided this is the padding\n            on left/right and top/bottom respectively. If a tuple of length 4 is provided\n            this is the padding for the left, top, right and bottom borders\n            respectively.\n        fill: Pixel fill value for constant fill. Default is 0. If a tuple of\n            length 3, it is used to fill R, G, B channels respectively.\n            This value is only used when the padding_mode is constant\n        padding_mode: Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant.\n\n            - constant: pads with a constant value, this value is specified with fill\n\n            - edge: pads with the last value on the edge of the image\n\n            - reflect: pads with reflection of image (without repeating the last value on the edge)\n\n                       padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode\n                       will result in [3, 2, 1, 2, 3, 4, 3, 2]\n\n            - symmetric: pads with reflection of image (repeating the last value on the edge)\n\n                         padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode\n                         will result in [2, 1, 1, 2, 3, 4, 4, 3]\n\n    Returns:\n        PIL Image: Padded image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "padding", ",", "(", "numbers", ".", "Number", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Got inappropriate padding arg'", ")", "\n", "", "if", "not", "isinstance", "(", "fill", ",", "(", "numbers", ".", "Number", ",", "str", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Got inappropriate fill arg'", ")", "\n", "", "if", "not", "isinstance", "(", "padding_mode", ",", "str", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Got inappropriate padding_mode arg'", ")", "\n", "\n", "", "if", "isinstance", "(", "padding", ",", "collections", ".", "Sequence", ")", "and", "len", "(", "padding", ")", "not", "in", "[", "2", ",", "4", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"Padding must be an int or a 2, or 4 element tuple, not a \"", "+", "\n", "\"{} element tuple\"", ".", "format", "(", "len", "(", "padding", ")", ")", ")", "\n", "\n", "", "assert", "padding_mode", "in", "[", "'constant'", ",", "'edge'", ",", "'reflect'", ",", "'symmetric'", "]", ",", "'Padding mode should be either constant, edge, reflect or symmetric'", "\n", "\n", "if", "padding_mode", "==", "'constant'", ":", "\n", "        ", "return", "ImageOps", ".", "expand", "(", "img", ",", "border", "=", "padding", ",", "fill", "=", "fill", ")", "\n", "", "else", ":", "\n", "        ", "if", "isinstance", "(", "padding", ",", "int", ")", ":", "\n", "            ", "pad_left", "=", "pad_right", "=", "pad_top", "=", "pad_bottom", "=", "padding", "\n", "", "if", "isinstance", "(", "padding", ",", "collections", ".", "Sequence", ")", "and", "len", "(", "padding", ")", "==", "2", ":", "\n", "            ", "pad_left", "=", "pad_right", "=", "padding", "[", "0", "]", "\n", "pad_top", "=", "pad_bottom", "=", "padding", "[", "1", "]", "\n", "", "if", "isinstance", "(", "padding", ",", "collections", ".", "Sequence", ")", "and", "len", "(", "padding", ")", "==", "4", ":", "\n", "            ", "pad_left", "=", "padding", "[", "0", "]", "\n", "pad_top", "=", "padding", "[", "1", "]", "\n", "pad_right", "=", "padding", "[", "2", "]", "\n", "pad_bottom", "=", "padding", "[", "3", "]", "\n", "\n", "", "img", "=", "np", ".", "asarray", "(", "img", ")", "\n", "# RGB image", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "            ", "img", "=", "np", ".", "pad", "(", "img", ",", "(", "(", "pad_top", ",", "pad_bottom", ")", ",", "(", "pad_left", ",", "pad_right", ")", ",", "(", "0", ",", "0", ")", ")", ",", "padding_mode", ")", "\n", "# Grayscale image", "\n", "", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "            ", "img", "=", "np", ".", "pad", "(", "img", ",", "(", "(", "pad_top", ",", "pad_bottom", ")", ",", "(", "pad_left", ",", "pad_right", ")", ")", ",", "padding_mode", ")", "\n", "\n", "", "return", "Image", ".", "fromarray", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.crop": [[300, 317], ["img.crop", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "", "def", "crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ")", ":", "\n", "    ", "\"\"\"Crop the given PIL Image.\n\n    Args:\n        img (PIL Image): Image to be cropped.\n        i: Upper pixel coordinate.\n        j: Left pixel coordinate.\n        h: Height of the cropped image.\n        w: Width of the cropped image.\n\n    Returns:\n        PIL Image: Cropped image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "return", "img", ".", "crop", "(", "(", "j", ",", "i", ",", "j", "+", "w", ",", "i", "+", "h", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.center_crop": [[319, 327], ["isinstance", "int", "int", "functional.crop", "round", "round", "int", "int"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop"], ["", "def", "center_crop", "(", "img", ",", "output_size", ")", ":", "\n", "    ", "if", "isinstance", "(", "output_size", ",", "numbers", ".", "Number", ")", ":", "\n", "        ", "output_size", "=", "(", "int", "(", "output_size", ")", ",", "int", "(", "output_size", ")", ")", "\n", "", "w", ",", "h", "=", "img", ".", "size", "\n", "th", ",", "tw", "=", "output_size", "\n", "i", "=", "int", "(", "round", "(", "(", "h", "-", "th", ")", "/", "2.", ")", ")", "\n", "j", "=", "int", "(", "round", "(", "(", "w", "-", "tw", ")", "/", "2.", ")", ")", "\n", "return", "crop", "(", "img", ",", "i", ",", "j", ",", "th", ",", "tw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resized_crop": [[329, 350], ["functional._is_pil_image", "functional.crop", "functional.resize"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize"], ["", "def", "resized_crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "    ", "\"\"\"Crop the given PIL Image and resize it to desired size.\n\n    Notably used in :class:`~torchvision.transforms.RandomResizedCrop`.\n\n    Args:\n        img (PIL Image): Image to be cropped.\n        i: Upper pixel coordinate.\n        j: Left pixel coordinate.\n        h: Height of the cropped image.\n        w: Width of the cropped image.\n        size (sequence or int): Desired output size. Same semantics as ``scale``.\n        interpolation (int, optional): Desired interpolation. Default is\n            ``PIL.Image.BILINEAR``.\n    Returns:\n        PIL Image: Cropped image.\n    \"\"\"", "\n", "assert", "_is_pil_image", "(", "img", ")", ",", "'img should be PIL Image'", "\n", "img", "=", "crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ")", "\n", "img", "=", "resize", "(", "img", ",", "size", ",", "interpolation", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.hflip": [[352, 365], ["img.transpose", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "hflip", "(", "img", ")", ":", "\n", "    ", "\"\"\"Horizontally flip the given PIL Image.\n\n    Args:\n        img (PIL Image): Image to be flipped.\n\n    Returns:\n        PIL Image:  Horizontall flipped image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.vflip": [[367, 380], ["img.transpose", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "vflip", "(", "img", ")", ":", "\n", "    ", "\"\"\"Vertically flip the given PIL Image.\n\n    Args:\n        img (PIL Image): Image to be flipped.\n\n    Returns:\n        PIL Image:  Vertically flipped image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.five_crop": [[382, 414], ["isinstance", "img.crop", "img.crop", "img.crop", "img.crop", "functional.center_crop", "ValueError", "int", "int", "len"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.center_crop"], ["", "def", "five_crop", "(", "img", ",", "size", ")", ":", "\n", "    ", "\"\"\"Crop the given PIL Image into four corners and the central crop.\n\n    .. Note::\n        This transform returns a tuple of images and there may be a\n        mismatch in the number of inputs and targets your ``Dataset`` returns.\n\n    Args:\n       size (sequence or int): Desired output size of the crop. If size is an\n           int instead of sequence like (h, w), a square crop (size, size) is\n           made.\n\n    Returns:\n       tuple: tuple (tl, tr, bl, br, center)\n                Corresponding top left, top right, bottom left, bottom right and center crop.\n    \"\"\"", "\n", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "        ", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "size", ")", "==", "2", ",", "\"Please provide only two dimensions (h, w) for size.\"", "\n", "\n", "", "w", ",", "h", "=", "img", ".", "size", "\n", "crop_h", ",", "crop_w", "=", "size", "\n", "if", "crop_w", ">", "w", "or", "crop_h", ">", "h", ":", "\n", "        ", "raise", "ValueError", "(", "\"Requested crop size {} is bigger than input size {}\"", ".", "format", "(", "size", ",", "\n", "(", "h", ",", "w", ")", ")", ")", "\n", "", "tl", "=", "img", ".", "crop", "(", "(", "0", ",", "0", ",", "crop_w", ",", "crop_h", ")", ")", "\n", "tr", "=", "img", ".", "crop", "(", "(", "w", "-", "crop_w", ",", "0", ",", "w", ",", "crop_h", ")", ")", "\n", "bl", "=", "img", ".", "crop", "(", "(", "0", ",", "h", "-", "crop_h", ",", "crop_w", ",", "h", ")", ")", "\n", "br", "=", "img", ".", "crop", "(", "(", "w", "-", "crop_w", ",", "h", "-", "crop_h", ",", "w", ",", "h", ")", ")", "\n", "center", "=", "center_crop", "(", "img", ",", "(", "crop_h", ",", "crop_w", ")", ")", "\n", "return", "(", "tl", ",", "tr", ",", "bl", ",", "br", ",", "center", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.ten_crop": [[416, 449], ["isinstance", "functional.five_crop", "functional.five_crop", "functional.vflip", "functional.hflip", "int", "int", "len"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.five_crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.five_crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.vflip", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.hflip"], ["", "def", "ten_crop", "(", "img", ",", "size", ",", "vertical_flip", "=", "False", ")", ":", "\n", "    ", "r\"\"\"Crop the given PIL Image into four corners and the central crop plus the\n        flipped version of these (horizontal flipping is used by default).\n\n    .. Note::\n        This transform returns a tuple of images and there may be a\n        mismatch in the number of inputs and targets your ``Dataset`` returns.\n\n    Args:\n       size (sequence or int): Desired output size of the crop. If size is an\n            int instead of sequence like (h, w), a square crop (size, size) is\n            made.\n       vertical_flip (bool): Use vertical flipping instead of horizontal\n\n    Returns:\n       tuple: tuple (tl, tr, bl, br, center, tl_flip, tr_flip, bl_flip, br_flip, center_flip)\n                Corresponding top left, top right, bottom left, bottom right and center crop\n                and same for the flipped image.\n    \"\"\"", "\n", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "        ", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "size", ")", "==", "2", ",", "\"Please provide only two dimensions (h, w) for size.\"", "\n", "\n", "", "first_five", "=", "five_crop", "(", "img", ",", "size", ")", "\n", "\n", "if", "vertical_flip", ":", "\n", "        ", "img", "=", "vflip", "(", "img", ")", "\n", "", "else", ":", "\n", "        ", "img", "=", "hflip", "(", "img", ")", "\n", "\n", "", "second_five", "=", "five_crop", "(", "img", ",", "size", ")", "\n", "return", "first_five", "+", "second_five", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_brightness": [[451, 469], ["PIL.ImageEnhance.Brightness", "ImageEnhance.Brightness.enhance", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "adjust_brightness", "(", "img", ",", "brightness_factor", ")", ":", "\n", "    ", "\"\"\"Adjust brightness of an Image.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        brightness_factor (float):  How much to adjust the brightness. Can be\n            any non negative number. 0 gives a black image, 1 gives the\n            original image while 2 increases the brightness by a factor of 2.\n\n    Returns:\n        PIL Image: Brightness adjusted image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "enhancer", "=", "ImageEnhance", ".", "Brightness", "(", "img", ")", "\n", "img", "=", "enhancer", ".", "enhance", "(", "brightness_factor", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_contrast": [[471, 489], ["PIL.ImageEnhance.Contrast", "ImageEnhance.Contrast.enhance", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "adjust_contrast", "(", "img", ",", "contrast_factor", ")", ":", "\n", "    ", "\"\"\"Adjust contrast of an Image.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        contrast_factor (float): How much to adjust the contrast. Can be any\n            non negative number. 0 gives a solid gray image, 1 gives the\n            original image while 2 increases the contrast by a factor of 2.\n\n    Returns:\n        PIL Image: Contrast adjusted image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "enhancer", "=", "ImageEnhance", ".", "Contrast", "(", "img", ")", "\n", "img", "=", "enhancer", ".", "enhance", "(", "contrast_factor", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_saturation": [[491, 509], ["PIL.ImageEnhance.Color", "ImageEnhance.Color.enhance", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "adjust_saturation", "(", "img", ",", "saturation_factor", ")", ":", "\n", "    ", "\"\"\"Adjust color saturation of an image.\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        saturation_factor (float):  How much to adjust the saturation. 0 will\n            give a black and white image, 1 will give the original image while\n            2 will enhance the saturation by a factor of 2.\n\n    Returns:\n        PIL Image: Saturation adjusted image.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "enhancer", "=", "ImageEnhance", ".", "Color", "(", "img", ")", "\n", "img", "=", "enhancer", ".", "enhance", "(", "saturation_factor", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_hue": [[511, 556], ["Image.merge().convert.convert().split", "numpy.array", "PIL.Image.fromarray", "PIL.Image.merge().convert", "ValueError", "functional._is_pil_image", "TypeError", "numpy.errstate", "numpy.uint8", "Image.merge().convert.convert", "PIL.Image.merge", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "adjust_hue", "(", "img", ",", "hue_factor", ")", ":", "\n", "    ", "\"\"\"Adjust hue of an image.\n\n    The image hue is adjusted by converting the image to HSV and\n    cyclically shifting the intensities in the hue channel (H).\n    The image is then converted back to original image mode.\n\n    `hue_factor` is the amount of shift in H channel and must be in the\n    interval `[-0.5, 0.5]`.\n\n    See `Hue`_ for more details.\n\n    .. _Hue: https://en.wikipedia.org/wiki/Hue\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        hue_factor (float):  How much to shift the hue channel. Should be in\n            [-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel in\n            HSV space in positive and negative direction respectively.\n            0 means no shift. Therefore, both -0.5 and 0.5 will give an image\n            with complementary colors while 0 gives the original image.\n\n    Returns:\n        PIL Image: Hue adjusted image.\n    \"\"\"", "\n", "if", "not", "(", "-", "0.5", "<=", "hue_factor", "<=", "0.5", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'hue_factor is not in [-0.5, 0.5].'", ".", "format", "(", "hue_factor", ")", ")", "\n", "\n", "", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "input_mode", "=", "img", ".", "mode", "\n", "if", "input_mode", "in", "{", "'L'", ",", "'1'", ",", "'I'", ",", "'F'", "}", ":", "\n", "        ", "return", "img", "\n", "\n", "", "h", ",", "s", ",", "v", "=", "img", ".", "convert", "(", "'HSV'", ")", ".", "split", "(", ")", "\n", "\n", "np_h", "=", "np", ".", "array", "(", "h", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "# uint8 addition take cares of rotation across boundaries", "\n", "with", "np", ".", "errstate", "(", "over", "=", "'ignore'", ")", ":", "\n", "        ", "np_h", "+=", "np", ".", "uint8", "(", "hue_factor", "*", "255", ")", "\n", "", "h", "=", "Image", ".", "fromarray", "(", "np_h", ",", "'L'", ")", "\n", "\n", "img", "=", "Image", ".", "merge", "(", "'HSV'", ",", "(", "h", ",", "s", ",", "v", ")", ")", ".", "convert", "(", "input_mode", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_gamma": [[558, 592], ["img.convert.convert", "img.convert.point", "img.convert.convert", "functional._is_pil_image", "TypeError", "ValueError", "type", "pow", "range"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "adjust_gamma", "(", "img", ",", "gamma", ",", "gain", "=", "1", ")", ":", "\n", "    ", "r\"\"\"Perform gamma correction on an image.\n\n    Also known as Power Law Transform. Intensities in RGB mode are adjusted\n    based on the following equation:\n\n    .. math::\n        I_{\\text{out}} = 255 \\times \\text{gain} \\times \\left(\\frac{I_{\\text{in}}}{255}\\right)^{\\gamma}\n\n    See `Gamma Correction`_ for more details.\n\n    .. _Gamma Correction: https://en.wikipedia.org/wiki/Gamma_correction\n\n    Args:\n        img (PIL Image): PIL Image to be adjusted.\n        gamma (float): Non negative real number, same as :math:`\\gamma` in the equation.\n            gamma larger than 1 make the shadows darker,\n            while gamma smaller than 1 make dark regions lighter.\n        gain (float): The constant multiplier.\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "if", "gamma", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'Gamma should be a non-negative real number'", ")", "\n", "\n", "", "input_mode", "=", "img", ".", "mode", "\n", "img", "=", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "gamma_map", "=", "[", "255", "*", "gain", "*", "pow", "(", "ele", "/", "255.", ",", "gamma", ")", "for", "ele", "in", "range", "(", "256", ")", "]", "*", "3", "\n", "img", "=", "img", ".", "point", "(", "gamma_map", ")", "# use PIL's point-function to accelerate this part", "\n", "\n", "img", "=", "img", ".", "convert", "(", "input_mode", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.rotate": [[594, 620], ["img.rotate", "functional._is_pil_image", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.rotate", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "rotate", "(", "img", ",", "angle", ",", "resample", "=", "False", ",", "expand", "=", "False", ",", "center", "=", "None", ")", ":", "\n", "    ", "\"\"\"Rotate the image by angle.\n\n\n    Args:\n        img (PIL Image): PIL Image to be rotated.\n        angle (float or int): In degrees degrees counter clockwise order.\n        resample (``PIL.Image.NEAREST`` or ``PIL.Image.BILINEAR`` or ``PIL.Image.BICUBIC``, optional):\n            An optional resampling filter. See `filters`_ for more information.\n            If omitted, or if the image has mode \"1\" or \"P\", it is set to ``PIL.Image.NEAREST``.\n        expand (bool, optional): Optional expansion flag.\n            If true, expands the output image to make it large enough to hold the entire rotated image.\n            If false or omitted, make the output image the same size as the input image.\n            Note that the expand flag assumes rotation around the center and no translation.\n        center (2-tuple, optional): Optional center of rotation.\n            Origin is the upper left corner.\n            Default is the center of the image.\n\n    .. _filters: http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n\n    \"\"\"", "\n", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "return", "img", ".", "rotate", "(", "angle", ",", "resample", ",", "expand", ",", "center", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._get_inverse_affine_matrix": [[622, 655], ["math.radians", "math.radians", "math.cos", "math.sin", "math.cos", "math.cos", "math.cos", "math.sin", "math.sin", "math.sin", "functional.scale"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.scale"], ["", "def", "_get_inverse_affine_matrix", "(", "center", ",", "angle", ",", "translate", ",", "scale", ",", "shear", ")", ":", "\n", "# Helper method to compute inverse matrix for affine transformation", "\n", "\n", "# As it is explained in PIL.Image.rotate", "\n", "# We need compute INVERSE of affine transformation matrix: M = T * C * RSS * C^-1", "\n", "# where T is translation matrix: [1, 0, tx | 0, 1, ty | 0, 0, 1]", "\n", "#       C is translation matrix to keep center: [1, 0, cx | 0, 1, cy | 0, 0, 1]", "\n", "#       RSS is rotation with scale and shear matrix", "\n", "#       RSS(a, scale, shear) = [ cos(a)*scale    -sin(a + shear)*scale     0]", "\n", "#                              [ sin(a)*scale    cos(a + shear)*scale     0]", "\n", "#                              [     0                  0          1]", "\n", "# Thus, the inverse is M^-1 = C * RSS^-1 * C^-1 * T^-1", "\n", "\n", "    ", "angle", "=", "math", ".", "radians", "(", "angle", ")", "\n", "shear", "=", "math", ".", "radians", "(", "shear", ")", "\n", "scale", "=", "1.0", "/", "scale", "\n", "\n", "# Inverted rotation matrix with scale and shear", "\n", "d", "=", "math", ".", "cos", "(", "angle", "+", "shear", ")", "*", "math", ".", "cos", "(", "angle", ")", "+", "math", ".", "sin", "(", "angle", "+", "shear", ")", "*", "math", ".", "sin", "(", "angle", ")", "\n", "matrix", "=", "[", "\n", "math", ".", "cos", "(", "angle", "+", "shear", ")", ",", "math", ".", "sin", "(", "angle", "+", "shear", ")", ",", "0", ",", "\n", "-", "math", ".", "sin", "(", "angle", ")", ",", "math", ".", "cos", "(", "angle", ")", ",", "0", "\n", "]", "\n", "matrix", "=", "[", "scale", "/", "d", "*", "m", "for", "m", "in", "matrix", "]", "\n", "\n", "# Apply inverse of translation and of center translation: RSS^-1 * C^-1 * T^-1", "\n", "matrix", "[", "2", "]", "+=", "matrix", "[", "0", "]", "*", "(", "-", "center", "[", "0", "]", "-", "translate", "[", "0", "]", ")", "+", "matrix", "[", "1", "]", "*", "(", "-", "center", "[", "1", "]", "-", "translate", "[", "1", "]", ")", "\n", "matrix", "[", "5", "]", "+=", "matrix", "[", "3", "]", "*", "(", "-", "center", "[", "0", "]", "-", "translate", "[", "0", "]", ")", "+", "matrix", "[", "4", "]", "*", "(", "-", "center", "[", "1", "]", "-", "translate", "[", "1", "]", ")", "\n", "\n", "# Apply center translation: C * RSS^-1 * C^-1 * T^-1", "\n", "matrix", "[", "2", "]", "+=", "center", "[", "0", "]", "\n", "matrix", "[", "5", "]", "+=", "center", "[", "1", "]", "\n", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.affine": [[657, 685], ["functional._get_inverse_affine_matrix", "img.transform", "functional._is_pil_image", "TypeError", "isinstance", "len", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._get_inverse_affine_matrix", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "affine", "(", "img", ",", "angle", ",", "translate", ",", "scale", ",", "shear", ",", "resample", "=", "0", ",", "fillcolor", "=", "None", ")", ":", "\n", "    ", "\"\"\"Apply affine transformation on the image keeping image center invariant\n\n    Args:\n        img (PIL Image): PIL Image to be rotated.\n        angle (float or int): rotation angle in degrees between -180 and 180, clockwise direction.\n        translate (list or tuple of integers): horizontal and vertical translations (post-rotation translation)\n        scale (float): overall scale\n        shear (float): shear angle value in degrees between -180 to 180, clockwise direction.\n        resample (``PIL.Image.NEAREST`` or ``PIL.Image.BILINEAR`` or ``PIL.Image.BICUBIC``, optional):\n            An optional resampling filter.\n            See `filters`_ for more information.\n            If omitted, or if the image has mode \"1\" or \"P\", it is set to ``PIL.Image.NEAREST``.\n        fillcolor (int): Optional fill color for the area outside the transform in the output image. (Pillow>=5.0.0)\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "assert", "isinstance", "(", "translate", ",", "(", "tuple", ",", "list", ")", ")", "and", "len", "(", "translate", ")", "==", "2", ",", "\"Argument translate should be a list or tuple of length 2\"", "\n", "\n", "assert", "scale", ">", "0.0", ",", "\"Argument scale should be positive\"", "\n", "\n", "output_size", "=", "img", ".", "size", "\n", "center", "=", "(", "img", ".", "size", "[", "0", "]", "*", "0.5", "+", "0.5", ",", "img", ".", "size", "[", "1", "]", "*", "0.5", "+", "0.5", ")", "\n", "matrix", "=", "_get_inverse_affine_matrix", "(", "center", ",", "angle", ",", "translate", ",", "scale", ",", "shear", ")", "\n", "kwargs", "=", "{", "\"fillcolor\"", ":", "fillcolor", "}", "if", "PILLOW_VERSION", "[", "0", "]", "==", "'5'", "else", "{", "}", "\n", "return", "img", ".", "transform", "(", "output_size", ",", "Image", ".", "AFFINE", ",", "matrix", ",", "resample", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_grayscale": [[687, 713], ["functional._is_pil_image", "TypeError", "Image.fromarray.convert", "Image.fromarray.convert", "numpy.array", "numpy.dstack", "PIL.Image.fromarray", "ValueError", "type"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional._is_pil_image"], ["", "def", "to_grayscale", "(", "img", ",", "num_output_channels", "=", "1", ")", ":", "\n", "    ", "\"\"\"Convert image to grayscale version of image.\n\n    Args:\n        img (PIL Image): Image to be converted to grayscale.\n\n    Returns:\n        PIL Image: Grayscale version of the image.\n            if num_output_channels = 1 : returned image is single channel\n\n            if num_output_channels = 3 : returned image is 3 channel with r = g = b\n    \"\"\"", "\n", "if", "not", "_is_pil_image", "(", "img", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'img should be PIL Image. Got {}'", ".", "format", "(", "type", "(", "img", ")", ")", ")", "\n", "\n", "", "if", "num_output_channels", "==", "1", ":", "\n", "        ", "img", "=", "img", ".", "convert", "(", "'L'", ")", "\n", "", "elif", "num_output_channels", "==", "3", ":", "\n", "        ", "img", "=", "img", ".", "convert", "(", "'L'", ")", "\n", "np_img", "=", "np", ".", "array", "(", "img", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "np_img", "=", "np", ".", "dstack", "(", "[", "np_img", ",", "np_img", ",", "np_img", "]", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "np_img", ",", "'RGB'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'num_output_channels should be either 1 or 3'", ")", "\n", "\n", "", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Compose.__init__": [[52, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Compose.__call__": [[55, 59], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "imgs", "=", "t", "(", "imgs", ")", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Compose.__repr__": [[60, 67], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ToTensor.__call__": [[76, 85], ["functional.to_tensor"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_tensor"], ["def", "__call__", "(", "self", ",", "pics", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n\n        Returns:\n            Tensor: Converted image.\n        \"\"\"", "\n", "return", "[", "F", ".", "to_tensor", "(", "pic", ")", "for", "pic", "in", "pics", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ToTensor.__repr__": [[86, 88], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ToPILImage.__init__": [[106, 108], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mode", "=", "None", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ToPILImage.__call__": [[109, 119], ["functional.to_pil_image"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_pil_image"], ["", "def", "__call__", "(", "self", ",", "pics", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\n\n        Returns:\n            PIL Image: Image converted to PIL Image.\n\n        \"\"\"", "\n", "return", "[", "F", ".", "to_pil_image", "(", "pic", ",", "self", ".", "mode", ")", "for", "pic", "in", "pics", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ToPILImage.__repr__": [[120, 126], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "if", "self", ".", "mode", "is", "not", "None", ":", "\n", "            ", "format_string", "+=", "'mode={0}'", ".", "format", "(", "self", ".", "mode", ")", "\n", "", "format_string", "+=", "')'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Normalize.__init__": [[142, 145], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Normalize.__call__": [[146, 155], ["functional.normalize", "functional.to_tensor"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.normalize", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_tensor"], ["", "def", "__call__", "(", "self", ",", "tensors", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n\n        Returns:\n            Tensor: Normalized Tensor image.\n        \"\"\"", "\n", "return", "[", "F", ".", "normalize", "(", "F", ".", "to_tensor", "(", "tensors", "[", "0", "]", ")", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "]", "+", "tensors", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Normalize.__repr__": [[156, 158], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(mean={0}, std={1})'", ".", "format", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Resize.__init__": [[173, 177], ["isinstance", "isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "assert", "isinstance", "(", "size", ",", "int", ")", "or", "(", "isinstance", "(", "size", ",", "collections", ".", "Iterable", ")", "and", "len", "(", "size", ")", "==", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Resize.__call__": [[178, 187], ["functional.resize"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resize"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be scaled.\n\n        Returns:\n            PIL Image: Rescaled image.\n        \"\"\"", "\n", "return", "[", "F", ".", "resize", "(", "img", ",", "self", ".", "size", ",", "self", ".", "interpolation", ")", "for", "img", "in", "imgs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Resize.__repr__": [[188, 191], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "interpolate_str", "=", "_pil_interpolation_to_str", "[", "self", ".", "interpolation", "]", "\n", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}, interpolation={1})'", ".", "format", "(", "self", ".", "size", ",", "interpolate_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Scale.__init__": [[197, 201], ["warnings.warn", "transforms_group.Resize.__init__"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"The use of the transforms.Scale transform is deprecated, \"", "+", "\n", "\"please use transforms.Resize instead.\"", ")", "\n", "super", "(", "Scale", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.CenterCrop.__init__": [[212, 217], ["isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.CenterCrop.__call__": [[218, 227], ["functional.center_crop"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.center_crop"], ["", "", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n\n        Returns:\n            PIL Image: Cropped image.\n        \"\"\"", "\n", "return", "F", ".", "center_crop", "(", "img", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.CenterCrop.__repr__": [[228, 230], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0})'", ".", "format", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Pad.__init__": [[262, 273], ["isinstance", "isinstance", "isinstance", "ValueError", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "padding", ",", "fill", "=", "0", ",", "padding_mode", "=", "'constant'", ")", ":", "\n", "        ", "assert", "isinstance", "(", "padding", ",", "(", "numbers", ".", "Number", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "fill", ",", "(", "numbers", ".", "Number", ",", "str", ",", "tuple", ")", ")", "\n", "assert", "padding_mode", "in", "[", "'constant'", ",", "'edge'", ",", "'reflect'", ",", "'symmetric'", "]", "\n", "if", "isinstance", "(", "padding", ",", "collections", ".", "Sequence", ")", "and", "len", "(", "padding", ")", "not", "in", "[", "2", ",", "4", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"Padding must be an int or a 2, or 4 element tuple, not a \"", "+", "\n", "\"{} element tuple\"", ".", "format", "(", "len", "(", "padding", ")", ")", ")", "\n", "\n", "", "self", ".", "padding", "=", "padding", "\n", "self", ".", "fill", "=", "fill", "\n", "self", ".", "padding_mode", "=", "padding_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Pad.__call__": [[274, 283], ["functional.pad"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be padded.\n\n        Returns:\n            PIL Image: Padded image.\n        \"\"\"", "\n", "return", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Pad.__repr__": [[284, 287], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(padding={0}, fill={1}, padding_mode={2})'", ".", "format", "(", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Lambda.__init__": [[296, 299], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lambd", ")", ":", "\n", "        ", "assert", "isinstance", "(", "lambd", ",", "types", ".", "LambdaType", ")", "\n", "self", ".", "lambd", "=", "lambd", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Lambda.__call__": [[300, 302], ["transforms_group.Lambda.lambd"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "self", ".", "lambd", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Lambda.__repr__": [[303, 305], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomTransforms.__init__": [[314, 317], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "assert", "isinstance", "(", "transforms", ",", "(", "list", ",", "tuple", ")", ")", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomTransforms.__call__": [[318, 320], ["NotImplementedError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomTransforms.__repr__": [[321, 328], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomApply.__init__": [[338, 341], ["transforms_group.RandomTransforms.__init__"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["def", "__init__", "(", "self", ",", "transforms", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RandomApply", ",", "self", ")", ".", "__init__", "(", "transforms", ")", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomApply.__call__": [[342, 348], ["random.random", "t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "self", ".", "p", "<", "random", ".", "random", "(", ")", ":", "\n", "            ", "return", "img", "\n", "", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "img", "=", "t", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomApply.__repr__": [[349, 357], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "format_string", "+=", "'\\n    p={}'", ".", "format", "(", "self", ".", "p", ")", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomOrder.__call__": [[362, 368], ["list", "random.shuffle", "range", "len"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "order", "=", "list", "(", "range", "(", "len", "(", "self", ".", "transforms", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "order", ")", "\n", "for", "i", "in", "order", ":", "\n", "            ", "img", "=", "self", ".", "transforms", "[", "i", "]", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomChoice.__call__": [[373, 376], ["random.choice", "random.choice."], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "t", "=", "random", ".", "choice", "(", "self", ".", "transforms", ")", "\n", "return", "t", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomCrop.__init__": [[413, 422], ["isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "padding", "=", "None", ",", "pad_if_needed", "=", "False", ",", "fill", "=", "0", ",", "padding_mode", "=", "'constant'", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "self", ".", "padding", "=", "padding", "\n", "self", ".", "pad_if_needed", "=", "pad_if_needed", "\n", "self", ".", "fill", "=", "fill", "\n", "self", ".", "padding_mode", "=", "padding_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomCrop.get_params": [[423, 442], ["random.randint", "random.randint"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "img", ",", "output_size", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``crop`` for a random crop.\n\n        Args:\n            img (PIL Image): Image to be cropped.\n            output_size (tuple): Expected output size of the crop.\n\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n        \"\"\"", "\n", "w", ",", "h", "=", "img", ".", "size", "\n", "th", ",", "tw", "=", "output_size", "\n", "if", "w", "==", "tw", "and", "h", "==", "th", ":", "\n", "            ", "return", "0", ",", "0", ",", "h", ",", "w", "\n", "\n", "", "i", "=", "random", ".", "randint", "(", "0", ",", "h", "-", "th", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "tw", ")", "\n", "return", "i", ",", "j", ",", "th", ",", "tw", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomCrop.__call__": [[443, 481], ["transforms_group.RandomCrop.get_params", "out_imgs.append", "functional.pad", "functional.pad", "functional.pad", "functional.crop", "out_imgs.append", "functional.pad", "functional.pad", "functional.pad", "functional.crop", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.get_params", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n\n        Returns:\n            PIL Image: Cropped image.\n        \"\"\"", "\n", "out_imgs", "=", "[", "]", "\n", "img", "=", "imgs", "[", "0", "]", "\n", "if", "self", ".", "padding", "is", "not", "None", ":", "\n", "            ", "img", "=", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n", "# pad the width if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", "<", "self", ".", "size", "[", "1", "]", ":", "\n", "            ", "img", "=", "F", ".", "pad", "(", "img", ",", "(", "int", "(", "(", "1", "+", "self", ".", "size", "[", "1", "]", "-", "img1", ".", "size", "[", "0", "]", ")", "/", "2", ")", ",", "0", ")", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n", "# pad the height if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", ".", "size", "[", "1", "]", "<", "self", ".", "size", "[", "0", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "(", "0", ",", "int", "(", "(", "1", "+", "self", ".", "size", "[", "0", "]", "-", "img1", ".", "size", "[", "1", "]", ")", "/", "2", ")", ")", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n", "", "i", ",", "j", ",", "h", ",", "w", "=", "self", ".", "get_params", "(", "img", ",", "self", ".", "size", ")", "\n", "out_imgs", ".", "append", "(", "F", ".", "crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ")", ")", "\n", "\n", "for", "img", "in", "imgs", "[", "1", ":", "]", ":", "\n", "            ", "if", "self", ".", "padding", "is", "not", "None", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n", "# pad the width if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", "<", "self", ".", "size", "[", "1", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "(", "int", "(", "(", "1", "+", "self", ".", "size", "[", "1", "]", "-", "img1", ".", "size", "[", "0", "]", ")", "/", "2", ")", ",", "0", ")", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n", "# pad the height if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", ".", "size", "[", "1", "]", "<", "self", ".", "size", "[", "0", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "(", "0", ",", "int", "(", "(", "1", "+", "self", ".", "size", "[", "0", "]", "-", "img1", ".", "size", "[", "1", "]", ")", "/", "2", ")", ")", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n", "", "out_imgs", ".", "append", "(", "F", ".", "crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ")", ")", "\n", "", "return", "out_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomCrop.__repr__": [[482, 484], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}, padding={1})'", ".", "format", "(", "self", ".", "size", ",", "self", ".", "padding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomHorizontalFlip.__init__": [[493, 495], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomHorizontalFlip.__call__": [[496, 507], ["random.random", "functional.hflip"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.hflip"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be flipped.\n\n        Returns:\n            PIL Image: Randomly flipped image.\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "p", ":", "\n", "            ", "return", "F", ".", "hflip", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomHorizontalFlip.__repr__": [[508, 510], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(p={})'", ".", "format", "(", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomVerticalFlip.__init__": [[519, 521], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomVerticalFlip.__call__": [[522, 533], ["random.random", "functional.vflip"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.vflip"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be flipped.\n\n        Returns:\n            PIL Image: Randomly flipped image.\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "p", ":", "\n", "            ", "return", "F", ".", "vflip", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomVerticalFlip.__repr__": [[534, 536], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(p={})'", ".", "format", "(", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomResizedCrop.__init__": [[553, 558], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ",", "ratio", "=", "(", "3.", "/", "4.", ",", "4.", "/", "3.", ")", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "self", ".", "size", "=", "(", "size", ",", "size", ")", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "ratio", "=", "ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomResizedCrop.get_params": [[559, 593], ["range", "min", "random.uniform", "int", "int", "random.uniform", "round", "round", "random.random", "random.randint", "random.randint", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "img", ",", "scale", ",", "ratio", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``crop`` for a random sized crop.\n\n        Args:\n            img (PIL Image): Image to be cropped.\n            scale (tuple): range of size of the origin size cropped\n            ratio (tuple): range of aspect ratio of the origin aspect ratio cropped\n\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for a random\n                sized crop.\n        \"\"\"", "\n", "for", "attempt", "in", "range", "(", "10", ")", ":", "\n", "            ", "area", "=", "img", ".", "size", "[", "0", "]", "*", "img", ".", "size", "[", "1", "]", "\n", "target_area", "=", "random", ".", "uniform", "(", "*", "scale", ")", "*", "area", "\n", "aspect_ratio", "=", "random", ".", "uniform", "(", "*", "ratio", ")", "\n", "\n", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "w", ",", "h", "=", "h", ",", "w", "\n", "\n", "", "if", "w", "<=", "img", ".", "size", "[", "0", "]", "and", "h", "<=", "img", ".", "size", "[", "1", "]", ":", "\n", "                ", "i", "=", "random", ".", "randint", "(", "0", ",", "img", ".", "size", "[", "1", "]", "-", "h", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "img", ".", "size", "[", "0", "]", "-", "w", ")", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n", "# Fallback", "\n", "", "", "w", "=", "min", "(", "img", ".", "size", "[", "0", "]", ",", "img", ".", "size", "[", "1", "]", ")", "\n", "i", "=", "(", "img", ".", "size", "[", "1", "]", "-", "w", ")", "//", "2", "\n", "j", "=", "(", "img", ".", "size", "[", "0", "]", "-", "w", ")", "//", "2", "\n", "return", "i", ",", "j", ",", "w", ",", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomResizedCrop.__call__": [[594, 604], ["transforms_group.RandomResizedCrop.get_params", "functional.resized_crop"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.get_params", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.resized_crop"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped and resized.\n\n        Returns:\n            PIL Image: Randomly cropped and resized image.\n        \"\"\"", "\n", "i", ",", "j", ",", "h", ",", "w", "=", "self", ".", "get_params", "(", "img", ",", "self", ".", "scale", ",", "self", ".", "ratio", ")", "\n", "return", "F", ".", "resized_crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ",", "self", ".", "size", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomResizedCrop.__repr__": [[605, 612], ["tuple", "tuple", "round", "round"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "interpolate_str", "=", "_pil_interpolation_to_str", "[", "self", ".", "interpolation", "]", "\n", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}'", ".", "format", "(", "self", ".", "size", ")", "\n", "format_string", "+=", "', scale={0}'", ".", "format", "(", "tuple", "(", "round", "(", "s", ",", "4", ")", "for", "s", "in", "self", ".", "scale", ")", ")", "\n", "format_string", "+=", "', ratio={0}'", ".", "format", "(", "tuple", "(", "round", "(", "r", ",", "4", ")", "for", "r", "in", "self", ".", "ratio", ")", ")", "\n", "format_string", "+=", "', interpolation={0})'", ".", "format", "(", "interpolate_str", ")", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomSizedCrop.__init__": [[618, 622], ["warnings.warn", "transforms_group.RandomResizedCrop.__init__"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"The use of the transforms.RandomSizedCrop transform is deprecated, \"", "+", "\n", "\"please use transforms.RandomResizedCrop instead.\"", ")", "\n", "super", "(", "RandomSizedCrop", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.FiveCrop.__init__": [[648, 655], ["isinstance", "int", "int", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "size", ")", "==", "2", ",", "\"Please provide only two dimensions (h, w) for size.\"", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.FiveCrop.__call__": [[656, 658], ["functional.five_crop"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.five_crop"], ["", "", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "F", ".", "five_crop", "(", "img", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.FiveCrop.__repr__": [[659, 661], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0})'", ".", "format", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.TenCrop.__init__": [[690, 698], ["isinstance", "int", "int", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "vertical_flip", "=", "False", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "size", ")", "==", "2", ",", "\"Please provide only two dimensions (h, w) for size.\"", "\n", "self", ".", "size", "=", "size", "\n", "", "self", ".", "vertical_flip", "=", "vertical_flip", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.TenCrop.__call__": [[699, 701], ["functional.ten_crop"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.ten_crop"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "F", ".", "ten_crop", "(", "img", ",", "self", ".", "size", ",", "self", ".", "vertical_flip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.TenCrop.__repr__": [[702, 704], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}, vertical_flip={1})'", ".", "format", "(", "self", ".", "size", ",", "self", ".", "vertical_flip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.LinearTransformation.__init__": [[723, 728], ["transformation_matrix.size", "transformation_matrix.size", "ValueError", "transformation_matrix.size"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transformation_matrix", ")", ":", "\n", "        ", "if", "transformation_matrix", ".", "size", "(", "0", ")", "!=", "transformation_matrix", ".", "size", "(", "1", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"transformation_matrix should be square. Got \"", "+", "\n", "\"[{} x {}] rectangular matrix.\"", ".", "format", "(", "*", "transformation_matrix", ".", "size", "(", ")", ")", ")", "\n", "", "self", ".", "transformation_matrix", "=", "transformation_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.LinearTransformation.__call__": [[729, 745], ["torch.mm.view.view", "torch.mm", "torch.mm.view", "transforms_group.LinearTransformation.transformation_matrix.size", "ValueError", "torch.mm.view.size", "torch.mm.view.size", "torch.mm.view.size", "torch.mm.view.size", "transforms_group.LinearTransformation.transformation_matrix.size", "torch.mm.view.size"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be whitened.\n\n        Returns:\n            Tensor: Transformed image.\n        \"\"\"", "\n", "if", "tensor", ".", "size", "(", "0", ")", "*", "tensor", ".", "size", "(", "1", ")", "*", "tensor", ".", "size", "(", "2", ")", "!=", "self", ".", "transformation_matrix", ".", "size", "(", "0", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"tensor and transformation matrix have incompatible shape.\"", "+", "\n", "\"[{} x {} x {}] != \"", ".", "format", "(", "*", "tensor", ".", "size", "(", ")", ")", "+", "\n", "\"{}\"", ".", "format", "(", "self", ".", "transformation_matrix", ".", "size", "(", "0", ")", ")", ")", "\n", "", "flat_tensor", "=", "tensor", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "transformed_tensor", "=", "torch", ".", "mm", "(", "flat_tensor", ",", "self", ".", "transformation_matrix", ")", "\n", "tensor", "=", "transformed_tensor", ".", "view", "(", "tensor", ".", "size", "(", ")", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.LinearTransformation.__repr__": [[746, 750], ["str", "transforms_group.LinearTransformation.transformation_matrix.numpy().tolist", "transforms_group.LinearTransformation.transformation_matrix.numpy"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "format_string", "+=", "(", "str", "(", "self", ".", "transformation_matrix", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "+", "')'", ")", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ColorJitter.__init__": [[765, 770], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "brightness", "\n", "self", ".", "contrast", "=", "contrast", "\n", "self", ".", "saturation", "=", "saturation", "\n", "self", ".", "hue", "=", "hue", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ColorJitter.get_params": [[771, 802], ["random.shuffle", "transforms_group.Compose", "random.uniform", "transforms.append", "random.uniform", "transforms.append", "random.uniform", "transforms.append", "random.uniform", "transforms.append", "max", "transforms_group.Lambda", "max", "transforms_group.Lambda", "max", "transforms_group.Lambda", "transforms_group.Lambda", "functional.adjust_brightness", "functional.adjust_contrast", "functional.adjust_saturation", "functional.adjust_hue"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_brightness", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_contrast", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_saturation", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.adjust_hue"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "\"\"\"Get a randomized transform to be applied on image.\n\n        Arguments are same as that of __init__.\n\n        Returns:\n            Transform which randomly adjusts brightness, contrast and\n            saturation in a random order.\n        \"\"\"", "\n", "transforms", "=", "[", "]", "\n", "if", "brightness", ">", "0", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_brightness", "(", "img", ",", "brightness_factor", ")", ")", ")", "\n", "\n", "", "if", "contrast", ">", "0", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_contrast", "(", "img", ",", "contrast_factor", ")", ")", ")", "\n", "\n", "", "if", "saturation", ">", "0", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_saturation", "(", "img", ",", "saturation_factor", ")", ")", ")", "\n", "\n", "", "if", "hue", ">", "0", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "-", "hue", ",", "hue", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_hue", "(", "img", ",", "hue_factor", ")", ")", ")", "\n", "\n", "", "random", ".", "shuffle", "(", "transforms", ")", "\n", "transform", "=", "Compose", "(", "transforms", ")", "\n", "\n", "return", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ColorJitter.__call__": [[803, 815], ["transforms_group.ColorJitter.get_params", "transforms_group.ColorJitter."], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.get_params"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Input image.\n\n        Returns:\n            PIL Image: Color jittered image.\n        \"\"\"", "\n", "transform", "=", "self", ".", "get_params", "(", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "\n", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "out", "=", "[", "transform", "(", "imgs", "[", "0", "]", ")", "]", "\n", "return", "out", "+", "imgs", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.ColorJitter.__repr__": [[816, 823], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "format_string", "+=", "'brightness={0}'", ".", "format", "(", "self", ".", "brightness", ")", "\n", "format_string", "+=", "', contrast={0}'", ".", "format", "(", "self", ".", "contrast", ")", "\n", "format_string", "+=", "', saturation={0}'", ".", "format", "(", "self", ".", "saturation", ")", "\n", "format_string", "+=", "', hue={0})'", ".", "format", "(", "self", ".", "hue", ")", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomRotation.__init__": [[845, 858], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ",", "resample", "=", "False", ",", "expand", "=", "False", ",", "center", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"If degrees is a single number, it must be positive.\"", ")", "\n", "", "self", ".", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\"If degrees is a sequence, it must be of len 2.\"", ")", "\n", "", "self", ".", "degrees", "=", "degrees", "\n", "\n", "", "self", ".", "resample", "=", "resample", "\n", "self", ".", "expand", "=", "expand", "\n", "self", ".", "center", "=", "center", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomRotation.get_params": [[859, 869], ["random.uniform"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "degrees", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``rotate`` for a random rotation.\n\n        Returns:\n            sequence: params to be passed to ``rotate`` for random rotation.\n        \"\"\"", "\n", "angle", "=", "random", ".", "uniform", "(", "degrees", "[", "0", "]", ",", "degrees", "[", "1", "]", ")", "\n", "\n", "return", "angle", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomRotation.__call__": [[870, 881], ["transforms_group.RandomRotation.get_params", "functional.rotate"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.get_params", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.rotate"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"\n            img (PIL Image): Image to be rotated.\n\n        Returns:\n            PIL Image: Rotated image.\n        \"\"\"", "\n", "\n", "angle", "=", "self", ".", "get_params", "(", "self", ".", "degrees", ")", "\n", "\n", "return", "[", "F", ".", "rotate", "(", "img", ",", "angle", ",", "self", ".", "resample", ",", "self", ".", "expand", ",", "self", ".", "center", ")", "for", "img", "in", "imgs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomRotation.__repr__": [[882, 890], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'(degrees={0}'", ".", "format", "(", "self", ".", "degrees", ")", "\n", "format_string", "+=", "', resample={0}'", ".", "format", "(", "self", ".", "resample", ")", "\n", "format_string", "+=", "', expand={0}'", ".", "format", "(", "self", ".", "expand", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "            ", "format_string", "+=", "', center={0}'", ".", "format", "(", "self", ".", "center", ")", "\n", "", "format_string", "+=", "')'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.__init__": [[915, 955], ["isinstance", "isinstance", "ValueError", "isinstance", "isinstance", "isinstance", "len", "len", "ValueError", "len", "ValueError", "ValueError", "isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ",", "translate", "=", "None", ",", "scale", "=", "None", ",", "shear", "=", "None", ",", "resample", "=", "False", ",", "fillcolor", "=", "0", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"If degrees is a single number, it must be positive.\"", ")", "\n", "", "self", ".", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "degrees", ",", "(", "tuple", ",", "list", ")", ")", "and", "len", "(", "degrees", ")", "==", "2", ",", "\"degrees should be a list or tuple and it must be of length 2.\"", "\n", "self", ".", "degrees", "=", "degrees", "\n", "\n", "", "if", "translate", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "translate", ",", "(", "tuple", ",", "list", ")", ")", "and", "len", "(", "translate", ")", "==", "2", ",", "\"translate should be a list or tuple and it must be of length 2.\"", "\n", "for", "t", "in", "translate", ":", "\n", "                ", "if", "not", "(", "0.0", "<=", "t", "<=", "1.0", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\"translation values should be between 0 and 1\"", ")", "\n", "", "", "", "self", ".", "translate", "=", "translate", "\n", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "scale", ",", "(", "tuple", ",", "list", ")", ")", "and", "len", "(", "scale", ")", "==", "2", ",", "\"scale should be a list or tuple and it must be of length 2.\"", "\n", "for", "s", "in", "scale", ":", "\n", "                ", "if", "s", "<=", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "\"scale values should be positive\"", ")", "\n", "", "", "", "self", ".", "scale", "=", "scale", "\n", "\n", "if", "shear", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "shear", ",", "numbers", ".", "Number", ")", ":", "\n", "                ", "if", "shear", "<", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "\"If shear is a single number, it must be positive.\"", ")", "\n", "", "self", ".", "shear", "=", "(", "-", "shear", ",", "shear", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "shear", ",", "(", "tuple", ",", "list", ")", ")", "and", "len", "(", "shear", ")", "==", "2", ",", "\"shear should be a list or tuple and it must be of length 2.\"", "\n", "self", ".", "shear", "=", "shear", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "shear", "=", "shear", "\n", "\n", "", "self", ".", "resample", "=", "resample", "\n", "self", ".", "fillcolor", "=", "fillcolor", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.get_params": [[956, 983], ["random.uniform", "random.uniform", "random.uniform", "numpy.round", "numpy.round", "random.uniform", "random.uniform"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "degrees", ",", "translate", ",", "scale_ranges", ",", "shears", ",", "img_size", ")", ":", "\n", "        ", "\"\"\"Get parameters for affine transformation\n\n        Returns:\n            sequence: params to be passed to the affine transformation\n        \"\"\"", "\n", "angle", "=", "random", ".", "uniform", "(", "degrees", "[", "0", "]", ",", "degrees", "[", "1", "]", ")", "\n", "if", "translate", "is", "not", "None", ":", "\n", "            ", "max_dx", "=", "translate", "[", "0", "]", "*", "img_size", "[", "0", "]", "\n", "max_dy", "=", "translate", "[", "1", "]", "*", "img_size", "[", "1", "]", "\n", "translations", "=", "(", "np", ".", "round", "(", "random", ".", "uniform", "(", "-", "max_dx", ",", "max_dx", ")", ")", ",", "\n", "np", ".", "round", "(", "random", ".", "uniform", "(", "-", "max_dy", ",", "max_dy", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "translations", "=", "(", "0", ",", "0", ")", "\n", "\n", "", "if", "scale_ranges", "is", "not", "None", ":", "\n", "            ", "scale", "=", "random", ".", "uniform", "(", "scale_ranges", "[", "0", "]", ",", "scale_ranges", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "scale", "=", "1.0", "\n", "\n", "", "if", "shears", "is", "not", "None", ":", "\n", "            ", "shear", "=", "random", ".", "uniform", "(", "shears", "[", "0", "]", ",", "shears", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "shear", "=", "0.0", "\n", "\n", "", "return", "angle", ",", "translations", ",", "scale", ",", "shear", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.__call__": [[984, 993], ["transforms_group.RandomAffine.get_params", "functional.affine"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.get_params", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.affine"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n            img (PIL Image): Image to be transformed.\n\n        Returns:\n            PIL Image: Affine transformed image.\n        \"\"\"", "\n", "ret", "=", "self", ".", "get_params", "(", "self", ".", "degrees", ",", "self", ".", "translate", ",", "self", ".", "scale", ",", "self", ".", "shear", ",", "img", ".", "size", ")", "\n", "return", "F", ".", "affine", "(", "img", ",", "*", "ret", ",", "resample", "=", "self", ".", "resample", ",", "fillcolor", "=", "self", ".", "fillcolor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomAffine.__repr__": [[994, 1010], ["dict", "s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "'{name}(degrees={degrees}'", "\n", "if", "self", ".", "translate", "is", "not", "None", ":", "\n", "            ", "s", "+=", "', translate={translate}'", "\n", "", "if", "self", ".", "scale", "is", "not", "None", ":", "\n", "            ", "s", "+=", "', scale={scale}'", "\n", "", "if", "self", ".", "shear", "is", "not", "None", ":", "\n", "            ", "s", "+=", "', shear={shear}'", "\n", "", "if", "self", ".", "resample", ">", "0", ":", "\n", "            ", "s", "+=", "', resample={resample}'", "\n", "", "if", "self", ".", "fillcolor", "!=", "0", ":", "\n", "            ", "s", "+=", "', fillcolor={fillcolor}'", "\n", "", "s", "+=", "')'", "\n", "d", "=", "dict", "(", "self", ".", "__dict__", ")", "\n", "d", "[", "'resample'", "]", "=", "_pil_interpolation_to_str", "[", "d", "[", "'resample'", "]", "]", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Grayscale.__init__": [[1025, 1027], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_output_channels", "=", "1", ")", ":", "\n", "        ", "self", ".", "num_output_channels", "=", "num_output_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Grayscale.__call__": [[1028, 1037], ["functional.to_grayscale"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_grayscale"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be converted to grayscale.\n\n        Returns:\n            PIL Image: Randomly grayscaled image.\n        \"\"\"", "\n", "return", "F", ".", "to_grayscale", "(", "img", ",", "num_output_channels", "=", "self", ".", "num_output_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.Grayscale.__repr__": [[1038, 1040], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(num_output_channels={0})'", ".", "format", "(", "self", ".", "num_output_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomGrayscale.__init__": [[1056, 1058], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "p", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomGrayscale.__call__": [[1059, 1071], ["random.random", "functional.to_grayscale"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.to_grayscale"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be converted to grayscale.\n\n        Returns:\n            PIL Image: Randomly grayscaled image.\n        \"\"\"", "\n", "num_output_channels", "=", "1", "if", "img", ".", "mode", "==", "'L'", "else", "3", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "p", ":", "\n", "            ", "return", "F", ".", "to_grayscale", "(", "img", ",", "num_output_channels", "=", "num_output_channels", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.transforms_group.RandomGrayscale.__repr__": [[1072, 1074], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(p={0})'", ".", "format", "(", "self", ".", "p", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.evaluate_model.eval_model": [[38, 75], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "model", "torch.softmax().cpu", "true_masks[].cpu", "torch.softmax"], "function", ["None"], ["softmax", "=", "nn", ".", "Softmax", "(", "1", ")", "\n", "\n", "def", "eval_model", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.train.eval_model": [[39, 76], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "model", "torch.softmax().cpu", "true_masks[].cpu", "torch.softmax"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ",", "softmax", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.train.denormalize": [[77, 79], ["None"], "function", ["None"], ["masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", "[", "0", "]", ",", "masks_soft", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.train.generate_log_images": [[80, 96], ["train.denormalize", "masks_pred_softmax_t.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize"], ["return", "ap", "\n", "\n", "", "def", "denormalize", "(", "inputs", ")", ":", "\n", "    ", "if", "net_name", "==", "'unet'", ":", "\n", "        ", "return", "(", "inputs", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "", "else", ":", "\n", "        ", "mean", "=", "torch", ".", "FloatTensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "(", "inputs", "*", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "+", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "", "", "def", "generate_log_images", "(", "inputs_t", ",", "true_masks_t", ",", "masks_pred_softmax_t", ")", ":", "\n", "    ", "true_masks", "=", "(", "true_masks_t", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "masks_pred_softmax", "=", "(", "masks_pred_softmax_t", ".", "detach", "(", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "inputs", "=", "denormalize", "(", "inputs_t", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "pad_size", "=", "5", "\n", "images_batch", "=", "(", "torch", ".", "ones", "(", "(", "bs", ",", "3", ",", "h", ",", "w", "*", "3", "+", "pad_size", "*", "2", ")", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.train.image_to_patch": [[97, 102], ["image.reshape().permute().reshape", "image.reshape().permute", "image.reshape"], "function", ["None"], ["\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", ":", "w", "]", "=", "inputs", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "true_masks", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.train.train_model": [[104, 160], ["model.to", "range", "lesion.lower", "print", "g_scheduler.step", "model.train", "inputs.to.to", "true_masks.to.to", "model", "model.permute", "masks_pred.permute.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.reshape", "criterion", "g_optimizer.zero_grad", "g_loss.backward", "g_optimizer.step", "os.path.exists", "os.mkdir", "train.eval_model", "true_masks_indices.reshape.long", "open", "f.write", "f.write", "f.write", "torch.save", "torch.save", "torch.save", "torch.save", "model.state_dict", "g_optimizer.state_dict", "os.path.join", "str", "str"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model"], ["images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "masks_pred_softmax", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "return", "images_batch", "\n", "\n", "", "def", "image_to_patch", "(", "image", ",", "patch_size", ")", ":", "\n", "    ", "bs", ",", "channel", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "return", "(", "image", ".", "reshape", "(", "(", "bs", ",", "channel", ",", "h", "//", "patch_size", ",", "patch_size", ",", "w", "//", "patch_size", ",", "patch_size", ")", ")", "\n", ".", "permute", "(", "2", ",", "4", ",", "0", ",", "1", ",", "3", ",", "5", ")", "\n", ".", "reshape", "(", "(", "-", "1", ",", "channel", ",", "patch_size", ",", "patch_size", ")", ")", ")", "\n", "\n", "\n", "", "def", "train_model", "(", "model", ",", "lesion", ",", "preprocess", ",", "train_loader", ",", "eval_loader", ",", "criterion", ",", "g_optimizer", ",", "g_scheduler", ",", "\n", "batch_size", ",", "num_epochs", "=", "5", ",", "start_epoch", "=", "0", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "softmax", "=", "nn", ".", "Softmax", "(", "1", ")", "\n", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "tot_step_count", "=", "start_step", "\n", "\n", "best_ap", "=", "0.", "\n", "dir_checkpoint", "=", "'results/models_'", "+", "lesion", ".", "lower", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "start_epoch", "+", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'Starting epoch {}/{}.\\t\\n'", ".", "format", "(", "epoch", "+", "1", ",", "start_epoch", "+", "num_epochs", ")", ")", "\n", "g_scheduler", ".", "step", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "inputs", ",", "true_masks", "in", "train_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                ", "masks_pred", "=", "model", "(", "inputs", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                ", "masks_pred", "=", "model", "(", "inputs", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred_transpose", "=", "masks_pred", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "masks_pred_flat", "=", "masks_pred_transpose", ".", "reshape", "(", "-", "1", ",", "masks_pred_transpose", ".", "shape", "[", "-", "1", "]", ")", "\n", "true_masks_indices", "=", "torch", ".", "argmax", "(", "true_masks", ",", "1", ")", "\n", "true_masks_flat", "=", "true_masks_indices", ".", "reshape", "(", "-", "1", ")", "\n", "loss_ce", "=", "criterion", "(", "masks_pred_flat", ",", "true_masks_flat", ".", "long", "(", ")", ")", "\n", "\n", "ce_weight", "=", "1.", "\n", "g_loss", "=", "loss_ce", "*", "ce_weight", "\n", "\n", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "tot_step_count", "+=", "1", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_checkpoint", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_checkpoint", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "40", "==", "0", ":", "\n", "            ", "eval_ap", "=", "eval_model", "(", "model", ",", "eval_loader", ",", "softmax", ")", "\n", "with", "open", "(", "\"ap_during_learning_\"", "+", "lesion", "+", "preprocess", "+", "\".txt\"", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"epoch: \"", "+", "str", "(", "epoch", ")", ")", "\n", "f", ".", "write", "(", "\"ap: \"", "+", "str", "(", "eval_ap", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.dataset.IDRIDDataset.__init__": [[16, 41], ["len", "len", "zip", "dataset.IDRIDDataset.image_paths.append", "dataset.IDRIDDataset.mask_paths.append", "dataset.IDRIDDataset.images.append", "dataset.IDRIDDataset.masks.append", "dataset.IDRIDDataset.pil_loader", "dataset.IDRIDDataset.pil_loader"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader"], ["    ", "def", "__init__", "(", "self", ",", "image_paths", ",", "mask_paths", "=", "None", ",", "class_id", "=", "0", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_paths: paths to the original images []\n            mask_paths: paths to the mask images, [[]]\n            class_id: id of lesions, 0:ex, 1:he, 2:ma, 3:se\n        \"\"\"", "\n", "assert", "len", "(", "image_paths", ")", "==", "len", "(", "mask_paths", ")", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "mask_paths", "=", "[", "]", "\n", "self", ".", "masks", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "if", "self", ".", "mask_paths", "is", "not", "None", ":", "\n", "            ", "for", "image_path", ",", "mask_path4", "in", "zip", "(", "image_paths", ",", "mask_paths", ")", ":", "\n", "                ", "mask_path", "=", "mask_path4", "[", "class_id", "]", "\n", "if", "mask_path", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "self", ".", "image_paths", ".", "append", "(", "image_path", ")", "\n", "self", ".", "mask_paths", ".", "append", "(", "mask_path", ")", "\n", "self", ".", "images", ".", "append", "(", "self", ".", "pil_loader", "(", "image_path", ")", ")", "\n", "self", ".", "masks", ".", "append", "(", "self", ".", "pil_loader", "(", "mask_path", ")", ")", "\n", "\n", "", "", "", "self", ".", "class_id", "=", "class_id", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.dataset.IDRIDDataset.__len__": [[42, 44], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.dataset.IDRIDDataset.pil_loader": [[45, 51], ["open", "PIL.Image.open", "PIL.Image.open.convert"], "methods", ["None"], ["", "def", "pil_loader", "(", "self", ",", "image_path", ")", ":", "\n", "        ", "with", "open", "(", "image_path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "h", ",", "w", "=", "img", ".", "size", "\n", "#return img.resize((h//2, w//2)).convert('RGB')", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.dataset.IDRIDDataset.__getitem__": [[52, 72], ["numpy.array", "dataset.IDRIDDataset.append", "dataset.IDRIDDataset.transform", "numpy.transpose", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "info", "=", "[", "self", ".", "images", "[", "idx", "]", "]", "\n", "if", "self", ".", "mask_paths", ":", "\n", "            ", "info", ".", "append", "(", "self", ".", "masks", "[", "idx", "]", ")", "\n", "", "if", "self", ".", "transform", ":", "\n", "            ", "info", "=", "self", ".", "transform", "(", "info", ")", "\n", "", "inputs", "=", "np", ".", "array", "(", "info", "[", "0", "]", ")", "\n", "if", "inputs", ".", "shape", "[", "2", "]", "==", "3", ":", "\n", "            ", "inputs", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "info", "[", "0", "]", ")", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "inputs", "=", "inputs", "/", "255.", "\n", "\n", "", "if", "len", "(", "info", ")", ">", "1", ":", "\n", "            ", "mask", "=", "np", ".", "array", "(", "np", ".", "array", "(", "info", "[", "1", "]", ")", ")", "[", ":", ",", ":", ",", "0", "]", "/", "255.0", "\n", "empty_mask", "=", "1", "-", "mask", "\n", "masks", "=", "np", ".", "array", "(", "[", "empty_mask", ",", "mask", "]", ")", "\n", "\n", "return", "inputs", ",", "masks", "\n", "", "else", ":", "\n", "            ", "return", "inputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.preprocess.clahe_gridsize": [[17, 52], ["cv2.imread", "cv2.cvtColor", "cv2.imread", "numpy.uint8", "cv2.cvtColor", "cv2.split", "cv2.createCLAHE", "cv2.createCLAHE.apply", "cv2.merge", "cv2.cvtColor", "cv2.fastNlMeansDenoisingColored", "cv2.bilateralFilter", "cv2.cvtColor.sum", "numpy.minimum", "cv2.imread.sum"], "function", ["None"], ["\n", "bgr", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "\n", "# brightness balance.", "\n", "if", "brightnessbalance", ":", "\n", "        ", "gray", "=", "cv2", ".", "cvtColor", "(", "bgr", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "mask_img", "=", "cv2", ".", "imread", "(", "mask_path", ",", "0", ")", "\n", "brightness", "=", "gray", ".", "sum", "(", ")", "/", "(", "mask_img", ".", "shape", "[", "0", "]", "*", "mask_img", ".", "shape", "[", "1", "]", "-", "mask_img", ".", "sum", "(", ")", "/", "255.", ")", "\n", "bgr", "=", "np", ".", "uint8", "(", "np", ".", "minimum", "(", "bgr", "*", "brightnessbalance", "/", "brightness", ",", "255", ")", ")", "\n", "\n", "", "if", "contrastenhancement", ":", "\n", "# illumination correction and contrast enhancement.", "\n", "      ", "lab", "=", "cv2", ".", "cvtColor", "(", "bgr", ",", "cv2", ".", "COLOR_BGR2LAB", ")", "\n", "lab_planes", "=", "cv2", ".", "split", "(", "lab", ")", "\n", "clahe", "=", "cv2", ".", "createCLAHE", "(", "clipLimit", "=", "cliplimit", ",", "tileGridSize", "=", "(", "gridsize", ",", "gridsize", ")", ")", "\n", "lab_planes", "[", "0", "]", "=", "clahe", ".", "apply", "(", "lab_planes", "[", "0", "]", ")", "\n", "lab", "=", "cv2", ".", "merge", "(", "lab_planes", ")", "\n", "bgr", "=", "cv2", ".", "cvtColor", "(", "lab", ",", "cv2", ".", "COLOR_LAB2BGR", ")", "\n", "\n", "", "if", "denoise", ":", "\n", "        ", "bgr", "=", "cv2", ".", "fastNlMeansDenoisingColored", "(", "bgr", ",", "None", ",", "10", ",", "10", ",", "1", ",", "3", ")", "\n", "bgr", "=", "cv2", ".", "bilateralFilter", "(", "bgr", ",", "5", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "bgr", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.utils.initialize_weights": [[15, 26], ["net.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["def", "initialize_weights", "(", "net", ")", ":", "\n", "    ", "for", "m", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.UNet.utils.get_images": [[30, 95], ["glob.glob", "glob.glob.sort", "int", "int", "os.path.join", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "glob.glob", "os.path.join", "zip", "mask_paths.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "glob.glob", "glob.glob.sort", "len", "os.path.join", "os.path.join", "preprocess.clahe_gridsize", "cv2.imwrite", "len", "len", "[].split", "os.path.join", "os.path.exists", "os.path.join", "os.path.join", "cv2.imread", "cv2.imread", "[].split", "os.path.join", "paths.append", "paths.append", "[].split", "cv2.imread.sum", "os.path.split", "os.path.split", "cv2.imread.sum", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.preprocess.clahe_gridsize"], ["def", "get_images", "(", "image_dir", ",", "preprocess", "=", "'0'", ",", "phase", "=", "'train'", ")", ":", "\n", "    ", "if", "phase", "==", "'train'", "or", "phase", "==", "'eval'", ":", "\n", "        ", "setname", "=", "'TrainingSet'", "\n", "", "elif", "phase", "==", "'test'", ":", "\n", "        ", "setname", "=", "'TestingSet'", "\n", "\n", "", "limit", "=", "2", "\n", "grid_size", "=", "8", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ")", ")", "\n", "\n", "# compute mean brightess", "\n", "meanbright", "=", "0.", "\n", "images_number", "=", "0", "\n", "for", "tempsetname", "in", "[", "'TrainingSet'", ",", "'TestingSet'", "]", ":", "\n", "            ", "imgs_ori", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'OriginalImages/'", "+", "tempsetname", "+", "'/*.jpg'", ")", ")", "\n", "imgs_ori", ".", "sort", "(", ")", "\n", "images_number", "+=", "len", "(", "imgs_ori", ")", "\n", "# mean brightness.", "\n", "for", "img_path", "in", "imgs_ori", ":", "\n", "                ", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "tempsetname", ",", "'Mask'", ",", "img_name", "+", "'_MASK.tif'", ")", "\n", "gray", "=", "cv2", ".", "imread", "(", "img_path", ",", "0", ")", "\n", "mask_img", "=", "cv2", ".", "imread", "(", "mask_path", ",", "0", ")", "\n", "brightness", "=", "gray", ".", "sum", "(", ")", "/", "(", "mask_img", ".", "shape", "[", "0", "]", "*", "mask_img", ".", "shape", "[", "1", "]", "-", "mask_img", ".", "sum", "(", ")", "/", "255.", ")", "\n", "meanbright", "+=", "brightness", "\n", "", "", "meanbright", "/=", "images_number", "\n", "\n", "imgs_ori", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'OriginalImages/'", "+", "setname", "+", "'/*.jpg'", ")", ")", "\n", "\n", "preprocess_dict", "=", "{", "'0'", ":", "[", "False", ",", "False", ",", "None", "]", ",", "'1'", ":", "[", "False", ",", "False", ",", "meanbright", "]", ",", "'2'", ":", "[", "False", ",", "True", ",", "None", "]", ",", "'3'", ":", "[", "False", ",", "True", ",", "meanbright", "]", ",", "'4'", ":", "[", "True", ",", "False", ",", "None", "]", ",", "'5'", ":", "[", "True", ",", "False", ",", "meanbright", "]", ",", "'6'", ":", "[", "True", ",", "True", ",", "None", "]", ",", "'7'", ":", "[", "True", ",", "True", ",", "meanbright", "]", "}", "\n", "for", "img_path", "in", "imgs_ori", ":", "\n", "            ", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "setname", ",", "'Mask'", ",", "img_name", "+", "'_MASK.tif'", ")", "\n", "clahe_img", "=", "clahe_gridsize", "(", "img_path", ",", "mask_path", ",", "denoise", "=", "preprocess_dict", "[", "preprocess", "]", "[", "0", "]", ",", "contrastenhancement", "=", "preprocess_dict", "[", "preprocess", "]", "[", "1", "]", ",", "brightnessbalance", "=", "preprocess_dict", "[", "preprocess", "]", "[", "2", "]", ",", "cliplimit", "=", "limit", ",", "gridsize", "=", "grid_size", ")", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ",", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ")", ",", "clahe_img", ")", "\n", "\n", "", "", "imgs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ",", "'*.jpg'", ")", ")", "\n", "\n", "imgs", ".", "sort", "(", ")", "\n", "mask_paths", "=", "[", "]", "\n", "train_number", "=", "int", "(", "len", "(", "imgs", ")", "*", "train_ratio", ")", "\n", "eval_number", "=", "int", "(", "len", "(", "imgs", ")", "*", "eval_ratio", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "        ", "image_paths", "=", "imgs", "[", ":", "train_number", "]", "\n", "", "elif", "phase", "==", "'eval'", ":", "\n", "        ", "image_paths", "=", "imgs", "[", "train_number", ":", "]", "\n", "", "else", ":", "\n", "        ", "image_paths", "=", "imgs", "\n", "", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "setname", ")", "\n", "lesions", "=", "[", "'HardExudates'", ",", "'Haemorrhages'", ",", "'Microaneurysms'", ",", "'SoftExudates'", ",", "'Mask'", "]", "\n", "lesion_abbvs", "=", "[", "'EX'", ",", "'HE'", ",", "'MA'", ",", "'SE'", ",", "'MASK'", "]", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "        ", "paths", "=", "[", "]", "\n", "name", "=", "os", ".", "path", ".", "split", "(", "image_path", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "for", "lesion", ",", "lesion_abbv", "in", "zip", "(", "lesions", ",", "lesion_abbvs", ")", ":", "\n", "            ", "candidate_path", "=", "os", ".", "path", ".", "join", "(", "mask_path", ",", "lesion", ",", "name", "+", "'_'", "+", "lesion_abbv", "+", "'.tif'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "candidate_path", ")", ":", "\n", "                ", "paths", ".", "append", "(", "candidate_path", ")", "\n", "", "else", ":", "\n", "                ", "paths", ".", "append", "(", "None", ")", "\n", "", "", "mask_paths", ".", "append", "(", "paths", ")", "\n", "", "return", "image_paths", ",", "mask_paths", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.double_conv.__init__": [[17, 26], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "super", "(", "double_conv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_ch", ",", "out_ch", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_ch", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.double_conv.forward": [[28, 31], ["unet_parts.double_conv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.inconv.__init__": [[34, 37], ["torch.Module.__init__", "unet_parts.double_conv"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "super", "(", "inconv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "double_conv", "(", "in_ch", ",", "out_ch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.inconv.forward": [[38, 41], ["unet_parts.inconv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.down.__init__": [[44, 49], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "unet_parts.double_conv"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "super", "(", "down", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mpconv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", ",", "\n", "double_conv", "(", "in_ch", ",", "out_ch", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.down.forward": [[51, 54], ["unet_parts.down.mpconv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "mpconv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.up.__init__": [[57, 68], ["torch.Module.__init__", "unet_parts.double_conv", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ",", "bilinear", "=", "True", ")", ":", "\n", "        ", "super", "(", "up", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "#  would be a nice idea if the upsampling could be learned too,", "\n", "#  but my machine do not have enough memory to handle all those weights", "\n", "if", "bilinear", ":", "\n", "            ", "self", ".", "up", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "up", "=", "nn", ".", "ConvTranspose2d", "(", "in_ch", "//", "2", ",", "in_ch", "//", "2", ",", "2", ",", "stride", "=", "2", ")", "\n", "\n", "", "self", ".", "conv", "=", "double_conv", "(", "in_ch", ",", "out_ch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.up.forward": [[69, 78], ["unet_parts.up.up", "torch.pad", "torch.pad", "torch.pad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "unet_parts.up.conv", "unet_parts.up.size", "torch.pad.size", "unet_parts.up.size", "torch.pad.size", "int", "int"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.transform.functional.pad"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "        ", "x1", "=", "self", ".", "up", "(", "x1", ")", "\n", "diffX", "=", "x1", ".", "size", "(", ")", "[", "2", "]", "-", "x2", ".", "size", "(", ")", "[", "2", "]", "\n", "diffY", "=", "x1", ".", "size", "(", ")", "[", "3", "]", "-", "x2", ".", "size", "(", ")", "[", "3", "]", "\n", "x2", "=", "F", ".", "pad", "(", "x2", ",", "(", "diffX", "//", "2", ",", "int", "(", "diffX", "/", "2", ")", ",", "\n", "diffY", "//", "2", ",", "int", "(", "diffY", "/", "2", ")", ")", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x2", ",", "x1", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.outconv.__init__": [[81, 84], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "super", "(", "outconv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_parts.outconv.forward": [[85, 88], ["unet_parts.outconv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_model.UNet.__init__": [[13, 25], ["nn.Module.__init__", "unet_parts.inconv", "unet_parts.down", "unet_parts.down", "unet_parts.down", "unet_parts.down", "unet_parts.up", "unet_parts.up", "unet_parts.up", "unet_parts.up", "unet_parts.outconv"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_classes", ")", ":", "\n", "        ", "super", "(", "UNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inc", "=", "inconv", "(", "n_channels", ",", "64", ")", "\n", "self", ".", "down1", "=", "down", "(", "64", ",", "128", ")", "\n", "self", ".", "down2", "=", "down", "(", "128", ",", "256", ")", "\n", "self", ".", "down3", "=", "down", "(", "256", ",", "512", ")", "\n", "self", ".", "down4", "=", "down", "(", "512", ",", "512", ")", "\n", "self", ".", "up1", "=", "up", "(", "1024", ",", "256", ")", "\n", "self", ".", "up2", "=", "up", "(", "512", ",", "128", ")", "\n", "self", ".", "up3", "=", "up", "(", "256", ",", "64", ")", "\n", "self", ".", "up4", "=", "up", "(", "128", ",", "64", ")", "\n", "self", ".", "outc", "=", "outconv", "(", "64", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.unet.unet_model.UNet.forward": [[26, 38], ["unet_model.UNet.inc", "unet_model.UNet.down1", "unet_model.UNet.down2", "unet_model.UNet.down3", "unet_model.UNet.down4", "unet_model.UNet.up1", "unet_model.UNet.up2", "unet_model.UNet.up3", "unet_model.UNet.up4", "unet_model.UNet.outc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "self", ".", "inc", "(", "x", ")", "\n", "x2", "=", "self", ".", "down1", "(", "x1", ")", "\n", "x3", "=", "self", ".", "down2", "(", "x2", ")", "\n", "x4", "=", "self", ".", "down3", "(", "x3", ")", "\n", "x5", "=", "self", ".", "down4", "(", "x4", ")", "\n", "x", "=", "self", ".", "up1", "(", "x5", ",", "x4", ")", "\n", "x", "=", "self", ".", "up2", "(", "x", ",", "x3", ")", "\n", "x", "=", "self", ".", "up3", "(", "x", ",", "x2", ")", "\n", "x", "=", "self", ".", "up4", "(", "x", ",", "x1", ")", "\n", "x", "=", "self", ".", "outc", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.evaluate_model.eval_model": [[41, 81], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "masks_hard[].astype", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "masks_hard[].astype.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax"], "function", ["None"], ["    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "if", "net_name", "==", "'unet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "\n", "", "elif", "net_name", "==", "'hednet'", ":", "\n", "                        ", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "masks_hard", "=", "masks_hard", "[", "0", "]", ".", "astype", "(", "np", ".", "int", ")", "\n", "masks_soft", "=", "masks_soft", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_he.eval_model": [[45, 83], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "\n", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", "[", "0", "]", ",", "masks_soft", "[", "0", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_he.denormalize": [[84, 88], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "denormalize", "(", "inputs", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "FloatTensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "(", "inputs", "*", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "+", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_he.generate_log_images": [[89, 105], ["train_gan_he.denormalize", "masks_pred_softmax_t.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize"], ["", "def", "generate_log_images", "(", "inputs_t", ",", "true_masks_t", ",", "masks_pred_softmax_t", ")", ":", "\n", "    ", "true_masks", "=", "(", "true_masks_t", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "masks_pred_softmax", "=", "(", "masks_pred_softmax_t", ".", "detach", "(", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "inputs", "=", "denormalize", "(", "inputs_t", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "pad_size", "=", "5", "\n", "images_batch", "=", "(", "torch", ".", "ones", "(", "(", "bs", ",", "3", ",", "h", ",", "w", "*", "3", "+", "pad_size", "*", "2", ")", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", ":", "w", "]", "=", "inputs", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "true_masks", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "masks_pred_softmax", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "return", "images_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_he.image_to_patch": [[106, 111], ["image.reshape().permute().reshape", "image.reshape().permute", "image.reshape", "config_gan_he.config.PATCH_SIZE", "config_gan_he.config.PATCH_SIZE", "config_gan_he.config.PATCH_SIZE", "config_gan_he.config.PATCH_SIZE"], "function", ["None"], ["", "def", "image_to_patch", "(", "image", ",", "patch_size", ")", ":", "\n", "    ", "bs", ",", "channel", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "return", "(", "image", ".", "reshape", "(", "(", "bs", ",", "channel", ",", "h", "//", "patch_size", ",", "patch_size", ",", "w", "//", "patch_size", ",", "patch_size", ")", ")", "\n", ".", "permute", "(", "2", ",", "4", ",", "0", ",", "1", ",", "3", ",", "5", ")", "\n", ".", "reshape", "(", "(", "-", "1", ",", "channel", ",", "patch_size", ",", "patch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_he.train_model": [[113, 208], ["model.to", "dnet.to", "range", "print", "g_scheduler.step", "d_scheduler.step", "model.train", "dnet.train", "inputs.to.to", "true_masks.to.to", "masks_pred.permute", "masks_pred.permute.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.reshape", "criterion", "softmax", "dnet", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "d_optimizer.zero_grad", "loss_d.backward", "d_optimizer.step", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "g_optimizer.zero_grad", "g_loss.backward", "g_optimizer.step", "os.path.exists", "os.mkdir", "train_gan_he.eval_model", "model", "true_masks_indices.reshape.long", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_he.image_to_patch", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_he.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_he.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_he.image_to_patch", "image_to_patch.detach", "open", "f.write", "f.write", "f.write", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "str", "str", "model.state_dict", "dnet.state_dict", "g_optimizer.state_dict", "d_optimizer.state_dict", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch"], ["", "def", "train_model", "(", "model", ",", "dnet", ",", "gan_exist", ",", "train_loader", ",", "eval_loader", ",", "criterion", ",", "g_optimizer", ",", "g_scheduler", ",", "d_optimizer", ",", "d_scheduler", ",", "batch_size", ",", "num_epochs", "=", "5", ",", "start_epoch", "=", "0", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "dnet", ".", "to", "(", "device", "=", "device", ")", "\n", "tot_step_count", "=", "start_step", "\n", "\n", "best_ap", "=", "0.", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "start_epoch", "+", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'Starting epoch {}/{}.\\t\\n'", ".", "format", "(", "epoch", "+", "1", ",", "start_epoch", "+", "num_epochs", ")", ")", "\n", "g_scheduler", ".", "step", "(", ")", "\n", "d_scheduler", ".", "step", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "dnet", ".", "train", "(", ")", "\n", "\n", "for", "inputs", ",", "true_masks", "in", "train_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "masks_pred", "=", "model", "(", "inputs", ")", "[", "-", "1", "]", "\n", "masks_pred_transpose", "=", "masks_pred", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "masks_pred_flat", "=", "masks_pred_transpose", ".", "reshape", "(", "-", "1", ",", "masks_pred_transpose", ".", "shape", "[", "-", "1", "]", ")", "\n", "true_masks_indices", "=", "torch", ".", "argmax", "(", "true_masks", ",", "1", ")", "\n", "true_masks_flat", "=", "true_masks_indices", ".", "reshape", "(", "-", "1", ")", "\n", "loss_ce", "=", "criterion", "(", "masks_pred_flat", ",", "true_masks_flat", ".", "long", "(", ")", ")", "\n", "masks_pred_softmax", "=", "softmax", "(", "masks_pred", ")", "\n", "\n", "ce_weight", "=", "1.", "\n", "g_loss", "=", "loss_ce", "*", "ce_weight", "\n", "\n", "# add descriminator loss", "\n", "if", "config", ".", "D_MULTIPLY", ":", "\n", "                ", "input_real", "=", "torch", ".", "matmul", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "matmul", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "", "else", ":", "\n", "                ", "input_real", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "\n", "", "d_real", "=", "dnet", "(", "input_real", ")", "\n", "d_fake", "=", "dnet", "(", "input_fake", ".", "detach", "(", ")", ")", "#do not backward to generator", "\n", "d_real_loss", "=", "torch", ".", "mean", "(", "1", "-", "d_real", ")", "\n", "d_fake_loss", "=", "torch", ".", "mean", "(", "d_fake", ")", "\n", "\n", "#update d loss", "\n", "loss_d", "=", "d_real_loss", "+", "d_fake_loss", "\n", "d_optimizer", ".", "zero_grad", "(", ")", "\n", "loss_d", ".", "backward", "(", ")", "\n", "d_optimizer", ".", "step", "(", ")", "\n", "\n", "#updage g loss", "\n", "d_fake", "=", "dnet", "(", "input_fake", ")", "#do backward to generator", "\n", "loss_gan", "=", "torch", ".", "mean", "(", "1", "-", "d_fake", ")", "\n", "g_loss", "+=", "loss_gan", "*", "gan_weight", "\n", "\n", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "tot_step_count", "+=", "1", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_checkpoint", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_checkpoint", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "40", "==", "0", ":", "\n", "            ", "eval_ap", "=", "eval_model", "(", "model", ",", "eval_loader", ")", "\n", "with", "open", "(", "\"ap_during_learning_he_\"", "+", "gan_exist", "+", "\".txt\"", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"epoch: \"", "+", "str", "(", "epoch", ")", ")", "\n", "f", ".", "write", "(", "\"ap: \"", "+", "str", "(", "eval_ap", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "if", "eval_ap", ">", "best_ap", ":", "\n", "                ", "best_ap", "=", "eval_ap", "\n", "if", "dnet", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'g_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'d_state_dict'", ":", "dnet", ".", "state_dict", "(", ")", ",", "\n", "'g_optimizer'", ":", "g_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'d_optimizer'", ":", "d_optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "dir_checkpoint", ",", "'model_'", "+", "gan_exist", "+", "'.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG16features.__init__": [[26, 60], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "hednet.VGG16features.modules", "isinstance", "m.weight.data.normal_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation", "=", "F", ".", "relu", ")", ":", "\n", "        ", "super", "(", "VGG16features", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "conv1_1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "(", "33", ",", "33", ")", ")", "\n", "self", ".", "conv1_2", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv2_1", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv2_2", "=", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv3_1", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv3_2", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv3_3", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool3", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv4_1", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv4_2", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv4_3", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool4", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv5_1", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv5_2", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv5_3", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "pool5", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", ".5", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG16features.forward": [[61, 104], ["hednet.VGG16features.conv1_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv1_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool1", "hednet.VGG16features.conv2_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv2_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool2", "hednet.VGG16features.conv3_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool3", "hednet.VGG16features.conv4_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool4", "hednet.VGG16features.conv5_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool5"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1_2", "(", "x", ")", "\n", "c1", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool1", "(", "c1", ")", "\n", "\n", "x", "=", "self", ".", "conv2_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_2", "(", "x", ")", "\n", "c2", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool2", "(", "c2", ")", "\n", "\n", "x", "=", "self", ".", "conv3_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_3", "(", "x", ")", "\n", "c3", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool3", "(", "c3", ")", "\n", "\n", "x", "=", "self", ".", "conv4_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_3", "(", "x", ")", "\n", "c4", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool4", "(", "c4", ")", "\n", "\n", "x", "=", "self", ".", "conv5_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_3", "(", "x", ")", "\n", "c5", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool5", "(", "c5", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG16features.forward_hypercol": [[105, 146], ["hednet.VGG16features.conv1_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv1_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool1", "hednet.VGG16features.conv2_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv2_2", "hednet.VGG16features.activation", "hednet.VGG16features.pool2", "hednet.VGG16features.conv3_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv3_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool3", "hednet.VGG16features.conv4_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv4_3", "hednet.VGG16features.activation", "hednet.VGG16features.pool4", "hednet.VGG16features.conv5_1", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_2", "hednet.VGG16features.activation", "hednet.VGG16features.conv5_3", "hednet.VGG16features.activation"], "methods", ["None"], ["", "def", "forward_hypercol", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1_2", "(", "x", ")", "\n", "c1", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool1", "(", "c1", ")", "\n", "\n", "x", "=", "self", ".", "conv2_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_2", "(", "x", ")", "\n", "c2", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool2", "(", "c2", ")", "\n", "\n", "x", "=", "self", ".", "conv3_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_3", "(", "x", ")", "\n", "c3", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool3", "(", "c3", ")", "\n", "\n", "x", "=", "self", ".", "conv4_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4_3", "(", "x", ")", "\n", "c4", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pool4", "(", "c4", ")", "\n", "\n", "x", "=", "self", ".", "conv5_1", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5_3", "(", "x", ")", "\n", "c5", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "return", "c1", ",", "c2", ",", "c3", ",", "c4", ",", "c5", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG.__init__": [[150, 163], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "hednet.VGG._initialize_weights", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG._initialize_weights"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "super", "(", "VGG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "features", "=", "features", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "num_classes", ")", ",", "\n", ")", "\n", "self", ".", "_initialize_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG.forward": [[164, 169], ["hednet.VGG.features", "hednet.VGG.view", "hednet.VGG.classifier", "hednet.VGG.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG._initialize_weights": [[170, 183], ["hednet.VGG.modules", "isinstance", "m.weight.data.normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", ".5", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.__init__": [[228, 259], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "hednet.HNNNet.named_modules", "hednet.vgg16", "m[].weight.data.fill_", "isinstance", "m[].weight.data.normal_", "isinstance", "m[].weight.data.fill_", "m[].bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.vgg16"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "True", ",", "class_number", "=", "2", ")", ":", "\n", "# define VGG architecture and layers", "\n", "        ", "super", "(", "HNNNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# define fully-convolutional layers", "\n", "self", ".", "dsn1", "=", "nn", ".", "Conv2d", "(", "64", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn2", "=", "nn", ".", "Conv2d", "(", "128", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn3", "=", "nn", ".", "Conv2d", "(", "256", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn4", "=", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn5", "=", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "1", ")", "\n", "self", ".", "dsn6", "=", "nn", ".", "Conv2d", "(", "5", ",", "class_number", ",", "1", ")", "\n", "\n", "# define upsampling/deconvolutional layers", "\n", "self", ".", "upscore2", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "upscore3", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "4", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "upscore4", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "8", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "upscore5", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "16", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "# initialize weights of layers", "\n", "for", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "m", "[", "0", "]", "==", "'dsn6'", ":", "\n", "                ", "m", "[", "1", "]", ".", "weight", ".", "data", ".", "fill_", "(", "0.2", ")", "\n", "", "elif", "isinstance", "(", "m", "[", "1", "]", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", "[", "1", "]", ".", "kernel_size", "[", "0", "]", "*", "m", "[", "1", "]", ".", "kernel_size", "[", "1", "]", "*", "m", "[", "1", "]", ".", "out_channels", "\n", "m", "[", "1", "]", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", ".5", ")", "\n", "", "elif", "isinstance", "(", "m", "[", "1", "]", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", "[", "1", "]", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", "[", "1", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "", "_", ",", "VGG16fs", "=", "vgg16", "(", "pretrained", "=", "pretrained", ")", "\n", "self", ".", "VGG16fs", "=", "VGG16fs", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.forward": [[261, 294], ["hednet.HNNNet.VGG16fs.forward_hypercol", "hednet.HNNNet.upscore5", "hednet.HNNNet.crop", "hednet.HNNNet.upscore4", "hednet.HNNNet.crop", "hednet.HNNNet.upscore3", "hednet.HNNNet.crop", "hednet.HNNNet.upscore2", "hednet.HNNNet.crop", "hednet.HNNNet.dsn1", "hednet.HNNNet.crop", "hednet.HNNNet.dsn6", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "x.size", "hednet.HNNNet.dsn5", "hednet.HNNNet.dsn4", "hednet.HNNNet.dsn3", "hednet.HNNNet.dsn2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.VGG16features.forward_hypercol", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "size", "=", "x", ".", "size", "(", ")", "[", "2", ":", "4", "]", "\n", "\n", "# get output from VGG model", "\n", "conv1", ",", "conv2", ",", "conv3", ",", "conv4", ",", "conv5", "=", "self", ".", "VGG16fs", ".", "forward_hypercol", "(", "x", ")", "\n", "\n", "## side output", "\n", "dsn5_up", "=", "self", ".", "upscore5", "(", "self", ".", "dsn5", "(", "conv5", ")", ")", "\n", "d5", "=", "self", ".", "crop", "(", "dsn5_up", ",", "size", ")", "\n", "\n", "dsn4_up", "=", "self", ".", "upscore4", "(", "self", ".", "dsn4", "(", "conv4", ")", ")", "\n", "d4", "=", "self", ".", "crop", "(", "dsn4_up", ",", "size", ")", "\n", "\n", "dsn3_up", "=", "self", ".", "upscore3", "(", "self", ".", "dsn3", "(", "conv3", ")", ")", "\n", "d3", "=", "self", ".", "crop", "(", "dsn3_up", ",", "size", ")", "\n", "\n", "dsn2_up", "=", "self", ".", "upscore2", "(", "self", ".", "dsn2", "(", "conv2", ")", ")", "\n", "d2", "=", "self", ".", "crop", "(", "dsn2_up", ",", "size", ")", "\n", "\n", "dsn1", "=", "self", ".", "dsn1", "(", "conv1", ")", "\n", "d1", "=", "self", ".", "crop", "(", "dsn1", ",", "size", ")", "\n", "\n", "# weighted fusion (with learning fusion weights)", "\n", "d6", "=", "self", ".", "dsn6", "(", "torch", ".", "cat", "(", "(", "d1", ",", "d2", ",", "d3", ",", "d4", ",", "d5", ")", ",", "1", ")", ")", "\n", "\n", "d1", "=", "F", ".", "sigmoid", "(", "d1", ")", "\n", "d2", "=", "F", ".", "sigmoid", "(", "d2", ")", "\n", "d3", "=", "F", ".", "sigmoid", "(", "d3", ")", "\n", "d4", "=", "F", ".", "sigmoid", "(", "d4", ")", "\n", "d5", "=", "F", ".", "sigmoid", "(", "d5", ")", "\n", "#d6 = F.sigmoid(d6)", "\n", "return", "d1", ",", "d2", ",", "d3", ",", "d4", ",", "d5", ",", "d6", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.HNNNet.crop": [[296, 301], ["d.size", "int", "int", "math.floor", "int", "math.floor", "int", "math.floor", "math.floor"], "methods", ["None"], ["", "def", "crop", "(", "self", ",", "d", ",", "size", ")", ":", "\n", "        ", "d_h", ",", "d_w", "=", "d", ".", "size", "(", ")", "[", "2", ":", "4", "]", "\n", "g_h", ",", "g_w", "=", "size", "[", "0", "]", ",", "size", "[", "1", "]", "\n", "d1", "=", "d", "[", ":", ",", ":", ",", "int", "(", "math", ".", "floor", "(", "(", "d_h", "-", "g_h", ")", "/", "2.0", ")", ")", ":", "int", "(", "math", ".", "floor", "(", "(", "d_h", "-", "g_h", ")", "/", "2.0", ")", ")", "+", "g_h", ",", "int", "(", "math", ".", "floor", "(", "(", "d_w", "-", "g_w", ")", "/", "2.0", ")", ")", ":", "int", "(", "math", ".", "floor", "(", "(", "d_w", "-", "g_w", ")", "/", "2.0", ")", ")", "+", "g_w", "]", "\n", "return", "d1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.hednet.vgg16": [[185, 225], ["hednet.VGG16features", "hednet.VGG", "torch.utils.model_zoo.load_url", "torch.utils.model_zoo.load_url", "torch.utils.model_zoo.load_url", "torch.utils.model_zoo.load_url", "set", "torch.utils.model_zoo.load_url.keys", "sorted", "set", "VGG.state_dict().keys", "sorted", "torch.utils.model_zoo.load_url.items", "VGG.load_state_dict", "list", "list", "VGG.state_dict", "int", "sorted.index", "set.add", "set.add", "key.split", "int", "key.split", "key.split", "key.split"], "function", ["None"], ["", "", "", "", "def", "vgg16", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"VGG 16-layer model (configuration \"D\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "VGG16fs", "=", "VGG16features", "(", ")", "\n", "model", "=", "VGG", "(", "VGG16fs", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "torch", ".", "utils", ".", "model_zoo", ".", "load_url", "(", "torchvision", ".", "models", ".", "vgg", ".", "model_urls", "[", "'vgg16'", "]", ",", "'pre-trained'", ")", "\n", "new_state_dict", "=", "{", "}", "\n", "\n", "original_layer_ids", "=", "set", "(", ")", "\n", "# copy the classifier entries and make a mapping for the feature mappings", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "'classifier'", "in", "key", ":", "\n", "                ", "new_state_dict", "[", "key", "]", "=", "state_dict", "[", "key", "]", "\n", "", "elif", "'features'", "in", "key", ":", "\n", "                ", "original_layer_ids", ".", "add", "(", "int", "(", "key", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", ")", "\n", "", "", "sorted_original_layer_ids", "=", "sorted", "(", "list", "(", "original_layer_ids", ")", ")", "\n", "\n", "layer_ids", "=", "set", "(", ")", "\n", "for", "key", "in", "model", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ":", "\n", "            ", "if", "'classifier'", "in", "key", ":", "\n", "                ", "continue", "\n", "", "elif", "'features'", "in", "key", ":", "\n", "                ", "layer_id", "=", "key", ".", "split", "(", "'.'", ")", "[", "1", "]", "\n", "layer_ids", ".", "add", "(", "layer_id", ")", "\n", "", "", "sorted_layer_ids", "=", "sorted", "(", "list", "(", "layer_ids", ")", ")", "\n", "\n", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "'features'", "in", "key", ":", "\n", "                ", "original_layer_id", "=", "int", "(", "key", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", "\n", "original_param_id", "=", "key", ".", "split", "(", "'.'", ")", "[", "2", "]", "\n", "idx", "=", "sorted_original_layer_ids", ".", "index", "(", "original_layer_id", ")", "\n", "new_layer_id", "=", "sorted_layer_ids", "[", "idx", "]", "\n", "new_key", "=", "'features.'", "+", "new_layer_id", "+", "'.'", "+", "original_param_id", "\n", "new_state_dict", "[", "new_key", "]", "=", "value", "\n", "\n", "", "", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "", "return", "model", ",", "VGG16fs", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ma.eval_model": [[45, 83], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", "[", "0", "]", ",", "masks_soft", "[", "0", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ma.denormalize": [[84, 88], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "denormalize", "(", "inputs", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "FloatTensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "(", "inputs", "*", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "+", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ma.generate_log_images": [[89, 105], ["train_gan_ma.denormalize", "masks_pred_softmax_t.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize"], ["", "def", "generate_log_images", "(", "inputs_t", ",", "true_masks_t", ",", "masks_pred_softmax_t", ")", ":", "\n", "    ", "true_masks", "=", "(", "true_masks_t", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "masks_pred_softmax", "=", "(", "masks_pred_softmax_t", ".", "detach", "(", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "inputs", "=", "denormalize", "(", "inputs_t", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "pad_size", "=", "5", "\n", "images_batch", "=", "(", "torch", ".", "ones", "(", "(", "bs", ",", "3", ",", "h", ",", "w", "*", "3", "+", "pad_size", "*", "2", ")", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", ":", "w", "]", "=", "inputs", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "true_masks", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "masks_pred_softmax", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "return", "images_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ma.image_to_patch": [[106, 111], ["image.reshape().permute().reshape", "image.reshape().permute", "image.reshape", "config_gan_ma.config.PATCH_SIZE", "config_gan_ma.config.PATCH_SIZE", "config_gan_ma.config.PATCH_SIZE", "config_gan_ma.config.PATCH_SIZE"], "function", ["None"], ["", "def", "image_to_patch", "(", "image", ",", "patch_size", ")", ":", "\n", "    ", "bs", ",", "channel", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "return", "(", "image", ".", "reshape", "(", "(", "bs", ",", "channel", ",", "h", "//", "patch_size", ",", "patch_size", ",", "w", "//", "patch_size", ",", "patch_size", ")", ")", "\n", ".", "permute", "(", "2", ",", "4", ",", "0", ",", "1", ",", "3", ",", "5", ")", "\n", ".", "reshape", "(", "(", "-", "1", ",", "channel", ",", "patch_size", ",", "patch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ma.train_model": [[113, 208], ["model.to", "dnet.to", "range", "print", "g_scheduler.step", "d_scheduler.step", "model.train", "dnet.train", "inputs.to.to", "true_masks.to.to", "masks_pred.permute", "masks_pred.permute.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.reshape", "criterion", "softmax", "dnet", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "d_optimizer.zero_grad", "loss_d.backward", "d_optimizer.step", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "g_optimizer.zero_grad", "g_loss.backward", "g_optimizer.step", "os.path.exists", "os.mkdir", "train_gan_ma.eval_model", "model", "true_masks_indices.reshape.long", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_ma.image_to_patch", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_ma.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_ma.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_ma.image_to_patch", "image_to_patch.detach", "open", "f.write", "f.write", "f.write", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "str", "str", "model.state_dict", "dnet.state_dict", "g_optimizer.state_dict", "d_optimizer.state_dict", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch"], ["", "def", "train_model", "(", "model", ",", "dnet", ",", "gan_exist", ",", "train_loader", ",", "eval_loader", ",", "criterion", ",", "g_optimizer", ",", "g_scheduler", ",", "d_optimizer", ",", "d_scheduler", ",", "batch_size", ",", "num_epochs", "=", "5", ",", "start_epoch", "=", "0", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "dnet", ".", "to", "(", "device", "=", "device", ")", "\n", "tot_step_count", "=", "start_step", "\n", "\n", "best_ap", "=", "0.", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "start_epoch", "+", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'Starting epoch {}/{}.\\t\\n'", ".", "format", "(", "epoch", "+", "1", ",", "start_epoch", "+", "num_epochs", ")", ")", "\n", "g_scheduler", ".", "step", "(", ")", "\n", "d_scheduler", ".", "step", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "dnet", ".", "train", "(", ")", "\n", "\n", "for", "inputs", ",", "true_masks", "in", "train_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "masks_pred", "=", "model", "(", "inputs", ")", "[", "-", "1", "]", "\n", "\n", "masks_pred_transpose", "=", "masks_pred", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "masks_pred_flat", "=", "masks_pred_transpose", ".", "reshape", "(", "-", "1", ",", "masks_pred_transpose", ".", "shape", "[", "-", "1", "]", ")", "\n", "true_masks_indices", "=", "torch", ".", "argmax", "(", "true_masks", ",", "1", ")", "\n", "true_masks_flat", "=", "true_masks_indices", ".", "reshape", "(", "-", "1", ")", "\n", "loss_ce", "=", "criterion", "(", "masks_pred_flat", ",", "true_masks_flat", ".", "long", "(", ")", ")", "\n", "masks_pred_softmax", "=", "softmax", "(", "masks_pred", ")", "\n", "\n", "ce_weight", "=", "1.", "\n", "g_loss", "=", "loss_ce", "*", "ce_weight", "\n", "\n", "# add descriminator loss", "\n", "if", "config", ".", "D_MULTIPLY", ":", "\n", "                ", "input_real", "=", "torch", ".", "matmul", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "matmul", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "", "else", ":", "\n", "                ", "input_real", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "\n", "", "d_real", "=", "dnet", "(", "input_real", ")", "\n", "d_fake", "=", "dnet", "(", "input_fake", ".", "detach", "(", ")", ")", "#do not backward to generator", "\n", "d_real_loss", "=", "torch", ".", "mean", "(", "1", "-", "d_real", ")", "\n", "d_fake_loss", "=", "torch", ".", "mean", "(", "d_fake", ")", "\n", "\n", "#update d loss", "\n", "loss_d", "=", "d_real_loss", "+", "d_fake_loss", "\n", "d_optimizer", ".", "zero_grad", "(", ")", "\n", "loss_d", ".", "backward", "(", ")", "\n", "d_optimizer", ".", "step", "(", ")", "\n", "\n", "#updage g loss", "\n", "d_fake", "=", "dnet", "(", "input_fake", ")", "#do backward to generator", "\n", "loss_gan", "=", "torch", ".", "mean", "(", "1", "-", "d_fake", ")", "\n", "g_loss", "+=", "loss_gan", "*", "gan_weight", "\n", "\n", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "tot_step_count", "+=", "1", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_checkpoint", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_checkpoint", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "40", "==", "0", ":", "\n", "            ", "eval_ap", "=", "eval_model", "(", "model", ",", "eval_loader", ")", "\n", "with", "open", "(", "\"ap_during_learning_ma_\"", "+", "gan_exist", "+", "\".txt\"", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"epoch: \"", "+", "str", "(", "epoch", ")", ")", "\n", "f", ".", "write", "(", "\"ap: \"", "+", "str", "(", "eval_ap", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "if", "eval_ap", ">", "best_ap", ":", "\n", "                ", "best_ap", "=", "eval_ap", "\n", "if", "dnet", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'g_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'d_state_dict'", ":", "dnet", ".", "state_dict", "(", ")", ",", "\n", "'g_optimizer'", ":", "g_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'d_optimizer'", ":", "d_optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "dir_checkpoint", ",", "'model_'", "+", "gan_exist", "+", "'.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.__init__": [[16, 41], ["len", "len", "zip", "dataset.IDRIDDataset.image_paths.append", "dataset.IDRIDDataset.mask_paths.append", "dataset.IDRIDDataset.images.append", "dataset.IDRIDDataset.masks.append", "dataset.IDRIDDataset.pil_loader", "dataset.IDRIDDataset.pil_loader"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader"], ["    ", "def", "__init__", "(", "self", ",", "image_paths", ",", "mask_paths", "=", "None", ",", "class_id", "=", "0", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_paths: paths to the original images []\n            mask_paths: paths to the mask images, [[]]\n            class_id: id of lesions, 0:ex, 1:he, 2:ma, 3:se\n        \"\"\"", "\n", "assert", "len", "(", "image_paths", ")", "==", "len", "(", "mask_paths", ")", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "mask_paths", "=", "[", "]", "\n", "self", ".", "masks", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "if", "self", ".", "mask_paths", "is", "not", "None", ":", "\n", "            ", "for", "image_path", ",", "mask_path4", "in", "zip", "(", "image_paths", ",", "mask_paths", ")", ":", "\n", "                ", "mask_path", "=", "mask_path4", "[", "class_id", "]", "\n", "if", "mask_path", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "self", ".", "image_paths", ".", "append", "(", "image_path", ")", "\n", "self", ".", "mask_paths", ".", "append", "(", "mask_path", ")", "\n", "self", ".", "images", ".", "append", "(", "self", ".", "pil_loader", "(", "image_path", ")", ")", "\n", "self", ".", "masks", ".", "append", "(", "self", ".", "pil_loader", "(", "mask_path", ")", ")", "\n", "\n", "", "", "", "self", ".", "class_id", "=", "class_id", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.__len__": [[42, 44], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.pil_loader": [[45, 51], ["open", "PIL.Image.open", "PIL.Image.open.convert"], "methods", ["None"], ["", "def", "pil_loader", "(", "self", ",", "image_path", ")", ":", "\n", "        ", "with", "open", "(", "image_path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "h", ",", "w", "=", "img", ".", "size", "\n", "#return img.resize((h//2, w//2)).convert('RGB')", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dataset.IDRIDDataset.__getitem__": [[52, 72], ["numpy.array", "dataset.IDRIDDataset.append", "dataset.IDRIDDataset.transform", "numpy.transpose", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "info", "=", "[", "self", ".", "images", "[", "idx", "]", "]", "\n", "if", "self", ".", "mask_paths", ":", "\n", "            ", "info", ".", "append", "(", "self", ".", "masks", "[", "idx", "]", ")", "\n", "", "if", "self", ".", "transform", ":", "\n", "            ", "info", "=", "self", ".", "transform", "(", "info", ")", "\n", "", "inputs", "=", "np", ".", "array", "(", "info", "[", "0", "]", ")", "\n", "if", "inputs", ".", "shape", "[", "2", "]", "==", "3", ":", "\n", "            ", "inputs", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "info", "[", "0", "]", ")", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "inputs", "=", "inputs", "/", "255.", "\n", "\n", "", "if", "len", "(", "info", ")", ">", "1", ":", "\n", "            ", "mask", "=", "np", ".", "array", "(", "np", ".", "array", "(", "info", "[", "1", "]", ")", ")", "[", ":", ",", ":", ",", "0", "]", "/", "255.0", "\n", "empty_mask", "=", "1", "-", "mask", "\n", "masks", "=", "np", ".", "array", "(", "[", "empty_mask", ",", "mask", "]", ")", "\n", "\n", "return", "inputs", ",", "masks", "\n", "", "else", ":", "\n", "            ", "return", "inputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ex.eval_model": [[46, 83], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", "[", "0", "]", ",", "masks_soft", "[", "0", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ex.denormalize": [[84, 88], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "denormalize", "(", "inputs", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "FloatTensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "(", "inputs", "*", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "+", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ex.generate_log_images": [[89, 105], ["train_gan_ex.denormalize", "masks_pred_softmax_t.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize"], ["", "def", "generate_log_images", "(", "inputs_t", ",", "true_masks_t", ",", "masks_pred_softmax_t", ")", ":", "\n", "    ", "true_masks", "=", "(", "true_masks_t", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "masks_pred_softmax", "=", "(", "masks_pred_softmax_t", ".", "detach", "(", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "inputs", "=", "denormalize", "(", "inputs_t", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "pad_size", "=", "5", "\n", "images_batch", "=", "(", "torch", ".", "ones", "(", "(", "bs", ",", "3", ",", "h", ",", "w", "*", "3", "+", "pad_size", "*", "2", ")", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", ":", "w", "]", "=", "inputs", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "true_masks", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "masks_pred_softmax", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "return", "images_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ex.image_to_patch": [[106, 111], ["image.reshape().permute().reshape", "image.reshape().permute", "image.reshape", "config_gan_ex.config.PATCH_SIZE", "config_gan_ex.config.PATCH_SIZE", "config_gan_ex.config.PATCH_SIZE", "config_gan_ex.config.PATCH_SIZE"], "function", ["None"], ["", "def", "image_to_patch", "(", "image", ",", "patch_size", ")", ":", "\n", "    ", "bs", ",", "channel", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "return", "(", "image", ".", "reshape", "(", "(", "bs", ",", "channel", ",", "h", "//", "patch_size", ",", "patch_size", ",", "w", "//", "patch_size", ",", "patch_size", ")", ")", "\n", ".", "permute", "(", "2", ",", "4", ",", "0", ",", "1", ",", "3", ",", "5", ")", "\n", ".", "reshape", "(", "(", "-", "1", ",", "channel", ",", "patch_size", ",", "patch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_ex.train_model": [[113, 209], ["model.to", "dnet.to", "range", "print", "g_scheduler.step", "d_scheduler.step", "model.train", "dnet.train", "inputs.to.to", "true_masks.to.to", "masks_pred.permute", "masks_pred.permute.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.reshape", "criterion", "softmax", "dnet", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "d_optimizer.zero_grad", "loss_d.backward", "d_optimizer.step", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "g_optimizer.zero_grad", "g_loss.backward", "g_optimizer.step", "os.path.exists", "os.mkdir", "train_gan_ex.eval_model", "model", "true_masks_indices.reshape.long", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_ex.image_to_patch", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_ex.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_ex.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_ex.image_to_patch", "image_to_patch.detach", "open", "f.write", "f.write", "f.write", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "str", "str", "model.state_dict", "dnet.state_dict", "g_optimizer.state_dict", "d_optimizer.state_dict", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch"], ["", "def", "train_model", "(", "model", ",", "dnet", ",", "gan_exist", ",", "train_loader", ",", "eval_loader", ",", "criterion", ",", "g_optimizer", ",", "g_scheduler", ",", "d_optimizer", ",", "d_scheduler", ",", "batch_size", ",", "num_epochs", "=", "5", ",", "start_epoch", "=", "0", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "dnet", ".", "to", "(", "device", "=", "device", ")", "\n", "tot_step_count", "=", "start_step", "\n", "\n", "best_ap", "=", "0.", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "start_epoch", "+", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'Starting epoch {}/{}.\\t\\n'", ".", "format", "(", "epoch", "+", "1", ",", "start_epoch", "+", "num_epochs", ")", ")", "\n", "g_scheduler", ".", "step", "(", ")", "\n", "d_scheduler", ".", "step", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "dnet", ".", "train", "(", ")", "\n", "\n", "for", "inputs", ",", "true_masks", "in", "train_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "masks_pred", "=", "model", "(", "inputs", ")", "[", "-", "1", "]", "\n", "masks_pred_transpose", "=", "masks_pred", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "masks_pred_flat", "=", "masks_pred_transpose", ".", "reshape", "(", "-", "1", ",", "masks_pred_transpose", ".", "shape", "[", "-", "1", "]", ")", "\n", "true_masks_indices", "=", "torch", ".", "argmax", "(", "true_masks", ",", "1", ")", "\n", "true_masks_flat", "=", "true_masks_indices", ".", "reshape", "(", "-", "1", ")", "\n", "loss_ce", "=", "criterion", "(", "masks_pred_flat", ",", "true_masks_flat", ".", "long", "(", ")", ")", "\n", "masks_pred_softmax", "=", "softmax", "(", "masks_pred", ")", "\n", "\n", "# Save images", "\n", "ce_weight", "=", "1.", "\n", "g_loss", "=", "loss_ce", "*", "ce_weight", "\n", "\n", "# add descriminator loss", "\n", "if", "config", ".", "D_MULTIPLY", ":", "\n", "                ", "input_real", "=", "torch", ".", "matmul", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "matmul", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "", "else", ":", "\n", "                ", "input_real", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "\n", "", "d_real", "=", "dnet", "(", "input_real", ")", "\n", "d_fake", "=", "dnet", "(", "input_fake", ".", "detach", "(", ")", ")", "#do not backward to generator", "\n", "d_real_loss", "=", "torch", ".", "mean", "(", "1", "-", "d_real", ")", "\n", "d_fake_loss", "=", "torch", ".", "mean", "(", "d_fake", ")", "\n", "\n", "#update d loss", "\n", "loss_d", "=", "d_real_loss", "+", "d_fake_loss", "\n", "d_optimizer", ".", "zero_grad", "(", ")", "\n", "loss_d", ".", "backward", "(", ")", "\n", "d_optimizer", ".", "step", "(", ")", "\n", "\n", "#updage g loss", "\n", "d_fake", "=", "dnet", "(", "input_fake", ")", "#do backward to generator", "\n", "loss_gan", "=", "torch", ".", "mean", "(", "1", "-", "d_fake", ")", "\n", "g_loss", "+=", "loss_gan", "*", "gan_weight", "\n", "\n", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "tot_step_count", "+=", "1", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_checkpoint", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_checkpoint", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "40", "==", "0", ":", "\n", "            ", "eval_ap", "=", "eval_model", "(", "model", ",", "eval_loader", ")", "\n", "with", "open", "(", "\"ap_during_learning_ex_\"", "+", "gan_exist", "+", "\".txt\"", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"epoch: \"", "+", "str", "(", "epoch", ")", ")", "\n", "f", ".", "write", "(", "\"ap: \"", "+", "str", "(", "eval_ap", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "if", "eval_ap", ">", "best_ap", ":", "\n", "                ", "best_ap", "=", "eval_ap", "\n", "if", "dnet", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'g_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'d_state_dict'", ":", "dnet", ".", "state_dict", "(", ")", ",", "\n", "'g_optimizer'", ":", "g_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'d_optimizer'", ":", "d_optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "dir_checkpoint", ",", "'model_'", "+", "gan_exist", "+", "'.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__": [[15, 36], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "utils.initialize_weights", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.__init__", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.utils.initialize_weights"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", "=", "1", ",", "output_dim", "=", "1", ",", "input_size", "=", "32", ")", ":", "\n", "        ", "super", "(", "DNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "input_size", "=", "input_size", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "input_dim", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "128", "*", "(", "self", ".", "input_size", "//", "4", ")", "*", "(", "self", ".", "input_size", "//", "4", ")", ",", "1024", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "1024", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "output_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "utils", ".", "initialize_weights", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.dnet.DNet.forward": [[37, 43], ["dnet.DNet.conv", "dnet.DNet.view", "dnet.DNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "input", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "128", "*", "(", "self", ".", "input_size", "//", "4", ")", "*", "(", "self", ".", "input_size", "//", "4", ")", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.preprocess.clahe_gridsize": [[17, 51], ["cv2.imread", "cv2.cvtColor", "cv2.split", "cv2.createCLAHE", "cv2.createCLAHE.apply", "cv2.merge", "cv2.cvtColor", "cv2.cvtColor", "cv2.imread", "numpy.uint8", "cv2.fastNlMeansDenoisingColored", "cv2.bilateralFilter", "cv2.cvtColor.sum", "numpy.minimum", "cv2.imread.sum"], "function", ["None"], ["\n", "bgr", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "\n", "# brightness balance.", "\n", "if", "brightnessbalance", ":", "\n", "        ", "gray", "=", "cv2", ".", "cvtColor", "(", "bgr", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "mask_img", "=", "cv2", ".", "imread", "(", "mask_path", ",", "0", ")", "\n", "brightness", "=", "gray", ".", "sum", "(", ")", "/", "(", "mask_img", ".", "shape", "[", "0", "]", "*", "mask_img", ".", "shape", "[", "1", "]", "-", "mask_img", ".", "sum", "(", ")", "/", "255.", ")", "\n", "bgr", "=", "np", ".", "uint8", "(", "np", ".", "minimum", "(", "bgr", "*", "brightnessbalance", "/", "brightness", ",", "255", ")", ")", "\n", "\n", "", "if", "contrastenhancement", ":", "\n", "# illumination correction and contrast enhancement.", "\n", "      ", "lab", "=", "cv2", ".", "cvtColor", "(", "bgr", ",", "cv2", ".", "COLOR_BGR2LAB", ")", "\n", "lab_planes", "=", "cv2", ".", "split", "(", "lab", ")", "\n", "clahe", "=", "cv2", ".", "createCLAHE", "(", "clipLimit", "=", "cliplimit", ",", "tileGridSize", "=", "(", "gridsize", ",", "gridsize", ")", ")", "\n", "lab_planes", "[", "0", "]", "=", "clahe", ".", "apply", "(", "lab_planes", "[", "0", "]", ")", "\n", "lab", "=", "cv2", ".", "merge", "(", "lab_planes", ")", "\n", "bgr", "=", "cv2", ".", "cvtColor", "(", "lab", ",", "cv2", ".", "COLOR_LAB2BGR", ")", "\n", "\n", "", "if", "denoise", ":", "\n", "        ", "bgr", "=", "cv2", ".", "fastNlMeansDenoisingColored", "(", "bgr", ",", "None", ",", "10", ",", "10", ",", "1", ",", "3", ")", "\n", "bgr", "=", "cv2", ".", "bilateralFilter", "(", "bgr", ",", "5", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "bgr", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.utils.initialize_weights": [[15, 26], ["net.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["def", "initialize_weights", "(", "net", ")", ":", "\n", "    ", "for", "m", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.utils.get_images": [[30, 96], ["glob.glob.sort", "int", "int", "os.path.join", "glob.glob", "glob.glob", "zip", "mask_paths.append", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "glob.glob", "os.path.join", "os.path.join", "len", "len", "[].split", "os.path.join", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "glob.glob", "glob.glob.sort", "len", "os.path.join", "os.path.join", "preprocess.clahe_gridsize", "cv2.imwrite", "paths.append", "paths.append", "os.path.join", "os.path.join", "cv2.imread", "cv2.imread", "[].split", "os.path.join", "[].split", "cv2.imread.sum", "os.path.split", "os.path.split", "cv2.imread.sum", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.preprocess.clahe_gridsize"], ["def", "get_images", "(", "image_dir", ",", "preprocess", "=", "'0'", ",", "phase", "=", "'train'", ")", ":", "\n", "    ", "if", "phase", "==", "'train'", "or", "phase", "==", "'eval'", ":", "\n", "        ", "setname", "=", "'TrainingSet'", "\n", "", "elif", "phase", "==", "'test'", ":", "\n", "        ", "setname", "=", "'TestingSet'", "\n", "\n", "", "limit", "=", "2", "\n", "grid_size", "=", "8", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ")", ")", "\n", "\n", "# compute mean brightess", "\n", "meanbright", "=", "0.", "\n", "images_number", "=", "0", "\n", "for", "tempsetname", "in", "[", "'TrainingSet'", ",", "'TestingSet'", "]", ":", "\n", "            ", "imgs_ori", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'OriginalImages/'", "+", "tempsetname", "+", "'/*.jpg'", ")", ")", "\n", "imgs_ori", ".", "sort", "(", ")", "\n", "images_number", "+=", "len", "(", "imgs_ori", ")", "\n", "# mean brightness.", "\n", "for", "img_path", "in", "imgs_ori", ":", "\n", "                ", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "tempsetname", ",", "'Mask'", ",", "img_name", "+", "'_MASK.tif'", ")", "\n", "gray", "=", "cv2", ".", "imread", "(", "img_path", ",", "0", ")", "\n", "mask_img", "=", "cv2", ".", "imread", "(", "mask_path", ",", "0", ")", "\n", "brightness", "=", "gray", ".", "sum", "(", ")", "/", "(", "mask_img", ".", "shape", "[", "0", "]", "*", "mask_img", ".", "shape", "[", "1", "]", "-", "mask_img", ".", "sum", "(", ")", "/", "255.", ")", "\n", "meanbright", "+=", "brightness", "\n", "", "", "meanbright", "/=", "images_number", "\n", "\n", "imgs_ori", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'OriginalImages/'", "+", "setname", "+", "'/*.jpg'", ")", ")", "\n", "\n", "preprocess_dict", "=", "{", "'0'", ":", "[", "False", ",", "False", ",", "None", "]", ",", "'1'", ":", "[", "False", ",", "False", ",", "meanbright", "]", ",", "'2'", ":", "[", "False", ",", "True", ",", "None", "]", ",", "'3'", ":", "[", "False", ",", "True", ",", "meanbright", "]", ",", "'4'", ":", "[", "True", ",", "False", ",", "None", "]", ",", "'5'", ":", "[", "True", ",", "False", ",", "meanbright", "]", ",", "'6'", ":", "[", "True", ",", "True", ",", "None", "]", ",", "'7'", ":", "[", "True", ",", "True", ",", "meanbright", "]", "}", "\n", "for", "img_path", "in", "imgs_ori", ":", "\n", "            ", "img_name", "=", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "setname", ",", "'Mask'", ",", "img_name", "+", "'_MASK.tif'", ")", "\n", "clahe_img", "=", "clahe_gridsize", "(", "img_path", ",", "mask_path", ",", "denoise", "=", "preprocess_dict", "[", "preprocess", "]", "[", "0", "]", ",", "contrastenhancement", "=", "preprocess_dict", "[", "preprocess", "]", "[", "1", "]", ",", "brightnessbalance", "=", "preprocess_dict", "[", "preprocess", "]", "[", "2", "]", ",", "cliplimit", "=", "limit", ",", "gridsize", "=", "grid_size", ")", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ",", "os", ".", "path", ".", "split", "(", "img_path", ")", "[", "-", "1", "]", ")", ",", "clahe_img", ")", "\n", "\n", "", "", "imgs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Images_CLAHE'", "+", "preprocess", ",", "setname", ",", "'*.jpg'", ")", ")", "\n", "\n", "imgs", ".", "sort", "(", ")", "\n", "mask_paths", "=", "[", "]", "\n", "train_number", "=", "int", "(", "len", "(", "imgs", ")", "*", "train_ratio", ")", "\n", "eval_number", "=", "int", "(", "len", "(", "imgs", ")", "*", "eval_ratio", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "        ", "image_paths", "=", "imgs", "[", ":", "train_number", "]", "\n", "", "elif", "phase", "==", "'eval'", ":", "\n", "        ", "image_paths", "=", "imgs", "[", "train_number", ":", "]", "\n", "", "else", ":", "\n", "        ", "image_paths", "=", "imgs", "\n", "", "mask_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'Groundtruths'", ",", "setname", ")", "\n", "lesions", "=", "[", "'HardExudates'", ",", "'Haemorrhages'", ",", "'Microaneurysms'", ",", "'SoftExudates'", ",", "'Mask'", "]", "\n", "lesion_abbvs", "=", "[", "'EX'", ",", "'HE'", ",", "'MA'", ",", "'SE'", ",", "'MASK'", "]", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "        ", "paths", "=", "[", "]", "\n", "name", "=", "os", ".", "path", ".", "split", "(", "image_path", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "for", "lesion", ",", "lesion_abbv", "in", "zip", "(", "lesions", ",", "lesion_abbvs", ")", ":", "\n", "            ", "candidate_path", "=", "os", ".", "path", ".", "join", "(", "mask_path", ",", "lesion", ",", "name", "+", "'_'", "+", "lesion_abbv", "+", "'.tif'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "candidate_path", ")", ":", "\n", "                ", "paths", ".", "append", "(", "candidate_path", ")", "\n", "", "else", ":", "\n", "                ", "paths", ".", "append", "(", "None", ")", "\n", "", "", "mask_paths", ".", "append", "(", "paths", ")", "\n", "", "return", "image_paths", ",", "mask_paths", "\n", "", ""]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model": [[45, 83], ["model.eval", "numpy.array().transpose", "numpy.array().transpose", "numpy.reshape", "numpy.reshape", "sklearn.metrics.average_precision_score", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "inputs.to.to", "true_masks.to.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "softmax().cpu().numpy", "true_masks[].cpu().numpy", "np.reshape.extend", "np.reshape.extend", "numpy.array", "numpy.array", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "min", "min", "softmax().cpu", "true_masks[].cpu", "model", "softmax"], "function", ["None"], ["def", "eval_model", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "masks_soft", "=", "[", "]", "\n", "masks_hard", "=", "[", "]", "\n", "\n", "with", "torch", ".", "set_grad_enabled", "(", "False", ")", ":", "\n", "        ", "for", "inputs", ",", "true_masks", "in", "eval_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "# not ignore the last few patches", "\n", "h_size", "=", "(", "h", "-", "1", ")", "//", "image_size", "+", "1", "\n", "w_size", "=", "(", "w", "-", "1", ")", "//", "image_size", "+", "1", "\n", "masks_pred", "=", "torch", ".", "zeros", "(", "true_masks", ".", "shape", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "for", "i", "in", "range", "(", "h_size", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "w_size", ")", ":", "\n", "                    ", "h_max", "=", "min", "(", "h", ",", "(", "i", "+", "1", ")", "*", "image_size", ")", "\n", "w_max", "=", "min", "(", "w", ",", "(", "j", "+", "1", ")", "*", "image_size", ")", "\n", "inputs_part", "=", "inputs", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "\n", "masks_pred_single", "=", "model", "(", "inputs_part", ")", "[", "-", "1", "]", "\n", "\n", "masks_pred", "[", ":", ",", ":", ",", "i", "*", "image_size", ":", "h_max", ",", "j", "*", "image_size", ":", "w_max", "]", "=", "masks_pred_single", "\n", "\n", "", "", "masks_pred_softmax_batch", "=", "softmax", "(", "masks_pred", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "masks_soft_batch", "=", "masks_pred_softmax_batch", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "masks_hard_batch", "=", "true_masks", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "masks_soft", ".", "extend", "(", "masks_soft_batch", ")", "\n", "masks_hard", ".", "extend", "(", "masks_hard_batch", ")", "\n", "\n", "", "", "masks_soft", "=", "np", ".", "array", "(", "masks_soft", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_hard", "=", "np", ".", "array", "(", "masks_hard", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "masks_soft", "=", "np", ".", "reshape", "(", "masks_soft", ",", "(", "masks_soft", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "masks_hard", "=", "np", ".", "reshape", "(", "masks_hard", ",", "(", "masks_hard", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "ap", "=", "average_precision_score", "(", "masks_hard", "[", "0", "]", ",", "masks_soft", "[", "0", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize": [[84, 88], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "denormalize", "(", "inputs", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "FloatTensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "(", "inputs", "*", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "+", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.generate_log_images": [[89, 105], ["train_gan_se.denormalize", "masks_pred_softmax_t.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.denormalize"], ["", "def", "generate_log_images", "(", "inputs_t", ",", "true_masks_t", ",", "masks_pred_softmax_t", ")", ":", "\n", "    ", "true_masks", "=", "(", "true_masks_t", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "masks_pred_softmax", "=", "(", "masks_pred_softmax_t", ".", "detach", "(", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "inputs", "=", "denormalize", "(", "inputs_t", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "inputs", ".", "shape", "\n", "pad_size", "=", "5", "\n", "images_batch", "=", "(", "torch", ".", "ones", "(", "(", "bs", ",", "3", ",", "h", ",", "w", "*", "3", "+", "pad_size", "*", "2", ")", ")", "*", "255.", ")", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", ":", "w", "]", "=", "inputs", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "+", "pad_size", ":", "w", "*", "2", "+", "pad_size", "]", "=", "true_masks", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "\n", "images_batch", "[", ":", ",", ":", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "0", "\n", "images_batch", "[", ":", ",", "0", ",", ":", ",", "w", "*", "2", "+", "pad_size", "*", "2", ":", "]", "=", "masks_pred_softmax", "[", ":", ",", "1", ",", ":", ",", ":", "]", "\n", "return", "images_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch": [[106, 111], ["image.reshape().permute().reshape", "image.reshape().permute", "image.reshape", "config_gan_se.config.PATCH_SIZE", "config_gan_se.config.PATCH_SIZE", "config_gan_se.config.PATCH_SIZE", "config_gan_se.config.PATCH_SIZE"], "function", ["None"], ["", "def", "image_to_patch", "(", "image", ",", "patch_size", ")", ":", "\n", "    ", "bs", ",", "channel", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "return", "(", "image", ".", "reshape", "(", "(", "bs", ",", "channel", ",", "h", "//", "patch_size", ",", "patch_size", ",", "w", "//", "patch_size", ",", "patch_size", ")", ")", "\n", ".", "permute", "(", "2", ",", "4", ",", "0", ",", "1", ",", "3", ",", "5", ")", "\n", ".", "reshape", "(", "(", "-", "1", ",", "channel", ",", "patch_size", ",", "patch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.train_model": [[113, 208], ["model.to", "dnet.to", "range", "print", "g_scheduler.step", "d_scheduler.step", "model.train", "dnet.train", "inputs.to.to", "true_masks.to.to", "masks_pred.permute", "masks_pred.permute.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.reshape", "criterion", "softmax", "dnet", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "d_optimizer.zero_grad", "loss_d.backward", "d_optimizer.step", "dnet", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "g_optimizer.zero_grad", "g_loss.backward", "g_optimizer.step", "os.path.exists", "os.mkdir", "train_gan_se.eval_model", "model", "true_masks_indices.reshape.long", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_se.image_to_patch", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_gan_se.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_se.image_to_patch", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_gan_se.image_to_patch", "image_to_patch.detach", "open", "f.write", "f.write", "f.write", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "str", "str", "model.state_dict", "dnet.state_dict", "g_optimizer.state_dict", "d_optimizer.state_dict", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.eval_model", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch", "home.repos.pwc.inspect_result.zoujx96_DR-segmentation.HEDNet_cGAN.train_gan_se.image_to_patch"], ["", "def", "train_model", "(", "model", ",", "dnet", ",", "gan_exist", ",", "train_loader", ",", "eval_loader", ",", "criterion", ",", "g_optimizer", ",", "g_scheduler", ",", "d_optimizer", ",", "d_scheduler", ",", "batch_size", ",", "num_epochs", "=", "5", ",", "start_epoch", "=", "0", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "dnet", ".", "to", "(", "device", "=", "device", ")", "\n", "tot_step_count", "=", "start_step", "\n", "\n", "best_ap", "=", "0.", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "start_epoch", "+", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'Starting epoch {}/{}.\\t\\n'", ".", "format", "(", "epoch", "+", "1", ",", "start_epoch", "+", "num_epochs", ")", ")", "\n", "g_scheduler", ".", "step", "(", ")", "\n", "d_scheduler", ".", "step", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "dnet", ".", "train", "(", ")", "\n", "\n", "for", "inputs", ",", "true_masks", "in", "train_loader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "true_masks", "=", "true_masks", ".", "to", "(", "device", "=", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "masks_pred", "=", "model", "(", "inputs", ")", "[", "-", "1", "]", "\n", "\n", "masks_pred_transpose", "=", "masks_pred", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "masks_pred_flat", "=", "masks_pred_transpose", ".", "reshape", "(", "-", "1", ",", "masks_pred_transpose", ".", "shape", "[", "-", "1", "]", ")", "\n", "true_masks_indices", "=", "torch", ".", "argmax", "(", "true_masks", ",", "1", ")", "\n", "true_masks_flat", "=", "true_masks_indices", ".", "reshape", "(", "-", "1", ")", "\n", "loss_ce", "=", "criterion", "(", "masks_pred_flat", ",", "true_masks_flat", ".", "long", "(", ")", ")", "\n", "masks_pred_softmax", "=", "softmax", "(", "masks_pred", ")", "\n", "\n", "ce_weight", "=", "1.", "\n", "g_loss", "=", "loss_ce", "*", "ce_weight", "\n", "\n", "# add descriminator loss", "\n", "if", "config", ".", "D_MULTIPLY", ":", "\n", "                ", "input_real", "=", "torch", ".", "matmul", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "matmul", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "", "else", ":", "\n", "                ", "input_real", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "true_masks", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_real", "=", "image_to_patch", "(", "input_real", ",", "config", ".", "PATCH_SIZE", ")", "\n", "input_fake", "=", "torch", ".", "cat", "(", "(", "inputs", ",", "masks_pred_softmax", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ")", ",", "1", ")", "\n", "input_fake", "=", "image_to_patch", "(", "input_fake", ",", "config", ".", "PATCH_SIZE", ")", "\n", "\n", "", "d_real", "=", "dnet", "(", "input_real", ")", "\n", "d_fake", "=", "dnet", "(", "input_fake", ".", "detach", "(", ")", ")", "#do not backward to generator", "\n", "d_real_loss", "=", "torch", ".", "mean", "(", "1", "-", "d_real", ")", "\n", "d_fake_loss", "=", "torch", ".", "mean", "(", "d_fake", ")", "\n", "\n", "#update d loss", "\n", "loss_d", "=", "d_real_loss", "+", "d_fake_loss", "\n", "d_optimizer", ".", "zero_grad", "(", ")", "\n", "loss_d", ".", "backward", "(", ")", "\n", "d_optimizer", ".", "step", "(", ")", "\n", "\n", "#updage g loss", "\n", "d_fake", "=", "dnet", "(", "input_fake", ")", "#do backward to generator", "\n", "loss_gan", "=", "torch", ".", "mean", "(", "1", "-", "d_fake", ")", "\n", "g_loss", "+=", "loss_gan", "*", "gan_weight", "\n", "\n", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "tot_step_count", "+=", "1", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_checkpoint", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_checkpoint", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "40", "==", "0", ":", "\n", "            ", "eval_ap", "=", "eval_model", "(", "model", ",", "eval_loader", ")", "\n", "with", "open", "(", "\"ap_during_learning_se_\"", "+", "gan_exist", "+", "\".txt\"", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"epoch: \"", "+", "str", "(", "epoch", ")", ")", "\n", "f", ".", "write", "(", "\"ap: \"", "+", "str", "(", "eval_ap", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "if", "eval_ap", ">", "best_ap", ":", "\n", "                ", "best_ap", "=", "eval_ap", "\n", "if", "dnet", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'g_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'d_state_dict'", ":", "dnet", ".", "state_dict", "(", ")", ",", "\n", "'g_optimizer'", ":", "g_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'d_optimizer'", ":", "d_optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "tot_step_count", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "dir_checkpoint", ",", "'model_'", "+", "gan_exist", "+", "'.pth.tar'", ")", ")", "\n", "\n"]]}