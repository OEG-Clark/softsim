{"home.repos.pwc.inspect_result.idiap_drill.None.splitcross.SplitCrossEntropyLoss.__init__": [[28, 42], ["torch.Module.__init__", "collections.defaultdict", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "splits", ",", "verbose", "=", "False", ")", ":", "\n", "# We assume splits is [0, split1, split2, N] where N >= |V|", "\n", "# For example, a vocab of 1000 words may have splits [0] + [100, 500] + [inf]", "\n", "        ", "super", "(", "SplitCrossEntropyLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "splits", "=", "[", "0", "]", "+", "splits", "+", "[", "100", "*", "1000000", "]", "\n", "self", ".", "nsplits", "=", "len", "(", "self", ".", "splits", ")", "-", "1", "\n", "self", ".", "stats", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "verbose", "=", "verbose", "\n", "# Each of the splits that aren't in the head require a pretend token, we'll call them tombstones", "\n", "# The probability given to this tombstone is the probability of selecting an item from the represented split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "            ", "self", ".", "tail_vectors", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "nsplits", "-", "1", ",", "hidden_size", ")", ")", "\n", "self", ".", "tail_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "nsplits", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.splitcross.SplitCrossEntropyLoss.logprob": [[43, 88], ["torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "list", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "results.append", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "softmaxed_head_res[].contiguous", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "results.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "softmaxed_head_res[].contiguous.view"], "methods", ["None"], ["", "", "def", "logprob", "(", "self", ",", "weight", ",", "bias", ",", "hiddens", ",", "splits", "=", "None", ",", "softmaxed_head_res", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "# First we perform the first softmax on the head vocabulary and the tombstones", "\n", "        ", "if", "softmaxed_head_res", "is", "None", ":", "\n", "            ", "start", ",", "end", "=", "self", ".", "splits", "[", "0", "]", ",", "self", ".", "splits", "[", "1", "]", "\n", "head_weight", "=", "None", "if", "end", "-", "start", "==", "0", "else", "weight", "[", "start", ":", "end", "]", "\n", "head_bias", "=", "None", "if", "end", "-", "start", "==", "0", "else", "bias", "[", "start", ":", "end", "]", "\n", "# We only add the tombstones if we have more than one split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "                ", "head_weight", "=", "self", ".", "tail_vectors", "if", "head_weight", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_weight", ",", "self", ".", "tail_vectors", "]", ")", "\n", "head_bias", "=", "self", ".", "tail_bias", "if", "head_bias", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_bias", ",", "self", ".", "tail_bias", "]", ")", "\n", "\n", "# Perform the softmax calculation for the word vectors in the head for all splits", "\n", "# We need to guard against empty splits as torch.cat does not like random lists", "\n", "", "head_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "hiddens", ",", "head_weight", ",", "bias", "=", "head_bias", ")", "\n", "softmaxed_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "head_res", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "if", "splits", "is", "None", ":", "\n", "            ", "splits", "=", "list", "(", "range", "(", "self", ".", "nsplits", ")", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "running_offset", "=", "0", "\n", "for", "idx", "in", "splits", ":", "\n", "\n", "# For those targets in the head (idx == 0) we only need to return their loss", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "results", ".", "append", "(", "softmaxed_head_res", "[", ":", ",", ":", "-", "(", "self", ".", "nsplits", "-", "1", ")", "]", ")", "\n", "\n", "# If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)", "\n", "", "else", ":", "\n", "                ", "start", ",", "end", "=", "self", ".", "splits", "[", "idx", "]", ",", "self", ".", "splits", "[", "idx", "+", "1", "]", "\n", "tail_weight", "=", "weight", "[", "start", ":", "end", "]", "\n", "tail_bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "\n", "# Calculate the softmax for the words in the tombstone", "\n", "tail_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "hiddens", ",", "tail_weight", ",", "bias", "=", "tail_bias", ")", "\n", "\n", "# Then we calculate p(tombstone) * p(word in tombstone)", "\n", "# Adding is equivalent to multiplication in log space", "\n", "head_entropy", "=", "(", "softmaxed_head_res", "[", ":", ",", "-", "idx", "]", ")", ".", "contiguous", "(", ")", "\n", "tail_entropy", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "tail_res", ",", "dim", "=", "-", "1", ")", "\n", "results", ".", "append", "(", "head_entropy", ".", "view", "(", "-", "1", ",", "1", ")", "+", "tail_entropy", ")", "\n", "\n", "", "", "if", "len", "(", "results", ")", ">", "1", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "results", ",", "dim", "=", "1", ")", "\n", "", "return", "results", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.splitcross.SplitCrossEntropyLoss.split_on_targets": [[89, 122], ["range", "range", "split_targets.append", "split_hiddens.append", "sum", "len", "split_targets.append", "split_hiddens.append", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "hiddens.masked_select().view", "hiddens.size", "len", "hiddens.masked_select", "tmp_mask.unsqueeze().expand_as", "tmp_mask.unsqueeze"], "methods", ["None"], ["", "def", "split_on_targets", "(", "self", ",", "hiddens", ",", "targets", ")", ":", "\n", "# Split the targets into those in the head and in the tail", "\n", "        ", "split_targets", "=", "[", "]", "\n", "split_hiddens", "=", "[", "]", "\n", "\n", "# Determine to which split each element belongs (for each start split value, add 1 if equal or greater)", "\n", "# This method appears slower at least for WT-103 values for approx softmax", "\n", "#masks = [(targets >= self.splits[idx]).view(1, -1) for idx in range(1, self.nsplits)]", "\n", "#mask = torch.sum(torch.cat(masks, dim=0), dim=0)", "\n", "###", "\n", "# This is equally fast for smaller splits as method below but scales linearly", "\n", "mask", "=", "None", "\n", "for", "idx", "in", "range", "(", "1", ",", "self", ".", "nsplits", ")", ":", "\n", "            ", "partial_mask", "=", "targets", ">=", "self", ".", "splits", "[", "idx", "]", "\n", "mask", "=", "mask", "+", "partial_mask", "if", "mask", "is", "not", "None", "else", "partial_mask", "\n", "###", "\n", "#masks = torch.stack([targets] * (self.nsplits - 1))", "\n", "#mask = torch.sum(masks >= self.split_starts, dim=0)", "\n", "", "for", "idx", "in", "range", "(", "self", ".", "nsplits", ")", ":", "\n", "# If there are no splits, avoid costly masked select", "\n", "            ", "if", "self", ".", "nsplits", "==", "1", ":", "\n", "                ", "split_targets", ",", "split_hiddens", "=", "[", "targets", "]", ",", "[", "hiddens", "]", "\n", "continue", "\n", "# If all the words are covered by earlier targets, we have empties so later stages don't freak out", "\n", "", "if", "sum", "(", "len", "(", "t", ")", "for", "t", "in", "split_targets", ")", "==", "len", "(", "targets", ")", ":", "\n", "                ", "split_targets", ".", "append", "(", "[", "]", ")", "\n", "split_hiddens", ".", "append", "(", "[", "]", ")", "\n", "continue", "\n", "# Are you in our split?", "\n", "", "tmp_mask", "=", "mask", "==", "idx", "\n", "split_targets", ".", "append", "(", "torch", ".", "masked_select", "(", "targets", ",", "tmp_mask", ")", ")", "\n", "split_hiddens", ".", "append", "(", "hiddens", ".", "masked_select", "(", "tmp_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "hiddens", ")", ")", ".", "view", "(", "-", "1", ",", "hiddens", ".", "size", "(", "1", ")", ")", ")", "\n", "", "return", "split_targets", ",", "split_hiddens", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.splitcross.SplitCrossEntropyLoss.forward": [[123, 187], ["splitcross.SplitCrossEntropyLoss.split_on_targets", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "range", "sorted", "print", "len", "hiddens.view.view.view", "splitcross.SplitCrossEntropyLoss.stats[].append", "len", "print", "hiddens.view.view.size", "hiddens.view.view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "splitcross.SplitCrossEntropyLoss.logprob", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "entropy.float().sum", "range", "len", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "splitcross.SplitCrossEntropyLoss.stats[].append", "entropy.float().sum", "len", "int", "torch.cat.size", "torch.cat.size", "head_weight.size", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "entropy.float", "numpy.mean", "len", "split_targets[].view", "len", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "entropy.float", "split_hiddens[].size", "tail_weight.size"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.None.splitcross.SplitCrossEntropyLoss.split_on_targets", "home.repos.pwc.inspect_result.idiap_drill.None.splitcross.SplitCrossEntropyLoss.logprob"], ["", "def", "forward", "(", "self", ",", "weight", ",", "bias", ",", "hiddens", ",", "targets", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "            ", "for", "idx", "in", "sorted", "(", "self", ".", "stats", ")", ":", "\n", "                ", "print", "(", "'{}: {}'", ".", "format", "(", "idx", ",", "int", "(", "np", ".", "mean", "(", "self", ".", "stats", "[", "idx", "]", ")", ")", ")", ")", "\n", "", "print", "(", ")", "\n", "\n", "", "total_loss", "=", "None", "\n", "if", "len", "(", "hiddens", ".", "size", "(", ")", ")", ">", "2", ":", "hiddens", "=", "hiddens", ".", "view", "(", "-", "1", ",", "hiddens", ".", "size", "(", "2", ")", ")", "\n", "\n", "split_targets", ",", "split_hiddens", "=", "self", ".", "split_on_targets", "(", "hiddens", ",", "targets", ")", "\n", "\n", "# First we perform the first softmax on the head vocabulary and the tombstones", "\n", "start", ",", "end", "=", "self", ".", "splits", "[", "0", "]", ",", "self", ".", "splits", "[", "1", "]", "\n", "head_weight", "=", "None", "if", "end", "-", "start", "==", "0", "else", "weight", "[", "start", ":", "end", "]", "\n", "head_bias", "=", "None", "if", "end", "-", "start", "==", "0", "else", "bias", "[", "start", ":", "end", "]", "\n", "\n", "# We only add the tombstones if we have more than one split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "            ", "head_weight", "=", "self", ".", "tail_vectors", "if", "head_weight", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_weight", ",", "self", ".", "tail_vectors", "]", ")", "\n", "head_bias", "=", "self", ".", "tail_bias", "if", "head_bias", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_bias", ",", "self", ".", "tail_bias", "]", ")", "\n", "\n", "# Perform the softmax calculation for the word vectors in the head for all splits", "\n", "# We need to guard against empty splits as torch.cat does not like random lists", "\n", "", "combo", "=", "torch", ".", "cat", "(", "[", "split_hiddens", "[", "i", "]", "for", "i", "in", "range", "(", "self", ".", "nsplits", ")", "if", "len", "(", "split_hiddens", "[", "i", "]", ")", "]", ")", "\n", "###", "\n", "all_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "combo", ",", "head_weight", ",", "bias", "=", "head_bias", ")", "\n", "softmaxed_all_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "all_head_res", ",", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "            ", "self", ".", "stats", "[", "0", "]", ".", "append", "(", "combo", ".", "size", "(", ")", "[", "0", "]", "*", "head_weight", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "running_offset", "=", "0", "\n", "for", "idx", "in", "range", "(", "self", ".", "nsplits", ")", ":", "\n", "# If there are no targets for this split, continue", "\n", "            ", "if", "len", "(", "split_targets", "[", "idx", "]", ")", "==", "0", ":", "continue", "\n", "\n", "# For those targets in the head (idx == 0) we only need to return their loss", "\n", "if", "idx", "==", "0", ":", "\n", "                ", "softmaxed_head_res", "=", "softmaxed_all_head_res", "[", "running_offset", ":", "running_offset", "+", "len", "(", "split_hiddens", "[", "idx", "]", ")", "]", "\n", "entropy", "=", "-", "torch", ".", "gather", "(", "softmaxed_head_res", ",", "dim", "=", "1", ",", "index", "=", "split_targets", "[", "idx", "]", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "# If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)", "\n", "", "else", ":", "\n", "                ", "softmaxed_head_res", "=", "softmaxed_all_head_res", "[", "running_offset", ":", "running_offset", "+", "len", "(", "split_hiddens", "[", "idx", "]", ")", "]", "\n", "\n", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "                    ", "start", ",", "end", "=", "self", ".", "splits", "[", "idx", "]", ",", "self", ".", "splits", "[", "idx", "+", "1", "]", "\n", "tail_weight", "=", "weight", "[", "start", ":", "end", "]", "\n", "self", ".", "stats", "[", "idx", "]", ".", "append", "(", "split_hiddens", "[", "idx", "]", ".", "size", "(", ")", "[", "0", "]", "*", "tail_weight", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "# Calculate the softmax for the words in the tombstone", "\n", "", "tail_res", "=", "self", ".", "logprob", "(", "weight", ",", "bias", ",", "split_hiddens", "[", "idx", "]", ",", "splits", "=", "[", "idx", "]", ",", "softmaxed_head_res", "=", "softmaxed_head_res", ")", "\n", "\n", "# Then we calculate p(tombstone) * p(word in tombstone)", "\n", "# Adding is equivalent to multiplication in log space", "\n", "head_entropy", "=", "softmaxed_head_res", "[", ":", ",", "-", "idx", "]", "\n", "# All indices are shifted - if the first split handles [0,...,499] then the 500th in the second split will be 0 indexed", "\n", "indices", "=", "(", "split_targets", "[", "idx", "]", "-", "self", ".", "splits", "[", "idx", "]", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# Warning: if you don't squeeze, you get an N x 1 return, which acts oddly with broadcasting", "\n", "tail_entropy", "=", "torch", ".", "gather", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "tail_res", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "1", ",", "index", "=", "indices", ")", ".", "squeeze", "(", ")", "\n", "entropy", "=", "-", "(", "head_entropy", "+", "tail_entropy", ")", "\n", "###", "\n", "", "running_offset", "+=", "len", "(", "split_hiddens", "[", "idx", "]", ")", "\n", "total_loss", "=", "entropy", ".", "float", "(", ")", ".", "sum", "(", ")", "if", "total_loss", "is", "None", "else", "total_loss", "+", "entropy", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "\n", "", "return", "(", "total_loss", "/", "len", "(", "targets", ")", ")", ".", "type_as", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.main.logging": [[123, 128], ["print", "open", "f_log.write", "os.path.join", "os.path.join", "str", "model"], "function", ["None"], ["", "", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "    ", "print", "(", "s", ")", "\n", "if", "log_", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'log.txt'", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "            ", "f_log", ".", "write", "(", "str", "(", "s", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.main.model_save": [[142, 144], ["utils.save_checkpoint"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.utils.save_checkpoint"], ["", "", "def", "model_save", "(", "model", ",", "criterion", ",", "optimizer", ",", "save", ")", ":", "\n", "    ", "save_checkpoint", "(", "model", ",", "criterion", ",", "optimizer", ",", "save", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.main.model_load": [[145, 153], ["open", "torch.load", "torch.load", "open", "torch.load", "torch.load", "open", "torch.load", "torch.load"], "function", ["None"], ["", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "global", "model", ",", "criterion", ",", "optimizer", "\n", "with", "open", "(", "fn", "+", "'/model.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "fn", "+", "'/criterion.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "criterion", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "fn", "+", "'/optimizer.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.main.evaluate": [[231, 244], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "utils.repackage_hidden", "total_loss.item", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "weight", ",", "bias", ",", "output", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.main.train": [[246, 299], ["time.time", "len", "model.init_hidden", "model.reset", "max", "model.train", "utils.get_batch", "utils.repackage_hidden", "optimizer.zero_grad", "model", "criterion", "loss.backward", "optimizer.step", "int", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "main.logging", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "sum", "sum", "total_loss.item", "time.time", "math.exp", "len", "math.log", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.finetune.train", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.finetune.logging"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "data", ",", "targets", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ",", "train", "=", "True", ")", "\n", "raw_loss", "=", "criterion", "(", "weight", ",", "bias", ",", "output", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "if", "args", ".", "clip", ":", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.embed_regularize.embedded_dropout": [[22, 40], ["torch.nn.functional.embedding", "embed.weight.data.new().resize_().bernoulli_().expand_as", "scale.expand_as", "embed.weight.data.new().resize_().bernoulli_", "embed.weight.data.new().resize_", "embed.weight.data.new", "embed.weight.size"], "function", ["None"], ["def", "embedded_dropout", "(", "embed", ",", "words", ",", "dropout", "=", "0.1", ",", "scale", "=", "None", ")", ":", "\n", "  ", "if", "dropout", ":", "\n", "    ", "mask", "=", "embed", ".", "weight", ".", "data", ".", "new", "(", ")", ".", "resize_", "(", "(", "embed", ".", "weight", ".", "size", "(", "0", ")", ",", "1", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", ".", "expand_as", "(", "embed", ".", "weight", ")", "/", "(", "1", "-", "dropout", ")", "\n", "masked_embed_weight", "=", "mask", "*", "embed", ".", "weight", "\n", "", "else", ":", "\n", "    ", "masked_embed_weight", "=", "embed", ".", "weight", "\n", "", "if", "scale", ":", "\n", "    ", "masked_embed_weight", "=", "scale", ".", "expand_as", "(", "masked_embed_weight", ")", "*", "masked_embed_weight", "\n", "\n", "", "padding_idx", "=", "embed", ".", "padding_idx", "\n", "if", "padding_idx", "is", "None", ":", "\n", "      ", "padding_idx", "=", "-", "1", "\n", "\n", "", "X", "=", "torch", ".", "nn", ".", "functional", ".", "embedding", "(", "words", ",", "masked_embed_weight", ",", "\n", "padding_idx", ",", "embed", ".", "max_norm", ",", "embed", ".", "norm_type", ",", "\n", "embed", ".", "scale_grad_by_freq", ",", "embed", ".", "sparse", "\n", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop.__init__": [[23, 30], ["super().__init__", "weight_drop.WeightDrop._setup"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__", "home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop._setup"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "weights", ",", "dropout", "=", "0", ",", "variational", "=", "False", ")", ":", "\n", "        ", "super", "(", "WeightDrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "variational", "=", "variational", "\n", "self", ".", "_setup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop.widget_demagnetizer_y2k_edition": [[31, 36], ["None"], "methods", ["None"], ["", "def", "widget_demagnetizer_y2k_edition", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# We need to replace flatten_parameters with a nothing function", "\n", "# It must be a function rather than a lambda as otherwise pickling explodes", "\n", "# We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop._setup": [[37, 47], ["issubclass", "type", "print", "getattr", "weight_drop.WeightDrop.module.register_parameter", "torch.nn.Parameter"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "# Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN", "\n", "        ", "if", "issubclass", "(", "type", "(", "self", ".", "module", ")", ",", "torch", ".", "nn", ".", "RNNBase", ")", ":", "\n", "            ", "self", ".", "module", ".", "flatten_parameters", "=", "self", ".", "widget_demagnetizer_y2k_edition", "\n", "\n", "", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "print", "(", "'Applying weight drop of {} to {}'", ".", "format", "(", "self", ".", "dropout", ",", "name_w", ")", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", ")", "\n", "del", "self", ".", "module", ".", "_parameters", "[", "name_w", "]", "\n", "self", ".", "module", ".", "register_parameter", "(", "name_w", "+", "'_raw'", ",", "Parameter", "(", "w", ".", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop._setweights": [[48, 60], ["getattr", "setattr", "torch.autograd.Variable", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.ones", "mask.cuda.cuda.cuda", "mask.cuda.cuda.expand_as", "getattr.size"], "methods", ["None"], ["", "", "def", "_setweights", "(", "self", ")", ":", "\n", "        ", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", "+", "'_raw'", ")", "\n", "w", "=", "None", "\n", "if", "self", ".", "variational", ":", "\n", "                ", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "ones", "(", "raw_w", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "if", "raw_w", ".", "is_cuda", ":", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "True", ")", "\n", "w", "=", "mask", ".", "expand_as", "(", "raw_w", ")", "*", "raw_w", "\n", "", "else", ":", "\n", "                ", "w", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "raw_w", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "", "setattr", "(", "self", ".", "module", ",", "name_w", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop.forward": [[61, 64], ["weight_drop.WeightDrop._setweights", "weight_drop.WeightDrop.module.forward"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.None.weight_drop.WeightDrop._setweights", "home.repos.pwc.inspect_result.idiap_drill.None.locked_dropout.LockedDropout.forward"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_setweights", "(", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.dynamiceval.batchify": [[79, 89], ["data.cuda.narrow", "data.cuda.view().t().contiguous", "data.cuda.size", "data.cuda.cuda", "data.cuda.view().t", "data.cuda.view"], "function", ["None"], ["def", "batchify", "(", "data", ",", "bsz", ")", ":", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "    ", "nbatch", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "nbatch", "*", "bsz", ")", "\n", "# Evenly divide the data across the bsz batches.", "\n", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "#######################################################################", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.dynamiceval.repackage_hidden": [[91, 97], ["isinstance", "isinstance", "tuple", "h.detach", "dynamiceval.repackage_hidden"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["", "def", "repackage_hidden", "(", "h", ")", ":", "\n", "    ", "\"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"", "\n", "if", "isinstance", "(", "h", ",", "tuple", ")", "or", "isinstance", "(", "h", ",", "list", ")", ":", "\n", "        ", "return", "tuple", "(", "repackage_hidden", "(", "v", ")", "for", "v", "in", "h", ")", "\n", "", "else", ":", "\n", "        ", "return", "h", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.dynamiceval.get_batch": [[99, 104], ["min", "torch.autograd.Variable", "torch.autograd.Variable", "source[].view", "len"], "function", ["None"], ["", "", "def", "get_batch", "(", "source", ",", "i", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "seq_len", "=", "min", "(", "args", ".", "bptt", ",", "len", "(", "source", ")", "-", "1", "-", "i", ")", "\n", "data", "=", "Variable", "(", "source", "[", "i", ":", "i", "+", "seq_len", "]", ",", "volatile", "=", "evaluation", ")", "\n", "target", "=", "Variable", "(", "source", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "data", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.dynamiceval.gradstat": [[105, 174], ["time.time", "len", "model.init_hidden", "model.parameters", "model.parameters", "model.parameters", "model.reset", "model.train", "dynamiceval.get_batch", "dynamiceval.repackage_hidden", "model.zero_grad", "model", "criterion", "criterion.backward", "model.parameters", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "math.sqrt", "math.sqrt", "print", "print", "print", "torch.mm", "torch.mm", "output.view", "train_data.size", "weight.t", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.finetune.train", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["", "def", "gradstat", "(", ")", ":", "\n", "\n", "    ", "if", "args", ".", "QRNN", ":", "\n", "        ", "model", ".", "reset", "(", ")", "\n", "\n", "", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "MS", "=", "0", "*", "param", ".", "data", "\n", "\n", "\n", "", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "seq_len", "=", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "use_dropout", "=", "False", "\n", "data", ",", "targets", "=", "get_batch", "(", "train_data", ",", "i", ")", "\n", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#assumes model has atleast 2 returns, and first is output and second is hidden", "\n", "#returns = model(data, hidden)", "\n", "#output = returns[0]", "\n", "#hidden = returns[1]", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "output", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "\n", "\n", "loss", "=", "criterion", "(", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "MS", "=", "param", ".", "MS", "+", "param", ".", "grad", ".", "data", "*", "param", ".", "grad", ".", "data", "\n", "\n", "", "total_loss", "+=", "loss", ".", "data", "\n", "\n", "batch", "+=", "1", "\n", "\n", "\n", "i", "+=", "seq_len", "\n", "if", "args", ".", "max_batches", ">", "0", ":", "\n", "            ", "if", "batch", ">=", "args", ".", "max_batches", ":", "\n", "                ", "break", "\n", "", "", "", "gsum", "=", "0", "\n", "count", "=", "0", "\n", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "\n", "        ", "param", ".", "MS", "=", "torch", ".", "sqrt", "(", "param", ".", "MS", "/", "batch", ")", "\n", "\n", "gsum", "+=", "torch", ".", "mean", "(", "param", ".", "MS", ")", "\n", "count", "+=", "1", "\n", "", "gsum", "/=", "count", "\n", "if", "args", ".", "oldhyper", ":", "\n", "        ", "args", ".", "lamb", "/=", "count", "\n", "args", ".", "lr", "/=", "math", ".", "sqrt", "(", "batch", ")", "\n", "args", ".", "epsilon", "/=", "math", ".", "sqrt", "(", "batch", ")", "\n", "print", "(", "\"transformed lambda: \"", "+", "str", "(", "args", ".", "lamb", ")", ")", "\n", "print", "(", "\"transformed lr: \"", "+", "str", "(", "args", ".", "lr", ")", ")", "\n", "print", "(", "\"transformed epsilon: \"", "+", "str", "(", "args", ".", "epsilon", ")", ")", "\n", "\n", "\n", "", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "decrate", "=", "param", ".", "MS", "/", "gsum", "\n", "param", ".", "data0", "=", "1", "*", "param", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.dynamiceval.evaluate": [[175, 253], ["model.parameters", "len", "model.init_hidden", "torch.exp", "torch.exp", "model.reset", "model.train", "dynamiceval.get_batch", "dynamiceval.repackage_hidden", "model.zero_grad", "model", "criterion", "criterion.backward", "model.parameters", "torch.exp.cpu().numpy", "torch.exp.numpy", "param.decrate.cpu().numpy", "numpy.nonzero", "torch.from_numpy().type", "torch.from_numpy().type", "param.decrate.numpy", "numpy.nonzero", "torch.from_numpy().type", "torch.from_numpy().type", "eval_data.size", "torch.mm", "torch.mm", "output.view", "eval_data.size", "weight.t", "torch.exp.cpu", "param.decrate.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "eval_data.size"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.finetune.train", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["", "", "def", "evaluate", "(", ")", ":", "\n", "\n", "    ", "if", "args", ".", "QRNN", ":", "\n", "       ", "model", ".", "reset", "(", ")", "\n", "#clips decay rates at 1/lamb", "\n", "#otherwise scaled decay rates can be greater than 1", "\n", "#would cause decay updates to overshoot", "\n", "", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "args", ".", "cuda", ":", "\n", "            ", "decratenp", "=", "param", ".", "decrate", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ind", "=", "np", ".", "nonzero", "(", "decratenp", ">", "(", "1", "/", "lamb", ")", ")", "\n", "decratenp", "[", "ind", "]", "=", "(", "1", "/", "lamb", ")", "\n", "param", ".", "decrate", "=", "torch", ".", "from_numpy", "(", "decratenp", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "\n", "", "else", ":", "\n", "            ", "decratenp", "=", "param", ".", "decrate", ".", "numpy", "(", ")", "\n", "ind", "=", "np", ".", "nonzero", "(", "decratenp", ">", "(", "1", "/", "lamb", ")", ")", "\n", "decratenp", "[", "ind", "]", "=", "(", "1", "/", "lamb", ")", "\n", "param", ".", "decrate", "=", "torch", ".", "from_numpy", "(", "decratenp", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "\n", "", "", "total_loss", "=", "0", "\n", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "last", "=", "False", "\n", "seq_len", "=", "args", ".", "bptt", "\n", "seq_len0", "=", "seq_len", "\n", "#loops through data", "\n", "while", "i", "<", "eval_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "\n", "        ", "model", ".", "train", "(", ")", "\n", "model", ".", "use_dropout", "=", "False", "\n", "\n", "#gets last chunk of seqlence if seqlen doesn't divide full sequence cleanly", "\n", "if", "(", "i", "+", "seq_len", ")", ">=", "eval_data", ".", "size", "(", "0", ")", ":", "\n", "            ", "if", "last", ":", "\n", "                ", "break", "\n", "", "seq_len", "=", "eval_data", ".", "size", "(", "0", ")", "-", "i", "-", "1", "\n", "last", "=", "True", "\n", "\n", "", "data", ",", "targets", "=", "get_batch", "(", "eval_data", ",", "i", ")", "\n", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "#assumes model has atleast 2 returns, and first is output and second is hidden", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "output", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "loss", "=", "criterion", "(", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", ",", "targets", ")", "\n", "\n", "#compute gradient on sequence segment loss", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "#update rule", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "dW", "=", "lamb", "*", "param", ".", "decrate", "*", "(", "param", ".", "data0", "-", "param", ".", "data", ")", "-", "lr", "*", "param", ".", "grad", ".", "data", "/", "(", "param", ".", "MS", "+", "epsilon", ")", "\n", "param", ".", "data", "+=", "dW", "\n", "\n", "#seq_len/seq_len0 will be 1 except for last sequence", "\n", "#for last sequence, we downweight if sequence is shorter", "\n", "", "total_loss", "+=", "(", "seq_len", "/", "seq_len0", ")", "*", "loss", ".", "data", "\n", "batch", "+=", "(", "seq_len", "/", "seq_len0", ")", "\n", "i", "+=", "seq_len", "\n", "\n", "#since entropy of first token was never measured", "\n", "#can conservatively measure with uniform distribution", "\n", "#makes very little difference, usually < 0.01 perplexity point", "\n", "#total_loss += (1/seq_len0)*torch.log(torch.from_numpy(np.array([ntokens])).type(torch.cuda.FloatTensor))", "\n", "#batch+=(1/seq_len0)", "\n", "\n", "", "perp", "=", "torch", ".", "exp", "(", "total_loss", "/", "batch", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "return", "perp", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "perp", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.data.Dictionary.__init__": [[25, 30], ["collections.Counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.data.Dictionary.add_word": [[31, 39], ["data.Dictionary.idx2word.append", "len"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "idx2word", ")", "-", "1", "\n", "", "token_id", "=", "self", ".", "word2idx", "[", "word", "]", "\n", "self", ".", "counter", "[", "token_id", "]", "+=", "1", "\n", "self", ".", "total", "+=", "1", "\n", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.data.Dictionary.__len__": [[40, 42], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.data.Corpus.__init__": [[45, 50], ["data.Dictionary", "data.Corpus.tokenize", "data.Corpus.tokenize", "data.Corpus.tokenize", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.idiap_drill.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.idiap_drill.None.data.Corpus.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "Dictionary", "(", ")", "\n", "self", ".", "train", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "valid", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.data.Corpus.tokenize": [[51, 74], ["os.path.exists", "open", "open", "torch.LongTensor", "len", "line.split", "data.Corpus.dictionary.add_word", "line.split"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.None.data.Dictionary.add_word"], ["", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "tokens", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "tokens", "+=", "len", "(", "words", ")", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n", "# Tokenize file content", "\n", "", "", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ids", "=", "torch", ".", "LongTensor", "(", "tokens", ")", "\n", "token", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "ids", "[", "token", "]", "=", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "token", "+=", "1", "\n", "\n", "", "", "", "return", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.idiap_drill.None.finetune.logging": [[117, 122], ["print", "open", "f_log.write", "os.path.join", "str"], "function", ["None"], ["def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "    ", "print", "(", "s", ")", "\n", "if", "log_", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", "+", "'/log-finetuned.txt'", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "            ", "f_log", ".", "write", "(", "str", "(", "s", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.finetune.store_datadist": [[161, 186], ["model.eval", "model.init_hidden", "tables.open_file", "tables.Float64Atom", "tables.open_file.create_earray", "range", "tables.open_file.close", "model.reset", "utils.get_batch", "model", "utils.repackage_hidden", "f.create_earray.append", "data_source.size", "torch.mm", "torch.mm", "torch.LogSoftmax", "datadist.detach().cpu().numpy", "weight.t", "datadist.detach().cpu", "datadist.detach"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["def", "store_datadist", "(", "data_source", ",", "model", ",", "batch_size", "=", "10", ",", "fname", "=", "'datamatrix.h5'", ")", ":", "\n", "    ", "\"\"\"\n       Store the log-probability matrix for a given method.\n    \"\"\"", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "model", ".", "eval", "(", ")", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# Initialize a data matrix structure which can be stored directly to the disk.", "\n", "f", "=", "tables", ".", "open_file", "(", "filename", ",", "mode", "=", "'w'", ")", "\n", "atom", "=", "tables", ".", "Float64Atom", "(", ")", "\n", "array_c", "=", "f", ".", "create_earray", "(", "f", ".", "root", ",", "'data'", ",", "atom", ",", "(", "0", ",", "10000", ")", ")", "\n", "\n", "# Add a row sequentially to the matrix for each different context.", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "pred_targets", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "datadist", "=", "nn", ".", "LogSoftmax", "(", ")", "(", "pred_targets", ")", "\n", "array_c", ".", "append", "(", "datadist", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# Close file.", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.finetune.store_word_cediff": [[187, 215], ["model.eval", "model.init_hidden", "range", "pickle.dump", "model.reset", "utils.get_batch", "model", "enumerate", "utils.repackage_hidden", "open", "data_source.size", "torch.mm", "torch.mm", "weight.t", "criterion", "vocab[].append", "target.tolist", "target_loss.tolist", "target_loss.tolist"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["", "def", "store_word_cediff", "(", "data_source", ",", "model", ",", "batch_size", "=", "10", ",", "fname", "=", "'out'", ")", ":", "\n", "    ", "\"\"\"\n       Store the cross-entropy loss per word in the vocabulary.\n    \"\"\"", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "model", ".", "eval", "(", ")", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# Initialize vocabulary structure to store the crossentropy losses.", "\n", "vocab", ",", "words", "=", "{", "}", ",", "corpus", ".", "dictionary", ".", "idx2word", "\n", "\n", "# Add the loss per word in the vocabulary structure for each different context.", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "pred_targets", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "for", "j", ",", "target", "in", "enumerate", "(", "targets", ")", ":", "\n", "            ", "target_loss", "=", "criterion", "(", "pred_targets", "[", "j", ":", "j", "+", "1", "]", ",", "targets", "[", "j", ":", "j", "+", "1", "]", ")", ".", "data", "\n", "word", "=", "words", "[", "target", ".", "tolist", "(", ")", "]", "\n", "if", "word", "in", "vocab", ":", "\n", "                ", "vocab", "[", "word", "]", ".", "append", "(", "target_loss", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "vocab", "[", "word", "]", "=", "[", "target_loss", ".", "tolist", "(", ")", "]", "\n", "", "", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "\n", "# Store the vocabulary to the disk.", "\n", "", "pickle", ".", "dump", "(", "vocab", ",", "open", "(", "fname", "+", "'.pkl'", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.finetune.evaluate": [[216, 230], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "utils.repackage_hidden", "len", "data_source.size", "torch.mm", "torch.mm", "len", "weight.t", "criterion"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["", "def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "pred_targets", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "pred_targets", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", "[", "0", "]", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.finetune.train": [[231, 287], ["time.time", "len", "model.init_hidden", "model.reset", "max", "min", "model.train", "utils.get_batch", "utils.repackage_hidden", "optimizer.zero_grad", "model", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer.step", "int", "torch.mm", "torch.mm", "sum", "sum", "model.parameters", "finetune.logging", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "weight.t", "time.time", "math.exp", "dropped_rnn_h.pow().mean", "len", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.idiap_drill.None.finetune.train", "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch", "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.idiap_drill.None.finetune.logging"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "seq_len", "=", "min", "(", "seq_len", ",", "args", ".", "bptt", "+", "10", ")", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "use_dropout", "=", "True", "\n", "data", ",", "targets", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "\n", "pred_targets", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "raw_loss", "=", "criterion", "(", "pred_targets", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activation Regularization", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", "[", "0", "]", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.__init__": [[28, 110], ["torch.Module.__init__", "locked_dropout.LockedDropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "model.RNNModel.init_weights", "torch.Dropout", "torch.Dropout", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.RNNModel.encoder_projs.append", "range", "weight_drop.WeightDrop", "range", "weight_drop.WeightDrop", "QRNNLayer", "weight_drop.WeightDrop", "ValueError", "torch.Linear", "torch.Linear", "eval", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "exec", "exec", "model.RNNModel.hidden_projs.append", "eval", "range", "torch.Linear", "torch.Linear", "eval", "torch.Linear", "torch.Linear", "exec", "exec", "eval"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_weights"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "ntoken", ",", "ninp", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "0.5", ",", "dropouth", "=", "0.5", ",", "dropouti", "=", "0.5", ",", "dropoute", "=", "0.1", ",", "wdrop", "=", "0", ",", "tie_weights", "=", "False", ",", "joint_emb", "=", "None", ",", "joint_emb_depth", "=", "0", ",", "joint_emb_dense", "=", "False", ",", "joint_emb_dual", "=", "True", ",", "joint_dropout", "=", "0.2", ",", "joint_emb_activation", "=", "'Sigmoid'", ",", "joint_locked_dropout", "=", "False", ",", "joint_residual_prev", "=", "False", ",", "joint_noresid", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_dropout", "=", "True", "\n", "self", ".", "lockdrop", "=", "LockedDropout", "(", ")", "\n", "self", ".", "idrop", "=", "nn", ".", "Dropout", "(", "dropouti", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "self", ".", "hdrop", "=", "nn", ".", "Dropout", "(", "dropouth", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "ninp", ")", "\n", "assert", "rnn_type", "in", "[", "'LSTM'", ",", "'QRNN'", ",", "'GRU'", "]", ",", "'RNN type is not supported'", "\n", "if", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "LSTM", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "(", "ninp", "if", "tie_weights", "or", "(", "joint_emb", "is", "not", "None", ")", "else", "nhid", ")", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "wdrop", ":", "\n", "                ", "self", ".", "rnns", "=", "[", "WeightDrop", "(", "rnn", ",", "[", "'weight_hh_l0'", "]", ",", "dropout", "=", "wdrop", "if", "self", ".", "use_dropout", "else", "0", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "", "if", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "GRU", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "ninp", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "wdrop", ":", "\n", "                ", "self", ".", "rnns", "=", "[", "WeightDrop", "(", "rnn", ",", "[", "'weight_hh_l0'", "]", ",", "dropout", "=", "wdrop", "if", "self", ".", "use_dropout", "else", "0", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "", "elif", "rnn_type", "==", "'QRNN'", ":", "\n", "            ", "from", "torchqrnn", "import", "QRNNLayer", "\n", "self", ".", "rnns", "=", "[", "QRNNLayer", "(", "input_size", "=", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "hidden_size", "=", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "(", "ninp", "if", "tie_weights", "else", "nhid", ")", ",", "save_prev_x", "=", "True", ",", "zoneout", "=", "0", ",", "window", "=", "2", "if", "l", "==", "0", "else", "1", ",", "output_gate", "=", "True", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "                ", "rnn", ".", "linear", "=", "WeightDrop", "(", "rnn", ".", "linear", ",", "[", "'weight'", "]", ",", "dropout", "=", "wdrop", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "", "", "print", "(", "self", ".", "rnns", ")", "\n", "self", ".", "rnns", "=", "torch", ".", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "\n", "if", "joint_emb", "is", "None", ":", "\n", "            ", "if", "tie_weights", ":", "\n", "                ", "if", "nhid", "!=", "ninp", ":", "\n", "                    ", "raise", "ValueError", "(", "'When using the tied flag, nhid must be equal to emsize'", ")", "\n", "", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "ninp", ",", "ntoken", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "self", ".", "encoder", ".", "weight", "\n", "", "else", ":", "\n", "                ", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nhid", ",", "ntoken", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "dropjoint", "=", "nn", ".", "Dropout", "(", "joint_dropout", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "\n", "# Define the first layer of the label encoder network", "\n", "if", "joint_emb_activation", "!=", "\"Linear\"", ":", "\n", "                ", "self", ".", "joint_encoder_proj_0", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "ninp", ",", "joint_emb", ",", "bias", "=", "True", ")", ",", "eval", "(", "\"nn.%s()\"", "%", "joint_emb_activation", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "joint_encoder_proj_0", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "ninp", ",", "joint_emb", ",", "bias", "=", "True", ")", ")", "\n", "", "self", ".", "encoder_projs", "=", "[", "self", ".", "joint_encoder_proj_0", "]", "\n", "\n", "# (Optional) Define the first layer of the input encoder network", "\n", "if", "joint_emb_dual", ":", "\n", "                ", "if", "joint_emb_activation", "!=", "\"Linear\"", ":", "\n", "                    ", "self", ".", "joint_hidden_proj_0", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "ninp", ",", "joint_emb", ",", "bias", "=", "True", ")", ",", "eval", "(", "\"nn.%s()\"", "%", "joint_emb_activation", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "joint_hidden_proj_0", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "ninp", ",", "joint_emb", ",", "bias", "=", "True", ")", ")", "\n", "", "self", ".", "hidden_projs", "=", "[", "self", ".", "joint_hidden_proj_0", "]", "\n", "# Define the subsequent layers for the input and label encoder networks", "\n", "", "for", "i", "in", "range", "(", "joint_emb_depth", "-", "1", ")", ":", "\n", "                ", "if", "joint_emb_activation", "!=", "\"Linear\"", ":", "\n", "                    ", "exec", "(", "\"self.joint_encoder_proj_%d = nn.Sequential(nn.Linear(joint_emb, joint_emb, bias=True), nn.%s())\"", "%", "(", "i", "+", "1", ",", "joint_emb_activation", ")", ")", "\n", "", "else", ":", "\n", "                    ", "exec", "(", "\"self.joint_encoder_proj_%d = nn.Sequential(nn.Linear(joint_emb, joint_emb, bias=True)\"", ")", "\n", "", "if", "joint_emb_dual", ":", "\n", "                    ", "if", "joint_emb_activation", "!=", "\"Linear\"", ":", "\n", "                        ", "exec", "(", "\"self.joint_hidden_proj_%d = nn.Sequential(nn.Linear(joint_emb, joint_emb, bias=True), nn.%s())\"", "%", "(", "i", "+", "1", ",", "joint_emb_activation", ")", ")", "\n", "", "else", ":", "\n", "                        ", "exec", "(", "\"self.joint_hidden_proj_%d = nn.Sequential(nn.Linear(joint_emb, joint_emb, bias=True)\"", ")", "\n", "", "self", ".", "hidden_projs", ".", "append", "(", "eval", "(", "\"self.joint_hidden_proj_%d\"", "%", "(", "i", "+", "1", ")", ")", ")", "\n", "", "self", ".", "encoder_projs", ".", "append", "(", "eval", "(", "\"self.joint_encoder_proj_%d\"", "%", "(", "i", "+", "1", ")", ")", ")", "\n", "", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Linear", "(", "ntoken", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "ninp", "=", "ninp", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropouti", "=", "dropouti", "\n", "self", ".", "dropouth", "=", "dropouth", "\n", "self", ".", "dropoute", "=", "dropoute", "\n", "self", ".", "ntoken", "=", "ntoken", "\n", "self", ".", "tie_weights", "=", "tie_weights", "\n", "self", ".", "joint_emb", "=", "joint_emb", "\n", "self", ".", "joint_emb_depth", "=", "joint_emb_depth", "\n", "self", ".", "joint_emb_dual", "=", "joint_emb_dual", "\n", "self", ".", "joint_dropout", "=", "joint_dropout", "\n", "self", ".", "joint_locked_dropout", "=", "joint_locked_dropout", "\n", "self", ".", "joint_residual_prev", "=", "joint_residual_prev", "\n", "self", ".", "joint_noresid", "=", "joint_noresid", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset": [[111, 113], ["r.reset"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "rnn_type", "==", "'QRNN'", ":", "[", "r", ".", "reset", "(", ")", "for", "r", "in", "self", ".", "rnns", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_weights": [[114, 127], ["model.RNNModel.encoder.weight.data.uniform_", "hasattr", "hasattr", "hasattr", "model.RNNModel.decoder.bias.data.fill_", "model.RNNModel.decoder.weight.data.uniform_", "range", "model.RNNModel.bias.weight.data.fill_", "[].weight.data.uniform_", "[].weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "if", "hasattr", "(", "self", ",", "'decoder'", ")", ":", "\n", "            ", "self", ".", "decoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "if", "hasattr", "(", "self", ",", "'encoder_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "joint_emb_depth", ")", ":", "\n", "                ", "if", "self", ".", "joint_emb_dual", ":", "\n", "                    ", "self", ".", "hidden_projs", "[", "i", "]", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "self", ".", "encoder_projs", "[", "i", "]", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "", "if", "hasattr", "(", "self", ",", "'bias'", ")", ":", "\n", "            ", "self", ".", "bias", ".", "weight", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.init_hidden": [[128, 137], ["next", "model.RNNModel.parameters", "weight.new().zero_", "weight.new().zero_", "range", "weight.new().zero_", "range", "weight.new", "weight.new", "weight.new"], "methods", ["None"], ["", "", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "[", "(", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "or", "(", "self", ".", "joint_emb", "is", "not", "None", ")", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", ",", "\n", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "or", "(", "self", ".", "joint_emb", "is", "not", "None", ")", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", "\n", "", "elif", "self", ".", "rnn_type", "==", "'QRNN'", "or", "self", ".", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "return", "[", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "or", "(", "self", ".", "joint_emb", "is", "not", "None", ")", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.forward": [[138, 168], ["embed_regularize.embedded_dropout", "model.RNNModel.lockdrop", "enumerate", "model.RNNModel.lockdrop", "outputs.append", "model.RNNModel.view", "rnn", "new_hidden.append", "raw_outputs.append", "model.RNNModel.size", "model.RNNModel.apply_drill", "model.RNNModel.lockdrop", "outputs.append", "model.RNNModel.size", "model.RNNModel.size"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.None.embed_regularize.embedded_dropout", "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.apply_drill"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "return_h", "=", "False", ",", "train", "=", "False", ")", ":", "\n", "        ", "emb", "=", "embedded_dropout", "(", "self", ".", "encoder", ",", "input", ",", "dropout", "=", "self", ".", "dropoute", "if", "self", ".", "training", "and", "self", ".", "use_dropout", "else", "0", ")", "\n", "emb", "=", "self", ".", "lockdrop", "(", "emb", ",", "self", ".", "dropouti", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "raw_output", "=", "emb", "\n", "new_hidden", "=", "[", "]", "\n", "raw_outputs", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "l", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnns", ")", ":", "\n", "            ", "current_input", "=", "raw_output", "\n", "raw_output", ",", "new_h", "=", "rnn", "(", "raw_output", ",", "hidden", "[", "l", "]", ")", "\n", "new_hidden", ".", "append", "(", "new_h", ")", "\n", "raw_outputs", ".", "append", "(", "raw_output", ")", "\n", "\n", "if", "l", "!=", "self", ".", "nlayers", "-", "1", ":", "\n", "                ", "raw_output", "=", "self", ".", "lockdrop", "(", "raw_output", ",", "self", ".", "dropouth", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "outputs", ".", "append", "(", "raw_output", ")", "\n", "\n", "", "", "hidden", "=", "new_hidden", "\n", "output", "=", "self", ".", "lockdrop", "(", "raw_output", ",", "self", ".", "dropout", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "result", "=", "output", ".", "view", "(", "output", ".", "size", "(", "0", ")", "*", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "\n", "weight", "=", "self", ".", "encoder", ".", "weight", "if", "self", ".", "tie_weights", "or", "self", ".", "joint_emb", "is", "not", "None", "else", "self", ".", "decoder", ".", "weight", "\n", "bias", "=", "self", ".", "decoder", ".", "bias", "if", "self", ".", "tie_weights", "or", "self", ".", "joint_emb", "is", "None", "else", "self", ".", "bias", ".", "weight", "\n", "\n", "if", "self", ".", "joint_emb", "is", "not", "None", ":", "\n", "            ", "result", ",", "weight", "=", "self", ".", "apply_drill", "(", "output", ",", "weight", ")", "\n", "\n", "", "if", "return_h", ":", "\n", "            ", "return", "result", ",", "weight", ",", "bias", ",", "hidden", ",", "raw_outputs", ",", "outputs", "\n", "", "return", "result", ",", "weight", ",", "bias", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.model.RNNModel.apply_drill": [[169, 207], ["output.view.view.view", "range", "prevs_hidden_out[].view", "prevs_encoder_out.append", "model.RNNModel.lockdrop().view", "prevs_hidden_out.append", "model.RNNModel.dropjoint", "model.RNNModel.lockdrop", "model.RNNModel.lockdrop().view", "model.RNNModel.dropjoint", "prevs_encoder_out[].view", "model.RNNModel.lockdrop", "prevs_hidden_out[].view"], "methods", ["None"], ["", "def", "apply_drill", "(", "self", ",", "output", ",", "weight", ")", ":", "\n", "        ", "origshape", "=", "output", ".", "shape", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "self", ".", "ninp", ")", "\n", "prevs_hidden_out", "=", "[", "output", "]", "\n", "prevs_encoder_out", "=", "[", "weight", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "joint_emb_depth", ")", ":", "\n", "# Forward through the label encoder network", "\n", "            ", "if", "self", ".", "joint_locked_dropout", ":", "\n", "                ", "cur_weight", "=", "self", ".", "lockdrop", "(", "prevs_encoder_out", "[", "i", "]", ".", "view", "(", "self", ".", "ntoken", ",", "1", ",", "self", ".", "ninp", ")", ",", "self", ".", "joint_dropout", "if", "self", ".", "use_dropout", "else", "0", ")", ".", "view", "(", "self", ".", "ntoken", ",", "self", ".", "ninp", ")", "\n", "", "else", ":", "\n", "                ", "cur_weight", "=", "self", ".", "dropjoint", "(", "prevs_encoder_out", "[", "i", "]", ")", "if", "self", ".", "use_dropout", "else", "prevs_encoder_out", "[", "i", "]", "\n", "", "cur_weight_proj", "=", "self", ".", "encoder_projs", "[", "i", "]", "(", "cur_weight", ")", "\n", "\n", "if", "i", ">", "0", "and", "self", ".", "joint_residual_prev", ":", "\n", "                ", "cur_weight_proj", "=", "cur_weight_proj", "+", "prevs_encoder_out", "[", "i", "]", "\n", "\n", "", "if", "not", "self", ".", "joint_noresid", ":", "\n", "                ", "cur_weight_proj", "=", "cur_weight_proj", "+", "weight", "\n", "\n", "# (Optional) Forward through the input encoder network", "\n", "", "if", "self", ".", "joint_emb_dual", ":", "\n", "                ", "if", "self", ".", "joint_locked_dropout", ":", "\n", "                    ", "cur_output", "=", "self", ".", "lockdrop", "(", "prevs_hidden_out", "[", "i", "]", ".", "view", "(", "origshape", ")", ",", "self", ".", "joint_dropout", "if", "self", ".", "use_dropout", "else", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "ninp", ")", "if", "i", ">", "0", "else", "prevs_hidden_out", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "cur_output", "=", "self", ".", "dropjoint", "(", "prevs_hidden_out", "[", "i", "]", ")", "if", "i", ">", "0", "and", "self", ".", "use_dropout", "else", "prevs_hidden_out", "[", "i", "]", "\n", "", "cur_output_proj", "=", "self", ".", "hidden_projs", "[", "i", "]", "(", "cur_output", ")", "\n", "\n", "if", "i", ">", "0", "and", "self", ".", "joint_residual_prev", ":", "\n", "                    ", "cur_output_proj", "=", "cur_output_proj", "+", "prevs_hidden_out", "[", "i", "]", "\n", "\n", "", "if", "not", "self", ".", "joint_noresid", ":", "\n", "                    ", "cur_output_proj", "=", "cur_output_proj", "+", "output", "\n", "\n", "", "prevs_hidden_out", ".", "append", "(", "cur_output_proj", ")", "\n", "", "prevs_encoder_out", ".", "append", "(", "cur_weight_proj", ")", "\n", "", "h_final", "=", "prevs_hidden_out", "[", "-", "1", "]", ".", "view", "(", "-", "1", ",", "self", ".", "ninp", ")", "\n", "E_final", "=", "prevs_encoder_out", "[", "-", "1", "]", "\n", "return", "h_final", ",", "E_final", "\n", "", "", ""]], "home.repos.pwc.inspect_result.idiap_drill.None.locked_dropout.LockedDropout.__init__": [[24, 26], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.locked_dropout.LockedDropout.forward": [[27, 34], ["x.data.new().bernoulli_", "mask.expand_as.expand_as.expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "dropout", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ",", "requires_grad", "=", "False", ")", "/", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden": [[21, 28], ["isinstance", "h.detach", "tuple", "utils.repackage_hidden"], "function", ["home.repos.pwc.inspect_result.idiap_drill.None.utils.repackage_hidden"], ["def", "repackage_hidden", "(", "h", ")", ":", "\n", "    ", "\"\"\"Wraps hidden states in new Tensors,\n    to detach them from their history.\"\"\"", "\n", "if", "isinstance", "(", "h", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "h", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tuple", "(", "repackage_hidden", "(", "v", ")", "for", "v", "in", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.utils.batchify": [[30, 40], ["data.cuda.narrow", "data.cuda.view().t().contiguous", "data.cuda.size", "data.cuda.cuda", "data.cuda.view().t", "data.cuda.view"], "function", ["None"], ["", "", "def", "batchify", "(", "data", ",", "bsz", ",", "args", ")", ":", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "    ", "nbatch", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "nbatch", "*", "bsz", ")", "\n", "# Evenly divide the data across the bsz batches.", "\n", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.utils.get_batch": [[42, 47], ["min", "source[].view", "len"], "function", ["None"], ["", "def", "get_batch", "(", "source", ",", "i", ",", "args", ",", "seq_len", "=", "None", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "seq_len", "=", "min", "(", "seq_len", "if", "seq_len", "else", "args", ".", "bptt", ",", "len", "(", "source", ")", "-", "1", "-", "i", ")", "\n", "data", "=", "source", "[", "i", ":", "i", "+", "seq_len", "]", "\n", "target", "=", "source", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", ".", "view", "(", "-", "1", ")", "\n", "return", "data", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.utils.create_exp_dir": [[49, 59], ["print", "os.path.exists", "os.mkdir", "os.mkdir", "os.path.join", "os.path.join", "shutil.copyfile", "os.path.basename"], "function", ["None"], ["", "def", "create_exp_dir", "(", "path", ",", "scripts_to_save", "=", "None", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "\n", "", "print", "(", "'Experiment dir : {}'", ".", "format", "(", "path", ")", ")", "\n", "if", "scripts_to_save", "is", "not", "None", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'scripts'", ")", ")", "\n", "for", "script", "in", "scripts_to_save", ":", "\n", "            ", "dst_file", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'scripts'", ",", "os", ".", "path", ".", "basename", "(", "script", ")", ")", "\n", "shutil", ".", "copyfile", "(", "script", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.None.utils.save_checkpoint": [[60, 69], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "", "def", "save_checkpoint", "(", "model", ",", "criterion", ",", "optimizer", ",", "path", ",", "finetune", "=", "False", ")", ":", "\n", "    ", "if", "finetune", ":", "\n", "        ", "torch", ".", "save", "(", "model", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'finetune_model.pt'", ")", ")", "\n", "torch", ".", "save", "(", "criterion", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'finetune_criterion.pt'", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'finetune_optimizer.pt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "save", "(", "model", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'model.pt'", ")", ")", "\n", "torch", ".", "save", "(", "criterion", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'criterion.pt'", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'optimizer.pt'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpFormatter._format_usage": [[677, 679], ["None"], "methods", ["None"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpFormatter.format_help": [[680, 684], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpFormatter.start_section": [[685, 688], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpFormatter._format_action": [[689, 701], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpAction.__init__": [[706, 715], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "configargparse", ".", "SUPPRESS", ",", "default", "=", "configargparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.MarkdownHelpAction.__call__": [[716, 720], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.StoreLoggingLevelAction.__init__": [[736, 739], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "StoreLoggingLevelAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", ",", "dest", ",", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.StoreLoggingLevelAction.__call__": [[740, 744], ["StoreLoggingLevelAction.LEVELS.get", "setattr"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "value", ",", "option_string", "=", "None", ")", ":", "\n", "# Get the key 'value' in the dict, or just use 'value'", "\n", "        ", "level", "=", "StoreLoggingLevelAction", ".", "LEVELS", ".", "get", "(", "value", ",", "value", ")", "\n", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__": [[749, 752], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.DeprecateAction.__call__": [[753, 757], ["configargparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "mdhelp", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "configargparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.config_opts": [[26, 32], ["parser.add", "parser.add"], "function", ["None"], ["def", "config_opts", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add", "(", "'-config'", ",", "'--config'", ",", "required", "=", "False", ",", "\n", "is_config_file_arg", "=", "True", ",", "help", "=", "'config file path'", ")", "\n", "parser", ".", "add", "(", "'-save_config'", ",", "'--save_config'", ",", "required", "=", "False", ",", "\n", "is_write_out_config_file_arg", "=", "True", ",", "\n", "help", "=", "'config file save path'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.model_opts": [[34, 202], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add", "(", "'--src_word_vec_size'", ",", "'-src_word_vec_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add", "(", "'--tgt_word_vec_size'", ",", "'-tgt_word_vec_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add", "(", "'--word_vec_size'", ",", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add", "(", "'--share_decoder_embeddings'", ",", "'-share_decoder_embeddings'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--share_embeddings'", ",", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding'", ",", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add", "(", "'--feat_merge'", ",", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add", "(", "'--feat_vec_size'", ",", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--feat_vec_exponent'", ",", "'-feat_vec_exponent'", ",", "\n", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# Encoder-Decoder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add", "(", "'--model_type'", ",", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--encoder_type'", ",", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|brnn|mean|transformer|cnn].\"\"\"", ")", "\n", "group", ".", "add", "(", "'--decoder_type'", ",", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of decoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|transformer|cnn].\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--layers'", ",", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add", "(", "'--enc_layers'", ",", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add", "(", "'--dec_layers'", ",", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add", "(", "'--rnn_size'", ",", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Size of rnn hidden states. Overwrites\n                       enc_rnn_size and dec_rnn_size\"\"\"", ")", "\n", "group", ".", "add", "(", "'--enc_rnn_size'", ",", "'-enc_rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"\"\"Size of encoder rnn hidden states.\n                       Must be equal to dec_rnn_size except for\n                       speech-to-text.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--dec_rnn_size'", ",", "'-dec_rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"\"\"Size of decoder rnn hidden states.\n                       Must be equal to enc_rnn_size except for\n                       speech-to-text.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--audio_enc_pooling'", ",", "'-audio_enc_pooling'", ",", "\n", "type", "=", "str", ",", "default", "=", "'1'", ",", "\n", "help", "=", "\"\"\"The amount of pooling of audio encoder,\n                       either the same amount of pooling across all layers\n                       indicated by a single number, or different amounts of\n                       pooling per layer separated by comma.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--cnn_kernel_width'", ",", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--input_feed'", ",", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--bridge'", ",", "'-bridge'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Have an additional layer between the last encoder\n                       state and the first decoder state\"\"\"", ")", "\n", "group", ".", "add", "(", "'--rnn_type'", ",", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add('--residual', '-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add", "(", "'--brnn'", ",", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--context_gate'", ",", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# DRILL options", "\n", "parser", ".", "add_argument", "(", "'--joint_emb'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'whether to use joint embedding or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_emb_depth'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'depth of the joint embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_dropout'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "\n", "help", "=", "'dropout for joint embedding layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_emb_dense'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'add residuals to all previous joint embedding projections'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_emb_activation'", ",", "type", "=", "str", ",", "default", "=", "'Sigmoid'", ",", "\n", "help", "=", "'activation function for the joint embedding layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_emb_dual'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to use projection on both outputs and weights or not (in the latter case only the weights projection is used)'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_locked_dropout'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to use locked dropout or not for the joint space'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_residual_prev'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to use residual connection to previous layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_noresid'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'disable residual connections'", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add", "(", "'--global_attention'", ",", "'-global_attention'", ",", "\n", "type", "=", "str", ",", "default", "=", "'general'", ",", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "group", ".", "add", "(", "'--global_attention_function'", ",", "'-global_attention_function'", ",", "\n", "type", "=", "str", ",", "default", "=", "\"softmax\"", ",", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ")", "\n", "group", ".", "add", "(", "'--self_attn_type'", ",", "'-self_attn_type'", ",", "\n", "type", "=", "str", ",", "default", "=", "\"scaled-dot\"", ",", "\n", "help", "=", "\"\"\"Self attention type in Transformer decoder\n                       layer -- currently \"scaled-dot\" or \"average\" \"\"\"", ")", "\n", "group", ".", "add", "(", "'--heads'", ",", "'-heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of heads for transformer self-attention'", ")", "\n", "group", ".", "add", "(", "'--transformer_ff'", ",", "'-transformer_ff'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'Size of hidden transformer feed-forward'", ")", "\n", "\n", "# Generator and loss options.", "\n", "group", ".", "add", "(", "'--copy_attn'", ",", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add", "(", "'--generator_function'", ",", "'-generator_function'", ",", "default", "=", "\"softmax\"", ",", "\n", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ",", "\n", "help", "=", "\"\"\"Which function to use for generating\n              probabilities over the target vocabulary (choices:\n              softmax, sparsemax)\"\"\"", ")", "\n", "group", ".", "add", "(", "'--copy_attn_force'", ",", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add", "(", "'--reuse_copy_attn'", ",", "'-reuse_copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Reuse standard attention for copy\"", ")", "\n", "group", ".", "add", "(", "'--copy_loss_by_seqlength'", ",", "'-copy_loss_by_seqlength'", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Divide copy loss by length of sequence\"", ")", "\n", "group", ".", "add", "(", "'--coverage_attn'", ",", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add", "(", "'--lambda_coverage'", ",", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.preprocess_opts": [[204, 316], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Pre-procesing options \"\"\"", "\n", "# Data options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--train_src'", ",", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add", "(", "'--train_tgt'", ",", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add", "(", "'--valid_src'", ",", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add", "(", "'--valid_tgt'", ",", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src_dir'", ",", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_data'", ",", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--max_shard_size'", ",", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Deprecated use shard_size instead\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--shard_size'", ",", "'-shard_size'", ",", "type", "=", "int", ",", "default", "=", "1000000", ",", "\n", "help", "=", "\"\"\"Divide src_corpus and tgt_corpus into\n                       smaller multiple src_copus and tgt corpus files, then\n                       build shards, each shard will have\n                       opt.shard_size samples except last shard.\n                       shard_size=0 means no segmentation\n                       shard_size>0 means segment dataset into multiple shards,\n                       each shard has shard_size samples\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add", "(", "'--src_vocab'", ",", "'-src_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"\"\"Path to an existing source vocabulary. Format:\n                       one word per line.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--tgt_vocab'", ",", "'-tgt_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"\"\"Path to an existing target vocabulary. Format:\n                       one word per line.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--features_vocabs_prefix'", ",", "'-features_vocabs_prefix'", ",", "\n", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add", "(", "'--src_vocab_size'", ",", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--tgt_vocab_size'", ",", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src_words_min_frequency'", ",", "\n", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add", "(", "'--tgt_words_min_frequency'", ",", "\n", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add", "(", "'--dynamic_dict'", ",", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add", "(", "'--share_vocab'", ",", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add", "(", "'--src_seq_length'", ",", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add", "(", "'--src_seq_length_trunc'", ",", "'-src_seq_length_trunc'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_seq_length'", ",", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_seq_length_trunc'", ",", "'-tgt_seq_length_trunc'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add", "(", "'--lower'", ",", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "group", ".", "add", "(", "'--filter_valid'", ",", "'-filter_valid'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Filter validation data by src and/or tgt length'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add", "(", "'--shuffle'", ",", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--report_every'", ",", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add", "(", "'--window_stride'", ",", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add", "(", "'--window'", ",", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"\"\"Using grayscale image can training\n                       model faster and smaller\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.train_opts": [[318, 522], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Training and saving options \"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add", "(", "'--data'", ",", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_model'", ",", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_N.pt where N is the number\n                       of steps\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_checkpoint_steps'", ",", "'-save_checkpoint_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"\"\"Save a checkpoint every X steps\"\"\"", ")", "\n", "group", ".", "add", "(", "'--keep_checkpoint'", ",", "'-keep_checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Keep X checkpoints (negative: keep all)\"\"\"", ")", "\n", "\n", "# GPU", "\n", "group", ".", "add", "(", "'--gpuid'", ",", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Deprecated see world_size and gpu_ranks.\"", ")", "\n", "group", ".", "add", "(", "'--gpu_ranks'", ",", "'-gpu_ranks'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"list of ranks of each process.\"", ")", "\n", "group", ".", "add", "(", "'--world_size'", ",", "'-world_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"total number of distributed processes.\"", ")", "\n", "group", ".", "add", "(", "'--gpu_backend'", ",", "'-gpu_backend'", ",", "\n", "default", "=", "\"nccl\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Type of torch distributed backend\"", ")", "\n", "group", ".", "add", "(", "'--gpu_verbose_level'", ",", "'-gpu_verbose_level'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Gives more info on each process per GPU.\"", ")", "\n", "group", ".", "add", "(", "'--master_ip'", ",", "'-master_ip'", ",", "default", "=", "\"localhost\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"IP of master for torch.distributed training.\"", ")", "\n", "group", ".", "add", "(", "'--master_port'", ",", "'-master_port'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Port of master for torch.distributed training.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add", "(", "'--param_init'", ",", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add", "(", "'--param_init_glorot'", ",", "'-param_init_glorot'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Init parameters with xavier_uniform.\n                       Required for transfomer.\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--train_from'", ",", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--reset_optim'", ",", "'-reset_optim'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'all'", ",", "'states'", ",", "'keep_states'", "]", ",", "\n", "help", "=", "\"\"\"Optimization resetter when train_from.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add", "(", "'--pre_word_vecs_enc'", ",", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--pre_word_vecs_dec'", ",", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add", "(", "'--fix_word_vecs_enc'", ",", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add", "(", "'--fix_word_vecs_dec'", ",", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the decoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add", "(", "'--batch_size'", ",", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add", "(", "'--batch_type'", ",", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "group", ".", "add", "(", "'--normalization'", ",", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add", "(", "'--accum_count'", ",", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--valid_steps'", ",", "'-valid_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Perfom validation every X steps'", ")", "\n", "group", ".", "add", "(", "'--valid_batch_size'", ",", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add", "(", "'--max_generator_batches'", ",", "'-max_generator_batches'", ",", "\n", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--train_steps'", ",", "'-train_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "'Number of training steps'", ")", "\n", "group", ".", "add", "(", "'--epochs'", ",", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Deprecated epochs see train_steps'", ")", "\n", "group", ".", "add", "(", "'--optim'", ",", "'-optim'", ",", "default", "=", "'sgd'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", ",", "\n", "'sparseadam'", ",", "'adafactor'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--adagrad_accumulator_init'", ",", "'-adagrad_accumulator_init'", ",", "\n", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add", "(", "'--max_grad_norm'", ",", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add", "(", "'--dropout'", ",", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add", "(", "'--truncated_decoder'", ",", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--adam_beta1'", ",", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--adam_beta2'", ",", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--label_smoothing'", ",", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add", "(", "'--learning_rate'", ",", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add", "(", "'--learning_rate_decay'", ",", "'-learning_rate_decay'", ",", "\n", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if steps have gone past\n                       start_decay_steps\"\"\"", ")", "\n", "group", ".", "add", "(", "'--start_decay_steps'", ",", "'-start_decay_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"\"\"Start decaying every decay_steps after\n                       start_decay_steps\"\"\"", ")", "\n", "group", ".", "add", "(", "'--decay_steps'", ",", "'-decay_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"\"\"Decay every decay_steps\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--decay_method'", ",", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "'noam'", ",", "'none'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add", "(", "'--warmup_steps'", ",", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--report_every'", ",", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "group", ".", "add", "(", "'--exp_host'", ",", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add", "(", "'--exp'", ",", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "# Use TensorboardX for visualization during training", "\n", "group", ".", "add", "(", "'--tensorboard'", ",", "'-tensorboard'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Use tensorboardX for visualization during training.\n                       Must have the library tensorboardX.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "\"-tensorboard_log_dir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"runs/onmt\"", ",", "\n", "help", "=", "\"\"\"Log directory for Tensorboard.\n                       This is also the name of the run.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"\"\"Using grayscale image can training\n                       model faster and smaller\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.translate_opts": [[524, 651], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Translation / inference options \"\"\"", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add", "(", "'--model'", ",", "'-model'", ",", "dest", "=", "'models'", ",", "metavar", "=", "'MODEL'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file(s). '", "\n", "'Multiple models can be specified, '", "\n", "'for ensemble decoding.'", ")", "\n", "group", ".", "add", "(", "'--avg_raw_probs'", ",", "'-avg_raw_probs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"If this is set, during ensembling scores from\n              different models will be combined by averaging their\n              raw probabilities and then taking the log. Otherwise,\n              the log probabilities will be averaged directly.\n              Necessary for models whose output layers can assign\n              zero probability.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src'", ",", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add", "(", "'--src_dir'", ",", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add", "(", "'--tgt'", ",", "'-tgt'", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add", "(", "'--output'", ",", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add", "(", "'--report_bleu'", ",", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add", "(", "'--report_rouge'", ",", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add", "(", "'--dynamic_dict'", ",", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add", "(", "'--share_vocab'", ",", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add", "(", "'--fast'", ",", "'-fast'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Use fast beam search (some features may not be\n                       supported!)\"\"\"", ")", "\n", "group", ".", "add", "(", "'--beam_size'", ",", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add", "(", "'--min_length'", ",", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add", "(", "'--max_length'", ",", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add", "(", "'--max_sent_length'", ",", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add", "(", "'--stepwise_penalty'", ",", "'-stepwise_penalty'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Apply penalty at every decoding step.\n                       Helpful for summary penalty.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--length_penalty'", ",", "'-length_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'avg'", "]", ",", "\n", "help", "=", "\"\"\"Length Penalty to use.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--coverage_penalty'", ",", "'-coverage_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'summary'", "]", ",", "\n", "help", "=", "\"\"\"Coverage Penalty to use.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--alpha'", ",", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add", "(", "'--beta'", ",", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add", "(", "'--block_ngram_repeat'", ",", "'-block_ngram_repeat'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Block repetition of ngrams during decoding.'", ")", "\n", "group", ".", "add", "(", "'--ignore_when_blocking'", ",", "'-ignore_when_blocking'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "\"\"\"Ignore these strings when blocking repeats.\n                       You want to block sentence delimiters.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--replace_unk'", ",", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--verbose'", ",", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "group", ".", "add", "(", "'--attn_debug'", ",", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add", "(", "'--dump_beam'", ",", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add", "(", "'--n_best'", ",", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add", "(", "'--batch_size'", ",", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add", "(", "'--gpu'", ",", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add", "(", "'--window_stride'", ",", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add", "(", "'--window'", ",", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"\"\"Using grayscale image can training\n                       model faster and smaller\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.opts.add_md_help_argument": [[653, 657], ["parser.add"], "function", ["None"], ["", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "\"\"\" md help parser \"\"\"", "\n", "parser", ".", "add", "(", "'--md'", ",", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_embeddings": [[46, 76], ["len", "onmt.modules.Embeddings", "len"], "function", ["None"], ["def", "build_embeddings", "(", "opt", ",", "word_field", ",", "feat_fields", ",", "for_encoder", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        opt: the option in current environment.\n        word_dict(Vocab): words dictionary.\n        feature_dicts([Vocab], optional): a list of feature dictionary.\n        for_encoder(bool): build Embeddings for encoder or decoder?\n    \"\"\"", "\n", "emb_dim", "=", "opt", ".", "src_word_vec_size", "if", "for_encoder", "else", "opt", ".", "tgt_word_vec_size", "\n", "\n", "word_padding_idx", "=", "word_field", ".", "vocab", ".", "stoi", "[", "word_field", ".", "pad_token", "]", "\n", "num_word_embeddings", "=", "len", "(", "word_field", ".", "vocab", ")", "\n", "\n", "feat_pad_indices", "=", "[", "ff", ".", "vocab", ".", "stoi", "[", "ff", ".", "pad_token", "]", "for", "ff", "in", "feat_fields", "]", "\n", "num_feat_embeddings", "=", "[", "len", "(", "ff", ".", "vocab", ")", "for", "ff", "in", "feat_fields", "]", "\n", "\n", "emb", "=", "Embeddings", "(", "\n", "word_vec_size", "=", "emb_dim", ",", "\n", "position_encoding", "=", "opt", ".", "position_encoding", ",", "\n", "feat_merge", "=", "opt", ".", "feat_merge", ",", "\n", "feat_vec_exponent", "=", "opt", ".", "feat_vec_exponent", ",", "\n", "feat_vec_size", "=", "opt", ".", "feat_vec_size", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "word_padding_idx", "=", "word_padding_idx", ",", "\n", "feat_padding_idx", "=", "feat_pad_indices", ",", "\n", "word_vocab_size", "=", "num_word_embeddings", ",", "\n", "feat_vocab_sizes", "=", "num_feat_embeddings", ",", "\n", "sparse", "=", "opt", ".", "optim", "==", "\"sparseadam\"", "\n", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_encoder": [[78, 114], ["onmt.encoders.transformer.TransformerEncoder", "onmt.encoders.cnn_encoder.CNNEncoder", "onmt.encoders.mean_encoder.MeanEncoder", "onmt.encoders.rnn_encoder.RNNEncoder"], "function", ["None"], ["", "def", "build_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various encoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this encoder.\n    \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "\"transformer\"", ":", "\n", "        ", "encoder", "=", "TransformerEncoder", "(", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "heads", ",", "\n", "opt", ".", "transformer_ff", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", "\n", ")", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"cnn\"", ":", "\n", "        ", "encoder", "=", "CNNEncoder", "(", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"mean\"", ":", "\n", "        ", "encoder", "=", "MeanEncoder", "(", "opt", ".", "enc_layers", ",", "embeddings", ")", "\n", "", "else", ":", "\n", "        ", "encoder", "=", "RNNEncoder", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "bridge", "\n", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_decoder": [[116, 162], ["onmt.decoders.transformer.TransformerDecoder", "onmt.decoders.cnn_decoder.CNNDecoder", "dec_class"], "function", ["None"], ["", "def", "build_decoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various decoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this decoder.\n    \"\"\"", "\n", "if", "opt", ".", "decoder_type", "==", "\"transformer\"", ":", "\n", "        ", "decoder", "=", "TransformerDecoder", "(", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "heads", ",", "\n", "opt", ".", "transformer_ff", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "self_attn_type", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", "\n", ")", "\n", "", "elif", "opt", ".", "decoder_type", "==", "\"cnn\"", ":", "\n", "        ", "decoder", "=", "CNNDecoder", "(", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", "\n", ")", "\n", "", "else", ":", "\n", "        ", "dec_class", "=", "InputFeedRNNDecoder", "if", "opt", ".", "input_feed", "else", "StdRNNDecoder", "\n", "decoder", "=", "dec_class", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "global_attention_function", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", "\n", ")", "\n", "", "return", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.load_test_model": [[164, 181], ["torch.load", "torch.load", "onmt.load_fields_from_vocab", "model_builder.build_base_model", "build_base_model.eval", "build_base_model.generator.eval", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_base_model"], ["", "def", "load_test_model", "(", "opt", ",", "dummy_opt", ",", "model_path", "=", "None", ")", ":", "\n", "    ", "if", "model_path", "is", "None", ":", "\n", "        ", "model_path", "=", "opt", ".", "models", "[", "0", "]", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "fields", "=", "inputters", ".", "load_fields_from_vocab", "(", "\n", "checkpoint", "[", "'vocab'", "]", ",", "data_type", "=", "opt", ".", "data_type", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "\n", "for", "arg", "in", "dummy_opt", ":", "\n", "        ", "if", "arg", "not", "in", "model_opt", ":", "\n", "            ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", "[", "arg", "]", "\n", "", "", "model", "=", "build_base_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "generator", ".", "eval", "(", ")", "\n", "return", "fields", ",", "model", ",", "model_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_base_model": [[183, 318], ["model_builder.build_embeddings", "model_builder.build_decoder", "torch.device", "torch.device", "onmt.models.NMTModel", "onmt.models.NMTModel", "onmt.models.NMTModel.to", "model_builder.build_embeddings", "model_builder.build_encoder", "len", "onmt.modules.CopyGenerator", "onmt.models.NMTModel.load_state_dict", "onmt.modules.DrillGenerator.load_state_dict", "hasattr", "hasattr", "onmt.encoders.image_encoder.ImageEncoder", "onmt.collect_features", "onmt.modules.sparse_activations.LogSparsemax", "onmt.modules.sparse_activations.LogSparsemax", "torch.LogSoftmax", "torch.Sequential", "onmt.modules.DrillGenerator", "re.sub", "re.sub", "model_builder.build_base_model.fix_key"], "function", ["home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_encoder"], ["", "def", "build_base_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        model_opt: the option loaded from checkpoint.\n        fields: `Field` objects for the model.\n        gpu(bool): whether to use gpu.\n        checkpoint: the model gnerated by train phase, or a resumed snapshot\n                    model from a stopped training.\n    Returns:\n        the NMTModel.\n    \"\"\"", "\n", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", ",", "\"img\"", ",", "\"audio\"", "]", ",", "\"Unsupported model type %s\"", "%", "model_opt", ".", "model_type", "\n", "\n", "# for backward compatibility", "\n", "if", "model_opt", ".", "rnn_size", "!=", "-", "1", ":", "\n", "        ", "model_opt", ".", "enc_rnn_size", "=", "model_opt", ".", "rnn_size", "\n", "model_opt", ".", "dec_rnn_size", "=", "model_opt", ".", "rnn_size", "\n", "\n", "# Build encoder.", "\n", "", "if", "model_opt", ".", "model_type", "==", "\"text\"", ":", "\n", "        ", "feat_fields", "=", "[", "fields", "[", "k", "]", "\n", "for", "k", "in", "inputters", ".", "collect_features", "(", "fields", ",", "'src'", ")", "]", "\n", "src_emb", "=", "build_embeddings", "(", "model_opt", ",", "fields", "[", "\"src\"", "]", ",", "feat_fields", ")", "\n", "encoder", "=", "build_encoder", "(", "model_opt", ",", "src_emb", ")", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"img\"", ":", "\n", "# why is build_encoder not used here?", "\n", "# why is the model_opt.__dict__ check necessary?", "\n", "        ", "if", "\"image_channel_size\"", "not", "in", "model_opt", ".", "__dict__", ":", "\n", "            ", "image_channel_size", "=", "3", "\n", "", "else", ":", "\n", "            ", "image_channel_size", "=", "model_opt", ".", "image_channel_size", "\n", "\n", "", "encoder", "=", "ImageEncoder", "(", "\n", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "enc_rnn_size", ",", "\n", "model_opt", ".", "dropout", ",", "\n", "image_channel_size", "\n", ")", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"audio\"", ":", "\n", "        ", "encoder", "=", "AudioEncoder", "(", "\n", "model_opt", ".", "rnn_type", ",", "\n", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "dec_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "enc_rnn_size", ",", "\n", "model_opt", ".", "dec_rnn_size", ",", "\n", "model_opt", ".", "audio_enc_pooling", ",", "\n", "model_opt", ".", "dropout", ",", "\n", "model_opt", ".", "sample_rate", ",", "\n", "model_opt", ".", "window_size", "\n", ")", "\n", "\n", "# Build decoder.", "\n", "", "feat_fields", "=", "[", "fields", "[", "k", "]", "\n", "for", "k", "in", "inputters", ".", "collect_features", "(", "fields", ",", "'tgt'", ")", "]", "\n", "tgt_emb", "=", "build_embeddings", "(", "\n", "model_opt", ",", "fields", "[", "\"tgt\"", "]", ",", "feat_fields", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "assert", "fields", "[", "'src'", "]", ".", "vocab", "==", "fields", "[", "'tgt'", "]", ".", "vocab", ",", "\"preprocess with -share_vocab if you use share_embeddings\"", "\n", "\n", "tgt_emb", ".", "word_lut", ".", "weight", "=", "src_emb", ".", "word_lut", ".", "weight", "\n", "\n", "", "decoder", "=", "build_decoder", "(", "model_opt", ",", "tgt_emb", ")", "\n", "\n", "# Build NMTModel(= encoder + decoder).", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "gpu", "else", "\"cpu\"", ")", "\n", "model", "=", "onmt", ".", "models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "\n", "# Build Generator.", "\n", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "        ", "if", "model_opt", ".", "generator_function", "==", "\"sparsemax\"", ":", "\n", "            ", "gen_func", "=", "onmt", ".", "modules", ".", "sparse_activations", ".", "LogSparsemax", "(", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "gen_func", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "", "if", "model_opt", ".", "joint_emb", "is", "None", ":", "\n", "            ", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "dec_rnn_size", ",", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", ",", "\n", "gen_func", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "                ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "", "else", ":", "\n", "            ", "generator", "=", "DrillGenerator", "(", "model_opt", ",", "decoder", ",", "gen_func", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "vocab_size", "=", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "\n", "pad_idx", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", ".", "stoi", "[", "fields", "[", "\"tgt\"", "]", ".", "pad_token", "]", "\n", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "dec_rnn_size", ",", "vocab_size", ",", "pad_idx", ")", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "# This preserves backward-compat for models using customed layernorm", "\n", "        ", "def", "fix_key", "(", "s", ")", ":", "\n", "            ", "s", "=", "re", ".", "sub", "(", "r'(.*)\\.layer_norm((_\\d+)?)\\.b_2'", ",", "\n", "r'\\1.layer_norm\\2.bias'", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "r'(.*)\\.layer_norm((_\\d+)?)\\.a_2'", ",", "\n", "r'\\1.layer_norm\\2.weight'", ",", "s", ")", "\n", "return", "s", "\n", "\n", "", "checkpoint", "[", "'model'", "]", "=", "{", "fix_key", "(", "k", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "checkpoint", "[", "'model'", "]", ".", "items", "(", ")", "}", "\n", "# end of patch for backward compatibility", "\n", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "hasattr", "(", "model", ".", "encoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ",", "model_opt", ".", "fix_word_vecs_enc", ")", "\n", "", "if", "hasattr", "(", "model", ".", "decoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_dec", ",", "model_opt", ".", "fix_word_vecs_dec", ")", "\n", "\n", "", "", "model", ".", "generator", "=", "generator", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_model": [[320, 325], ["onmt.utils.logging.logger.info", "model_builder.build_base_model", "onmt.utils.logging.logger.info", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.idiap_drill.onmt.model_builder.build_base_model"], ["", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Building model...'", ")", "\n", "model", "=", "build_base_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.idiap_drill.lowfreq.cediff.cediff_per_bin": [[25, 52], ["pickle.load", "pickle.load", "pickle.load", "open", "open", "open", "numpy.mean", "print", "sorted", "numpy.array", "len", "numpy.array", "numpy.array", "numpy.sum", "numpy.sum", "total.append"], "function", ["None"], ["def", "cediff_per_bin", "(", "dataset", ",", "method", ")", ":", "\n", "    ", "\"\"\"\n        Function to compute the mean relative crossentropy loss difference\n        for different word frequency bins between two models. To calculate \n        the cross-entropy loss difference per word and store them into pkl \n        files by running the store_word_cediff() function in finetune.py \n        with the model of your preference.\n    \"\"\"", "\n", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "dataset", "+", "'/'", "+", "dataset", "+", "'-vocab.pkl'", ",", "'rb'", ")", ")", "\n", "ours_vocab", "=", "pickle", ".", "load", "(", "open", "(", "dataset", "+", "'/'", "+", "dataset", "+", "'-ours.pkl'", ",", "'rb'", ")", ")", "\n", "base_vocab", "=", "pickle", ".", "load", "(", "open", "(", "dataset", "+", "'/'", "+", "dataset", "+", "'-'", "+", "method", "+", "'.pkl'", ",", "'rb'", ")", ")", "\n", "s", "=", "[", "(", "k", ",", "vocab", "[", "k", "]", ")", "for", "k", "in", "sorted", "(", "vocab", ",", "key", "=", "vocab", ".", "get", ",", "reverse", "=", "True", ")", "]", "\n", "ranges", "=", "[", "(", "1", ",", "50", ")", ",", "(", "50", ",", "100", ")", ",", "(", "100", ",", "250", ")", ",", "(", "250", ",", "500", ")", ",", "(", "500", ",", "1000", ")", ",", "(", "1000", ",", "2500", ")", ",", "(", "2500", ",", "5000", ")", ",", "(", "5000", ",", "1000000", ")", "]", "\n", "\n", "for", "(", "minval", ",", "maxval", ")", "in", "ranges", ":", "\n", "        ", "total", ",", "count", "=", "[", "]", ",", "0", "\n", "for", "word", ",", "freq", "in", "s", ":", "\n", "            ", "if", "word", "in", "base_vocab", "and", "freq", "<", "maxval", "and", "freq", ">=", "minval", ":", "\n", "                ", "base_val", "=", "np", ".", "array", "(", "base_vocab", "[", "word", "]", ")", "\n", "ours_val", "=", "np", ".", "array", "(", "ours_vocab", "[", "word", "]", ")", "\n", "base", "=", "np", ".", "sum", "(", "base_val", ")", "\n", "ours", "=", "np", ".", "sum", "(", "ours_val", ")", "\n", "res", "=", "(", "(", "base", "-", "ours", ")", "/", "ours", ")", "*", "100", "\n", "total", ".", "append", "(", "res", ")", "\n", "count", "+=", "1", "\n", "", "", "tot", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "total", ")", ")", "\n", "print", "(", "tot", ",", "len", "(", "total", ")", ")", "\n", "\n"]]}