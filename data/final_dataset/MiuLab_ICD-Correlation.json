{"home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MaskedLinear.__init__": [[18, 21], ["torch.Linear.__init__", "made.MaskedLinear.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "torch", ".", "ones", "(", "out_features", ",", "in_features", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MaskedLinear.set_mask": [[22, 24], ["made.MaskedLinear.mask.copy_", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "mask.astype"], "methods", ["None"], ["", "def", "set_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "mask", ".", "astype", "(", "np", ".", "uint8", ")", ".", "T", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MaskedLinear.forward": [[25, 27], ["torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "self", ".", "mask", "*", "self", ".", "weight", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MADE.__init__": [[29, 66], ["torch.Module.__init__", "zip", "made.MADE.net.pop", "torch.Sequential", "torch.Sequential", "torch.Sequential", "made.MADE.update_masks", "made.MADE.net.extend", "made.MaskedLinear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MADE.update_masks"], ["    ", "def", "__init__", "(", "self", ",", "nin", ",", "hidden_sizes", ",", "nout", ",", "num_masks", "=", "1", ",", "natural_ordering", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        nin: integer; number of inputs\n        hidden sizes: a list of integers; number of units in hidden layers\n        nout: integer; number of outputs, which usually collectively parameterize some kind of 1D distribution\n              note: if nout is e.g. 2x larger than nin (perhaps the mean and std), then the first nin\n              will be all the means and the second nin will be stds. i.e. output dimensions depend on the\n              same input dimensions in \"chunks\" and should be carefully decoded downstream appropriately.\n              the output of running the tests for this file makes this a bit more clear with examples.\n        num_masks: can be used to train ensemble over orderings/connections\n        natural_ordering: force natural ordering of dimensions, don't use random permutations\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nin", "=", "nin", "\n", "self", ".", "nout", "=", "nout", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "assert", "self", ".", "nout", "%", "self", ".", "nin", "==", "0", ",", "\"nout must be integer multiple of nin\"", "\n", "\n", "# define a simple MLP neural net", "\n", "self", ".", "net", "=", "[", "]", "\n", "hs", "=", "[", "nin", "]", "+", "hidden_sizes", "+", "[", "nout", "]", "\n", "for", "h0", ",", "h1", "in", "zip", "(", "hs", ",", "hs", "[", "1", ":", "]", ")", ":", "\n", "            ", "self", ".", "net", ".", "extend", "(", "[", "\n", "MaskedLinear", "(", "h0", ",", "h1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "]", ")", "\n", "", "self", ".", "net", ".", "pop", "(", ")", "# pop the last ReLU for the output layer", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n", "# seeds for orders/connectivities of the model ensemble", "\n", "self", ".", "natural_ordering", "=", "natural_ordering", "\n", "self", ".", "num_masks", "=", "num_masks", "\n", "self", ".", "seed", "=", "0", "# for cycling through num_masks orderings", "\n", "\n", "self", ".", "m", "=", "{", "}", "\n", "self", ".", "update_masks", "(", ")", "# builds the initial self.m connectivity", "\n", "# note, we could also precompute the masks and cache them, but this", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MADE.update_masks": [[69, 96], ["len", "numpy.random.RandomState", "range", "masks.append", "zip", "numpy.arange", "numpy.random.RandomState.permutation", "numpy.random.RandomState.randint", "int", "numpy.concatenate", "l.set_mask", "made.MADE.m[].min", "range", "made.MADE.net.modules", "isinstance"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MaskedLinear.set_mask"], ["", "def", "update_masks", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "m", "and", "self", ".", "num_masks", "==", "1", ":", "return", "# only a single seed, skip for efficiency", "\n", "L", "=", "len", "(", "self", ".", "hidden_sizes", ")", "\n", "\n", "# fetch the next seed and construct a random stream", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "seed", ")", "\n", "self", ".", "seed", "=", "(", "self", ".", "seed", "+", "1", ")", "%", "self", ".", "num_masks", "\n", "\n", "# sample the order of the inputs and the connectivity of all neurons", "\n", "self", ".", "m", "[", "-", "1", "]", "=", "np", ".", "arange", "(", "self", ".", "nin", ")", "if", "self", ".", "natural_ordering", "else", "rng", ".", "permutation", "(", "self", ".", "nin", ")", "\n", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "            ", "self", ".", "m", "[", "l", "]", "=", "rng", ".", "randint", "(", "self", ".", "m", "[", "l", "-", "1", "]", ".", "min", "(", ")", ",", "self", ".", "nin", "-", "1", ",", "size", "=", "self", ".", "hidden_sizes", "[", "l", "]", ")", "\n", "\n", "# construct the mask matrices", "\n", "", "masks", "=", "[", "self", ".", "m", "[", "l", "-", "1", "]", "[", ":", ",", "None", "]", "<=", "self", ".", "m", "[", "l", "]", "[", "None", ",", ":", "]", "for", "l", "in", "range", "(", "L", ")", "]", "\n", "masks", ".", "append", "(", "self", ".", "m", "[", "L", "-", "1", "]", "[", ":", ",", "None", "]", "<", "self", ".", "m", "[", "-", "1", "]", "[", "None", ",", ":", "]", ")", "\n", "\n", "# handle the case where nout = nin * k, for integer k > 1", "\n", "if", "self", ".", "nout", ">", "self", ".", "nin", ":", "\n", "            ", "k", "=", "int", "(", "self", ".", "nout", "/", "self", ".", "nin", ")", "\n", "# replicate the mask across the other outputs", "\n", "masks", "[", "-", "1", "]", "=", "np", ".", "concatenate", "(", "[", "masks", "[", "-", "1", "]", "]", "*", "k", ",", "axis", "=", "1", ")", "\n", "\n", "# set the masks in all MaskedLinear layers", "\n", "", "layers", "=", "[", "l", "for", "l", "in", "self", ".", "net", ".", "modules", "(", ")", "if", "isinstance", "(", "l", ",", "MaskedLinear", ")", "]", "\n", "for", "l", ",", "m", "in", "zip", "(", "layers", ",", "masks", ")", ":", "\n", "            ", "l", ".", "set_mask", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MADE.forward": [[97, 99], ["made.MADE.net"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "net", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_made": [[23, 71], ["torch.load", "torch.load", "torch.load.cuda", "tqdm.tqdm", "numpy.array", "evaluation.all_metrics", "print", "print", "rescore.rescore_grid", "rescore.get_y_true", "rescore.get_made_likelihood", "print", "rescore.get_y_pred", "rescore.get_made_likelihood", "print", "open", "zip", "rescore.get_n_best", "rescore.get_y_pred_made", "rescore.get_made_likelihood", "zip", "np.array.append", "y_pred_nbests.append", "numpy.mean", "numpy.mean", "json.load", "nbest_labels.append", "evaluation.micro_f1", "nbests.append", "sorted", "len", "nbests_with_made.append", "numpy.nonzero"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_grid", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_true", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_made_likelihood", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_made_likelihood", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_n_best", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred_made", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_made_likelihood"], ["def", "rescore_made", "(", "args", ",", "dataset", ",", "scores", ",", "ind2c", ",", "c2ind", ",", "y_true", ",", "y_pred", ",", "y_pred_raw", ")", ":", "\n", "    ", "made", "=", "torch", ".", "load", "(", "args", ".", "made_model", ")", "\n", "made", ".", "cuda", "(", ")", "\n", "with", "open", "(", "args", ".", "made_vocab", ")", "as", "jsonfile", ":", "\n", "        ", "made_vocab", "=", "json", ".", "load", "(", "jsonfile", ")", "[", "\"rev_vocab\"", "]", "\n", "\n", "", "y_pred_oracle", "=", "[", "]", "\n", "y_pred_nbests", "=", "[", "]", "\n", "for", "probs", ",", "pred", ",", "true", "in", "tqdm", "(", "zip", "(", "y_pred_raw", ",", "y_pred", ",", "y_true", ")", ")", ":", "\n", "        ", "y_pred_nbest", "=", "get_n_best", "(", "probs", ",", "n", "=", "args", ".", "n_best", ")", "\n", "\n", "nbests", "=", "[", "]", "\n", "nbest_labels", "=", "[", "]", "\n", "for", "prob", ",", "labels", "in", "y_pred_nbest", ":", "\n", "            ", "nbest_labels", ".", "append", "(", "labels", ")", "\n", "f1", "=", "micro_f1", "(", "labels", ",", "true", ")", "\n", "nbests", ".", "append", "(", "(", "f1", ",", "prob", ",", "labels", ")", ")", "\n", "\n", "", "labels_made", "=", "get_y_pred_made", "(", "nbest_labels", ",", "ind2c", ",", "made_vocab", ")", "\n", "made_losses", "=", "get_made_likelihood", "(", "args", ",", "made", ",", "made_vocab", ",", "labels_made", ")", "\n", "_", ",", "_", ",", "labels_oracle", "=", "sorted", "(", "nbests", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", "-", "1", "]", "\n", "\n", "nbests_with_made", "=", "[", "]", "\n", "for", "(", "f1", ",", "prob", ",", "labels", ")", ",", "made_loss", "in", "zip", "(", "nbests", ",", "made_losses", ")", ":", "\n", "            ", "nonzeros", "=", "len", "(", "np", ".", "nonzero", "(", "labels", ")", "[", "0", "]", ")", "\n", "if", "nonzeros", "==", "0", ":", "nonzeros", "=", "1", "\n", "nbests_with_made", ".", "append", "(", "(", "f1", ",", "-", "made_loss", ",", "nonzeros", ",", "prob", ",", "labels", ")", ")", "\n", "", "y_pred_oracle", ".", "append", "(", "labels_oracle", ")", "\n", "y_pred_nbests", ".", "append", "(", "nbests_with_made", ")", "\n", "\n", "", "y_pred_oracle", "=", "np", ".", "array", "(", "y_pred_oracle", ")", "\n", "metrics", "=", "all_metrics", "(", "y_pred_oracle", ",", "y_true", ",", "k", "=", "[", "8", ",", "15", "]", ")", "\n", "print", "(", "\"oracle\"", ")", "\n", "print", "(", "metrics", ")", "\n", "\n", "rescore_grid", "(", "\n", "coefs", "=", "[", "0.01", ",", "0.03", ",", "0.1", ",", "0.3", ",", "1.0", ",", "2.0", ",", "3.0", ",", "5.0", ",", "10.0", "]", ",", "\n", "alphas", "=", "[", "0.0", ",", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.5", ",", "0.6", ",", "0.7", ",", "0.8", ",", "0.9", ",", "1.0", ",", "1.1", ",", "1.2", ",", "1.3", ",", "1.4", ",", "1.5", ",", "1.6", ",", "1.7", ",", "1.8", ",", "1.9", ",", "2.0", "]", ",", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred_nbests", "=", "y_pred_nbests", "\n", ")", "\n", "\n", "y_true_made", ",", "ids_made", "=", "get_y_true", "(", "dataset", ",", "made_vocab", ")", "\n", "y_true_losses", "=", "get_made_likelihood", "(", "args", ",", "made", ",", "made_vocab", ",", "y_true_made", ")", "\n", "print", "(", "\"y_true loss\"", ",", "np", ".", "mean", "(", "y_true_losses", ")", ")", "\n", "y_pred_made", "=", "get_y_pred", "(", "scores", ",", "made_vocab", ",", "ids_made", ")", "\n", "y_pred_losses", "=", "get_made_likelihood", "(", "args", ",", "made", ",", "made_vocab", ",", "y_pred_made", ")", "\n", "print", "(", "\"y_pred loss\"", ",", "np", ".", "mean", "(", "y_pred_losses", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_bert": [[73, 116], ["icd_bert.ICDBertForMaskedLM.from_pretrained", "ICDBertForMaskedLM.from_pretrained.eval", "ICDBertForMaskedLM.from_pretrained.cuda", "icd_bert.ICDBertTokenizer", "tqdm.tqdm", "rescore.rescore_grid", "os.path.join", "zip", "rescore.get_n_best", "y_pred_nbests.append", "open", "pickle.dump", "icd_bert.ICDBertTokenizer.convert_tokens_to_ids", "enumerate", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "enumerate", "nbests_with_bert.append", "len", "rescore.build_masked_input", "torch.tensor().cuda.append", "torch.tensor().cuda.append", "torch.no_grad", "torch.no_grad", "ICDBertForMaskedLM.from_pretrained.", "[].cpu().item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "numpy.nonzero", "[].cpu", "prediction_scores[].detach().log_softmax", "prediction_scores[].detach"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_grid", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_n_best", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.build_masked_input"], ["", "def", "rescore_bert", "(", "args", ",", "dataset", ",", "scores", ",", "ind2c", ",", "c2ind", ",", "y_true", ",", "y_pred", ",", "y_pred_raw", ")", ":", "\n", "    ", "model", "=", "ICDBertForMaskedLM", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "tokenizer", "=", "ICDBertTokenizer", "(", "os", ".", "path", ".", "join", "(", "args", ".", "bert_model", ",", "\"vocab.txt\"", ")", ")", "\n", "\n", "y_pred_nbests", "=", "[", "]", "\n", "for", "pred", ",", "pred_raw", "in", "tqdm", "(", "zip", "(", "y_pred", ",", "y_pred_raw", ")", ")", ":", "\n", "        ", "y_pred_nbest", "=", "get_n_best", "(", "pred_raw", ",", "n", "=", "args", ".", "n_best", ")", "\n", "nbests_with_bert", "=", "[", "]", "\n", "for", "prob", ",", "labels", "in", "y_pred_nbest", ":", "\n", "            ", "codes", "=", "[", "ind2c", "[", "ind", "]", "for", "ind", "in", "np", ".", "nonzero", "(", "labels", ")", "[", "0", "]", "if", "ind", "in", "ind2c", "]", "\n", "if", "len", "(", "codes", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "token_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "codes", ")", "\n", "all_input_ids", ",", "all_attention_mask", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "token_id", "in", "enumerate", "(", "token_ids", ")", ":", "\n", "                ", "input_ids", ",", "attention_mask", "=", "build_masked_input", "(", "\n", "token_ids", ",", "tokenizer", ",", "mask_positions", "=", "[", "i", "]", "\n", ")", "\n", "all_input_ids", ".", "append", "(", "input_ids", ")", "\n", "all_attention_mask", ".", "append", "(", "attention_mask", ")", "\n", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "all_input_ids", ")", ".", "cuda", "(", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "all_attention_mask", ")", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "output", "=", "model", "(", "all_input_ids", ",", "all_attention_mask", ")", "\n", "", "prediction_scores", "=", "output", "[", "0", "]", "\n", "log_prob", "=", "0.0", "\n", "for", "i", ",", "token_id", "in", "enumerate", "(", "token_ids", ")", ":", "\n", "                ", "log_prob", "+=", "prediction_scores", "[", "i", ",", "i", "]", ".", "detach", "(", ")", ".", "log_softmax", "(", "dim", "=", "-", "1", ")", "[", "token_id", "]", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "", "nbests_with_bert", ".", "append", "(", "(", "0.0", ",", "log_prob", ",", "len", "(", "token_ids", ")", ",", "prob", ",", "labels", ")", ")", "\n", "\n", "", "y_pred_nbests", ".", "append", "(", "nbests_with_bert", ")", "\n", "\n", "", "with", "open", "(", "\"y_pred_nbests.bert\"", ",", "\"wb\"", ")", "as", "pkl", ":", "\n", "        ", "pickle", ".", "dump", "(", "y_pred_nbests", ",", "pkl", ")", "\n", "\n", "", "rescore_grid", "(", "\n", "coefs", "=", "[", "0.1", ",", "0.3", ",", "1.0", ",", "2.0", ",", "3.0", ",", "5.0", ",", "10.0", "]", ",", "\n", "alphas", "=", "[", "0.0", ",", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.5", ",", "0.6", ",", "0.7", ",", "0.8", ",", "0.9", ",", "1.0", ",", "1.1", ",", "1.2", ",", "1.3", ",", "1.4", ",", "1.5", ",", "1.6", ",", "1.7", ",", "1.8", ",", "1.9", ",", "2.0", "]", ",", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred_nbests", "=", "y_pred_nbests", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_grid": [[119, 131], ["print", "numpy.array", "evaluation.all_metrics", "print", "np.array.append", "sorted"], "function", ["None"], ["", "def", "rescore_grid", "(", "coefs", ",", "alphas", ",", "y_true", ",", "y_pred_nbests", ")", ":", "\n", "    ", "for", "coef", "in", "coefs", ":", "\n", "        ", "for", "alpha", "in", "alphas", ":", "\n", "            ", "print", "(", "\"coef: \"", ",", "coef", ",", "\", alpha: \"", ",", "alpha", ")", "\n", "this_pred", "=", "[", "]", "\n", "for", "nbests", "in", "y_pred_nbests", ":", "\n", "                ", "_", ",", "_", ",", "_", ",", "_", ",", "labels", "=", "sorted", "(", "nbests", ",", "key", "=", "lambda", "x", ":", "x", "[", "3", "]", "+", "coef", "*", "x", "[", "1", "]", "/", "(", "x", "[", "2", "]", "**", "alpha", ")", ")", "[", "-", "1", "]", "\n", "this_pred", ".", "append", "(", "labels", ")", "\n", "", "this_pred", "=", "np", ".", "array", "(", "this_pred", ")", "\n", "metrics", "=", "all_metrics", "(", "this_pred", ",", "y_true", ",", "k", "=", "[", "8", ",", "15", "]", ")", "\n", "print", "(", "metrics", ")", "\n", "return", "this_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.build_masked_input": [[133, 140], ["len", "isinstance", "enumerate"], "function", ["None"], ["", "", "", "def", "build_masked_input", "(", "input_ids", ",", "tokenizer", ",", "mask_positions", "=", "None", ")", ":", "\n", "    ", "attention_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "if", "mask_positions", ":", "\n", "        ", "if", "isinstance", "(", "mask_positions", ",", "int", ")", ":", "\n", "            ", "mask_positions", "=", "[", "mask_positions", "]", "\n", "", "input_ids", "=", "[", "tokenizer", ".", "mask_token_id", "if", "i", "in", "mask_positions", "else", "ind", "for", "i", ",", "ind", "in", "enumerate", "(", "input_ids", ")", "]", "\n", "", "return", "input_ids", ",", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.main": [[142, 162], ["rescore.get_code_vocab", "len", "rescore.get_y_true", "rescore.get_y_pred", "rescore.get_y_pred_raw", "evaluation.all_metrics", "print", "open", "csv.DictReader", "list", "open", "json.load", "rescore.rescore_made", "rescore.rescore_bert"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_code_vocab", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_true", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred_raw", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_made", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.rescore_bert"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "with", "open", "(", "args", ".", "dataset", ")", "as", "csvfile", ":", "\n", "        ", "reader", "=", "csv", ".", "DictReader", "(", "csvfile", ")", "\n", "dataset", "=", "list", "(", "reader", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "scores", ")", "as", "jsonfile", ":", "\n", "        ", "scores", "=", "json", ".", "load", "(", "jsonfile", ")", "\n", "\n", "", "ind2c", ",", "c2ind", "=", "get_code_vocab", "(", "args", ")", "\n", "vocab_size", "=", "len", "(", "ind2c", ")", "\n", "y_true", ",", "ids", "=", "get_y_true", "(", "dataset", ",", "c2ind", ")", "\n", "y_pred", "=", "get_y_pred", "(", "scores", ",", "c2ind", ",", "ids", ")", "\n", "y_pred_raw", "=", "get_y_pred_raw", "(", "scores", ",", "c2ind", ",", "ids", ")", "\n", "metrics", "=", "all_metrics", "(", "y_pred", ",", "y_true", ",", "k", "=", "[", "8", ",", "15", "]", ",", "yhat_raw", "=", "y_pred_raw", ")", "\n", "print", "(", "metrics", ")", "\n", "\n", "if", "args", ".", "rescorer", "==", "\"made\"", ":", "\n", "        ", "rescore_made", "(", "args", ",", "dataset", ",", "scores", ",", "ind2c", ",", "c2ind", ",", "y_true", ",", "y_pred", ",", "y_pred_raw", ")", "\n", "", "elif", "args", ".", "rescorer", "==", "\"bert\"", ":", "\n", "        ", "rescore_bert", "(", "args", ",", "dataset", ",", "scores", ",", "ind2c", ",", "c2ind", ",", "y_true", ",", "y_pred", ",", "y_pred_raw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred_hard": [[164, 177], ["dict", "open", "numpy.zeros", "enumerate", "line.strip().rstrip().split.strip().rstrip().split", "dict.items", "len", "len", "line.strip().rstrip().split.strip().rstrip", "len", "line.strip().rstrip().split.strip"], "function", ["None"], ["", "", "def", "get_y_pred_hard", "(", "c2ind", ",", "ids", ")", ":", "\n", "    ", "predictions", "=", "dict", "(", ")", "\n", "for", "line", "in", "open", "(", "\"predictions/CAML_mimic2_full/preds_test.psv\"", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "rstrip", "(", "'|'", ")", ".", "split", "(", "'|'", ")", "\n", "id", "=", "line", "[", "0", "]", "\n", "labels", "=", "[", "]", "if", "len", "(", "line", ")", "==", "1", "else", "line", "[", "1", ":", "]", "\n", "predictions", "[", "id", "]", "=", "labels", "\n", "", "preds", "=", "np", ".", "zeros", "(", "(", "len", "(", "predictions", ")", ",", "len", "(", "c2ind", ")", ")", ")", "\n", "for", "i", ",", "(", "id", ",", "labels", ")", "in", "enumerate", "(", "predictions", ".", "items", "(", ")", ")", ":", "\n", "        ", "for", "label", "in", "labels", ":", "\n", "            ", "if", "label", "in", "c2ind", ":", "\n", "                ", "preds", "[", "ids", "[", "id", "]", ",", "c2ind", "[", "label", "]", "]", "=", "1", "\n", "", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_n_best": [[179, 216], ["numpy.zeros", "enumerate", "queue.PriorityQueue", "queue.PriorityQueue.put", "enumerate", "numpy.argsort", "len", "queue.PriorityQueue", "queue.PriorityQueue.empty", "n_best.append", "numpy.abs", "numpy.log", "numpy.log", "numpy.copy", "queue.PriorityQueue.put", "queue.PriorityQueue.put", "len", "queue.PriorityQueue.get", "queue.PriorityQueue.get", "numpy.log", "numpy.log"], "function", ["None"], ["", "def", "get_n_best", "(", "probs", ",", "n", "=", "10", ")", ":", "\n", "    ", "flip_idx", "=", "np", ".", "argsort", "(", "np", ".", "abs", "(", "probs", "-", "0.5", ")", ")", "[", ":", "n", "]", "\n", "labels", "=", "np", ".", "zeros", "(", "len", "(", "probs", ")", ")", "\n", "cum_prob", "=", "0.0", "\n", "for", "i", ",", "prob", "in", "enumerate", "(", "probs", ")", ":", "\n", "        ", "if", "i", "in", "flip_idx", ":", "\n", "            ", "continue", "\n", "", "if", "prob", ">=", "0.5", ":", "\n", "            ", "labels", "[", "i", "]", "=", "1", "\n", "cum_prob", "+=", "np", ".", "log", "(", "prob", ")", "\n", "", "else", ":", "\n", "            ", "labels", "[", "i", "]", "=", "0", "\n", "cum_prob", "+=", "np", ".", "log", "(", "1", "-", "prob", ")", "\n", "\n", "", "", "last_queue", "=", "PriorityQueue", "(", ")", "\n", "last_queue", ".", "put", "(", "(", "cum_prob", ",", "labels", ")", ")", "\n", "for", "i", ",", "prob", "in", "enumerate", "(", "probs", ")", ":", "\n", "        ", "if", "i", "not", "in", "flip_idx", ":", "\n", "            ", "continue", "\n", "", "queue", "=", "PriorityQueue", "(", ")", "\n", "for", "cum_prob", ",", "labels", "in", "last_queue", ".", "queue", ":", "\n", "            ", "labels2", "=", "np", ".", "copy", "(", "labels", ")", "\n", "labels", "[", "i", "]", "=", "1", "\n", "queue", ".", "put", "(", "(", "cum_prob", "+", "np", ".", "log", "(", "prob", "+", "1e-6", ")", ",", "labels", ")", ")", "\n", "labels2", "[", "i", "]", "=", "0", "\n", "queue", ".", "put", "(", "(", "cum_prob", "+", "np", ".", "log", "(", "1", "-", "prob", "+", "1e-6", ")", ",", "labels2", ")", ")", "\n", "\n", "", "while", "len", "(", "queue", ".", "queue", ")", ">", "n", ":", "\n", "            ", "_", "=", "queue", ".", "get", "(", ")", "\n", "\n", "", "last_queue", "=", "queue", "\n", "\n", "", "n_best", "=", "[", "]", "\n", "while", "not", "queue", ".", "empty", "(", ")", ":", "\n", "        ", "n_best", ".", "append", "(", "queue", ".", "get", "(", ")", ")", "\n", "", "n_best", "=", "n_best", "[", ":", ":", "-", "1", "]", "\n", "return", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_made_likelihood": [[218, 245], ["made.eval", "range", "numpy.concatenate", "torch.tensor.float().cuda", "torch.zeros_like", "torch.zeros_like", "range", "torch.binary_cross_entropy_with_logits", "loss.sum().cpu().numpy.sum().cpu().numpy", "np.concatenate.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "made.update_masks", "torch.tensor.float", "torch.no_grad", "torch.no_grad", "made", "loss.sum().cpu().numpy.sum().cpu", "loss.sum().cpu().numpy.sum"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.made.MADE.update_masks"], ["", "def", "get_made_likelihood", "(", "args", ",", "made", ",", "made_vocab", ",", "y_matrix", ")", ":", "\n", "    ", "made", ".", "eval", "(", ")", "\n", "batch_size", "=", "100", "\n", "n_examples", ",", "dim_input", "=", "y_matrix", ".", "shape", "\n", "nsteps", "=", "n_examples", "//", "batch_size", "\n", "if", "n_examples", "%", "batch_size", "!=", "0", ":", "\n", "        ", "nsteps", "+=", "1", "\n", "", "losses", "=", "[", "]", "\n", "for", "step", "in", "range", "(", "nsteps", ")", ":", "\n", "        ", "if", "step", "==", "nsteps", "-", "1", ":", "\n", "            ", "x", "=", "torch", ".", "tensor", "(", "y_matrix", "[", "step", "*", "batch_size", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "tensor", "(", "y_matrix", "[", "step", "*", "batch_size", ":", "(", "step", "+", "1", ")", "*", "batch_size", "]", ")", "\n", "\n", "", "x", "=", "x", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "x_pred", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "for", "s", "in", "range", "(", "args", ".", "n_samples", ")", ":", "\n", "            ", "made", ".", "update_masks", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x_pred", "+=", "made", "(", "x", ")", "\n", "", "", "x_pred", "/=", "args", ".", "n_samples", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "x_pred", ",", "x", ",", "reduction", "=", "'none'", ")", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "losses", ".", "append", "(", "loss", ")", "\n", "", "losses", "=", "np", ".", "concatenate", "(", "losses", ",", "axis", "=", "0", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_true": [[247, 256], ["numpy.zeros", "dict", "enumerate", "entry[].strip().split", "len", "len", "entry[].strip"], "function", ["None"], ["", "def", "get_y_true", "(", "dataset", ",", "c2ind", ")", ":", "\n", "    ", "labels", "=", "np", ".", "zeros", "(", "(", "len", "(", "dataset", ")", ",", "len", "(", "c2ind", ")", ")", ")", "\n", "ids", "=", "dict", "(", ")", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "dataset", ")", ":", "\n", "        ", "ids", "[", "entry", "[", "\"HADM_ID\"", "]", "]", "=", "i", "\n", "for", "label", "in", "entry", "[", "\"LABELS\"", "]", ".", "strip", "(", ")", ".", "split", "(", "\";\"", ")", ":", "\n", "            ", "if", "label", "in", "c2ind", ":", "\n", "                ", "labels", "[", "i", ",", "c2ind", "[", "label", "]", "]", "=", "1", "\n", "", "", "", "return", "labels", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred": [[258, 265], ["numpy.zeros", "enumerate", "scores.items", "entry.items", "len", "len"], "function", ["None"], ["", "def", "get_y_pred", "(", "scores", ",", "c2ind", ",", "ids", ")", ":", "\n", "    ", "preds", "=", "np", ".", "zeros", "(", "(", "len", "(", "scores", ")", ",", "len", "(", "c2ind", ")", ")", ")", "\n", "for", "i", ",", "(", "id", ",", "entry", ")", "in", "enumerate", "(", "scores", ".", "items", "(", ")", ")", ":", "\n", "        ", "for", "label", ",", "prob", "in", "entry", ".", "items", "(", ")", ":", "\n", "            ", "if", "prob", ">=", "0.5", "and", "label", "in", "c2ind", ":", "\n", "                ", "preds", "[", "ids", "[", "id", "]", ",", "c2ind", "[", "label", "]", "]", "=", "1", "\n", "", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred_made": [[267, 275], ["numpy.zeros", "enumerate", "len", "len", "numpy.nonzero"], "function", ["None"], ["", "def", "get_y_pred_made", "(", "y_pred", ",", "ind2c", ",", "c2ind", ")", ":", "\n", "    ", "preds", "=", "np", ".", "zeros", "(", "(", "len", "(", "y_pred", ")", ",", "len", "(", "c2ind", ")", ")", ")", "\n", "for", "i", ",", "pred", "in", "enumerate", "(", "y_pred", ")", ":", "\n", "        ", "for", "label", "in", "np", ".", "nonzero", "(", "pred", ")", "[", "0", "]", ":", "\n", "            ", "label_name", "=", "ind2c", "[", "label", "]", "\n", "if", "label_name", "in", "c2ind", ":", "\n", "                ", "preds", "[", "i", ",", "c2ind", "[", "label_name", "]", "]", "=", "1", "\n", "", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_y_pred_raw": [[277, 284], ["numpy.zeros", "enumerate", "scores.items", "entry.items", "len", "len"], "function", ["None"], ["", "def", "get_y_pred_raw", "(", "scores", ",", "c2ind", ",", "ids", ")", ":", "\n", "    ", "preds", "=", "np", ".", "zeros", "(", "(", "len", "(", "scores", ")", ",", "len", "(", "c2ind", ")", ")", ")", "\n", "for", "i", ",", "(", "id", ",", "entry", ")", "in", "enumerate", "(", "scores", ".", "items", "(", ")", ")", ":", "\n", "        ", "for", "label", ",", "prob", "in", "entry", ".", "items", "(", ")", ":", "\n", "            ", "if", "label", "in", "c2ind", ":", "\n", "                ", "preds", "[", "ids", "[", "id", "]", ",", "c2ind", "[", "label", "]", "]", "=", "prob", "\n", "", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.rescore.get_code_vocab": [[286, 299], ["datasets.load_full_codes", "set", "open", "csv.reader", "enumerate", "ind2c.items", "set.add", "enumerate", "sorted"], "function", ["None"], ["", "def", "get_code_vocab", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "code_type", "==", "\"full\"", ":", "\n", "        ", "ind2c", ",", "_", "=", "load_full_codes", "(", "\n", "f\"{MIMICDATA}/{args.version}/train_{args.code_type}.csv\"", ",", "version", "=", "args", ".", "version", ")", "\n", "", "else", ":", "\n", "        ", "codes", "=", "set", "(", ")", "\n", "with", "open", "(", "f\"{MIMICDATA}/{args.version}/TOP_{args.code_type}_CODES.csv\"", ")", "as", "labelfile", ":", "\n", "            ", "lr", "=", "csv", ".", "reader", "(", "labelfile", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "lr", ")", ":", "\n", "                ", "codes", ".", "add", "(", "row", "[", "0", "]", ")", "\n", "", "", "ind2c", "=", "{", "i", ":", "c", "for", "i", ",", "c", "in", "enumerate", "(", "sorted", "(", "codes", ")", ")", "}", "\n", "", "c2ind", "=", "{", "c", ":", "i", "for", "i", ",", "c", "in", "ind2c", ".", "items", "(", ")", "}", "\n", "return", "ind2c", ",", "c2ind", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.TextDataset.__init__": [[72, 104], ["os.path.isfile", "os.path.split", "os.path.split", "os.path.join", "os.path.exists", "logger.info", "logger.info", "logger.info", "open", "pickle.load", "open", "f.readlines", "tokenizer.convert_tokens_to_ids", "run_icd_pretraining.TextDataset.examples.append", "open", "pickle.dump", "tokenizer.tokenize", "len", "str", "len", "tokenizer.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.tokenize", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.build_inputs_with_special_tokens"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "\"train\"", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "directory", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "file_path", ")", "\n", "_", ",", "model_name", "=", "os", ".", "path", ".", "split", "(", "args", ".", "model_name_or_path", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "directory", ",", "model_name", "+", "\"_cached_lm_\"", "+", "str", "(", "block_size", ")", "+", "\"_\"", "+", "filename", "\n", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "                ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "directory", ")", "\n", "\n", "self", ".", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "texts", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "for", "text", "in", "texts", ":", "\n", "                ", "tokenized_text", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "text", ")", ")", "\n", "pad_size", "=", "args", ".", "block_size", "-", "len", "(", "tokenized_text", ")", "\n", "attention_mask", "=", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "+", "[", "0", "]", "*", "pad_size", "\n", "tokenized_text", "=", "tokenized_text", "+", "[", "tokenizer", ".", "pad_token_id", "]", "*", "pad_size", "\n", "self", ".", "examples", ".", "append", "(", "(", "\n", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "tokenized_text", ")", ",", "\n", "attention_mask", "\n", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.TextDataset.__len__": [[105, 107], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.TextDataset.__getitem__": [[108, 111], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "input_ids", ",", "attention_mask", "=", "self", ".", "examples", "[", "item", "]", "\n", "return", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "attention_mask", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.load_and_cache_examples": [[113, 121], ["run_icd_pretraining.TextDataset"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "dataset", "=", "TextDataset", "(", "\n", "tokenizer", ",", "\n", "args", ",", "\n", "file_path", "=", "args", ".", "eval_data_file", "if", "evaluate", "else", "args", ".", "train_data_file", ",", "\n", "block_size", "=", "args", ".", "block_size", ",", "\n", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.set_seed": [[123, 129], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining._rotate_checkpoints": [[131, 158], ["glob.glob", "sorted", "max", "os.path.join", "len", "logger.info", "shutil.rmtree", "ordering_and_checkpoint_path.append", "re.match", "len", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", "=", "False", ")", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "if", "len", "(", "glob_checkpoints", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.mask_tokens": [[160, 183], ["inputs.clone", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "torch.randint", "tokenizer.get_special_tokens_mask", "torch.tensor", "torch.bernoulli().bool", "len", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli().bool", "torch.bernoulli", "torch.full", "torch.bernoulli", "torch.full"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.get_special_tokens_mask"], ["", "", "def", "mask_tokens", "(", "inputs", ":", "torch", ".", "Tensor", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "# 10% of the time, we replace masked input tokens with random word", "\n", "indices_random", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.5", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "&", "~", "indices_replaced", "\n", "random_words", "=", "torch", ".", "randint", "(", "len", "(", "tokenizer", ")", ",", "labels", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "inputs", "[", "indices_random", "]", "=", "random_words", "[", "indices_random", "]", "\n", "\n", "# The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "return", "inputs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.train": [[185, 366], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_icd_pretraining.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "hasattr", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "inputs.to.to", "labels.to.to", "masks.to.to", "torch.nn.parallel.DistributedDataParallel.train", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "run_icd_pretraining.mask_tokens", "torch.nn.parallel.DistributedDataParallel.", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_icd_pretraining._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_icd_pretraining.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.set_seed", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.train", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.mask_tokens", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining._rotate_checkpoints", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "masks", "=", "batch", "\n", "inputs", ",", "labels", "=", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "args", ")", "if", "args", ".", "mlm", "else", "(", "inputs", ",", "inputs", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "masks", "=", "masks", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ",", "attention_mask", "=", "masks", ",", "masked_lm_labels", "=", "labels", ")", "if", "args", ".", "mlm", "else", "model", "(", "inputs", ",", "attention_mask", "=", "masks", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.evaluate": [[368, 420], ["run_icd_pretraining.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "len", "inputs.to.to", "labels.to.to", "masks.to.to", "torch.tensor", "open", "logger.info", "sorted", "os.path.exists", "run_icd_pretraining.mask_tokens", "torch.no_grad", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.load_and_cache_examples", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.mask_tokens"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "masks", "=", "batch", "\n", "inputs", ",", "labels", "=", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "args", ")", "if", "args", ".", "mlm", "else", "(", "inputs", ",", "inputs", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "masks", "=", "masks", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "inputs", ",", "attention_mask", "=", "masks", ",", "masked_lm_labels", "=", "labels", ")", "if", "args", ".", "mlm", "else", "model", "(", "inputs", ",", "attention_mask", "=", "masks", ",", "labels", "=", "labels", ")", "\n", "lm_loss", "=", "outputs", "[", "0", "]", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", ",", "\"eval_loss\"", ":", "eval_loss", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.main": [[422, 696], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_icd_pretraining.set_seed", "config_class.from_pretrained", "tokenizer_class", "model_class", "model_class.from_pretrained.to", "logger.info", "ValueError", "ValueError", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.join", "torch.distributed.barrier", "run_icd_pretraining.load_and_cache_examples", "run_icd_pretraining.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class", "model_class.from_pretrained.to", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_icd_pretraining.evaluate", "dict", "results.update", "torch.distributed.get_rank", "os.path.exists", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.set_seed", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.load_and_cache_examples", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.train", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.run_icd_pretraining.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "\"bert-base-cased\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", "and", "not", "args", ".", "mlm", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"BERT and RoBERTa do not have LM heads but masked LM heads. They must be run using the --mlm \"", "\n", "\"flag (masked language modeling).\"", "\n", ")", "\n", "", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", "\n", ")", "\n", "\n", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"vocab.txt\"", ")", ")", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "# tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)", "\n", "tokenizer", "=", "tokenizer_class", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"vocab.txt\"", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.__init__": [[71, 101], ["transformers.PreTrainedTokenizer.__init__", "icd_bert.load_vocab", "collections.OrderedDict", "os.path.isfile", "ValueError", "len", "len", "len", "icd_bert.ICDBertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.load_vocab"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "unk_token", "=", "\"[UNK]\"", ",", "\n", "pad_token", "=", "\"[PAD]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs a ICDBertTokenizer.\n\n        Args:\n            **vocab_file**: Path to a one-wordpiece-per-line vocabulary file\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "unk_token", "=", "unk_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'.\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "if", "unk_token", "not", "in", "self", ".", "vocab", ":", "\n", "            ", "self", ".", "vocab", "[", "unk_token", "]", "=", "len", "(", "self", ".", "vocab", ")", "\n", "self", ".", "vocab", "[", "pad_token", "]", "=", "len", "(", "self", ".", "vocab", ")", "\n", "self", ".", "vocab", "[", "mask_token", "]", "=", "len", "(", "self", ".", "vocab", ")", "\n", "", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.vocab_size": [[102, 105], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer._tokenize": [[106, 109], ["icd_bert.whitespace_tokenize"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.whitespace_tokenize"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.tokenize": [[110, 112], ["icd_bert.ICDBertTokenizer._tokenize"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer._tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "self", ".", "_tokenize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer._convert_token_to_id": [[113, 116], ["icd_bert.ICDBertTokenizer.vocab.get", "icd_bert.ICDBertTokenizer.vocab.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "vocab", ".", "get", "(", "token", ",", "self", ".", "vocab", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer._convert_id_to_token": [[117, 120], ["icd_bert.ICDBertTokenizer.ids_to_tokens.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "ids_to_tokens", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.convert_tokens_to_string": [[121, 125], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.build_inputs_with_special_tokens": [[126, 132], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence\n        by concatenating and adding special tokens.\n        \"\"\"", "\n", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.get_special_tokens_mask": [[133, 150], ["list", "map"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "\n", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "==", "self", ".", "pad_token_id", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.create_token_type_ids_from_sequences": [[151, 161], ["len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A BERT sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "return", "len", "(", "token_ids_0", ")", "*", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.save_vocabulary": [[162, 180], ["os.path.isdir", "os.path.join", "open", "sorted", "icd_bert.ICDBertTokenizer.vocab.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "index", "=", "0", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "vocab_path", "\n", "", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "token", ",", "token_index", "in", "sorted", "(", "self", ".", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertEmbeddings.__init__": [[186, 194], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "transformers.modeling_bert.BertLayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertEmbeddings.forward": [[195, 210], ["icd_bert.ICDBertEmbeddings.LayerNorm", "icd_bert.ICDBertEmbeddings.dropout", "input_ids.size", "icd_bert.ICDBertEmbeddings.word_embeddings", "icd_bert.ICDBertEmbeddings.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "\n", "", "embeddings", "=", "inputs_embeds", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertModel.__init__": [[213, 222], ["transformers.BertModel.__init__", "icd_bert.ICDBertEmbeddings", "transformers.modeling_bert.BertEncoder", "transformers.modeling_bert.BertPooler", "icd_bert.ICDBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "ICDBertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertForMaskedLM.__init__": [[225, 232], ["transformers.BertForMaskedLM.__init__", "icd_bert.ICDBertModel", "transformers.modeling_bert.BertOnlyMLMHead", "icd_bert.ICDBertForMaskedLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "ICDBertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__init__": [[235, 267], ["os.path.isfile", "os.path.split", "os.path.split", "os.path.join", "os.path.exists", "logger.info", "logger.info", "logger.info", "open", "pickle.load", "open", "f.readlines", "tokenizer.convert_tokens_to_ids", "icd_bert.TextDataset.examples.append", "open", "pickle.dump", "tokenizer.tokenize", "len", "str", "len", "tokenizer.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.tokenize", "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.ICDBertTokenizer.build_inputs_with_special_tokens"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "\"train\"", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "directory", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "file_path", ")", "\n", "_", ",", "model_name", "=", "os", ".", "path", ".", "split", "(", "args", ".", "model_name_or_path", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "directory", ",", "model_name", "+", "\"_cached_lm_\"", "+", "str", "(", "block_size", ")", "+", "\"_\"", "+", "filename", "\n", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "                ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "directory", ")", "\n", "\n", "self", ".", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "texts", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "for", "text", "in", "texts", ":", "\n", "                ", "tokenized_text", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "text", ")", ")", "\n", "pad_size", "=", "args", ".", "block_size", "-", "len", "(", "tokenized_text", ")", "\n", "attention_mask", "=", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "+", "[", "0", "]", "*", "pad_size", "\n", "tokenized_text", "=", "tokenized_text", "+", "[", "tokenizer", ".", "pad_token_id", "]", "*", "pad_size", "\n", "self", ".", "examples", ".", "append", "(", "(", "\n", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "tokenized_text", ")", ",", "\n", "attention_mask", "\n", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__len__": [[268, 270], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.TextDataset.__getitem__": [[271, 274], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "input_ids", ",", "attention_mask", "=", "self", ".", "examples", "[", "item", "]", "\n", "return", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "attention_mask", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.load_vocab": [[41, 50], ["collections.OrderedDict", "enumerate", "open", "reader.readlines", "token.rstrip.rstrip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "tokens", "=", "reader", ".", "readlines", "(", ")", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token", "=", "token", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.MiuLab_ICD-Correlation.None.icd_bert.whitespace_tokenize": [[52, 59], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]]}