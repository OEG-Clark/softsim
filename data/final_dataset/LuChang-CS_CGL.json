{"home.repos.pwc.inspect_result.LuChang-CS_CGL.None.train_codes.load_data": [[26, 35], ["_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "open", "open", "open", "open", "open", "open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "load_data", "(", "note_use_summary", "=", "True", ")", "->", "(", "tuple", ",", "tuple", ",", "dict", ")", ":", "\n", "    ", "code_map", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "encoded_path", ",", "'code_map.pkl'", ")", ",", "'rb'", ")", ")", "\n", "dictionary", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "encoded_path", ",", "'dictionary_summary.pkl'", "if", "note_use_summary", "else", "'dictionary.pkl'", ")", ",", "'rb'", ")", ")", "\n", "\n", "codes_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'codes_dataset.pkl'", ")", ",", "'rb'", ")", ")", "\n", "time_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'time_dataset.pkl'", ")", ",", "'rb'", ")", ")", "\n", "note_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'note_dataset_summary.pkl'", "if", "note_use_summary", "else", "'note_dataset.pkl'", ")", ",", "'rb'", ")", ")", "\n", "auxiliary", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'auxiliary.pkl'", ")", ",", "'rb'", ")", ")", "\n", "return", "(", "code_map", ",", "dictionary", ")", ",", "(", "codes_dataset", ",", "time_dataset", ",", "note_dataset", ")", ",", "auxiliary", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.train_codes.historical_hot": [[37, 43], ["numpy.zeros", "enumerate", "len"], "function", ["None"], ["", "def", "historical_hot", "(", "code_x", ",", "code_num", ")", ":", "\n", "    ", "result", "=", "np", ".", "zeros", "(", "(", "len", "(", "code_x", ")", ",", "code_num", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "code_x", ")", ":", "\n", "        ", "for", "code", "in", "x", ":", "\n", "            ", "result", "[", "i", "]", "[", "code", "-", "1", "]", "=", "1", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.EvaluateCodesCallBack.__init__": [[48, 53], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_gen", ",", "y", ",", "historical", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "data_gen", "=", "data_gen", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "historical", "=", "historical", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.EvaluateCodesCallBack.on_epoch_end": [[54, 76], ["len", "range", "numpy.vstack", "metrics.f1", "metrics.top_k_prec_recall", "metrics.EvaluateCodesCallBack.model", "tensorflow.math.sigmoid", "tensorflow.argsort", "numpy.vstack.append", "metrics.calculate_occurred", "print", "print", "tensorflow.argsort.numpy"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.f1", "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.top_k_prec_recall", "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.calculate_occurred"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "step_size", "=", "len", "(", "self", ".", "data_gen", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "step_size", ")", ":", "\n", "            ", "batch_codes_x", ",", "batch_visit_lens", ",", "batch_note_x", ",", "batch_note_lens", "=", "self", ".", "data_gen", "[", "i", "]", "\n", "output", "=", "self", ".", "model", "(", "inputs", "=", "{", "\n", "'visit_codes'", ":", "batch_codes_x", ",", "\n", "'visit_lens'", ":", "batch_visit_lens", ",", "\n", "'word_ids'", ":", "batch_note_x", ",", "\n", "'word_lens'", ":", "batch_note_lens", "\n", "}", ",", "training", "=", "False", ")", "\n", "logits", "=", "tf", ".", "math", ".", "sigmoid", "(", "output", ")", "\n", "pred", "=", "tf", ".", "argsort", "(", "logits", ",", "axis", "=", "-", "1", ",", "direction", "=", "'DESCENDING'", ")", "\n", "preds", ".", "append", "(", "pred", ".", "numpy", "(", ")", ")", "\n", "", "preds", "=", "np", ".", "vstack", "(", "preds", ")", "\n", "f1_score", "=", "f1", "(", "self", ".", "y", ",", "preds", ")", "\n", "prec", ",", "recall", "=", "top_k_prec_recall", "(", "self", ".", "y", ",", "preds", ",", "ks", "=", "[", "10", ",", "20", ",", "30", ",", "40", "]", ")", "\n", "if", "self", ".", "historical", "is", "not", "None", ":", "\n", "            ", "r1", ",", "r2", "=", "calculate_occurred", "(", "self", ".", "historical", ",", "self", ".", "y", ",", "preds", ",", "ks", "=", "[", "10", ",", "20", ",", "30", ",", "40", "]", ")", "\n", "print", "(", "'\\t'", ",", "'f1_score:'", ",", "f1_score", ",", "'\\t'", ",", "'top_k_recall:'", ",", "recall", ",", "'\\t'", ",", "'occurred:'", ",", "r1", ",", "'\\t'", ",", "'not occurred:'", ",", "r2", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'\\t'", ",", "'f1_score:'", ",", "f1_score", ",", "'\\t'", ",", "'top_k_recall:'", ",", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.EvaluateHFCallBack.__init__": [[79, 83], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_gen", ",", "y", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "data_gen", "=", "data_gen", "\n", "self", ".", "y", "=", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.EvaluateHFCallBack.on_epoch_end": [[84, 103], ["len", "range", "numpy.concatenate", "numpy.concatenate", "sklearn.metrics.roc_auc_score", "sklearn.metrics.f1_score", "print", "metrics.EvaluateHFCallBack.model", "numpy.concatenate.append", "tensorflow.squeeze", "numpy.concatenate.append", "tensorflow.squeeze().numpy", "tensorflow.cast", "tensorflow.squeeze.numpy", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "step_size", "=", "len", "(", "self", ".", "data_gen", ")", "\n", "preds", ",", "outputs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "step_size", ")", ":", "\n", "            ", "batch_codes_x", ",", "batch_visit_lens", ",", "batch_note_x", ",", "batch_note_lens", "=", "self", ".", "data_gen", "[", "i", "]", "\n", "output", "=", "self", ".", "model", "(", "inputs", "=", "{", "\n", "'visit_codes'", ":", "batch_codes_x", ",", "\n", "'visit_lens'", ":", "batch_visit_lens", ",", "\n", "'word_ids'", ":", "batch_note_x", ",", "\n", "'word_lens'", ":", "batch_note_lens", "\n", "}", ",", "training", "=", "False", ")", "\n", "outputs", ".", "append", "(", "tf", ".", "squeeze", "(", "output", ")", ".", "numpy", "(", ")", ")", "\n", "pred", "=", "tf", ".", "squeeze", "(", "tf", ".", "cast", "(", "output", ">", "0.5", ",", "tf", ".", "int32", ")", ")", "\n", "preds", ".", "append", "(", "pred", ".", "numpy", "(", ")", ")", "\n", "", "outputs", "=", "np", ".", "concatenate", "(", "outputs", ")", "\n", "preds", "=", "np", ".", "concatenate", "(", "preds", ")", "\n", "auc", "=", "roc_auc_score", "(", "self", ".", "y", ",", "outputs", ")", "\n", "f1_score_", "=", "f1_score", "(", "self", ".", "y", ",", "preds", ")", "\n", "print", "(", "'\\t'", ",", "'auc:'", ",", "auc", ",", "'\\t'", ",", "'f1_score:'", ",", "f1_score_", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.f1": [[7, 13], ["numpy.zeros_like", "range", "sklearn.metrics.f1_score", "len", "numpy.sum"], "function", ["None"], ["def", "f1", "(", "y_true_hot", ",", "y_pred", ",", "metrics", "=", "'weighted'", ")", ":", "\n", "    ", "result", "=", "np", ".", "zeros_like", "(", "y_true_hot", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "result", ")", ")", ":", "\n", "        ", "true_number", "=", "np", ".", "sum", "(", "y_true_hot", "[", "i", "]", "==", "1", ")", "\n", "result", "[", "i", "]", "[", "y_pred", "[", "i", "]", "[", ":", "true_number", "]", "]", "=", "1", "\n", "", "return", "f1_score", "(", "y_true", "=", "y_true_hot", ",", "y_pred", "=", "result", ",", "average", "=", "metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.top_k_prec_recall": [[15, 27], ["numpy.zeros", "numpy.zeros", "zip", "[].tolist", "set", "enumerate", "len", "len", "set", "set.intersection", "len", "len", "len", "len", "len", "numpy.where"], "function", ["None"], ["", "def", "top_k_prec_recall", "(", "y_true_hot", ",", "y_pred", ",", "ks", ")", ":", "\n", "    ", "a", "=", "np", ".", "zeros", "(", "(", "len", "(", "ks", ")", ",", ")", ")", "\n", "r", "=", "np", ".", "zeros", "(", "(", "len", "(", "ks", ")", ",", ")", ")", "\n", "for", "pred", ",", "true_hot", "in", "zip", "(", "y_pred", ",", "y_true_hot", ")", ":", "\n", "        ", "true", "=", "np", ".", "where", "(", "true_hot", "==", "1", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "t", "=", "set", "(", "true", ")", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "ks", ")", ":", "\n", "            ", "p", "=", "set", "(", "pred", "[", ":", "k", "]", ")", "\n", "it", "=", "p", ".", "intersection", "(", "t", ")", "\n", "a", "[", "i", "]", "+=", "len", "(", "it", ")", "/", "k", "\n", "r", "[", "i", "]", "+=", "len", "(", "it", ")", "/", "len", "(", "t", ")", "\n", "", "", "return", "a", "/", "len", "(", "y_true_hot", ")", ",", "r", "/", "len", "(", "y_true_hot", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.metrics.calculate_occurred": [[29, 45], ["numpy.zeros", "numpy.zeros", "numpy.sum", "enumerate", "numpy.zeros_like", "range", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.mean", "numpy.mean", "len", "len", "len", "numpy.logical_not", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "calculate_occurred", "(", "historical", ",", "y", ",", "preds", ",", "ks", ")", ":", "\n", "    ", "r1", "=", "np", ".", "zeros", "(", "(", "len", "(", "ks", ")", ",", ")", ")", "\n", "r2", "=", "np", ".", "zeros", "(", "(", "len", "(", "ks", ")", ",", ")", ")", "\n", "n", "=", "np", ".", "sum", "(", "y", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "ks", ")", ":", "\n", "        ", "n_k", "=", "n", "\n", "pred_k", "=", "np", ".", "zeros_like", "(", "y", ")", "\n", "for", "T", "in", "range", "(", "len", "(", "pred_k", ")", ")", ":", "\n", "            ", "pred_k", "[", "T", "]", "[", "preds", "[", "T", "]", "[", ":", "k", "]", "]", "=", "1", "\n", "", "pred_occurred", "=", "np", ".", "logical_and", "(", "historical", ",", "pred_k", ")", "\n", "pred_not_occurred", "=", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "historical", ")", ",", "pred_k", ")", "\n", "pred_occurred_true", "=", "np", ".", "logical_and", "(", "pred_occurred", ",", "y", ")", "\n", "pred_not_occurred_true", "=", "np", ".", "logical_and", "(", "pred_not_occurred", ",", "y", ")", "\n", "r1", "[", "i", "]", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "pred_occurred_true", ",", "axis", "=", "-", "1", ")", "/", "n_k", ")", "\n", "r2", "[", "i", "]", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "pred_not_occurred_true", ",", "axis", "=", "-", "1", ")", "/", "n_k", ")", "\n", "", "return", "r1", ",", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.loss.medical_codes_loss": [[4, 6], ["tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "function", ["None"], ["def", "medical_codes_loss", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "y_true", ",", "logits", "=", "y_pred", ")", ",", "axis", "=", "1", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.train_hf.load_data": [[25, 35], ["_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "_pickle.load", "open", "open", "open", "open", "open", "open", "open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "load_data", "(", "note_use_summary", "=", "True", ")", "->", "(", "tuple", ",", "tuple", ",", "dict", ")", ":", "\n", "    ", "code_map", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "encoded_path", ",", "'code_map.pkl'", ")", ",", "'rb'", ")", ")", "\n", "dictionary", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "encoded_path", ",", "'dictionary_summary.pkl'", "if", "note_use_summary", "else", "'dictionary.pkl'", ")", ",", "'rb'", ")", ")", "\n", "\n", "codes_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'codes_dataset.pkl'", ")", ",", "'rb'", ")", ")", "\n", "time_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'time_dataset.pkl'", ")", ",", "'rb'", ")", ")", "\n", "note_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'note_dataset_summary.pkl'", "if", "note_use_summary", "else", "'note_dataset.pkl'", ")", ",", "'rb'", ")", ")", "\n", "hf_dataset", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'heart_failure.pkl'", ")", ",", "'rb'", ")", ")", "\n", "auxiliary", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "standard_path", ",", "'auxiliary.pkl'", ")", ",", "'rb'", ")", ")", "\n", "return", "(", "code_map", ",", "dictionary", ")", ",", "(", "codes_dataset", ",", "time_dataset", ",", "note_dataset", ",", "hf_dataset", ")", ",", "auxiliary", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.__init__": [[5, 12], ["numpy.arange", "utils.DataGenerator.on_epoch_end", "len", "len"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.on_epoch_end"], ["    ", "def", "__init__", "(", "self", ",", "inputs", ",", "shuffle", "=", "True", ",", "batch_size", "=", "32", ")", ":", "\n", "        ", "assert", "len", "(", "inputs", ")", ">", "0", "\n", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "idx", "=", "np", ".", "arange", "(", "len", "(", "inputs", "[", "0", "]", ")", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "on_epoch_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.data_length": [[13, 15], ["len"], "methods", ["None"], ["", "def", "data_length", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.__len__": [[16, 20], ["utils.DataGenerator.data_length"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.data_length"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "n", "=", "self", ".", "data_length", "(", ")", "\n", "len_", "=", "n", "//", "self", ".", "batch_size", "\n", "return", "len_", "if", "n", "%", "self", ".", "batch_size", "==", "0", "else", "len_", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.__getitem__": [[21, 29], ["data.append"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "start", "=", "index", "*", "self", ".", "batch_size", "\n", "end", "=", "start", "+", "self", ".", "batch_size", "\n", "index", "=", "self", ".", "idx", "[", "start", ":", "end", "]", "\n", "data", "=", "[", "]", "\n", "for", "x", "in", "self", ".", "inputs", ":", "\n", "            ", "data", ".", "append", "(", "x", "[", "start", ":", "end", "]", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.on_epoch_end": [[30, 33], ["numpy.random.shuffle"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.None.utils.DataGenerator.set_batch_size": [[34, 36], ["None"], "methods", ["None"], ["", "", "def", "set_batch_size", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.HierarchicalEmbedding.__init__": [[10, 19], ["tensorflow.keras.layers.Layer.__init__", "len", "layers.HierarchicalEmbedding.add_weight", "enumerate", "tensorflow.keras.initializers.GlorotUniform", "zip"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "code_levels", ",", "code_num_in_levels", ",", "code_dims", ",", "name", "=", "'hierarchical_embedding'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "level_num", "=", "len", "(", "code_num_in_levels", ")", "\n", "self", ".", "code_levels", "=", "code_levels", "# (leaf code num * level_num)", "\n", "self", ".", "level_embeddings", "=", "[", "self", ".", "add_weight", "(", "name", "=", "'hier_emb_level_%d'", "%", "level", ",", "\n", "shape", "=", "(", "code_num", ",", "code_dim", ")", ",", "\n", "initializer", "=", "GlorotUniform", "(", ")", ",", "\n", "trainable", "=", "True", ")", "\n", "for", "level", ",", "(", "code_num", ",", "code_dim", ")", "in", "enumerate", "(", "zip", "(", "code_num_in_levels", ",", "code_dims", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.HierarchicalEmbedding.call": [[20, 28], ["tensorflow.nn.embedding_lookup", "tensorflow.keras.layers.Concatenate", "range"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            return: (code_num, embedding_size)\n        \"\"\"", "\n", "embeddings", "=", "[", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "level_embeddings", "[", "level", "]", ",", "self", ".", "code_levels", "[", ":", ",", "level", "]", ")", "\n", "for", "level", "in", "range", "(", "self", ".", "level_num", ")", "]", "\n", "embeddings", "=", "Concatenate", "(", ")", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.PatientEmbedding.__init__": [[31, 37], ["tensorflow.keras.layers.Layer.__init__", "layers.PatientEmbedding.add_weight", "tensorflow.keras.initializers.GlorotUniform"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "patient_num", ",", "patient_dim", ",", "name", "=", "'patient_embedding'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "patient_embeddings", "=", "self", ".", "add_weight", "(", "name", "=", "'p_emb'", ",", "\n", "shape", "=", "(", "patient_num", ",", "patient_dim", ")", ",", "\n", "initializer", "=", "GlorotUniform", "(", ")", ",", "\n", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.PatientEmbedding.call": [[38, 40], ["None"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "patient_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.WordEmbedding.__init__": [[43, 45], ["tensorflow.keras.layers.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "word_num", ",", "word_dim", ",", "embeddings_initializer", "=", "'glorot_uniform'", ",", "name", "=", "'word_embedding'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "word_num", ",", "word_dim", ",", "embeddings_initializer", "=", "embeddings_initializer", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.GraphConvBlock.__init__": [[48, 55], ["tensorflow.keras.layers.Layer.__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.BatchNormalization"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_type", ",", "dim", ",", "adj", ",", "name", "=", "'graph_conv_block'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "node_type", "=", "node_type", "\n", "self", ".", "adj", "=", "adj", "\n", "self", ".", "dense", "=", "Dense", "(", "dim", ",", "activation", "=", "None", ",", "name", "=", "name", "+", "'_dense'", ")", "\n", "self", ".", "activation", "=", "Activation", "(", "'relu'", ",", "name", "=", "name", "+", "'_activation'", ")", "\n", "self", ".", "bn", "=", "BatchNormalization", "(", "name", "=", "name", "+", "'bn'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.GraphConvBlock.call": [[56, 65], ["layers.GraphConvBlock.dense", "layers.GraphConvBlock.bn", "layers.GraphConvBlock.activation", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "embedding", ",", "embedding_neighbor", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "output", "=", "embedding", "+", "tf", ".", "matmul", "(", "self", ".", "adj", ",", "embedding_neighbor", ")", "\n", "if", "self", ".", "node_type", "==", "'code'", ":", "\n", "            ", "assert", "weight_decay", "is", "not", "None", "\n", "output", "+=", "tf", ".", "matmul", "(", "weight_decay", ",", "embedding", ")", "\n", "", "output", "=", "self", ".", "dense", "(", "output", ")", "\n", "output", "=", "self", ".", "bn", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.GraphConvolution.__init__": [[72, 96], ["tensorflow.keras.layers.Layer.__init__", "layers.norm_no_nan", "layers.norm_no_nan", "layers.GraphConvolution.add_weight", "layers.GraphConvolution.add_weight", "tensorflow.transpose", "layers.GraphConvBlock", "layers.GraphConvBlock", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "enumerate", "enumerate", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__", "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.norm_no_nan", "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.norm_no_nan"], ["    ", "def", "__init__", "(", "self", ",", "patient_dim", ",", "code_dim", ",", "\n", "patient_code_adj", ",", "code_code_adj", ",", "\n", "patient_hidden_dims", ",", "code_hidden_dims", ",", "name", "=", "'graph_convolution'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "patient_code_adj", "=", "norm_no_nan", "(", "patient_code_adj", ")", "# (patient_num, code_num)", "\n", "self", ".", "code_patient_adj", "=", "norm_no_nan", "(", "tf", ".", "transpose", "(", "patient_code_adj", ")", ")", "# (code_num, patient_num)", "\n", "self", ".", "code_code_adj", "=", "code_code_adj", "# (code_num, code_num)", "\n", "\n", "self", ".", "patient_blocks", "=", "[", "\n", "GraphConvBlock", "(", "'patient'", ",", "dim", ",", "self", ".", "patient_code_adj", ",", "name", "=", "'patient_graph_block_%d'", "%", "layer", ")", "\n", "for", "layer", ",", "dim", "in", "enumerate", "(", "patient_hidden_dims", ")", "]", "\n", "self", ".", "code_blocks", "=", "[", "GraphConvBlock", "(", "'code'", ",", "dim", ",", "self", ".", "code_patient_adj", ",", "name", "=", "'code_graph_block_%d'", "%", "layer", ")", "\n", "for", "layer", ",", "dim", "in", "enumerate", "(", "code_hidden_dims", ")", "]", "\n", "\n", "c2p_dims", "=", "(", "[", "patient_dim", "]", "+", "patient_hidden_dims", ")", "[", ":", "-", "1", "]", "\n", "p2c_dims", "=", "(", "[", "code_dim", "]", "+", "code_hidden_dims", ")", "[", ":", "-", "1", "]", "\n", "self", ".", "c2p_denses", "=", "[", "Dense", "(", "dim", ",", "activation", "=", "None", ",", "name", "=", "'code_to_patient_dense_%d'", "%", "layer", ")", "\n", "for", "layer", ",", "dim", "in", "enumerate", "(", "c2p_dims", ")", "]", "\n", "self", ".", "p2c_denses", "=", "[", "Dense", "(", "dim", ",", "activation", "=", "None", ",", "name", "=", "'patient_to_code_dense_%d'", "%", "layer", ")", "\n", "for", "layer", ",", "dim", "in", "enumerate", "(", "p2c_dims", ")", "]", "\n", "\n", "code_num", "=", "code_code_adj", ".", "shape", "[", "0", "]", "\n", "self", ".", "miu", "=", "self", ".", "add_weight", "(", "name", "=", "'miu'", ",", "shape", "=", "(", "code_num", ",", ")", ",", "trainable", "=", "True", ")", "\n", "self", ".", "theta", "=", "self", ".", "add_weight", "(", "name", "=", "'theta'", ",", "shape", "=", "(", "code_num", ",", ")", ",", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.GraphConvolution.call": [[97, 111], ["tensorflow.nn.sigmoid", "layers.norm_no_nan", "zip", "c2p_dense", "patient_block", "p2c_dense", "code_block"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.norm_no_nan"], ["", "def", "call", "(", "self", ",", "patient_embeddings", ",", "code_embeddings", ")", ":", "\n", "        ", "weight_decay", "=", "tf", ".", "nn", ".", "sigmoid", "(", "self", ".", "miu", "*", "self", ".", "code_code_adj", "+", "self", ".", "theta", ")", "\n", "weight_decay", "=", "norm_no_nan", "(", "weight_decay", ")", "\n", "# weight_decay = None", "\n", "for", "c2p_dense", ",", "p2c_dense", ",", "patient_block", ",", "code_block", "in", "zip", "(", "self", ".", "c2p_denses", ",", "self", ".", "p2c_denses", ",", "\n", "self", ".", "patient_blocks", ",", "self", ".", "code_blocks", ")", ":", "\n", "            ", "code_embeddings_p", "=", "c2p_dense", "(", "code_embeddings", ")", "\n", "patient_embeddings_new", "=", "patient_block", "(", "patient_embeddings", ",", "code_embeddings_p", ")", "\n", "patient_embeddings_c", "=", "p2c_dense", "(", "patient_embeddings", ")", "\n", "code_embeddings", "=", "code_block", "(", "code_embeddings", ",", "patient_embeddings_c", ",", "weight_decay", ")", "\n", "patient_embeddings", "=", "patient_embeddings_new", "\n", "", "patient_embeddings_c", "=", "self", ".", "p2c_denses", "[", "-", "1", "]", "(", "patient_embeddings", ")", "\n", "code_embeddings", "=", "self", ".", "code_blocks", "[", "-", "1", "]", "(", "code_embeddings", ",", "patient_embeddings_c", ",", "weight_decay", ")", "\n", "return", "patient_embeddings", ",", "code_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.VisitEmbedding.__init__": [[114, 117], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "max_seq_len", ",", "name", "=", "'visit_embedding'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.VisitEmbedding.call": [[118, 131], ["tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.math.divide_no_nan", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.sequence_mask", "tensorflow.cast"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "code_embeddings", ",", "visit_codes", ",", "visit_lens", ")", ":", "\n", "        ", "\"\"\"\n            visit_codes: (batch_size, max_seq_len, max_code_num_in_a_visit)\n        \"\"\"", "\n", "visit_codes_embedding", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "code_embeddings", ",", "visit_codes", ")", "# (batch_size, max_seq_len, max_code_num_in_a_visit, code_dim)", "\n", "visit_codes_mask", "=", "tf", ".", "expand_dims", "(", "visit_codes", ">", "0", ",", "axis", "=", "-", "1", ")", "\n", "visit_codes_mask", "=", "tf", ".", "cast", "(", "visit_codes_mask", ",", "visit_codes_embedding", ".", "dtype", ")", "\n", "visit_codes_embedding", "*=", "visit_codes_mask", "# (batch_size, max_seq_len, max_code_num_in_a_visit, code_dim)", "\n", "visit_codes_num", "=", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "visit_codes", ">", "0", ",", "visit_codes_embedding", ".", "dtype", ")", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "\n", "visits_embeddings", "=", "tf", ".", "math", ".", "divide_no_nan", "(", "tf", ".", "reduce_sum", "(", "visit_codes_embedding", ",", "axis", "=", "-", "2", ")", ",", "visit_codes_num", ")", "# (batch_size, max_seq_len, code_dim)", "\n", "visit_mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "visit_lens", ",", "self", ".", "max_seq_len", ",", "dtype", "=", "visits_embeddings", ".", "dtype", ")", ",", "axis", "=", "-", "1", ")", "# (batch_size, max_seq_len, 1)", "\n", "visits_embeddings", "*=", "visit_mask", "# (batch_size, max_seq_len, code_dim)", "\n", "return", "visits_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.Attention.__init__": [[141, 146], ["tensorflow.keras.layers.Layer.__init__", "layers.Attention.add_weight", "tensorflow.keras.initializers.GlorotUniform"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_dim", ",", "name", "=", "'attention'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "attention_dim", "=", "attention_dim", "\n", "self", ".", "u_omega", "=", "self", ".", "add_weight", "(", "name", "=", "name", "+", "'_u'", ",", "shape", "=", "(", "attention_dim", ",", ")", ",", "initializer", "=", "GlorotUniform", "(", ")", ")", "\n", "self", ".", "w_omega", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.Attention.build": [[147, 150], ["layers.Attention.add_weight", "tensorflow.keras.initializers.GlorotUniform"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "hidden_size", "=", "input_shape", "[", "-", "1", "]", "\n", "self", ".", "w_omega", "=", "self", ".", "add_weight", "(", "name", "=", "self", ".", "name", "+", "'_w'", ",", "shape", "=", "(", "hidden_size", ",", "self", ".", "attention_dim", ")", ",", "initializer", "=", "GlorotUniform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.Attention.call": [[151, 164], ["tensorflow.matmul", "tensorflow.tensordot", "tensorflow.reduce_sum", "layers.masked_softmax", "tensorflow.nn.softmax", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.masked_softmax"], ["", "def", "call", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            x: (batch_size, max_seq_len, rnn_dim[-1] / hidden_size)\n        \"\"\"", "\n", "t", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "w_omega", ")", "\n", "vu", "=", "tf", ".", "tensordot", "(", "t", ",", "self", ".", "u_omega", ",", "axes", "=", "1", ")", "# (batch_size, max_seq_len)", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "vu", "*=", "mask", "\n", "alphas", "=", "masked_softmax", "(", "vu", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "alphas", "=", "tf", ".", "nn", ".", "softmax", "(", "vu", ")", "# (batch_size, max_seq_len)", "\n", "", "output", "=", "tf", ".", "reduce_sum", "(", "x", "*", "tf", ".", "expand_dims", "(", "alphas", ",", "-", "1", ")", ",", "axis", "=", "-", "2", ")", "# (batch_size, rnn_dim[-1] / hidden_size)", "\n", "return", "output", ",", "alphas", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.TemporalEmbedding.__init__": [[167, 174], ["tensorflow.keras.layers.Layer.__init__", "tensorflow.keras.layers.StackedRNNCells", "tensorflow.keras.layers.RNN", "layers.Attention", "cell_type"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_dims", ",", "attention_dim", ",", "max_seq_len", ",", "cell_type", "=", "GRUCell", ",", "name", "=", "'code_ra'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "rnn_cells", "=", "[", "cell_type", "(", "rnn_dim", ")", "for", "rnn_dim", "in", "rnn_dims", "]", "\n", "stacked_rnn", "=", "StackedRNNCells", "(", "rnn_cells", ")", "\n", "self", ".", "rnn_layers", "=", "RNN", "(", "stacked_rnn", ",", "return_sequences", "=", "True", ",", "name", "=", "name", "+", "'rnn'", ")", "\n", "self", ".", "attention", "=", "Attention", "(", "attention_dim", ",", "name", "=", "name", "+", "'_attention'", ")", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.TemporalEmbedding.call": [[175, 180], ["tensorflow.sequence_mask", "layers.TemporalEmbedding.attention", "layers.TemporalEmbedding.rnn_layers", "tensorflow.expand_dims"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "embeddings", ",", "lens", ")", ":", "\n", "        ", "seq_mask", "=", "tf", ".", "sequence_mask", "(", "lens", ",", "self", ".", "max_seq_len", ",", "dtype", "=", "embeddings", ".", "dtype", ")", "\n", "outputs", "=", "self", ".", "rnn_layers", "(", "embeddings", ")", "*", "tf", ".", "expand_dims", "(", "seq_mask", ",", "axis", "=", "-", "1", ")", "# (batch_size, max_seq_len, rnn_dim[-1])", "\n", "outputs", ",", "alphas", "=", "self", ".", "attention", "(", "outputs", ",", "seq_mask", ")", "# (batch_size, rnn_dim[-1])", "\n", "return", "outputs", ",", "alphas", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.NoteAttention.__init__": [[189, 193], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_dim", ",", "name", "=", "'attention'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "attention_dim", "=", "attention_dim", "\n", "self", ".", "w_omega", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.NoteAttention.build": [[194, 197], ["layers.NoteAttention.add_weight", "tensorflow.keras.initializers.GlorotUniform"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "hidden_size", "=", "input_shape", "[", "-", "1", "]", "\n", "self", ".", "w_omega", "=", "self", ".", "add_weight", "(", "name", "=", "self", ".", "name", "+", "'_w'", ",", "shape", "=", "(", "hidden_size", ",", "self", ".", "attention_dim", ")", ",", "initializer", "=", "GlorotUniform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.NoteAttention.call": [[198, 211], ["tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "layers.masked_softmax", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.masked_softmax"], ["", "def", "call", "(", "self", ",", "x", ",", "ctx_vector", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            x: (batch_size, max_seq_len, rnn_dim[-1] / hidden_size)\n        \"\"\"", "\n", "t", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "w_omega", ")", "\n", "vu", "=", "tf", ".", "reduce_sum", "(", "t", "*", "tf", ".", "expand_dims", "(", "ctx_vector", ",", "axis", "=", "1", ")", ",", "axis", "=", "-", "1", ")", "# (batch_size, max_seq_len)", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "vu", "*=", "mask", "\n", "alphas", "=", "masked_softmax", "(", "vu", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "alphas", "=", "tf", ".", "nn", ".", "softmax", "(", "vu", ")", "# (batch_size, max_seq_len)", "\n", "", "output", "=", "tf", ".", "reduce_sum", "(", "t", "*", "tf", ".", "expand_dims", "(", "alphas", ",", "-", "1", ")", ",", "axis", "=", "-", "2", ")", "# (batch_size, rnn_dim[-1] / hidden_size)", "\n", "return", "output", ",", "alphas", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.NoteEmbedding.__init__": [[214, 220], ["tensorflow.keras.layers.Layer.__init__", "layers.NoteAttention", "print"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_dim", ",", "max_seq_len", ",", "lambda_", ",", "name", "=", "'note_embedding'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "attention", "=", "NoteAttention", "(", "attention_dim", ",", "name", "=", "name", "+", "'_attention'", ")", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "print", "(", "max_seq_len", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.NoteEmbedding.call": [[221, 230], ["tensorflow.sequence_mask", "layers.NoteEmbedding.attention", "tensorflow.expand_dims", "layers.NoteEmbedding.add_loss", "tensorflow.reduce_mean", "layers.log_no_nan", "layers.log_no_nan", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.log_no_nan", "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.log_no_nan"], ["", "def", "call", "(", "self", ",", "word_embeddings", ",", "word_lens", ",", "visit_output", ",", "tf_idf", "=", "None", ",", "training", "=", "True", ")", ":", "\n", "        ", "word_mask", "=", "tf", ".", "sequence_mask", "(", "word_lens", ",", "self", ".", "max_seq_len", ",", "dtype", "=", "word_embeddings", ".", "dtype", ")", "\n", "word_embeddings", "=", "word_embeddings", "*", "tf", ".", "expand_dims", "(", "word_mask", ",", "axis", "=", "-", "1", ")", "\n", "outputs", ",", "alphas", "=", "self", ".", "attention", "(", "word_embeddings", ",", "visit_output", ",", "word_mask", ")", "\n", "if", "training", ":", "\n", "            ", "loss", "=", "alphas", "*", "log_no_nan", "(", "tf_idf", ")", "+", "(", "1", "-", "alphas", ")", "*", "log_no_nan", "(", "1", "-", "tf_idf", ")", "\n", "loss", "=", "-", "self", ".", "lambda_", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "loss", ",", "axis", "=", "-", "1", ")", ")", "\n", "self", ".", "add_loss", "(", "loss", ")", "\n", "", "return", "outputs", ",", "alphas", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.norm_no_nan": [[67, 69], ["tensorflow.math.divide_no_nan", "tensorflow.reduce_sum"], "function", ["None"], ["", "", "def", "norm_no_nan", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "math", ".", "divide_no_nan", "(", "x", ",", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.masked_softmax": [[133, 138], ["tensorflow.math.divide_no_nan", "tensorflow.reduce_max", "tensorflow.exp", "tensorflow.reduce_sum"], "function", ["None"], ["", "", "def", "masked_softmax", "(", "inputs", ",", "mask", ")", ":", "\n", "    ", "inputs", "=", "inputs", "-", "tf", ".", "reduce_max", "(", "inputs", ",", "keepdims", "=", "True", ",", "axis", "=", "-", "1", ")", "\n", "exp", "=", "tf", ".", "exp", "(", "inputs", ")", "*", "mask", "\n", "result", "=", "tf", ".", "math", ".", "divide_no_nan", "(", "exp", ",", "tf", ".", "reduce_sum", "(", "exp", ",", "keepdims", "=", "True", ",", "axis", "=", "-", "1", ")", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.layers.log_no_nan": [[182, 186], ["tensorflow.cast", "tensorflow.math.log"], "function", ["None"], ["", "", "def", "log_no_nan", "(", "x", ")", ":", "\n", "    ", "mask", "=", "tf", ".", "cast", "(", "x", "==", "0", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x", "=", "x", "+", "mask", "\n", "return", "tf", ".", "math", ".", "log", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGLFeatureExtractor.__init__": [[12, 46], ["tensorflow.keras.layers.Layer.__init__", "models.layers.HierarchicalEmbedding", "models.layers.PatientEmbedding", "models.layers.GraphConvolution", "models.layers.VisitEmbedding", "models.layers.TemporalEmbedding", "models.layers.WordEmbedding", "models.layers.NoteEmbedding", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "hyper_params", ",", "name", "=", "'cgl_feature'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "hyper_params", "=", "hyper_params", "\n", "self", ".", "hierarchical_embedding_layer", "=", "HierarchicalEmbedding", "(", "\n", "code_levels", "=", "config", "[", "'code_levels'", "]", ",", "\n", "code_num_in_levels", "=", "config", "[", "'code_num_in_levels'", "]", ",", "\n", "code_dims", "=", "hyper_params", "[", "'code_dims'", "]", ")", "\n", "self", ".", "patient_embedding_layer", "=", "PatientEmbedding", "(", "\n", "patient_num", "=", "config", "[", "'patient_num'", "]", ",", "\n", "patient_dim", "=", "hyper_params", "[", "'patient_dim'", "]", ")", "\n", "self", ".", "graph_convolution_layer", "=", "GraphConvolution", "(", "\n", "patient_dim", "=", "hyper_params", "[", "'patient_dim'", "]", ",", "\n", "code_dim", "=", "np", ".", "sum", "(", "hyper_params", "[", "'code_dims'", "]", ")", ",", "\n", "patient_code_adj", "=", "config", "[", "'patient_code_adj'", "]", ",", "\n", "code_code_adj", "=", "config", "[", "'code_code_adj'", "]", ",", "\n", "patient_hidden_dims", "=", "hyper_params", "[", "'patient_hidden_dims'", "]", ",", "\n", "code_hidden_dims", "=", "hyper_params", "[", "'code_hidden_dims'", "]", ")", "\n", "self", ".", "visit_embedding_layer", "=", "VisitEmbedding", "(", "\n", "max_seq_len", "=", "config", "[", "'max_visit_seq_len'", "]", ")", "\n", "self", ".", "visit_temporal_embedding_layer", "=", "TemporalEmbedding", "(", "\n", "rnn_dims", "=", "hyper_params", "[", "'visit_rnn_dims'", "]", ",", "\n", "attention_dim", "=", "hyper_params", "[", "'visit_attention_dim'", "]", ",", "\n", "max_seq_len", "=", "config", "[", "'max_visit_seq_len'", "]", ",", "\n", "name", "=", "'visit_temporal'", ")", "\n", "if", "config", "[", "'use_note'", "]", ":", "\n", "            ", "self", ".", "word_embedding_layer", "=", "WordEmbedding", "(", "\n", "word_num", "=", "config", "[", "'word_num'", "]", ",", "\n", "word_dim", "=", "hyper_params", "[", "'word_dim'", "]", ")", "\n", "self", ".", "note_embedding_layer", "=", "NoteEmbedding", "(", "\n", "attention_dim", "=", "hyper_params", "[", "'note_attention_dim'", "]", ",", "\n", "max_seq_len", "=", "config", "[", "'max_note_seq_len'", "]", ",", "\n", "lambda_", "=", "config", "[", "'lambda'", "]", ",", "\n", "name", "=", "'note_embedding'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGLFeatureExtractor.call": [[47, 72], ["tensorflow.reshape", "tensorflow.reshape", "model.CGLFeatureExtractor.hierarchical_embedding_layer", "model.CGLFeatureExtractor.patient_embedding_layer", "model.CGLFeatureExtractor.graph_convolution_layer", "model.CGLFeatureExtractor.visit_embedding_layer", "model.CGLFeatureExtractor.visit_temporal_embedding_layer", "model.CGLFeatureExtractor.word_embedding_layer", "model.CGLFeatureExtractor.note_embedding_layer", "tensorflow.math.l2_normalize", "tensorflow.math.l2_normalize", "tensorflow.keras.layers.Concatenate"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "True", ")", ":", "\n", "        ", "visit_codes", "=", "inputs", "[", "'visit_codes'", "]", "# (batch_size, max_seq_len, max_code_num_in_a_visit)", "\n", "visit_lens", "=", "tf", ".", "reshape", "(", "inputs", "[", "'visit_lens'", "]", ",", "(", "-", "1", ",", ")", ")", "# (batch_size, )", "\n", "word_ids", "=", "inputs", "[", "'word_ids'", "]", "# (batch_size, max_word_num_in_a_note)", "\n", "word_tf_idf", "=", "inputs", "[", "'tf_idf'", "]", "if", "training", "and", "self", ".", "config", "[", "'use_note'", "]", "else", "None", "# (batch_size, max_word_num_in_a_note)", "\n", "word_lens", "=", "tf", ".", "reshape", "(", "inputs", "[", "'word_lens'", "]", ",", "(", "-", "1", ",", ")", ")", "# (batch_size, )", "\n", "code_embeddings", "=", "self", ".", "hierarchical_embedding_layer", "(", "None", ")", "\n", "patient_embddings", "=", "self", ".", "patient_embedding_layer", "(", "None", ")", "\n", "\n", "patient_embddings", ",", "code_embeddings", "=", "self", ".", "graph_convolution_layer", "(", "\n", "patient_embeddings", "=", "patient_embddings", ",", "code_embeddings", "=", "code_embeddings", ")", "\n", "visits_embeddings", "=", "self", ".", "visit_embedding_layer", "(", "\n", "code_embeddings", "=", "code_embeddings", ",", "\n", "visit_codes", "=", "visit_codes", ",", "\n", "visit_lens", "=", "visit_lens", ")", "\n", "visit_output", ",", "alpha_visit", "=", "self", ".", "visit_temporal_embedding_layer", "(", "visits_embeddings", ",", "visit_lens", ")", "\n", "output", "=", "visit_output", "\n", "if", "self", ".", "config", "[", "'use_note'", "]", ":", "\n", "            ", "words_embeddings", "=", "self", ".", "word_embedding_layer", "(", "word_ids", ")", "\n", "note_output", ",", "alpha_word", "=", "self", ".", "note_embedding_layer", "(", "words_embeddings", ",", "word_lens", ",", "visit_output", ",", "word_tf_idf", ",", "training", ")", "\n", "note_output", "=", "tf", ".", "math", ".", "l2_normalize", "(", "note_output", ",", "axis", "=", "-", "1", ")", "\n", "visit_output", "=", "tf", ".", "math", ".", "l2_normalize", "(", "visit_output", ",", "axis", "=", "-", "1", ")", "\n", "output", "=", "Concatenate", "(", ")", "(", "[", "visit_output", ",", "note_output", "]", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.Classifier.__init__": [[75, 79], ["tensorflow.keras.layers.Layer.__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_dim", ",", "activation", "=", "None", ",", "name", "=", "'classifier'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "dense", "=", "Dense", "(", "output_dim", ",", "activation", "=", "activation", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.Classifier.call": [[80, 85], ["model.Classifier.dropout", "model.Classifier.dense"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "output", "=", "self", ".", "dense", "(", "x", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__": [[88, 92], ["tensorflow.keras.Model.__init__", "model.CGLFeatureExtractor", "model.Classifier"], "methods", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "hyper_params", ",", "name", "=", "'cgl'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "cgl_feature_extractor", "=", "CGLFeatureExtractor", "(", "config", ",", "hyper_params", ")", "\n", "self", ".", "classifier", "=", "Classifier", "(", "config", "[", "'output_dim'", "]", ",", "activation", "=", "config", "[", "'activation'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.models.model.CGL.call": [[93, 97], ["model.CGL.cgl_feature_extractor", "model.CGL.classifier"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "True", ")", ":", "\n", "        ", "output", "=", "self", ".", "cgl_feature_extractor", "(", "inputs", ",", "training", "=", "training", ")", "\n", "output", "=", "self", ".", "classifier", "(", "output", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.encode_code": [[12, 25], ["print", "dict", "enumerate", "admission_codes.items", "admission_codes.items", "len"], "function", ["None"], ["def", "encode_code", "(", "admission_codes", ":", "dict", ")", "->", "(", "dict", ",", "dict", ")", ":", "\n", "    ", "print", "(", "'encoding code ...'", ")", "\n", "code_map", "=", "dict", "(", ")", "\n", "for", "i", ",", "(", "admission_id", ",", "codes", ")", "in", "enumerate", "(", "admission_codes", ".", "items", "(", ")", ")", ":", "\n", "        ", "for", "code", "in", "codes", ":", "\n", "            ", "if", "code", "not", "in", "code_map", ":", "\n", "                ", "code_map", "[", "code", "]", "=", "len", "(", "code_map", ")", "+", "1", "\n", "\n", "", "", "", "admission_codes_encoded", "=", "{", "\n", "admission_id", ":", "[", "code_map", "[", "code", "]", "for", "code", "in", "codes", "]", "\n", "for", "admission_id", ",", "codes", "in", "admission_codes", ".", "items", "(", ")", "\n", "}", "\n", "return", "admission_codes_encoded", ",", "code_map", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.encode_time_duration": [[27, 37], ["print", "dict", "patient_admission.items", "range", "len", "duration.append"], "function", ["None"], ["", "def", "encode_time_duration", "(", "patient_admission", ":", "dict", ")", "->", "dict", ":", "\n", "    ", "print", "(", "'encoding time duration ...'", ")", "\n", "patient_time_duration_encoded", "=", "dict", "(", ")", "\n", "for", "pid", ",", "admissions", "in", "patient_admission", ".", "items", "(", ")", ":", "\n", "        ", "duration", "=", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "admissions", ")", ")", ":", "\n", "            ", "days", "=", "(", "admissions", "[", "i", "]", "[", "'admission_time'", "]", "-", "admissions", "[", "i", "-", "1", "]", "[", "'admission_time'", "]", ")", ".", "days", "\n", "duration", ".", "append", "(", "days", ")", "\n", "", "patient_time_duration_encoded", "[", "pid", "]", "=", "duration", "\n", "", "return", "patient_time_duration_encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.extract_word": [[39, 56], ["re.sub", "nltk.tokenize.word_tokenize", "re.sub.strip().lower", "ps.stem().lower", "re.sub.strip", "clean_words.append", "ps.stem"], "function", ["None"], ["", "def", "extract_word", "(", "text", ":", "str", ")", "->", "list", ":", "\n", "    ", "\"\"\"Extract words from a text\n    @param: text, str\n    @param: max_len, the maximum length of text we want to extract, default None\n    @return: list, words list in the text\n    \"\"\"", "\n", "# replace non-word-character with space", "\n", "text", "=", "re", ".", "sub", "(", "r'[^A-Za-z_]'", ",", "' '", ",", "text", ".", "strip", "(", ")", ".", "lower", "(", ")", ")", "\n", "# tokenize text using NLTK", "\n", "words", "=", "word_tokenize", "(", "text", ")", "\n", "clean_words", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "        ", "if", "word", "not", "in", "stopwords_set", ":", "\n", "            ", "word", "=", "ps", ".", "stem", "(", "word", ")", ".", "lower", "(", ")", "\n", "if", "word", "not", "in", "stopwords_set", ":", "\n", "                ", "clean_words", ".", "append", "(", "word", ")", "\n", "", "", "", "return", "clean_words", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.encode_note_train": [[58, 78], ["print", "dict", "dict", "enumerate", "print", "print", "encode.extract_word", "note_encoded.append", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.extract_word"], ["", "def", "encode_note_train", "(", "patient_note", ":", "dict", ",", "pids", ":", "np", ".", "ndarray", ",", "max_note_len", "=", "None", ")", "->", "(", "dict", ",", "dict", ")", ":", "\n", "    ", "print", "(", "'encoding train notes ...'", ")", "\n", "dictionary", "=", "dict", "(", ")", "\n", "patient_note_encoded", "=", "dict", "(", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", "+", "1", ",", "len", "(", "pids", ")", ")", ",", "end", "=", "''", ")", "\n", "words", "=", "extract_word", "(", "patient_note", "[", "pid", "]", ")", "\n", "note_encoded", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "not", "in", "dictionary", ":", "\n", "                ", "wid", "=", "len", "(", "dictionary", ")", "+", "1", "\n", "dictionary", "[", "word", "]", "=", "wid", "\n", "", "else", ":", "\n", "                ", "wid", "=", "dictionary", "[", "word", "]", "\n", "", "note_encoded", ".", "append", "(", "wid", ")", "\n", "", "if", "max_note_len", "is", "not", "None", ":", "\n", "            ", "note_encoded", "=", "note_encoded", "[", ":", "max_note_len", "]", "\n", "", "patient_note_encoded", "[", "pid", "]", "=", "note_encoded", "\n", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "len", "(", "pids", ")", ",", "len", "(", "pids", ")", ")", ")", "\n", "return", "patient_note_encoded", ",", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.encode_note_test": [[80, 97], ["print", "dict", "enumerate", "print", "print", "encode.extract_word", "len", "note_encoded.append", "note_encoded.append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.encode.extract_word"], ["", "def", "encode_note_test", "(", "patient_note", ":", "dict", ",", "pids", ":", "np", ".", "ndarray", ",", "dictionary", ":", "dict", ",", "max_note_len", "=", "None", ")", "->", "dict", ":", "\n", "    ", "print", "(", "'encoding valid/test notes ...'", ")", "\n", "patient_note_encoded", "=", "dict", "(", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", ",", "len", "(", "pids", ")", ")", ",", "end", "=", "''", ")", "\n", "words", "=", "extract_word", "(", "patient_note", "[", "pid", "]", ")", "\n", "note_encoded", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "dictionary", ":", "\n", "                ", "note_encoded", ".", "append", "(", "dictionary", "[", "word", "]", ")", "\n", "", "", "if", "len", "(", "note_encoded", ")", "==", "0", ":", "\n", "            ", "note_encoded", ".", "append", "(", "0", ")", "\n", "", "if", "max_note_len", "is", "not", "None", ":", "\n", "            ", "note_encoded", "=", "note_encoded", "[", ":", "max_note_len", "]", "\n", "", "patient_note_encoded", "[", "pid", "]", "=", "note_encoded", "\n", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "len", "(", "pids", ")", ",", "len", "(", "pids", ")", ")", ")", "\n", "return", "patient_note_encoded", "\n", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.parse_csv.parse_admission": [[8, 38], ["print", "os.path.join", "pandas.read_csv", "dict", "pd.read_csv.iterrows", "print", "dict", "dict.items", "datetime.datetime.strptime", "admission.append", "print", "len", "sorted", "len", "len", "len"], "function", ["None"], ["def", "parse_admission", "(", "path", ")", "->", "dict", ":", "\n", "    ", "print", "(", "'parsing ADMISSIONS.csv ...'", ")", "\n", "admission_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'ADMISSIONS.csv'", ")", "\n", "admissions", "=", "pd", ".", "read_csv", "(", "\n", "admission_path", ",", "\n", "usecols", "=", "[", "'SUBJECT_ID'", ",", "'HADM_ID'", ",", "'ADMITTIME'", "]", ",", "\n", "converters", "=", "{", "'SUBJECT_ID'", ":", "np", ".", "int", ",", "'HADM_ID'", ":", "np", ".", "int", ",", "'ADMITTIME'", ":", "np", ".", "str", "}", "\n", ")", "\n", "all_patients", "=", "dict", "(", ")", "\n", "for", "i", ",", "row", "in", "admissions", ".", "iterrows", "(", ")", ":", "\n", "        ", "if", "i", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "'\\r\\t%d in %d rows'", "%", "(", "i", "+", "1", ",", "len", "(", "admissions", ")", ")", ",", "end", "=", "''", ")", "\n", "", "pid", "=", "row", "[", "'SUBJECT_ID'", "]", "\n", "admission_id", "=", "row", "[", "'HADM_ID'", "]", "\n", "admission_time", "=", "datetime", ".", "strptime", "(", "row", "[", "'ADMITTIME'", "]", ",", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "if", "pid", "not", "in", "all_patients", ":", "\n", "            ", "all_patients", "[", "pid", "]", "=", "[", "]", "\n", "", "admission", "=", "all_patients", "[", "pid", "]", "\n", "admission", ".", "append", "(", "{", "\n", "'admission_id'", ":", "admission_id", ",", "\n", "'admission_time'", ":", "admission_time", "\n", "}", ")", "\n", "", "print", "(", "'\\r\\t%d in %d rows'", "%", "(", "len", "(", "admissions", ")", ",", "len", "(", "admissions", ")", ")", ")", "\n", "\n", "patient_admission", "=", "dict", "(", ")", "\n", "for", "pid", ",", "admissions", "in", "all_patients", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "admissions", ")", ">", "1", ":", "\n", "            ", "patient_admission", "[", "pid", "]", "=", "sorted", "(", "admissions", ",", "key", "=", "lambda", "admission", ":", "admission", "[", "'admission_time'", "]", ")", "\n", "\n", "", "", "return", "patient_admission", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.parse_csv.parse_diagnoses": [[40, 74], ["print", "os.path.join", "pandas.read_csv", "dict", "pd.read_csv.iterrows", "print", "to_standard_icd9.startswith", "print", "parse_csv.parse_diagnoses.to_standard_icd9"], "function", ["None"], ["", "def", "parse_diagnoses", "(", "path", ",", "patient_admission", ":", "dict", ")", "->", "dict", ":", "\n", "    ", "print", "(", "'parsing DIAGNOSES_ICD.csv ...'", ")", "\n", "diagnoses_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'DIAGNOSES_ICD.csv'", ")", "\n", "diagnoses", "=", "pd", ".", "read_csv", "(", "\n", "diagnoses_path", ",", "\n", "usecols", "=", "[", "'SUBJECT_ID'", ",", "'HADM_ID'", ",", "'ICD9_CODE'", "]", ",", "\n", "converters", "=", "{", "'SUBJECT_ID'", ":", "np", ".", "int", ",", "'HADM_ID'", ":", "np", ".", "int", ",", "'ICD9_CODE'", ":", "np", ".", "str", "}", "\n", ")", "\n", "\n", "def", "to_standard_icd9", "(", "code", ":", "str", ")", ":", "\n", "        ", "split_pos", "=", "4", "if", "code", ".", "startswith", "(", "'E'", ")", "else", "3", "\n", "icd9_code", "=", "code", "[", ":", "split_pos", "]", "+", "'.'", "+", "code", "[", "split_pos", ":", "]", "if", "len", "(", "code", ")", ">", "split_pos", "else", "code", "\n", "return", "icd9_code", "\n", "\n", "", "admission_codes", "=", "dict", "(", ")", "\n", "for", "i", ",", "row", "in", "diagnoses", ".", "iterrows", "(", ")", ":", "\n", "        ", "if", "i", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "'\\r\\t%d in %d rows'", "%", "(", "i", "+", "1", ",", "len", "(", "diagnoses", ")", ")", ",", "end", "=", "''", ")", "\n", "", "pid", "=", "row", "[", "'SUBJECT_ID'", "]", "\n", "if", "pid", "in", "patient_admission", ":", "\n", "            ", "admission_id", "=", "row", "[", "'HADM_ID'", "]", "\n", "code", "=", "row", "[", "'ICD9_CODE'", "]", "\n", "if", "code", "==", "''", ":", "\n", "                ", "continue", "\n", "", "code", "=", "to_standard_icd9", "(", "code", ")", "\n", "if", "admission_id", "not", "in", "admission_codes", ":", "\n", "                ", "codes", "=", "[", "]", "\n", "admission_codes", "[", "admission_id", "]", "=", "codes", "\n", "", "else", ":", "\n", "                ", "codes", "=", "admission_codes", "[", "admission_id", "]", "\n", "", "codes", ".", "append", "(", "code", ")", "\n", "", "", "print", "(", "'\\r\\t%d in %d rows'", "%", "(", "len", "(", "diagnoses", ")", ",", "len", "(", "diagnoses", ")", ")", ")", "\n", "\n", "return", "admission_codes", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.parse_csv.parse_notes": [[76, 100], ["print", "os.path.join", "pandas.read_csv", "dict", "enumerate", "print", "patient_admission.items", "print", "len", "len", "len", "len", "notes[].iterrows", "notes[].iterrows", "numpy.int"], "function", ["None"], ["", "def", "parse_notes", "(", "path", ",", "patient_admission", ":", "dict", ",", "use_summary", "=", "False", ")", "->", "dict", ":", "\n", "    ", "print", "(", "'parsing NOTEEVENTS.csv ...'", ")", "\n", "notes_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'NOTEEVENTS.csv'", ")", "\n", "notes", "=", "pd", ".", "read_csv", "(", "\n", "notes_path", ",", "\n", "usecols", "=", "[", "'HADM_ID'", ",", "'TEXT'", ",", "'CATEGORY'", "]", ",", "\n", "converters", "=", "{", "'HADM_ID'", ":", "lambda", "x", ":", "np", ".", "int", "(", "x", ")", "if", "x", "!=", "''", "else", "-", "1", ",", "'TEXT'", ":", "np", ".", "str", ",", "'CATEGORY'", ":", "np", ".", "str", "}", "\n", ")", "\n", "patient_note", "=", "dict", "(", ")", "\n", "for", "i", ",", "(", "pid", ",", "admissions", ")", "in", "enumerate", "(", "patient_admission", ".", "items", "(", ")", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d in %d patients'", "%", "(", "i", "+", "1", ",", "len", "(", "patient_admission", ")", ")", ",", "end", "=", "''", ")", "\n", "admission_id", "=", "admissions", "[", "-", "1", "]", "[", "'admission_id'", "]", "\n", "if", "use_summary", ":", "\n", "            ", "note", "=", "[", "row", "[", "'TEXT'", "]", "for", "_", ",", "row", "in", "notes", "[", "notes", "[", "'HADM_ID'", "]", "==", "admission_id", "]", ".", "iterrows", "(", ")", "\n", "if", "row", "[", "'CATEGORY'", "]", "==", "'Discharge summary'", "]", "\n", "", "else", ":", "\n", "# note = notes[notes['HADM_ID'] == admission_id]['TEXT'].tolist()", "\n", "            ", "note", "=", "[", "row", "[", "'TEXT'", "]", "for", "_", ",", "row", "in", "notes", "[", "notes", "[", "'HADM_ID'", "]", "==", "admission_id", "]", ".", "iterrows", "(", ")", "\n", "if", "row", "[", "'CATEGORY'", "]", "!=", "'Discharge summary'", "]", "\n", "", "note", "=", "' '", ".", "join", "(", "note", ")", "\n", "if", "len", "(", "note", ")", ">", "0", ":", "\n", "            ", "patient_note", "[", "pid", "]", "=", "note", "\n", "", "", "print", "(", "'\\r\\t%d in %d patients'", "%", "(", "len", "(", "patient_admission", ")", ",", "len", "(", "patient_admission", ")", ")", ")", "\n", "return", "patient_note", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.parse_csv.calibrate_patient_by_admission": [[102, 120], ["print", "patient_admission.items", "del_pids.append", "print"], "function", ["None"], ["", "def", "calibrate_patient_by_admission", "(", "patient_admission", ":", "dict", ",", "admission_codes", ":", "dict", ")", ":", "\n", "    ", "print", "(", "'calibrating patients by admission ...'", ")", "\n", "del_pids", "=", "[", "]", "\n", "for", "pid", ",", "admissions", "in", "patient_admission", ".", "items", "(", ")", ":", "\n", "        ", "for", "admission", "in", "admissions", ":", "\n", "            ", "if", "admission", "[", "'admission_id'", "]", "not", "in", "admission_codes", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "            ", "continue", "\n", "", "del_pids", ".", "append", "(", "pid", ")", "\n", "", "for", "pid", "in", "del_pids", ":", "\n", "        ", "admissions", "=", "patient_admission", "[", "pid", "]", "\n", "for", "admission", "in", "admissions", ":", "\n", "            ", "if", "admission", "[", "'admission_id'", "]", "in", "admission_codes", ":", "\n", "                ", "del", "admission_codes", "[", "admission", "[", "'admission_id'", "]", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "'\\tpatient %d have an admission %d without diagnosis'", "%", "(", "pid", ",", "admission", "[", "'admission_id'", "]", ")", ")", "\n", "", "", "del", "patient_admission", "[", "pid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.parse_csv.calibrate_patient_by_notes": [[122, 131], ["print", "print"], "function", ["None"], ["", "", "def", "calibrate_patient_by_notes", "(", "patient_admission", ":", "dict", ",", "admission_codes", ":", "dict", ",", "patient_note", ":", "dict", ")", ":", "\n", "    ", "print", "(", "'calibrating patients by notes ...'", ")", "\n", "del_pids", "=", "[", "pid", "for", "pid", "in", "patient_admission", "if", "pid", "not", "in", "patient_note", "]", "\n", "for", "pid", "in", "del_pids", ":", "\n", "        ", "print", "(", "'\\tpatient %d doesn\\'t have notes'", "%", "pid", ")", "\n", "admissions", "=", "patient_admission", "[", "pid", "]", "\n", "for", "admission", "in", "admissions", ":", "\n", "            ", "del", "admission_codes", "[", "admission", "[", "'admission_id'", "]", "]", "\n", "", "del", "patient_admission", "[", "pid", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.auxiliary.parse_icd9_range": [[6, 25], ["range_.lstrip().split", "range_.lstrip", "int", "int", "int", "int", "len", "int", "int", "int"], "function", ["None"], ["def", "parse_icd9_range", "(", "range_", ":", "str", ")", "->", "(", "str", ",", "str", ",", "int", ",", "int", ")", ":", "\n", "    ", "ranges", "=", "range_", ".", "lstrip", "(", ")", ".", "split", "(", "'-'", ")", "\n", "if", "ranges", "[", "0", "]", "[", "0", "]", "==", "'V'", ":", "\n", "        ", "prefix", "=", "'V'", "\n", "format_", "=", "'%02d'", "\n", "start", ",", "end", "=", "int", "(", "ranges", "[", "0", "]", "[", "1", ":", "]", ")", ",", "int", "(", "ranges", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "", "elif", "ranges", "[", "0", "]", "[", "0", "]", "==", "'E'", ":", "\n", "        ", "prefix", "=", "'E'", "\n", "format_", "=", "'%03d'", "\n", "start", ",", "end", "=", "int", "(", "ranges", "[", "0", "]", "[", "1", ":", "]", ")", ",", "int", "(", "ranges", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "        ", "prefix", "=", "''", "\n", "format_", "=", "'%03d'", "\n", "if", "len", "(", "ranges", ")", "==", "1", ":", "\n", "            ", "start", "=", "int", "(", "ranges", "[", "0", "]", ")", "\n", "end", "=", "start", "+", "1", "\n", "", "else", ":", "\n", "            ", "start", ",", "end", "=", "int", "(", "ranges", "[", "0", "]", ")", ",", "int", "(", "ranges", "[", "1", "]", ")", "\n", "", "", "return", "prefix", ",", "format_", ",", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.auxiliary.generate_code_levels": [[27, 71], ["print", "set", "os.path.join", "list", "dict", "dict", "numpy.zeros", "code_map.items", "open().readlines", "range_.rstrip.rstrip", "auxiliary.parse_icd9_range", "range", "code.split", "print", "code.split", "open", "len"], "function", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.auxiliary.parse_icd9_range"], ["", "def", "generate_code_levels", "(", "path", ",", "code_map", ":", "dict", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "print", "(", "'generating code levels ...'", ")", "\n", "three_level_code_set", "=", "set", "(", "code", ".", "split", "(", "'.'", ")", "[", "0", "]", "for", "code", "in", "code_map", ")", "\n", "icd9_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'icd9.txt'", ")", "\n", "icd9_range", "=", "list", "(", "open", "(", "icd9_path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", ".", "readlines", "(", ")", ")", "\n", "three_level_dict", "=", "dict", "(", ")", "\n", "level1", ",", "level2", ",", "level3", "=", "(", "1", ",", "1", ",", "1", ")", "\n", "level1_can_add", "=", "False", "\n", "for", "range_", "in", "icd9_range", ":", "\n", "        ", "range_", "=", "range_", ".", "rstrip", "(", ")", "\n", "if", "range_", "[", "0", "]", "==", "' '", ":", "\n", "            ", "prefix", ",", "format_", ",", "start", ",", "end", "=", "parse_icd9_range", "(", "range_", ")", "\n", "level2_cannot_add", "=", "True", "\n", "for", "i", "in", "range", "(", "start", ",", "end", "+", "1", ")", ":", "\n", "                ", "code", "=", "prefix", "+", "format_", "%", "i", "\n", "if", "code", "in", "three_level_code_set", ":", "\n", "                    ", "three_level_dict", "[", "code", "]", "=", "[", "level1", ",", "level2", ",", "level3", "]", "\n", "level3", "+=", "1", "\n", "level1_can_add", "=", "True", "\n", "level2_cannot_add", "=", "False", "\n", "", "", "if", "not", "level2_cannot_add", ":", "\n", "                ", "level2", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "if", "level1_can_add", ":", "\n", "                ", "level1", "+=", "1", "\n", "level1_can_add", "=", "False", "\n", "\n", "", "", "", "level4", "=", "1", "\n", "code_level", "=", "dict", "(", ")", "\n", "for", "code", "in", "code_map", ":", "\n", "        ", "three_level_code", "=", "code", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "three_level_code", "in", "three_level_dict", ":", "\n", "            ", "three_level", "=", "three_level_dict", "[", "three_level_code", "]", "\n", "code_level", "[", "code", "]", "=", "three_level", "+", "[", "level4", "]", "\n", "level4", "+=", "1", "\n", "", "else", ":", "\n", "            ", "print", "(", "three_level_code", ")", "\n", "code_level", "[", "code", "]", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "", "", "code_level_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "code_map", ")", "+", "1", ",", "4", ")", ",", "dtype", "=", "int", ")", "\n", "for", "code", ",", "cid", "in", "code_map", ".", "items", "(", ")", ":", "\n", "        ", "code_level_matrix", "[", "cid", "]", "=", "code_level", "[", "code", "]", "\n", "\n", "", "return", "code_level_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.auxiliary.generate_patient_code_adjacent": [[73, 80], ["print", "numpy.zeros", "enumerate", "len"], "function", ["None"], ["", "def", "generate_patient_code_adjacent", "(", "code_x", ":", "np", ".", "ndarray", ",", "code_num", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "print", "(", "'generating patient code adjacent matrix ...'", ")", "\n", "result", "=", "np", ".", "zeros", "(", "(", "len", "(", "code_x", ")", ",", "code_num", "+", "1", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", ",", "codes", "in", "enumerate", "(", "code_x", ")", ":", "\n", "        ", "adj_codes", "=", "codes", "[", "codes", ">", "0", "]", "\n", "result", "[", "i", "]", "[", "adj_codes", "]", "=", "1", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.auxiliary.generate_code_code_adjacent": [[82, 101], ["print", "numpy.zeros", "range", "print", "print", "range"], "function", ["None"], ["", "def", "generate_code_code_adjacent", "(", "code_num", ":", "int", ",", "code_level_matrix", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "print", "(", "'generating code code adjacent matrix ...'", ")", "\n", "n", "=", "code_num", "+", "1", "\n", "result", "=", "np", ".", "zeros", "(", "(", "n", ",", "n", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", ",", "n", ")", ",", "end", "=", "''", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "level_i", "=", "code_level_matrix", "[", "i", "]", "\n", "level_j", "=", "code_level_matrix", "[", "j", "]", "\n", "same_level", "=", "4", "\n", "while", "same_level", ">", "0", ":", "\n", "                    ", "level", "=", "same_level", "-", "1", "\n", "if", "level_i", "[", "level", "]", "==", "level_j", "[", "level", "]", ":", "\n", "                        ", "break", "\n", "", "same_level", "-=", "1", "\n", "", "result", "[", "i", ",", "j", "]", "=", "same_level", "+", "1", "\n", "", "", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "n", ",", "n", ")", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.auxiliary.co_occur": [[103, 121], ["print", "numpy.zeros", "enumerate", "print", "print", "enumerate", "range", "range", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "co_occur", "(", "pids", ":", "np", ".", "ndarray", ",", "\n", "patient_admission", ":", "dict", ",", "\n", "admission_codes_encoded", ":", "dict", ",", "\n", "code_num", ":", "int", ")", "->", "(", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "print", "(", "'calculating co-occurrence ...'", ")", "\n", "x", "=", "np", ".", "zeros", "(", "(", "code_num", "+", "1", ",", "code_num", "+", "1", ")", ",", "dtype", "=", "float", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", "+", "1", ",", "len", "(", "pids", ")", ")", ",", "end", "=", "''", ")", "\n", "admissions", "=", "patient_admission", "[", "pid", "]", "\n", "for", "k", ",", "admission", "in", "enumerate", "(", "admissions", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "codes", "=", "admission_codes_encoded", "[", "admission", "[", "'admission_id'", "]", "]", "\n", "for", "m", "in", "range", "(", "len", "(", "codes", ")", "-", "1", ")", ":", "\n", "                ", "for", "n", "in", "range", "(", "m", "+", "1", ",", "len", "(", "codes", ")", ")", ":", "\n", "                    ", "c_i", ",", "c_j", "=", "codes", "[", "m", "]", ",", "codes", "[", "n", "]", "\n", "x", "[", "c_i", ",", "c_j", "]", "=", "1", "\n", "x", "[", "c_j", ",", "c_i", "]", "=", "1", "\n", "", "", "", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "len", "(", "pids", ")", ",", "len", "(", "pids", ")", ")", ")", "\n", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.split_patients": [[6, 38], ["print", "numpy.random.seed", "set", "enumerate", "print", "patient_admission.items", "set.add", "numpy.array", "numpy.random.shuffle", "numpy.array", "print", "patient_admission.items", "list", "list", "len", "len", "set().difference", "set.union", "set", "len", "len", "len", "len", "set.add", "set", "remaining_pids[].tolist", "patient_admission.keys", "len"], "function", ["None"], ["def", "split_patients", "(", "patient_admission", ":", "dict", ",", "admission_codes", ":", "dict", ",", "code_map", ":", "dict", ",", "seed", "=", "6669", ")", "->", "(", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "print", "(", "'splitting train, valid, and test pids'", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "common_pids", "=", "set", "(", ")", "\n", "for", "i", ",", "code", "in", "enumerate", "(", "code_map", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%.2f%%'", "%", "(", "(", "i", "+", "1", ")", "*", "100", "/", "len", "(", "code_map", ")", ")", ",", "end", "=", "''", ")", "\n", "for", "pid", ",", "admissions", "in", "patient_admission", ".", "items", "(", ")", ":", "\n", "            ", "for", "admission", "in", "admissions", ":", "\n", "                ", "codes", "=", "admission_codes", "[", "admission", "[", "'admission_id'", "]", "]", "\n", "if", "code", "in", "codes", ":", "\n", "                    ", "common_pids", ".", "add", "(", "pid", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "continue", "\n", "", "break", "\n", "", "", "print", "(", "'\\r\\t100%'", ")", "\n", "max_admission_num", "=", "0", "\n", "pid_max_admission_num", "=", "0", "\n", "for", "pid", ",", "admissions", "in", "patient_admission", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "admissions", ")", ">", "max_admission_num", ":", "\n", "            ", "max_admission_num", "=", "len", "(", "admissions", ")", "\n", "pid_max_admission_num", "=", "pid", "\n", "", "", "common_pids", ".", "add", "(", "pid_max_admission_num", ")", "\n", "remaining_pids", "=", "np", ".", "array", "(", "list", "(", "set", "(", "patient_admission", ".", "keys", "(", ")", ")", ".", "difference", "(", "common_pids", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "remaining_pids", ")", "\n", "\n", "train_num", "=", "6000", "\n", "valid_num", "=", "125", "\n", "train_pids", "=", "np", ".", "array", "(", "list", "(", "common_pids", ".", "union", "(", "set", "(", "remaining_pids", "[", ":", "(", "train_num", "-", "len", "(", "common_pids", ")", ")", "]", ".", "tolist", "(", ")", ")", ")", ")", ")", "\n", "valid_pids", "=", "remaining_pids", "[", "(", "train_num", "-", "len", "(", "common_pids", ")", ")", ":", "(", "train_num", "+", "valid_num", "-", "len", "(", "common_pids", ")", ")", "]", "\n", "test_pids", "=", "remaining_pids", "[", "(", "train_num", "+", "valid_num", "-", "len", "(", "common_pids", ")", ")", ":", "]", "\n", "return", "train_pids", ",", "valid_pids", ",", "test_pids", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.build_code_xy": [[40, 62], ["print", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "print", "print", "enumerate", "numpy.array", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "build_code_xy", "(", "pids", ":", "np", ".", "ndarray", ",", "\n", "patient_admission", ":", "dict", ",", "\n", "admission_codes_encoded", ":", "dict", ",", "\n", "max_admission_num", ":", "int", ",", "\n", "code_num", ":", "int", ",", "\n", "max_code_num_in_a_visit", ":", "int", ")", "->", "(", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "print", "(", "'building train/valid/test codes features and labels ...'", ")", "\n", "n", "=", "len", "(", "pids", ")", "\n", "x", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_admission_num", ",", "max_code_num_in_a_visit", ")", ",", "dtype", "=", "int", ")", "\n", "y", "=", "np", ".", "zeros", "(", "(", "n", ",", "code_num", ")", ",", "dtype", "=", "int", ")", "\n", "lens", "=", "np", ".", "zeros", "(", "(", "n", ",", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", "+", "1", ",", "len", "(", "pids", ")", ")", ",", "end", "=", "''", ")", "\n", "admissions", "=", "patient_admission", "[", "pid", "]", "\n", "for", "k", ",", "admission", "in", "enumerate", "(", "admissions", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "codes", "=", "admission_codes_encoded", "[", "admission", "[", "'admission_id'", "]", "]", "\n", "x", "[", "i", "]", "[", "k", "]", "[", ":", "len", "(", "codes", ")", "]", "=", "codes", "\n", "", "codes", "=", "np", ".", "array", "(", "admission_codes_encoded", "[", "admissions", "[", "-", "1", "]", "[", "'admission_id'", "]", "]", ")", "-", "1", "\n", "y", "[", "i", "]", "[", "codes", "]", "=", "1", "\n", "lens", "[", "i", "]", "=", "len", "(", "admissions", ")", "-", "1", "\n", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "len", "(", "pids", ")", ",", "len", "(", "pids", ")", ")", ")", "\n", "return", "x", ",", "y", ",", "lens", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.build_time_duration_xy": [[64, 78], ["print", "len", "numpy.zeros", "numpy.zeros", "enumerate", "print", "print", "len", "len", "len", "len"], "function", ["None"], ["", "def", "build_time_duration_xy", "(", "pids", ":", "np", ".", "ndarray", ",", "\n", "patient_time_duration_encoded", ":", "dict", ",", "\n", "max_admission_num", ":", "int", ")", "->", "(", "np", ".", "ndarray", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "print", "(", "'building train/valid/test time duration features and labels ...'", ")", "\n", "n", "=", "len", "(", "pids", ")", "\n", "x", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_admission_num", ")", ")", "\n", "y", "=", "np", ".", "zeros", "(", "(", "n", ",", ")", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", "+", "1", ",", "len", "(", "pids", ")", ")", ",", "end", "=", "''", ")", "\n", "duration", "=", "patient_time_duration_encoded", "[", "pid", "]", "\n", "x", "[", "i", "]", "[", ":", "len", "(", "duration", ")", "-", "1", "]", "=", "duration", "[", ":", "-", "1", "]", "\n", "y", "[", "i", "]", "=", "duration", "[", "-", "1", "]", "\n", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "len", "(", "pids", ")", ",", "len", "(", "pids", ")", ")", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.build_note_x": [[80, 95], ["print", "len", "numpy.zeros", "numpy.zeros", "enumerate", "print", "print", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "build_note_x", "(", "pids", ":", "np", ".", "ndarray", ",", "\n", "patient_note_encoded", ":", "dict", ",", "\n", "max_word_num_in_a_note", ":", "int", ")", "->", "(", "np", ".", "ndarray", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "print", "(", "'building train/valid/test notes features and labels ...'", ")", "\n", "n", "=", "len", "(", "pids", ")", "\n", "x", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_word_num_in_a_note", ")", ",", "dtype", "=", "int", ")", "\n", "lens", "=", "np", ".", "zeros", "(", "(", "n", ",", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", "+", "1", ",", "len", "(", "pids", ")", ")", ",", "end", "=", "''", ")", "\n", "note", "=", "patient_note_encoded", "[", "pid", "]", "\n", "length", "=", "max_word_num_in_a_note", "if", "max_word_num_in_a_note", "<", "len", "(", "note", ")", "else", "len", "(", "note", ")", "\n", "x", "[", "i", "]", "[", ":", "length", "]", "=", "note", "[", ":", "length", "]", "\n", "lens", "[", "i", "]", "=", "length", "\n", "", "print", "(", "'\\r\\t%d / %d'", "%", "(", "len", "(", "pids", ")", ",", "len", "(", "pids", ")", ")", ")", "\n", "return", "x", ",", "lens", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.calculate_tf_idf": [[97, 122], ["len", "dict", "numpy.zeros", "print", "enumerate", "print", "print", "dict", "enumerate", "print", "note_encoded.items", "print", "dict", "set", "note_encoded.items", "print", "dict.get", "len", "math.log"], "function", ["None"], ["", "def", "calculate_tf_idf", "(", "note_encoded", ":", "dict", ",", "word_num", ":", "int", ")", "->", "dict", ":", "\n", "    ", "n_docs", "=", "len", "(", "note_encoded", ")", "\n", "tf", "=", "dict", "(", ")", "\n", "df", "=", "np", ".", "zeros", "(", "(", "word_num", "+", "1", ",", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "print", "(", "'calculating tf and df ...'", ")", "\n", "for", "i", ",", "(", "pid", ",", "note", ")", "in", "enumerate", "(", "note_encoded", ".", "items", "(", ")", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d'", "%", "(", "i", "+", "1", ",", "n_docs", ")", ",", "end", "=", "''", ")", "\n", "note_tf", "=", "dict", "(", ")", "\n", "for", "word", "in", "note", ":", "\n", "            ", "note_tf", "[", "word", "]", "=", "note_tf", ".", "get", "(", "word", ",", "0", ")", "+", "1", "\n", "", "wset", "=", "set", "(", "note", ")", "\n", "for", "word", "in", "wset", ":", "\n", "            ", "df", "[", "word", "]", "+=", "1", "\n", "", "tf", "[", "pid", "]", "=", "note_tf", "\n", "", "print", "(", "'\\r\\t%d / %d patients'", "%", "(", "n_docs", ",", "n_docs", ")", ")", "\n", "print", "(", "'calculating tf_idf ...'", ")", "\n", "tf_idf", "=", "dict", "(", ")", "\n", "for", "i", ",", "(", "pid", ",", "note", ")", "in", "enumerate", "(", "note_encoded", ".", "items", "(", ")", ")", ":", "\n", "        ", "print", "(", "'\\r\\t%d / %d patients'", "%", "(", "i", "+", "1", ",", "n_docs", ")", ",", "end", "=", "''", ")", "\n", "note_tf", "=", "tf", "[", "pid", "]", "\n", "note_tf_idf", "=", "[", "note_tf", "[", "word", "]", "/", "len", "(", "note", ")", "*", "(", "math", ".", "log", "(", "n_docs", "/", "(", "1", "+", "df", "[", "word", "]", ")", ",", "10", ")", "+", "1", ")", "\n", "for", "word", "in", "note", "]", "\n", "tf_idf", "[", "pid", "]", "=", "note_tf_idf", "\n", "", "print", "(", "'\\r\\t%d / %d patients'", "%", "(", "n_docs", ",", "n_docs", ")", ")", "\n", "return", "tf_idf", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.build_tf_idf_weight": [[124, 133], ["print", "build_dataset.calculate_tf_idf", "numpy.zeros_like", "enumerate", "np.zeros_like.sum", "len"], "function", ["home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.calculate_tf_idf"], ["", "def", "build_tf_idf_weight", "(", "pids", ":", "np", ".", "ndarray", ",", "note_x", ":", "np", ".", "ndarray", ",", "note_encoded", ":", "dict", ",", "word_num", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "print", "(", "'build tf_idf for notes ...'", ")", "\n", "tf_idf", "=", "calculate_tf_idf", "(", "note_encoded", ",", "word_num", ")", "\n", "weight", "=", "np", ".", "zeros_like", "(", "note_x", ",", "dtype", "=", "float", ")", "\n", "for", "i", ",", "pid", "in", "enumerate", "(", "pids", ")", ":", "\n", "        ", "note_tf_idf", "=", "tf_idf", "[", "pid", "]", "\n", "weight", "[", "i", "]", "[", ":", "len", "(", "note_tf_idf", ")", "]", "=", "note_tf_idf", "\n", "", "weight", "=", "weight", "/", "weight", ".", "sum", "(", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.LuChang-CS_CGL.preprocess.build_dataset.build_heart_failure_y": [[135, 143], ["print", "numpy.array", "numpy.zeros", "numpy.logical_and", "len", "code_map.items", "code.startswith", "numpy.sum"], "function", ["None"], ["", "def", "build_heart_failure_y", "(", "hf_prefix", ":", "str", ",", "codes_y", ":", "np", ".", "ndarray", ",", "code_map", ":", "dict", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "print", "(", "'building train/valid/test heart failure labels ...'", ")", "\n", "hf_list", "=", "np", ".", "array", "(", "[", "cid", "for", "code", ",", "cid", "in", "code_map", ".", "items", "(", ")", "if", "code", ".", "startswith", "(", "hf_prefix", ")", "]", ")", "\n", "hfs", "=", "np", ".", "zeros", "(", "(", "len", "(", "code_map", ")", ",", ")", ",", "dtype", "=", "int", ")", "\n", "hfs", "[", "hf_list", "-", "1", "]", "=", "1", "\n", "hf_exist", "=", "np", ".", "logical_and", "(", "codes_y", ",", "hfs", ")", "\n", "y", "=", "(", "np", ".", "sum", "(", "hf_exist", ",", "axis", "=", "-", "1", ")", ">", "0", ")", ".", "astype", "(", "int", ")", "\n", "return", "y", "\n", "", ""]]}