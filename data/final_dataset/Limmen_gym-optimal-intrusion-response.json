{"home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.transition_attacker": [[10, 24], ["gym_optimal_intrusion_response.dao.game.env_state.EnvState.get_attacked_node", "gym_optimal_intrusion_response.dao.game.env_state.EnvState.get_attacked_attribute", "transition_operator.TransitionOperator.attacker_reward_fun", "node.recon", "node.attack"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacked_node", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacked_attribute", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.attacker_reward_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.recon", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.attack"], ["    ", "@", "staticmethod", "\n", "def", "transition_attacker", "(", "attacker_action_id", ":", "int", ",", "env_state", ":", "EnvState", ",", "env_config", ":", "EnvConfig", ")", "->", "Tuple", "[", "EnvState", ",", "int", ",", "int", ",", "bool", "]", ":", "\n", "        ", "node_id", "=", "EnvState", ".", "get_attacked_node", "(", "attacker_action_id", ",", "env_config", ")", "\n", "attribute_id", "=", "EnvState", ".", "get_attacked_attribute", "(", "attacker_action_id", ",", "env_config", ")", "\n", "node", "=", "env_state", ".", "nodes", "[", "node_id", "]", "\n", "if", "attribute_id", "==", "env_config", ".", "recon_attribute", ":", "\n", "            ", "node", ".", "recon", "(", ")", "\n", "", "else", ":", "\n", "            ", "node", ".", "attack", "(", "attribute_id", ")", "\n", "", "attacker_reward", ",", "defender_reward", "=", "TransitionOperator", ".", "attacker_reward_fun", "(", "node", ",", "env_config", ")", "\n", "done", "=", "(", "node", ".", "target_component", "and", "node", ".", "compromised", ")", "\n", "s", "=", "env_state", "\n", "return", "s", ",", "attacker_reward", ",", "defender_reward", ",", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.transition_defender": [[25, 43], ["transition_operator.TransitionOperator.defender_reward_fun"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.defender_reward_fun"], ["", "@", "staticmethod", "\n", "def", "transition_defender", "(", "defender_action_id", ":", "int", ",", "env_state", ":", "EnvState", ",", "env_config", ":", "EnvConfig", ")", "->", "Tuple", "[", "EnvState", ",", "int", ",", "int", ",", "bool", ",", "dict", "]", ":", "\n", "        ", "s", "=", "env_state", "\n", "if", "defender_action_id", "==", "constants", ".", "ACTIONS", ".", "STOPPING_ACTION", ":", "\n", "            ", "s", ".", "stopped", "=", "True", "\n", "", "attacker_reward", ",", "defender_reward", ",", "info", "=", "TransitionOperator", ".", "defender_reward_fun", "(", "s", ",", "env_config", ",", "defender_action_id", ")", "\n", "done", "=", "s", ".", "stopped", "\n", "s", ".", "t", "+=", "1", "\n", "if", "env_config", ".", "dp", "and", "s", ".", "t", ">=", "constants", ".", "DP", ".", "MAX_TIMESTEPS", ":", "\n", "            ", "done", "=", "True", "\n", "if", "defender_action_id", "!=", "1", ":", "\n", "                ", "info", "[", "\"successful_intrusion\"", "]", "=", "1", "\n", "", "", "if", "env_config", ".", "traces", "and", "s", ".", "t", ">=", "constants", ".", "TRACES", ".", "MAX_TIMESTEPS", ":", "\n", "            ", "done", "=", "True", "\n", "if", "defender_action_id", "!=", "1", ":", "\n", "                ", "info", "[", "\"successful_intrusion\"", "]", "=", "1", "\n", "", "", "return", "s", ",", "attacker_reward", ",", "defender_reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.attacker_reward_fun": [[44, 50], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "attacker_reward_fun", "(", "node", ",", "env_config", ":", "EnvConfig", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "if", "node", ".", "target_component", "and", "node", ".", "compromised", ":", "\n", "            ", "return", "env_config", ".", "attacker_target_compromised_reward", ",", "env_config", ".", "defender_target_compromised_reward", "\n", "", "else", ":", "\n", "            ", "return", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.update_defender_state": [[51, 58], ["any", "env_state.defender_observation_state.update_state", "list", "map"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.defender_obs_state.DefenderObservationState.update_state"], ["", "", "@", "staticmethod", "\n", "def", "update_defender_state", "(", "env_state", ":", "EnvState", ",", "attacker_action", ",", "t", ")", "->", "bool", ":", "\n", "        ", "intrusion_in_progress", "=", "any", "(", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "compromised", ",", "env_state", ".", "nodes", ")", ")", ")", "\n", "done", "=", "env_state", ".", "defender_observation_state", ".", "update_state", "(", "t", ",", "intrusion_in_progress", "=", "intrusion_in_progress", ",", "\n", "dp_setup", "=", "env_state", ".", "dp_setup", ",", "attacker_action", "=", "attacker_action", ",", "\n", "defender_dynamics_model", "=", "env_state", ".", "dynamics_model", ")", "\n", "return", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.defender_reward_fun": [[59, 103], ["any", "list", "map", "numpy.random.rand", "max", "math.pow"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "defender_reward_fun", "(", "env_state", ":", "EnvState", ",", "env_config", ":", "EnvConfig", ",", "defender_action", ":", "int", ")", "->", "Tuple", "[", "int", ",", "int", ",", "dict", "]", ":", "\n", "        ", "info", "=", "{", "}", "\n", "if", "not", "env_state", ".", "env_config", ".", "dp", "and", "not", "env_state", ".", "env_config", ".", "traces", ":", "\n", "            ", "intrusion_in_progress", "=", "any", "(", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "compromised", ",", "env_state", ".", "nodes", ")", ")", ")", "\n", "if", "intrusion_in_progress", "and", "env_state", ".", "stopped", ":", "\n", "                ", "env_state", ".", "caught", "=", "True", "\n", "info", "[", "\"caught_attacker\"", "]", "=", "1", "\n", "return", "env_config", ".", "attacker_intrusion_prevention_reward", ",", "env_config", ".", "defender_intrusion_prevention_reward", ",", "info", "\n", "", "elif", "intrusion_in_progress", "and", "not", "env_state", ".", "stopped", ":", "\n", "                ", "return", "0", ",", "0", ",", "info", "\n", "", "elif", "not", "intrusion_in_progress", "and", "env_state", ".", "stopped", ":", "\n", "                ", "info", "[", "\"early_stopped\"", "]", "=", "1", "\n", "return", "env_config", ".", "attacker_early_stopping_reward", ",", "env_config", ".", "defender_early_stopping_reward", ",", "info", "\n", "", "elif", "not", "env_state", ".", "stopped", "and", "not", "intrusion_in_progress", ":", "\n", "                ", "return", "0", ",", "0", ",", "info", "\n", "", "", "elif", "env_state", ".", "env_config", ".", "dp", ":", "\n", "            ", "info", "=", "{", "}", "\n", "state_id", "=", "env_state", ".", "dp_setup", ".", "state_to_id", "[", "(", "env_state", ".", "t", ",", "env_state", ".", "defender_observation_state", ".", "ttc", ")", "]", "\n", "r", "=", "env_state", ".", "dp_setup", ".", "R", "[", "state_id", "]", "[", "defender_action", "]", "\n", "hp", "=", "env_state", ".", "dp_setup", ".", "HP", "[", "state_id", "]", "\n", "if", "defender_action", "==", "1", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "hp", ":", "\n", "                    ", "info", "[", "\"caught_attacker\"", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "info", "[", "\"early_stopped\"", "]", "=", "1", "\n", "", "", "return", "0", ",", "r", ",", "info", "\n", "", "elif", "env_config", ".", "traces", ":", "\n", "# print(\"t:{}, intrusion_t:{}\".format(env_state.t, env_state.intrusion_t))", "\n", "            ", "intrusion_in_progress", "=", "env_state", ".", "intrusion_in_progress", "\n", "if", "intrusion_in_progress", "and", "env_state", ".", "stopped", ":", "\n", "                ", "env_state", ".", "caught", "=", "True", "\n", "info", "[", "\"caught_attacker\"", "]", "=", "1", "\n", "info", "[", "\"intrusion_steps\"", "]", "=", "(", "env_state", ".", "t", "-", "env_state", ".", "intrusion_t", ")", "\n", "r", "=", "env_config", ".", "defender_intrusion_prevention_reward", "/", "max", "(", "1", ",", "(", "math", ".", "pow", "(", "(", "env_state", ".", "t", "-", "env_state", ".", "intrusion_t", ")", ",", "1.05", ")", ")", ")", "\n", "return", "env_config", ".", "attacker_intrusion_prevention_reward", ",", "r", ",", "info", "\n", "", "elif", "intrusion_in_progress", "and", "not", "env_state", ".", "stopped", ":", "\n", "                ", "return", "env_config", ".", "attacker_target_compromised_reward", ",", "env_config", ".", "defender_target_compromised_reward", "+", "env_config", ".", "defender_continue_reward", ",", "info", "\n", "", "elif", "not", "intrusion_in_progress", "and", "env_state", ".", "stopped", ":", "\n", "                ", "info", "[", "\"early_stopped\"", "]", "=", "1", "\n", "return", "env_config", ".", "attacker_early_stopping_reward", ",", "env_config", ".", "defender_early_stopping_reward", ",", "info", "\n", "", "elif", "not", "env_state", ".", "stopped", "and", "not", "intrusion_in_progress", ":", "\n", "                ", "return", "env_config", ".", "attacker_continue_reward", ",", "env_config", ".", "defender_continue_reward", ",", "info", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.static_defender.StaticDefender.__init__": [[7, 11], ["numpy.array", "list", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ":", "int", ",", "stopping_probability", ":", "float", ")", ":", "\n", "        ", "self", ".", "num_actions", "=", "num_actions", "\n", "self", ".", "actions", "=", "np", ".", "array", "(", "list", "(", "range", "(", "num_actions", ")", ")", ")", "\n", "self", ".", "stopping_probability", "=", "stopping_probability", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.static_defender.StaticDefender.action": [[12, 15], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "action", "(", "self", ",", "env", ")", "->", "int", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.static_attacker.StaticAttacker.__init__": [[8, 11], ["numpy.array", "list", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ":", "int", ")", ":", "\n", "        ", "self", ".", "num_actions", "=", "num_actions", "\n", "self", ".", "actions", "=", "np", ".", "array", "(", "list", "(", "range", "(", "num_actions", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.static_attacker.StaticAttacker.action": [[12, 15], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "action", "(", "self", ",", "env", ",", "t", "=", "None", ")", "->", "int", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.custom_attacker.CustomAttacker.__init__": [[8, 14], ["gym_optimal_intrusion_response.logic.static_opponents.static_attacker.StaticAttacker.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ":", "int", ",", "strategy", ":", "List", "[", "int", "]", ",", "continue_prob", ":", "float", "=", "0.8", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_actions", "=", "num_actions", ")", "\n", "self", ".", "strategy", "=", "strategy", "\n", "self", ".", "continue_prob", "=", "continue_prob", "\n", "self", ".", "t", "=", "0", "\n", "self", ".", "startup_phase", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.custom_attacker.CustomAttacker.action": [[15, 26], ["numpy.random.rand"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "env", ",", "t", "=", "None", ")", "->", "int", ":", "\n", "        ", "if", "t", "==", "0", ":", "\n", "            ", "self", ".", "t", "=", "0", "\n", "self", ".", "startup_phase", "=", "True", "\n", "", "if", "self", ".", "startup_phase", "and", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "continue_prob", ":", "\n", "            ", "return", "372", ",", "0", "\n", "", "else", ":", "\n", "# print(\"intrusion started, {}\".format(t))", "\n", "            ", "self", ".", "t", "+=", "1", "\n", "self", ".", "startup_phase", "=", "False", "\n", "return", "self", ".", "strategy", "[", "self", ".", "t", "-", "1", "]", ",", "self", ".", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.custom_attacker.CustomAttacker.reset": [[27, 30], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "t", "=", "0", "\n", "self", ".", "startup_phase", "=", "True", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_defender.RandomDefender.__init__": [[7, 9], ["gym_optimal_intrusion_response.logic.static_opponents.static_defender.StaticDefender.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ":", "int", ",", "stopping_probability", ":", "float", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_actions", "=", "num_actions", ",", "stopping_probability", "=", "stopping_probability", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_defender.RandomDefender.action": [[10, 16], ["numpy.random.rand"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "env", ")", "->", "int", ":", "\n", "        ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "stopping_probability", ":", "\n", "            ", "action", "=", "1", "\n", "", "else", ":", "\n", "            ", "action", "=", "0", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_attacker.RandomAttacker.__init__": [[7, 9], ["gym_optimal_intrusion_response.logic.static_opponents.static_attacker.StaticAttacker.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_actions", "=", "num_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_attacker.RandomAttacker.action": [[10, 18], ["list", "numpy.random.choice", "filter", "len", "print", "print", "print", "env.is_attack_action_legal", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal"], ["", "def", "action", "(", "self", ",", "env", ",", "t", ")", "->", "int", ":", "\n", "        ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "x", ":", "env", ".", "is_attack_action_legal", "(", "x", ",", "env", ".", "env_config", ",", "env", ".", "env_state", ")", ",", "self", ".", "actions", ")", ")", "\n", "if", "len", "(", "legal_actions", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"no legal actions\"", ")", "\n", "print", "(", "\"stopped:{}, caught:{}\"", ".", "format", "(", "env", ".", "env_state", ".", "stopped", ",", "env", ".", "env_state", ".", "caught", ")", ")", "\n", "print", "(", "\"nodes: {}\"", ".", "format", "(", "str", "(", "env", ".", "env_state", ")", ")", ")", "\n", "", "action", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "return", "action", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.p1": [[11, 21], ["math.exp"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "p1", "(", "v", ",", "m", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        p1 parameter for the TTC\n        :param v: v\n        :param m: m\n        :param k: k\n        :return: p1\n        \"\"\"", "\n", "return", "(", "1", "-", "math", ".", "exp", "(", "-", "(", "v", "*", "m", ")", "/", "k", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.ttc": [[22, 44], ["math.pow", "math.exp", "defender_dynamics.DefenderDynamics.E", "defender_dynamics.DefenderDynamics.f_fun", "defender_dynamics.DefenderDynamics.m_fun", "defender_dynamics.DefenderDynamics.f_fun"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.E", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.m_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun"], ["", "@", "staticmethod", "\n", "def", "ttc", "(", "v", ",", "s", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        TTC computation\n        :param v: v\n        :param s: s\n        :param k: k\n        :return: ttc\n        \"\"\"", "\n", "if", "v", "==", "0", ":", "\n", "            ", "return", "constants", ".", "DP", ".", "MAX_TTC", "\n", "", "s", "=", "s", "/", "constants", ".", "DP", ".", "MAX_LOGINS", "\n", "c1", "=", "1", "\n", "c2", "=", "5.8", "\n", "c3", "=", "32.42", "\n", "t1", "=", "c1", "\n", "P1", "=", "1", "-", "math", ".", "exp", "(", "-", "v", "*", "(", "DefenderDynamics", ".", "m_fun", "(", "s", ")", "/", "k", ")", ")", "\n", "t2", "=", "c2", "*", "DefenderDynamics", ".", "E", "(", "v", ",", "s", ")", "\n", "t3", "=", "(", "1", "/", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "-", "0.5", ")", "*", "c3", "+", "c2", "\n", "u", "=", "math", ".", "pow", "(", "1", "-", "DefenderDynamics", ".", "f_fun", "(", "s", ")", ",", "v", ")", "\n", "res", "=", "t1", "*", "P1", "+", "t2", "*", "(", "1", "-", "P1", ")", "*", "(", "1", "-", "u", ")", "+", "t3", "*", "u", "*", "(", "1", "-", "P1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob": [[45, 57], ["max", "math.pow", "math.pow", "max", "max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "hack_prob", "(", "ttc_val", ",", "t", ")", ":", "\n", "        ", "\"\"\"\n        The hack probability\n\n        :param ttc_val: the ttc\n        :param t: the time-step\n        :return:\n        \"\"\"", "\n", "ttc_1", "=", "max", "(", "1", ",", "ttc_val", ")", "\n", "hp", "=", "(", "1", "/", "(", "0.99", "*", "math", ".", "pow", "(", "max", "(", "1", ",", "ttc_1", ")", ",", "3", ")", "+", "0.01", "*", "math", ".", "pow", "(", "max", "(", "1", ",", "(", "(", "constants", ".", "DP", ".", "MAX_TIMESTEPS", "-", "1", ")", "-", "(", "t", ")", ")", ")", ",", "2", ")", ")", ")", "\n", "return", "hp", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun": [[58, 67], ["math.pow"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "f_fun", "(", "s", ")", ":", "\n", "        ", "\"\"\"\n        The f function for the TTC computation\n\n        :param s: s\n        :return: f(s)\n        \"\"\"", "\n", "return", "0.145", "*", "math", ".", "pow", "(", "2.6", ",", "2", "*", "s", "+", "0.07", ")", "-", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.m_fun": [[68, 76], ["math.pow"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "m_fun", "(", "s", ")", ":", "\n", "        ", "\"\"\"\n        The m function for the TTC computation\n        :param s: s\n        :return: m(s)\n        \"\"\"", "\n", "return", "83", "*", "math", ".", "pow", "(", "3.5", ",", "(", "4", "*", "s", ")", "/", "2.7", ")", "-", "82", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.E": [[77, 90], ["defender_dynamics.DefenderDynamics.xi", "defender_dynamics.DefenderDynamics.xi", "math.floor", "math.ceil", "math.ceil", "defender_dynamics.DefenderDynamics.f_fun", "math.ceil", "defender_dynamics.DefenderDynamics.f_fun", "defender_dynamics.DefenderDynamics.f_fun", "defender_dynamics.DefenderDynamics.f_fun", "defender_dynamics.DefenderDynamics.f_fun", "defender_dynamics.DefenderDynamics.f_fun"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.xi", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.xi", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f_fun"], ["", "@", "staticmethod", "\n", "def", "E", "(", "v", ",", "s", ")", ":", "\n", "        ", "\"\"\"\n        The E function for the TTC computation\n        :param v: v\n        :param s: s\n        :return: E(v,s)\n        \"\"\"", "\n", "temp", "=", "DefenderDynamics", ".", "xi", "(", "math", ".", "floor", "(", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "*", "v", ")", ",", "v", ")", "*", "(", "\n", "math", ".", "ceil", "(", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "*", "v", ")", "-", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "*", "v", ")", "+", "DefenderDynamics", ".", "xi", "(", "math", ".", "ceil", "(", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "*", "v", ")", ",", "v", ")", "*", "(", "\n", "1", "-", "math", ".", "ceil", "(", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "*", "v", ")", "+", "DefenderDynamics", ".", "f_fun", "(", "s", ")", "*", "v", ")", "\n", "return", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.xi": [[91, 107], ["range", "math.ceil", "math.factorial", "math.factorial", "math.factorial", "math.factorial"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "xi", "(", "a", ",", "v", ")", ":", "\n", "        ", "\"\"\"\n        The xi function for the TTC computation\n\n        :param a: a\n        :param v: v\n        :return: xi(a,v)\n        \"\"\"", "\n", "s", "=", "0", "\n", "for", "t", "in", "range", "(", "math", ".", "ceil", "(", "(", "v", "*", "(", "1", "-", "a", "/", "v", ")", ")", "+", "1", ")", ")", ":", "\n", "            ", "x", "=", "t", "*", "(", "math", ".", "factorial", "(", "v", "-", "t", "+", "1", ")", "/", "(", "math", ".", "factorial", "(", "v", "-", "a", "-", "t", "+", "1", ")", "*", "(", "v", "-", "t", "+", "1", ")", ")", ")", "\n", "s", "=", "s", "+", "x", "\n", "\n", "", "res", "=", "a", "/", "v", "+", "(", "(", "a", "*", "(", "math", ".", "factorial", "(", "v", "-", "a", ")", ")", ")", "/", "math", ".", "factorial", "(", "v", ")", ")", "*", "(", "s", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f1_a": [[109, 115], ["scipy.stats.poisson"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "f1_a", "(", ")", ":", "\n", "        ", "\"\"\"\n        :return: f1_a() in the model\n        \"\"\"", "\n", "return", "poisson", "(", "mu", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f2_a": [[116, 122], ["scipy.stats.poisson"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "f2_a", "(", ")", ":", "\n", "        ", "\"\"\"\n        :return: f2_a() in the model\n        \"\"\"", "\n", "return", "poisson", "(", "mu", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f1_b": [[123, 129], ["scipy.stats.poisson"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "f1_b", "(", ")", ":", "\n", "        ", "\"\"\"\n        :return: f1_b() in the model\n        \"\"\"", "\n", "return", "poisson", "(", "mu", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f2_b": [[130, 136], ["scipy.stats.poisson"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "f2_b", "(", ")", ":", "\n", "        ", "\"\"\"\n        :return: f2_b() in the model\n        \"\"\"", "\n", "return", "poisson", "(", "mu", "=", "0.25", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_states": [[12, 18], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "num_states", "(", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the number of states\n        \"\"\"", "\n", "return", "constants", ".", "DP", ".", "MAX_TTC", "*", "constants", ".", "DP", ".", "MAX_TIMESTEPS", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_actions": [[19, 25], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "num_actions", "(", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the number of actions\n        \"\"\"", "\n", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.actions": [[26, 32], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "actions", "(", ")", "->", "dict", ":", "\n", "        ", "\"\"\"\n        :return: action lookup dictp\n        \"\"\"", "\n", "return", "{", "\"continue\"", ":", "0", ",", "\"stop\"", ":", "1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.hp_and_ttc_and_r": [[33, 61], ["numpy.zeros", "numpy.zeros", "range", "dp.DP.save_numpy", "dp.DP.save_numpy", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob", "range", "dp.DP.reward_fun"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.reward_fun"], ["", "@", "staticmethod", "\n", "def", "hp_and_ttc_and_r", "(", "n_states", ":", "int", ",", "n_actions", ":", "int", ",", "id_to_state", ":", "dict", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Pre-computes the HP, TTC, and R\n\n        :param n_states: number of states\n        :param n_actions: number of actions\n        :param id_to_state: lookup dict to convert between ids and states\n        :return: the hack probability matrix and the reward matrix\n        \"\"\"", "\n", "HP", "=", "np", ".", "zeros", "(", "n_states", ")", "\n", "R", "=", "np", ".", "zeros", "(", "(", "n_states", ",", "n_actions", ")", ")", "\n", "for", "i", "in", "range", "(", "n_states", ")", ":", "\n", "            ", "s1", "=", "id_to_state", "[", "i", "]", "\n", "if", "s1", "==", "\"terminal\"", ":", "\n", "                ", "HP", "[", "i", "]", "=", "0", "\n", "R", "[", "i", "]", "[", "0", "]", "=", "0", "\n", "R", "[", "i", "]", "[", "1", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "t1", ",", "x1", "=", "s1", "\n", "hp", "=", "DefenderDynamics", ".", "hack_prob", "(", "x1", ",", "t1", ")", "\n", "HP", "[", "i", "]", "=", "hp", "\n", "for", "j", "in", "range", "(", "n_actions", ")", ":", "\n", "                    ", "r", "=", "DP", ".", "reward_fun", "(", "i", ",", "j", ",", "id_to_state", ")", "\n", "R", "[", "i", "]", "[", "j", "]", "=", "r", "\n", "", "", "", "DP", ".", "save_numpy", "(", "HP", ",", "\"hp_table.npy\"", ")", "\n", "DP", ".", "save_numpy", "(", "R", ",", "\"reward_fun.npy\"", ")", "\n", "return", "HP", ",", "R", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.ttc_to_alerts_table": [[62, 97], ["range", "ttc_to_alerts_logins.items", "range", "dp.DP.save_pickle", "dp.DP.save_pickle", "range", "list", "list", "int", "map", "map", "numpy.mean", "numpy.mean", "round", "numpy.array", "numpy.array", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.ttc", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_pickle", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_pickle", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.ttc"], ["", "@", "staticmethod", "\n", "def", "ttc_to_alerts_table", "(", ")", "->", "Tuple", "[", "dict", ",", "dict", "]", ":", "\n", "        ", "\"\"\"\n        Utility function for computing a lookup table between TTC and alerts\n\n        :return: (ttc->alerts/logins,alerts/logins->ttc)\n        \"\"\"", "\n", "alerts_logins_to_ttc", "=", "{", "}", "\n", "ttc_to_alerts_logins", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "constants", ".", "DP", ".", "MAX_ALERTS", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "constants", ".", "DP", ".", "MAX_LOGINS", ")", ":", "\n", "                ", "ttc", "=", "int", "(", "round", "(", "DefenderDynamics", ".", "ttc", "(", "i", ",", "j", ",", "constants", ".", "DP", ".", "MAX_ALERTS", ")", ")", ")", "\n", "alerts_logins_to_ttc", "[", "(", "i", ",", "j", ")", "]", "=", "ttc", "\n", "if", "ttc", "not", "in", "ttc_to_alerts_logins", ":", "\n", "                    ", "ttc_to_alerts_logins", "[", "ttc", "]", "=", "[", "(", "i", ",", "j", ")", "]", "\n", "", "else", ":", "\n", "                    ", "ttc_to_alerts_logins", "[", "ttc", "]", "=", "ttc_to_alerts_logins", "[", "ttc", "]", "+", "[", "(", "i", ",", "j", ")", "]", "\n", "", "", "", "avg_ttc_to_alerts_logins", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "ttc_to_alerts_logins", ".", "items", "(", ")", ":", "\n", "            ", "alerts", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "0", "]", ",", "v", ")", ")", "\n", "logins", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "1", "]", ",", "v", ")", ")", "\n", "avg_ttc_to_alerts_logins", "[", "k", "]", "=", "(", "np", ".", "mean", "(", "np", ".", "array", "(", "alerts", ")", ")", ",", "np", ".", "mean", "(", "np", ".", "array", "(", "logins", ")", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "constants", ".", "DP", ".", "MAX_TTC", ")", ":", "\n", "            ", "if", "i", "not", "in", "avg_ttc_to_alerts_logins", "or", "avg_ttc_to_alerts_logins", "[", "i", "]", "==", "0", ":", "\n", "                ", "if", "i", "-", "1", "in", "avg_ttc_to_alerts_logins", ":", "\n", "                    ", "avg_ttc_to_alerts_logins", "[", "i", "]", "=", "avg_ttc_to_alerts_logins", "[", "i", "-", "1", "]", "\n", "", "elif", "i", "+", "1", "in", "avg_ttc_to_alerts_logins", ":", "\n", "                    ", "avg_ttc_to_alerts_logins", "[", "i", "]", "=", "avg_ttc_to_alerts_logins", "[", "i", "+", "1", "]", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"total miss\"", ")", "\n", "\n", "", "", "", "DP", ".", "save_pickle", "(", "avg_ttc_to_alerts_logins", ",", "\"ttc_to_alerts_logins.pkl\"", ")", "\n", "DP", ".", "save_pickle", "(", "alerts_logins_to_ttc", ",", "\"logins_alerts_to_tcc.pkl\"", ")", "\n", "return", "avg_ttc_to_alerts_logins", ",", "alerts_logins_to_ttc", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.transition_kernel": [[98, 211], ["gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f1_a", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f1_b", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f2_a", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f2_b", "numpy.zeros", "list", "range", "dp.DP.save_numpy", "range", "sum", "sum", "print", "sum", "sum", "sum", "range", "print", "max", "max", "print", "print", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f1_a.pmf", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f2_a.pmf", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f1_b.pmf", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f2_b.pmf"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f1_a", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f1_b", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f2_a", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f2_b", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy"], ["", "@", "staticmethod", "\n", "def", "transition_kernel", "(", "id_to_state", ":", "dict", ",", "num_states", ":", "int", ",", "num_actions", ":", "int", ",", "HP", ":", "np", ".", "ndarray", ",", "\n", "ttc_to_alerts_logins", ":", "dict", ",", "\n", "alerts_logins_to_ttc", ":", "dict", ",", "state_to_id", ":", "dict", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n\n        Precomputes the transition kernel\n\n        :param id_to_state: dict to convert between ids and states\n        :param num_states: the number of states\n        :param num_actions: the number of actions\n        :param HP: the hack probability\n        :param ttc_to_alerts_logins: a lookup dict between TTC and alerts and logins\n        :param alerts_logins_to_ttc: a lookup dict between alerts/logins and TTC\n        :param state_to_id: state to id dict\n        :return: the transition kernel\n        \"\"\"", "\n", "f1_a", "=", "DefenderDynamics", ".", "f1_a", "(", ")", "\n", "f1_b", "=", "DefenderDynamics", ".", "f1_b", "(", ")", "\n", "f2_a", "=", "DefenderDynamics", ".", "f2_a", "(", ")", "\n", "f2_b", "=", "DefenderDynamics", ".", "f2_b", "(", ")", "\n", "T", "=", "np", ".", "zeros", "(", "(", "num_states", ",", "num_actions", ",", "num_states", ")", ")", "\n", "state_ids", "=", "list", "(", "range", "(", "num_states", ")", ")", "\n", "sorted_state_ids", "=", "state_ids", "\n", "\n", "for", "i", "in", "range", "(", "num_states", ")", ":", "\n", "            ", "s1", "=", "id_to_state", "[", "i", "]", "\n", "if", "s1", "==", "\"terminal\"", ":", "\n", "                ", "T", "[", "i", "]", "[", "0", "]", "[", "i", "]", "=", "1", "\n", "T", "[", "i", "]", "[", "1", "]", "[", "i", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "t1", ",", "x1", "=", "s1", "\n", "if", "t1", "==", "constants", ".", "DP", ".", "MAX_TIMESTEPS", "-", "1", ":", "\n", "                    ", "T", "[", "i", "]", "[", "0", "]", "[", "state_to_id", "[", "\"terminal\"", "]", "]", "=", "1", "\n", "T", "[", "i", "]", "[", "1", "]", "[", "state_to_id", "[", "\"terminal\"", "]", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"{}/{}\"", ".", "format", "(", "i", ",", "num_states", ")", ")", "\n", "feasible_states", "=", "sorted_state_ids", "\n", "for", "j", "in", "feasible_states", ":", "\n", "                        ", "s2", "=", "id_to_state", "[", "j", "]", "\n", "\n", "if", "x1", "==", "constants", ".", "DP", ".", "MIN_TTC", ":", "\n", "                            ", "T", "[", "i", "]", "[", "1", "]", "[", "state_to_id", "[", "\"terminal\"", "]", "]", "=", "1", "\n", "if", "s2", "==", "\"terminal\"", "and", "t1", "<", "constants", ".", "DP", ".", "MAX_TIMESTEPS", "-", "1", ":", "\n", "                                ", "T", "[", "i", "]", "[", "0", "]", "[", "j", "]", "=", "0", "\n", "", "else", ":", "\n", "                                ", "t2", ",", "x2", "=", "s2", "\n", "if", "t2", "==", "t1", "+", "1", "and", "x2", "==", "x1", ":", "\n", "                                    ", "print", "(", "\"min reached\"", ")", "\n", "T", "[", "i", "]", "[", "0", "]", "[", "j", "]", "=", "1", "\n", "", "", "", "else", ":", "\n", "                            ", "for", "k", "in", "range", "(", "num_actions", ")", ":", "\n", "                                ", "if", "k", "==", "constants", ".", "ACTIONS", ".", "STOPPING_ACTION", ":", "\n", "                                    ", "if", "s2", "==", "\"terminal\"", ":", "\n", "                                        ", "T", "[", "i", "]", "[", "k", "]", "[", "j", "]", "=", "1", "\n", "", "else", ":", "\n", "                                        ", "T", "[", "i", "]", "[", "k", "]", "[", "j", "]", "=", "0", "\n", "", "", "else", ":", "\n", "                                    ", "if", "s2", "==", "\"terminal\"", "and", "t1", "<", "constants", ".", "DP", ".", "MAX_TIMESTEPS", "-", "1", ":", "\n", "                                        ", "T", "[", "i", "]", "[", "k", "]", "[", "j", "]", "=", "0", "\n", "", "else", ":", "\n", "                                        ", "t2", ",", "x2", "=", "s2", "\n", "if", "t2", "!=", "(", "t1", "+", "1", ")", "or", "x2", ">=", "x1", ":", "\n", "                                            ", "T", "[", "i", "]", "[", "k", "]", "[", "j", "]", "=", "0", "\n", "", "else", ":", "\n", "                                            ", "hp", "=", "HP", "[", "j", "]", "\n", "prob", "=", "0.0", "\n", "if", "x1", "in", "ttc_to_alerts_logins", "and", "x2", "in", "ttc_to_alerts_logins", ":", "\n", "                                                ", "(", "alerts1", ",", "logins1", ")", "=", "ttc_to_alerts_logins", "[", "x1", "]", "\n", "(", "alerts2", ",", "logins2", ")", "=", "ttc_to_alerts_logins", "[", "x2", "]", "\n", "alerts_delta", "=", "max", "(", "alerts2", "-", "alerts1", ",", "0.0", ")", "\n", "logins_delta", "=", "max", "(", "logins2", "-", "logins1", ",", "0.0", ")", "\n", "p", "=", "hp", "*", "(", "f1_a", ".", "pmf", "(", "alerts_delta", ")", "*", "f2_a", ".", "pmf", "(", "logins_delta", ")", ")", "+", "(", "1", "-", "hp", ")", "*", "(", "f1_b", ".", "pmf", "(", "alerts_delta", ")", "*", "f2_b", ".", "pmf", "(", "logins_delta", ")", ")", "\n", "prob", "=", "prob", "+", "p", "\n", "p", "=", "prob", "\n", "if", "p", ">", "0", "and", "k", "==", "1", ":", "\n", "                                                    ", "print", "(", "\n", "\"setting positive probability despite stopping:{}, next state:{}\"", ".", "format", "(", "\n", "p", ",", "j", ")", ")", "\n", "", "T", "[", "i", "]", "[", "k", "]", "[", "j", "]", "=", "p", "\n", "", "else", ":", "\n", "                                                ", "print", "(", "\"total miss\"", ")", "\n", "", "", "", "", "", "", "", "if", "sum", "(", "T", "[", "i", "]", "[", "0", "]", ")", "==", "0", ":", "\n", "# t1, x1 = s1", "\n", "                        ", "new_state1", "=", "(", "t1", "+", "1", ",", "x1", "-", "1", ")", "\n", "s_prime_id1", "=", "state_to_id", "[", "new_state1", "]", "\n", "s_prime_id2", "=", "None", "\n", "if", "x1", ">", "5", ":", "\n", "                            ", "new_state2", "=", "(", "t1", "+", "1", ",", "x1", "-", "5", ")", "\n", "s_prime_id2", "=", "state_to_id", "[", "new_state2", "]", "\n", "", "elif", "x1", ">", "4", ":", "\n", "                            ", "new_state2", "=", "(", "t1", "+", "1", ",", "x1", "-", "4", ")", "\n", "s_prime_id2", "=", "state_to_id", "[", "new_state2", "]", "\n", "", "elif", "x1", ">", "3", ":", "\n", "                            ", "new_state2", "=", "(", "t1", "+", "1", ",", "x1", "-", "3", ")", "\n", "s_prime_id2", "=", "state_to_id", "[", "new_state2", "]", "\n", "", "elif", "x1", ">", "2", ":", "\n", "                            ", "new_state2", "=", "(", "t1", "+", "1", ",", "x1", "-", "2", ")", "\n", "s_prime_id2", "=", "state_to_id", "[", "new_state2", "]", "\n", "", "if", "s_prime_id2", "is", "not", "None", ":", "\n", "                            ", "hp", "=", "HP", "[", "i", "]", "\n", "T", "[", "i", "]", "[", "0", "]", "[", "s_prime_id1", "]", "=", "1", "-", "hp", "\n", "T", "[", "i", "]", "[", "0", "]", "[", "s_prime_id2", "]", "=", "hp", "\n", "", "else", ":", "\n", "                            ", "T", "[", "i", "]", "[", "0", "]", "[", "s_prime_id1", "]", "=", "1", "\n", "", "", "", "", "if", "sum", "(", "T", "[", "i", "]", "[", "0", "]", ")", "!=", "0", ":", "\n", "                ", "T", "[", "i", "]", "[", "0", "]", "=", "T", "[", "i", "]", "[", "0", "]", "/", "sum", "(", "T", "[", "i", "]", "[", "0", "]", ")", "\n", "", "if", "sum", "(", "T", "[", "i", "]", "[", "1", "]", ")", "!=", "0", ":", "\n", "                ", "T", "[", "i", "]", "[", "1", "]", "=", "T", "[", "i", "]", "[", "1", "]", "/", "sum", "(", "T", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "DP", ".", "save_numpy", "(", "T", ",", "\"transition_kernel.npy\"", ")", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.state_to_id_dict": [[212, 232], ["range", "dp.DP.save_pickle", "dp.DP.save_pickle", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_pickle", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_pickle"], ["", "@", "staticmethod", "\n", "def", "state_to_id_dict", "(", ")", "->", "Tuple", "[", "dict", ",", "dict", "]", ":", "\n", "        ", "\"\"\"\n        Utility function for creating a lookup dict to convert between state ids and states and back\n\n        :return: (state_to_id lookup, id_to_state lookup)\n        \"\"\"", "\n", "state_to_id", "=", "{", "}", "\n", "id_to_state", "=", "{", "}", "\n", "id", "=", "1", "\n", "state_to_id", "[", "\"terminal\"", "]", "=", "0", "\n", "id_to_state", "[", "0", "]", "=", "\"terminal\"", "\n", "for", "t", "in", "range", "(", "constants", ".", "DP", ".", "MAX_TIMESTEPS", ")", ":", "\n", "            ", "for", "x", "in", "range", "(", "constants", ".", "DP", ".", "MAX_TTC", ")", ":", "\n", "                ", "state_to_id", "[", "(", "t", ",", "x", ")", "]", "=", "id", "\n", "id_to_state", "[", "id", "]", "=", "(", "t", ",", "x", ")", "\n", "id", "+=", "1", "\n", "", "", "DP", ".", "save_pickle", "(", "state_to_id", ",", "\"state_to_id.pkl\"", ")", "\n", "DP", ".", "save_pickle", "(", "id_to_state", ",", "\"id_to_state.pkl\"", ")", "\n", "return", "state_to_id", ",", "id_to_state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.reward_fun": [[233, 254], ["gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob", "max", "math.pow"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob"], ["", "@", "staticmethod", "\n", "def", "reward_fun", "(", "state", ":", "np", ".", "ndarray", ",", "action", ":", "int", ",", "id_to_state", ":", "dict", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        The reward function\n\n        :param state: the current state\n        :param action: the current action\n        :param id_to_state: the id to state lookup dict\n        :return: the reward\n        \"\"\"", "\n", "s1", "=", "id_to_state", "[", "state", "]", "\n", "t1", ",", "x1", "=", "s1", "\n", "hp", "=", "DefenderDynamics", ".", "hack_prob", "(", "x1", ",", "t1", ")", "\n", "if", "t1", "==", "constants", ".", "DP", ".", "MAX_TIMESTEPS", "and", "action", "!=", "constants", ".", "ACTIONS", ".", "STOPPING_ACTION", ":", "\n", "            ", "return", "hp", "*", "constants", ".", "DP", ".", "ATTACK_REWARD", "\n", "", "else", ":", "\n", "            ", "if", "action", "==", "constants", ".", "ACTIONS", ".", "STOPPING_ACTION", ":", "\n", "                ", "r", "=", "hp", "*", "50", "*", "(", "max", "(", "math", ".", "pow", "(", "x1", ",", "1", ")", ",", "1", ")", ")", "+", "(", "1", "-", "hp", ")", "*", "(", "constants", ".", "DP", ".", "EARLY_STOPPING_REWARD", ")", "\n", "return", "r", "\n", "", "else", ":", "\n", "                ", "return", "hp", "*", "constants", ".", "DP", ".", "ATTACK_REWARD", "+", "(", "1", "-", "hp", ")", "*", "(", "constants", ".", "DP", ".", "SERVICE_REWARD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.one_step_lookahead": [[255, 279], ["numpy.zeros", "range", "str"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "one_step_lookahead", "(", "state", ",", "V", ",", "num_actions", ",", "num_states", ",", "T", ",", "discount_factor", ",", "R", ",", "next_state_lookahead", ",", "id_to_state", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Performs a one-step lookahead for value iteration\n\n        :param state: the current state\n        :param V: the current value function\n        :param num_actions: the number of actions\n        :param num_states: the number of states\n        :param T: the transition kernel\n        :param discount_factor: the discount factor\n        :param R: the table with rewards\n        :param next_state_lookahead: the next state lookahead table\n        :param id_to_state: the id to state lookeahead table\n        :return: an array with lookahead values\n        \"\"\"", "\n", "A", "=", "np", ".", "zeros", "(", "num_actions", ")", "\n", "for", "a", "in", "range", "(", "num_actions", ")", ":", "\n", "            ", "for", "next_state", "in", "next_state_lookahead", "[", "str", "(", "state", ")", "]", ":", "\n", "                ", "reward", "=", "R", "[", "state", "]", "[", "a", "]", "\n", "prob", "=", "T", "[", "state", "]", "[", "a", "]", "[", "next_state", "]", "\n", "A", "[", "a", "]", "+=", "prob", "*", "(", "reward", "+", "discount_factor", "*", "V", "[", "next_state", "]", ")", "\n", "", "", "return", "A", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.next_states_lookahead_table": [[280, 304], ["range", "dp.DP.save_json", "print", "range", "range", "len", "print", "next_states.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_json"], ["", "@", "staticmethod", "\n", "def", "next_states_lookahead_table", "(", "n_states", ":", "int", ",", "n_actions", ":", "int", ",", "T", ":", "np", ".", "ndarray", ",", "id_to_state", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "\"\"\"\n        Precomputes a table with lookeahead values\n\n        :param n_states: the number of states\n        :param n_actions: the number of actions\n        :param T: the transition kernel\n        :param id_to_state: the id to state lookup table\n        :return: a dict with next state lookups\n        \"\"\"", "\n", "next_state_lookahead", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "n_states", ")", ":", "\n", "            ", "next_states", "=", "[", "]", "\n", "print", "(", "\"{}/{}\"", ".", "format", "(", "i", ",", "n_states", ")", ")", "\n", "for", "j", "in", "range", "(", "n_states", ")", ":", "\n", "                ", "for", "k", "in", "range", "(", "n_actions", ")", ":", "\n", "                    ", "if", "T", "[", "i", "]", "[", "k", "]", "[", "j", "]", ">", "0.0", "and", "j", "not", "in", "next_states", ":", "\n", "                        ", "next_states", ".", "append", "(", "j", ")", "\n", "", "", "", "if", "len", "(", "next_states", ")", "==", "0", ":", "\n", "                ", "print", "(", "\"state:{}, {}, has no next state\"", ".", "format", "(", "i", ",", "id_to_state", "[", "i", "]", ")", ")", "\n", "", "next_state_lookahead", "[", "i", "]", "=", "next_states", "\n", "", "DP", ".", "save_json", "(", "next_state_lookahead", ",", "\"next_state_lookahead.json\"", ")", "\n", "return", "next_state_lookahead", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.value_iteration": [[305, 361], ["numpy.zeros", "numpy.zeros", "range", "dp.DP.save_numpy", "dp.DP.save_numpy", "range", "print", "dp.DP.one_step_lookahead", "numpy.argmax", "dp.DP.one_step_lookahead", "numpy.max", "max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.one_step_lookahead", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.one_step_lookahead"], ["", "@", "staticmethod", "\n", "def", "value_iteration", "(", "T", ":", "np", ".", "ndarray", ",", "num_states", ":", "int", ",", "num_actions", ":", "int", ",", "state_to_id", ":", "dict", ",", "\n", "id_to_state", ":", "dict", ",", "HP", ":", "np", ".", "ndarray", ",", "R", ":", "np", ".", "ndarray", ",", "\n", "next_state_lookahead", ":", "dict", ",", "\n", "theta", "=", "0.0001", ",", "discount_factor", "=", "1.0", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        An implementation of the Value Iteration algorithm\n\n        :param T: the transition kernel T\n        :param num_states: the number of states\n        :param num_actions: the number of actions\n        :param state_to_id: the state-to-id lookup table\n        :param id_to_state: the id-to-state lookup table\n        :param HP: the table with hack probabilities\n        :param R: the table with rewards\n        :param next_state_lookahead: the next-state-lookahead table\n        :param theta: convergence threshold\n        :param discount_factor: the discount factor\n        :return: (greedy policy, value function)\n        \"\"\"", "\n", "V", "=", "np", ".", "zeros", "(", "num_states", ")", "\n", "\n", "while", "True", ":", "\n", "# Stopping condition", "\n", "            ", "delta", "=", "0", "\n", "# Update each state...", "\n", "for", "s", "in", "range", "(", "num_states", ")", ":", "\n", "# Do a one-step lookahead to find the best action", "\n", "                ", "A", "=", "DP", ".", "one_step_lookahead", "(", "s", ",", "V", ",", "num_actions", ",", "num_states", ",", "T", ",", "discount_factor", ",", "R", ",", "next_state_lookahead", ",", "\n", "id_to_state", ")", "\n", "best_action_value", "=", "np", ".", "max", "(", "A", ")", "\n", "# Calculate delta across all states seen so far", "\n", "delta", "=", "max", "(", "delta", ",", "np", ".", "abs", "(", "best_action_value", "-", "V", "[", "s", "]", ")", ")", "\n", "# Update the value function. Ref: Sutton book eq. 4.10.", "\n", "V", "[", "s", "]", "=", "best_action_value", "\n", "\n", "", "print", "(", "\"delta:{}\"", ".", "format", "(", "delta", ")", ")", "\n", "# Check if we can stop", "\n", "if", "delta", "<", "theta", ":", "\n", "                ", "break", "\n", "\n", "# Create a deterministic policy using the optimal value function", "\n", "", "", "policy", "=", "np", ".", "zeros", "(", "[", "num_states", ",", "num_actions", "*", "2", "]", ")", "\n", "for", "s", "in", "range", "(", "num_states", ")", ":", "\n", "# One step lookahead to find the best action for this state", "\n", "            ", "A", "=", "DP", ".", "one_step_lookahead", "(", "s", ",", "V", ",", "num_actions", ",", "num_states", ",", "T", ",", "discount_factor", ",", "R", ",", "next_state_lookahead", ",", "\n", "id_to_state", ")", "\n", "best_action", "=", "np", ".", "argmax", "(", "A", ")", "\n", "# Always take the best action", "\n", "policy", "[", "s", ",", "best_action", "]", "=", "1.0", "\n", "policy", "[", "s", "]", "[", "2", "]", "=", "A", "[", "0", "]", "\n", "policy", "[", "s", "]", "[", "3", "]", "=", "A", "[", "1", "]", "\n", "\n", "", "DP", ".", "save_numpy", "(", "V", ",", "\"value_fun.npy\"", ")", "\n", "DP", ".", "save_numpy", "(", "policy", ",", "\"policy.npy\"", ")", "\n", "return", "policy", ",", "V", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.compute_thresholds": [[362, 394], ["numpy.zeros", "range", "dp.DP.save_numpy", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy"], ["", "@", "staticmethod", "\n", "def", "compute_thresholds", "(", "V", ":", "np", ".", "ndarray", ",", "T", ":", "np", ".", "ndarray", ",", "R", ":", "np", ".", "ndarray", ",", "n_states", ":", "int", ",", "next_state_lookahead", ":", "dict", ",", "\n", "id_to_state", ":", "dict", ",", "HP", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Utility function for computing stopping thresholds\n\n        :param V: the value function\n        :param T: the transiton kernel\n        :param R: the reward function\n        :param n_states: the number of states\n        :param next_state_lookahead: the lookup table for the next state\n        :param id_to_state: the id-to-state lookup table\n        :param HP: the hack probabilities\n        :return: the computed thresholds\n        \"\"\"", "\n", "thresholds", "=", "np", ".", "zeros", "(", "n_states", ")", "\n", "for", "i", "in", "range", "(", "n_states", ")", ":", "\n", "            ", "s1", "=", "id_to_state", "[", "i", "]", "\n", "w", "=", "0", "\n", "hp", "=", "HP", "[", "i", "]", "\n", "w", "=", "R", "[", "i", "]", "[", "0", "]", "\n", "for", "next_state", "in", "next_state_lookahead", "[", "str", "(", "i", ")", "]", ":", "\n", "                ", "prob", "=", "T", "[", "i", "]", "[", "0", "]", "[", "next_state", "]", "\n", "w", "=", "w", "+", "prob", "*", "V", "[", "next_state", "]", "\n", "", "if", "s1", "!=", "\"terminal\"", ":", "\n", "                ", "(", "t1", ",", "x1", ")", "=", "s1", "\n", "alpha", "=", "-", "(", "w", "+", "10", "-", "10", "*", "hp", ")", "/", "(", "50", "*", "hp", ")", "\n", "", "else", ":", "\n", "                ", "alpha", "=", "0", "\n", "", "thresholds", "[", "i", "]", "=", "alpha", "\n", "", "DP", ".", "save_numpy", "(", "thresholds", ",", "\"thresholds.npy\"", ")", "\n", "return", "thresholds", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_numpy": [[395, 406], ["print", "numpy.save", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save"], ["", "@", "staticmethod", "\n", "def", "save_numpy", "(", "arr", ":", "np", ".", "ndarray", ",", "filename", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for saving a numpy array\n\n        :param arr: the HP table to save\n        :return: None\n        \"\"\"", "\n", "print", "(", "\"saving {}...\"", ".", "format", "(", "filename", ")", ")", "\n", "np", ".", "save", "(", "filename", ",", "arr", ")", "\n", "print", "(", "\"{} saved\"", ".", "format", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.load_numpy": [[408, 421], ["print", "open", "numpy.load", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "load_numpy", "(", "filename", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Utility function for loading a numpy array\n\n        :param filename: the name of the file to load\n        :return: the loaded array\n        \"\"\"", "\n", "print", "(", "\"loading {}..\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "arr", "=", "np", ".", "load", "(", "f", ")", "\n", "print", "(", "\"{} loaded:{}\"", ".", "format", "(", "filename", ",", "arr", ".", "shape", ")", ")", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_json": [[422, 434], ["print", "print", "open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump"], ["", "", "@", "staticmethod", "\n", "def", "save_json", "(", "d", ":", "dict", ",", "file_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for saving a dict into json format\n\n        :param d:\n        :return: None\n        \"\"\"", "\n", "print", "(", "\"Saving {}\"", ".", "format", "(", "file_name", ")", ")", "\n", "with", "open", "(", "file_name", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "d", ",", "fp", ")", "\n", "", "print", "(", "\"{} saved\"", ".", "format", "(", "file_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.save_pickle": [[435, 448], ["print", "print", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump"], ["", "@", "staticmethod", "\n", "def", "save_pickle", "(", "obj", ",", "filename", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for saving an object with pickle\n\n        :param obj: the obj to save\n        :param filename: the name of the file to save\n        :return: None\n        \"\"\"", "\n", "print", "(", "\"Saving {} table\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "obj", ",", "fp", ")", "\n", "", "print", "(", "\"{} saved\"", ".", "format", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.load_pickle": [[449, 463], ["print", "print", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "load_pickle", "(", "filename", ")", "->", "object", ":", "\n", "        ", "\"\"\"\n        Utility function for loading an object saved as pickle\n\n        :param filename: the filename to load\n        :return: the loaded object\n        \"\"\"", "\n", "print", "(", "\"Loading {}\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "fp", ":", "\n", "            ", "obj", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "print", "(", "\"{} loaded\"", ".", "format", "(", "filename", ")", ")", "\n", "\n", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.load_json": [[464, 477], ["print", "print", "open", "json.load", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "load_json", "(", "filename", ")", "->", "dict", ":", "\n", "        ", "\"\"\"\n        Loads a dict saved as json\n\n        :param filename: name of the file to load\n        :return: the loaded file\n        \"\"\"", "\n", "print", "(", "\"Loading {}\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "d", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "print", "(", "\"{} loaded:{}\"", ".", "format", "(", "filename", ",", "len", "(", "d", ")", ")", ")", "\n", "return", "d", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.experiment.client_config.ClientConfig.__init__": [[14, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_name", ":", "str", ",", "\n", "attacker_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "defender_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "output_dir", ":", "str", "=", "None", ",", "title", "=", "None", ",", "\n", "env_config", "=", "None", ",", "run_many", ":", "bool", "=", "False", ",", "\n", "random_seeds", ":", "list", "=", "None", ",", "random_seed", "=", "0", ",", "\n", "agent_type", ":", "int", "=", "0", ",", "\n", "env_checkpoint_dir", ":", "str", "=", "None", ",", "\n", "mode", ":", "RunnerMode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ",", "\n", "eval_env", ":", "bool", "=", "None", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ",", "\n", "traces_dir", ":", "str", "=", "\"\"", ",", "\n", "traces_filename", "=", "\"\"", "\n", ")", ":", "\n", "        ", "self", ".", "env_name", "=", "env_name", "\n", "self", ".", "logger", "=", "None", "\n", "self", ".", "output_dir", "=", "output_dir", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "env_config", "=", "env_config", "\n", "self", ".", "run_many", "=", "run_many", "\n", "self", ".", "random_seeds", "=", "random_seeds", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "attacker_agent_config", "=", "attacker_agent_config", "\n", "self", ".", "defender_agent_config", "=", "defender_agent_config", "\n", "self", ".", "agent_type", "=", "agent_type", "\n", "self", ".", "env_checkpoint_dir", "=", "env_checkpoint_dir", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "eval_env", "=", "eval_env", "\n", "self", ".", "n_envs", "=", "n_envs", "\n", "self", ".", "train_mode", "=", "train_mode", "\n", "self", ".", "traces_dir", "=", "traces_dir", "\n", "self", ".", "traces_filename", "=", "traces_filename", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.experiment.experiment_result.ExperimentResult.__init__": [[12, 469], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "attacker_avg_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "defender_avg_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "avg_episode_steps", ":", "List", "[", "int", "]", "=", "None", ",", "epsilon_values", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_cumulative_reward", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "defender_cumulative_reward", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "attacker_avg_episode_loss", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "defender_avg_episode_loss", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "lr_list", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "avg_episode_flags", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "avg_episode_flags_percentage", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_eval_avg_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "defender_eval_avg_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_avg_episode_steps", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_avg_episode_flags", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_avg_episode_flags_percentage", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_eval_2_avg_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "defender_eval_2_avg_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_avg_episode_steps", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_avg_episode_flags", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_avg_episode_flags_percentage", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_train_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "defender_train_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "train_env_specific_steps", ":", "dict", "=", "None", ",", "\n", "train_env_specific_flags", ":", "dict", "=", "None", ",", "\n", "train_env_specific_flags_percentage", ":", "dict", "=", "None", ",", "\n", "attacker_train_env_specific_regrets", ":", "dict", "=", "None", ",", "\n", "defender_train_env_specific_regrets", ":", "dict", "=", "None", ",", "\n", "attacker_train_env_specific_opt_fracs", ":", "dict", "=", "None", ",", "\n", "defender_train_env_specific_opt_fracs", ":", "dict", "=", "None", ",", "\n", "attacker_eval_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "defender_eval_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "eval_env_specific_steps", ":", "dict", "=", "None", ",", "\n", "eval_env_specific_flags", ":", "dict", "=", "None", ",", "\n", "eval_env_specific_flags_percentage", ":", "dict", "=", "None", ",", "\n", "attacker_eval_env_specific_regrets", ":", "dict", "=", "None", ",", "\n", "defender_eval_env_specific_regrets", ":", "dict", "=", "None", ",", "\n", "attacker_eval_env_specific_opt_fracs", ":", "dict", "=", "None", ",", "\n", "defender_eval_env_specific_opt_fracs", ":", "dict", "=", "None", ",", "\n", "attacker_eval_2_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "defender_eval_2_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "eval_2_env_specific_steps", ":", "dict", "=", "None", ",", "\n", "eval_2_env_specific_flags", ":", "dict", "=", "None", ",", "\n", "eval_2_env_specific_flags_percentage", ":", "dict", "=", "None", ",", "\n", "attacker_eval_2_env_specific_regrets", ":", "dict", "=", "None", ",", "\n", "defender_eval_2_env_specific_regrets", ":", "dict", "=", "None", ",", "\n", "attacker_eval_2_env_specific_opt_fracs", ":", "dict", "=", "None", ",", "\n", "defender_eval_2_env_specific_opt_fracs", ":", "dict", "=", "None", ",", "\n", "rollout_times", ":", "List", "=", "None", ",", "env_response_times", ":", "List", "=", "None", ",", "\n", "action_pred_times", ":", "List", "=", "None", ",", "grad_comp_times", ":", "List", "=", "None", ",", "\n", "weight_update_times", ":", "List", "=", "None", ",", "\n", "attacker_avg_regret", ":", "List", "=", "None", ",", "defender_avg_regret", ":", "List", "=", "None", ",", "\n", "attacker_avg_opt_frac", ":", "List", "=", "None", ",", "defender_avg_opt_frac", ":", "List", "=", "None", ",", "\n", "attacker_eval_avg_regret", ":", "List", "=", "None", ",", "defender_eval_avg_regret", ":", "List", "=", "None", ",", "\n", "attacker_eval_avg_opt_frac", ":", "List", "=", "None", ",", "defender_eval_avg_opt_frac", ":", "List", "=", "None", ",", "\n", "attacker_eval_2_avg_regret", ":", "List", "=", "None", ",", "defender_eval_2_avg_regret", ":", "List", "=", "None", ",", "\n", "attacker_eval_2_avg_opt_frac", ":", "List", "=", "None", ",", "defender_eval_2_avg_opt_frac", ":", "List", "=", "None", ",", "\n", "caught_frac", ":", "List", "=", "None", ",", "early_stopping_frac", ":", "List", "=", "None", ",", "\n", "intrusion_frac", ":", "List", "=", "None", ",", "\n", "eval_caught_frac", ":", "List", "=", "None", ",", "eval_early_stopping_frac", ":", "List", "=", "None", ",", "\n", "eval_intrusion_frac", ":", "List", "=", "None", ",", "\n", "eval_2_caught_frac", ":", "List", "=", "None", ",", "eval_2_early_stopping_frac", ":", "List", "=", "None", ",", "\n", "eval_2_intrusion_frac", ":", "List", "=", "None", ",", "\n", "snort_severe_baseline_rewards", ":", "List", "=", "None", ",", "snort_warning_baseline_rewards", ":", "List", "=", "None", ",", "\n", "eval_snort_severe_baseline_rewards", ":", "List", "=", "None", ",", "eval_snort_warning_baseline_rewards", ":", "List", "=", "None", ",", "\n", "eval_2_snort_severe_baseline_rewards", ":", "List", "=", "None", ",", "eval_2_snort_warning_baseline_rewards", ":", "List", "=", "None", ",", "\n", "snort_critical_baseline_rewards", ":", "List", "=", "None", ",", "var_log_baseline_rewards", ":", "List", "=", "None", ",", "\n", "eval_snort_critical_baseline_rewards", ":", "List", "=", "None", ",", "eval_var_log_baseline_rewards", ":", "List", "=", "None", ",", "\n", "eval_2_snort_critical_baseline_rewards", ":", "List", "=", "None", ",", "eval_2_var_log_baseline_rewards", ":", "List", "=", "None", ",", "\n", "attacker_action_costs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_action_costs_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_action_alerts", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_action_alerts_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_costs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_costs_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_alerts", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_alerts_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_costs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_costs_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_alerts", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_alerts_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "time_elapsed", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "optimal_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "optimal_steps", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "intrusion_steps", ":", "List", "[", "float", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the DTO\n\n        :param attacker_avg_episode_rewards: list of episode rewards for attacker\n        :param defender_avg_episode_rewards: list of episode rewards for defender\n        :param avg_episode_steps: list of episode steps\n        :param epsilon_values: list of epsilon values\n        :param attacker_cumulative_reward: list of attacker cumulative rewards\n        :param defender_cumulative_reward: list of defender cumulative rewards\n        :param attacker_avg_episode_loss: average loss for attacker\n        :param defender_avg_episode_loss: average loss for defnder\n        :param lr_list: learning rates\n        :param avg_episode_flags: avg number of flags catched per episode\n        :param avg_episode_flags_percentage: avg % of flags catched per episode\n        :param attacker_eval_avg_episode_rewards: list of episode rewards for eval deterministic attacker\n        :param defender_eval_avg_episode_rewards: list of episode rewards for eval deterministic defender\n        :param eval_avg_episode_steps: list of episode steps for eval deterministic\n        :param eval_avg_episode_flags: list of episode flags for eval deterministic\n        :param eval_avg_episode_flags_percentage: list of episode flags for eval deterministic\n        :param attacker_eval_2_avg_episode_rewards: list of episode rewards for second eval env deterministic attacker\n        :param defender_eval_2_avg_episode_rewards: list of episode rewards for second eval env deterministic defender\n        :param eval_2_avg_episode_steps: list of episode steps for second eval enveval deterministic\n        :param eval_2_avg_episode_flags: list of episode flags for second eval enveval deterministic\n        :param eval_2_avg_episode_flags_percentage: list of episode flags for second eval env eval deterministic\n        :param attacker_train_env_specific_rewards: rewards data for specific train env attacker\n        :param defender_train_env_specific_rewards: rewards data for specific train env defender\n        :param train_env_specific_flags: flags data for specific train env\n        :param train_env_specific_steps: steps data for specific train env\n        :param train_env_specific_flags_percentage: flags percentage for specific train env\n        :param attacker_eval_env_specific_rewards: eval reward data for specific train env deterministic attacker\n        :param defender_eval_env_specific_rewards: eval reward data for specific train env deterministic defender\n        :param eval_env_specific_flags: eval flags data for specific train env deterministic\n        :param eval_env_specific_flags_percentage: eval flags percentage data for specific train env deterministic\n        :param eval_env_specific_steps: eval steps data for specific train env deterministic\n        :param attacker_eval_2_env_specific_rewards: eval reward data for specific eval env deterministic attacker\n        :param defender_eval_2_env_specific_rewards: eval reward data for specific eval env deterministic defender\n        :param eval_2_env_specific_flags: eval flags data for specific eval env deterministic\n        :param eval_2_env_specific_flags_percentage: eval flags percentage dat2a for specific eval env deterministic\n        :param eval_2_env_specific_steps: eval steps data for specific eval env env deterministic\n        :param caught_frac: percentage that the attacker was caught by the defender\n        :param early_stopping_frac: percentage that the defender stopped too early\n        :param intrusion_frac: percentage of successful intrusions by the attacker\n        :param eval_caught_frac: eval percentage that the attacker was caught by the defender\n        :param eval_early_stopping_frac: eval percentage that the defender stopped too early\n        :param eval_intrusion_frac: eval percentage of successful intrusions by the attacker\n        :param eval_2_caught_frac: eval2 percentage that the attacker was caught by the defender\n        :param eval_2_early_stopping_frac: eval2 percentage that the defender stopped too early\n        :param eval_2_intrusion_frac: eval2 percentage of successful intrusions by the attacker\n        :param snort_severe_baseline_rewards: rewards of the snort severe baseline\n        :param snort_warning_baseline_rewards: rewards of the snort warning baseline\n        :param eval_snort_severe_baseline_rewards: eval rewards of the snort severe baseline\n        :param eval_snort_warning_baseline_rewards: eval rewards of the snort warning baseline\n        :param eval_2_snort_severe_baseline_rewards: eval 2 rewards of the snort severe baseline\n        :param eval_2_snort_warning_baseline_rewards: eval 2 rewards of the snort warning baseline\n        :param snort_critical_baseline_rewards: rewards of the snort critical baseline\n        :param var_log_baseline_rewards: rewards of the var_log  baseline\n        :param eval_snort_critical_baseline_rewards: eval rewards of the snort critical baseline\n        :param eval_var_log_baseline_rewards: eval rewards of the var_log  baseline\n        :param eval_2_snort_critical_baseline_rewards: eval 2 rewards of the snort critical baseline\n        :param eval_2_var_log_baseline_rewards: eval 2 rewards of the var_log  baseline\n        :param time_elapsed: the time elapsed from start of training\n        :param optimal_rewards: the optimal rewards\n        :param optimal_steps: the optimal steps\n        :param intrusion_steps: the number of intrusion steps\n        \"\"\"", "\n", "self", ".", "attacker_avg_episode_rewards", "=", "attacker_avg_episode_rewards", "\n", "self", ".", "defender_avg_episode_rewards", "=", "defender_avg_episode_rewards", "\n", "self", ".", "avg_episode_steps", "=", "avg_episode_steps", "\n", "self", ".", "epsilon_values", "=", "epsilon_values", "\n", "self", ".", "attacker_cumulative_reward", "=", "attacker_cumulative_reward", "\n", "self", ".", "defender_cumulative_reward", "=", "defender_cumulative_reward", "\n", "self", ".", "attacker_avg_episode_loss", "=", "attacker_avg_episode_loss", "\n", "self", ".", "defender_avg_episode_loss", "=", "defender_avg_episode_loss", "\n", "self", ".", "lr_list", "=", "lr_list", "\n", "self", ".", "avg_episode_flags", "=", "avg_episode_flags", "\n", "self", ".", "avg_episode_flags_percentage", "=", "avg_episode_flags_percentage", "\n", "self", ".", "attacker_eval_avg_episode_rewards", "=", "attacker_eval_avg_episode_rewards", "\n", "self", ".", "defender_eval_avg_episode_rewards", "=", "defender_eval_avg_episode_rewards", "\n", "self", ".", "eval_avg_episode_steps", "=", "eval_avg_episode_steps", "\n", "self", ".", "eval_avg_episode_flags", "=", "eval_avg_episode_flags", "\n", "self", ".", "eval_avg_episode_flags_percentage", "=", "eval_avg_episode_flags_percentage", "\n", "self", ".", "attacker_eval_2_avg_episode_rewards", "=", "attacker_eval_2_avg_episode_rewards", "\n", "self", ".", "defender_eval_2_avg_episode_rewards", "=", "defender_eval_2_avg_episode_rewards", "\n", "self", ".", "eval_2_avg_episode_steps", "=", "eval_2_avg_episode_steps", "\n", "self", ".", "eval_2_avg_episode_flags", "=", "eval_2_avg_episode_flags", "\n", "self", ".", "eval_2_avg_episode_flags_percentage", "=", "eval_2_avg_episode_flags_percentage", "\n", "self", ".", "attacker_train_env_specific_rewards", "=", "attacker_train_env_specific_rewards", "\n", "self", ".", "defender_train_env_specific_rewards", "=", "defender_train_env_specific_rewards", "\n", "self", ".", "train_env_specific_flags", "=", "train_env_specific_flags", "\n", "self", ".", "train_env_specific_steps", "=", "train_env_specific_steps", "\n", "self", ".", "train_env_specific_flags_percentage", "=", "train_env_specific_flags_percentage", "\n", "self", ".", "attacker_train_env_specific_regrets", "=", "attacker_train_env_specific_regrets", "\n", "self", ".", "defender_train_env_specific_regrets", "=", "defender_train_env_specific_regrets", "\n", "self", ".", "attacker_train_env_specific_opt_fracs", "=", "attacker_train_env_specific_opt_fracs", "\n", "self", ".", "defender_train_env_specific_opt_fracs", "=", "defender_train_env_specific_opt_fracs", "\n", "self", ".", "attacker_eval_env_specific_rewards", "=", "attacker_eval_env_specific_rewards", "\n", "self", ".", "defender_eval_env_specific_rewards", "=", "defender_eval_env_specific_rewards", "\n", "self", ".", "eval_env_specific_flags", "=", "eval_env_specific_flags", "\n", "self", ".", "eval_env_specific_steps", "=", "eval_env_specific_steps", "\n", "self", ".", "eval_env_specific_flags_percentage", "=", "eval_env_specific_flags_percentage", "\n", "self", ".", "attacker_eval_env_specific_regrets", "=", "attacker_eval_env_specific_regrets", "\n", "self", ".", "defender_eval_env_specific_regrets", "=", "defender_eval_env_specific_regrets", "\n", "self", ".", "attacker_eval_env_specific_opt_fracs", "=", "attacker_eval_env_specific_opt_fracs", "\n", "self", ".", "defender_eval_env_specific_opt_fracs", "=", "defender_eval_env_specific_opt_fracs", "\n", "self", ".", "attacker_eval_2_env_specific_rewards", "=", "attacker_eval_2_env_specific_rewards", "\n", "self", ".", "defender_eval_2_env_specific_rewards", "=", "defender_eval_2_env_specific_rewards", "\n", "self", ".", "eval_2_env_specific_flags", "=", "eval_2_env_specific_flags", "\n", "self", ".", "eval_2_env_specific_steps", "=", "eval_2_env_specific_steps", "\n", "self", ".", "eval_2_env_specific_flags_percentage", "=", "eval_2_env_specific_flags_percentage", "\n", "self", ".", "attacker_eval_2_env_specific_regrets", "=", "attacker_eval_2_env_specific_regrets", "\n", "self", ".", "defender_eval_2_env_specific_regrets", "=", "defender_eval_2_env_specific_regrets", "\n", "self", ".", "attacker_eval_2_env_specific_opt_fracs", "=", "attacker_eval_2_env_specific_opt_fracs", "\n", "self", ".", "defender_eval_2_env_specific_opt_fracs", "=", "defender_eval_2_env_specific_opt_fracs", "\n", "self", ".", "rollout_times", "=", "rollout_times", "\n", "self", ".", "env_response_times", "=", "env_response_times", "\n", "self", ".", "action_pred_times", "=", "action_pred_times", "\n", "self", ".", "grad_comp_times", "=", "grad_comp_times", "\n", "self", ".", "weight_update_times", "=", "weight_update_times", "\n", "self", ".", "attacker_avg_opt_frac", "=", "attacker_avg_opt_frac", "\n", "self", ".", "defender_avg_opt_frac", "=", "defender_avg_opt_frac", "\n", "self", ".", "attacker_avg_regret", "=", "attacker_avg_regret", "\n", "self", ".", "defender_avg_regret", "=", "defender_avg_regret", "\n", "self", ".", "attacker_eval_avg_regret", "=", "attacker_eval_avg_regret", "\n", "self", ".", "defender_eval_avg_regret", "=", "defender_eval_avg_regret", "\n", "self", ".", "attacker_eval_avg_opt_frac", "=", "attacker_eval_avg_opt_frac", "\n", "self", ".", "defender_eval_avg_opt_frac", "=", "defender_eval_avg_opt_frac", "\n", "self", ".", "attacker_eval_2_avg_regret", "=", "attacker_eval_2_avg_regret", "\n", "self", ".", "defender_eval_2_avg_regret", "=", "defender_eval_2_avg_regret", "\n", "self", ".", "attacker_eval_2_avg_opt_frac", "=", "attacker_eval_2_avg_opt_frac", "\n", "self", ".", "defender_eval_2_avg_opt_frac", "=", "defender_eval_2_avg_opt_frac", "\n", "self", ".", "caught_frac", "=", "caught_frac", "\n", "self", ".", "early_stopping_frac", "=", "early_stopping_frac", "\n", "self", ".", "intrusion_frac", "=", "intrusion_frac", "\n", "self", ".", "eval_caught_frac", "=", "eval_caught_frac", "\n", "self", ".", "eval_early_stopping_frac", "=", "eval_early_stopping_frac", "\n", "self", ".", "eval_intrusion_frac", "=", "eval_intrusion_frac", "\n", "self", ".", "eval_2_caught_frac", "=", "eval_2_caught_frac", "\n", "self", ".", "eval_2_early_stopping_frac", "=", "eval_2_early_stopping_frac", "\n", "self", ".", "eval_2_intrusion_frac", "=", "eval_2_intrusion_frac", "\n", "self", ".", "snort_severe_baseline_rewards", "=", "snort_severe_baseline_rewards", "\n", "self", ".", "snort_warning_baseline_rewards", "=", "snort_warning_baseline_rewards", "\n", "self", ".", "eval_snort_severe_baseline_rewards", "=", "eval_snort_severe_baseline_rewards", "\n", "self", ".", "eval_snort_warning_baseline_rewards", "=", "eval_snort_warning_baseline_rewards", "\n", "self", ".", "eval_2_snort_severe_baseline_rewards", "=", "eval_2_snort_severe_baseline_rewards", "\n", "self", ".", "eval_2_snort_warning_baseline_rewards", "=", "eval_2_snort_warning_baseline_rewards", "\n", "self", ".", "snort_critical_baseline_rewards", "=", "snort_critical_baseline_rewards", "\n", "self", ".", "var_log_baseline_rewards", "=", "var_log_baseline_rewards", "\n", "self", ".", "eval_snort_critical_baseline_rewards", "=", "eval_snort_critical_baseline_rewards", "\n", "self", ".", "eval_var_log_baseline_rewards", "=", "eval_var_log_baseline_rewards", "\n", "self", ".", "eval_2_snort_critical_baseline_rewards", "=", "eval_2_snort_critical_baseline_rewards", "\n", "self", ".", "eval_2_var_log_baseline_rewards", "=", "eval_2_var_log_baseline_rewards", "\n", "self", ".", "attacker_action_costs", "=", "attacker_action_costs", "\n", "self", ".", "attacker_action_costs_norm", "=", "attacker_action_costs_norm", "\n", "self", ".", "attacker_action_alerts", "=", "attacker_action_alerts", "\n", "self", ".", "attacker_action_alerts_norm", "=", "attacker_action_alerts_norm", "\n", "self", ".", "eval_attacker_action_costs", "=", "eval_attacker_action_costs", "\n", "self", ".", "eval_attacker_action_costs_norm", "=", "eval_attacker_action_costs_norm", "\n", "self", ".", "eval_attacker_action_alerts", "=", "eval_attacker_action_alerts", "\n", "self", ".", "eval_attacker_action_alerts_norm", "=", "eval_attacker_action_alerts_norm", "\n", "self", ".", "eval_2_attacker_action_costs", "=", "eval_2_attacker_action_costs", "\n", "self", ".", "eval_2_attacker_action_costs_norm", "=", "eval_2_attacker_action_costs_norm", "\n", "self", ".", "eval_2_attacker_action_alerts", "=", "eval_2_attacker_action_alerts", "\n", "self", ".", "eval_2_attacker_action_alerts_norm", "=", "eval_2_attacker_action_alerts_norm", "\n", "self", ".", "time_elapsed", "=", "time_elapsed", "\n", "self", ".", "optimal_rewards", "=", "optimal_rewards", "\n", "self", ".", "optimal_steps", "=", "optimal_steps", "\n", "self", ".", "intrusion_steps", "=", "intrusion_steps", "\n", "\n", "if", "avg_episode_steps", "is", "None", ":", "\n", "            ", "self", ".", "avg_episode_steps", "=", "[", "]", "\n", "", "if", "attacker_avg_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "attacker_avg_episode_rewards", "=", "[", "]", "\n", "", "if", "defender_avg_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "defender_avg_episode_rewards", "=", "[", "]", "\n", "", "if", "epsilon_values", "is", "None", ":", "\n", "            ", "self", ".", "epsilon_values", "=", "[", "]", "\n", "", "if", "attacker_cumulative_reward", "is", "None", ":", "\n", "            ", "self", ".", "attacker_cumulative_reward", "=", "[", "]", "\n", "", "if", "defender_cumulative_reward", "is", "None", ":", "\n", "            ", "self", ".", "defender_cumulative_reward", "=", "[", "]", "\n", "", "if", "attacker_avg_episode_loss", "is", "None", ":", "\n", "            ", "self", ".", "attacker_avg_episode_loss", "=", "[", "]", "\n", "", "if", "defender_avg_episode_loss", "is", "None", ":", "\n", "            ", "self", ".", "defender_avg_episode_loss", "=", "[", "]", "\n", "", "if", "lr_list", "is", "None", ":", "\n", "            ", "self", ".", "lr_list", "=", "[", "]", "\n", "", "if", "avg_episode_flags", "is", "None", ":", "\n", "            ", "self", ".", "avg_episode_flags", "=", "[", "]", "\n", "", "if", "avg_episode_flags_percentage", "is", "None", ":", "\n", "            ", "self", ".", "avg_episode_flags_percentage", "=", "[", "]", "\n", "", "if", "attacker_eval_avg_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_avg_episode_rewards", "=", "[", "]", "\n", "", "if", "defender_eval_avg_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_avg_episode_rewards", "=", "[", "]", "\n", "", "if", "eval_avg_episode_steps", "is", "None", ":", "\n", "            ", "self", ".", "eval_avg_episode_steps", "=", "[", "]", "\n", "", "if", "eval_avg_episode_flags", "is", "None", ":", "\n", "            ", "self", ".", "eval_avg_episode_flags", "=", "[", "]", "\n", "", "if", "eval_avg_episode_flags_percentage", "is", "None", ":", "\n", "            ", "self", ".", "eval_avg_episode_flags_percentage", "=", "[", "]", "\n", "", "if", "attacker_eval_2_avg_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_2_avg_episode_rewards", "=", "[", "]", "\n", "", "if", "defender_eval_2_avg_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_2_avg_episode_rewards", "=", "[", "]", "\n", "", "if", "eval_2_avg_episode_steps", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_avg_episode_steps", "=", "[", "]", "\n", "", "if", "eval_2_avg_episode_flags", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_avg_episode_flags", "=", "[", "]", "\n", "", "if", "eval_2_avg_episode_flags_percentage", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_avg_episode_flags_percentage", "=", "[", "]", "\n", "", "if", "attacker_train_env_specific_rewards", "is", "None", ":", "\n", "            ", "self", ".", "attacker_train_env_specific_rewards", "=", "{", "}", "\n", "", "if", "defender_train_env_specific_rewards", "is", "None", ":", "\n", "            ", "self", ".", "defender_train_env_specific_rewards", "=", "{", "}", "\n", "", "if", "attacker_train_env_specific_regrets", "is", "None", ":", "\n", "            ", "self", ".", "attacker_train_env_specific_regrets", "=", "{", "}", "\n", "", "if", "defender_train_env_specific_regrets", "is", "None", ":", "\n", "            ", "self", ".", "defender_train_env_specific_regrets", "=", "{", "}", "\n", "", "if", "attacker_train_env_specific_opt_fracs", "is", "None", ":", "\n", "            ", "self", ".", "attacker_train_env_specific_opt_fracs", "=", "{", "}", "\n", "", "if", "defender_train_env_specific_opt_fracs", "is", "None", ":", "\n", "            ", "self", ".", "defender_train_env_specific_opt_fracs", "=", "{", "}", "\n", "", "if", "train_env_specific_steps", "is", "None", ":", "\n", "            ", "self", ".", "train_env_specific_steps", "=", "{", "}", "\n", "", "if", "train_env_specific_flags", "is", "None", ":", "\n", "            ", "self", ".", "train_env_specific_flags", "=", "{", "}", "\n", "", "if", "train_env_specific_flags_percentage", "is", "None", ":", "\n", "            ", "self", ".", "train_env_specific_flags_percentage", "=", "{", "}", "\n", "", "if", "attacker_eval_env_specific_rewards", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_env_specific_rewards", "=", "{", "}", "\n", "", "if", "defender_eval_env_specific_rewards", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_env_specific_rewards", "=", "{", "}", "\n", "", "if", "attacker_eval_env_specific_regrets", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_env_specific_regrets", "=", "{", "}", "\n", "", "if", "defender_eval_env_specific_regrets", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_env_specific_regrets", "=", "{", "}", "\n", "", "if", "attacker_eval_env_specific_opt_fracs", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_env_specific_opt_fracs", "=", "{", "}", "\n", "", "if", "defender_eval_env_specific_opt_fracs", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_env_specific_opt_fracs", "=", "{", "}", "\n", "", "if", "eval_env_specific_steps", "is", "None", ":", "\n", "            ", "self", ".", "eval_env_specific_steps", "=", "{", "}", "\n", "", "if", "eval_env_specific_flags", "is", "None", ":", "\n", "            ", "self", ".", "eval_env_specific_flags", "=", "{", "}", "\n", "", "if", "eval_env_specific_flags_percentage", "is", "None", ":", "\n", "            ", "self", ".", "eval_env_specific_flags_percentage", "=", "{", "}", "\n", "", "if", "attacker_eval_2_env_specific_rewards", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_2_env_specific_rewards", "=", "{", "}", "\n", "", "if", "defender_eval_2_env_specific_rewards", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_2_env_specific_rewards", "=", "{", "}", "\n", "", "if", "attacker_eval_2_env_specific_regrets", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_2_env_specific_regrets", "=", "{", "}", "\n", "", "if", "defender_eval_2_env_specific_regrets", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_2_env_specific_regrets", "=", "{", "}", "\n", "", "if", "attacker_eval_2_env_specific_opt_fracs", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_2_env_specific_opt_fracs", "=", "{", "}", "\n", "", "if", "defender_eval_2_env_specific_opt_fracs", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_2_env_specific_opt_fracs", "=", "{", "}", "\n", "", "if", "eval_2_env_specific_steps", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_env_specific_steps", "=", "{", "}", "\n", "", "if", "eval_2_env_specific_flags", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_env_specific_flags", "=", "{", "}", "\n", "", "if", "eval_2_env_specific_flags_percentage", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_env_specific_flags_percentage", "=", "{", "}", "\n", "", "if", "rollout_times", "is", "None", ":", "\n", "            ", "self", ".", "rollout_times", "=", "[", "]", "\n", "", "if", "env_response_times", "is", "None", ":", "\n", "            ", "self", ".", "env_response_times", "=", "[", "]", "\n", "", "if", "action_pred_times", "is", "None", ":", "\n", "            ", "self", ".", "action_pred_times", "=", "[", "]", "\n", "", "if", "grad_comp_times", "is", "None", ":", "\n", "            ", "self", ".", "grad_comp_times", "=", "[", "]", "\n", "", "if", "weight_update_times", "is", "None", ":", "\n", "            ", "self", ".", "weight_update_times", "=", "[", "]", "\n", "", "if", "attacker_avg_regret", "is", "None", ":", "\n", "            ", "self", ".", "attacker_avg_regret", "=", "[", "]", "\n", "", "if", "defender_avg_regret", "is", "None", ":", "\n", "            ", "self", ".", "defender_avg_regret", "=", "[", "]", "\n", "", "if", "attacker_avg_opt_frac", "is", "None", ":", "\n", "            ", "self", ".", "attacker_avg_opt_frac", "=", "[", "]", "\n", "", "if", "defender_avg_opt_frac", "is", "None", ":", "\n", "            ", "self", ".", "defender_avg_opt_frac", "=", "[", "]", "\n", "", "if", "attacker_eval_avg_regret", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_avg_regret", "=", "[", "]", "\n", "", "if", "defender_eval_avg_regret", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_avg_regret", "=", "[", "]", "\n", "", "if", "attacker_eval_avg_opt_frac", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_avg_opt_frac", "=", "[", "]", "\n", "", "if", "defender_eval_avg_opt_frac", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_avg_opt_frac", "=", "[", "]", "\n", "", "if", "attacker_eval_2_avg_regret", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_2_avg_regret", "=", "[", "]", "\n", "", "if", "defender_eval_2_avg_regret", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_2_avg_regret", "=", "[", "]", "\n", "", "if", "attacker_eval_2_avg_opt_frac", "is", "None", ":", "\n", "            ", "self", ".", "attacker_eval_2_avg_opt_frac", "=", "[", "]", "\n", "", "if", "defender_eval_2_avg_opt_frac", "is", "None", ":", "\n", "            ", "self", ".", "defender_eval_2_avg_opt_frac", "=", "[", "]", "\n", "", "if", "caught_frac", "is", "None", ":", "\n", "            ", "self", ".", "caught_frac", "=", "[", "]", "\n", "", "if", "early_stopping_frac", "is", "None", ":", "\n", "            ", "self", ".", "early_stopping_frac", "=", "[", "]", "\n", "", "if", "intrusion_frac", "is", "None", ":", "\n", "            ", "self", ".", "intrusion_frac", "=", "[", "]", "\n", "", "if", "eval_caught_frac", "is", "None", ":", "\n", "            ", "self", ".", "eval_caught_frac", "=", "[", "]", "\n", "", "if", "eval_early_stopping_frac", "is", "None", ":", "\n", "            ", "self", ".", "eval_early_stopping_frac", "=", "[", "]", "\n", "", "if", "eval_intrusion_frac", "is", "None", ":", "\n", "            ", "self", ".", "eval_intrusion_frac", "=", "[", "]", "\n", "", "if", "eval_2_caught_frac", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_caught_frac", "=", "[", "]", "\n", "", "if", "eval_2_early_stopping_frac", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_early_stopping_frac", "=", "[", "]", "\n", "", "if", "eval_2_intrusion_frac", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_intrusion_frac", "=", "[", "]", "\n", "", "if", "snort_severe_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "snort_severe_baseline_rewards", "=", "[", "]", "\n", "", "if", "snort_warning_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "snort_warning_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_snort_severe_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_snort_severe_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_snort_warning_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_snort_warning_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_2_snort_severe_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_snort_severe_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_2_snort_warning_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_snort_warning_baseline_rewards", "=", "[", "]", "\n", "", "if", "snort_critical_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "snort_critical_baseline_rewards", "=", "[", "]", "\n", "", "if", "var_log_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "var_log_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_snort_critical_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_snort_critical_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_var_log_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_var_log_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_2_snort_critical_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_snort_critical_baseline_rewards", "=", "[", "]", "\n", "", "if", "eval_2_var_log_baseline_rewards", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_var_log_baseline_rewards", "=", "[", "]", "\n", "", "if", "attacker_action_costs", "is", "None", ":", "\n", "            ", "self", ".", "attacker_action_costs", "=", "[", "]", "\n", "", "if", "attacker_action_costs_norm", "is", "None", ":", "\n", "            ", "self", ".", "attacker_action_costs_norm", "=", "[", "]", "\n", "", "if", "attacker_action_alerts", "is", "None", ":", "\n", "            ", "self", ".", "attacker_action_alerts", "=", "[", "]", "\n", "", "if", "attacker_action_alerts_norm", "is", "None", ":", "\n", "            ", "self", ".", "attacker_action_alerts_norm", "=", "[", "]", "\n", "", "if", "eval_attacker_action_costs", "is", "None", ":", "\n", "            ", "self", ".", "eval_attacker_action_costs", "=", "[", "]", "\n", "", "if", "eval_attacker_action_costs_norm", "is", "None", ":", "\n", "            ", "self", ".", "eval_attacker_action_costs_norm", "=", "[", "]", "\n", "", "if", "eval_attacker_action_alerts", "is", "None", ":", "\n", "            ", "self", ".", "eval_attacker_action_alerts", "=", "[", "]", "\n", "", "if", "eval_attacker_action_alerts_norm", "is", "None", ":", "\n", "            ", "self", ".", "eval_attacker_action_alerts_norm", "=", "[", "]", "\n", "", "if", "eval_2_attacker_action_costs", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_attacker_action_costs", "=", "[", "]", "\n", "", "if", "eval_2_attacker_action_costs_norm", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_attacker_action_costs_norm", "=", "[", "]", "\n", "", "if", "eval_2_attacker_action_alerts", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_attacker_action_alerts", "=", "[", "]", "\n", "", "if", "eval_2_attacker_action_alerts_norm", "is", "None", ":", "\n", "            ", "self", ".", "eval_2_attacker_action_alerts_norm", "=", "[", "]", "\n", "", "if", "time_elapsed", "is", "None", ":", "\n", "            ", "self", ".", "time_elapsed", "=", "[", "]", "\n", "", "if", "optimal_rewards", "is", "None", ":", "\n", "            ", "self", ".", "optimal_rewards", "=", "[", "]", "\n", "", "if", "optimal_steps", "is", "None", ":", "\n", "            ", "self", ".", "optimal_steps", "=", "[", "]", "\n", "", "if", "intrusion_steps", "is", "None", ":", "\n", "            ", "self", ".", "intrusion_steps", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.experiment.experiment_result.ExperimentResult.to_csv": [[470, 673], ["range", "experiment_result.ExperimentResult.attacker_train_env_specific_rewards.keys", "experiment_result.ExperimentResult.defender_train_env_specific_rewards.keys", "experiment_result.ExperimentResult.attacker_train_env_specific_regrets.keys", "experiment_result.ExperimentResult.defender_train_env_specific_regrets.keys", "experiment_result.ExperimentResult.attacker_train_env_specific_opt_fracs.keys", "experiment_result.ExperimentResult.defender_train_env_specific_opt_fracs.keys", "experiment_result.ExperimentResult.train_env_specific_steps.keys", "experiment_result.ExperimentResult.train_env_specific_flags.keys", "experiment_result.ExperimentResult.train_env_specific_flags_percentage.keys", "experiment_result.ExperimentResult.attacker_eval_env_specific_rewards.keys", "experiment_result.ExperimentResult.defender_eval_env_specific_rewards.keys", "experiment_result.ExperimentResult.attacker_eval_env_specific_regrets.keys", "experiment_result.ExperimentResult.defender_eval_env_specific_regrets.keys", "experiment_result.ExperimentResult.attacker_eval_env_specific_opt_fracs.keys", "experiment_result.ExperimentResult.defender_eval_env_specific_opt_fracs.keys", "experiment_result.ExperimentResult.eval_env_specific_steps.keys", "experiment_result.ExperimentResult.eval_env_specific_flags.keys", "experiment_result.ExperimentResult.eval_env_specific_flags_percentage.keys", "experiment_result.ExperimentResult.attacker_eval_2_env_specific_rewards.keys", "experiment_result.ExperimentResult.defender_eval_2_env_specific_rewards.keys", "experiment_result.ExperimentResult.attacker_eval_2_env_specific_regrets.keys", "experiment_result.ExperimentResult.defender_eval_2_env_specific_regrets.keys", "experiment_result.ExperimentResult.attacker_eval_2_env_specific_opt_fracs.keys", "experiment_result.ExperimentResult.defender_eval_2_env_specific_opt_fracs.keys", "experiment_result.ExperimentResult.eval_2_env_specific_steps.keys", "experiment_result.ExperimentResult.eval_2_env_specific_flags.keys", "experiment_result.ExperimentResult.eval_2_env_specific_flags_percentage.keys", "zip", "len", "open", "csv.writer", "csv.writer.writerow", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "len", "filtered_metrics.append", "filtered_metric_labels.append", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save result to csv\n\n        :param file_path: path to save the csv file\n        :return: None\n        \"\"\"", "\n", "metrics", "=", "[", "self", ".", "attacker_avg_episode_rewards", ",", "self", ".", "defender_avg_episode_rewards", ",", "self", ".", "avg_episode_steps", ",", "\n", "self", ".", "epsilon_values", ",", "\n", "self", ".", "attacker_cumulative_reward", ",", "self", ".", "defender_cumulative_reward", ",", "\n", "self", ".", "attacker_avg_episode_loss", ",", "self", ".", "defender_avg_episode_loss", ",", "\n", "self", ".", "lr_list", ",", "self", ".", "avg_episode_flags", ",", "\n", "self", ".", "avg_episode_flags_percentage", ",", "self", ".", "attacker_eval_avg_episode_rewards", ",", "\n", "self", ".", "defender_eval_avg_episode_rewards", ",", "\n", "self", ".", "eval_avg_episode_steps", ",", "\n", "self", ".", "eval_avg_episode_flags", ",", "self", ".", "eval_avg_episode_flags_percentage", ",", "\n", "self", ".", "attacker_eval_2_avg_episode_rewards", ",", "self", ".", "defender_eval_2_avg_episode_rewards", ",", "\n", "self", ".", "eval_2_avg_episode_steps", ",", "\n", "self", ".", "eval_2_avg_episode_flags", ",", "self", ".", "eval_2_avg_episode_flags_percentage", ",", "self", ".", "rollout_times", ",", "\n", "self", ".", "env_response_times", ",", "self", ".", "action_pred_times", ",", "self", ".", "grad_comp_times", ",", "self", ".", "weight_update_times", ",", "\n", "self", ".", "attacker_avg_regret", ",", "self", ".", "defender_avg_regret", ",", "\n", "self", ".", "attacker_avg_opt_frac", ",", "self", ".", "defender_avg_opt_frac", ",", "\n", "self", ".", "attacker_eval_avg_regret", ",", "self", ".", "defender_eval_avg_regret", ",", "\n", "self", ".", "attacker_eval_avg_opt_frac", ",", "self", ".", "defender_eval_avg_opt_frac", ",", "\n", "self", ".", "attacker_eval_2_avg_regret", ",", "self", ".", "defender_eval_2_avg_regret", ",", "\n", "self", ".", "attacker_eval_2_avg_opt_frac", ",", "self", ".", "defender_eval_2_avg_opt_frac", ",", "\n", "self", ".", "caught_frac", ",", "self", ".", "early_stopping_frac", ",", "self", ".", "intrusion_frac", ",", "\n", "self", ".", "eval_caught_frac", ",", "self", ".", "eval_early_stopping_frac", ",", "self", ".", "eval_intrusion_frac", ",", "\n", "self", ".", "eval_2_caught_frac", ",", "self", ".", "eval_2_early_stopping_frac", ",", "\n", "self", ".", "eval_2_intrusion_frac", ",", "\n", "self", ".", "snort_severe_baseline_rewards", ",", "self", ".", "snort_warning_baseline_rewards", ",", "\n", "self", ".", "eval_snort_severe_baseline_rewards", ",", "self", ".", "eval_snort_warning_baseline_rewards", ",", "\n", "self", ".", "eval_2_snort_severe_baseline_rewards", ",", "self", ".", "eval_2_snort_warning_baseline_rewards", ",", "\n", "self", ".", "snort_critical_baseline_rewards", ",", "self", ".", "var_log_baseline_rewards", ",", "\n", "self", ".", "eval_snort_critical_baseline_rewards", ",", "self", ".", "eval_var_log_baseline_rewards", ",", "\n", "self", ".", "eval_2_snort_critical_baseline_rewards", ",", "self", ".", "eval_2_var_log_baseline_rewards", ",", "\n", "self", ".", "attacker_action_costs", ",", "self", ".", "attacker_action_costs_norm", ",", "\n", "self", ".", "attacker_action_alerts", ",", "self", ".", "attacker_action_alerts_norm", ",", "\n", "self", ".", "eval_attacker_action_costs", ",", "self", ".", "eval_attacker_action_costs_norm", ",", "\n", "self", ".", "eval_attacker_action_alerts", ",", "self", ".", "eval_attacker_action_alerts_norm", ",", "\n", "self", ".", "eval_2_attacker_action_costs", ",", "self", ".", "eval_2_attacker_action_costs_norm", ",", "\n", "self", ".", "eval_2_attacker_action_alerts", ",", "self", ".", "eval_2_attacker_action_alerts_norm", ",", "\n", "self", ".", "time_elapsed", ",", "self", ".", "optimal_rewards", ",", "self", ".", "optimal_steps", ",", "self", ".", "intrusion_steps", "\n", "]", "\n", "metric_labels", "=", "[", "\"attacker_avg_episode_rewards\"", ",", "\"defender_avg_episode_rewards\"", ",", "\"avg_episode_steps\"", ",", "\n", "\"epsilon_values\"", ",", "\"attacker_cumulative_reward\"", ",", "\"defender_cumulative_reward\"", ",", "\n", "\"attacker_avg_episode_loss\"", ",", "\n", "\"defender_avg_episode_loss\"", ",", "\n", "\"lr_list\"", ",", "\"avg_episode_flags\"", ",", "\"avg_episode_flags_percentage\"", ",", "\n", "\"attacker_eval_avg_episode_rewards\"", ",", "\"defender_eval_avg_episode_rewards\"", ",", "\n", "\"eval_avg_episode_steps\"", ",", "\"eval_avg_episode_flags\"", ",", "\"eval_avg_episode_flags_percentage\"", ",", "\n", "\"attacker_eval_2_avg_episode_rewards\"", ",", "\"defender_eval_2_avg_episode_rewards\"", ",", "\n", "\"eval_2_avg_episode_steps\"", ",", "\"eval_2_avg_episode_flags\"", ",", "\n", "\"eval_2_avg_episode_flags_percentage\"", ",", "\"rollout_times\"", ",", "\"env_response_times\"", ",", "\n", "\"action_pred_times\"", ",", "\n", "\"grad_comp_times\"", ",", "\"weight_update_times\"", ",", "\"attacker_avg_regret\"", ",", "\"defender_avg_regret\"", ",", "\n", "\"attacker_avg_opt_frac\"", ",", "\"defender_avg_opt_frac\"", ",", "\n", "\"attacker_eval_avg_regret\"", ",", "\"defender_eval_avg_regret\"", ",", "\n", "\"attacker_eval_avg_opt_frac\"", ",", "\"defender_eval_avg_opt_frac\"", ",", "\n", "\"attacker_eval_2_avg_regret\"", ",", "\"defender_eval_2_avg_regret\"", ",", "\n", "\"attacker_eval_2_avg_opt_frac\"", ",", "\"defender_eval_2_avg_opt_frac\"", ",", "\n", "\"caught_frac\"", ",", "\"early_stopping_frac\"", ",", "\"intrusion_frac\"", ",", "\n", "\"eval_caught_frac\"", ",", "\"eval_early_stopping_frac\"", ",", "\"eval_intrusion_frac\"", ",", "\n", "\"eval_2_caught_frac\"", ",", "\"eval_2_early_stopping_frac\"", ",", "\"eval_2_intrusion_frac\"", ",", "\n", "\"snort_severe_baseline_rewards\"", ",", "\"snort_warning_baseline_rewards\"", ",", "\n", "\"eval_snort_severe_baseline_rewards\"", ",", "\"eval_snort_warning_baseline_rewards\"", ",", "\n", "\"eval_2_snort_severe_baseline_rewards\"", ",", "\"eval_2_snort_warning_baseline_rewards\"", ",", "\n", "\"snort_critical_baseline_rewards\"", ",", "\"var_log_baseline_rewards\"", ",", "\n", "\"eval_snort_critical_baseline_rewards\"", ",", "\"eval_var_log_baseline_rewards\"", ",", "\n", "\"eval_2_snort_critical_baseline_rewards\"", ",", "\"eval_2_var_log_baseline_rewards\"", ",", "\n", "\"attacker_action_costs\"", ",", "\"attacker_action_costs_norm\"", ",", "\n", "\"attacker_action_alerts\"", ",", "\"attacker_action_alerts_norm\"", ",", "\n", "\"eval_attacker_action_costs\"", ",", "\"eval_attacker_action_costs_norm\"", ",", "\n", "\"eval_attacker_action_alerts\"", ",", "\"eval_attacker_action_alerts_norm\"", ",", "\n", "\"eval_2_attacker_action_costs\"", ",", "\"eval_2_attacker_action_costs_norm\"", ",", "\n", "\"eval_2_attacker_action_alerts\"", ",", "\"eval_2_attacker_action_alerts_norm\"", ",", "\n", "\"time_elapsed\"", ",", "\"optimal_rewards\"", ",", "\"optimal_steps\"", ",", "\"intrusion_steps\"", "\n", "]", "\n", "filtered_metric_labels", "=", "[", "]", "\n", "filtered_metrics", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "metrics", ")", ")", ":", "\n", "            ", "if", "len", "(", "metrics", "[", "i", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "metrics", "[", "i", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "metric_labels", "[", "i", "]", ")", "\n", "\n", "", "", "for", "key", "in", "self", ".", "attacker_train_env_specific_rewards", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_train_env_specific_rewards", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_train_env_specific_rewards", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_avg_episode_rewards\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_train_env_specific_rewards", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_train_env_specific_rewards", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_train_env_specific_rewards", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_avg_episode_rewards\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_train_env_specific_regrets", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_train_env_specific_regrets", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_train_env_specific_regrets", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_avg_episode_regrets\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_train_env_specific_regrets", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_train_env_specific_regrets", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_train_env_specific_regrets", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_avg_episode_regrets\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_train_env_specific_opt_fracs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_train_env_specific_opt_fracs", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_train_env_specific_opt_fracs", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_avg_episode_opt_fracs\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_train_env_specific_opt_fracs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_train_env_specific_opt_fracs", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_train_env_specific_opt_fracs", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_avg_episode_opt_fracs\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "train_env_specific_steps", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "train_env_specific_steps", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "train_env_specific_steps", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"avg_episode_steps\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "train_env_specific_flags", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "train_env_specific_flags", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "train_env_specific_flags", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"avg_episode_flags\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "train_env_specific_flags_percentage", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "train_env_specific_flags_percentage", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "train_env_specific_flags_percentage", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"avg_episode_flags_percentage\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_eval_env_specific_rewards", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_eval_env_specific_rewards", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_eval_env_specific_rewards", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_eval_avg_episode_rewards\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_eval_env_specific_rewards", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_eval_env_specific_rewards", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_eval_env_specific_rewards", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_eval_avg_episode_rewards\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_eval_env_specific_regrets", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_eval_env_specific_regrets", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_eval_env_specific_regrets", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_eval_avg_episode_regrets\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_eval_env_specific_regrets", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_eval_env_specific_regrets", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_eval_env_specific_regrets", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_eval_avg_episode_regrets\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_eval_env_specific_opt_fracs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_eval_env_specific_opt_fracs", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_eval_env_specific_opt_fracs", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_eval_avg_episode_opt_fracs\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_eval_env_specific_opt_fracs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_eval_env_specific_opt_fracs", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_eval_env_specific_opt_fracs", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_eval_avg_episode_opt_fracs\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "eval_env_specific_steps", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "eval_env_specific_steps", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "eval_env_specific_steps", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"eval_avg_episode_steps\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "eval_env_specific_flags", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "eval_env_specific_flags", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "eval_env_specific_flags", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"eval_avg_episode_flags\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "eval_env_specific_flags_percentage", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "eval_env_specific_flags_percentage", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "eval_env_specific_flags_percentage", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"eval_avg_episode_flags_percentage\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_eval_2_env_specific_rewards", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_eval_2_env_specific_rewards", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_eval_2_env_specific_rewards", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_eval_2_avg_episode_rewards\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_eval_2_env_specific_rewards", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_eval_2_env_specific_rewards", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_eval_2_env_specific_rewards", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_eval_2_avg_episode_rewards\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_eval_2_env_specific_regrets", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_eval_2_env_specific_regrets", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_eval_2_env_specific_regrets", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_eval_2_avg_episode_regrets\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_eval_2_env_specific_regrets", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_eval_2_env_specific_regrets", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_eval_2_env_specific_regrets", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_eval_2_avg_episode_regrets\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "attacker_eval_2_env_specific_opt_fracs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "attacker_eval_2_env_specific_opt_fracs", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "attacker_eval_2_env_specific_opt_fracs", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"attacker_eval_2_avg_episode_opt_fracs\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "defender_eval_2_env_specific_opt_fracs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "defender_eval_2_env_specific_opt_fracs", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "defender_eval_2_env_specific_opt_fracs", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"defender_eval_2_avg_episode_opt_fracs\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "eval_2_env_specific_steps", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "eval_2_env_specific_steps", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "eval_2_env_specific_steps", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"eval_2_avg_episode_steps\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "eval_2_env_specific_flags", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "eval_2_env_specific_flags", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "eval_2_env_specific_flags", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"eval_2_avg_episode_flags\"", ")", "\n", "", "", "for", "key", "in", "self", ".", "eval_2_env_specific_flags_percentage", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "eval_2_env_specific_flags_percentage", "[", "key", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "self", ".", "eval_2_env_specific_flags_percentage", "[", "key", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "str", "(", "key", ")", "+", "\"_\"", "+", "\"eval_2_avg_episode_flags_percentage\"", ")", "\n", "\n", "# for i in range(len(filtered_metrics)):", "\n", "#     print(\"filtered metric: {}, len:{}\".format(filtered_metric_labels[i], len(filtered_metrics[i])))", "\n", "\n", "", "", "rows", "=", "zip", "(", "*", "filtered_metrics", ")", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "filtered_metric_labels", ")", "\n", "for", "row", "in", "rows", ":", "\n", "                ", "writer", ".", "writerow", "(", "row", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.attacker_obs_state.AttackerObservationState.__init__": [[12, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_config", ":", "EnvConfig", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor\n\n        :param env_config: the environment configuration\n        \"\"\"", "\n", "self", ".", "env_config", "=", "env_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.attacker_obs_state.AttackerObservationState.get_attacker_observation": [[21, 38], ["numpy.zeros().tolist", "range", "numpy.array", "len", "int", "numpy.zeros", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "get_attacker_observation", "(", "self", ",", "nodes", ":", "List", "[", "Node", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Returns the attacker's observation\n\n        :param nodes: the list of node states\n        :return: the attacker's observation\n        \"\"\"", "\n", "obs", "=", "np", ".", "zeros", "(", "(", "self", ".", "env_config", ".", "num_nodes", ",", "self", ".", "env_config", ".", "num_attributes", "+", "2", ")", ")", ".", "tolist", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "nodes", ")", ")", ":", "\n", "            ", "if", "nodes", "[", "i", "]", ".", "recon_done", ":", "\n", "                ", "obs", "[", "i", "]", "[", "0", ":", "self", ".", "env_config", ".", "num_attributes", "]", "=", "(", "np", ".", "array", "(", "nodes", "[", "i", "]", ".", "attack_attributes", ")", "-", "np", ".", "array", "(", "nodes", "[", "i", "]", ".", "defense_attributes", ")", ")", ".", "tolist", "(", ")", "\n", "obs", "[", "i", "]", "[", "self", ".", "env_config", ".", "num_attributes", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "obs", "[", "i", "]", "[", "0", ":", "self", ".", "env_config", ".", "num_attributes", "]", "=", "nodes", "[", "i", "]", ".", "attack_attributes", "\n", "obs", "[", "i", "]", "[", "self", ".", "env_config", ".", "num_attributes", "]", "=", "0", "\n", "", "obs", "[", "i", "]", "[", "self", ".", "env_config", ".", "num_attributes", "+", "1", "]", "=", "int", "(", "nodes", "[", "i", "]", ".", "compromised", ")", "\n", "", "return", "np", ".", "array", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.defender_obs_state.DefenderObservationState.__init__": [[14, 33], ["gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f1_a", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f1_b", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f2_a", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.f2_b", "defender_obs_state.DefenderObservationState.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f1_a", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f1_b", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f2_a", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.f2_b", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["def", "__init__", "(", "self", ",", "env_config", ":", "EnvConfig", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the observation\n\n        :param env_config: the environment configuration\n        \"\"\"", "\n", "self", ".", "env_config", "=", "env_config", "\n", "self", ".", "num_alerts", "=", "0", "\n", "self", ".", "num_failed_logins", "=", "0", "\n", "self", ".", "num_severe_alerts", "=", "0", "\n", "self", ".", "num_warning_alerts", "=", "0", "\n", "self", ".", "num_alert_priority", "=", "0", "\n", "\n", "self", ".", "ttc", "=", "constants", ".", "DP", ".", "MAX_TTC", "-", "1", "\n", "self", ".", "f1_a", "=", "DefenderDynamics", ".", "f1_a", "(", ")", "\n", "self", ".", "f1_b", "=", "DefenderDynamics", ".", "f1_b", "(", ")", "\n", "self", ".", "f2_a", "=", "DefenderDynamics", ".", "f2_a", "(", ")", "\n", "self", ".", "f2_b", "=", "DefenderDynamics", ".", "f2_b", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.defender_obs_state.DefenderObservationState.reset": [[35, 47], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the observation\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "num_alerts", "=", "0", "\n", "self", ".", "num_failed_logins", "=", "0", "\n", "self", ".", "num_severe_alerts", "=", "0", "\n", "self", ".", "num_warning_alerts", "=", "0", "\n", "self", ".", "num_alert_priority", "=", "0", "\n", "self", ".", "ttc", "=", "constants", ".", "DP", ".", "MAX_TTC", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.defender_obs_state.DefenderObservationState.get_defender_observation": [[48, 73], ["numpy.array", "numpy.zeros().tolist", "numpy.zeros().tolist", "numpy.zeros().tolist", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "get_defender_observation", "(", "self", ",", "t", ":", "int", ",", "dp_setup", ":", "DPSetup", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Funciton for computing the defender observation\n\n        :param t: the time-step\n        :param dp_setup: the dp-parameters\n        :return: the observation\n        \"\"\"", "\n", "if", "not", "self", ".", "env_config", ".", "dp", "and", "not", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "obs", "=", "np", ".", "zeros", "(", "3", ")", ".", "tolist", "(", ")", "\n", "obs", "[", "0", "]", "=", "t", "\n", "obs", "[", "1", "]", "=", "self", ".", "num_alerts", "\n", "obs", "[", "2", "]", "=", "self", ".", "num_failed_logins", "\n", "", "elif", "self", ".", "env_config", ".", "dp", ":", "\n", "            ", "obs", "=", "np", ".", "zeros", "(", "2", ")", ".", "tolist", "(", ")", "\n", "obs", "[", "0", "]", "=", "t", "\n", "obs", "[", "1", "]", "=", "self", ".", "ttc", "\n", "", "else", ":", "\n", "            ", "obs", "=", "np", ".", "zeros", "(", "4", ")", ".", "tolist", "(", ")", "\n", "obs", "[", "0", "]", "=", "t", "\n", "obs", "[", "1", "]", "=", "self", ".", "num_severe_alerts", "\n", "obs", "[", "2", "]", "=", "self", ".", "num_warning_alerts", "\n", "obs", "[", "3", "]", "=", "self", ".", "num_failed_logins", "\n", "\n", "", "return", "np", ".", "array", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.defender_obs_state.DefenderObservationState.update_state": [[74, 151], ["int", "int", "int", "int", "min", "min", "numpy.random.choice", "round", "round", "round", "round", "defender_dynamics_model.machines_dynamics_model.items", "defender_dynamics_model.norm_num_new_severe_alerts[].rvs", "defender_dynamics_model.norm_num_new_warning_alerts[].rvs", "defender_dynamics_model.norm_num_new_priority[].rvs", "defender_obs_state.DefenderObservationState.f1_a.rvs", "defender_obs_state.DefenderObservationState.f2_a.rvs", "defender_obs_state.DefenderObservationState.f1_b.rvs", "defender_obs_state.DefenderObservationState.f2_b.rvs", "m_dynamics.norm_num_new_failed_login_attempts[].rvs"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "t", ":", "int", ",", "intrusion_in_progress", ":", "bool", "=", "False", ",", "dp_setup", ":", "DPSetup", "=", "None", ",", "\n", "attacker_action", ":", "int", "=", "None", ",", "defender_dynamics_model", ":", "DefenderDynamicsModel", "=", "None", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Function for updating the state\n\n        :param t: the current time-step\n        :param intrusion_in_progress: Boolean flag whether an intrusion is in progress or not\n        :param dp_setup: dp parameters\n        :param attacker_action: the attackker's latest action\n        :param defender_dynamics_model: the dynamics model\n        :return: True if done otherwise False\n        \"\"\"", "\n", "if", "not", "self", ".", "env_config", ".", "dp", "and", "not", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "if", "intrusion_in_progress", ":", "\n", "                ", "new_alerts", "=", "int", "(", "round", "(", "self", ".", "f1_a", ".", "rvs", "(", "size", "=", "1", ")", "[", "0", "]", ")", ")", "\n", "new_logins", "=", "int", "(", "round", "(", "self", ".", "f2_a", ".", "rvs", "(", "size", "=", "1", ")", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "new_alerts", "=", "int", "(", "round", "(", "self", ".", "f1_b", ".", "rvs", "(", "size", "=", "1", ")", "[", "0", "]", ")", ")", "\n", "new_logins", "=", "int", "(", "round", "(", "self", ".", "f2_b", ".", "rvs", "(", "size", "=", "1", ")", "[", "0", "]", ")", ")", "\n", "", "self", ".", "num_alerts", "=", "self", ".", "num_alerts", "+", "new_alerts", "\n", "self", ".", "num_failed_logins", "=", "self", ".", "num_failed_logins", "+", "new_logins", "\n", "if", "self", ".", "env_config", ".", "use_state_limits", ":", "\n", "                ", "self", ".", "num_alerts", "=", "min", "(", "constants", ".", "DP", ".", "MAX_ALERTS", ",", "self", ".", "num_alerts", ")", "\n", "self", ".", "num_failed_logins", "=", "min", "(", "constants", ".", "DP", ".", "MAX_LOGINS", ",", "self", ".", "num_failed_logins", ")", "\n", "", "", "elif", "self", ".", "env_config", ".", "dp", ":", "\n", "            ", "state", "=", "(", "t", ",", "self", ".", "ttc", ")", "\n", "state_id", "=", "dp_setup", ".", "state_to_id", "[", "state", "]", "\n", "next_state_id", "=", "np", ".", "random", ".", "choice", "(", "dp_setup", ".", "state_ids", ",", "p", "=", "dp_setup", ".", "T", "[", "state_id", "]", "[", "0", "]", ")", "\n", "next_state", "=", "dp_setup", ".", "id_to_state", "[", "next_state_id", "]", "\n", "done", "=", "False", "\n", "if", "next_state", "==", "\"terminal\"", ":", "\n", "                ", "done", "=", "True", "\n", "", "else", ":", "\n", "                ", "(", "t2", ",", "ttc2", ")", "=", "next_state", "\n", "# print(\"t1:{}, t2:{} old ttc:{}, new ttc:{}, state id:{}, new state id:{}, prob:{}\".format(t, t2,", "\n", "#     self.ttc, ttc2, state_id, next_state_id, dp_setup.T[state_id][0][next_state_id]))", "\n", "self", ".", "ttc", "=", "ttc2", "\n", "", "return", "done", "\n", "", "elif", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "num_new_alerts", "=", "0", "\n", "num_new_severe_alerts", "=", "0", "\n", "num_new_warning_alerts", "=", "0", "\n", "num_new_priority", "=", "0", "\n", "logged_in_ips_str", ",", "done", ",", "intrusion_in_progress", "=", "self", ".", "env_config", ".", "action_to_state", "[", "(", "attacker_action", ",", "t", ")", "]", "\n", "attacker_action_id", "=", "self", ".", "env_config", ".", "attack_idx_to_id", "[", "attacker_action", "]", "\n", "\n", "if", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "in", "defender_dynamics_model", ".", "norm_num_new_severe_alerts", ":", "\n", "                ", "num_new_severe_alerts", "=", "defender_dynamics_model", ".", "norm_num_new_severe_alerts", "[", "\n", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "]", ".", "rvs", "(", ")", "\n", "\n", "", "if", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "in", "defender_dynamics_model", ".", "norm_num_new_warning_alerts", ":", "\n", "                ", "num_new_warning_alerts", "=", "defender_dynamics_model", ".", "norm_num_new_warning_alerts", "[", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "]", ".", "rvs", "(", ")", "\n", "\n", "", "if", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "in", "defender_dynamics_model", ".", "norm_num_new_priority", ":", "\n", "                ", "num_new_priority", "=", "defender_dynamics_model", ".", "norm_num_new_priority", "[", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "]", ".", "rvs", "(", ")", "\n", "\n", "# num_new_alerts = num_new_severe_alerts + num_new_warning_alerts", "\n", "", "num_new_alerts", "=", "num_new_severe_alerts", "\n", "num_new_failed_login_attempts", "=", "0", "\n", "for", "k", ",", "v", "in", "defender_dynamics_model", ".", "machines_dynamics_model", ".", "items", "(", ")", ":", "\n", "                ", "ip", "=", "k", "\n", "m_dynamics", "=", "v", "\n", "if", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "in", "m_dynamics", ".", "norm_num_new_failed_login_attempts", ":", "\n", "                    ", "num_new_failed_login_attempts", "=", "m_dynamics", ".", "norm_num_new_failed_login_attempts", "[", "\n", "(", "attacker_action_id", ",", "logged_in_ips_str", ")", "]", ".", "rvs", "(", ")", "\n", "", "", "self", ".", "num_alerts", "=", "self", ".", "num_alerts", "+", "num_new_alerts", "\n", "self", ".", "num_severe_alerts", "=", "self", ".", "num_severe_alerts", "+", "num_new_severe_alerts", "\n", "self", ".", "num_warning_alerts", "=", "self", ".", "num_warning_alerts", "+", "num_new_warning_alerts", "\n", "self", ".", "num_failed_logins", "=", "self", ".", "num_failed_logins", "+", "num_new_failed_login_attempts", "\n", "self", ".", "num_alert_priority", "=", "self", ".", "num_alert_priority", "+", "num_new_priority", "\n", "return", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.obs.defender_obs_state.DefenderObservationState.probability_of_intrusion": [[154, 164], ["gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.ttc", "gym_optimal_intrusion_response.logic.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.ttc", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.defender_dynamics.DefenderDynamics.hack_prob"], ["", "", "def", "probability_of_intrusion", "(", "self", ",", "t", ":", "int", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Computes the probabability of an intrusion\n\n        :param t: the current time-step\n        :return: the probability of an intrusion\n        \"\"\"", "\n", "ttc", "=", "DefenderDynamics", ".", "ttc", "(", "self", ".", "num_alerts", ",", "self", ".", "num_failed_logins", ",", "constants", ".", "DP", ".", "MAX_ALERTS", ")", "\n", "hp", "=", "DefenderDynamics", ".", "hack_prob", "(", "ttc", ")", "\n", "return", "hp", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.rollout_data_dto.RolloutDataDTO.__init__": [[6, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "attacker_episode_rewards", "=", "None", ",", "defender_episode_rewards", "=", "None", ",", "episode_steps", "=", "None", ",", "\n", "episode_flags", "=", "None", ",", "episode_caught", "=", "None", ",", "episode_early_stopped", "=", "None", ",", "\n", "episode_successful_intrusion", "=", "None", ",", "episode_snort_severe_baseline_rewards", "=", "None", ",", "\n", "episode_snort_warning_baseline_rewards", "=", "None", ",", "\n", "episode_snort_critical_baseline_rewards", "=", "None", ",", "\n", "episode_var_log_baseline_rewards", "=", "None", ",", "\n", "episode_flags_percentage", "=", "None", ",", "\n", "attacker_env_specific_rewards", "=", "None", ",", "\n", "defender_env_specific_rewards", "=", "None", ",", "\n", "env_specific_steps", "=", "None", ",", "\n", "env_specific_flags", "=", "None", ",", "\n", "env_specific_flags_percentage", "=", "None", ",", "\n", "env_response_times", "=", "None", ",", "\n", "action_pred_times", "=", "None", ",", "\n", "attacker_action_costs", "=", "None", ",", "\n", "attacker_action_costs_norm", "=", "None", ",", "\n", "attacker_action_alerts", "=", "None", ",", "\n", "attacker_action_alerts_norm", "=", "None", ",", "\n", "optimal_steps", "=", "None", ",", "\n", "optimal_rewards", "=", "None", ",", "\n", "intrusion_steps", "=", "None", "\n", ")", ":", "\n", "        ", "self", ".", "attacker_episode_rewards", "=", "attacker_episode_rewards", "\n", "self", ".", "defender_episode_rewards", "=", "defender_episode_rewards", "\n", "self", ".", "episode_steps", "=", "episode_steps", "\n", "self", ".", "episode_flags", "=", "episode_flags", "\n", "self", ".", "episode_caught", "=", "episode_caught", "\n", "self", ".", "episode_early_stopped", "=", "episode_early_stopped", "\n", "self", ".", "episode_successful_intrusion", "=", "episode_successful_intrusion", "\n", "self", ".", "episode_snort_severe_baseline_rewards", "=", "episode_snort_severe_baseline_rewards", "\n", "self", ".", "episode_snort_warning_baseline_rewards", "=", "episode_snort_warning_baseline_rewards", "\n", "self", ".", "episode_snort_critical_baseline_rewards", "=", "episode_snort_critical_baseline_rewards", "\n", "self", ".", "episode_var_log_baseline_rewards", "=", "episode_var_log_baseline_rewards", "\n", "self", ".", "episode_flags_percentage", "=", "episode_flags_percentage", "\n", "self", ".", "attacker_env_specific_rewards", "=", "attacker_env_specific_rewards", "\n", "self", ".", "defender_env_specific_rewards", "=", "defender_env_specific_rewards", "\n", "self", ".", "env_specific_steps", "=", "env_specific_steps", "\n", "self", ".", "env_specific_flags", "=", "env_specific_flags", "\n", "self", ".", "env_specific_flags_percentage", "=", "env_specific_flags_percentage", "\n", "self", ".", "env_response_times", "=", "env_response_times", "\n", "self", ".", "action_pred_times", "=", "action_pred_times", "\n", "self", ".", "attacker_action_costs", "=", "attacker_action_costs", "\n", "self", ".", "attacker_action_costs_norm", "=", "attacker_action_costs_norm", "\n", "self", ".", "attacker_action_alerts", "=", "attacker_action_alerts", "\n", "self", ".", "attacker_action_alerts_norm", "=", "attacker_action_alerts_norm", "\n", "self", ".", "optimal_steps", "=", "optimal_steps", "\n", "self", ".", "optimal_rewards", "=", "optimal_rewards", "\n", "self", ".", "intrusion_steps", "=", "intrusion_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.rollout_data_dto.RolloutDataDTO.initialize": [[55, 83], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "attacker_episode_rewards", "=", "[", "]", "\n", "self", ".", "attacker_episode_rewards", "=", "[", "]", "\n", "self", ".", "defender_episode_rewards", "=", "[", "]", "\n", "self", ".", "episode_steps", "=", "[", "]", "\n", "self", ".", "episode_flags", "=", "[", "]", "\n", "self", ".", "episode_caught", "=", "[", "]", "\n", "self", ".", "episode_early_stopped", "=", "[", "]", "\n", "self", ".", "episode_successful_intrusion", "=", "[", "]", "\n", "self", ".", "episode_snort_severe_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_snort_warning_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_snort_critical_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_var_log_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_flags_percentage", "=", "[", "]", "\n", "self", ".", "attacker_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "defender_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "env_specific_steps", "=", "{", "}", "\n", "self", ".", "env_specific_flags", "=", "{", "}", "\n", "self", ".", "env_specific_flags_percentage", "=", "{", "}", "\n", "self", ".", "env_response_times", "=", "[", "]", "\n", "self", ".", "action_pred_times", "=", "[", "]", "\n", "self", ".", "attacker_action_costs", "=", "[", "]", "\n", "self", ".", "attacker_action_costs_norm", "=", "[", "]", "\n", "self", ".", "attacker_action_alerts", "=", "[", "]", "\n", "self", ".", "attacker_action_alerts_norm", "=", "[", "]", "\n", "self", ".", "optimal_steps", "=", "[", "]", "\n", "self", ".", "optimal_rewards", "=", "[", "]", "\n", "self", ".", "intrusion_steps", "=", "[", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.__init__": [[9, 167], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iteration", ":", "int", "=", "0", ",", "train_result", ":", "ExperimentResult", "=", "None", ",", "eval_result", ":", "ExperimentResult", "=", "None", ",", "\n", "attacker_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_episode_avg_loss", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_lr", ":", "float", "=", "0.0", ",", "\n", "defender_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "defender_episode_avg_loss", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "defender_lr", ":", "float", "=", "0.0", ",", "\n", "total_num_episodes", ":", "int", "=", "1", ",", "\n", "episode_steps", ":", "List", "[", "int", "]", "=", "None", ",", "episode_flags", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval", ":", "bool", "=", "False", ",", "episode_flags_percentage", ":", "List", "[", "float", "]", "=", "None", ",", "progress_left", ":", "float", "=", "0.0", ",", "\n", "n_af", ":", "int", "=", "0", ",", "n_d", ":", "int", "=", "0", ",", "\n", "attacker_eval_episode_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "defender_eval_episode_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_steps", ":", "List", "[", "int", "]", "=", "None", ",", "eval_episode_flags", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_flags_percentage", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_eval_2_episode_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "defender_eval_2_episode_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_steps", ":", "List", "[", "int", "]", "=", "None", ",", "eval_2_episode_flags", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_flags_percentage", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_train_episode_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "defender_train_episode_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "train_env_specific_steps", ":", "dict", "=", "None", ",", "\n", "train_env_specific_flags", ":", "dict", "=", "None", ",", "\n", "train_env_specific_flags_percentage", ":", "dict", "=", "None", ",", "\n", "attacker_eval_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "defender_eval_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "eval_env_specific_steps", ":", "dict", "=", "None", ",", "\n", "eval_env_specific_flags", ":", "dict", "=", "None", ",", "\n", "eval_env_specific_flags_percentage", ":", "dict", "=", "None", ",", "\n", "attacker_eval_2_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "defender_eval_2_env_specific_rewards", ":", "dict", "=", "None", ",", "\n", "eval_2_env_specific_steps", ":", "dict", "=", "None", ",", "\n", "eval_2_env_specific_flags", ":", "dict", "=", "None", ",", "\n", "eval_2_env_specific_flags_percentage", ":", "dict", "=", "None", ",", "\n", "rollout_times", ":", "List", "[", "float", "]", "=", "None", ",", "env_response_times", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "action_pred_times", ":", "List", "[", "float", "]", "=", "None", ",", "grad_comp_times", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "weight_update_times", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "episode_caught", ":", "List", "[", "int", "]", "=", "None", ",", "episode_early_stopped", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "episode_successful_intrusion", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_caught", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_early_stopped", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_successful_intrusion", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_caught", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_early_stopped", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_successful_intrusion", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "episode_snort_severe_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "episode_snort_warning_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_snort_severe_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_snort_warning_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_snort_severe_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_snort_warning_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "episode_snort_critical_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "episode_var_log_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_snort_critical_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_episode_var_log_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_snort_critical_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "eval_2_episode_var_log_baseline_rewards", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "attacker_action_costs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_action_costs_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_action_alerts", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_action_alerts_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_costs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_costs_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_alerts", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_attacker_action_alerts_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_costs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_costs_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_alerts", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "eval_2_attacker_action_alerts_norm", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "start_time", ":", "float", "=", "0.0", ",", "\n", "optimal_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "optimal_steps", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "intrusion_steps", ":", "List", "[", "float", "]", "=", "None", "\n", ")", ":", "\n", "        ", "self", ".", "iteration", "=", "iteration", "\n", "self", ".", "train_result", "=", "train_result", "\n", "self", ".", "eval_result", "=", "eval_result", "\n", "self", ".", "attacker_episode_rewards", "=", "attacker_episode_rewards", "\n", "self", ".", "attacker_episode_avg_loss", "=", "attacker_episode_avg_loss", "\n", "self", ".", "attacker_lr", "=", "attacker_lr", "\n", "self", ".", "defender_episode_rewards", "=", "defender_episode_rewards", "\n", "self", ".", "defender_episode_avg_loss", "=", "defender_episode_avg_loss", "\n", "self", ".", "defender_lr", "=", "defender_lr", "\n", "self", ".", "total_num_episodes", "=", "total_num_episodes", "\n", "self", ".", "episode_steps", "=", "episode_steps", "\n", "self", ".", "episode_flags", "=", "episode_flags", "\n", "self", ".", "eval", "=", "eval", "\n", "self", ".", "episode_flags_percentage", "=", "episode_flags_percentage", "\n", "self", ".", "progress_left", "=", "progress_left", "\n", "self", ".", "n_af", "=", "n_af", "\n", "self", ".", "n_d", "=", "n_d", "\n", "self", ".", "attacker_eval_episode_rewards", "=", "attacker_eval_episode_rewards", "\n", "self", ".", "defender_eval_episode_rewards", "=", "defender_eval_episode_rewards", "\n", "self", ".", "eval_episode_steps", "=", "eval_episode_steps", "\n", "self", ".", "eval_episode_flags", "=", "eval_episode_flags", "\n", "self", ".", "eval_episode_flags_percentage", "=", "eval_episode_flags_percentage", "\n", "self", ".", "attacker_eval_2_episode_rewards", "=", "attacker_eval_2_episode_rewards", "\n", "self", ".", "defender_eval_2_episode_rewards", "=", "defender_eval_2_episode_rewards", "\n", "self", ".", "eval_2_episode_steps", "=", "eval_2_episode_steps", "\n", "self", ".", "eval_2_episode_flags", "=", "eval_2_episode_flags", "\n", "self", ".", "eval_2_episode_flags_percentage", "=", "eval_2_episode_flags_percentage", "\n", "self", ".", "attacker_train_episode_env_specific_rewards", "=", "attacker_train_episode_env_specific_rewards", "\n", "self", ".", "defender_train_episode_env_specific_rewards", "=", "defender_train_episode_env_specific_rewards", "\n", "self", ".", "train_env_specific_steps", "=", "train_env_specific_steps", "\n", "self", ".", "train_env_specific_flags", "=", "train_env_specific_flags", "\n", "self", ".", "train_env_specific_flags_percentage", "=", "train_env_specific_flags_percentage", "\n", "self", ".", "attacker_eval_env_specific_rewards", "=", "attacker_eval_env_specific_rewards", "\n", "self", ".", "defender_eval_env_specific_rewards", "=", "defender_eval_env_specific_rewards", "\n", "self", ".", "eval_env_specific_steps", "=", "eval_env_specific_steps", "\n", "self", ".", "eval_env_specific_flags", "=", "eval_env_specific_flags", "\n", "self", ".", "eval_env_specific_flags_percentage", "=", "eval_env_specific_flags_percentage", "\n", "self", ".", "attacker_eval_2_env_specific_rewards", "=", "attacker_eval_2_env_specific_rewards", "\n", "self", ".", "defender_eval_2_env_specific_rewards", "=", "defender_eval_2_env_specific_rewards", "\n", "self", ".", "eval_2_env_specific_steps", "=", "eval_2_env_specific_steps", "\n", "self", ".", "eval_2_env_specific_flags", "=", "eval_2_env_specific_flags", "\n", "self", ".", "eval_2_env_specific_flags_percentage", "=", "eval_2_env_specific_flags_percentage", "\n", "self", ".", "rollout_times", "=", "rollout_times", "\n", "self", ".", "env_response_times", "=", "env_response_times", "\n", "self", ".", "action_pred_times", "=", "action_pred_times", "\n", "self", ".", "grad_comp_times", "=", "grad_comp_times", "\n", "self", ".", "weight_update_times", "=", "weight_update_times", "\n", "self", ".", "episode_caught", "=", "episode_caught", "\n", "self", ".", "episode_early_stopped", "=", "episode_early_stopped", "\n", "self", ".", "episode_successful_intrusion", "=", "episode_successful_intrusion", "\n", "self", ".", "eval_episode_caught", "=", "eval_episode_caught", "\n", "self", ".", "eval_episode_early_stopped", "=", "eval_episode_early_stopped", "\n", "self", ".", "eval_episode_successful_intrusion", "=", "eval_episode_successful_intrusion", "\n", "self", ".", "eval_2_episode_caught", "=", "eval_2_episode_caught", "\n", "self", ".", "eval_2_episode_early_stopped", "=", "eval_2_episode_early_stopped", "\n", "self", ".", "eval_2_episode_successful_intrusion", "=", "eval_2_episode_successful_intrusion", "\n", "self", ".", "episode_snort_severe_baseline_rewards", "=", "episode_snort_severe_baseline_rewards", "\n", "self", ".", "episode_snort_warning_baseline_rewards", "=", "episode_snort_warning_baseline_rewards", "\n", "self", ".", "eval_episode_snort_severe_baseline_rewards", "=", "eval_episode_snort_severe_baseline_rewards", "\n", "self", ".", "eval_episode_snort_warning_baseline_rewards", "=", "eval_episode_snort_warning_baseline_rewards", "\n", "self", ".", "eval_2_episode_snort_severe_baseline_rewards", "=", "eval_2_episode_snort_severe_baseline_rewards", "\n", "self", ".", "eval_2_episode_snort_warning_baseline_rewards", "=", "eval_2_episode_snort_warning_baseline_rewards", "\n", "self", ".", "episode_snort_critical_baseline_rewards", "=", "episode_snort_critical_baseline_rewards", "\n", "self", ".", "episode_var_log_baseline_rewards", "=", "episode_var_log_baseline_rewards", "\n", "self", ".", "eval_episode_snort_critical_baseline_rewards", "=", "eval_episode_snort_critical_baseline_rewards", "\n", "self", ".", "eval_episode_var_log_baseline_rewards", "=", "eval_episode_var_log_baseline_rewards", "\n", "self", ".", "eval_2_episode_var_log_baseline_rewards", "=", "eval_2_episode_var_log_baseline_rewards", "\n", "self", ".", "eval_2_episode_snort_critical_baseline_rewards", "=", "eval_2_episode_snort_critical_baseline_rewards", "\n", "self", ".", "attacker_action_costs", "=", "attacker_action_costs", "\n", "self", ".", "attacker_action_costs_norm", "=", "attacker_action_costs_norm", "\n", "self", ".", "attacker_action_alerts", "=", "attacker_action_alerts", "\n", "self", ".", "attacker_action_alerts_norm", "=", "attacker_action_alerts_norm", "\n", "self", ".", "eval_attacker_action_costs", "=", "eval_attacker_action_costs", "\n", "self", ".", "eval_attacker_action_costs_norm", "=", "eval_attacker_action_costs_norm", "\n", "self", ".", "eval_attacker_action_alerts", "=", "eval_attacker_action_alerts", "\n", "self", ".", "eval_attacker_action_alerts_norm", "=", "eval_attacker_action_alerts_norm", "\n", "self", ".", "eval_2_attacker_action_costs", "=", "eval_2_attacker_action_costs", "\n", "self", ".", "eval_2_attacker_action_costs_norm", "=", "eval_2_attacker_action_costs_norm", "\n", "self", ".", "eval_2_attacker_action_alerts", "=", "eval_2_attacker_action_alerts", "\n", "self", ".", "eval_2_attacker_action_alerts_norm", "=", "eval_2_attacker_action_alerts_norm", "\n", "self", ".", "start_time", "=", "start_time", "\n", "self", ".", "optimal_rewards", "=", "optimal_rewards", "\n", "self", ".", "optimal_steps", "=", "optimal_steps", "\n", "self", ".", "intrusion_steps", "=", "intrusion_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.initialize": [[169, 258], ["gym_optimal_intrusion_response.dao.experiment.experiment_result.ExperimentResult", "gym_optimal_intrusion_response.dao.experiment.experiment_result.ExperimentResult"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "0.0", "\n", "self", ".", "iteration", "=", "0", "\n", "self", ".", "train_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "attacker_episode_rewards", "=", "[", "]", "\n", "self", ".", "attacker_episode_avg_loss", "=", "[", "]", "\n", "self", ".", "attacker_lr", "=", "0.0", "\n", "self", ".", "defender_episode_rewards", "=", "[", "]", "\n", "self", ".", "defender_episode_avg_loss", "=", "[", "]", "\n", "self", ".", "defender_lr", "=", "0.0", "\n", "self", ".", "total_num_episodes", "=", "1", "\n", "self", ".", "episode_steps", "=", "[", "]", "\n", "self", ".", "episode_flags", "=", "[", "]", "\n", "self", ".", "eval", "=", "False", "\n", "self", ".", "episode_flags_percentage", "=", "[", "]", "\n", "self", ".", "progress_left", "=", "0.0", "\n", "self", ".", "n_af", "=", "0", "\n", "self", ".", "n_d", "=", "0", "\n", "self", ".", "attacker_eval_episode_rewards", "=", "[", "]", "\n", "self", ".", "defender_eval_episode_rewards", "=", "[", "]", "\n", "self", ".", "eval_episode_steps", "=", "[", "]", "\n", "self", ".", "eval_episode_flags", "=", "[", "]", "\n", "self", ".", "eval_episode_flags_percentage", "=", "[", "]", "\n", "self", ".", "attacker_eval_2_episode_rewards", "=", "[", "]", "\n", "self", ".", "defender_eval_2_episode_rewards", "=", "[", "]", "\n", "self", ".", "eval_2_episode_steps", "=", "[", "]", "\n", "self", ".", "eval_2_episode_flags", "=", "[", "]", "\n", "self", ".", "eval_2_episode_flags_percentage", "=", "[", "]", "\n", "self", ".", "attacker_train_episode_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "defender_train_episode_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "train_env_specific_steps", "=", "{", "}", "\n", "self", ".", "train_env_specific_flags", "=", "{", "}", "\n", "self", ".", "train_env_specific_flags_percentage", "=", "{", "}", "\n", "self", ".", "attacker_eval_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "defender_eval_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "eval_env_specific_steps", "=", "{", "}", "\n", "self", ".", "eval_env_specific_flags", "=", "{", "}", "\n", "self", ".", "eval_env_specific_flags_percentage", "=", "{", "}", "\n", "self", ".", "attacker_eval_2_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "defender_eval_2_env_specific_rewards", "=", "{", "}", "\n", "self", ".", "eval_2_env_specific_steps", "=", "{", "}", "\n", "self", ".", "eval_2_env_specific_flags", "=", "{", "}", "\n", "self", ".", "eval_2_env_specific_flags_percentage", "=", "{", "}", "\n", "self", ".", "rollout_times", "=", "[", "]", "\n", "self", ".", "env_response_times", "=", "[", "]", "\n", "self", ".", "action_pred_times", "=", "[", "]", "\n", "self", ".", "grad_comp_times", "=", "[", "]", "\n", "self", ".", "weight_update_times", "=", "[", "]", "\n", "self", ".", "episode_caught", "=", "[", "]", "\n", "self", ".", "episode_early_stopped", "=", "[", "]", "\n", "self", ".", "episode_successful_intrusion", "=", "[", "]", "\n", "self", ".", "eval_episode_caught", "=", "[", "]", "\n", "self", ".", "eval_episode_early_stopped", "=", "[", "]", "\n", "self", ".", "eval_episode_successful_intrusion", "=", "[", "]", "\n", "self", ".", "eval_2_episode_caught", "=", "[", "]", "\n", "self", ".", "eval_2_episode_early_stopped", "=", "[", "]", "\n", "self", ".", "eval_2_episode_successful_intrusion", "=", "[", "]", "\n", "self", ".", "snort_severe_baseline_rewards", "=", "[", "]", "\n", "self", ".", "snort_warning_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_snort_severe_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_snort_warning_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_2_episode_snort_severe_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_2_episode_snort_warning_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_snort_critical_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_var_log_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_episode_snort_critical_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_episode_var_log_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_2_episode_snort_critical_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_2_episode_var_log_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_snort_warning_baseline_rewards", "=", "[", "]", "\n", "self", ".", "episode_snort_severe_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_episode_snort_severe_baseline_rewards", "=", "[", "]", "\n", "self", ".", "eval_episode_snort_warning_baseline_rewards", "=", "[", "]", "\n", "self", ".", "attacker_action_costs", "=", "[", "]", "\n", "self", ".", "attacker_action_costs_norm", "=", "[", "]", "\n", "self", ".", "attacker_action_alerts", "=", "[", "]", "\n", "self", ".", "attacker_action_alerts_norm", "=", "[", "]", "\n", "self", ".", "eval_attacker_action_costs", "=", "[", "]", "\n", "self", ".", "eval_attacker_action_costs_norm", "=", "[", "]", "\n", "self", ".", "eval_attacker_action_alerts", "=", "[", "]", "\n", "self", ".", "eval_attacker_action_alerts_norm", "=", "[", "]", "\n", "self", ".", "eval_2_attacker_action_costs", "=", "[", "]", "\n", "self", ".", "eval_2_attacker_action_costs_norm", "=", "[", "]", "\n", "self", ".", "eval_2_attacker_action_alerts", "=", "[", "]", "\n", "self", ".", "eval_2_attacker_action_alerts_norm", "=", "[", "]", "\n", "self", ".", "optimal_steps", "=", "[", "]", "\n", "self", ".", "optimal_rewards", "=", "[", "]", "\n", "self", ".", "intrusion_steps", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy": [[259, 345], ["train_agent_log_dto.TrainAgentLogDTO"], "methods", ["None"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "c", "=", "TrainAgentLogDTO", "(", ")", "\n", "c", ".", "iteration", "=", "self", ".", "iteration", "\n", "c", ".", "train_result", "=", "self", ".", "train_result", "\n", "c", ".", "eval_result", "=", "self", ".", "eval_result", "\n", "c", ".", "attacker_episode_rewards", "=", "self", ".", "attacker_episode_rewards", "\n", "c", ".", "attacker_episode_avg_loss", "=", "self", ".", "attacker_episode_avg_loss", "\n", "c", ".", "attacker_lr", "=", "self", ".", "attacker_lr", "\n", "c", ".", "defender_episode_rewards", "=", "self", ".", "defender_episode_rewards", "\n", "c", ".", "defender_episode_avg_loss", "=", "self", ".", "defender_episode_avg_loss", "\n", "c", ".", "defender_lr", "=", "self", ".", "defender_lr", "\n", "c", ".", "total_num_episodes", "=", "self", ".", "total_num_episodes", "\n", "c", ".", "episode_steps", "=", "self", ".", "episode_steps", "\n", "c", ".", "episode_flags", "=", "self", ".", "episode_flags", "\n", "c", ".", "eval", "=", "self", ".", "eval", "\n", "c", ".", "episode_flags_percentage", "=", "self", ".", "episode_flags_percentage", "\n", "c", ".", "progress_left", "=", "self", ".", "progress_left", "\n", "c", ".", "n_af", "=", "self", ".", "n_af", "\n", "c", ".", "n_d", "=", "self", ".", "n_d", "\n", "c", ".", "attacker_eval_episode_rewards", "=", "self", ".", "attacker_eval_episode_rewards", "\n", "c", ".", "defender_eval_episode_rewards", "=", "self", ".", "defender_eval_episode_rewards", "\n", "c", ".", "eval_episode_steps", "=", "self", ".", "eval_episode_steps", "\n", "c", ".", "eval_episode_flags", "=", "self", ".", "eval_episode_flags", "\n", "c", ".", "eval_episode_flags_percentage", "=", "self", ".", "eval_episode_flags_percentage", "\n", "c", ".", "attacker_eval_2_episode_rewards", "=", "self", ".", "attacker_eval_2_episode_rewards", "\n", "c", ".", "defender_eval_2_episode_rewards", "=", "self", ".", "defender_eval_2_episode_rewards", "\n", "c", ".", "eval_2_episode_steps", "=", "self", ".", "eval_2_episode_steps", "\n", "c", ".", "eval_2_episode_flags", "=", "self", ".", "eval_2_episode_flags", "\n", "c", ".", "eval_2_episode_flags_percentage", "=", "self", ".", "eval_2_episode_flags_percentage", "\n", "c", ".", "attacker_train_episode_env_specific_rewards", "=", "self", ".", "attacker_train_episode_env_specific_rewards", "\n", "c", ".", "defender_train_episode_env_specific_rewards", "=", "self", ".", "defender_train_episode_env_specific_rewards", "\n", "c", ".", "train_env_specific_steps", "=", "self", ".", "train_env_specific_steps", "\n", "c", ".", "train_env_specific_flags", "=", "self", ".", "train_env_specific_flags", "\n", "c", ".", "train_env_specific_flags_percentage", "=", "self", ".", "train_env_specific_flags_percentage", "\n", "c", ".", "attacker_eval_env_specific_rewards", "=", "self", ".", "attacker_eval_env_specific_rewards", "\n", "c", ".", "defender_eval_env_specific_rewards", "=", "self", ".", "defender_eval_env_specific_rewards", "\n", "c", ".", "eval_env_specific_steps", "=", "self", ".", "eval_env_specific_steps", "\n", "c", ".", "eval_env_specific_flags", "=", "self", ".", "eval_env_specific_flags", "\n", "c", ".", "eval_env_specific_flags_percentage", "=", "self", ".", "eval_env_specific_flags_percentage", "\n", "c", ".", "attacker_eval_2_env_specific_rewards", "=", "self", ".", "attacker_eval_2_env_specific_rewards", "\n", "c", ".", "defender_eval_2_env_specific_rewards", "=", "self", ".", "defender_eval_2_env_specific_rewards", "\n", "c", ".", "eval_2_env_specific_steps", "=", "self", ".", "eval_2_env_specific_steps", "\n", "c", ".", "eval_2_env_specific_flags", "=", "self", ".", "eval_2_env_specific_flags", "\n", "c", ".", "eval_2_env_specific_flags_percentage", "=", "self", ".", "eval_2_env_specific_flags_percentage", "\n", "c", ".", "rollout_times", "=", "self", ".", "rollout_times", "\n", "c", ".", "env_response_times", "=", "self", ".", "env_response_times", "\n", "c", ".", "action_pred_times", "=", "self", ".", "action_pred_times", "\n", "c", ".", "grad_comp_times", "=", "self", ".", "grad_comp_times", "\n", "c", ".", "weight_update_times", "=", "self", ".", "weight_update_times", "\n", "c", ".", "episode_caught", "=", "self", ".", "episode_caught", "\n", "c", ".", "episode_early_stopped", "=", "self", ".", "episode_early_stopped", "\n", "c", ".", "episode_successful_intrusion", "=", "self", ".", "episode_successful_intrusion", "\n", "c", ".", "eval_episode_caught", "=", "self", ".", "eval_episode_caught", "\n", "c", ".", "eval_episode_early_stopped", "=", "self", ".", "eval_episode_early_stopped", "\n", "c", ".", "eval_episode_successful_intrusion", "=", "self", ".", "eval_episode_successful_intrusion", "\n", "c", ".", "eval_2_episode_caught", "=", "self", ".", "eval_2_episode_caught", "\n", "c", ".", "eval_2_episode_early_stopped", "=", "self", ".", "eval_2_episode_early_stopped", "\n", "c", ".", "eval_2_episode_successful_intrusion", "=", "self", ".", "eval_2_episode_successful_intrusion", "\n", "c", ".", "episode_snort_severe_baseline_rewards", "=", "self", ".", "episode_snort_severe_baseline_rewards", "\n", "c", ".", "episode_snort_warning_baseline_rewards", "=", "self", ".", "episode_snort_warning_baseline_rewards", "\n", "c", ".", "eval_episode_snort_severe_baseline_rewards", "=", "self", ".", "eval_episode_snort_severe_baseline_rewards", "\n", "c", ".", "eval_episode_snort_warning_baseline_rewards", "=", "self", ".", "eval_episode_snort_warning_baseline_rewards", "\n", "c", ".", "eval_2_episode_snort_severe_baseline_rewards", "=", "self", ".", "eval_2_episode_snort_severe_baseline_rewards", "\n", "c", ".", "eval_2_episode_snort_warning_baseline_rewards", "=", "self", ".", "eval_2_episode_snort_warning_baseline_rewards", "\n", "c", ".", "episode_snort_critical_baseline_rewards", "=", "self", ".", "episode_snort_critical_baseline_rewards", "\n", "c", ".", "episode_var_log_baseline_rewards", "=", "self", ".", "episode_var_log_baseline_rewards", "\n", "c", ".", "eval_episode_snort_critical_baseline_rewards", "=", "self", ".", "eval_episode_snort_critical_baseline_rewards", "\n", "c", ".", "eval_episode_var_log_baseline_rewards", "=", "self", ".", "eval_episode_var_log_baseline_rewards", "\n", "c", ".", "eval_2_episode_var_log_baseline_rewards", "=", "self", ".", "eval_2_episode_var_log_baseline_rewards", "\n", "c", ".", "eval_2_episode_snort_critical_baseline_rewards", "=", "self", ".", "eval_2_episode_snort_critical_baseline_rewards", "\n", "c", ".", "attacker_action_costs", "=", "self", ".", "attacker_action_costs", "\n", "c", ".", "attacker_action_costs_norm", "=", "self", ".", "attacker_action_costs_norm", "\n", "c", ".", "attacker_action_alerts", "=", "self", ".", "attacker_action_alerts", "\n", "c", ".", "attacker_action_alerts_norm", "=", "self", ".", "attacker_action_alerts_norm", "\n", "c", ".", "eval_attacker_action_costs", "=", "self", ".", "eval_attacker_action_costs", "\n", "c", ".", "eval_attacker_action_costs_norm", "=", "self", ".", "eval_attacker_action_costs_norm", "\n", "c", ".", "eval_attacker_action_alerts", "=", "self", ".", "eval_attacker_action_alerts", "\n", "c", ".", "eval_attacker_action_alerts_norm", "=", "self", ".", "eval_attacker_action_alerts_norm", "\n", "c", ".", "eval_2_attacker_action_costs", "=", "self", ".", "eval_2_attacker_action_costs", "\n", "c", ".", "eval_2_attacker_action_costs_norm", "=", "self", ".", "eval_2_attacker_action_costs_norm", "\n", "c", ".", "eval_2_attacker_action_alerts", "=", "self", ".", "eval_2_attacker_action_alerts", "\n", "c", ".", "eval_2_attacker_action_alerts_norm", "=", "self", ".", "eval_2_attacker_action_alerts_norm", "\n", "c", ".", "start_time", "=", "self", ".", "start_time", "\n", "c", ".", "optimal_steps", "=", "self", ".", "optimal_steps", "\n", "c", ".", "optimal_rewards", "=", "self", ".", "optimal_rewards", "\n", "c", ".", "intrusion_steps", "=", "self", ".", "intrusion_steps", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.__init__": [[6, 93], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iteration", ":", "int", "=", "0", ",", "avg_episode_rewards", ":", "float", "=", "0.0", ",", "\n", "avg_episode_steps", ":", "float", "=", "0.0", ",", "\n", "avg_episode_loss", ":", "float", "=", "0.0", ",", "eps", ":", "float", "=", "0.0", ",", "\n", "lr", ":", "float", "=", "0.0", ",", "eval", ":", "bool", "=", "False", ",", "\n", "avg_flags_catched", ":", "float", "=", "0.0", ",", "avg_episode_flags_percentage", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_rewards", ":", "float", "=", "0.0", ",", "eval_avg_episode_steps", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_flags", ":", "float", "=", "0.0", ",", "eval_avg_episode_flags_percentage", ":", "float", "=", "0.0", ",", "\n", "rolling_avg_episode_rewards", ":", "float", "=", "0.0", ",", "rolling_avg_episode_steps", ":", "float", "=", "0.0", ",", "\n", "tensorboard_writer", "=", "None", ",", "episode_caught_frac", ":", "float", "=", "0.0", ",", "\n", "episode_early_stopped_frac", ":", "float", "=", "0.0", ",", "episode_successful_intrusion_frac", ":", "float", "=", "0.0", ",", "\n", "eval_episode_caught_frac", ":", "float", "=", "0.0", ",", "eval_episode_early_stopped_frac", ":", "float", "=", "0.0", ",", "\n", "eval_episode_successful_intrusion_frac", ":", "float", "=", "0.0", ",", "\n", "avg_regret", ":", "float", "=", "0.0", ",", "avg_opt_frac", ":", "float", "=", "0.0", ",", "rolling_avg_rewards", ":", "float", "=", "0.0", ",", "\n", "rolling_avg_steps", ":", "float", "=", "0.0", ",", "avg_episode_flags", ":", "float", "=", "0.0", ",", "n_af", ":", "int", "=", "0", ",", "\n", "n_d", ":", "int", "=", "0", ",", "\n", "avg_episode_costs", ":", "float", "=", "0.0", ",", "avg_episode_costs_norm", ":", "float", "=", "0.0", ",", "\n", "avg_episode_alerts", ":", "float", "=", "0.0", ",", "avg_episode_alerts_norm", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_costs", ":", "float", "=", "0.0", ",", "eval_avg_episode_costs_norm", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_alerts", ":", "float", "=", "0.0", ",", "eval_avg_episode_alerts_norm", ":", "float", "=", "0.0", ",", "\n", "total_num_episodes", ":", "int", "=", "0", ",", "avg_eval_regret", ":", "float", "=", "0.0", ",", "\n", "eval_avg_opt_frac", ":", "float", "=", "0.0", ",", "\n", "epsilon", ":", "float", "=", "0.0", ",", "training_time_hours", ":", "float", "=", "0.0", ",", "\n", "avg_episode_snort_severe_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "avg_episode_snort_warning_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_snort_severe_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_snort_warning_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "avg_episode_snort_critical_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "avg_episode_var_log_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_snort_critical_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "eval_avg_episode_var_log_baseline_rewards", ":", "float", "=", "0.0", ",", "\n", "avg_optimal_steps", ":", "float", "=", "0.0", ",", "\n", "avg_optimal_reward", ":", "float", "=", "0.0", ",", "\n", "avg_intrusion_steps", ":", "float", "=", "0.0", "\n", ")", ":", "\n", "        ", "self", ".", "iteration", "=", "iteration", "\n", "self", ".", "avg_episode_rewards", "=", "avg_episode_rewards", "\n", "self", ".", "avg_episode_steps", "=", "avg_episode_steps", "\n", "self", ".", "avg_episode_loss", "=", "avg_episode_loss", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "eval", "=", "eval", "\n", "self", ".", "avg_flags_catched", "=", "avg_flags_catched", "\n", "self", ".", "avg_episode_flags_percentage", "=", "avg_episode_flags_percentage", "\n", "self", ".", "eval_avg_episode_rewards", "=", "eval_avg_episode_rewards", "\n", "self", ".", "eval_avg_episode_steps", "=", "eval_avg_episode_steps", "\n", "self", ".", "eval_avg_episode_flags", "=", "eval_avg_episode_flags", "\n", "self", ".", "eval_avg_episode_flags_percentage", "=", "eval_avg_episode_flags_percentage", "\n", "self", ".", "rolling_avg_episode_rewards", "=", "rolling_avg_episode_rewards", "\n", "self", ".", "rolling_avg_episode_steps", "=", "rolling_avg_episode_steps", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "self", ".", "episode_caught_frac", "=", "episode_caught_frac", "\n", "self", ".", "episode_early_stopped_frac", "=", "episode_early_stopped_frac", "\n", "self", ".", "episode_successful_intrusion_frac", "=", "episode_successful_intrusion_frac", "\n", "self", ".", "eval_episode_caught_frac", "=", "eval_episode_caught_frac", "\n", "self", ".", "eval_episode_early_stopped_frac", "=", "eval_episode_early_stopped_frac", "\n", "self", ".", "eval_episode_successful_intrusion_frac", "=", "eval_episode_successful_intrusion_frac", "\n", "self", ".", "avg_regret", "=", "avg_regret", "\n", "self", ".", "avg_opt_frac", "=", "avg_opt_frac", "\n", "self", ".", "rolling_avg_rewards", "=", "rolling_avg_rewards", "\n", "self", ".", "rolling_avg_steps", "=", "rolling_avg_steps", "\n", "self", ".", "avg_episode_flags", "=", "avg_episode_flags", "\n", "self", ".", "n_af", "=", "n_af", "\n", "self", ".", "n_d", "=", "n_d", "\n", "self", ".", "avg_episode_costs", "=", "avg_episode_costs", "\n", "self", ".", "avg_episode_costs_norm", "=", "avg_episode_costs_norm", "\n", "self", ".", "avg_episode_alerts", "=", "avg_episode_alerts", "\n", "self", ".", "avg_episode_alerts_norm", "=", "avg_episode_alerts_norm", "\n", "self", ".", "eval_avg_episode_costs", "=", "eval_avg_episode_costs", "\n", "self", ".", "eval_avg_episode_costs_norm", "=", "eval_avg_episode_costs_norm", "\n", "self", ".", "eval_avg_episode_alerts", "=", "eval_avg_episode_alerts", "\n", "self", ".", "eval_avg_episode_alerts_norm", "=", "eval_avg_episode_alerts_norm", "\n", "self", ".", "total_num_episodes", "=", "total_num_episodes", "\n", "self", ".", "avg_eval_regret", "=", "avg_eval_regret", "\n", "self", ".", "eval_avg_opt_frac", "=", "eval_avg_opt_frac", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "training_time_hours", "=", "training_time_hours", "\n", "self", ".", "avg_episode_snort_severe_baseline_rewards", "=", "avg_episode_snort_severe_baseline_rewards", "\n", "self", ".", "avg_episode_snort_warning_baseline_rewards", "=", "avg_episode_snort_warning_baseline_rewards", "\n", "self", ".", "eval_avg_episode_snort_severe_baseline_rewards", "=", "eval_avg_episode_snort_severe_baseline_rewards", "\n", "self", ".", "eval_avg_episode_snort_warning_baseline_rewards", "=", "eval_avg_episode_snort_warning_baseline_rewards", "\n", "self", ".", "avg_episode_snort_critical_baseline_rewards", "=", "avg_episode_snort_critical_baseline_rewards", "\n", "self", ".", "avg_episode_var_log_baseline_rewards", "=", "avg_episode_var_log_baseline_rewards", "\n", "self", ".", "eval_avg_episode_snort_critical_baseline_rewards", "=", "eval_avg_episode_snort_critical_baseline_rewards", "\n", "self", ".", "eval_avg_episode_var_log_baseline_rewards", "=", "eval_avg_episode_var_log_baseline_rewards", "\n", "self", ".", "avg_optimal_steps", "=", "avg_optimal_steps", "\n", "self", ".", "avg_optimal_reward", "=", "avg_optimal_reward", "\n", "self", ".", "avg_intrusion_steps", "=", "avg_intrusion_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_tensorboard_defender": [[94, 152], ["tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar"], "methods", ["None"], ["", "def", "log_tensorboard_defender", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log metrics to tensorboard for defender\n\n        :return: None\n        \"\"\"", "\n", "train_or_eval", "=", "\"eval\"", "if", "self", ".", "eval", "else", "\"train\"", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_episode_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/rolling_avg_episode_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "rolling_avg_episode_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_episode_steps/'", "+", "train_or_eval", ",", "self", ".", "avg_episode_steps", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/rolling_avg_episode_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "rolling_avg_episode_steps", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/episode_avg_loss/'", "+", "train_or_eval", ",", "self", ".", "avg_episode_loss", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/epsilon/'", "+", "train_or_eval", ",", "self", ".", "epsilon", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_avg_episode_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_avg_episode_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_steps", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/episode_caught_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "episode_caught_frac", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/episode_early_stopped_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "episode_early_stopped_frac", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/episode_successful_intrusion_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "episode_successful_intrusion_frac", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_episode_caught_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_episode_caught_frac", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_episode_early_stopped_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_episode_early_stopped_frac", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_episode_successful_intrusion_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_episode_successful_intrusion_frac", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_episode_snort_severe_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_snort_severe_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_episode_snort_warning_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_snort_warning_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_avg_episode_snort_severe_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_snort_severe_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_avg_episode_snort_warning_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_snort_warning_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_episode_snort_critical_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_snort_critical_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_episode_var_log_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_var_log_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_avg_episode_snort_critical_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_snort_critical_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/eval_avg_episode_var_log_baseline_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_var_log_baseline_rewards", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_optimal_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_optimal_steps", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_optimal_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_optimal_reward", ",", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/avg_intrusion_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_intrusion_steps", ",", "self", ".", "iteration", ")", "\n", "if", "not", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'defender/lr'", ",", "self", ".", "lr", ",", "self", ".", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_str_attacker": [[154, 204], ["None"], "methods", ["None"], ["", "", "def", "log_str_attacker", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string representation of the DTO for the attacker\n        \"\"\"", "\n", "if", "self", ".", "eval", ":", "\n", "            ", "log_str", "=", "\"[Eval A] iter:{},Avg_Reg:{:.2f},Opt_frac:{:.2f},avg_R:{:.2f},rolling_avg_R:{:.2f},\"", "\"avg_t:{:.2f},rolling_avg_t:{:.2f},lr:{:.2E},avg_F:{:.2f},avg_F%:{:.2f},\"", "\"n_af:{},n_d:{},\"", "\"c:{:.2f},s:{:.2f},s_i:{:.2f},costs:{:.2f},costs_N:{:.2f},alerts:{:.2f},\"", "\"alerts_N:{:.2f}\"", ".", "format", "(", "\n", "self", ".", "iteration", ",", "self", ".", "avg_regret", ",", "self", ".", "avg_opt_frac", ",", "self", ".", "avg_episode_rewards", ",", "self", ".", "rolling_avg_rewards", ",", "\n", "self", ".", "avg_episode_steps", ",", "self", ".", "rolling_avg_steps", ",", "self", ".", "lr", ",", "self", ".", "avg_episode_flags", ",", "\n", "self", ".", "avg_episode_flags_percentage", ",", "self", ".", "n_af", ",", "self", ".", "n_d", ",", "\n", "self", ".", "episode_caught_frac", ",", "self", ".", "episode_early_stopped_frac", ",", "self", ".", "episode_successful_intrusion_frac", ",", "\n", "self", ".", "avg_episode_costs", ",", "self", ".", "avg_episode_costs_norm", ",", "self", ".", "avg_episode_alerts", ",", "\n", "self", ".", "avg_episode_alerts_norm", "\n", ")", "\n", "", "else", ":", "\n", "            ", "log_str", "=", "\"[Train A] iter:{:.2f},avg_reg_T:{:.2f},opt_frac_T:{:.2f},avg_R_T:{:.2f},rolling_avg_R_T:{:.2f},\"", "\"avg_t_T:{:.2f},rolling_avg_t_T:{:.2f},\"", "\"loss:{:.6f},lr:{:.2E},episode:{},avg_F_T:{:.2f},avg_F_T%:{:.2f},eps:{:.2f},\"", "\"n_af:{},n_d:{},avg_R_E:{:.2f},avg_reg_E:{:.2f},avg_opt_frac_E:{:.2f},\"", "\"avg_t_E:{:.2f},avg_F_E:{:.2f},avg_F_E%:{:.2f},\"", "\"epsilon:{:.2f},\"", "\"c:{:.2f},s:{:.2f},s_i:{:.2f},\"", "\"c_E:{:.2f},s_E:{:.2f},s_i_E:{:.2f},\"", "\"costs:{:.2f},costs_N:{:.2f},alerts:{:.2f},\"", "\"alerts_N:{:.2f},E_costs:{:.2f},E_costs_N:{:.2f},E_alerts:{:.2f},E_alerts_N:{:.2f},\"", "\"tt_h:{:.2f},avg_F_T_E:{:.2f},avg_F_T_E%:{:.2f},opt_R:{},opt_t:{},i_t:{}\"", ".", "format", "(", "\n", "self", ".", "iteration", ",", "self", ".", "avg_regret", ",", "self", ".", "avg_opt_frac", ",", "self", ".", "avg_episode_rewards", ",", "self", ".", "rolling_avg_rewards", ",", "\n", "self", ".", "avg_episode_steps", ",", "self", ".", "rolling_avg_steps", ",", "self", ".", "avg_episode_loss", ",", "\n", "self", ".", "lr", ",", "self", ".", "total_num_episodes", ",", "self", ".", "avg_episode_flags", ",", "\n", "self", ".", "avg_episode_flags_percentage", ",", "self", ".", "eps", ",", "\n", "self", ".", "n_af", ",", "self", ".", "n_d", ",", "\n", "self", ".", "eval_avg_episode_rewards", ",", "self", ".", "avg_eval_regret", ",", "self", ".", "eval_avg_opt_frac", ",", "self", ".", "eval_avg_episode_steps", ",", "\n", "self", ".", "eval_avg_episode_flags", ",", "\n", "self", ".", "eval_avg_episode_flags_percentage", ",", "\n", "self", ".", "epsilon", ",", "\n", "self", ".", "episode_caught_frac", ",", "self", ".", "episode_early_stopped_frac", ",", "self", ".", "episode_successful_intrusion_frac", ",", "\n", "self", ".", "eval_episode_caught_frac", ",", "self", ".", "eval_episode_early_stopped_frac", ",", "\n", "self", ".", "eval_episode_successful_intrusion_frac", ",", "\n", "self", ".", "avg_episode_costs", ",", "self", ".", "avg_episode_costs_norm", ",", "self", ".", "avg_episode_alerts", ",", "\n", "self", ".", "avg_episode_alerts_norm", ",", "\n", "self", ".", "eval_avg_episode_costs", ",", "self", ".", "eval_avg_episode_costs_norm", ",", "self", ".", "eval_avg_episode_alerts", ",", "\n", "self", ".", "eval_avg_episode_alerts_norm", ",", "\n", "self", ".", "training_time_hours", ",", "\n", "self", ".", "eval_avg_episode_flags", ",", "self", ".", "eval_avg_episode_flags_percentage", ",", "\n", "self", ".", "avg_optimal_reward", ",", "self", ".", "avg_optimal_steps", ",", "self", ".", "avg_intrusion_steps", "\n", ")", "\n", "", "return", "log_str", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_str_defender": [[205, 266], ["None"], "methods", ["None"], ["", "def", "log_str_defender", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string representation of the DTO for the attacker\n        \"\"\"", "\n", "if", "self", ".", "eval", ":", "\n", "            ", "log_str", "=", "\"[Eval D] iter:{},avg_R:{:.2f},rolling_avg_R:{:.2f},\"", "\"S_sev_avg_R_T:{:.2f},S_warn_avg_R_T:{:.2f},\"", "\"S_crit_avg_R_T:{:.2f},V_log_avg_R_T:{:.2f},\"", "\"avg_t:{:.2f},rolling_avg_t:{:.2f},lr:{:.2E},\"", "\"c:{:.2f},s:{:.2f},s_i:{:.2f},\"", ".", "format", "(", "\n", "self", ".", "iteration", ",", "self", ".", "avg_episode_rewards", ",", "self", ".", "rolling_avg_rewards", ",", "\n", "self", ".", "avg_episode_snort_severe_baseline_rewards", ",", "\n", "self", ".", "avg_episode_snort_warning_baseline_rewards", ",", "\n", "self", ".", "avg_episode_snort_critical_baseline_rewards", ",", "\n", "self", ".", "avg_episode_var_log_baseline_rewards", ",", "\n", "self", ".", "avg_episode_steps", ",", "self", ".", "rolling_avg_steps", ",", "\n", "self", ".", "lr", ",", "self", ".", "episode_caught_frac", ",", "\n", "self", ".", "episode_early_stopped_frac", ",", "self", ".", "episode_successful_intrusion_frac", ")", "\n", "", "else", ":", "\n", "            ", "log_str", "=", "\"[Train D] iter:{:.2f},avg_reg_T:{:.2f},opt_frac_T:{:.2f},\"", "\"avg_R_T:{:.2f},rolling_avg_R_T:{:.2f},\"", "\"S_sev_avg_R_T:{:.2f},S_warn_avg_R_T:{:.2f},S_crit_avg_R_T:{:.2f},V_log_avg_R_T:{:.2f},\"", "\"avg_t_T:{:.2f},rolling_avg_t_T:{:.2f},\"", "\"loss:{:.6f},lr:{:.2E},episode:{},eps:{:.2f},\"", "\"avg_R_E:{:.2f},S_sev_avg_R_E:{:.2f},S_warn_avg_R_E:{:.2f},\"", "\"S_crit_avg_R_E:{:.2f},V_log_avg_R_E:{:.2f},\"", "\"avg_reg_E:{:.2f},avg_opt_frac_E:{:.2f},\"", "\"avg_t_E:{:.2f},\"", "\"epsilon:{:.2f},\"", "\"c:{:.2f},s:{:.2f},s_i:{:.2f},n_af:{:.2f},\"", "\"c_E:{:.2f},s_E:{:.2f},s_i_E:{:.2f},\"", "\"avg_F_T:{:.2f},avg_F_T%:{:.2f},\"", "\"avg_F_E:{:.2f},avg_F_E%:{:.2f}\"", "\"costs:{:.2f},costs_N:{:.2f},alerts:{:.2f},\"", "\"alerts_N:{:.2f},E_costs:{:.2f},E_costs_N:{:.2f},E_alerts:{:.2f},E_alerts_N:{:.2f},\"", "\"opt_R:{:.2f},opt_t:{:.2f},i_t:{}\"", ".", "format", "(", "\n", "self", ".", "iteration", ",", "self", ".", "avg_regret", ",", "self", ".", "avg_opt_frac", ",", "self", ".", "avg_episode_rewards", ",", "\n", "self", ".", "rolling_avg_rewards", ",", "\n", "self", ".", "avg_episode_snort_severe_baseline_rewards", ",", "self", ".", "avg_episode_snort_warning_baseline_rewards", ",", "\n", "self", ".", "avg_episode_snort_critical_baseline_rewards", ",", "self", ".", "avg_episode_var_log_baseline_rewards", ",", "\n", "self", ".", "avg_episode_steps", ",", "self", ".", "rolling_avg_steps", ",", "self", ".", "avg_episode_loss", ",", "\n", "self", ".", "lr", ",", "self", ".", "total_num_episodes", ",", "self", ".", "eps", ",", "\n", "self", ".", "eval_avg_episode_rewards", ",", "self", ".", "eval_avg_episode_snort_severe_baseline_rewards", ",", "\n", "self", ".", "eval_avg_episode_snort_warning_baseline_rewards", ",", "\n", "self", ".", "eval_avg_episode_snort_critical_baseline_rewards", ",", "\n", "self", ".", "eval_avg_episode_var_log_baseline_rewards", ",", "\n", "self", ".", "avg_eval_regret", ",", "self", ".", "eval_avg_opt_frac", ",", "self", ".", "eval_avg_episode_steps", ",", "\n", "self", ".", "epsilon", ",", "\n", "self", ".", "episode_caught_frac", ",", "self", ".", "episode_early_stopped_frac", ",", "\n", "self", ".", "episode_successful_intrusion_frac", ",", "\n", "self", ".", "n_af", ",", "self", ".", "eval_episode_caught_frac", ",", "self", ".", "eval_episode_early_stopped_frac", ",", "\n", "self", ".", "eval_episode_successful_intrusion_frac", ",", "\n", "self", ".", "avg_episode_flags", ",", "self", ".", "avg_episode_flags_percentage", ",", "self", ".", "eval_avg_episode_flags", ",", "\n", "self", ".", "eval_avg_episode_flags_percentage", ",", "\n", "self", ".", "avg_episode_costs", ",", "self", ".", "avg_episode_costs_norm", ",", "self", ".", "avg_episode_alerts", ",", "\n", "self", ".", "avg_episode_alerts_norm", ",", "\n", "self", ".", "eval_avg_episode_costs", ",", "self", ".", "eval_avg_episode_costs_norm", ",", "self", ".", "eval_avg_episode_alerts", ",", "\n", "self", ".", "eval_avg_episode_alerts_norm", ",", "self", ".", "avg_optimal_reward", ",", "self", ".", "avg_optimal_steps", ",", "\n", "self", ".", "avg_intrusion_steps", "\n", ")", "\n", "", "return", "log_str", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_tensorboard_attacker": [[268, 335], ["tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar", "tensorboard_data_dto.TensorboardDataDTO.tensorboard_writer.add_scalar"], "methods", ["None"], ["", "def", "log_tensorboard_attacker", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log metrics to tensorboard for attacker\n        \n        :return: None\n        \"\"\"", "\n", "train_or_eval", "=", "\"eval\"", "if", "self", ".", "eval", "else", "\"train\"", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/avg_episode_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_rewards", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/rolling_avg_episode_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "rolling_avg_episode_rewards", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/avg_episode_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_steps", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/rolling_avg_episode_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "rolling_avg_episode_steps", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/episode_avg_loss/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_loss", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/epsilon/'", "+", "train_or_eval", ",", "\n", "self", ".", "epsilon", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/avg_episode_flags/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_flags_catched", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/avg_episode_flags_percentage/'", "+", "train_or_eval", ",", "\n", "self", ".", "avg_episode_flags_percentage", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_avg_episode_rewards/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_rewards", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_avg_episode_steps/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_steps", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_avg_episode_flags/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_flags", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_avg_episode_flags_percentage/'", "\n", "+", "train_or_eval", ",", "\n", "self", ".", "eval_avg_episode_flags_percentage", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/episode_caught_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "episode_caught_frac", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/episode_early_stopped_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "episode_early_stopped_frac", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/episode_successful_intrusion_frac/'", "\n", "+", "train_or_eval", ",", "\n", "self", ".", "episode_successful_intrusion_frac", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_episode_caught_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_episode_caught_frac", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_episode_early_stopped_frac/'", "+", "train_or_eval", ",", "\n", "self", ".", "eval_episode_early_stopped_frac", ",", "\n", "self", ".", "iteration", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/eval_episode_successful_intrusion_frac/'", "\n", "+", "train_or_eval", ",", "\n", "self", ".", "eval_episode_successful_intrusion_frac", ",", "\n", "self", ".", "iteration", ")", "\n", "\n", "if", "not", "self", ".", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'attacker/lr'", ",", "self", ".", "lr", ",", "self", ".", "iteration", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.dp.dp_setup.DPSetup.__init__": [[9, 17], ["numpy.array", "list", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "HP", ",", "R", ",", "T", ",", "next_state_lookahead", ",", "state_to_id", ",", "id_to_state", ")", ":", "\n", "        ", "self", ".", "HP", "=", "HP", "\n", "self", ".", "R", "=", "R", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "next_state_lookahead", "=", "next_state_lookahead", "\n", "self", ".", "state_to_id", "=", "state_to_id", "\n", "self", ".", "id_to_state", "=", "id_to_state", "\n", "self", ".", "state_ids", "=", "np", ".", "array", "(", "list", "(", "range", "(", "T", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.__init__": [[17, 45], ["env_state.EnvState.setup_spaces", "gym_optimal_intrusion_response.dao.obs.attacker_obs_state.AttackerObservationState", "gym_optimal_intrusion_response.dao.obs.defender_obs_state.DefenderObservationState", "env_state.EnvState.initialize_nodes", "env_state.EnvState.setup_dp", "env_state.EnvState.setup_dynamics_model"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.setup_spaces", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.initialize_nodes", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.setup_dp", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.setup_dynamics_model"], ["def", "__init__", "(", "self", ",", "env_config", ":", "EnvConfig", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the state\n\n        :param env_config: the environment configuration\n        \"\"\"", "\n", "self", ".", "env_config", "=", "env_config", "\n", "self", ".", "attacker_observation_space", "=", "None", "\n", "self", ".", "defender_observation_space", "=", "None", "\n", "self", ".", "attacker_action_space", "=", "None", "\n", "self", ".", "defender_action_space", "=", "None", "\n", "self", ".", "setup_spaces", "(", "self", ".", "env_config", ")", "\n", "self", ".", "attacker_observation_state", "=", "AttackerObservationState", "(", "env_config", "=", "env_config", ")", "\n", "self", ".", "defender_observation_state", "=", "DefenderObservationState", "(", "env_config", "=", "env_config", ")", "\n", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "initialize_nodes", "(", ")", "\n", "self", ".", "stopped", "=", "False", "\n", "self", ".", "caught", "=", "False", "\n", "self", ".", "intrusion_in_progress", "=", "False", "\n", "self", ".", "target_compromised", "=", "False", "\n", "self", ".", "intrusion_t", "=", "0", "\n", "self", ".", "t", "=", "0", "\n", "self", ".", "dp_setup", "=", "None", "\n", "self", ".", "dynamics_model", "=", "None", "\n", "if", "self", ".", "env_config", ".", "dp", ":", "\n", "            ", "self", ".", "dp_setup", "=", "self", ".", "setup_dp", "(", ")", "\n", "", "elif", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "self", ".", "dynamics_model", "=", "self", ".", "setup_dynamics_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.setup_spaces": [[46, 68], ["gym.spaces.Box", "gym.spaces.Discrete", "gym.spaces.Discrete", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["None"], ["", "", "def", "setup_spaces", "(", "self", ",", "env_config", ":", "EnvConfig", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Setup of the action and observation spaces\n\n        :param env_config: the environment configuration\n        :return: None\n        \"\"\"", "\n", "self", ".", "attacker_observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "1000", ",", "dtype", "=", "np", ".", "float32", ",", "shape", "=", "(", "env_config", ".", "num_nodes", "*", "(", "env_config", ".", "num_attributes", "+", "2", ")", ",", ")", ")", "\n", "if", "self", ".", "env_config", ".", "dp", ":", "\n", "            ", "self", ".", "defender_observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "1000", ",", "dtype", "=", "np", ".", "float32", ",", "shape", "=", "(", "2", ",", ")", ")", "\n", "", "elif", "not", "self", ".", "env_config", ".", "dp", "and", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "self", ".", "defender_observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "1000", ",", "dtype", "=", "np", ".", "float32", ",", "shape", "=", "(", "4", ",", ")", ")", "\n", "# self.defender_observation_space = gym.spaces.Box(", "\n", "#     low=0, high=1000, dtype=np.float32, shape=(5,))", "\n", "", "else", ":", "\n", "            ", "self", ".", "defender_observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "1000", ",", "dtype", "=", "np", ".", "float32", ",", "shape", "=", "(", "3", ",", ")", ")", "\n", "", "self", ".", "attacker_action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "env_config", ".", "num_nodes", "*", "(", "env_config", ".", "num_attributes", "+", "1", ")", ")", "\n", "self", ".", "defender_action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_defender_observation": [[69, 74], ["env_state.EnvState.defender_observation_state.get_defender_observation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_defender_observation"], ["", "def", "get_defender_observation", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        :return: the latest defender observation\n        \"\"\"", "\n", "return", "self", ".", "defender_observation_state", ".", "get_defender_observation", "(", "t", "=", "self", ".", "t", ",", "dp_setup", "=", "self", ".", "dp_setup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacker_observation": [[75, 80], ["env_state.EnvState.attacker_observation_state.get_attacker_observation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacker_observation"], ["", "def", "get_attacker_observation", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        :return: the latest attacker observation\n        \"\"\"", "\n", "return", "self", ".", "attacker_observation_state", ".", "get_attacker_observation", "(", "self", ".", "nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.reset": [[81, 95], ["env_state.EnvState.initialize_nodes", "env_state.EnvState.defender_observation_state.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.initialize_nodes", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the state\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "initialize_nodes", "(", ")", "\n", "self", ".", "stopped", "=", "False", "\n", "self", ".", "caught", "=", "False", "\n", "self", ".", "intrusion_in_progress", "=", "False", "\n", "self", ".", "target_compromised", "=", "False", "\n", "self", ".", "defender_observation_state", ".", "reset", "(", ")", "\n", "self", ".", "t", "=", "1", "\n", "self", ".", "intrusion_t", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.initialize_nodes": [[96, 112], ["range", "gym_optimal_intrusion_response.dao.game.node.Node", "nodes.append"], "methods", ["None"], ["", "def", "initialize_nodes", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for initializing the node states\n\n        :return: None\n        \"\"\"", "\n", "nodes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "env_config", ".", "num_nodes", ")", ":", "\n", "            ", "target", "=", "(", "i", "==", "self", ".", "env_config", ".", "target_id", ")", "\n", "node", "=", "Node", "(", "initial_defense_attributes", "=", "self", ".", "env_config", ".", "initial_defense_attributes", "[", "i", "]", ",", "\n", "initial_attack_attributes", "=", "self", ".", "env_config", ".", "initial_attack_attributes", "[", "i", "]", ",", "\n", "num_attributes", "=", "self", ".", "env_config", ".", "num_attributes", ",", "\n", "max_attribute_value", "=", "self", ".", "env_config", ".", "max_attribute_value", ",", "\n", "target_component", "=", "target", ")", "\n", "nodes", ".", "append", "(", "node", ")", "\n", "", "self", ".", "nodes", "=", "nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.attacker_reachable": [[113, 129], ["range", "len"], "methods", ["None"], ["", "def", "attacker_reachable", "(", "self", ",", "node_id", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Utility function for checking if a node id is reachable for the  attacker or not\n\n        :param node_id: the id of the node to check\n        :return: True if reachable otherwise False\n        \"\"\"", "\n", "if", "node_id", ">=", "self", ".", "env_config", ".", "num_nodes", ":", "\n", "            ", "return", "False", "\n", "", "if", "node_id", "in", "self", ".", "env_config", ".", "initial_reachable", ":", "\n", "            ", "return", "True", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "if", "self", ".", "nodes", "[", "i", "]", ".", "compromised", ":", "\n", "                ", "if", "self", ".", "env_config", ".", "adjacency_matrix", "[", "i", "]", "[", "node_id", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.setup_dynamics_model": [[130, 147], ["gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel", "gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel", "print", "gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel.read_model", "gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel.normalize", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.read_model"], ["", "def", "setup_dynamics_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for loading and setting up the dynamics model based on system traces\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "defender_dynamics_model", "=", "DefenderDynamicsModel", "(", ")", "\n", "new_model", "=", "DefenderDynamicsModel", "(", ")", "\n", "if", "self", ".", "env_config", ".", "save_dynamics_model_dir", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"loading dynamics model: {}/{}\"", ".", "format", "(", "self", ".", "env_config", ".", "save_dynamics_model_dir", ",", "self", ".", "env_config", ".", "dynamics_model_name", ")", ")", "\n", "defender_dynamics_model", ".", "read_model", "(", "self", ".", "env_config", ".", "save_dynamics_model_dir", ",", "\n", "model_name", "=", "self", ".", "env_config", ".", "dynamics_model_name", ")", "\n", "defender_dynamics_model", ".", "normalize", "(", ")", "\n", "print", "(", "\"model loaded\"", ")", "\n", "return", "defender_dynamics_model", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.setup_dp": [[148, 173], ["gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.load_HP_table", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.load_R_table", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.load_transition_kernel", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.load_next_states_lookahead_table", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.load_state_to_id", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.load_id_to_state", "gym_optimal_intrusion_response.dao.dp.dp_setup.DPSetup", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.state_to_id_dict", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.ttc_to_alerts_table", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.hp_and_ttc_and_r", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.transition_kernel", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.next_states_lookahead_table", "gym_optimal_intrusion_response.dao.dp.dp_setup.DPSetup", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.num_states", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.num_actions", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.num_states", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.num_actions", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.num_states", "gym_optimal_intrusion_response.logic.defender_dynamics.dp.DP.num_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.state_to_id_dict", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.ttc_to_alerts_table", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.hp_and_ttc_and_r", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.transition_kernel", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.next_states_lookahead_table", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_states", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_states", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_states", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.num_actions"], ["", "def", "setup_dp", "(", "self", ")", "->", "DPSetup", ":", "\n", "        ", "\"\"\"\n        Utility function for setting up the D.P parameters\n\n        :return: the DPsetup DTO\n        \"\"\"", "\n", "if", "self", ".", "env_config", ".", "dp_load", ":", "\n", "            ", "HP", "=", "DP", ".", "load_HP_table", "(", ")", "\n", "R", "=", "DP", ".", "load_R_table", "(", ")", "\n", "T", "=", "DP", ".", "load_transition_kernel", "(", ")", "\n", "next_state_lookahead", "=", "DP", ".", "load_next_states_lookahead_table", "(", ")", "\n", "state_to_id", "=", "DP", ".", "load_state_to_id", "(", ")", "\n", "id_to_state", "=", "DP", ".", "load_id_to_state", "(", ")", "\n", "dp_setup", "=", "DPSetup", "(", "HP", "=", "HP", ",", "R", "=", "R", ",", "T", "=", "T", ",", "next_state_lookahead", "=", "next_state_lookahead", ",", "\n", "state_to_id", "=", "state_to_id", ",", "id_to_state", "=", "id_to_state", ")", "\n", "", "else", ":", "\n", "            ", "state_to_id", ",", "id_to_state", "=", "DP", ".", "state_to_id_dict", "(", ")", "\n", "ttc_to_alerts_logins", ",", "alerts_logins_to_ttc", "=", "DP", ".", "ttc_to_alerts_table", "(", ")", "\n", "HP", ",", "R", "=", "DP", ".", "hp_and_ttc_and_r", "(", "DP", ".", "num_states", "(", ")", ",", "DP", ".", "num_actions", "(", ")", ",", "id_to_state", ")", "\n", "T", "=", "DP", ".", "transition_kernel", "(", "id_to_state", ",", "DP", ".", "num_states", "(", ")", ",", "DP", ".", "num_actions", "(", ")", ",", "HP", ",", "ttc_to_alerts_logins", ",", "\n", "alerts_logins_to_ttc", ",", "state_to_id", ")", "\n", "next_state_lookahead", "=", "DP", ".", "next_states_lookahead_table", "(", "DP", ".", "num_states", "(", ")", ",", "DP", ".", "num_actions", "(", ")", ",", "T", ",", "id_to_state", ")", "\n", "dp_setup", "=", "DPSetup", "(", "HP", "=", "HP", ",", "R", "=", "R", ",", "T", "=", "T", ",", "next_state_lookahead", "=", "next_state_lookahead", ",", "\n", "state_to_id", "=", "state_to_id", ",", "id_to_state", "=", "id_to_state", ")", "\n", "", "return", "dp_setup", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacked_node": [[174, 184], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_attacked_node", "(", "attacker_action_id", ":", "int", ",", "env_config", ":", "EnvConfig", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Utility function for getting the id of the node of an attack\n\n        :param attacker_action_id: the attack id\n        :param env_config: the environment config\n        :return: the node id\n        \"\"\"", "\n", "return", "attacker_action_id", "//", "(", "env_config", ".", "num_attributes", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacked_attribute": [[185, 195], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_attacked_attribute", "(", "attacker_action_id", ":", "int", ",", "env_config", ":", "EnvConfig", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Utility function for getting the attribute idx of an attack\n\n        :param attacker_action_id: the attack id\n        :param env_config: the environment config\n        :return: the attribute id\n        \"\"\"", "\n", "return", "attacker_action_id", "%", "(", "env_config", ".", "num_attributes", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.__str__": [[197, 202], ["list", "map", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: a string representation of the object\n        \"\"\"", "\n", "return", "\",\"", ".", "join", "(", "list", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "self", ".", "nodes", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_config.EnvConfig.__init__": [[11, 101], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "attacker_static_opponent", ":", "StaticAttacker", ",", "\n", "defender_static_opponent", ":", "StaticDefender", ",", "\n", "adjacency_matrix", ",", "\n", "initial_reachable", ",", "\n", "num_nodes", ":", "int", "=", "4", ",", "\n", "num_attributes", ":", "int", "=", "4", ",", "\n", "initial_attack_attributes", "=", "None", ",", "initial_defense_attributes", "=", "None", ",", "\n", "max_attribute_value", ":", "int", "=", "100", ",", "recon_attribute", ":", "int", "=", "4", ",", "\n", "attacker_target_compromised_reward", ":", "int", "=", "1", ",", "\n", "defender_target_compromised_reward", ":", "int", "=", "-", "1", ",", "\n", "defender_early_stopping_reward", ":", "int", "=", "-", "1", ",", "\n", "attacker_early_stopping_reward", ":", "int", "=", "-", "1", ",", "\n", "defender_intrusion_prevented_reward", ":", "int", "=", "1", ",", "\n", "attacker_intrusion_prevented_reward", ":", "int", "=", "1", ",", "\n", "defender_continue_reward", ":", "int", "=", "1", ",", "\n", "attacker_continue_reward", ":", "int", "=", "0", ",", "\n", "target_id", ":", "int", "=", "4", ",", "\n", "use_state_limits", ":", "bool", "=", "True", ",", "\n", "dp", ":", "bool", "=", "False", ",", "\n", "dp_load", ":", "bool", "=", "False", ",", "\n", "traces", ":", "bool", "=", "False", ",", "\n", "save_dynamics_model_dir", "=", "None", ",", "\n", "dynamics_model_name", "=", "None", ",", "\n", "action_to_state", "=", "None", ",", "\n", "attack_idx_to_id", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor\n\n        :param attacker_static_opponent: the static attacker opponent\n        :param defender_static_opponent: the static defender opponent\n        :param adjacency_matrix: the adjacency matrix defining the topology\n        :param initial_reachable: the nodes that are reachable from the attacker's starting position\n        :param num_nodes: the number of nodes\n        :param num_attributes: the number of attributes\n        :param initial_attack_attributes: the initial attack attributes\n        :param initial_defense_attributes: the initial defense attributes\n        :param max_attribute_value: the maximum attribute value in the model\n        :param recon_attribute: the index of the recon attribute\n        :param attacker_target_compromised_reward: the reward that the attacker gets for compromising a node\n        :param defender_target_compromised_reward: the reward that the defender gets for compromising a node\n        :param defender_early_stopping_reward: the reward that the defender gets for stopping early\n        :param attacker_early_stopping_reward: the reward that the attacker gets if the defender stops early\n        :param defender_intrusion_prevented_reward: the reward that the defender gets for preventing an intrusion\n        :param attacker_intrusion_prevented_reward: the reward that the attacker gets for preventing an intrusion\n        :param defender_continue_reward: the reward that the defender gets for continuing\n        :param attacker_continue_reward: the reward that the attacker gets for continuing\n        :param target_id: the id of the target node\n        :param use_state_limits: boolean flag whether to use state limits\n        :param dp: boolean flag whether to use dp\n        :param dp_load: boolean flag whether to load dp data\n        :param traces: boolean flag whether to train with traces\n        :param save_dynamics_model_dir: path to saved dynamics model\n        :param dynamics_model_name: name of dynamics model\n        :param action_to_state: dict for converting between action to state for the dynamics model\n        :param attack_idx_to_id: dict for converting between attack action idx and id\n        \"\"\"", "\n", "self", ".", "num_nodes", "=", "num_nodes", "\n", "self", ".", "num_attributes", "=", "num_attributes", "\n", "self", ".", "attacker_static_opponent", "=", "attacker_static_opponent", "\n", "self", ".", "defender_static_opponent", "=", "defender_static_opponent", "\n", "self", ".", "initial_attack_attributes", "=", "initial_attack_attributes", "\n", "self", ".", "initial_defense_attributes", "=", "initial_defense_attributes", "\n", "if", "initial_attack_attributes", "is", "None", ":", "\n", "            ", "self", ".", "initial_attack_attributes", "=", "np", ".", "zeros", "(", "self", ".", "num_nodes", ",", "self", ".", "num_attributes", ")", "\n", "", "if", "initial_defense_attributes", "is", "None", ":", "\n", "            ", "self", ".", "initial_defense_attributes", "=", "np", ".", "zeros", "(", "self", ".", "num_nodes", ",", "self", ".", "num_attributes", ")", "\n", "", "self", ".", "max_attribute_value", "=", "max_attribute_value", "\n", "self", ".", "recon_attribute", "=", "recon_attribute", "\n", "self", ".", "attacker_target_compromised_reward", ":", "int", "=", "attacker_target_compromised_reward", "\n", "self", ".", "defender_target_compromised_reward", ":", "int", "=", "defender_target_compromised_reward", "\n", "self", ".", "attacker_early_stopping_reward", "=", "attacker_early_stopping_reward", "\n", "self", ".", "defender_early_stopping_reward", "=", "defender_early_stopping_reward", "\n", "self", ".", "defender_intrusion_prevention_reward", "=", "defender_intrusion_prevented_reward", "\n", "self", ".", "attacker_intrusion_prevention_reward", "=", "attacker_intrusion_prevented_reward", "\n", "self", ".", "defender_continue_reward", "=", "defender_continue_reward", "\n", "self", ".", "attacker_continue_reward", "=", "attacker_continue_reward", "\n", "self", ".", "attacker_num_actions", "=", "self", ".", "num_nodes", "*", "self", ".", "num_attributes", "\n", "self", ".", "defender_num_actions", "=", "2", "\n", "self", ".", "target_id", "=", "target_id", "\n", "self", ".", "adjacency_matrix", "=", "adjacency_matrix", "\n", "self", ".", "initial_reachable", "=", "initial_reachable", "\n", "self", ".", "use_state_limits", "=", "use_state_limits", "\n", "self", ".", "dp", "=", "dp", "\n", "self", ".", "dp_load", "=", "dp_load", "\n", "self", ".", "traces", "=", "traces", "\n", "self", ".", "save_dynamics_model_dir", "=", "save_dynamics_model_dir", "\n", "self", ".", "dynamics_model_name", "=", "dynamics_model_name", "\n", "self", ".", "action_to_state", "=", "action_to_state", "\n", "self", ".", "attack_idx_to_id", "=", "attack_idx_to_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.__init__": [[6, 22], ["list", "list", "node.Node.initialize_attributes", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.initialize_attributes"], ["    ", "def", "__init__", "(", "self", ",", "initial_defense_attributes", "=", "None", ",", "initial_attack_attributes", "=", "None", ",", "\n", "num_attributes", ":", "int", "=", "1", ",", "max_attribute_value", ":", "int", "=", "100", ",", "target_component", ":", "bool", "=", "False", ")", ":", "\n", "        ", "self", ".", "initial_defense_attributes", "=", "initial_defense_attributes", "\n", "self", ".", "initial_attack_attributes", "=", "initial_attack_attributes", "\n", "if", "self", ".", "initial_defense_attributes", "is", "None", ":", "\n", "            ", "self", ".", "initial_defense_attributes", "=", "np", ".", "zeros", "(", "num_attributes", ")", "\n", "", "if", "self", ".", "initial_attack_attributes", "is", "None", ":", "\n", "            ", "self", ".", "initial_attack_attributes", "=", "np", ".", "zeros", "(", "num_attributes", ")", "\n", "", "self", ".", "num_attributes", "=", "num_attributes", "\n", "self", ".", "max_attribute_value", "=", "max_attribute_value", "\n", "self", ".", "compromised", "=", "False", "\n", "self", ".", "attack_attributes", "=", "list", "(", "np", ".", "zeros", "(", "num_attributes", ")", ")", "\n", "self", ".", "defense_attributes", "=", "list", "(", "np", ".", "zeros", "(", "num_attributes", ")", ")", "\n", "self", ".", "initialize_attributes", "(", ")", "\n", "self", ".", "recon_done", "=", "False", "\n", "self", ".", "target_component", "=", "target_component", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.attack": [[24, 29], ["None"], "methods", ["None"], ["", "def", "attack", "(", "self", ",", "attribute_id", ")", ":", "\n", "        ", "if", "self", ".", "attack_attributes", "[", "attribute_id", "]", "<", "self", ".", "max_attribute_value", ":", "\n", "            ", "self", ".", "attack_attributes", "[", "attribute_id", "]", "+=", "1", "\n", "", "if", "self", ".", "attack_attributes", "[", "attribute_id", "]", ">", "self", ".", "defense_attributes", "[", "attribute_id", "]", ":", "\n", "            ", "self", ".", "compromised", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.recon": [[30, 32], ["None"], "methods", ["None"], ["", "", "def", "recon", "(", "self", ")", ":", "\n", "        ", "self", ".", "recon_done", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.initialize_attributes": [[34, 38], ["range"], "methods", ["None"], ["", "def", "initialize_attributes", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "num_attributes", ")", ":", "\n", "            ", "self", ".", "attack_attributes", "[", "i", "]", "=", "self", ".", "initial_attack_attributes", "[", "i", "]", "\n", "self", ".", "defense_attributes", "[", "i", "]", "=", "self", ".", "initial_defense_attributes", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.node.Node.__str__": [[39, 42], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"attack attributes:{},defense attributes:{},compromised:{},recon_done:{},target:{}\\n\"", ".", "format", "(", "\n", "self", ".", "attack_attributes", ",", "self", ".", "defense_attributes", ",", "self", ".", "compromised", ",", "self", ".", "recon_done", ",", "self", ".", "target_component", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agents.train_agent.TrainAgent.__init__": [[17, 40], ["gym_optimal_intrusion_response.dao.experiment.experiment_result.ExperimentResult", "gym_optimal_intrusion_response.dao.experiment.experiment_result.ExperimentResult", "random.seed", "numpy.random.seed", "torch.manual_seed", "print", "logging.getLogger", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed"], ["def", "__init__", "(", "self", ",", "env", ",", "attacker_config", ":", "AgentConfig", ",", "\n", "defender_config", ":", "AgentConfig", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "self", ".", "attacker_config", "=", "attacker_config", "\n", "self", ".", "defender_config", "=", "defender_config", "\n", "self", ".", "train_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "train_mode", "=", "train_mode", "\n", "if", "self", ".", "attacker_config", "is", "None", ":", "\n", "            ", "self", ".", "attacker_config", "=", "self", ".", "defender_config", "\n", "", "if", "self", ".", "attacker_config", ".", "logger", "is", "None", ":", "\n", "            ", "self", ".", "attacker_config", ".", "logger", "=", "logging", ".", "getLogger", "(", "'Train Agent - Attacker'", ")", "\n", "\n", "", "if", "self", ".", "defender_config", "is", "None", ":", "\n", "            ", "self", ".", "defender_config", "=", "self", ".", "attacker_config", "\n", "", "if", "self", ".", "defender_config", ".", "logger", "is", "None", ":", "\n", "            ", "self", ".", "defender_config", ".", "logger", "=", "logging", ".", "getLogger", "(", "'Train Agent - Defender'", ")", "\n", "\n", "", "random", ".", "seed", "(", "self", ".", "attacker_config", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "attacker_config", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "self", ".", "attacker_config", ".", "random_seed", ")", "\n", "print", "(", "\"Seed:{}\"", ".", "format", "(", "self", ".", "attacker_config", ".", "random_seed", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agents.train_agent.TrainAgent.train": [[41, 44], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agents.train_agent.TrainAgent.eval": [[45, 48], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "eval", "(", "self", ",", "log", "=", "True", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.ActionNoise.__init__": [[13, 15], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ActionNoise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.ActionNoise.reset": [[16, 21], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        call end of episode reset for the noise\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.ActionNoise.__call__": [[22, 25], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__call__", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.NormalActionNoise.__init__": [[35, 39], ["noise.ActionNoise.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "mean", ":", "np", ".", "ndarray", ",", "sigma", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "self", ".", "_mu", "=", "mean", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "super", "(", "NormalActionNoise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.NormalActionNoise.__call__": [[40, 42], ["numpy.random.normal"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "return", "np", ".", "random", ".", "normal", "(", "self", ".", "_mu", ",", "self", ".", "_sigma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.NormalActionNoise.__repr__": [[43, 45], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"NormalActionNoise(mu={self._mu}, sigma={self._sigma})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.OrnsteinUhlenbeckActionNoise.__init__": [[60, 76], ["numpy.zeros_like", "noise.OrnsteinUhlenbeckActionNoise.reset", "noise.ActionNoise.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "mean", ":", "np", ".", "ndarray", ",", "\n", "sigma", ":", "np", ".", "ndarray", ",", "\n", "theta", ":", "float", "=", "0.15", ",", "\n", "dt", ":", "float", "=", "1e-2", ",", "\n", "initial_noise", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "_theta", "=", "theta", "\n", "self", ".", "_mu", "=", "mean", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "self", ".", "_dt", "=", "dt", "\n", "self", ".", "initial_noise", "=", "initial_noise", "\n", "self", ".", "noise_prev", "=", "np", ".", "zeros_like", "(", "self", ".", "_mu", ")", "\n", "self", ".", "reset", "(", ")", "\n", "super", "(", "OrnsteinUhlenbeckActionNoise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.OrnsteinUhlenbeckActionNoise.__call__": [[77, 85], ["numpy.random.normal", "numpy.sqrt"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "noise", "=", "(", "\n", "self", ".", "noise_prev", "\n", "+", "self", ".", "_theta", "*", "(", "self", ".", "_mu", "-", "self", ".", "noise_prev", ")", "*", "self", ".", "_dt", "\n", "+", "self", ".", "_sigma", "*", "np", ".", "sqrt", "(", "self", ".", "_dt", ")", "*", "np", ".", "random", ".", "normal", "(", "size", "=", "self", ".", "_mu", ".", "shape", ")", "\n", ")", "\n", "self", ".", "noise_prev", "=", "noise", "\n", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.OrnsteinUhlenbeckActionNoise.reset": [[86, 91], ["numpy.zeros_like"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        reset the Ornstein Uhlenbeck noise, to the initial position\n        \"\"\"", "\n", "self", ".", "noise_prev", "=", "self", ".", "initial_noise", "if", "self", ".", "initial_noise", "is", "not", "None", "else", "np", ".", "zeros_like", "(", "self", ".", "_mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.OrnsteinUhlenbeckActionNoise.__repr__": [[92, 94], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"OrnsteinUhlenbeckActionNoise(mu={self._mu}, sigma={self._sigma})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.VectorizedActionNoise.__init__": [[104, 113], ["int", "copy.deepcopy", "ValueError", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "base_noise", ":", "ActionNoise", ",", "n_envs", ":", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "n_envs", "=", "int", "(", "n_envs", ")", "\n", "assert", "self", ".", "n_envs", ">", "0", "\n", "", "except", "(", "TypeError", ",", "AssertionError", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Expected n_envs={n_envs} to be positive integer greater than 0\"", ")", "\n", "\n", "", "self", ".", "base_noise", "=", "base_noise", "\n", "self", ".", "noises", "=", "[", "copy", ".", "deepcopy", "(", "self", ".", "base_noise", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.VectorizedActionNoise.reset": [[114, 126], ["range", "noise.VectorizedActionNoise.noises[].reset", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ",", "indices", ":", "Optional", "[", "Iterable", "[", "int", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reset all the noise processes, or those listed in indices\n\n        :param indices: Optional[Iterable[int]] The indices to reset. Default: None.\n            If the parameter is None, then all processes are reset to their initial position.\n        \"\"\"", "\n", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "range", "(", "len", "(", "self", ".", "noises", ")", ")", "\n", "\n", "", "for", "index", "in", "indices", ":", "\n", "            ", "self", ".", "noises", "[", "index", "]", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.VectorizedActionNoise.__repr__": [[127, 129], ["repr", "len"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"VecNoise(BaseNoise={repr(self.base_noise)}), n_envs={len(self.noises)})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.VectorizedActionNoise.__call__": [[130, 136], ["numpy.stack", "numpy.stack."], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Generate and stack the action noise from each noise object\n        \"\"\"", "\n", "noise", "=", "np", ".", "stack", "(", "[", "noise", "(", ")", "for", "noise", "in", "self", ".", "noises", "]", ")", "\n", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.VectorizedActionNoise.base_noise": [[141, 148], ["ValueError", "isinstance", "TypeError"], "methods", ["None"], ["", "@", "base_noise", ".", "setter", "\n", "def", "base_noise", "(", "self", ",", "base_noise", ":", "ActionNoise", ")", "->", "None", ":", "\n", "        ", "if", "base_noise", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Expected base_noise to be an instance of ActionNoise, not None\"", ",", "ActionNoise", ")", "\n", "", "if", "not", "isinstance", "(", "base_noise", ",", "ActionNoise", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Expected base_noise to be an instance of type ActionNoise\"", ",", "ActionNoise", ")", "\n", "", "self", ".", "_base_noise", "=", "base_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.noise.VectorizedActionNoise.noises": [[153, 168], ["list", "len", "len", "ValueError", "noise.reset", "len", "enumerate", "type", "isinstance", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "@", "noises", ".", "setter", "\n", "def", "noises", "(", "self", ",", "noises", ":", "List", "[", "ActionNoise", "]", ")", "->", "None", ":", "\n", "        ", "noises", "=", "list", "(", "noises", ")", "# raises TypeError if not iterable", "\n", "assert", "len", "(", "noises", ")", "==", "self", ".", "n_envs", ",", "f\"Expected a list of {self.n_envs} ActionNoises, found {len(noises)}.\"", "\n", "\n", "different_types", "=", "[", "i", "for", "i", ",", "noise", "in", "enumerate", "(", "noises", ")", "if", "not", "isinstance", "(", "noise", ",", "type", "(", "self", ".", "base_noise", ")", ")", "]", "\n", "\n", "if", "len", "(", "different_types", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Noise instances at indices {different_types} don't match the type of base_noise\"", ",", "type", "(", "self", ".", "base_noise", ")", "\n", ")", "\n", "\n", "", "self", ".", "_noises", "=", "noises", "\n", "for", "noise", "in", "noises", ":", "\n", "            ", "noise", ".", "reset", "(", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.unwrap_wrapper": [[11, 25], ["isinstance", "isinstance"], "function", ["None"], ["def", "unwrap_wrapper", "(", "env", ":", "gym", ".", "Env", ",", "wrapper_class", ":", "Type", "[", "gym", ".", "Wrapper", "]", ")", "->", "Optional", "[", "gym", ".", "Wrapper", "]", ":", "\n", "    ", "\"\"\"\n    Retrieve a ``VecEnvWrapper`` object by recursively searching.\n\n    :param env: Environment to unwrap\n    :param wrapper_class: Wrapper to look for\n    :return: Environment unwrapped till ``wrapper_class`` if it has been wrapped with it\n    \"\"\"", "\n", "env_tmp", "=", "env", "\n", "while", "isinstance", "(", "env_tmp", ",", "gym", ".", "Wrapper", ")", ":", "\n", "        ", "if", "isinstance", "(", "env_tmp", ",", "wrapper_class", ")", ":", "\n", "            ", "return", "env_tmp", "\n", "", "env_tmp", "=", "env_tmp", ".", "env", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.is_wrapped": [[27, 36], ["env_util.unwrap_wrapper"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.unwrap_wrapper"], ["", "def", "is_wrapped", "(", "env", ":", "Type", "[", "gym", ".", "Env", "]", ",", "wrapper_class", ":", "Type", "[", "gym", ".", "Wrapper", "]", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Check if a given environment has been wrapped with a given wrapper.\n\n    :param env: Environment to check\n    :param wrapper_class: Wrapper class to look for\n    :return: True if environment has been wrapped with ``wrapper_class``.\n    \"\"\"", "\n", "return", "unwrap_wrapper", "(", "env", ",", "wrapper_class", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.make_vec_env": [[38, 103], ["vec_env_cls", "isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.monitor.Monitor", "env_util.make_vec_env.make_env"], "function", ["None"], ["", "def", "make_vec_env", "(", "\n", "env_id", ":", "Union", "[", "str", ",", "Type", "[", "gym", ".", "Env", "]", "]", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "start_index", ":", "int", "=", "0", ",", "\n", "monitor_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "wrapper_class", ":", "Optional", "[", "Callable", "[", "[", "gym", ".", "Env", "]", ",", "gym", ".", "Env", "]", "]", "=", "None", ",", "\n", "env_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "vec_env_cls", ":", "Optional", "[", "Type", "[", "Union", "[", "DummyVecEnv", ",", "SubprocVecEnv", "]", "]", "]", "=", "None", ",", "\n", "vec_env_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "monitor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", "->", "VecEnv", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored ``VecEnv``.\n    By default it uses a ``DummyVecEnv`` which is usually faster\n    than a ``SubprocVecEnv``.\n\n    :param env_id: the environment ID or the environment class\n    :param n_envs: the number of environments you wish to have in parallel\n    :param seed: the initial seed for the random number generator\n    :param start_index: start rank index\n    :param monitor_dir: Path to a folder where the monitor files will be saved.\n        If None, no file will be written, however, the env will still be wrapped\n        in a Monitor wrapper to provide additional information about training.\n    :param wrapper_class: Additional wrapper to use on the environment.\n        This can also be a function with single argument that wraps the environment in many things.\n    :param env_kwargs: Optional keyword argument to pass to the env constructor\n    :param vec_env_cls: A custom ``VecEnv`` class constructor. Default: None.\n    :param vec_env_kwargs: Keyword arguments to pass to the ``VecEnv`` class constructor.\n    :param monitor_kwargs: Keyword arguments to pass to the ``Monitor`` class constructor.\n    :return: The wrapped environment\n    \"\"\"", "\n", "env_kwargs", "=", "{", "}", "if", "env_kwargs", "is", "None", "else", "env_kwargs", "\n", "vec_env_kwargs", "=", "{", "}", "if", "vec_env_kwargs", "is", "None", "else", "vec_env_kwargs", "\n", "monitor_kwargs", "=", "{", "}", "if", "monitor_kwargs", "is", "None", "else", "monitor_kwargs", "\n", "\n", "def", "make_env", "(", "rank", ")", ":", "\n", "        ", "def", "_init", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "env_id", ",", "str", ")", ":", "\n", "                ", "env", "=", "gym", ".", "make", "(", "env_id", ",", "**", "env_kwargs", ")", "\n", "", "else", ":", "\n", "                ", "env", "=", "env_id", "(", "**", "env_kwargs", ")", "\n", "", "if", "seed", "is", "not", "None", ":", "\n", "                ", "env", ".", "seed", "(", "seed", "+", "rank", ")", "\n", "env", ".", "action_space", ".", "seed", "(", "seed", "+", "rank", ")", "\n", "# Wrap the env in a Monitor wrapper", "\n", "# to have additional training information", "\n", "", "monitor_path", "=", "os", ".", "path", ".", "join", "(", "monitor_dir", ",", "str", "(", "rank", ")", ")", "if", "monitor_dir", "is", "not", "None", "else", "None", "\n", "# Create the monitor folder if needed", "\n", "if", "monitor_path", "is", "not", "None", ":", "\n", "                ", "os", ".", "makedirs", "(", "monitor_dir", ",", "exist_ok", "=", "True", ")", "\n", "", "env", "=", "Monitor", "(", "env", ",", "filename", "=", "monitor_path", ",", "**", "monitor_kwargs", ")", "\n", "# Optionally, wrap the environment with the provided wrapper", "\n", "if", "wrapper_class", "is", "not", "None", ":", "\n", "                ", "env", "=", "wrapper_class", "(", "env", ")", "\n", "", "return", "env", "\n", "\n", "", "return", "_init", "\n", "\n", "# No custom VecEnv is passed", "\n", "", "if", "vec_env_cls", "is", "None", ":", "\n", "# Default: use a DummyVecEnv", "\n", "        ", "vec_env_cls", "=", "DummyVecEnv", "\n", "\n", "", "return", "vec_env_cls", "(", "[", "make_env", "(", "i", "+", "start_index", ")", "for", "i", "in", "range", "(", "n_envs", ")", "]", ",", "**", "vec_env_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.make_atari_env": [[105, 153], ["env_util.make_vec_env", "gym_optimal_intrusion_response.agents.openai_baselines.common.atari_wrappers.AtariWrapper"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.make_vec_env"], ["", "def", "make_atari_env", "(", "\n", "env_id", ":", "Union", "[", "str", ",", "Type", "[", "gym", ".", "Env", "]", "]", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "start_index", ":", "int", "=", "0", ",", "\n", "monitor_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "wrapper_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "env_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "vec_env_cls", ":", "Optional", "[", "Union", "[", "DummyVecEnv", ",", "SubprocVecEnv", "]", "]", "=", "None", ",", "\n", "vec_env_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "monitor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", "->", "VecEnv", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored VecEnv for Atari.\n    It is a wrapper around ``make_vec_env`` that includes common preprocessing for Atari games.\n\n    :param env_id: the environment ID or the environment class\n    :param n_envs: the number of environments you wish to have in parallel\n    :param seed: the initial seed for the random number generator\n    :param start_index: start rank index\n    :param monitor_dir: Path to a folder where the monitor files will be saved.\n        If None, no file will be written, however, the env will still be wrapped\n        in a Monitor wrapper to provide additional information about training.\n    :param wrapper_kwargs: Optional keyword argument to pass to the ``AtariWrapper``\n    :param env_kwargs: Optional keyword argument to pass to the env constructor\n    :param vec_env_cls: A custom ``VecEnv`` class constructor. Default: None.\n    :param vec_env_kwargs: Keyword arguments to pass to the ``VecEnv`` class constructor.\n    :param monitor_kwargs: Keyword arguments to pass to the ``Monitor`` class constructor.\n    :return: The wrapped environment\n    \"\"\"", "\n", "if", "wrapper_kwargs", "is", "None", ":", "\n", "        ", "wrapper_kwargs", "=", "{", "}", "\n", "\n", "", "def", "atari_wrapper", "(", "env", ":", "gym", ".", "Env", ")", "->", "gym", ".", "Env", ":", "\n", "        ", "env", "=", "AtariWrapper", "(", "env", ",", "**", "wrapper_kwargs", ")", "\n", "return", "env", "\n", "\n", "", "return", "make_vec_env", "(", "\n", "env_id", ",", "\n", "n_envs", "=", "n_envs", ",", "\n", "seed", "=", "seed", ",", "\n", "start_index", "=", "start_index", ",", "\n", "monitor_dir", "=", "monitor_dir", ",", "\n", "wrapper_class", "=", "atari_wrapper", ",", "\n", "env_kwargs", "=", "env_kwargs", ",", "\n", "vec_env_cls", "=", "vec_env_cls", ",", "\n", "vec_env_kwargs", "=", "vec_env_kwargs", ",", "\n", "monitor_kwargs", "=", "monitor_kwargs", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._is_numpy_array_space": [[11, 17], ["isinstance"], "function", ["None"], ["def", "_is_numpy_array_space", "(", "space", ":", "spaces", ".", "Space", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Returns False if provided space is not representable as a single numpy array\n    (e.g. Dict and Tuple spaces return False)\n    \"\"\"", "\n", "return", "not", "isinstance", "(", "space", ",", "(", "spaces", ".", "Dict", ",", "spaces", ".", "Tuple", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_image_input": [[19, 43], ["warnings.warn", "numpy.any", "numpy.any", "warnings.warn", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "_check_image_input", "(", "observation_space", ":", "spaces", ".", "Box", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Check that the input will be compatible with Stable-Baselines\n    when the observation is apparently an image.\n    \"\"\"", "\n", "if", "observation_space", ".", "dtype", "!=", "np", ".", "uint8", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"It seems that your observation is an image but the `dtype` \"", "\n", "\"of your observation_space is not `np.uint8`. \"", "\n", "\"If your observation is not an image, we recommend you to flatten the observation \"", "\n", "\"to have only a 1D vector\"", "\n", ")", "\n", "\n", "", "if", "np", ".", "any", "(", "observation_space", ".", "low", "!=", "0", ")", "or", "np", ".", "any", "(", "observation_space", ".", "high", "!=", "255", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"It seems that your observation space is an image but the \"", "\n", "\"upper and lower bounds are not in [0, 255]. \"", "\n", "\"Because the CNN policy normalize automatically the observation \"", "\n", "\"you may encounter issue if the values are not in that range.\"", "\n", ")", "\n", "\n", "", "if", "observation_space", ".", "shape", "[", "0", "]", "<", "36", "or", "observation_space", ".", "shape", "[", "1", "]", "<", "36", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"The minimal resolution for an image is 36x36 for the default CnnPolicy. \"", "\n", "\"You might need to use a custom `cnn_extractor` \"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_unsupported_spaces": [[48, 71], ["isinstance", "isinstance", "warnings.warn", "warnings.warn", "env_checker._is_numpy_array_space", "warnings.warn", "isinstance"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._is_numpy_array_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "", "def", "_check_unsupported_spaces", "(", "env", ":", "gym", ".", "Env", ",", "observation_space", ":", "spaces", ".", "Space", ",", "action_space", ":", "spaces", ".", "Space", ")", "->", "None", ":", "\n", "    ", "\"\"\"Emit warnings when the observation space or action space used is not supported by Stable-Baselines.\"\"\"", "\n", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Dict", ")", "and", "not", "isinstance", "(", "env", ",", "gym", ".", "GoalEnv", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"The observation space is a Dict but the environment is not a gym.GoalEnv \"", "\n", "\"(cf https://github.com/openai/gym/blob/master/gym/core.py), \"", "\n", "\"this is currently not supported by Stable Baselines \"", "\n", "\"(cf https://github.com/hill-a/stable-baselines/issues/133), \"", "\n", "\"you will need to use a custom policy. \"", "\n", ")", "\n", "\n", "", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"The observation space is a Tuple,\"", "\n", "\"this is currently not supported by Stable Baselines \"", "\n", "\"(cf https://github.com/hill-a/stable-baselines/issues/133), \"", "\n", "\"you will need to flatten the observation and maybe use a custom policy. \"", "\n", ")", "\n", "\n", "", "if", "not", "_is_numpy_array_space", "(", "action_space", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"The action space is not based off a numpy array. Typically this means it's either a Dict or Tuple space. \"", "\n", "\"This type of action space is currently not supported by Stable Baselines 3. You should try to flatten the \"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_nan": [[76, 82], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.VecCheckNan", "range", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.DummyVecEnv", "numpy.array", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.VecCheckNan.step", "env.action_space.sample"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "", "def", "_check_nan", "(", "env", ":", "gym", ".", "Env", ")", "->", "None", ":", "\n", "    ", "\"\"\"Check for Inf and NaN using the VecWrapper.\"\"\"", "\n", "vec_env", "=", "VecCheckNan", "(", "DummyVecEnv", "(", "[", "lambda", ":", "env", "]", ")", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "        ", "action", "=", "np", ".", "array", "(", "[", "env", ".", "action_space", ".", "sample", "(", ")", "]", ")", "\n", "_", ",", "_", ",", "_", ",", "_", "=", "vec_env", ".", "step", "(", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_obs": [[84, 105], ["isinstance", "observation_space.contains", "isinstance", "isinstance", "env_checker._is_numpy_array_space", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._is_numpy_array_space"], ["", "", "def", "_check_obs", "(", "obs", ":", "Union", "[", "tuple", ",", "dict", ",", "np", ".", "ndarray", ",", "int", "]", ",", "observation_space", ":", "spaces", ".", "Space", ",", "method_name", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Check that the observation returned by the environment\n    correspond to the declared one.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "observation_space", ",", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "assert", "not", "isinstance", "(", "\n", "obs", ",", "tuple", "\n", ")", ",", "\"The observation returned by the `{}()` method should be a single value, not a tuple\"", ".", "format", "(", "method_name", ")", "\n", "\n", "# The check for a GoalEnv is done by the base class", "\n", "", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "        ", "assert", "isinstance", "(", "obs", ",", "int", ")", ",", "\"The observation returned by `{}()` method must be an int\"", ".", "format", "(", "method_name", ")", "\n", "", "elif", "_is_numpy_array_space", "(", "observation_space", ")", ":", "\n", "        ", "assert", "isinstance", "(", "obs", ",", "np", ".", "ndarray", ")", ",", "\"The observation returned by `{}()` method must be a numpy array\"", ".", "format", "(", "\n", "method_name", "\n", ")", "\n", "\n", "", "assert", "observation_space", ".", "contains", "(", "\n", "obs", "\n", ")", ",", "\"The observation returned by the `{}()` method does not match the given observation space\"", ".", "format", "(", "method_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_returned_values": [[107, 135], ["env.reset", "env_checker._check_obs", "action_space.sample", "env.step", "env_checker._check_obs", "isinstance", "isinstance", "isinstance", "isinstance", "len", "env.compute_reward"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.compute_reward"], ["", "def", "_check_returned_values", "(", "env", ":", "gym", ".", "Env", ",", "observation_space", ":", "spaces", ".", "Space", ",", "action_space", ":", "spaces", ".", "Space", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Check the returned values by the env when calling `.reset()` or `.step()` methods.\n    \"\"\"", "\n", "# because env inherits from gym.Env, we assume that `reset()` and `step()` methods exists", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "_check_obs", "(", "obs", ",", "observation_space", ",", "\"reset\"", ")", "\n", "\n", "# Sample a random action", "\n", "action", "=", "action_space", ".", "sample", "(", ")", "\n", "data", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "assert", "len", "(", "data", ")", "==", "4", ",", "\"The `step()` method must return four values: obs, reward, done, info\"", "\n", "\n", "# Unpack", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "data", "\n", "\n", "_check_obs", "(", "obs", ",", "observation_space", ",", "\"step\"", ")", "\n", "\n", "# We also allow int because the reward will be cast to float", "\n", "assert", "isinstance", "(", "reward", ",", "(", "float", ",", "int", ")", ")", ",", "\"The reward returned by `step()` must be a float\"", "\n", "assert", "isinstance", "(", "done", ",", "bool", ")", ",", "\"The `done` signal must be a boolean\"", "\n", "assert", "isinstance", "(", "info", ",", "dict", ")", ",", "\"The `info` returned by `step()` must be a python dictionary\"", "\n", "\n", "if", "isinstance", "(", "env", ",", "gym", ".", "GoalEnv", ")", ":", "\n", "# For a GoalEnv, the keys are checked at reset", "\n", "        ", "assert", "reward", "==", "env", ".", "compute_reward", "(", "obs", "[", "\"achieved_goal\"", "]", ",", "obs", "[", "\"desired_goal\"", "]", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_spaces": [[137, 150], ["hasattr", "hasattr", "isinstance", "isinstance"], "function", ["None"], ["", "", "def", "_check_spaces", "(", "env", ":", "gym", ".", "Env", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Check that the observation and action spaces are defined\n    and inherit from gym.spaces.Space.\n    \"\"\"", "\n", "# Helper to link to the code, because gym has no proper documentation", "\n", "gym_spaces", "=", "\" cf https://github.com/openai/gym/blob/master/gym/spaces/\"", "\n", "\n", "assert", "hasattr", "(", "env", ",", "\"observation_space\"", ")", ",", "\"You must specify an observation space (cf gym.spaces)\"", "+", "gym_spaces", "\n", "assert", "hasattr", "(", "env", ",", "\"action_space\"", ")", ",", "\"You must specify an action space (cf gym.spaces)\"", "+", "gym_spaces", "\n", "\n", "assert", "isinstance", "(", "env", ".", "observation_space", ",", "spaces", ".", "Space", ")", ",", "\"The observation space must inherit from gym.spaces\"", "+", "gym_spaces", "\n", "assert", "isinstance", "(", "env", ".", "action_space", ",", "spaces", ".", "Space", ")", ",", "\"The action space must inherit from gym.spaces\"", "+", "gym_spaces", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_render": [[152, 180], ["env.metadata.get", "env.close", "warnings.warn", "env.metadata.get.remove", "env.render"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render"], ["", "def", "_check_render", "(", "env", ":", "gym", ".", "Env", ",", "warn", ":", "bool", "=", "True", ",", "headless", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Check the declared render modes and the `render()`/`close()`\n    method of the environment.\n\n    :param env: The environment to check\n    :param warn: Whether to output additional warnings\n    :param headless: Whether to disable render modes\n        that require a graphical interface. False by default.\n    \"\"\"", "\n", "render_modes", "=", "env", ".", "metadata", ".", "get", "(", "\"render.modes\"", ")", "\n", "if", "render_modes", "is", "None", ":", "\n", "        ", "if", "warn", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"No render modes was declared in the environment \"", "\n", "\" (env.metadata['render.modes'] is None or not defined), \"", "\n", "\"you may have trouble when calling `.render()`\"", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "# Don't check render mode that require a", "\n", "# graphical interface (useful for CI)", "\n", "        ", "if", "headless", "and", "\"human\"", "in", "render_modes", ":", "\n", "            ", "render_modes", ".", "remove", "(", "\"human\"", ")", "\n", "# Check all declared render modes", "\n", "", "for", "render_mode", "in", "render_modes", ":", "\n", "            ", "env", ".", "render", "(", "mode", "=", "render_mode", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker.check_env": [[182, 246], ["isinstance", "env_checker._check_spaces", "env_checker._check_returned_values", "env_checker._check_unsupported_spaces", "env_checker._check_render", "env_checker._is_numpy_array_space", "env_checker._is_numpy_array_space", "env_checker._check_nan", "isinstance", "env_checker._check_image_input", "isinstance", "warnings.warn", "isinstance", "warnings.warn", "len", "len", "numpy.any", "numpy.any", "numpy.any", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_spaces", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_returned_values", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_unsupported_spaces", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_render", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._is_numpy_array_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._is_numpy_array_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_nan", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_checker._check_image_input", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "", "def", "check_env", "(", "env", ":", "gym", ".", "Env", ",", "warn", ":", "bool", "=", "True", ",", "skip_render_check", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Check that an environment follows Gym API.\n    This is particularly useful when using a custom environment.\n    Please take a look at https://github.com/openai/gym/blob/master/gym/core.py\n    for more information about the API.\n\n    It also optionally check that the environment is compatible with Stable-Baselines.\n\n    :param env: The Gym environment that will be checked\n    :param warn: Whether to output additional warnings\n        mainly related to the interaction with Stable Baselines\n    :param skip_render_check: Whether to skip the checks for the render method.\n        True by default (useful for the CI)\n    \"\"\"", "\n", "assert", "isinstance", "(", "\n", "env", ",", "gym", ".", "Env", "\n", ")", ",", "\"Your environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py\"", "\n", "\n", "# ============= Check the spaces (observation and action) ================", "\n", "_check_spaces", "(", "env", ")", "\n", "\n", "# Define aliases for convenience", "\n", "observation_space", "=", "env", ".", "observation_space", "\n", "action_space", "=", "env", ".", "action_space", "\n", "\n", "# Warn the user if needed.", "\n", "# A warning means that the environment may run but not work properly with Stable Baselines algorithms", "\n", "if", "warn", ":", "\n", "        ", "_check_unsupported_spaces", "(", "env", ",", "observation_space", ",", "action_space", ")", "\n", "\n", "# If image, check the low and high values, the type and the number of channels", "\n", "# and the shape (minimal value)", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Box", ")", "and", "len", "(", "observation_space", ".", "shape", ")", "==", "3", ":", "\n", "            ", "_check_image_input", "(", "observation_space", ")", "\n", "\n", "", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Box", ")", "and", "len", "(", "observation_space", ".", "shape", ")", "not", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Your observation has an unconventional shape (neither an image, nor a 1D vector). \"", "\n", "\"We recommend you to flatten the observation \"", "\n", "\"to have only a 1D vector\"", "\n", ")", "\n", "\n", "# Check for the action space, it may lead to hard-to-debug issues", "\n", "", "if", "isinstance", "(", "action_space", ",", "spaces", ".", "Box", ")", "and", "(", "\n", "np", ".", "any", "(", "np", ".", "abs", "(", "action_space", ".", "low", ")", "!=", "np", ".", "abs", "(", "action_space", ".", "high", ")", ")", "\n", "or", "np", ".", "any", "(", "np", ".", "abs", "(", "action_space", ".", "low", ")", ">", "1", ")", "\n", "or", "np", ".", "any", "(", "np", ".", "abs", "(", "action_space", ".", "high", ")", ">", "1", ")", "\n", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"", "\n", "\"cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\"", "\n", ")", "\n", "\n", "# ============ Check the returned values ===============", "\n", "", "", "_check_returned_values", "(", "env", ",", "observation_space", ",", "action_space", ")", "\n", "\n", "# ==== Check the render method and the declared render modes ====", "\n", "if", "not", "skip_render_check", ":", "\n", "        ", "_check_render", "(", "env", ",", "warn", "=", "warn", ")", "\n", "\n", "# The check only works with numpy arrays", "\n", "", "if", "_is_numpy_array_space", "(", "observation_space", ")", "and", "_is_numpy_array_space", "(", "action_space", ")", ":", "\n", "        ", "_check_nan", "(", "env", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.__init__": [[47, 79], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "features_extractor_class", ":", "Type", "[", "BaseFeaturesExtractor", "]", "=", "FlattenExtractor", ",", "\n", "features_extractor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "features_extractor", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "normalize_images", ":", "bool", "=", "True", ",", "\n", "optimizer_class", ":", "Type", "[", "th", ".", "optim", ".", "Optimizer", "]", "=", "th", ".", "optim", ".", "Adam", ",", "\n", "optimizer_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "agent_config", ":", "AgentConfig", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "optimizer_kwargs", "is", "None", ":", "\n", "            ", "optimizer_kwargs", "=", "{", "}", "\n", "\n", "", "if", "features_extractor_kwargs", "is", "None", ":", "\n", "            ", "features_extractor_kwargs", "=", "{", "}", "\n", "\n", "", "self", ".", "observation_space", "=", "observation_space", "\n", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "features_extractor", "=", "features_extractor", "\n", "self", ".", "normalize_images", "=", "normalize_images", "\n", "\n", "self", ".", "optimizer_class", "=", "optimizer_class", "\n", "self", ".", "optimizer_kwargs", "=", "optimizer_kwargs", "\n", "self", ".", "optimizer", "=", "None", "# type: Optional[th.optim.Optimizer]", "\n", "\n", "self", ".", "features_extractor_class", "=", "features_extractor_class", "\n", "self", ".", "features_extractor_kwargs", "=", "features_extractor_kwargs", "\n", "self", ".", "agent_config", "=", "agent_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.forward": [[80, 83], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel._update_features_extractor": [[84, 103], ["net_kwargs.copy.copy.copy", "net_kwargs.copy.copy.update", "policies.BaseModel.make_features_extractor", "dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.make_features_extractor"], ["", "def", "_update_features_extractor", "(", "\n", "self", ",", "net_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "features_extractor", ":", "Optional", "[", "BaseFeaturesExtractor", "]", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Update the network keyword arguments and create a new features extractor object if needed.\n        If a ``features_extractor`` object is passed, then it will be shared.\n\n        :param net_kwargs: the base network keyword arguments, without the ones\n            related to features extractor\n        :param features_extractor: a features extractor object.\n            If None, a new object will be created.\n        :return: The updated keyword arguments\n        \"\"\"", "\n", "net_kwargs", "=", "net_kwargs", ".", "copy", "(", ")", "\n", "if", "features_extractor", "is", "None", ":", "\n", "# The features extractor is not shared, create a new one", "\n", "            ", "features_extractor", "=", "self", ".", "make_features_extractor", "(", ")", "\n", "", "net_kwargs", ".", "update", "(", "dict", "(", "features_extractor", "=", "features_extractor", ",", "features_dim", "=", "features_extractor", ".", "features_dim", ")", ")", "\n", "return", "net_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.make_features_extractor": [[104, 107], ["policies.BaseModel.features_extractor_class"], "methods", ["None"], ["", "def", "make_features_extractor", "(", "self", ")", "->", "BaseFeaturesExtractor", ":", "\n", "        ", "\"\"\"Helper method to create a features extractor.\"\"\"", "\n", "return", "self", ".", "features_extractor_class", "(", "self", ".", "observation_space", ",", "**", "self", ".", "features_extractor_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.extract_features": [[108, 118], ["gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.preprocess_obs", "policies.BaseModel.features_extractor"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.preprocess_obs"], ["", "def", "extract_features", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Preprocess the observation if needed and extract features.\n\n        :param obs:\n        :return:\n        \"\"\"", "\n", "assert", "self", ".", "features_extractor", "is", "not", "None", ",", "\"No features extractor was set\"", "\n", "preprocessed_obs", "=", "preprocess_obs", "(", "obs", ",", "self", ".", "observation_space", ",", "normalize_images", "=", "self", ".", "normalize_images", ")", "\n", "return", "self", ".", "features_extractor", "(", "preprocessed_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel._get_constructor_parameters": [[119, 132], ["dict"], "methods", ["None"], ["", "def", "_get_constructor_parameters", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Get data that need to be saved in order to re-create the model when loading it from disk.\n\n        :return: The dictionary to pass to the as kwargs constructor when reconstruction this model.\n        \"\"\"", "\n", "return", "dict", "(", "\n", "observation_space", "=", "self", ".", "observation_space", ",", "\n", "action_space", "=", "self", ".", "action_space", ",", "\n", "# Passed to the constructor by child class", "\n", "# squash_output=self.squash_output,", "\n", "# features_extractor=self.features_extractor", "\n", "normalize_images", "=", "self", ".", "normalize_images", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.device": [[134, 143], ["policies.BaseModel.parameters", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.get_device"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_device"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "th", ".", "device", ":", "\n", "        ", "\"\"\"Infer which device this policy lives on by inspecting its parameters.\n        If it has no parameters, the 'cpu' device is used as a fallback.\n\n        :return:\"\"\"", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "return", "param", ".", "device", "\n", "", "return", "get_device", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.save": [[144, 151], ["torch.save", "policies.BaseModel.state_dict", "policies.BaseModel._get_constructor_parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_constructor_parameters"], ["", "def", "save", "(", "self", ",", "path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save model to a given location.\n\n        :param path:\n        \"\"\"", "\n", "th", ".", "save", "(", "{", "\"state_dict\"", ":", "self", ".", "state_dict", "(", ")", ",", "\"data\"", ":", "self", ".", "_get_constructor_parameters", "(", ")", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.load": [[152, 169], ["gym_optimal_intrusion_response.agents.openai_baselines.common.utils.get_device", "torch.load", "cls", "cls.load_state_dict", "cls.to"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_device", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "path", ":", "str", ",", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ")", "->", "\"BaseModel\"", ":", "\n", "        ", "\"\"\"\n        Load model from path.\n\n        :param path:\n        :param device: Device on which the policy should be loaded.\n        :return:\n        \"\"\"", "\n", "device", "=", "get_device", "(", "device", ")", "\n", "saved_variables", "=", "th", ".", "load", "(", "path", ",", "map_location", "=", "device", ")", "\n", "# Create policy object", "\n", "model", "=", "cls", "(", "**", "saved_variables", "[", "\"data\"", "]", ")", "# pytype: disable=not-instantiable", "\n", "# Load weights", "\n", "model", ".", "load_state_dict", "(", "saved_variables", "[", "\"state_dict\"", "]", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.load_from_vector": [[170, 177], ["torch.nn.utils.vector_to_parameters", "torch.FloatTensor().to", "policies.BaseModel.parameters", "torch.FloatTensor"], "methods", ["None"], ["", "def", "load_from_vector", "(", "self", ",", "vector", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Load parameters from a 1D vector.\n\n        :param vector:\n        \"\"\"", "\n", "th", ".", "nn", ".", "utils", ".", "vector_to_parameters", "(", "th", ".", "FloatTensor", "(", "vector", ")", ".", "to", "(", "self", ".", "device", ")", ",", "self", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.parameters_to_vector": [[178, 185], ["torch.nn.utils.parameters_to_vector().detach().cpu().numpy", "torch.nn.utils.parameters_to_vector().detach().cpu", "torch.nn.utils.parameters_to_vector().detach", "torch.nn.utils.parameters_to_vector", "policies.BaseModel.parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.parameters_to_vector"], ["", "def", "parameters_to_vector", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Convert the parameters to a 1D vector.\n\n        :return:\n        \"\"\"", "\n", "return", "th", ".", "nn", ".", "utils", ".", "parameters_to_vector", "(", "self", ".", "parameters", "(", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.__init__": [[198, 201], ["policies.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "squash_output", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BasePolicy", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_squash_output", "=", "squash_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy._dummy_schedule": [[202, 207], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_dummy_schedule", "(", "progress_remaining", ":", "float", ")", "->", "float", ":", "\n", "        ", "\"\"\"(float) Useful for pickling policy.\"\"\"", "\n", "del", "progress_remaining", "\n", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.squash_output": [[208, 212], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "squash_output", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"(bool) Getter for squash_output.\"\"\"", "\n", "return", "self", ".", "_squash_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.init_weights": [[213, 222], ["isinstance", "torch.nn.init.orthogonal_", "module.bias.data.fill_"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "init_weights", "(", "module", ":", "nn", ".", "Module", ",", "gain", ":", "float", "=", "1", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Orthogonal initialization (used in PPO and A2C)\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "            ", "nn", ".", "init", ".", "orthogonal_", "(", "module", ".", "weight", ",", "gain", "=", "gain", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy._predict": [[223, 227], ["None"], "methods", ["None"], ["", "", "", "@", "abstractmethod", "\n", "def", "_predict", "(", "self", ",", "observation", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ",", "attacker", ":", "bool", "=", "True", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.predict": [[228, 249], ["numpy.array", "torch.as_tensor().to.reshape", "torch.as_tensor().to", "torch.no_grad", "policies.BasePolicy._predict", "type", "actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor", "actions.cpu().numpy.cpu().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._predict"], ["", "def", "predict", "(", "\n", "self", ",", "\n", "observation", ":", "np", ".", "ndarray", ",", "\n", "state", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "mask", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "deterministic", ":", "bool", "=", "False", ",", "\n", "attacker", ":", "bool", "=", "True", ",", "\n", "env", "=", "None", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "Optional", "[", "np", ".", "ndarray", "]", "]", ":", "\n", "\n", "        ", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "self", ".", "observation_space", ".", "shape", ")", "\n", "observation", "=", "th", ".", "as_tensor", "(", "observation", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "            ", "actions", "=", "self", ".", "_predict", "(", "observation", ",", "deterministic", "=", "deterministic", ",", "attacker", "=", "attacker", ",", "env", "=", "env", ")", "\n", "\n", "", "if", "type", "(", "actions", ")", "==", "th", ".", "Tensor", ":", "\n", "# Convert to numpy", "\n", "            ", "actions", "=", "actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "actions", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.scale_action": [[250, 260], ["None"], "methods", ["None"], ["", "def", "scale_action", "(", "self", ",", "action", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Rescale the action from [low, high] to [-1, 1]\n        (no need for symmetric action space)\n\n        :param action: Action to scale\n        :return: Scaled action\n        \"\"\"", "\n", "low", ",", "high", "=", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", "\n", "return", "2.0", "*", "(", "(", "action", "-", "low", ")", "/", "(", "high", "-", "low", ")", ")", "-", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.unscale_action": [[261, 270], ["None"], "methods", ["None"], ["", "def", "unscale_action", "(", "self", ",", "scaled_action", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Rescale the action from [-1, 1] to [low, high]\n        (no need for symmetric action space)\n\n        :param scaled_action: Action to un-scale\n        \"\"\"", "\n", "low", ",", "high", "=", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", "\n", "return", "low", "+", "(", "0.5", "*", "(", "scaled_action", "+", "1.0", ")", "*", "(", "high", "-", "low", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy.__init__": [[273, 332], ["policies.BasePolicy.__init__", "features_extractor_class", "gym_optimal_intrusion_response.agents.openai_baselines.common.distributions.make_proba_distribution", "policies.ActorCriticPolicy._build", "dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.make_proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._build"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "lr", ":", "float", ",", "\n", "net_arch", ":", "Optional", "[", "List", "[", "Union", "[", "int", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "]", "]", "=", "None", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "Tanh", ",", "\n", "ortho_init", ":", "bool", "=", "True", ",", "\n", "log_std_init", ":", "float", "=", "0.0", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "features_extractor_class", ":", "Type", "[", "BaseFeaturesExtractor", "]", "=", "FlattenExtractor", ",", "\n", "features_extractor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "normalize_images", ":", "bool", "=", "True", ",", "\n", "optimizer_class", ":", "Type", "[", "th", ".", "optim", ".", "Optimizer", "]", "=", "th", ".", "optim", ".", "Adam", ",", "\n", "optimizer_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "agent_config", ":", "AgentConfig", "=", "None", "\n", ")", ":", "\n", "\n", "        ", "if", "optimizer_kwargs", "is", "None", ":", "\n", "            ", "optimizer_kwargs", "=", "{", "}", "\n", "# Small values to avoid NaN in Adam optimizer", "\n", "if", "optimizer_class", "==", "th", ".", "optim", ".", "Adam", ":", "\n", "                ", "optimizer_kwargs", "[", "\"eps\"", "]", "=", "1e-5", "\n", "\n", "", "", "super", "(", "ActorCriticPolicy", ",", "self", ")", ".", "__init__", "(", "\n", "observation_space", ",", "\n", "action_space", ",", "\n", "features_extractor_class", ",", "\n", "features_extractor_kwargs", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "optimizer_kwargs", "=", "optimizer_kwargs", ",", "\n", "squash_output", "=", "squash_output", ",", "\n", "agent_config", "=", "agent_config", "\n", ")", "\n", "\n", "# Default network architecture, from stable-baselines", "\n", "if", "net_arch", "is", "None", ":", "\n", "            ", "if", "features_extractor_class", "==", "FlattenExtractor", ":", "\n", "                ", "net_arch", "=", "[", "dict", "(", "pi", "=", "[", "64", ",", "64", "]", ",", "vf", "=", "[", "64", ",", "64", "]", ")", "]", "\n", "", "else", ":", "\n", "                ", "net_arch", "=", "[", "]", "\n", "\n", "", "", "self", ".", "net_arch", "=", "net_arch", "\n", "self", ".", "activation_fn", "=", "activation_fn", "\n", "self", ".", "ortho_init", "=", "ortho_init", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "features_extractor", "=", "features_extractor_class", "(", "self", ".", "observation_space", ",", "**", "self", ".", "features_extractor_kwargs", ")", "\n", "self", ".", "features_dim", "=", "self", ".", "features_extractor", ".", "features_dim", "\n", "\n", "self", ".", "normalize_images", "=", "normalize_images", "\n", "self", ".", "log_std_init", "=", "log_std_init", "\n", "dist_kwargs", "=", "None", "\n", "self", ".", "dist_kwargs", "=", "dist_kwargs", "\n", "\n", "# Action distribution", "\n", "self", ".", "action_dist", "=", "make_proba_distribution", "(", "action_space", ",", "dist_kwargs", "=", "dist_kwargs", ")", "\n", "\n", "self", ".", "_build", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_constructor_parameters": [[333, 355], ["policies.BaseModel._get_constructor_parameters", "super()._get_constructor_parameters.update", "collections.defaultdict", "dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_constructor_parameters", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update"], ["", "def", "_get_constructor_parameters", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "data", "=", "super", "(", ")", ".", "_get_constructor_parameters", "(", ")", "\n", "\n", "default_none_kwargs", "=", "self", ".", "dist_kwargs", "or", "collections", ".", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "\n", "data", ".", "update", "(", "\n", "dict", "(", "\n", "net_arch", "=", "self", ".", "net_arch", ",", "\n", "activation_fn", "=", "self", ".", "activation_fn", ",", "\n", "log_std_init", "=", "self", ".", "log_std_init", ",", "\n", "squash_output", "=", "default_none_kwargs", "[", "\"squash_output\"", "]", ",", "\n", "full_std", "=", "default_none_kwargs", "[", "\"full_std\"", "]", ",", "\n", "use_expln", "=", "default_none_kwargs", "[", "\"use_expln\"", "]", ",", "\n", "lr_schedule", "=", "self", ".", "_dummy_schedule", ",", "# dummy lr schedule, not needed for loading policy alone", "\n", "ortho_init", "=", "self", ".", "ortho_init", ",", "\n", "optimizer_class", "=", "self", ".", "optimizer_class", ",", "\n", "optimizer_kwargs", "=", "self", ".", "optimizer_kwargs", ",", "\n", "features_extractor_class", "=", "self", ".", "features_extractor_class", ",", "\n", "features_extractor_kwargs", "=", "self", ".", "features_extractor_kwargs", ",", "\n", ")", "\n", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._build_mlp_extractor": [[356, 366], ["gym_optimal_intrusion_response.agents.openai_baselines.common.torch_layers.MlpExtractor"], "methods", ["None"], ["", "def", "_build_mlp_extractor", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Create the policy and value networks.\n        Part of the layers can be shared.\n        \"\"\"", "\n", "# Note: If net_arch is None and some features extractor is used,", "\n", "#       net_arch here is an empty list and mlp_extractor does not", "\n", "#       really contain any layers (acts like an identity module).", "\n", "self", ".", "mlp_extractor", "=", "MlpExtractor", "(", "\n", "self", ".", "features_dim", ",", "net_arch", "=", "self", ".", "net_arch", ",", "activation_fn", "=", "self", ".", "activation_fn", ",", "device", "=", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._build": [[368, 393], ["policies.ActorCriticPolicy._build_mlp_extractor", "policies.ActorCriticPolicy.action_dist.proba_distribution_net", "torch.nn.Linear", "policies.ActorCriticPolicy.optimizer_class", "module_gains.items", "policies.ActorCriticPolicy.parameters", "numpy.sqrt", "numpy.sqrt", "module.apply", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._build_mlp_extractor", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution_net"], ["", "def", "_build", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_build_mlp_extractor", "(", ")", "\n", "\n", "latent_dim_pi", "=", "self", ".", "mlp_extractor", ".", "latent_dim_pi", "\n", "self", ".", "action_net", "=", "self", ".", "action_dist", ".", "proba_distribution_net", "(", "latent_dim", "=", "latent_dim_pi", ")", "\n", "\n", "self", ".", "value_net", "=", "nn", ".", "Linear", "(", "self", ".", "mlp_extractor", ".", "latent_dim_vf", ",", "1", ")", "\n", "# Init weights: use orthogonal initialization", "\n", "# with small initial weight for the output", "\n", "if", "self", ".", "ortho_init", ":", "\n", "# TODO: check for features_extractor", "\n", "# Values from stable-baselines.", "\n", "# features_extractor/mlp values are", "\n", "# originally from openai/baselines (default gains/init_scales).", "\n", "            ", "module_gains", "=", "{", "\n", "self", ".", "features_extractor", ":", "np", ".", "sqrt", "(", "2", ")", ",", "\n", "self", ".", "mlp_extractor", ":", "np", ".", "sqrt", "(", "2", ")", ",", "\n", "self", ".", "action_net", ":", "0.01", ",", "\n", "self", ".", "value_net", ":", "1", ",", "\n", "}", "\n", "for", "module", ",", "gain", "in", "module_gains", ".", "items", "(", ")", ":", "\n", "                ", "module", ".", "apply", "(", "partial", "(", "self", ".", "init_weights", ",", "gain", "=", "gain", ")", ")", "\n", "\n", "# Setup optimizer with initial learning rate", "\n", "", "", "self", ".", "optimizer", "=", "self", ".", "optimizer_class", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "**", "self", ".", "optimizer_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy.forward": [[394, 416], ["policies.ActorCriticPolicy._get_latent", "policies.ActorCriticPolicy.value_net", "policies.ActorCriticPolicy._get_action_dist_from_latent", "policies.ActorCriticPolicy.get_actions", "policies.ActorCriticPolicy.log_prob", "list", "range", "list", "list", "filter", "filter", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal"], ["", "def", "forward", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ",", "attacker", ":", "bool", "=", "True", ",", "env", "=", "None", ",", "\n", "filter_illegal", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "latent_pi", ",", "latent_vf", "=", "self", ".", "_get_latent", "(", "obs", ")", "\n", "values", "=", "self", ".", "value_net", "(", "latent_vf", ")", "\n", "if", "filter_illegal", ":", "\n", "            ", "env", "=", "env", ".", "envs", "[", "0", "]", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "agent_config", ".", "output_dim", ")", ")", "\n", "if", "attacker", ":", "\n", "                ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "OptimalIntrusionResponseEnv", ".", "is_attack_action_legal", "(", "\n", "a_id", "=", "action", ",", "env_config", "=", "env", ".", "env_config", ",", "env_state", "=", "env", ".", "env_state", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "                ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "OptimalIntrusionResponseEnv", ".", "is_defense_action_legal", "(", "\n", "d_id", "=", "action", ")", ",", "actions", ")", ")", "\n", "", "non_legal_actions", "=", "[", "non_legal_actions", "]", "\n", "", "else", ":", "\n", "            ", "non_legal_actions", "=", "[", "]", "\n", "\n", "", "distribution", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "actions", "=", "distribution", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "log_prob", "=", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "values", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_latent": [[417, 422], ["policies.ActorCriticPolicy.extract_features", "policies.ActorCriticPolicy.mlp_extractor"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.extract_features"], ["", "def", "_get_latent", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "features", "=", "self", ".", "extract_features", "(", "obs", ")", "\n", "latent_pi", ",", "latent_vf", "=", "self", ".", "mlp_extractor", "(", "features", ")", "\n", "\n", "return", "latent_pi", ",", "latent_vf", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_action_dist_from_latent": [[423, 440], ["policies.ActorCriticPolicy.action_net", "policies.ActorCriticPolicy.clone", "policies.ActorCriticPolicy.clone.to", "policies.ActorCriticPolicy.action_dist.proba_distribution", "range", "len", "len", "len", "len", "len", "AssertionError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution"], ["", "def", "_get_action_dist_from_latent", "(", "self", ",", "latent_pi", ":", "th", ".", "Tensor", ",", "non_legal_actions", "=", "None", ")", "->", "Distribution", ":", "\n", "        ", "mean_actions", "=", "self", ".", "action_net", "(", "latent_pi", ")", "\n", "\n", "action_logits", "=", "mean_actions", ".", "clone", "(", ")", "\n", "if", "non_legal_actions", "is", "not", "None", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "non_legal_actions", ")", ")", ":", "\n", "                ", "if", "non_legal_actions", "is", "not", "None", "and", "len", "(", "non_legal_actions", ")", ">", "0", "and", "len", "(", "non_legal_actions", "[", "i", "]", ")", ">", "0", ":", "\n", "                    ", "if", "len", "(", "action_logits", ".", "shape", ")", "==", "1", ":", "\n", "# action_probs_1[non_legal_actions] = 0.00000000000001 # Don't set to zero due to invalid distribution errors", "\n", "                        ", "action_logits", "[", "non_legal_actions", "[", "i", "]", "]", "=", "self", ".", "agent_config", ".", "illegal_action_logit", "\n", "", "elif", "len", "(", "action_logits", ".", "shape", ")", "==", "2", ":", "\n", "# action_probs_1[:, non_legal_actions] = 0.00000000000001  # Don't set to zero due to invalid distribution errors", "\n", "                        ", "action_logits", "[", "i", "]", "[", "non_legal_actions", "[", "i", "]", "]", "=", "self", ".", "agent_config", ".", "illegal_action_logit", "\n", "", "else", ":", "\n", "                        ", "raise", "AssertionError", "(", "\"Invalid shape of action probabilties\"", ")", "\n", "", "", "", "", "action_logits_1", "=", "action_logits", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "self", ".", "action_dist", ".", "proba_distribution", "(", "action_logits", "=", "action_logits_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._predict": [[441, 458], ["policies.ActorCriticPolicy._get_latent", "list", "policies.ActorCriticPolicy._get_action_dist_from_latent", "policies.ActorCriticPolicy.get_actions", "range", "list", "list", "filter", "filter", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal"], ["", "def", "_predict", "(", "self", ",", "observation", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ",", "attacker", ":", "bool", "=", "True", ",", "env", "=", "None", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "latent_pi", ",", "_", "=", "self", ".", "_get_latent", "(", "observation", ")", "\n", "\n", "env", "=", "env", ".", "envs", "[", "0", "]", "\n", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "agent_config", ".", "output_dim", ")", ")", "\n", "if", "attacker", ":", "\n", "            ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "OptimalIntrusionResponseEnv", ".", "is_attack_action_legal", "(", "\n", "a_id", "=", "action", ",", "env_config", "=", "env", ".", "env_config", ",", "env_state", "=", "env", ".", "env_state", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "            ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "OptimalIntrusionResponseEnv", ".", "is_defense_action_legal", "(", "\n", "d_id", "=", "action", ")", ",", "actions", ")", ")", "\n", "", "non_legal_actions", "=", "[", "non_legal_actions", "]", "\n", "\n", "distribution", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "return", "distribution", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy.evaluate_actions": [[459, 474], ["policies.ActorCriticPolicy._get_latent", "policies.ActorCriticPolicy._get_action_dist_from_latent", "policies.ActorCriticPolicy.log_prob", "policies.ActorCriticPolicy.value_net", "policies.ActorCriticPolicy.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "evaluate_actions", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Evaluate actions according to the current policy,\n        given the observations.\n\n        :param obs:\n        :param actions:\n        :return: estimated value, log likelihood of taking those actions\n            and entropy of the action distribution.\n        \"\"\"", "\n", "latent_pi", ",", "latent_vf", "=", "self", ".", "_get_latent", "(", "obs", ")", "\n", "distribution", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ")", "\n", "log_prob", "=", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "values", "=", "self", ".", "value_net", "(", "latent_vf", ")", "\n", "return", "values", ",", "log_prob", ",", "distribution", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticCnnPolicy.__init__": [[478, 511], ["policies.ActorCriticPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "lr_schedule", ":", "Schedule", ",", "\n", "net_arch", ":", "Optional", "[", "List", "[", "Union", "[", "int", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "]", "]", "=", "None", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "Tanh", ",", "\n", "ortho_init", ":", "bool", "=", "True", ",", "\n", "log_std_init", ":", "float", "=", "0.0", ",", "\n", "full_std", ":", "bool", "=", "True", ",", "\n", "use_expln", ":", "bool", "=", "False", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "features_extractor_class", ":", "Type", "[", "BaseFeaturesExtractor", "]", "=", "NatureCNN", ",", "\n", "features_extractor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "normalize_images", ":", "bool", "=", "True", ",", "\n", "optimizer_class", ":", "Type", "[", "th", ".", "optim", ".", "Optimizer", "]", "=", "th", ".", "optim", ".", "Adam", ",", "\n", "optimizer_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "ActorCriticCnnPolicy", ",", "self", ")", ".", "__init__", "(", "\n", "observation_space", ",", "\n", "action_space", ",", "\n", "net_arch", ",", "\n", "activation_fn", ",", "\n", "ortho_init", ",", "\n", "log_std_init", ",", "\n", "full_std", ",", "\n", "use_expln", ",", "\n", "squash_output", ",", "\n", "features_extractor_class", ",", "\n", "features_extractor_kwargs", ",", "\n", "normalize_images", ",", "\n", "optimizer_class", ",", "\n", "optimizer_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ContinuousCritic.__init__": [[541, 570], ["policies.BaseModel.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.get_action_dim", "range", "gym_optimal_intrusion_response.agents.openai_baselines.common.torch_layers.create_mlp", "torch.nn.Sequential", "policies.ContinuousCritic.add_module", "policies.ContinuousCritic.q_networks.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_action_dim", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.create_mlp"], ["def", "__init__", "(", "\n", "self", ",", "\n", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "net_arch", ":", "List", "[", "int", "]", ",", "\n", "features_extractor", ":", "nn", ".", "Module", ",", "\n", "features_dim", ":", "int", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "ReLU", ",", "\n", "normalize_images", ":", "bool", "=", "True", ",", "\n", "n_critics", ":", "int", "=", "2", ",", "\n", "share_features_extractor", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "observation_space", ",", "\n", "action_space", ",", "\n", "features_extractor", "=", "features_extractor", ",", "\n", "normalize_images", "=", "normalize_images", ",", "\n", ")", "\n", "\n", "action_dim", "=", "get_action_dim", "(", "self", ".", "action_space", ")", "\n", "\n", "self", ".", "share_features_extractor", "=", "share_features_extractor", "\n", "self", ".", "n_critics", "=", "n_critics", "\n", "self", ".", "q_networks", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "n_critics", ")", ":", "\n", "            ", "q_net", "=", "create_mlp", "(", "features_dim", "+", "action_dim", ",", "1", ",", "net_arch", ",", "activation_fn", ")", "\n", "q_net", "=", "nn", ".", "Sequential", "(", "*", "q_net", ")", "\n", "self", ".", "add_module", "(", "f\"qf{idx}\"", ",", "q_net", ")", "\n", "self", ".", "q_networks", ".", "append", "(", "q_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ContinuousCritic.forward": [[571, 578], ["torch.cat", "tuple", "torch.set_grad_enabled", "policies.ContinuousCritic.extract_features", "q_net"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.extract_features"], ["", "", "def", "forward", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "...", "]", ":", "\n", "# Learn the features extractor using the policy loss only", "\n", "# when the features_extractor is shared with the actor", "\n", "        ", "with", "th", ".", "set_grad_enabled", "(", "not", "self", ".", "share_features_extractor", ")", ":", "\n", "            ", "features", "=", "self", ".", "extract_features", "(", "obs", ")", "\n", "", "qvalue_input", "=", "th", ".", "cat", "(", "[", "features", ",", "actions", "]", ",", "dim", "=", "1", ")", "\n", "return", "tuple", "(", "q_net", "(", "qvalue_input", ")", "for", "q_net", "in", "self", ".", "q_networks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ContinuousCritic.q1_forward": [[579, 588], ["torch.no_grad", "policies.ContinuousCritic.extract_features", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.extract_features"], ["", "def", "q1_forward", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Only predict the Q-value using the first network.\n        This allows to reduce computation when all the estimates are not needed\n        (e.g. when updating the policy in TD3).\n        \"\"\"", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "            ", "features", "=", "self", ".", "extract_features", "(", "obs", ")", "\n", "", "return", "self", ".", "q_networks", "[", "0", "]", "(", "th", ".", "cat", "(", "[", "features", ",", "actions", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.get_policy_from_name": [[593, 610], ["KeyError", "KeyError", "list", "_policy_registry[].keys"], "function", ["None"], ["def", "get_policy_from_name", "(", "base_policy_type", ":", "Type", "[", "BasePolicy", "]", ",", "name", ":", "str", ")", "->", "Type", "[", "BasePolicy", "]", ":", "\n", "    ", "\"\"\"\n    Returns the registered policy from the base type and name.\n    See `register_policy` for registering policies and explanation.\n\n    :param base_policy_type: the base policy class\n    :param name: the policy name\n    :return: the policy\n    \"\"\"", "\n", "if", "base_policy_type", "not", "in", "_policy_registry", ":", "\n", "        ", "raise", "KeyError", "(", "f\"Error: the policy type {base_policy_type} is not registered!\"", ")", "\n", "", "if", "name", "not", "in", "_policy_registry", "[", "base_policy_type", "]", ":", "\n", "        ", "raise", "KeyError", "(", "\n", "f\"Error: unknown policy type {name},\"", "\n", "f\"the only registed policy type are: {list(_policy_registry[base_policy_type].keys())}!\"", "\n", ")", "\n", "", "return", "_policy_registry", "[", "base_policy_type", "]", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.register_policy": [[612, 653], ["BasePolicy.__subclasses__", "issubclass", "ValueError", "ValueError"], "function", ["None"], ["", "def", "register_policy", "(", "name", ":", "str", ",", "policy", ":", "Type", "[", "BasePolicy", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Register a policy, so it can be called using its name.\n    e.g. SAC('MlpPolicy', ...) instead of SAC(MlpPolicy, ...).\n\n    The goal here is to standardize policy naming, e.g.\n    all algorithms can call upon \"MlpPolicy\" or \"CnnPolicy\",\n    and they receive respective policies that work for them.\n    Consider following:\n\n    OnlinePolicy\n    -- OnlineMlpPolicy (\"MlpPolicy\")\n    -- OnlineCnnPolicy (\"CnnPolicy\")\n    OfflinePolicy\n    -- OfflineMlpPolicy (\"MlpPolicy\")\n    -- OfflineCnnPolicy (\"CnnPolicy\")\n\n    Two policies have name \"MlpPolicy\" and two have \"CnnPolicy\".\n    In `get_policy_from_name`, the parent class (e.g. OnlinePolicy)\n    is given and used to select and return the correct policy.\n\n    :param name: the policy name\n    :param policy: the policy class\n    \"\"\"", "\n", "sub_class", "=", "None", "\n", "for", "cls", "in", "BasePolicy", ".", "__subclasses__", "(", ")", ":", "\n", "        ", "if", "issubclass", "(", "policy", ",", "cls", ")", ":", "\n", "            ", "sub_class", "=", "cls", "\n", "break", "\n", "", "", "if", "sub_class", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Error: the policy {policy} is not of any known subclasses of BasePolicy!\"", ")", "\n", "\n", "", "if", "sub_class", "not", "in", "_policy_registry", ":", "\n", "        ", "_policy_registry", "[", "sub_class", "]", "=", "{", "}", "\n", "", "if", "name", "in", "_policy_registry", "[", "sub_class", "]", ":", "\n", "# Check if the registered policy is same", "\n", "# we try to register. If not so,", "\n", "# do not override and complain.", "\n", "        ", "if", "_policy_registry", "[", "sub_class", "]", "[", "name", "]", "!=", "policy", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Error: the name {name} is already registered for a different policy, will not override.\"", ")", "\n", "", "", "_policy_registry", "[", "sub_class", "]", "[", "name", "]", "=", "policy", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.rolling_window": [[19, 30], ["numpy.lib.stride_tricks.as_strided"], "function", ["None"], ["def", "rolling_window", "(", "array", ":", "np", ".", "ndarray", ",", "window", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Apply a rolling window to a np.ndarray\n\n    :param array: the input Array\n    :param window: length of the rolling window\n    :return: rolling window on the input array\n    \"\"\"", "\n", "shape", "=", "array", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "array", ".", "shape", "[", "-", "1", "]", "-", "window", "+", "1", ",", "window", ")", "\n", "strides", "=", "array", ".", "strides", "+", "(", "array", ".", "strides", "[", "-", "1", "]", ",", ")", "\n", "return", "np", ".", "lib", ".", "stride_tricks", ".", "as_strided", "(", "array", ",", "shape", "=", "shape", ",", "strides", "=", "strides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.window_func": [[32, 45], ["results_plotter.rolling_window", "numpy.np.mean"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.rolling_window"], ["", "def", "window_func", "(", "var_1", ":", "np", ".", "ndarray", ",", "var_2", ":", "np", ".", "ndarray", ",", "window", ":", "int", ",", "func", ":", "Callable", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Apply a function to the rolling window of 2 arrays\n\n    :param var_1: variable 1\n    :param var_2: variable 2\n    :param window: length of the rolling window\n    :param func: function to apply on the rolling window on variable 2 (such as np.mean)\n    :return:  the rolling output with applied function\n    \"\"\"", "\n", "var_2_window", "=", "rolling_window", "(", "var_2", ",", "window", ")", "\n", "function_on_var2", "=", "func", "(", "var_2_window", ",", "axis", "=", "-", "1", ")", "\n", "return", "var_1", "[", "window", "-", "1", ":", "]", ",", "function_on_var2", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.ts2xy": [[47, 69], ["numpy.cumsum", "numpy.arange", "len"], "function", ["None"], ["", "def", "ts2xy", "(", "data_frame", ":", "pd", ".", "DataFrame", ",", "x_axis", ":", "str", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Decompose a data frame variable to x ans ys\n\n    :param data_frame: the input data\n    :param x_axis: the axis for the x and y output\n        (can be X_TIMESTEPS='timesteps', X_EPISODES='episodes' or X_WALLTIME='walltime_hrs')\n    :return: the x and y output\n    \"\"\"", "\n", "if", "x_axis", "==", "X_TIMESTEPS", ":", "\n", "        ", "x_var", "=", "np", ".", "cumsum", "(", "data_frame", ".", "l", ".", "values", ")", "\n", "y_var", "=", "data_frame", ".", "r", ".", "values", "\n", "", "elif", "x_axis", "==", "X_EPISODES", ":", "\n", "        ", "x_var", "=", "np", ".", "arange", "(", "len", "(", "data_frame", ")", ")", "\n", "y_var", "=", "data_frame", ".", "r", ".", "values", "\n", "", "elif", "x_axis", "==", "X_WALLTIME", ":", "\n", "# Convert to hours", "\n", "        ", "x_var", "=", "data_frame", ".", "t", ".", "values", "/", "3600.0", "\n", "y_var", "=", "data_frame", ".", "r", ".", "values", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "return", "x_var", ",", "y_var", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.plot_curves": [[71, 99], ["matplotlib.pyplot.figure", "max", "enumerate", "matplotlib.pyplot.xlim", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.scatter", "results_plotter.window_func", "matplotlib.pyplot.plot"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.window_func", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_curves", "(", "\n", "xy_list", ":", "List", "[", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", "]", ",", "x_axis", ":", "str", ",", "title", ":", "str", ",", "figsize", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "8", ",", "2", ")", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    plot the curves\n\n    :param xy_list: the x and y coordinates to plot\n    :param x_axis: the axis for the x and y output\n        (can be X_TIMESTEPS='timesteps', X_EPISODES='episodes' or X_WALLTIME='walltime_hrs')\n    :param title: the title of the plot\n    :param figsize: Size of the figure (width, height)\n    \"\"\"", "\n", "\n", "plt", ".", "figure", "(", "title", ",", "figsize", "=", "figsize", ")", "\n", "max_x", "=", "max", "(", "xy", "[", "0", "]", "[", "-", "1", "]", "for", "xy", "in", "xy_list", ")", "\n", "min_x", "=", "0", "\n", "for", "(", "_", ",", "(", "x", ",", "y", ")", ")", "in", "enumerate", "(", "xy_list", ")", ":", "\n", "        ", "plt", ".", "scatter", "(", "x", ",", "y", ",", "s", "=", "2", ")", "\n", "# Do not plot the smoothed curve at all if the timeseries is shorter than window size.", "\n", "if", "x", ".", "shape", "[", "0", "]", ">=", "EPISODES_WINDOW", ":", "\n", "# Compute and plot rolling mean with window of size EPISODE_WINDOW", "\n", "            ", "x", ",", "y_mean", "=", "window_func", "(", "x", ",", "y", ",", "EPISODES_WINDOW", ",", "np", ".", "mean", ")", "\n", "plt", ".", "plot", "(", "x", ",", "y_mean", ")", "\n", "", "", "plt", ".", "xlim", "(", "min_x", ",", "max_x", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "xlabel", "(", "x_axis", ")", "\n", "plt", ".", "ylabel", "(", "\"Episode Rewards\"", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.plot_results": [[101, 123], ["results_plotter.plot_curves", "gym_optimal_intrusion_response.agents.openai_baselines.common.monitor.load_results", "data_frames.append", "results_plotter.ts2xy", "gym_optimal_intrusion_response.agents.openai_baselines.common.monitor.load_results.l.cumsum"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.plot_curves", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.load_results", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.results_plotter.ts2xy"], ["", "def", "plot_results", "(", "\n", "dirs", ":", "List", "[", "str", "]", ",", "num_timesteps", ":", "Optional", "[", "int", "]", ",", "x_axis", ":", "str", ",", "task_name", ":", "str", ",", "figsize", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "8", ",", "2", ")", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plot the results using csv files from ``Monitor`` wrapper.\n\n    :param dirs: the save location of the results to plot\n    :param num_timesteps: only plot the points below this value\n    :param x_axis: the axis for the x and y output\n        (can be X_TIMESTEPS='timesteps', X_EPISODES='episodes' or X_WALLTIME='walltime_hrs')\n    :param task_name: the title of the task to plot\n    :param figsize: Size of the figure (width, height)\n    \"\"\"", "\n", "\n", "data_frames", "=", "[", "]", "\n", "for", "folder", "in", "dirs", ":", "\n", "        ", "data_frame", "=", "load_results", "(", "folder", ")", "\n", "if", "num_timesteps", "is", "not", "None", ":", "\n", "            ", "data_frame", "=", "data_frame", "[", "data_frame", ".", "l", ".", "cumsum", "(", ")", "<=", "num_timesteps", "]", "\n", "", "data_frames", ".", "append", "(", "data_frame", ")", "\n", "", "xy_list", "=", "[", "ts2xy", "(", "data_frame", ",", "x_axis", ")", "for", "data_frame", "in", "data_frames", "]", "\n", "plot_curves", "(", "xy_list", ",", "x_axis", ",", "task_name", ",", "figsize", ")", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_getattr": [[24, 41], ["functools.reduce", "getattr", "attr.split"], "function", ["None"], ["def", "recursive_getattr", "(", "obj", ":", "Any", ",", "attr", ":", "str", ",", "*", "args", ")", "->", "Any", ":", "\n", "    ", "\"\"\"\n    Recursive version of getattr\n    taken from https://stackoverflow.com/questions/31174295\n\n    Ex:\n    > MyObject.sub_object = SubObject(name='test')\n    > recursive_getattr(MyObject, 'sub_object.name')  # return test\n    :param obj:\n    :param attr: Attribute to retrieve\n    :return: The attribute\n    \"\"\"", "\n", "\n", "def", "_getattr", "(", "obj", ":", "Any", ",", "attr", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "getattr", "(", "obj", ",", "attr", ",", "*", "args", ")", "\n", "\n", "", "return", "functools", ".", "reduce", "(", "_getattr", ",", "[", "obj", "]", "+", "attr", ".", "split", "(", "\".\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_setattr": [[43, 57], ["attr.rpartition", "setattr", "save_util.recursive_getattr"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_getattr"], ["", "def", "recursive_setattr", "(", "obj", ":", "Any", ",", "attr", ":", "str", ",", "val", ":", "Any", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Recursive version of setattr\n    taken from https://stackoverflow.com/questions/31174295\n\n    Ex:\n    > MyObject.sub_object = SubObject(name='test')\n    > recursive_setattr(MyObject, 'sub_object.name', 'hello')\n    :param obj:\n    :param attr: Attribute to set\n    :param val: New value of the attribute\n    \"\"\"", "\n", "pre", ",", "_", ",", "post", "=", "attr", ".", "rpartition", "(", "\".\"", ")", "\n", "return", "setattr", "(", "recursive_getattr", "(", "obj", ",", "pre", ")", "if", "pre", "else", "obj", ",", "post", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.is_json_serializable": [[59, 73], ["json.dumps"], "function", ["None"], ["", "def", "is_json_serializable", "(", "item", ":", "Any", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Test if an object is serializable into JSON\n\n    :param item: The object to be tested for JSON serialization.\n    :return: True if object is JSON serializable, false otherwise.\n    \"\"\"", "\n", "# Try with try-except struct.", "\n", "json_serializable", "=", "True", "\n", "try", ":", "\n", "        ", "_", "=", "json", ".", "dumps", "(", "item", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "json_serializable", "=", "False", "\n", "", "return", "json_serializable", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.data_to_json": [[75, 128], ["data.items", "json.dumps", "save_util.is_json_serializable", "base64.b64encode().decode", "str", "hasattr", "isinstance", "item_generator", "base64.b64encode", "type", "isinstance", "save_util.is_json_serializable", "cloudpickle.dumps", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.is_json_serializable", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.is_json_serializable"], ["", "def", "data_to_json", "(", "data", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Turn data (class parameters) into a JSON string for storing\n\n    :param data: Dictionary of class parameters to be\n        stored. Items that are not JSON serializable will be\n        pickled with Cloudpickle and stored as bytearray in\n        the JSON file\n    :return: JSON string of the data serialized.\n    \"\"\"", "\n", "# First, check what elements can not be JSONfied,", "\n", "# and turn them into byte-strings", "\n", "serializable_data", "=", "{", "}", "\n", "for", "data_key", ",", "data_item", "in", "data", ".", "items", "(", ")", ":", "\n", "# See if object is JSON serializable", "\n", "        ", "if", "is_json_serializable", "(", "data_item", ")", ":", "\n", "# All good, store as it is", "\n", "            ", "serializable_data", "[", "data_key", "]", "=", "data_item", "\n", "", "else", ":", "\n", "# Not serializable, cloudpickle it into", "\n", "# bytes and convert to base64 string for storing.", "\n", "# Also store type of the class for consumption", "\n", "# from other languages/humans, so we have an", "\n", "# idea what was being stored.", "\n", "            ", "base64_encoded", "=", "base64", ".", "b64encode", "(", "cloudpickle", ".", "dumps", "(", "data_item", ")", ")", ".", "decode", "(", ")", "\n", "\n", "# Use \":\" to make sure we do", "\n", "# not override these keys", "\n", "# when we include variables of the object later", "\n", "cloudpickle_serialization", "=", "{", "\n", "\":type:\"", ":", "str", "(", "type", "(", "data_item", ")", ")", ",", "\n", "\":serialized:\"", ":", "base64_encoded", ",", "\n", "}", "\n", "\n", "# Add first-level JSON-serializable items of the", "\n", "# object for further details (but not deeper than this to", "\n", "# avoid deep nesting).", "\n", "# First we check that object has attributes (not all do,", "\n", "# e.g. numpy scalars)", "\n", "if", "hasattr", "(", "data_item", ",", "\"__dict__\"", ")", "or", "isinstance", "(", "data_item", ",", "dict", ")", ":", "\n", "# Take elements from __dict__ for custom classes", "\n", "                ", "item_generator", "=", "data_item", ".", "items", "if", "isinstance", "(", "data_item", ",", "dict", ")", "else", "data_item", ".", "__dict__", ".", "items", "\n", "for", "variable_name", ",", "variable_item", "in", "item_generator", "(", ")", ":", "\n", "# Check if serializable. If not, just include the", "\n", "# string-representation of the object.", "\n", "                    ", "if", "is_json_serializable", "(", "variable_item", ")", ":", "\n", "                        ", "cloudpickle_serialization", "[", "variable_name", "]", "=", "variable_item", "\n", "", "else", ":", "\n", "                        ", "cloudpickle_serialization", "[", "variable_name", "]", "=", "str", "(", "variable_item", ")", "\n", "\n", "", "", "", "serializable_data", "[", "data_key", "]", "=", "cloudpickle_serialization", "\n", "", "", "json_string", "=", "json", ".", "dumps", "(", "serializable_data", ",", "indent", "=", "4", ")", "\n", "return", "json_string", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.json_to_data": [[130, 176], ["json.loads", "json.loads.items", "ValueError", "isinstance", "custom_objects.keys", "isinstance", "data_item.keys", "base64.b64decode", "cloudpickle.loads", "serialization.encode", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "json_to_data", "(", "json_string", ":", "str", ",", "custom_objects", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Turn JSON serialization of class-parameters back into dictionary.\n\n    :param json_string: JSON serialization of the class-parameters\n        that should be loaded.\n    :param custom_objects: Dictionary of objects to replace\n        upon loading. If a variable is present in this dictionary as a\n        key, it will not be deserialized and the corresponding item\n        will be used instead. Similar to custom_objects in\n        ``keras.models.load_model``. Useful when you have an object in\n        file that can not be deserialized.\n    :return: Loaded class parameters.\n    \"\"\"", "\n", "if", "custom_objects", "is", "not", "None", "and", "not", "isinstance", "(", "custom_objects", ",", "dict", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"custom_objects argument must be a dict or None\"", ")", "\n", "\n", "", "json_dict", "=", "json", ".", "loads", "(", "json_string", ")", "\n", "# This will be filled with deserialized data", "\n", "return_data", "=", "{", "}", "\n", "for", "data_key", ",", "data_item", "in", "json_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "custom_objects", "is", "not", "None", "and", "data_key", "in", "custom_objects", ".", "keys", "(", ")", ":", "\n", "# If item is provided in custom_objects, replace", "\n", "# the one from JSON with the one in custom_objects", "\n", "            ", "return_data", "[", "data_key", "]", "=", "custom_objects", "[", "data_key", "]", "\n", "", "elif", "isinstance", "(", "data_item", ",", "dict", ")", "and", "\":serialized:\"", "in", "data_item", ".", "keys", "(", ")", ":", "\n", "# If item is dictionary with \":serialized:\"", "\n", "# key, this means it is serialized with cloudpickle.", "\n", "            ", "serialization", "=", "data_item", "[", "\":serialized:\"", "]", "\n", "# Try-except deserialization in case we run into", "\n", "# errors. If so, we can tell bit more information to", "\n", "# user.", "\n", "try", ":", "\n", "                ", "base64_object", "=", "base64", ".", "b64decode", "(", "serialization", ".", "encode", "(", ")", ")", "\n", "deserialized_object", "=", "cloudpickle", ".", "loads", "(", "base64_object", ")", "\n", "", "except", "(", "RuntimeError", ",", "TypeError", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "f\"Could not deserialize object {data_key}. \"", "\n", "+", "\"Consider using `custom_objects` argument to replace \"", "\n", "+", "\"this object.\"", "\n", ")", "\n", "", "return_data", "[", "data_key", "]", "=", "deserialized_object", "\n", "", "else", ":", "\n", "# Read as it is", "\n", "            ", "return_data", "[", "data_key", "]", "=", "data_item", "\n", "", "", "return", "return_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path": [[178, 215], ["mode.lower.lower", "isinstance", "TypeError", "ValueError", "ValueError", "ValueError", "path.writable", "path.readable", "pathlib.Path"], "function", ["None"], ["", "@", "functools", ".", "singledispatch", "\n", "def", "open_path", "(", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "mode", ":", "str", ",", "verbose", ":", "int", "=", "0", ",", "suffix", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Opens a path for reading or writing with a preferred suffix and raises debug information.\n    If the provided path is a derivative of io.BufferedIOBase it ensures that the file\n    matches the provided mode, i.e. If the mode is read (\"r\", \"read\") it checks that the path is readable.\n    If the mode is write (\"w\", \"write\") it checks that the file is writable.\n\n    If the provided path is a string or a pathlib.Path, it ensures that it exists. If the mode is \"read\"\n    it checks that it exists, if it doesn't exist it attempts to read path.suffix if a suffix is provided.\n    If the mode is \"write\" and the path does not exist, it creates all the parent folders. If the path\n    points to a folder, it changes the path to path_2. If the path already exists and verbose == 2,\n    it raises a warning.\n\n    :param path: the path to open.\n        if save_path is a str or pathlib.Path and mode is \"w\", single dispatch ensures that the\n        path actually exists. If path is a io.BufferedIOBase the path exists.\n    :param mode: how to open the file. \"w\"|\"write\" for writing, \"r\"|\"read\" for reading.\n    :param verbose: Verbosity level, 0 means only warnings, 2 means debug information.\n    :param suffix: The preferred suffix. If mode is \"w\" then the opened file has the suffix.\n        If mode is \"r\" then we attempt to open the path. If an error is raised and the suffix\n        is not None, we attempt to open the path with the suffix.\n    :return:\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "path", ",", "io", ".", "BufferedIOBase", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"Path parameter has invalid type.\"", ",", "io", ".", "BufferedIOBase", ")", "\n", "", "if", "path", ".", "closed", ":", "\n", "        ", "raise", "ValueError", "(", "\"File stream is closed.\"", ")", "\n", "", "mode", "=", "mode", ".", "lower", "(", ")", "\n", "try", ":", "\n", "        ", "mode", "=", "{", "\"write\"", ":", "\"w\"", ",", "\"read\"", ":", "\"r\"", ",", "\"w\"", ":", "\"w\"", ",", "\"r\"", ":", "\"r\"", "}", "[", "mode", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "raise", "ValueError", "(", "\"Expected mode to be either 'w' or 'r'.\"", ")", "\n", "", "if", "(", "\"w\"", "==", "mode", ")", "and", "not", "path", ".", "writable", "(", ")", "or", "(", "\"r\"", "==", "mode", ")", "and", "not", "path", ".", "readable", "(", ")", ":", "\n", "        ", "e1", "=", "\"writable\"", "if", "\"w\"", "==", "mode", "else", "\"readable\"", "\n", "raise", "ValueError", "(", "f\"Expected a {e1} file.\"", ")", "\n", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path_str": [[217, 233], ["open_path.register", "save_util.open_path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path"], ["", "@", "open_path", ".", "register", "(", "str", ")", "\n", "def", "open_path_str", "(", "path", ":", "str", ",", "mode", ":", "str", ",", "verbose", ":", "int", "=", "0", ",", "suffix", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "io", ".", "BufferedIOBase", ":", "\n", "    ", "\"\"\"\n    Open a path given by a string. If writing to the path, the function ensures\n    that the path exists.\n\n    :param path: the path to open. If mode is \"w\" then it ensures that the path exists\n        by creating the necessary folders and renaming path if it points to a folder.\n    :param mode: how to open the file. \"w\" for writing, \"r\" for reading.\n    :param verbose: Verbosity level, 0 means only warnings, 2 means debug information.\n    :param suffix: The preferred suffix. If mode is \"w\" then the opened file has the suffix.\n        If mode is \"r\" then we attempt to open the path. If an error is raised and the suffix\n        is not None, we attempt to open the path with the suffix.\n    :return:\n    \"\"\"", "\n", "return", "open_path", "(", "pathlib", ".", "Path", "(", "path", ")", ",", "mode", ",", "verbose", ",", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path_pathlib": [[235, 285], ["open_path.register", "save_util.open_path", "ValueError", "pathlib.Path.open", "pathlib.Path.open", "pathlib.Path", "pathlib.Path.exists", "pathlib.Path.is_file", "warnings.warn", "warnings.warn", "pathlib.Path", "warnings.warn", "pathlib.Path.parent.mkdir", "pathlib.Path", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "@", "open_path", ".", "register", "(", "pathlib", ".", "Path", ")", "\n", "def", "open_path_pathlib", "(", "path", ":", "pathlib", ".", "Path", ",", "mode", ":", "str", ",", "verbose", ":", "int", "=", "0", ",", "suffix", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "io", ".", "BufferedIOBase", ":", "\n", "    ", "\"\"\"\n    Open a path given by a string. If writing to the path, the function ensures\n    that the path exists.\n\n    :param path: the path to check. If mode is \"w\" then it\n        ensures that the path exists by creating the necessary folders and\n        renaming path if it points to a folder.\n    :param mode: how to open the file. \"w\" for writing, \"r\" for reading.\n    :param verbose: Verbosity level, 0 means only warnings, 2 means debug information.\n    :param suffix: The preferred suffix. If mode is \"w\" then the opened file has the suffix.\n        If mode is \"r\" then we attempt to open the path. If an error is raised and the suffix\n        is not None, we attempt to open the path with the suffix.\n    :return:\n    \"\"\"", "\n", "if", "mode", "not", "in", "(", "\"w\"", ",", "\"r\"", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Expected mode to be either 'w' or 'r'.\"", ")", "\n", "\n", "", "if", "mode", "==", "\"r\"", ":", "\n", "        ", "try", ":", "\n", "            ", "path", "=", "path", ".", "open", "(", "\"rb\"", ")", "\n", "", "except", "FileNotFoundError", "as", "error", ":", "\n", "            ", "if", "suffix", "is", "not", "None", "and", "suffix", "!=", "\"\"", ":", "\n", "                ", "newpath", "=", "pathlib", ".", "Path", "(", "f\"{path}.{suffix}\"", ")", "\n", "if", "verbose", "==", "2", ":", "\n", "                    ", "warnings", ".", "warn", "(", "f\"Path '{path}' not found. Attempting {newpath}.\"", ")", "\n", "", "path", ",", "suffix", "=", "newpath", ",", "None", "\n", "", "else", ":", "\n", "                ", "raise", "error", "\n", "", "", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "if", "path", ".", "suffix", "==", "\"\"", "and", "suffix", "is", "not", "None", "and", "suffix", "!=", "\"\"", ":", "\n", "                ", "path", "=", "pathlib", ".", "Path", "(", "f\"{path}.{suffix}\"", ")", "\n", "", "if", "path", ".", "exists", "(", ")", "and", "path", ".", "is_file", "(", ")", "and", "verbose", "==", "2", ":", "\n", "                ", "warnings", ".", "warn", "(", "f\"Path '{path}' exists, will overwrite it.\"", ")", "\n", "", "path", "=", "path", ".", "open", "(", "\"wb\"", ")", "\n", "", "except", "IsADirectoryError", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"Path '{path}' is a folder. Will save instead to {path}_2\"", ")", "\n", "path", "=", "pathlib", ".", "Path", "(", "f\"{path}_2\"", ")", "\n", "", "except", "FileNotFoundError", ":", "# Occurs when the parent folder doesn't exist", "\n", "            ", "warnings", ".", "warn", "(", "f\"Path '{path.parent}' does not exist. Will create it.\"", ")", "\n", "path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "# if opening was successful uses the identity function", "\n", "# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib", "\n", "#   with corrections", "\n", "# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix", "\n", "\n", "", "", "return", "open_path", "(", "path", ",", "mode", ",", "verbose", ",", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.save_to_zip_file": [[287, 325], ["save_util.open_path", "save_util.data_to_json", "zipfile.ZipFile", "archive.writestr", "archive.writestr", "params.items", "archive.open", "torch.save", "archive.open", "torch.save"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.data_to_json", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save"], ["", "def", "save_to_zip_file", "(", "\n", "save_path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "\n", "data", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "params", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "pytorch_variables", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Save model data to a zip archive.\n\n    :param save_path: Where to store the model.\n        if save_path is a str or pathlib.Path ensures that the path actually exists.\n    :param data: Class parameters being stored (non-PyTorch variables)\n    :param params: Model parameters being stored expected to contain an entry for every\n                   state_dict with its name and the state_dict.\n    :param pytorch_variables: Other PyTorch variables expected to contain name and value of the variable.\n    :param verbose: Verbosity level, 0 means only warnings, 2 means debug information\n    \"\"\"", "\n", "save_path", "=", "open_path", "(", "save_path", ",", "\"w\"", ",", "verbose", "=", "0", ",", "suffix", "=", "\"zip\"", ")", "\n", "# data/params can be None, so do not", "\n", "# try to serialize them blindly", "\n", "if", "data", "is", "not", "None", ":", "\n", "        ", "serialized_data", "=", "data_to_json", "(", "data", ")", "\n", "\n", "# Create a zip-archive and write our objects there.", "\n", "", "with", "zipfile", ".", "ZipFile", "(", "save_path", ",", "mode", "=", "\"w\"", ")", "as", "archive", ":", "\n", "# Do not try to save \"None\" elements", "\n", "        ", "if", "data", "is", "not", "None", ":", "\n", "            ", "archive", ".", "writestr", "(", "\"data\"", ",", "serialized_data", ")", "\n", "", "if", "pytorch_variables", "is", "not", "None", ":", "\n", "            ", "with", "archive", ".", "open", "(", "\"pytorch_variables.pth\"", ",", "mode", "=", "\"w\"", ")", "as", "pytorch_variables_file", ":", "\n", "                ", "th", ".", "save", "(", "pytorch_variables", ",", "pytorch_variables_file", ")", "\n", "", "", "if", "params", "is", "not", "None", ":", "\n", "            ", "for", "file_name", ",", "dict_", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "with", "archive", ".", "open", "(", "file_name", "+", "\".pth\"", ",", "mode", "=", "\"w\"", ")", "as", "param_file", ":", "\n", "                    ", "th", ".", "save", "(", "dict_", ",", "param_file", ")", "\n", "# Save metadata: library version when file was saved", "\n", "", "", "", "archive", ".", "writestr", "(", "\"_stable_baselines3_version\"", ",", "stable_baselines3", ".", "__version__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.save_to_pkl": [[327, 343], ["save_util.open_path", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump"], ["", "", "def", "save_to_pkl", "(", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "obj", ":", "Any", ",", "verbose", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Save an object to path creating the necessary folders along the way.\n    If the path exists and is a directory, it will raise a warning and rename the path.\n    If a suffix is provided in the path, it will use that suffix, otherwise, it will use '.pkl'.\n\n    :param path: the path to open.\n        if save_path is a str or pathlib.Path and mode is \"w\", single dispatch ensures that the\n        path actually exists. If path is a io.BufferedIOBase the path exists.\n    :param obj: The object to save.\n    :param verbose: Verbosity level, 0 means only warnings, 2 means debug information.\n    \"\"\"", "\n", "with", "open_path", "(", "path", ",", "\"w\"", ",", "verbose", "=", "verbose", ",", "suffix", "=", "\"pkl\"", ")", "as", "file_handler", ":", "\n", "# Use protocol>=4 to support saving replay buffers >= 4Gb", "\n", "# See https://docs.python.org/3/library/pickle.html", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "file_handler", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.load_from_pkl": [[345, 357], ["save_util.open_path", "pickle.load"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "", "def", "load_from_pkl", "(", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "verbose", ":", "int", "=", "0", ")", "->", "Any", ":", "\n", "    ", "\"\"\"\n    Load an object from the path. If a suffix is provided in the path, it will use that suffix.\n    If the path does not exist, it will attempt to load using the .pkl suffix.\n\n    :param path: the path to open.\n        if save_path is a str or pathlib.Path and mode is \"w\", single dispatch ensures that the\n        path actually exists. If path is a io.BufferedIOBase the path exists.\n    :param verbose: Verbosity level, 0 means only warnings, 2 means debug information.\n    \"\"\"", "\n", "with", "open_path", "(", "path", ",", "\"r\"", ",", "verbose", "=", "verbose", ",", "suffix", "=", "\"pkl\"", ")", "as", "file_handler", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.load_from_zip_file": [[359, 431], ["save_util.open_path", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.get_device", "zipfile.ZipFile", "archive.namelist", "ValueError", "archive.read().decode", "save_util.json_to_data", "archive.open", "io.BytesIO", "io.BytesIO.write", "io.BytesIO.seek", "torch.load", "archive.read", "param_file.read", "os.path.splitext", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.open_path", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_device", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.json_to_data", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "", "def", "load_from_zip_file", "(", "\n", "load_path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "\n", "load_data", ":", "bool", "=", "True", ",", "\n", "custom_objects", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", ")", "->", "(", "Tuple", "[", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "Optional", "[", "TensorDict", "]", ",", "Optional", "[", "TensorDict", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Load model data from a .zip archive\n\n    :param load_path: Where to load the model from\n    :param load_data: Whether we should load and return data\n        (class parameters). Mainly used by 'load_parameters' to only load model parameters (weights)\n    :param custom_objects: Dictionary of objects to replace\n        upon loading. If a variable is present in this dictionary as a\n        key, it will not be deserialized and the corresponding item\n        will be used instead. Similar to custom_objects in\n        ``keras.models.load_model``. Useful when you have an object in\n        file that can not be deserialized.\n    :param device: Device on which the code should run.\n    :return: Class parameters, model state_dicts (aka \"params\", dict of state_dict)\n        and dict of pytorch variables\n    \"\"\"", "\n", "load_path", "=", "open_path", "(", "load_path", ",", "\"r\"", ",", "verbose", "=", "verbose", ",", "suffix", "=", "\"zip\"", ")", "\n", "\n", "# set device to cpu if cuda is not available", "\n", "device", "=", "get_device", "(", "device", "=", "device", ")", "\n", "\n", "# Open the zip archive and load data", "\n", "try", ":", "\n", "        ", "with", "zipfile", ".", "ZipFile", "(", "load_path", ")", "as", "archive", ":", "\n", "            ", "namelist", "=", "archive", ".", "namelist", "(", ")", "\n", "# If data or parameters is not in the", "\n", "# zip archive, assume they were stored", "\n", "# as None (_save_to_file_zip allows this).", "\n", "data", "=", "None", "\n", "pytorch_variables", "=", "None", "\n", "params", "=", "{", "}", "\n", "\n", "if", "\"data\"", "in", "namelist", "and", "load_data", ":", "\n", "# Load class parameters that are stored", "\n", "# with either JSON or pickle (not PyTorch variables).", "\n", "                ", "json_data", "=", "archive", ".", "read", "(", "\"data\"", ")", ".", "decode", "(", ")", "\n", "data", "=", "json_to_data", "(", "json_data", ",", "custom_objects", "=", "custom_objects", ")", "\n", "\n", "# Check for all .pth files and load them using th.load.", "\n", "# \"pytorch_variables.pth\" stores PyTorch variables, and any other .pth", "\n", "# files store state_dicts of variables with custom names (e.g. policy, policy.optimizer)", "\n", "", "pth_files", "=", "[", "file_name", "for", "file_name", "in", "namelist", "if", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "[", "1", "]", "==", "\".pth\"", "]", "\n", "for", "file_path", "in", "pth_files", ":", "\n", "                ", "with", "archive", ".", "open", "(", "file_path", ",", "mode", "=", "\"r\"", ")", "as", "param_file", ":", "\n", "# File has to be seekable, but param_file is not, so load in BytesIO first", "\n", "# fixed in python >= 3.7", "\n", "                    ", "file_content", "=", "io", ".", "BytesIO", "(", ")", "\n", "file_content", ".", "write", "(", "param_file", ".", "read", "(", ")", ")", "\n", "# go to start of file", "\n", "file_content", ".", "seek", "(", "0", ")", "\n", "# Load the parameters with the right ``map_location``.", "\n", "# Remove \".pth\" ending with splitext", "\n", "th_object", "=", "th", ".", "load", "(", "file_content", ",", "map_location", "=", "device", ")", "\n", "# \"tensors.pth\" was renamed \"pytorch_variables.pth\" in v0.9.0, see PR #138", "\n", "if", "file_path", "==", "\"pytorch_variables.pth\"", "or", "file_path", "==", "\"tensors.pth\"", ":", "\n", "# PyTorch variables (not state_dicts)", "\n", "                        ", "pytorch_variables", "=", "th_object", "\n", "", "else", ":", "\n", "# State dicts. Store into params dictionary", "\n", "# with same name as in .zip file (without .pth)", "\n", "                        ", "params", "[", "os", ".", "path", ".", "splitext", "(", "file_path", ")", "[", "0", "]", "]", "=", "th_object", "\n", "", "", "", "", "", "except", "zipfile", ".", "BadZipFile", ":", "\n", "# load_path wasn't a zip file", "\n", "        ", "raise", "ValueError", "(", "f\"Error: the file {load_path} wasn't a zip-file\"", ")", "\n", "", "return", "data", ",", "params", ",", "pytorch_variables", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.BaseFeaturesExtractor.__init__": [[20, 25], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "observation_space", ":", "gym", ".", "Space", ",", "features_dim", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "BaseFeaturesExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "features_dim", ">", "0", "\n", "self", ".", "_observation_space", "=", "observation_space", "\n", "self", ".", "_features_dim", "=", "features_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.BaseFeaturesExtractor.features_dim": [[26, 29], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "features_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_features_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.BaseFeaturesExtractor.forward": [[30, 32], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observations", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.FlattenExtractor.__init__": [[42, 45], ["torch_layers.BaseFeaturesExtractor.__init__", "torch.nn.Flatten", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.get_flattened_obs_dim"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_flattened_obs_dim"], ["def", "__init__", "(", "self", ",", "observation_space", ":", "gym", ".", "Space", ")", ":", "\n", "        ", "super", "(", "FlattenExtractor", ",", "self", ")", ".", "__init__", "(", "observation_space", ",", "get_flattened_obs_dim", "(", "observation_space", ")", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.FlattenExtractor.forward": [[46, 48], ["torch_layers.FlattenExtractor.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observations", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "flatten", "(", "observations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.NatureCNN.__init__": [[62, 90], ["torch_layers.BaseFeaturesExtractor.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.is_image_space", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Flatten", "torch.no_grad", "torch.nn.Linear", "torch.nn.ReLU", "torch_layers.NatureCNN.cnn", "torch.as_tensor().float", "torch.as_tensor", "observation_space.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["def", "__init__", "(", "self", ",", "observation_space", ":", "gym", ".", "spaces", ".", "Box", ",", "features_dim", ":", "int", "=", "512", ")", ":", "\n", "        ", "super", "(", "NatureCNN", ",", "self", ")", ".", "__init__", "(", "observation_space", ",", "features_dim", ")", "\n", "# We assume CxHxW images (channels first)", "\n", "# Re-ordering will be done by pre-preprocessing or wrapper", "\n", "assert", "is_image_space", "(", "observation_space", ")", ",", "(", "\n", "\"You should use NatureCNN \"", "\n", "f\"only with images not with {observation_space}\\n\"", "\n", "\"(you are probably using `CnnPolicy` instead of `MlpPolicy`)\\n\"", "\n", "\"If you are using a custom environment,\\n\"", "\n", "\"please check it using our env checker:\\n\"", "\n", "\"https://stable-baselines3.readthedocs.io/en/master/common/env_checker.html\"", "\n", ")", "\n", "n_input_channels", "=", "observation_space", ".", "shape", "[", "0", "]", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "32", ",", "kernel_size", "=", "8", ",", "stride", "=", "4", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ",", "\n", ")", "\n", "\n", "# Compute shape by doing one forward pass", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "            ", "n_flatten", "=", "self", ".", "cnn", "(", "th", ".", "as_tensor", "(", "observation_space", ".", "sample", "(", ")", "[", "None", "]", ")", ".", "float", "(", ")", ")", ".", "shape", "[", "1", "]", "\n", "\n", "", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "n_flatten", ",", "features_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.NatureCNN.forward": [[91, 93], ["torch_layers.NatureCNN.linear", "torch_layers.NatureCNN.cnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observations", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "linear", "(", "self", ".", "cnn", "(", "observations", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.MlpExtractor.__init__": [[158, 217], ["torch.nn.Module.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.get_device", "itertools.zip_longest", "torch.nn.Sequential().to", "torch.nn.Sequential().to", "torch.nn.Sequential().to", "isinstance", "shared_net.append", "shared_net.append", "isinstance", "isinstance", "policy_net.append", "policy_net.append", "isinstance", "value_net.append", "value_net.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "activation_fn", "isinstance", "isinstance", "torch.nn.Linear", "activation_fn", "torch.nn.Linear", "activation_fn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_device"], ["def", "__init__", "(", "\n", "self", ",", "\n", "feature_dim", ":", "int", ",", "\n", "net_arch", ":", "List", "[", "Union", "[", "int", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "]", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "MlpExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "device", "=", "get_device", "(", "device", ")", "\n", "shared_net", ",", "policy_net", ",", "value_net", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "policy_only_layers", "=", "[", "]", "# Layer sizes of the network that only belongs to the policy network", "\n", "value_only_layers", "=", "[", "]", "# Layer sizes of the network that only belongs to the value network", "\n", "last_layer_dim_shared", "=", "feature_dim", "\n", "\n", "# Iterate through the shared layers and build the shared parts of the network", "\n", "for", "layer", "in", "net_arch", ":", "\n", "            ", "if", "isinstance", "(", "layer", ",", "int", ")", ":", "# Check that this is a shared layer", "\n", "                ", "layer_size", "=", "layer", "\n", "# TODO: give layer a meaningful name", "\n", "shared_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_shared", ",", "layer_size", ")", ")", "\n", "shared_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_shared", "=", "layer_size", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "layer", ",", "dict", ")", ",", "\"Error: the net_arch list can only contain ints and dicts\"", "\n", "if", "\"pi\"", "in", "layer", ":", "\n", "                    ", "assert", "isinstance", "(", "layer", "[", "\"pi\"", "]", ",", "list", ")", ",", "\"Error: net_arch[-1]['pi'] must contain a list of integers.\"", "\n", "policy_only_layers", "=", "layer", "[", "\"pi\"", "]", "\n", "\n", "", "if", "\"vf\"", "in", "layer", ":", "\n", "                    ", "assert", "isinstance", "(", "layer", "[", "\"vf\"", "]", ",", "list", ")", ",", "\"Error: net_arch[-1]['vf'] must contain a list of integers.\"", "\n", "value_only_layers", "=", "layer", "[", "\"vf\"", "]", "\n", "", "break", "# From here on the network splits up in policy and value network", "\n", "\n", "", "", "last_layer_dim_pi", "=", "last_layer_dim_shared", "\n", "last_layer_dim_vf", "=", "last_layer_dim_shared", "\n", "\n", "# Build the non-shared part of the network", "\n", "for", "pi_layer_size", ",", "vf_layer_size", "in", "zip_longest", "(", "policy_only_layers", ",", "value_only_layers", ")", ":", "\n", "            ", "if", "pi_layer_size", "is", "not", "None", ":", "\n", "                ", "assert", "isinstance", "(", "pi_layer_size", ",", "int", ")", ",", "\"Error: net_arch[-1]['pi'] must only contain integers.\"", "\n", "policy_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_pi", ",", "pi_layer_size", ")", ")", "\n", "policy_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_pi", "=", "pi_layer_size", "\n", "\n", "", "if", "vf_layer_size", "is", "not", "None", ":", "\n", "                ", "assert", "isinstance", "(", "vf_layer_size", ",", "int", ")", ",", "\"Error: net_arch[-1]['vf'] must only contain integers.\"", "\n", "value_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_vf", ",", "vf_layer_size", ")", ")", "\n", "value_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_vf", "=", "vf_layer_size", "\n", "\n", "# Save dim, used to create the distributions", "\n", "", "", "self", ".", "latent_dim_pi", "=", "last_layer_dim_pi", "\n", "self", ".", "latent_dim_vf", "=", "last_layer_dim_vf", "\n", "\n", "# Create networks", "\n", "# If the list of layers is empty, the network will just act as an Identity module", "\n", "self", ".", "shared_net", "=", "nn", ".", "Sequential", "(", "*", "shared_net", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "policy_net", "=", "nn", ".", "Sequential", "(", "*", "policy_net", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "value_net", "=", "nn", ".", "Sequential", "(", "*", "value_net", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.MlpExtractor.forward": [[218, 225], ["torch_layers.MlpExtractor.shared_net", "torch_layers.MlpExtractor.policy_net", "torch_layers.MlpExtractor.value_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        :return: latent_policy, latent_value of the specified network.\n            If all layers are shared, then ``latent_policy == latent_value``\n        \"\"\"", "\n", "shared_latent", "=", "self", ".", "shared_net", "(", "features", ")", "\n", "return", "self", ".", "policy_net", "(", "shared_latent", ")", ",", "self", ".", "value_net", "(", "shared_latent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.create_mlp": [[95, 129], ["range", "len", "modules.append", "modules.append", "modules.append", "modules.append", "torch.nn.Linear", "activation_fn", "len", "torch.nn.Linear", "activation_fn", "torch.nn.Linear", "torch.nn.Tanh", "len"], "function", ["None"], ["", "", "def", "create_mlp", "(", "\n", "input_dim", ":", "int", ",", "output_dim", ":", "int", ",", "net_arch", ":", "List", "[", "int", "]", ",", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "ReLU", ",", "squash_output", ":", "bool", "=", "False", "\n", ")", "->", "List", "[", "nn", ".", "Module", "]", ":", "\n", "    ", "\"\"\"\n    Create a multi layer perceptron (MLP), which is\n    a collection of fully-connected layers each followed by an activation function.\n\n    :param input_dim: Dimension of the input vector\n    :param output_dim:\n    :param net_arch: Architecture of the neural net\n        It represents the number of units per layer.\n        The length of this list is the number of layers.\n    :param activation_fn: The activation function\n        to use after each layer.\n    :param squash_output: Whether to squash the output using a Tanh\n        activation function\n    :return:\n    \"\"\"", "\n", "\n", "if", "len", "(", "net_arch", ")", ">", "0", ":", "\n", "        ", "modules", "=", "[", "nn", ".", "Linear", "(", "input_dim", ",", "net_arch", "[", "0", "]", ")", ",", "activation_fn", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "modules", "=", "[", "]", "\n", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "net_arch", ")", "-", "1", ")", ":", "\n", "        ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "net_arch", "[", "idx", "]", ",", "net_arch", "[", "idx", "+", "1", "]", ")", ")", "\n", "modules", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "\n", "", "if", "output_dim", ">", "0", ":", "\n", "        ", "last_layer_dim", "=", "net_arch", "[", "-", "1", "]", "if", "len", "(", "net_arch", ")", ">", "0", "else", "input_dim", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim", ",", "output_dim", ")", ")", "\n", "", "if", "squash_output", ":", "\n", "        ", "modules", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.torch_layers.get_actor_critic_arch": [[227, 265], ["isinstance", "isinstance"], "function", ["None"], ["", "", "def", "get_actor_critic_arch", "(", "net_arch", ":", "Union", "[", "List", "[", "int", "]", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", ")", "->", "Tuple", "[", "List", "[", "int", "]", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Get the actor and critic network architectures for off-policy actor-critic algorithms (SAC, TD3, DDPG).\n\n    The ``net_arch`` parameter allows to specify the amount and size of the hidden layers,\n    which can be different for the actor and the critic.\n    It is assumed to be a list of ints or a dict.\n\n    1. If it is a list, actor and critic networks will have the same architecture.\n        The architecture is represented by a list of integers (of arbitrary length (zero allowed))\n        each specifying the number of units per layer.\n       If the number of ints is zero, the network will be linear.\n    2. If it is a dict,  it should have the following structure:\n       ``dict(qf=[<critic network architecture>], pi=[<actor network architecture>])``.\n       where the network architecture is a list as described in 1.\n\n    For example, to have actor and critic that share the same network architecture,\n    you only need to specify ``net_arch=[256, 256]`` (here, two hidden layers of 256 units each).\n\n    If you want a different architecture for the actor and the critic,\n    then you can specify ``net_arch=dict(qf=[400, 300], pi=[64, 64])``.\n\n    .. note::\n        Compared to their on-policy counterparts, no shared layers (other than the features extractor)\n        between the actor and the critic are allowed (to prevent issues with target networks).\n\n    :param net_arch: The specification of the actor and critic networks.\n        See above for details on its formatting.\n    :return: The network architectures for the actor and the critic\n    \"\"\"", "\n", "if", "isinstance", "(", "net_arch", ",", "list", ")", ":", "\n", "        ", "actor_arch", ",", "critic_arch", "=", "net_arch", ",", "net_arch", "\n", "", "else", ":", "\n", "        ", "assert", "isinstance", "(", "net_arch", ",", "dict", ")", ",", "\"Error: the net_arch can only contain be a list of ints or a dict\"", "\n", "assert", "\"pi\"", "in", "net_arch", ",", "\"Error: no key 'pi' was provided in net_arch for the actor network\"", "\n", "assert", "\"qf\"", "in", "net_arch", ",", "\"Error: no key 'qf' was provided in net_arch for the critic network\"", "\n", "actor_arch", ",", "critic_arch", "=", "net_arch", "[", "\"pi\"", "]", ",", "net_arch", "[", "\"qf\"", "]", "\n", "", "return", "actor_arch", ",", "critic_arch", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.__init__": [[20, 90], ["gym_optimal_intrusion_response.agents.openai_baselines.common.base_class.BaseAlgorithm.__init__", "on_policy_algorithm.OnPolicyAlgorithm._setup_model"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO._setup_model"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "attacker_policy", ":", "Union", "[", "str", ",", "Type", "[", "ActorCriticPolicy", "]", "]", ",", "\n", "defender_policy", ":", "Union", "[", "str", ",", "Type", "[", "ActorCriticPolicy", "]", "]", ",", "\n", "env", ":", "Union", "[", "GymEnv", ",", "str", "]", ",", "\n", "attacker_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", ",", "\n", "defender_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", ",", "\n", "n_steps", ":", "int", ",", "\n", "attacker_gamma", ":", "float", ",", "\n", "defender_gamma", ":", "float", ",", "\n", "attacker_gae_lambda", ":", "float", ",", "\n", "defender_gae_lambda", ":", "float", ",", "\n", "attacker_ent_coef", ":", "float", ",", "\n", "defender_ent_coef", ":", "float", ",", "\n", "attacker_vf_coef", ":", "float", ",", "\n", "defender_vf_coef", ":", "float", ",", "\n", "max_grad_norm", ":", "float", ",", "\n", "tensorboard_log", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "attacker_policy_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "defender_policy_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "attacker_clip_range", ":", "float", "=", "0.2", ",", "\n", "defender_clip_range", ":", "float", "=", "0.2", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", "_init_setup_model", ":", "bool", "=", "True", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ",", "\n", "attacker_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "defender_agent_config", ":", "AgentConfig", "=", "None", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "OnPolicyAlgorithm", ",", "self", ")", ".", "__init__", "(", "\n", "attacker_policy", "=", "attacker_policy", ",", "\n", "defender_policy", "=", "defender_policy", ",", "\n", "env", "=", "env", ",", "\n", "policy_base", "=", "ActorCriticPolicy", ",", "\n", "attacker_learning_rate", "=", "attacker_learning_rate", ",", "\n", "defender_learning_rate", "=", "defender_learning_rate", ",", "\n", "attacker_policy_kwargs", "=", "attacker_policy_kwargs", ",", "\n", "defender_policy_kwargs", "=", "defender_policy_kwargs", ",", "\n", "device", "=", "device", ",", "\n", "seed", "=", "seed", ",", "\n", "tensorboard_log", "=", "tensorboard_log", ",", "\n", "train_mode", "=", "train_mode", ",", "\n", "attacker_agent_config", "=", "attacker_agent_config", ",", "\n", "defender_agent_config", "=", "defender_agent_config", "\n", ")", "\n", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "attacker_gamma", "=", "attacker_gamma", "\n", "self", ".", "defender_gamma", "=", "defender_gamma", "\n", "self", ".", "attacker_gae_lambda", "=", "attacker_gae_lambda", "\n", "self", ".", "defender_gae_lambda", "=", "defender_gae_lambda", "\n", "self", ".", "attacker_ent_coef", "=", "attacker_ent_coef", "\n", "self", ".", "defender_ent_coef", "=", "defender_ent_coef", "\n", "self", ".", "attacker_vf_coef", "=", "attacker_vf_coef", "\n", "self", ".", "defender_vf_coef", "=", "defender_vf_coef", "\n", "self", ".", "attacker_clip_range", "=", "attacker_clip_range", "\n", "self", ".", "defender_clip_range", "=", "defender_clip_range", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "attacker_rollout_buffer", "=", "None", "\n", "self", ".", "defender_rollout_buffer", "=", "None", "\n", "self", ".", "train_mode", "=", "train_mode", "\n", "self", ".", "attacker_agent_config", "=", "attacker_agent_config", "\n", "self", ".", "defender_agent_config", "=", "defender_agent_config", "\n", "self", ".", "iteration", "=", "0", "\n", "self", ".", "num_episodes", "=", "0", "\n", "self", ".", "num_episodes_total", "=", "0", "\n", "\n", "if", "_init_setup_model", ":", "\n", "            ", "self", ".", "_setup_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm._setup_model": [[91, 129], ["on_policy_algorithm.OnPolicyAlgorithm.set_random_seed", "gym_optimal_intrusion_response.agents.openai_baselines.common.buffers.RolloutBuffer", "gym_optimal_intrusion_response.agents.openai_baselines.common.buffers.RolloutBuffer", "on_policy_algorithm.OnPolicyAlgorithm.attacker_policy_class", "on_policy_algorithm.OnPolicyAlgorithm.attacker_policy.to", "on_policy_algorithm.OnPolicyAlgorithm.defender_policy_class", "on_policy_algorithm.OnPolicyAlgorithm.defender_policy.to"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.set_random_seed"], ["", "", "def", "_setup_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "set_random_seed", "(", "self", ".", "seed", ")", "\n", "\n", "self", ".", "attacker_rollout_buffer", "=", "RolloutBuffer", "(", "\n", "self", ".", "n_steps", ",", "\n", "self", ".", "attacker_observation_space", ",", "\n", "self", ".", "attacker_action_space", ",", "\n", "self", ".", "device", ",", "\n", "gamma", "=", "self", ".", "attacker_gamma", ",", "\n", "gae_lambda", "=", "self", ".", "attacker_gae_lambda", ",", "\n", "n_envs", "=", "self", ".", "n_envs", ",", "\n", ")", "\n", "self", ".", "defender_rollout_buffer", "=", "RolloutBuffer", "(", "\n", "self", ".", "n_steps", ",", "\n", "self", ".", "defender_observation_space", ",", "\n", "self", ".", "defender_action_space", ",", "\n", "self", ".", "device", ",", "\n", "gamma", "=", "self", ".", "defender_gamma", ",", "\n", "gae_lambda", "=", "self", ".", "defender_gae_lambda", ",", "\n", "n_envs", "=", "self", ".", "n_envs", ",", "\n", ")", "\n", "self", ".", "attacker_policy", "=", "self", ".", "attacker_policy_class", "(", "\n", "self", ".", "attacker_observation_space", ",", "\n", "self", ".", "attacker_action_space", ",", "\n", "self", ".", "attacker_learning_rate", ",", "\n", "agent_config", "=", "self", ".", "attacker_agent_config", ",", "\n", "**", "self", ".", "attacker_policy_kwargs", "\n", ")", "\n", "self", ".", "attacker_policy", "=", "self", ".", "attacker_policy", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "defender_policy", "=", "self", ".", "defender_policy_class", "(", "\n", "self", ".", "defender_observation_space", ",", "\n", "self", ".", "defender_action_space", ",", "\n", "self", ".", "defender_learning_rate", ",", "\n", "agent_config", "=", "self", ".", "defender_agent_config", ",", "\n", "**", "self", ".", "defender_policy_kwargs", "\n", ")", "\n", "self", ".", "defender_policy", "=", "self", ".", "defender_policy", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.collect_rollouts": [[130, 205], ["attacker_rollout_buffer.reset", "defender_rollout_buffer.reset", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.initialize", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "on_policy_algorithm.OnPolicyAlgorithm.step_policy", "dones.any", "attacker_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "len", "range", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.attacker_episode_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.defender_episode_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_steps.append", "len", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.attacker_episode_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.defender_episode_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_steps.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_flags.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_caught.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_early_stopped.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_successful_intrusion.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_snort_severe_baseline_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_snort_warning_baseline_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_snort_critical_baseline_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_var_log_baseline_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.attacker_action_costs.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.attacker_action_costs_norm.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.attacker_action_alerts.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.attacker_action_alerts_norm.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.episode_flags_percentage.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.optimal_rewards.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.optimal_steps.append", "gym_optimal_intrusion_response.dao.agent.rollout_data_dto.RolloutDataDTO.intrusion_steps.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.initialize", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.step_policy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.compute_returns_and_advantage"], ["", "def", "collect_rollouts", "(", "\n", "self", ",", "env", ":", "VecEnv", ",", "attacker_rollout_buffer", ":", "RolloutBuffer", ",", "\n", "defender_rollout_buffer", ":", "RolloutBuffer", ",", "n_rollout_steps", ":", "int", ")", "->", "Tuple", "[", "bool", ",", "RolloutDataDTO", "]", ":", "\n", "        ", "assert", "self", ".", "_last_obs", "is", "not", "None", ",", "\"No previous observation was provided\"", "\n", "n_steps", "=", "0", "\n", "\n", "attacker_rollout_buffer", ".", "reset", "(", ")", "\n", "defender_rollout_buffer", ".", "reset", "(", ")", "\n", "\n", "# Avg metrics", "\n", "rollout_data_dto", "=", "RolloutDataDTO", "(", ")", "\n", "rollout_data_dto", ".", "initialize", "(", ")", "\n", "\n", "# Per episode metrics", "\n", "episode_reward_attacker", "=", "np", ".", "zeros", "(", "env", ".", "num_envs", ")", "\n", "episode_reward_defender", "=", "np", ".", "zeros", "(", "env", ".", "num_envs", ")", "\n", "episode_step", "=", "np", ".", "zeros", "(", "env", ".", "num_envs", ")", "\n", "\n", "while", "n_steps", "<", "n_rollout_steps", ":", "\n", "\n", "            ", "new_obs", ",", "attacker_rewards", ",", "dones", ",", "infos", ",", "attacker_values", ",", "attacker_log_probs", ",", "attacker_actions", ",", "action_pred_time_s", ",", "env_step_time", ",", "defender_values", ",", "defender_log_probs", ",", "defender_actions", ",", "defender_rewards", "=", "self", ".", "step_policy", "(", "env", ",", "attacker_rollout_buffer", ",", "defender_rollout_buffer", ")", "\n", "\n", "n_steps", "+=", "1", "\n", "episode_reward_attacker", "+=", "attacker_rewards", "\n", "episode_reward_defender", "+=", "defender_rewards", "\n", "episode_step", "+=", "1", "\n", "\n", "if", "dones", ".", "any", "(", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "dones", ")", ")", ":", "\n", "                    ", "if", "dones", "[", "i", "]", ":", "\n", "# Record episode metrics", "\n", "                        ", "rollout_data_dto", ".", "attacker_episode_rewards", ".", "append", "(", "episode_reward_attacker", "[", "i", "]", ")", "\n", "rollout_data_dto", ".", "defender_episode_rewards", ".", "append", "(", "episode_reward_defender", "[", "i", "]", ")", "\n", "rollout_data_dto", ".", "episode_steps", ".", "append", "(", "episode_step", "[", "i", "]", ")", "\n", "rollout_data_dto", ".", "episode_flags", ".", "append", "(", "infos", "[", "i", "]", "[", "\"flags\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_caught", ".", "append", "(", "infos", "[", "i", "]", "[", "\"caught_attacker\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_early_stopped", ".", "append", "(", "infos", "[", "i", "]", "[", "\"early_stopped\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_successful_intrusion", ".", "append", "(", "infos", "[", "i", "]", "[", "\"successful_intrusion\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_snort_severe_baseline_rewards", ".", "append", "(", "\n", "infos", "[", "i", "]", "[", "\"snort_severe_baseline_reward\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_snort_warning_baseline_rewards", ".", "append", "(", "\n", "infos", "[", "i", "]", "[", "\"snort_warning_baseline_reward\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_snort_critical_baseline_rewards", ".", "append", "(", "\n", "infos", "[", "i", "]", "[", "\"snort_critical_baseline_reward\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_var_log_baseline_rewards", ".", "append", "(", "infos", "[", "i", "]", "[", "\"var_log_baseline_reward\"", "]", ")", "\n", "rollout_data_dto", ".", "attacker_action_costs", ".", "append", "(", "infos", "[", "i", "]", "[", "\"attacker_cost\"", "]", ")", "\n", "rollout_data_dto", ".", "attacker_action_costs_norm", ".", "append", "(", "infos", "[", "i", "]", "[", "\"attacker_cost_norm\"", "]", ")", "\n", "rollout_data_dto", ".", "attacker_action_alerts", ".", "append", "(", "infos", "[", "i", "]", "[", "\"attacker_alerts\"", "]", ")", "\n", "rollout_data_dto", ".", "attacker_action_alerts_norm", ".", "append", "(", "infos", "[", "i", "]", "[", "\"attacker_alerts_norm\"", "]", ")", "\n", "rollout_data_dto", ".", "episode_flags_percentage", ".", "append", "(", "\n", "infos", "[", "i", "]", "[", "\"flags\"", "]", "/", "1", ")", "\n", "rollout_data_dto", ".", "optimal_rewards", ".", "append", "(", "infos", "[", "i", "]", "[", "\"optimal_reward\"", "]", ")", "\n", "rollout_data_dto", ".", "optimal_steps", ".", "append", "(", "infos", "[", "i", "]", "[", "\"optimal_step\"", "]", ")", "\n", "if", "infos", "[", "i", "]", "[", "\"caught_attacker\"", "]", "==", "1", ":", "\n", "                            ", "rollout_data_dto", ".", "intrusion_steps", ".", "append", "(", "infos", "[", "i", "]", "[", "\"intrusion_steps\"", "]", ")", "\n", "# print(\"reset reward:{}\".format(episode_reward_attacker))", "\n", "", "episode_reward_attacker", "[", "i", "]", "=", "0", "\n", "episode_reward_defender", "[", "i", "]", "=", "0", "\n", "episode_step", "[", "i", "]", "=", "0", "\n", "\n", "", "", "", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "attacker_rollout_buffer", ".", "compute_returns_and_advantage", "(", "attacker_values", ",", "dones", "=", "dones", ")", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_DEFENDER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "defender_rollout_buffer", ".", "compute_returns_and_advantage", "(", "defender_values", ",", "dones", "=", "dones", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "dones", ")", ")", ":", "\n", "            ", "if", "not", "dones", "[", "i", "]", ":", "\n", "                ", "rollout_data_dto", ".", "attacker_episode_rewards", ".", "append", "(", "episode_reward_attacker", "[", "i", "]", ")", "\n", "rollout_data_dto", ".", "defender_episode_rewards", ".", "append", "(", "episode_reward_defender", "[", "i", "]", ")", "\n", "rollout_data_dto", ".", "episode_steps", ".", "append", "(", "episode_step", "[", "i", "]", ")", "\n", "\n", "", "", "return", "True", ",", "rollout_data_dto", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.train": [[206, 212], ["None"], "methods", ["None"], ["", "def", "train", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Consume current rollout data and update policy parameters.\n        Implemented by individual algorithms.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.learn": [[213, 319], ["print", "on_policy_algorithm.OnPolicyAlgorithm._setup_learn", "gym_optimal_intrusion_response.dao.agent.train_agent_log_dto.TrainAgentLogDTO", "on_policy_algorithm.OnPolicyAlgorithm.initialize", "on_policy_algorithm.OnPolicyAlgorithm.collect_rollouts", "on_policy_algorithm.OnPolicyAlgorithm.attacker_episode_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.defender_episode_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_steps.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_flags.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_caught.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_successful_intrusion.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_early_stopped.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_flags_percentage.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_snort_severe_baseline_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_snort_warning_baseline_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_snort_critical_baseline_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.episode_var_log_baseline_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.attacker_action_costs.extend", "on_policy_algorithm.OnPolicyAlgorithm.attacker_action_costs_norm.extend", "on_policy_algorithm.OnPolicyAlgorithm.attacker_action_alerts.extend", "on_policy_algorithm.OnPolicyAlgorithm.attacker_action_alerts_norm.extend", "on_policy_algorithm.OnPolicyAlgorithm.optimal_rewards.extend", "on_policy_algorithm.OnPolicyAlgorithm.optimal_steps.extend", "on_policy_algorithm.OnPolicyAlgorithm.intrusion_steps.extend", "on_policy_algorithm.OnPolicyAlgorithm.train", "on_policy_algorithm.OnPolicyAlgorithm.attacker_episode_avg_loss.append", "on_policy_algorithm.OnPolicyAlgorithm.defender_episode_avg_loss.append", "gym_optimal_intrusion_response.agents.openai_baselines.common.evaluation.quick_evaluate_policy", "on_policy_algorithm.OnPolicyAlgorithm.initialize", "on_policy_algorithm.OnPolicyAlgorithm.log_metrics_attacker", "on_policy_algorithm.OnPolicyAlgorithm.log_metrics_defender", "on_policy_algorithm.OnPolicyAlgorithm.save_model", "str", "on_policy_algorithm.OnPolicyAlgorithm.train_result.to_csv", "on_policy_algorithm.OnPolicyAlgorithm.eval_result.to_csv", "print", "time.time", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._setup_learn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.initialize", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.collect_rollouts", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.train", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.evaluation.quick_evaluate_policy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.initialize", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.log_metrics_attacker", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.log_metrics_defender", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.save_model", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv"], ["", "def", "learn", "(", "\n", "self", ",", "\n", "total_timesteps", ":", "int", ",", "\n", "log_interval", ":", "int", "=", "1", ",", "\n", "eval_freq", ":", "int", "=", "-", "1", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "tb_log_name", ":", "str", "=", "\"OnPolicyAlgorithm\"", ",", "\n", "eval_log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", ")", "->", "\"OnPolicyAlgorithm\"", ":", "\n", "\n", "        ", "print", "(", "\"Setting up Training Configuration\"", ")", "\n", "\n", "self", ".", "iteration", "=", "0", "\n", "total_timesteps", "=", "self", ".", "_setup_learn", "(", "\n", "total_timesteps", ",", "eval_freq", ",", "n_eval_episodes", ",", "eval_log_path", ",", "reset_num_timesteps", ",", "tb_log_name", "\n", ")", "\n", "\n", "# Tracking metrics", "\n", "train_log_dto", "=", "TrainAgentLogDTO", "(", ")", "\n", "train_log_dto", ".", "initialize", "(", ")", "\n", "train_log_dto", ".", "train_result", "=", "self", ".", "train_result", "\n", "train_log_dto", ".", "eval_result", "=", "self", ".", "eval_result", "\n", "train_log_dto", ".", "iteration", "=", "self", ".", "iteration", "\n", "train_log_dto", ".", "start_time", "=", "self", ".", "training_start", "\n", "\n", "num_iterations", "=", "self", ".", "attacker_agent_config", ".", "num_iterations", "\n", "while", "self", ".", "num_timesteps", "<", "num_iterations", ":", "\n", "\n", "            ", "continue_training", ",", "rollout_data_dto", "=", "self", ".", "collect_rollouts", "(", "\n", "self", ".", "env", ",", "self", ".", "attacker_rollout_buffer", ",", "self", ".", "defender_rollout_buffer", ",", "n_rollout_steps", "=", "self", ".", "n_steps", ")", "\n", "\n", "train_log_dto", ".", "attacker_episode_rewards", ".", "extend", "(", "rollout_data_dto", ".", "attacker_episode_rewards", ")", "\n", "train_log_dto", ".", "defender_episode_rewards", ".", "extend", "(", "rollout_data_dto", ".", "defender_episode_rewards", ")", "\n", "train_log_dto", ".", "episode_steps", ".", "extend", "(", "rollout_data_dto", ".", "episode_steps", ")", "\n", "train_log_dto", ".", "episode_flags", ".", "extend", "(", "rollout_data_dto", ".", "episode_flags", ")", "\n", "train_log_dto", ".", "episode_caught", ".", "extend", "(", "rollout_data_dto", ".", "episode_caught", ")", "\n", "train_log_dto", ".", "episode_successful_intrusion", ".", "extend", "(", "rollout_data_dto", ".", "episode_successful_intrusion", ")", "\n", "train_log_dto", ".", "episode_early_stopped", ".", "extend", "(", "rollout_data_dto", ".", "episode_early_stopped", ")", "\n", "train_log_dto", ".", "episode_flags_percentage", ".", "extend", "(", "rollout_data_dto", ".", "episode_flags_percentage", ")", "\n", "train_log_dto", ".", "episode_snort_severe_baseline_rewards", ".", "extend", "(", "\n", "rollout_data_dto", ".", "episode_snort_severe_baseline_rewards", ")", "\n", "train_log_dto", ".", "episode_snort_warning_baseline_rewards", ".", "extend", "(", "\n", "rollout_data_dto", ".", "episode_snort_warning_baseline_rewards", ")", "\n", "train_log_dto", ".", "episode_snort_critical_baseline_rewards", ".", "extend", "(", "\n", "rollout_data_dto", ".", "episode_snort_critical_baseline_rewards", ")", "\n", "train_log_dto", ".", "episode_var_log_baseline_rewards", ".", "extend", "(", "rollout_data_dto", ".", "episode_var_log_baseline_rewards", ")", "\n", "train_log_dto", ".", "attacker_action_costs", ".", "extend", "(", "rollout_data_dto", ".", "attacker_action_costs", ")", "\n", "train_log_dto", ".", "attacker_action_costs_norm", ".", "extend", "(", "rollout_data_dto", ".", "attacker_action_costs_norm", ")", "\n", "train_log_dto", ".", "attacker_action_alerts", ".", "extend", "(", "rollout_data_dto", ".", "attacker_action_alerts", ")", "\n", "train_log_dto", ".", "attacker_action_alerts_norm", ".", "extend", "(", "rollout_data_dto", ".", "attacker_action_alerts_norm", ")", "\n", "train_log_dto", ".", "optimal_rewards", ".", "extend", "(", "rollout_data_dto", ".", "optimal_rewards", ")", "\n", "train_log_dto", ".", "optimal_steps", ".", "extend", "(", "rollout_data_dto", ".", "optimal_steps", ")", "\n", "train_log_dto", ".", "intrusion_steps", ".", "extend", "(", "rollout_data_dto", ".", "intrusion_steps", ")", "\n", "\n", "if", "continue_training", "is", "False", ":", "\n", "                ", "break", "\n", "\n", "", "self", ".", "iteration", "+=", "1", "\n", "train_log_dto", ".", "iteration", "=", "self", ".", "iteration", "\n", "\n", "if", "self", ".", "iteration", "%", "self", ".", "attacker_agent_config", ".", "train_log_frequency", "==", "0", "or", "self", ".", "iteration", "==", "1", ":", "\n", "                ", "train_log_dto", "=", "quick_evaluate_policy", "(", "\n", "attacker_model", "=", "self", ".", "attacker_policy", ",", "defender_model", "=", "self", ".", "defender_policy", ",", "\n", "env", "=", "self", ".", "env", ",", "n_eval_episodes_train", "=", "self", ".", "attacker_agent_config", ".", "eval_episodes", ",", "\n", "deterministic", "=", "self", ".", "attacker_agent_config", ".", "eval_deterministic", ",", "train_mode", "=", "self", ".", "train_mode", ",", "\n", "train_dto", "=", "train_log_dto", ")", "\n", "\n", "n_af", ",", "n_d", "=", "0", ",", "0", "\n", "\n", "train_log_dto", ".", "n_af", "=", "n_af", "\n", "train_log_dto", ".", "n_d", "=", "n_d", "\n", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "                    ", "train_log_dto", "=", "self", ".", "log_metrics_attacker", "(", "train_log_dto", "=", "train_log_dto", ",", "eval", "=", "False", ")", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_DEFENDER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "                    ", "train_log_dto", "=", "self", ".", "log_metrics_defender", "(", "train_log_dto", "=", "train_log_dto", ",", "eval", "=", "False", ")", "\n", "", "self", ".", "train_result", "=", "train_log_dto", ".", "train_result", "\n", "self", ".", "eval_result", "=", "train_log_dto", ".", "eval_result", "\n", "train_log_dto", ".", "initialize", "(", ")", "\n", "train_log_dto", ".", "train_result", "=", "self", ".", "train_result", "\n", "train_log_dto", ".", "eval_result", "=", "self", ".", "eval_result", "\n", "train_log_dto", ".", "iteration", "=", "self", ".", "iteration", "\n", "train_log_dto", ".", "start_time", "=", "self", ".", "training_start", "\n", "self", ".", "num_episodes", "=", "0", "\n", "\n", "# Save models every <self.config.checkpoint_frequency> iterations", "\n", "", "if", "self", ".", "iteration", "%", "self", ".", "attacker_agent_config", ".", "checkpoint_freq", "==", "0", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "save_model", "(", "self", ".", "iteration", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "\"There was an error saving the model: {}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "", "if", "self", ".", "attacker_agent_config", ".", "save_dir", "is", "not", "None", ":", "\n", "                    ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "train_result", ".", "to_csv", "(", "\n", "self", ".", "attacker_agent_config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_train_results_checkpoint.csv\"", ")", "\n", "self", ".", "eval_result", ".", "to_csv", "(", "\n", "self", ".", "attacker_agent_config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_eval_results_checkpoint.csv\"", ")", "\n", "\n", "", "", "entropy_loss_attacker", ",", "pg_loss_attacker", ",", "value_loss_attacker", ",", "lr_attacker", ",", "entropy_loss_defender", ",", "pg_loss_defender", ",", "value_loss_defender", ",", "lr_defender", ",", "=", "self", ".", "train", "(", ")", "\n", "\n", "train_log_dto", ".", "attacker_episode_avg_loss", ".", "append", "(", "entropy_loss_attacker", "+", "pg_loss_attacker", "+", "value_loss_attacker", ")", "\n", "train_log_dto", ".", "defender_episode_avg_loss", ".", "append", "(", "entropy_loss_defender", "+", "pg_loss_defender", "+", "value_loss_defender", ")", "\n", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm._get_torch_save_params": [[320, 325], ["None"], "methods", ["None"], ["", "def", "_get_torch_save_params", "(", "self", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "state_dicts", "=", "[", "\"attacker_policy\"", ",", "\"attacker_policy.optimizer\"", ",", "\n", "\"defender_policy\"", ",", "\"defender_policy.optimizer\"", "]", "\n", "\n", "return", "state_dicts", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.step_policy": [[328, 384], ["range", "env.step", "attacker_actions.cpu().numpy.cpu().numpy.reshape", "defender_actions.cpu().numpy.cpu().numpy.reshape", "on_policy_algorithm.OnPolicyAlgorithm.get_attacker_and_defender_obs", "on_policy_algorithm.OnPolicyAlgorithm.get_attacker_and_defender_reward", "torch.no_grad", "isinstance", "torch.as_tensor().to", "torch.as_tensor().to", "numpy.array", "numpy.array", "len", "actions.append", "attacker_rollout_buffer.add", "defender_rollout_buffer.add", "on_policy_algorithm.OnPolicyAlgorithm.attacker_policy.forward", "attacker_actions.cpu().numpy.cpu().numpy.cpu().numpy", "on_policy_algorithm.OnPolicyAlgorithm.defender_policy.forward", "defender_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor", "torch.as_tensor", "len", "len", "attacker_actions.cpu().numpy.cpu().numpy.cpu", "defender_actions.cpu().numpy.cpu().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.get_attacker_and_defender_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.get_attacker_and_defender_reward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.forward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.forward"], ["", "def", "step_policy", "(", "self", ",", "env", ",", "attacker_rollout_buffer", ",", "defender_rollout_buffer", ")", ":", "\n", "        ", "action_pred_time", "=", "0.0", "\n", "env_step_time", "=", "0.0", "\n", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "# Convert to pytorch tensor", "\n", "            ", "if", "isinstance", "(", "self", ".", "_last_obs", ",", "tuple", ")", ":", "\n", "                ", "attacker_obs", ",", "defender_obs", "=", "self", ".", "_last_obs", "\n", "", "obs_tensor_attacker", "=", "th", ".", "as_tensor", "(", "attacker_obs", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "obs_tensor_defender", "=", "th", ".", "as_tensor", "(", "defender_obs", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attacker_actions", "=", "None", "\n", "attacker_values", "=", "None", "\n", "attacker_log_probs", "=", "None", "\n", "defender_actions", "=", "None", "\n", "defender_values", "=", "None", "\n", "defender_log_probs", "=", "None", "\n", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "                ", "attacker_actions", ",", "attacker_values", ",", "attacker_log_probs", "=", "self", ".", "attacker_policy", ".", "forward", "(", "obs_tensor_attacker", ",", "attacker", "=", "True", ",", "env", "=", "env", ")", "\n", "attacker_actions", "=", "attacker_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_DEFENDER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "                ", "defender_actions", ",", "defender_values", ",", "defender_log_probs", "=", "self", ".", "defender_policy", ".", "forward", "(", "obs_tensor_defender", ",", "attacker", "=", "False", ",", "env", "=", "env", ")", "\n", "defender_actions", "=", "defender_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "if", "attacker_actions", "is", "None", ":", "\n", "            ", "attacker_actions", "=", "np", ".", "array", "(", "[", "None", "]", "*", "len", "(", "defender_actions", ")", ")", "\n", "\n", "", "if", "defender_actions", "is", "None", ":", "\n", "            ", "defender_actions", "=", "np", ".", "array", "(", "[", "None", "]", "*", "len", "(", "attacker_actions", ")", ")", "\n", "\n", "", "actions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "attacker_actions", ")", ")", ":", "\n", "            ", "actions", ".", "append", "(", "(", "attacker_actions", "[", "i", "]", ",", "defender_actions", "[", "i", "]", ")", ")", "\n", "\n", "", "new_obs", ",", "rewards", ",", "dones", ",", "infos", "=", "env", ".", "step", "(", "actions", ")", "\n", "\n", "attacker_actions", "=", "attacker_actions", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "defender_actions", "=", "defender_actions", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "get_attacker_and_defender_obs", "(", "self", ".", "_last_obs", ")", "\n", "attacker_rewards", ",", "defender_rewards", "=", "self", ".", "get_attacker_and_defender_reward", "(", "rewards", ")", "\n", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "attacker_rollout_buffer", ".", "add", "(", "attacker_obs", ",", "attacker_actions", ",", "attacker_rewards", ",", "self", ".", "_last_dones", ",", "\n", "attacker_values", ",", "attacker_log_probs", ")", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_DEFENDER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "defender_rollout_buffer", ".", "add", "(", "defender_obs", ",", "defender_actions", ",", "defender_rewards", ",", "self", ".", "_last_dones", ",", "\n", "defender_values", ",", "defender_log_probs", ")", "\n", "\n", "", "self", ".", "_last_obs", "=", "new_obs", "\n", "self", ".", "_last_dones", "=", "dones", "\n", "self", ".", "_last_infos", "=", "infos", "\n", "\n", "return", "new_obs", ",", "attacker_rewards", ",", "dones", ",", "infos", ",", "attacker_values", ",", "attacker_log_probs", ",", "attacker_actions", ",", "action_pred_time", ",", "env_step_time", ",", "defender_values", ",", "defender_log_probs", ",", "defender_actions", ",", "defender_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.get_attacker_and_defender_obs": [[386, 402], ["isinstance", "range", "numpy.array", "numpy.array", "attacker_obs.astype.astype.astype", "defender_obs.astype.astype.astype", "len", "attacker_obs.astype.astype.append", "defender_obs.astype.astype.append"], "methods", ["None"], ["", "def", "get_attacker_and_defender_obs", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "isinstance", "(", "obs", ",", "tuple", ")", ":", "\n", "            ", "return", "obs", "[", "0", "]", ",", "obs", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "attacker_obs", "=", "[", "]", "\n", "defender_obs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "obs", ")", ")", ":", "\n", "                ", "a_o", "=", "obs", "[", "i", "]", "[", "0", "]", "\n", "d_o", "=", "obs", "[", "i", "]", "[", "1", "]", "\n", "attacker_obs", ".", "append", "(", "a_o", ")", "\n", "defender_obs", ".", "append", "(", "d_o", ")", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "attacker_obs", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "defender_obs", ")", "\n", "attacker_obs", "=", "attacker_obs", ".", "astype", "(", "\"float64\"", ")", "\n", "defender_obs", "=", "defender_obs", ".", "astype", "(", "\"float64\"", ")", "\n", "return", "attacker_obs", ",", "defender_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.on_policy_algorithm.OnPolicyAlgorithm.get_attacker_and_defender_reward": [[403, 419], ["isinstance", "range", "numpy.array", "numpy.array", "attacker_reward.astype.astype.astype", "defender_reward.astype.astype.astype", "len", "attacker_reward.astype.astype.append", "defender_reward.astype.astype.append"], "methods", ["None"], ["", "", "def", "get_attacker_and_defender_reward", "(", "self", ",", "rewards", ")", ":", "\n", "        ", "if", "isinstance", "(", "rewards", ",", "tuple", ")", ":", "\n", "            ", "return", "rewards", "[", "0", "]", ",", "rewards", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "attacker_reward", "=", "[", "]", "\n", "defender_reward", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "rewards", ")", ")", ":", "\n", "                ", "a_r", "=", "rewards", "[", "i", "]", "[", "0", "]", "\n", "d_r", "=", "rewards", "[", "i", "]", "[", "1", "]", "\n", "attacker_reward", ".", "append", "(", "a_r", ")", "\n", "defender_reward", ".", "append", "(", "d_r", ")", "\n", "", "attacker_reward", "=", "np", ".", "array", "(", "attacker_reward", ")", "\n", "defender_reward", "=", "np", ".", "array", "(", "defender_reward", ")", "\n", "attacker_reward", "=", "attacker_reward", ".", "astype", "(", "\"float64\"", ")", "\n", "defender_reward", "=", "defender_reward", ".", "astype", "(", "\"float64\"", ")", "\n", "return", "attacker_reward", ",", "defender_reward", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.__init__": [[28, 67], ["gym.GoalEnv.__init__", "gym.spaces.MultiBinary", "numpy.ones", "gym.spaces.Dict", "gym.spaces.Dict", "gym.spaces.Box", "gym.spaces.Discrete", "gym.spaces.Discrete", "gym.spaces.Discrete", "gym.spaces.Discrete", "gym.spaces.MultiBinary", "gym.spaces.MultiBinary", "gym.spaces.MultiBinary"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "n_bits", ":", "int", "=", "10", ",", "continuous", ":", "bool", "=", "False", ",", "max_steps", ":", "Optional", "[", "int", "]", "=", "None", ",", "discrete_obs_space", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "BitFlippingEnv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# The achieved goal is determined by the current state", "\n", "# here, it is a special where they are equal", "\n", "if", "discrete_obs_space", ":", "\n", "# In the discrete case, the agent act on the binary", "\n", "# representation of the observation", "\n", "            ", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "\n", "{", "\n", "\"observation\"", ":", "spaces", ".", "Discrete", "(", "2", "**", "n_bits", "-", "1", ")", ",", "\n", "\"achieved_goal\"", ":", "spaces", ".", "Discrete", "(", "2", "**", "n_bits", "-", "1", ")", ",", "\n", "\"desired_goal\"", ":", "spaces", ".", "Discrete", "(", "2", "**", "n_bits", "-", "1", ")", ",", "\n", "}", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "\n", "{", "\n", "\"observation\"", ":", "spaces", ".", "MultiBinary", "(", "n_bits", ")", ",", "\n", "\"achieved_goal\"", ":", "spaces", ".", "MultiBinary", "(", "n_bits", ")", ",", "\n", "\"desired_goal\"", ":", "spaces", ".", "MultiBinary", "(", "n_bits", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "", "self", ".", "obs_space", "=", "spaces", ".", "MultiBinary", "(", "n_bits", ")", "\n", "\n", "if", "continuous", ":", "\n", "            ", "self", ".", "action_space", "=", "spaces", ".", "Box", "(", "-", "1", ",", "1", ",", "shape", "=", "(", "n_bits", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "n_bits", ")", "\n", "", "self", ".", "continuous", "=", "continuous", "\n", "self", ".", "discrete_obs_space", "=", "discrete_obs_space", "\n", "self", ".", "state", "=", "None", "\n", "self", ".", "desired_goal", "=", "np", ".", "ones", "(", "(", "n_bits", ",", ")", ")", "\n", "if", "max_steps", "is", "None", ":", "\n", "            ", "max_steps", "=", "n_bits", "\n", "", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "current_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.seed": [[68, 70], ["bit_flipping_env.BitFlippingEnv.obs_space.seed"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", ":", "int", ")", "->", "None", ":", "\n", "        ", "self", ".", "obs_space", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.convert_if_needed": [[71, 83], ["int", "sum", "range", "len"], "methods", ["None"], ["", "def", "convert_if_needed", "(", "self", ",", "state", ":", "np", ".", "ndarray", ")", "->", "Union", "[", "int", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Convert to discrete space if needed.\n\n        :param state:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "discrete_obs_space", ":", "\n", "# The internal state is the binary representation of the", "\n", "# observed one", "\n", "            ", "return", "int", "(", "sum", "(", "[", "state", "[", "i", "]", "*", "2", "**", "i", "for", "i", "in", "range", "(", "len", "(", "state", ")", ")", "]", ")", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv._get_obs": [[84, 95], ["collections.OrderedDict", "bit_flipping_env.BitFlippingEnv.convert_if_needed", "bit_flipping_env.BitFlippingEnv.convert_if_needed", "bit_flipping_env.BitFlippingEnv.convert_if_needed", "bit_flipping_env.BitFlippingEnv.state.copy", "bit_flipping_env.BitFlippingEnv.state.copy", "bit_flipping_env.BitFlippingEnv.desired_goal.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.convert_if_needed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.convert_if_needed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.convert_if_needed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "_get_obs", "(", "self", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Helper to create the observation.\n\n        :return:\n        \"\"\"", "\n", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "\"observation\"", ",", "self", ".", "convert_if_needed", "(", "self", ".", "state", ".", "copy", "(", ")", ")", ")", ",", "\n", "(", "\"achieved_goal\"", ",", "self", ".", "convert_if_needed", "(", "self", ".", "state", ".", "copy", "(", ")", ")", ")", ",", "\n", "(", "\"desired_goal\"", ",", "self", ".", "convert_if_needed", "(", "self", ".", "desired_goal", ".", "copy", "(", ")", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.reset": [[98, 102], ["bit_flipping_env.BitFlippingEnv.obs_space.sample", "bit_flipping_env.BitFlippingEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv._get_obs"], ["", "def", "reset", "(", "self", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "self", ".", "current_step", "=", "0", "\n", "self", ".", "state", "=", "self", ".", "obs_space", ".", "sample", "(", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.step": [[103, 116], ["bit_flipping_env.BitFlippingEnv._get_obs", "float", "bit_flipping_env.BitFlippingEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv._get_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.compute_reward"], ["", "def", "step", "(", "self", ",", "action", ":", "Union", "[", "np", ".", "ndarray", ",", "int", "]", ")", "->", "GymStepReturn", ":", "\n", "        ", "if", "self", ".", "continuous", ":", "\n", "            ", "self", ".", "state", "[", "action", ">", "0", "]", "=", "1", "-", "self", ".", "state", "[", "action", ">", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "state", "[", "action", "]", "=", "1", "-", "self", ".", "state", "[", "action", "]", "\n", "", "obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "reward", "=", "float", "(", "self", ".", "compute_reward", "(", "obs", "[", "\"achieved_goal\"", "]", ",", "obs", "[", "\"desired_goal\"", "]", ",", "None", ")", ")", "\n", "done", "=", "reward", "==", "0", "\n", "self", ".", "current_step", "+=", "1", "\n", "# Episode terminate when we reached the goal or the max number of steps", "\n", "info", "=", "{", "\"is_success\"", ":", "done", "}", "\n", "done", "=", "done", "or", "self", ".", "current_step", ">=", "self", ".", "max_steps", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.compute_reward": [[117, 124], ["numpy.linalg.norm"], "methods", ["None"], ["", "def", "compute_reward", "(", "\n", "self", ",", "achieved_goal", ":", "Union", "[", "int", ",", "np", ".", "ndarray", "]", ",", "desired_goal", ":", "Union", "[", "int", ",", "np", ".", "ndarray", "]", ",", "_info", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "\n", ")", "->", "np", ".", "float32", ":", "\n", "# Deceptive reward: it is positive only when the goal is achieved", "\n", "# vectorized version", "\n", "        ", "distance", "=", "np", ".", "linalg", ".", "norm", "(", "achieved_goal", "-", "desired_goal", ",", "axis", "=", "-", "1", ")", "\n", "return", "-", "(", "distance", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.render": [[125, 129], ["print", "bit_flipping_env.BitFlippingEnv.state.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "\"human\"", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "if", "mode", "==", "\"rgb_array\"", ":", "\n", "            ", "return", "self", ".", "state", ".", "copy", "(", ")", "\n", "", "print", "(", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.bit_flipping_env.BitFlippingEnv.close": [[130, 132], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Video.__init__": [[35, 38], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "frames", ":", "th", ".", "Tensor", ",", "fps", ":", "Union", "[", "float", ",", "int", "]", ")", ":", "\n", "        ", "self", ".", "frames", "=", "frames", "\n", "self", ".", "fps", "=", "fps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Figure.__init__": [[48, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "figure", ":", "plt", ".", "figure", ",", "close", ":", "bool", ")", ":", "\n", "        ", "self", ".", "figure", "=", "figure", "\n", "self", ".", "close", "=", "close", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Image.__init__": [[63, 66], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "image", ":", "Union", "[", "th", ".", "Tensor", ",", "np", ".", "ndarray", ",", "str", "]", ",", "dataformats", ":", "str", ")", ":", "\n", "        ", "self", ".", "image", "=", "image", "\n", "self", ".", "dataformats", "=", "dataformats", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.FormatUnsupportedError.__init__": [[69, 76], ["NotImplementedError.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "unsupported_formats", ":", "Sequence", "[", "str", "]", ",", "value_description", ":", "str", ")", ":", "\n", "        ", "if", "len", "(", "unsupported_formats", ")", ">", "1", ":", "\n", "            ", "format_str", "=", "f\"formats {', '.join(unsupported_formats)} are\"", "\n", "", "else", ":", "\n", "            ", "format_str", "=", "f\"format {unsupported_formats[0]} is\"", "\n", "", "super", "(", "FormatUnsupportedError", ",", "self", ")", ".", "__init__", "(", "\n", "f\"The {format_str} not supported for the {value_description} value logged.\\n\"", "\n", "f\"You can exclude formats via the `exclude` parameter of the logger's `record` function.\"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.KVWriter.write": [[85, 94], ["None"], "methods", ["None"], ["def", "write", "(", "self", ",", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ",", "key_excluded", ":", "Dict", "[", "str", ",", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", ",", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write a dictionary to file\n\n        :param key_values:\n        :param key_excluded:\n        :param step:\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.KVWriter.close": [[95, 100], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Close owned resources\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.SeqWriter.write_sequence": [[107, 114], ["None"], "methods", ["None"], ["def", "write_sequence", "(", "self", ",", "sequence", ":", "List", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        write_sequence an array to file\n\n        :param sequence:\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat.__init__": [[117, 130], ["isinstance", "open", "hasattr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename_or_file", ":", "Union", "[", "str", ",", "TextIO", "]", ")", ":", "\n", "        ", "\"\"\"\n        log to a file, in a human readable format\n\n        :param filename_or_file: the file to write the log to\n        \"\"\"", "\n", "if", "isinstance", "(", "filename_or_file", ",", "str", ")", ":", "\n", "            ", "self", ".", "file", "=", "open", "(", "filename_or_file", ",", "\"wt\"", ")", "\n", "self", ".", "own_file", "=", "True", "\n", "", "else", ":", "\n", "            ", "assert", "hasattr", "(", "filename_or_file", ",", "\"write\"", ")", ",", "f\"Expected file or str, got {filename_or_file}\"", "\n", "self", ".", "file", "=", "filename_or_file", "\n", "self", ".", "own_file", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat.write": [[131, 184], ["zip", "key2str.items", "lines.append", "logger.HumanOutputFormat.file.write", "logger.HumanOutputFormat.file.flush", "sorted", "sorted", "logger.HumanOutputFormat._truncate", "len", "warnings.warn", "max", "max", "lines.append", "key_values.items", "key_excluded.items", "isinstance", "str.find", "str", "map", "map", "logger.FormatUnsupportedError", "isinstance", "logger.HumanOutputFormat._truncate", "key2str.keys", "key2str.values", "len", "len", "logger.FormatUnsupportedError", "isinstance", "logger.HumanOutputFormat._truncate", "logger.FormatUnsupportedError", "isinstance", "str.find", "str", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat._truncate", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat._truncate", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat._truncate"], ["", "", "def", "write", "(", "self", ",", "key_values", ":", "Dict", ",", "key_excluded", ":", "Dict", ",", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "# Create strings for printing", "\n", "        ", "key2str", "=", "{", "}", "\n", "tag", "=", "None", "\n", "for", "(", "key", ",", "value", ")", ",", "(", "_", ",", "excluded", ")", "in", "zip", "(", "sorted", "(", "key_values", ".", "items", "(", ")", ")", ",", "sorted", "(", "key_excluded", ".", "items", "(", ")", ")", ")", ":", "\n", "\n", "            ", "if", "excluded", "is", "not", "None", "and", "(", "\"stdout\"", "in", "excluded", "or", "\"log\"", "in", "excluded", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Video", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"stdout\"", ",", "\"log\"", "]", ",", "\"video\"", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Figure", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"stdout\"", ",", "\"log\"", "]", ",", "\"figure\"", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Image", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"stdout\"", ",", "\"log\"", "]", ",", "\"image\"", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "float", ")", ":", "\n", "# Align left", "\n", "                ", "value_str", "=", "f\"{value:<8.3g}\"", "\n", "", "else", ":", "\n", "                ", "value_str", "=", "str", "(", "value", ")", "\n", "\n", "", "if", "key", ".", "find", "(", "\"/\"", ")", ">", "0", ":", "# Find tag and add it to the dict", "\n", "                ", "tag", "=", "key", "[", ":", "key", ".", "find", "(", "\"/\"", ")", "+", "1", "]", "\n", "key2str", "[", "self", ".", "_truncate", "(", "tag", ")", "]", "=", "\"\"", "\n", "# Remove tag from key", "\n", "", "if", "tag", "is", "not", "None", "and", "tag", "in", "key", ":", "\n", "                ", "key", "=", "str", "(", "\"   \"", "+", "key", "[", "len", "(", "tag", ")", ":", "]", ")", "\n", "\n", "", "key2str", "[", "self", ".", "_truncate", "(", "key", ")", "]", "=", "self", ".", "_truncate", "(", "value_str", ")", "\n", "\n", "# Find max widths", "\n", "", "if", "len", "(", "key2str", ")", "==", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Tried to write empty key-value dict\"", ")", "\n", "return", "\n", "", "else", ":", "\n", "            ", "key_width", "=", "max", "(", "map", "(", "len", ",", "key2str", ".", "keys", "(", ")", ")", ")", "\n", "val_width", "=", "max", "(", "map", "(", "len", ",", "key2str", ".", "values", "(", ")", ")", ")", "\n", "\n", "# Write out the data", "\n", "", "dashes", "=", "\"-\"", "*", "(", "key_width", "+", "val_width", "+", "7", ")", "\n", "lines", "=", "[", "dashes", "]", "\n", "for", "key", ",", "value", "in", "key2str", ".", "items", "(", ")", ":", "\n", "            ", "key_space", "=", "\" \"", "*", "(", "key_width", "-", "len", "(", "key", ")", ")", "\n", "val_space", "=", "\" \"", "*", "(", "val_width", "-", "len", "(", "value", ")", ")", "\n", "lines", ".", "append", "(", "f\"| {key}{key_space} | {value}{val_space} |\"", ")", "\n", "", "lines", ".", "append", "(", "dashes", ")", "\n", "self", ".", "file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "lines", ")", "+", "\"\\n\"", ")", "\n", "\n", "# Flush the output to the file", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat._truncate": [[185, 188], ["len"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_truncate", "(", "cls", ",", "string", ":", "str", ",", "max_length", ":", "int", "=", "23", ")", "->", "str", ":", "\n", "        ", "return", "string", "[", ":", "max_length", "-", "3", "]", "+", "\"...\"", "if", "len", "(", "string", ")", ">", "max_length", "else", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat.write_sequence": [[189, 197], ["list", "enumerate", "logger.HumanOutputFormat.file.write", "logger.HumanOutputFormat.file.flush", "logger.HumanOutputFormat.file.write", "logger.HumanOutputFormat.file.write", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write"], ["", "def", "write_sequence", "(", "self", ",", "sequence", ":", "List", ")", "->", "None", ":", "\n", "        ", "sequence", "=", "list", "(", "sequence", ")", "\n", "for", "i", ",", "elem", "in", "enumerate", "(", "sequence", ")", ":", "\n", "            ", "self", ".", "file", ".", "write", "(", "elem", ")", "\n", "if", "i", "<", "len", "(", "sequence", ")", "-", "1", ":", "# add space unless this is the last one", "\n", "                ", "self", ".", "file", ".", "write", "(", "\" \"", ")", "\n", "", "", "self", ".", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat.close": [[198, 204], ["logger.HumanOutputFormat.file.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        closes the file\n        \"\"\"", "\n", "if", "self", ".", "own_file", ":", "\n", "            ", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.JSONOutputFormat.__init__": [[225, 232], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        log to a file, in the JSON format\n\n        :param filename: the file to write the log to\n        \"\"\"", "\n", "self", ".", "file", "=", "open", "(", "filename", ",", "\"wt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.JSONOutputFormat.write": [[233, 256], ["logger.JSONOutputFormat.file.write", "logger.JSONOutputFormat.file.flush", "isinstance", "isinstance", "isinstance", "hasattr", "logger.JSONOutputFormat.write.cast_to_json_serializable"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write"], ["", "def", "write", "(", "self", ",", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ",", "key_excluded", ":", "Dict", "[", "str", ",", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", ",", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "def", "cast_to_json_serializable", "(", "value", ":", "Any", ")", ":", "\n", "            ", "if", "isinstance", "(", "value", ",", "Video", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"json\"", "]", ",", "\"video\"", ")", "\n", "", "if", "isinstance", "(", "value", ",", "Figure", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"json\"", "]", ",", "\"figure\"", ")", "\n", "", "if", "isinstance", "(", "value", ",", "Image", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"json\"", "]", ",", "\"image\"", ")", "\n", "", "if", "hasattr", "(", "value", ",", "\"dtype\"", ")", ":", "\n", "                ", "if", "value", ".", "shape", "==", "(", ")", "or", "len", "(", "value", ")", "==", "1", ":", "\n", "# if value is a dimensionless numpy array or of length 1, serialize as a float", "\n", "                    ", "return", "float", "(", "value", ")", "\n", "", "else", ":", "\n", "# otherwise, a value is a numpy array, serialize as a list or nested lists", "\n", "                    ", "return", "value", ".", "tolist", "(", ")", "\n", "", "", "return", "value", "\n", "\n", "", "key_values", "=", "{", "\n", "key", ":", "cast_to_json_serializable", "(", "value", ")", "\n", "for", "key", ",", "value", "in", "filter_excluded_keys", "(", "key_values", ",", "key_excluded", ",", "\"json\"", ")", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "file", ".", "write", "(", "json", ".", "dumps", "(", "key_values", ")", "+", "\"\\n\"", ")", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.JSONOutputFormat.close": [[257, 263], ["logger.JSONOutputFormat.file.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        closes the file\n        \"\"\"", "\n", "\n", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.CSVOutputFormat.__init__": [[266, 277], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        log to a file, in a CSV format\n\n        :param filename: the file to write the log to\n        \"\"\"", "\n", "\n", "self", ".", "file", "=", "open", "(", "filename", ",", "\"w+t\"", ")", "\n", "self", ".", "keys", "=", "[", "]", "\n", "self", ".", "separator", "=", "\",\"", "\n", "self", ".", "quotechar", "=", "'\"'", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.CSVOutputFormat.write": [[278, 321], ["logger.filter_excluded_keys", "enumerate", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.flush", "filter_excluded_keys.keys", "logger.CSVOutputFormat.keys.extend", "logger.CSVOutputFormat.file.seek", "logger.CSVOutputFormat.file.readlines", "logger.CSVOutputFormat.file.seek", "enumerate", "logger.CSVOutputFormat.file.write", "filter_excluded_keys.get", "isinstance", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.FormatUnsupportedError", "isinstance", "logger.CSVOutputFormat.file.write", "logger.FormatUnsupportedError", "isinstance", "len", "logger.FormatUnsupportedError", "isinstance", "value.replace.replace.replace", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.filter_excluded_keys", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write"], ["", "def", "write", "(", "self", ",", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ",", "key_excluded", ":", "Dict", "[", "str", ",", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", ",", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "# Add our current row to the history", "\n", "        ", "key_values", "=", "filter_excluded_keys", "(", "key_values", ",", "key_excluded", ",", "\"csv\"", ")", "\n", "extra_keys", "=", "key_values", ".", "keys", "(", ")", "-", "self", ".", "keys", "\n", "if", "extra_keys", ":", "\n", "            ", "self", ".", "keys", ".", "extend", "(", "extra_keys", ")", "\n", "self", ".", "file", ".", "seek", "(", "0", ")", "\n", "lines", "=", "self", ".", "file", ".", "readlines", "(", ")", "\n", "self", ".", "file", ".", "seek", "(", "0", ")", "\n", "for", "(", "i", ",", "key", ")", "in", "enumerate", "(", "self", ".", "keys", ")", ":", "\n", "                ", "if", "i", ">", "0", ":", "\n", "                    ", "self", ".", "file", ".", "write", "(", "\",\"", ")", "\n", "", "self", ".", "file", ".", "write", "(", "key", ")", "\n", "", "self", ".", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "for", "line", "in", "lines", "[", "1", ":", "]", ":", "\n", "                ", "self", ".", "file", ".", "write", "(", "line", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "file", ".", "write", "(", "self", ".", "separator", "*", "len", "(", "extra_keys", ")", ")", "\n", "self", ".", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "", "", "for", "i", ",", "key", "in", "enumerate", "(", "self", ".", "keys", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "self", ".", "file", ".", "write", "(", "\",\"", ")", "\n", "", "value", "=", "key_values", ".", "get", "(", "key", ")", "\n", "\n", "if", "isinstance", "(", "value", ",", "Video", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"csv\"", "]", ",", "\"video\"", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Figure", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"csv\"", "]", ",", "\"figure\"", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Image", ")", ":", "\n", "                ", "raise", "FormatUnsupportedError", "(", "[", "\"csv\"", "]", ",", "\"image\"", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "# escape quotechars by prepending them with another quotechar", "\n", "                ", "value", "=", "value", ".", "replace", "(", "self", ".", "quotechar", ",", "self", ".", "quotechar", "+", "self", ".", "quotechar", ")", "\n", "\n", "# additionally wrap text with quotechars so that any delimiters in the text are ignored by csv readers", "\n", "self", ".", "file", ".", "write", "(", "self", ".", "quotechar", "+", "value", "+", "self", ".", "quotechar", ")", "\n", "\n", "", "elif", "value", "is", "not", "None", ":", "\n", "                ", "self", ".", "file", ".", "write", "(", "str", "(", "value", ")", ")", "\n", "", "", "self", ".", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.CSVOutputFormat.close": [[322, 327], ["logger.CSVOutputFormat.file.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        closes the file\n        \"\"\"", "\n", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.__init__": [[330, 338], ["SummaryWriter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "folder", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Dumps key/value pairs into TensorBoard's numeric format.\n\n        :param folder: the folder to write the log to\n        \"\"\"", "\n", "assert", "SummaryWriter", "is", "not", "None", ",", "\"tensorboard is not installed, you can use \"", "\"pip install tensorboard to do so\"", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write": [[339, 367], ["zip", "logger.TensorBoardOutputFormat.writer.flush", "sorted", "sorted", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "key_values.items", "key_excluded.items", "isinstance", "logger.TensorBoardOutputFormat.writer.add_histogram", "logger.TensorBoardOutputFormat.writer.add_video", "logger.TensorBoardOutputFormat.writer.add_figure", "logger.TensorBoardOutputFormat.writer.add_image", "logger.TensorBoardOutputFormat.writer.add_text", "logger.TensorBoardOutputFormat.writer.add_scalar"], "methods", ["None"], ["", "def", "write", "(", "self", ",", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ",", "key_excluded", ":", "Dict", "[", "str", ",", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", ",", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "\n", "        ", "for", "(", "key", ",", "value", ")", ",", "(", "_", ",", "excluded", ")", "in", "zip", "(", "sorted", "(", "key_values", ".", "items", "(", ")", ")", ",", "sorted", "(", "key_excluded", ".", "items", "(", ")", ")", ")", ":", "\n", "\n", "            ", "if", "excluded", "is", "not", "None", "and", "\"tensorboard\"", "in", "excluded", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "isinstance", "(", "value", ",", "np", ".", "ScalarType", ")", ":", "\n", "                ", "if", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "# str is considered a np.ScalarType", "\n", "                    ", "self", ".", "writer", ".", "add_text", "(", "key", ",", "value", ",", "step", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "key", ",", "value", ",", "step", ")", "\n", "\n", "", "", "if", "isinstance", "(", "value", ",", "th", ".", "Tensor", ")", ":", "\n", "                ", "self", ".", "writer", ".", "add_histogram", "(", "key", ",", "value", ",", "step", ")", "\n", "\n", "", "if", "isinstance", "(", "value", ",", "Video", ")", ":", "\n", "                ", "self", ".", "writer", ".", "add_video", "(", "key", ",", "value", ".", "frames", ",", "step", ",", "value", ".", "fps", ")", "\n", "\n", "", "if", "isinstance", "(", "value", ",", "Figure", ")", ":", "\n", "                ", "self", ".", "writer", ".", "add_figure", "(", "key", ",", "value", ".", "figure", ",", "step", ",", "close", "=", "value", ".", "close", ")", "\n", "\n", "", "if", "isinstance", "(", "value", ",", "Image", ")", ":", "\n", "                ", "self", ".", "writer", ".", "add_image", "(", "key", ",", "value", ".", "image", ",", "step", ",", "dataformats", "=", "value", ".", "dataformats", ")", "\n", "\n", "# Flush the output to the file", "\n", "", "", "self", ".", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.close": [[368, 375], ["logger.TensorBoardOutputFormat.writer.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        closes the file\n        \"\"\"", "\n", "if", "self", ".", "writer", ":", "\n", "            ", "self", ".", "writer", ".", "close", "(", ")", "\n", "self", ".", "writer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.__init__": [[556, 569], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "folder", ":", "Optional", "[", "str", "]", ",", "output_formats", ":", "List", "[", "KVWriter", "]", ")", ":", "\n", "        ", "\"\"\"\n        the logger class\n\n        :param folder: the logging location\n        :param output_formats: the list of output format\n        \"\"\"", "\n", "self", ".", "name_to_value", "=", "defaultdict", "(", "float", ")", "# values this iteration", "\n", "self", ".", "name_to_count", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "name_to_excluded", "=", "defaultdict", "(", "str", ")", "\n", "self", ".", "level", "=", "INFO", "\n", "self", ".", "dir", "=", "folder", "\n", "self", ".", "output_formats", "=", "output_formats", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.record": [[572, 584], ["None"], "methods", ["None"], ["", "def", "record", "(", "self", ",", "key", ":", "str", ",", "value", ":", "Any", ",", "exclude", ":", "Optional", "[", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log a value of some diagnostic\n        Call this once for each diagnostic quantity, each iteration\n        If called many times, last value will be used.\n\n        :param key: save to log this key\n        :param value: save to log this value\n        :param exclude: outputs to be excluded\n        \"\"\"", "\n", "self", ".", "name_to_value", "[", "key", "]", "=", "value", "\n", "self", ".", "name_to_excluded", "[", "key", "]", "=", "exclude", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.record_mean": [[585, 600], ["None"], "methods", ["None"], ["", "def", "record_mean", "(", "self", ",", "key", ":", "str", ",", "value", ":", "Any", ",", "exclude", ":", "Optional", "[", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        The same as record(), but if called many times, values averaged.\n\n        :param key: save to log this key\n        :param value: save to log this value\n        :param exclude: outputs to be excluded\n        \"\"\"", "\n", "if", "value", "is", "None", ":", "\n", "            ", "self", ".", "name_to_value", "[", "key", "]", "=", "None", "\n", "return", "\n", "", "old_val", ",", "count", "=", "self", ".", "name_to_value", "[", "key", "]", ",", "self", ".", "name_to_count", "[", "key", "]", "\n", "self", ".", "name_to_value", "[", "key", "]", "=", "old_val", "*", "count", "/", "(", "count", "+", "1", ")", "+", "value", "/", "(", "count", "+", "1", ")", "\n", "self", ".", "name_to_count", "[", "key", "]", "=", "count", "+", "1", "\n", "self", ".", "name_to_excluded", "[", "key", "]", "=", "exclude", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.dump": [[601, 614], ["logger.Logger.name_to_value.clear", "logger.Logger.name_to_count.clear", "logger.Logger.name_to_excluded.clear", "isinstance", "_format.write"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write"], ["", "def", "dump", "(", "self", ",", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write all of the diagnostics from the current iteration\n        \"\"\"", "\n", "if", "self", ".", "level", "==", "DISABLED", ":", "\n", "            ", "return", "\n", "", "for", "_format", "in", "self", ".", "output_formats", ":", "\n", "            ", "if", "isinstance", "(", "_format", ",", "KVWriter", ")", ":", "\n", "                ", "_format", ".", "write", "(", "self", ".", "name_to_value", ",", "self", ".", "name_to_excluded", ",", "step", ")", "\n", "\n", "", "", "self", ".", "name_to_value", ".", "clear", "(", ")", "\n", "self", ".", "name_to_count", ".", "clear", "(", ")", "\n", "self", ".", "name_to_excluded", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.log": [[615, 628], ["logger.Logger._do_log"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger._do_log"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "level", ":", "int", "=", "INFO", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write the sequence of args, with no separators,\n        to the console and output files (if you've configured an output file).\n\n        level: int. (see logger.py docs) If the global logger level is higher than\n                    the level argument here, don't print to stdout.\n\n        :param args: log the arguments\n        :param level: the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)\n        \"\"\"", "\n", "if", "self", ".", "level", "<=", "level", ":", "\n", "            ", "self", ".", "_do_log", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.set_level": [[631, 638], ["None"], "methods", ["None"], ["", "", "def", "set_level", "(", "self", ",", "level", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set logging threshold on current logger.\n\n        :param level: the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)\n        \"\"\"", "\n", "self", ".", "level", "=", "level", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.get_dir": [[639, 647], ["None"], "methods", ["None"], ["", "def", "get_dir", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Get directory that log files are being written to.\n        will be None if there is no output directory (i.e., if you didn't call start)\n\n        :return: the logging directory\n        \"\"\"", "\n", "return", "self", ".", "dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger.close": [[648, 654], ["_format.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        closes the file\n        \"\"\"", "\n", "for", "_format", "in", "self", ".", "output_formats", ":", "\n", "            ", "_format", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.Logger._do_log": [[657, 666], ["isinstance", "_format.write_sequence", "map"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.HumanOutputFormat.write_sequence"], ["", "", "def", "_do_log", "(", "self", ",", "args", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        log to the requested format outputs\n\n        :param args: the arguments to log\n        \"\"\"", "\n", "for", "_format", "in", "self", ".", "output_formats", ":", "\n", "            ", "if", "isinstance", "(", "_format", ",", "SeqWriter", ")", ":", "\n", "                ", "_format", ".", "write_sequence", "(", "map", "(", "str", ",", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.ScopedConfigure.__init__": [[710, 724], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "folder", ":", "Optional", "[", "str", "]", "=", "None", ",", "format_strings", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Class for using context manager while logging\n\n        usage:\n        with ScopedConfigure(folder=None, format_strings=None):\n            {code}\n\n        :param folder: the logging folder\n        :param format_strings: the list of output logging format\n        \"\"\"", "\n", "self", ".", "dir", "=", "folder", "\n", "self", ".", "format_strings", "=", "format_strings", "\n", "self", ".", "prev_logger", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.ScopedConfigure.__enter__": [[725, 728], ["logger.configure"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.configure"], ["", "def", "__enter__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "prev_logger", "=", "Logger", ".", "CURRENT", "\n", "configure", "(", "folder", "=", "self", ".", "dir", ",", "format_strings", "=", "self", ".", "format_strings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.ScopedConfigure.__exit__": [[729, 732], ["Logger.CURRENT.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", "->", "None", ":", "\n", "        ", "Logger", ".", "CURRENT", ".", "close", "(", ")", "\n", "Logger", ".", "CURRENT", "=", "self", ".", "prev_logger", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.filter_excluded_keys": [[206, 222], ["key_values.items", "logger.filter_excluded_keys.is_excluded"], "function", ["None"], ["", "", "", "def", "filter_excluded_keys", "(", "\n", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ",", "key_excluded", ":", "Dict", "[", "str", ",", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", ",", "_format", ":", "str", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Filters the keys specified by ``key_exclude`` for the specified format\n\n    :param key_values: log dictionary to be filtered\n    :param key_excluded: keys to be excluded per format\n    :param _format: format for which this filter is run\n    :return: dict without the excluded keys\n    \"\"\"", "\n", "\n", "def", "is_excluded", "(", "key", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "key", "in", "key_excluded", "and", "key_excluded", "[", "key", "]", "is", "not", "None", "and", "_format", "in", "key_excluded", "[", "key", "]", "\n", "\n", "", "return", "{", "key", ":", "value", "for", "key", ",", "value", "in", "key_values", ".", "items", "(", ")", "if", "not", "is_excluded", "(", "key", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.make_output_format": [[377, 399], ["os.makedirs", "logger.HumanOutputFormat", "logger.HumanOutputFormat", "os.path.join", "logger.JSONOutputFormat", "os.path.join", "logger.CSVOutputFormat", "os.path.join", "logger.TensorBoardOutputFormat", "ValueError"], "function", ["None"], ["", "", "", "def", "make_output_format", "(", "_format", ":", "str", ",", "log_dir", ":", "str", ",", "log_suffix", ":", "str", "=", "\"\"", ")", "->", "KVWriter", ":", "\n", "    ", "\"\"\"\n    return a logger for the requested format\n\n    :param _format: the requested format to log to ('stdout', 'log', 'json' or 'csv' or 'tensorboard')\n    :param log_dir: the logging directory\n    :param log_suffix: the suffix for the log file\n    :return: the logger\n    \"\"\"", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "if", "_format", "==", "\"stdout\"", ":", "\n", "        ", "return", "HumanOutputFormat", "(", "sys", ".", "stdout", ")", "\n", "", "elif", "_format", "==", "\"log\"", ":", "\n", "        ", "return", "HumanOutputFormat", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "f\"log{log_suffix}.txt\"", ")", ")", "\n", "", "elif", "_format", "==", "\"json\"", ":", "\n", "        ", "return", "JSONOutputFormat", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "f\"progress{log_suffix}.json\"", ")", ")", "\n", "", "elif", "_format", "==", "\"csv\"", ":", "\n", "        ", "return", "CSVOutputFormat", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "f\"progress{log_suffix}.csv\"", ")", ")", "\n", "", "elif", "_format", "==", "\"tensorboard\"", ":", "\n", "        ", "return", "TensorBoardOutputFormat", "(", "log_dir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unknown format specified: {_format}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record": [[406, 417], ["Logger.CURRENT.record"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record"], ["", "", "def", "record", "(", "key", ":", "str", ",", "value", ":", "Any", ",", "exclude", ":", "Optional", "[", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Log a value of some diagnostic\n    Call this once for each diagnostic quantity, each iteration\n    If called many times, last value will be used.\n\n    :param key: save to log this key\n    :param value: save to log this value\n    :param exclude: outputs to be excluded\n    \"\"\"", "\n", "Logger", ".", "CURRENT", ".", "record", "(", "key", ",", "value", ",", "exclude", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record_mean": [[419, 428], ["Logger.CURRENT.record_mean"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record_mean"], ["", "def", "record_mean", "(", "key", ":", "str", ",", "value", ":", "Union", "[", "int", ",", "float", "]", ",", "exclude", ":", "Optional", "[", "Union", "[", "str", ",", "Tuple", "[", "str", ",", "...", "]", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    The same as record(), but if called many times, values averaged.\n\n    :param key: save to log this key\n    :param value: save to log this value\n    :param exclude: outputs to be excluded\n    \"\"\"", "\n", "Logger", ".", "CURRENT", ".", "record_mean", "(", "key", ",", "value", ",", "exclude", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record_dict": [[430, 438], ["key_values.items", "logger.record"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record"], ["", "def", "record_dict", "(", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Log a dictionary of key-value pairs.\n\n    :param key_values: the list of keys and values to save to log\n    \"\"\"", "\n", "for", "key", ",", "value", "in", "key_values", ".", "items", "(", ")", ":", "\n", "        ", "record", "(", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump": [[440, 445], ["Logger.CURRENT.dump"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump"], ["", "", "def", "dump", "(", "step", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Write all of the diagnostics from the current iteration\n    \"\"\"", "\n", "Logger", ".", "CURRENT", ".", "dump", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.get_log_dict": [[447, 454], ["None"], "function", ["None"], ["", "def", "get_log_dict", "(", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"\n    get the key values logs\n\n    :return: the logged values\n    \"\"\"", "\n", "return", "Logger", ".", "CURRENT", ".", "name_to_value", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log": [[456, 468], ["Logger.CURRENT.log"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "log", "(", "*", "args", ",", "level", ":", "int", "=", "INFO", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Write the sequence of args, with no separators,\n    to the console and output files (if you've configured an output file).\n\n    level: int. (see logger.py docs) If the global logger level is higher than\n                the level argument here, don't print to stdout.\n\n    :param args: log the arguments\n    :param level: the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)\n    \"\"\"", "\n", "Logger", ".", "CURRENT", ".", "log", "(", "*", "args", ",", "level", "=", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.debug": [[470, 479], ["logger.log"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "debug", "(", "*", "args", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Write the sequence of args, with no separators,\n    to the console and output files (if you've configured an output file).\n    Using the DEBUG level.\n\n    :param args: log the arguments\n    \"\"\"", "\n", "log", "(", "*", "args", ",", "level", "=", "DEBUG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info": [[481, 490], ["logger.log"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "info", "(", "*", "args", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Write the sequence of args, with no separators,\n    to the console and output files (if you've configured an output file).\n    Using the INFO level.\n\n    :param args: log the arguments\n    \"\"\"", "\n", "log", "(", "*", "args", ",", "level", "=", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn": [[492, 501], ["logger.log"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "warn", "(", "*", "args", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Write the sequence of args, with no separators,\n    to the console and output files (if you've configured an output file).\n    Using the WARN level.\n\n    :param args: log the arguments\n    \"\"\"", "\n", "log", "(", "*", "args", ",", "level", "=", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.error": [[503, 512], ["logger.log"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "error", "(", "*", "args", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Write the sequence of args, with no separators,\n    to the console and output files (if you've configured an output file).\n    Using the ERROR level.\n\n    :param args: log the arguments\n    \"\"\"", "\n", "log", "(", "*", "args", ",", "level", "=", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.set_level": [[514, 521], ["Logger.CURRENT.set_level"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.set_level"], ["", "def", "set_level", "(", "level", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Set logging threshold on current logger.\n\n    :param level: the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)\n    \"\"\"", "\n", "Logger", ".", "CURRENT", ".", "set_level", "(", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.get_level": [[523, 529], ["None"], "function", ["None"], ["", "def", "get_level", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Get logging threshold on current logger.\n    :return: the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)\n    \"\"\"", "\n", "return", "Logger", ".", "CURRENT", ".", "level", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.get_dir": [[531, 539], ["Logger.CURRENT.get_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.get_dir"], ["", "def", "get_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Get directory that log files are being written to.\n    will be None if there is no output directory (i.e., if you didn't call start)\n\n    :return: the logging directory\n    \"\"\"", "\n", "return", "Logger", ".", "CURRENT", ".", "get_dir", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.configure": [[672, 697], ["isinstance", "os.makedirs", "filter", "logger.Logger", "logger.log", "os.getenv", "os.path.join", "os.getenv().split", "logger.make_output_format", "tempfile.gettempdir", "datetime.datetime.now().strftime", "os.getenv", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.make_output_format"], ["def", "configure", "(", "folder", ":", "Optional", "[", "str", "]", "=", "None", ",", "format_strings", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    configure the current logger\n\n    :param folder: the save location\n        (if None, $SB3_LOGDIR, if still None, tempdir/baselines-[date & time])\n    :param format_strings: the output logging format\n        (if None, $SB3_LOG_FORMAT, if still None, ['stdout', 'log', 'csv'])\n    \"\"\"", "\n", "if", "folder", "is", "None", ":", "\n", "        ", "folder", "=", "os", ".", "getenv", "(", "\"SB3_LOGDIR\"", ")", "\n", "", "if", "folder", "is", "None", ":", "\n", "        ", "folder", "=", "os", ".", "path", ".", "join", "(", "tempfile", ".", "gettempdir", "(", ")", ",", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"SB3-%Y-%m-%d-%H-%M-%S-%f\"", ")", ")", "\n", "", "assert", "isinstance", "(", "folder", ",", "str", ")", "\n", "os", ".", "makedirs", "(", "folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "log_suffix", "=", "\"\"", "\n", "if", "format_strings", "is", "None", ":", "\n", "        ", "format_strings", "=", "os", ".", "getenv", "(", "\"SB3_LOG_FORMAT\"", ",", "\"stdout,log,csv\"", ")", ".", "split", "(", "\",\"", ")", "\n", "\n", "", "format_strings", "=", "filter", "(", "None", ",", "format_strings", ")", "\n", "output_formats", "=", "[", "make_output_format", "(", "f", ",", "folder", ",", "log_suffix", ")", "for", "f", "in", "format_strings", "]", "\n", "\n", "Logger", ".", "CURRENT", "=", "Logger", "(", "folder", "=", "folder", ",", "output_formats", "=", "output_formats", ")", "\n", "log", "(", "f\"Logging to {folder}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.reset": [[699, 707], ["Logger.CURRENT.close", "logger.log"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "reset", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    reset the current logger\n    \"\"\"", "\n", "if", "Logger", ".", "CURRENT", "is", "not", "Logger", ".", "DEFAULT", ":", "\n", "        ", "Logger", ".", "CURRENT", ".", "close", "(", ")", "\n", "Logger", ".", "CURRENT", "=", "Logger", ".", "DEFAULT", "\n", "log", "(", "\"Reset logger\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.read_json": [[739, 751], ["pandas.DataFrame", "open", "data.append", "json.loads"], "function", ["None"], ["", "", "def", "read_json", "(", "filename", ":", "str", ")", "->", "pandas", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    read a json file using pandas\n\n    :param filename: the file path to read\n    :return: the data in the json\n    \"\"\"", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"rt\"", ")", "as", "file_handler", ":", "\n", "        ", "for", "line", "in", "file_handler", ":", "\n", "            ", "data", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "return", "pandas", ".", "DataFrame", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.read_csv": [[753, 761], ["pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.read_csv"], ["", "def", "read_csv", "(", "filename", ":", "str", ")", "->", "pandas", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    read a csv file using pandas\n\n    :param filename: the file path to read\n    :return: the data in the csv\n    \"\"\"", "\n", "return", "pandas", ".", "read_csv", "(", "filename", ",", "index_col", "=", "None", ",", "comment", "=", "\"#\"", ")", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.__init__": [[7, 18], ["numpy.zeros", "numpy.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "epsilon", ":", "float", "=", "1e-4", ",", "shape", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", ")", ")", ":", "\n", "        ", "\"\"\"\n        Calulates the running mean and std of a data stream\n        https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n\n        :param epsilon: helps with arithmetic issues\n        :param shape: the shape of the data stream's output\n        \"\"\"", "\n", "self", ".", "mean", "=", "np", ".", "zeros", "(", "shape", ",", "np", ".", "float64", ")", "\n", "self", ".", "var", "=", "np", ".", "ones", "(", "shape", ",", "np", ".", "float64", ")", "\n", "self", ".", "count", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update": [[19, 24], ["numpy.mean", "numpy.var", "running_mean_std.RunningMeanStd.update_from_moments"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update_from_moments"], ["", "def", "update", "(", "self", ",", "arr", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "batch_mean", "=", "np", ".", "mean", "(", "arr", ",", "axis", "=", "0", ")", "\n", "batch_var", "=", "np", ".", "var", "(", "arr", ",", "axis", "=", "0", ")", "\n", "batch_count", "=", "arr", ".", "shape", "[", "0", "]", "\n", "self", ".", "update_from_moments", "(", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update_from_moments": [[25, 40], ["numpy.square"], "methods", ["None"], ["", "def", "update_from_moments", "(", "self", ",", "batch_mean", ":", "np", ".", "ndarray", ",", "batch_var", ":", "np", ".", "ndarray", ",", "batch_count", ":", "int", ")", "->", "None", ":", "\n", "        ", "delta", "=", "batch_mean", "-", "self", ".", "mean", "\n", "tot_count", "=", "self", ".", "count", "+", "batch_count", "\n", "\n", "new_mean", "=", "self", ".", "mean", "+", "delta", "*", "batch_count", "/", "tot_count", "\n", "m_a", "=", "self", ".", "var", "*", "self", ".", "count", "\n", "m_b", "=", "batch_var", "*", "batch_count", "\n", "m_2", "=", "m_a", "+", "m_b", "+", "np", ".", "square", "(", "delta", ")", "*", "self", ".", "count", "*", "batch_count", "/", "(", "self", ".", "count", "+", "batch_count", ")", "\n", "new_var", "=", "m_2", "/", "(", "self", ".", "count", "+", "batch_count", ")", "\n", "\n", "new_count", "=", "batch_count", "+", "self", ".", "count", "\n", "\n", "self", ".", "mean", "=", "new_mean", "\n", "self", ".", "var", "=", "new_var", "\n", "self", ".", "count", "=", "new_count", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv.__init__": [[11, 34], ["identity_env.IdentityEnv.reset", "gym.spaces.Discrete"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["    ", "def", "__init__", "(", "self", ",", "dim", ":", "Optional", "[", "int", "]", "=", "None", ",", "space", ":", "Optional", "[", "Space", "]", "=", "None", ",", "ep_length", ":", "int", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        Identity environment for testing purposes\n\n        :param dim: the size of the action and observation dimension you want\n            to learn. Provide at most one of ``dim`` and ``space``. If both are\n            None, then initialization proceeds with ``dim=1`` and ``space=None``.\n        :param space: the action and observation space. Provide at most one of\n            ``dim`` and ``space``.\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"", "\n", "if", "space", "is", "None", ":", "\n", "            ", "if", "dim", "is", "None", ":", "\n", "                ", "dim", "=", "1", "\n", "", "space", "=", "Discrete", "(", "dim", ")", "\n", "", "else", ":", "\n", "            ", "assert", "dim", "is", "None", ",", "\"arguments for both 'dim' and 'space' provided: at most one allowed\"", "\n", "\n", "", "self", ".", "action_space", "=", "self", ".", "observation_space", "=", "space", "\n", "self", ".", "ep_length", "=", "ep_length", "\n", "self", ".", "current_step", "=", "0", "\n", "self", ".", "num_resets", "=", "-", "1", "# Becomes 0 after __init__ exits.", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv.reset": [[35, 40], ["identity_env.IdentityEnv._choose_next_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv._choose_next_state"], ["", "def", "reset", "(", "self", ")", "->", "GymObs", ":", "\n", "        ", "self", ".", "current_step", "=", "0", "\n", "self", ".", "num_resets", "+=", "1", "\n", "self", ".", "_choose_next_state", "(", ")", "\n", "return", "self", ".", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv.step": [[41, 47], ["identity_env.IdentityEnv._get_reward", "identity_env.IdentityEnv._choose_next_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvBox._get_reward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv._choose_next_state"], ["", "def", "step", "(", "self", ",", "action", ":", "Union", "[", "int", ",", "np", ".", "ndarray", "]", ")", "->", "GymStepReturn", ":", "\n", "        ", "reward", "=", "self", ".", "_get_reward", "(", "action", ")", "\n", "self", ".", "_choose_next_state", "(", ")", "\n", "self", ".", "current_step", "+=", "1", "\n", "done", "=", "self", ".", "current_step", ">=", "self", ".", "ep_length", "\n", "return", "self", ".", "state", ",", "reward", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv._choose_next_state": [[48, 50], ["identity_env.IdentityEnv.action_space.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "_choose_next_state", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "state", "=", "self", ".", "action_space", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv._get_reward": [[51, 53], ["numpy.all"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "action", ":", "Union", "[", "int", ",", "np", ".", "ndarray", "]", ")", "->", "float", ":", "\n", "        ", "return", "1.0", "if", "np", ".", "all", "(", "self", ".", "state", "==", "action", ")", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv.render": [[54, 56], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "\"human\"", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvBox.__init__": [[59, 71], ["gym.spaces.Box", "identity_env.IdentityEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "low", ":", "float", "=", "-", "1.0", ",", "high", ":", "float", "=", "1.0", ",", "eps", ":", "float", "=", "0.05", ",", "ep_length", ":", "int", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        Identity environment for testing purposes\n\n        :param low: the lower bound of the box dim\n        :param high: the upper bound of the box dim\n        :param eps: the epsilon bound for correct value\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"", "\n", "space", "=", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "super", "(", ")", ".", "__init__", "(", "ep_length", "=", "ep_length", ",", "space", "=", "space", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvBox.step": [[72, 78], ["identity_env.IdentityEnvBox._get_reward", "identity_env.IdentityEnvBox._choose_next_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvBox._get_reward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnv._choose_next_state"], ["", "def", "step", "(", "self", ",", "action", ":", "np", ".", "ndarray", ")", "->", "GymStepReturn", ":", "\n", "        ", "reward", "=", "self", ".", "_get_reward", "(", "action", ")", "\n", "self", ".", "_choose_next_state", "(", ")", "\n", "self", ".", "current_step", "+=", "1", "\n", "done", "=", "self", ".", "current_step", ">=", "self", ".", "ep_length", "\n", "return", "self", ".", "state", ",", "reward", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvBox._get_reward": [[79, 81], ["None"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "action", ":", "np", ".", "ndarray", ")", "->", "float", ":", "\n", "        ", "return", "1.0", "if", "(", "self", ".", "state", "-", "self", ".", "eps", ")", "<=", "action", "<=", "(", "self", ".", "state", "+", "self", ".", "eps", ")", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvMultiDiscrete.__init__": [[84, 93], ["gym.spaces.MultiDiscrete", "identity_env.IdentityEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ":", "int", "=", "1", ",", "ep_length", ":", "int", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        Identity environment for testing purposes\n\n        :param dim: the size of the dimensions you want to learn\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"", "\n", "space", "=", "MultiDiscrete", "(", "[", "dim", ",", "dim", "]", ")", "\n", "super", "(", ")", ".", "__init__", "(", "ep_length", "=", "ep_length", ",", "space", "=", "space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.IdentityEnvMultiBinary.__init__": [[96, 105], ["gym.spaces.MultiBinary", "identity_env.IdentityEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ":", "int", "=", "1", ",", "ep_length", ":", "int", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        Identity environment for testing purposes\n\n        :param dim: the size of the dimensions you want to learn\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"", "\n", "space", "=", "MultiBinary", "(", "dim", ")", "\n", "super", "(", ")", ".", "__init__", "(", "ep_length", "=", "ep_length", ",", "space", "=", "space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.FakeImageEnv.__init__": [[119, 138], ["gym.spaces.Box", "gym.spaces.Discrete", "gym.spaces.Box"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "action_dim", ":", "int", "=", "6", ",", "\n", "screen_height", ":", "int", "=", "84", ",", "\n", "screen_width", ":", "int", "=", "84", ",", "\n", "n_channels", ":", "int", "=", "1", ",", "\n", "discrete", ":", "bool", "=", "True", ",", "\n", "channel_first", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "observation_shape", "=", "(", "screen_height", ",", "screen_width", ",", "n_channels", ")", "\n", "if", "channel_first", ":", "\n", "            ", "self", ".", "observation_shape", "=", "(", "n_channels", ",", "screen_height", ",", "screen_width", ")", "\n", "", "self", ".", "observation_space", "=", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "self", ".", "observation_shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "if", "discrete", ":", "\n", "            ", "self", ".", "action_space", "=", "Discrete", "(", "action_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "action_space", "=", "Box", "(", "low", "=", "-", "1", ",", "high", "=", "1", ",", "shape", "=", "(", "5", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "self", ".", "ep_length", "=", "10", "\n", "self", ".", "current_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.FakeImageEnv.reset": [[139, 142], ["identity_env.FakeImageEnv.observation_space.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "reset", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "self", ".", "current_step", "=", "0", "\n", "return", "self", ".", "observation_space", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.FakeImageEnv.step": [[143, 148], ["identity_env.FakeImageEnv.observation_space.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "step", "(", "self", ",", "action", ":", "Union", "[", "np", ".", "ndarray", ",", "int", "]", ")", "->", "GymStepReturn", ":", "\n", "        ", "reward", "=", "0.0", "\n", "self", ".", "current_step", "+=", "1", "\n", "done", "=", "self", ".", "current_step", ">=", "self", ".", "ep_length", "\n", "return", "self", ".", "observation_space", ".", "sample", "(", ")", ",", "reward", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.identity_env.FakeImageEnv.render": [[149, 151], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "\"human\"", ")", "->", "None", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.__init__": [[73, 144], ["gym_optimal_intrusion_response.agents.openai_baselines.common.base_class.BaseAlgorithm.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "attacker_policy", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "env", ":", "Union", "[", "GymEnv", ",", "str", "]", ",", "\n", "policy_base", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "attacker_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", ",", "\n", "buffer_size", ":", "int", "=", "1000000", ",", "\n", "learning_starts", ":", "int", "=", "100", ",", "\n", "batch_size", ":", "int", "=", "256", ",", "\n", "tau", ":", "float", "=", "0.005", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "train_freq", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "str", "]", "]", "=", "(", "1", ",", "\"step\"", ")", ",", "\n", "gradient_steps", ":", "int", "=", "1", ",", "\n", "action_noise", ":", "Optional", "[", "ActionNoise", "]", "=", "None", ",", "\n", "optimize_memory_usage", ":", "bool", "=", "False", ",", "\n", "attacker_policy_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "tensorboard_log", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", "support_multi_env", ":", "bool", "=", "False", ",", "\n", "create_eval_env", ":", "bool", "=", "False", ",", "\n", "monitor_wrapper", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_sde", ":", "bool", "=", "False", ",", "\n", "sde_sample_freq", ":", "int", "=", "-", "1", ",", "\n", "use_sde_at_warmup", ":", "bool", "=", "False", ",", "\n", "sde_support", ":", "bool", "=", "True", ",", "\n", "remove_time_limit_termination", ":", "bool", "=", "False", ",", "\n", "supported_action_spaces", ":", "Optional", "[", "Tuple", "[", "gym", ".", "spaces", ".", "Space", ",", "...", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "OffPolicyAlgorithm", ",", "self", ")", ".", "__init__", "(", "\n", "attacker_policy", "=", "attacker_policy", ",", "\n", "env", "=", "env", ",", "\n", "policy_base", "=", "policy_base", ",", "\n", "attacker_learning_rate", "=", "attacker_learning_rate", ",", "\n", "attacker_policy_kwargs", "=", "attacker_policy_kwargs", ",", "\n", "tensorboard_log", "=", "tensorboard_log", ",", "\n", "verbose", "=", "verbose", ",", "\n", "device", "=", "device", ",", "\n", "support_multi_env", "=", "support_multi_env", ",", "\n", "create_eval_env", "=", "create_eval_env", ",", "\n", "monitor_wrapper", "=", "monitor_wrapper", ",", "\n", "seed", "=", "seed", ",", "\n", "use_sde", "=", "use_sde", ",", "\n", "sde_sample_freq", "=", "sde_sample_freq", ",", "\n", "supported_action_spaces", "=", "supported_action_spaces", ",", "\n", ")", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_starts", "=", "learning_starts", "\n", "self", ".", "tau", "=", "tau", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "action_noise", "=", "action_noise", "\n", "self", ".", "optimize_memory_usage", "=", "optimize_memory_usage", "\n", "\n", "# Remove terminations (dones) that are due to time limit", "\n", "# see https://github.com/hill-a/stable-baselines/issues/863", "\n", "self", ".", "remove_time_limit_termination", "=", "remove_time_limit_termination", "\n", "\n", "# Save train freq parameter, will be converted later to TrainFreq object", "\n", "self", ".", "train_freq", "=", "train_freq", "\n", "\n", "self", ".", "actor", "=", "None", "# type: Optional[th.nn.Module]", "\n", "self", ".", "replay_buffer", "=", "None", "# type: Optional[ReplayBuffer]", "\n", "# Update policy keyword arguments", "\n", "if", "sde_support", ":", "\n", "            ", "self", ".", "attacker_policy_kwargs", "[", "\"use_sde\"", "]", "=", "self", ".", "use_sde", "\n", "# For gSDE only", "\n", "", "self", ".", "use_sde_at_warmup", "=", "use_sde_at_warmup", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._convert_train_freq": [[145, 166], ["isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.type_aliases.TrainFreq", "isinstance", "isinstance", "ValueError", "gym_optimal_intrusion_response.agents.openai_baselines.common.type_aliases.TrainFrequencyUnit", "ValueError"], "methods", ["None"], ["", "def", "_convert_train_freq", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Convert `train_freq` parameter (int or tuple)\n        to a TrainFreq object.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "self", ".", "train_freq", ",", "TrainFreq", ")", ":", "\n", "            ", "train_freq", "=", "self", ".", "train_freq", "\n", "\n", "# The value of the train frequency will be checked later", "\n", "if", "not", "isinstance", "(", "train_freq", ",", "tuple", ")", ":", "\n", "                ", "train_freq", "=", "(", "train_freq", ",", "\"step\"", ")", "\n", "\n", "", "try", ":", "\n", "                ", "train_freq", "=", "(", "train_freq", "[", "0", "]", ",", "TrainFrequencyUnit", "(", "train_freq", "[", "1", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "raise", "ValueError", "(", "f\"The unit of the `train_freq` must be either 'step' or 'episode' not '{train_freq[1]}'!\"", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "train_freq", "[", "0", "]", ",", "int", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"The frequency of `train_freq` must be an integer and not {train_freq[0]}\"", ")", "\n", "\n", "", "self", ".", "train_freq", "=", "TrainFreq", "(", "*", "train_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._setup_model": [[167, 187], ["off_policy_algorithm.OffPolicyAlgorithm._setup_lr_schedule", "off_policy_algorithm.OffPolicyAlgorithm.set_random_seed", "gym_optimal_intrusion_response.agents.openai_baselines.common.buffers.ReplayBuffer", "off_policy_algorithm.OffPolicyAlgorithm.attacker_policy_class", "off_policy_algorithm.OffPolicyAlgorithm.policy.to", "off_policy_algorithm.OffPolicyAlgorithm._convert_train_freq"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.set_random_seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._convert_train_freq"], ["", "", "def", "_setup_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_setup_lr_schedule", "(", ")", "\n", "self", ".", "set_random_seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "\n", "self", ".", "buffer_size", ",", "\n", "self", ".", "attacker_observation_space", ",", "\n", "self", ".", "attacker_action_space", ",", "\n", "self", ".", "device", ",", "\n", "optimize_memory_usage", "=", "self", ".", "optimize_memory_usage", ",", "\n", ")", "\n", "self", ".", "policy", "=", "self", ".", "attacker_policy_class", "(", "# pytype:disable=not-instantiable", "\n", "self", ".", "attacker_observation_space", ",", "\n", "self", ".", "attacker_action_space", ",", "\n", "self", ".", "lr_schedule", ",", "\n", "**", "self", ".", "attacker_policy_kwargs", ",", "# pytype:disable=not-instantiable", "\n", ")", "\n", "self", ".", "policy", "=", "self", ".", "policy", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Convert train freq parameter to TrainFreq object", "\n", "self", ".", "_convert_train_freq", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.save_replay_buffer": [[188, 197], ["gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.save_to_pkl"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.save_to_pkl"], ["", "def", "save_replay_buffer", "(", "self", ",", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save the replay buffer as a pickle file.\n\n        :param path: Path to the file where the replay buffer should be saved.\n            if path is a str or pathlib.Path, the path is automatically created if necessary.\n        \"\"\"", "\n", "assert", "self", ".", "replay_buffer", "is", "not", "None", ",", "\"The replay buffer is not defined\"", "\n", "save_to_pkl", "(", "path", ",", "self", ".", "replay_buffer", ",", "self", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.load_replay_buffer": [[198, 206], ["gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.load_from_pkl", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.load_from_pkl"], ["", "def", "load_replay_buffer", "(", "self", ",", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Load a replay buffer from a pickle file.\n\n        :param path: Path to the pickled replay buffer.\n        \"\"\"", "\n", "self", ".", "replay_buffer", "=", "load_from_pkl", "(", "path", ",", "self", ".", "verbose", ")", "\n", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "ReplayBuffer", ")", ",", "\"The replay buffer must inherit from ReplayBuffer class\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._setup_learn": [[207, 244], ["super()._setup_learn", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._setup_learn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "_setup_learn", "(", "\n", "self", ",", "\n", "total_timesteps", ":", "int", ",", "\n", "eval_env", ":", "Optional", "[", "GymEnv", "]", ",", "\n", "callback", ":", "MaybeCallback", "=", "None", ",", "\n", "eval_freq", ":", "int", "=", "10000", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", "tb_log_name", ":", "str", "=", "\"run\"", ",", "\n", ")", "->", "Tuple", "[", "int", ",", "BaseCallback", "]", ":", "\n", "        ", "\"\"\"\n        cf `BaseAlgorithm`.\n        \"\"\"", "\n", "# Prevent continuity issue by truncating trajectory", "\n", "# when using memory efficient replay buffer", "\n", "# see https://github.com/DLR-RM/stable-baselines3/issues/46", "\n", "truncate_last_traj", "=", "(", "\n", "self", ".", "optimize_memory_usage", "\n", "and", "reset_num_timesteps", "\n", "and", "self", ".", "replay_buffer", "is", "not", "None", "\n", "and", "(", "self", ".", "replay_buffer", ".", "full", "or", "self", ".", "replay_buffer", ".", "pos", ">", "0", ")", "\n", ")", "\n", "\n", "if", "truncate_last_traj", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The last trajectory in the replay buffer will be truncated, \"", "\n", "\"see https://github.com/DLR-RM/stable-baselines3/issues/46.\"", "\n", "\"You should use `reset_num_timesteps=False` or `optimize_memory_usage=False`\"", "\n", "\"to avoid that issue.\"", "\n", ")", "\n", "# Go to the previous index", "\n", "pos", "=", "(", "self", ".", "replay_buffer", ".", "pos", "-", "1", ")", "%", "self", ".", "replay_buffer", ".", "buffer_size", "\n", "self", ".", "replay_buffer", ".", "dones", "[", "pos", "]", "=", "True", "\n", "\n", "", "return", "super", "(", ")", ".", "_setup_learn", "(", "\n", "total_timesteps", ",", "eval_env", ",", "callback", ",", "eval_freq", ",", "n_eval_episodes", ",", "log_path", ",", "reset_num_timesteps", ",", "tb_log_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.learn": [[246, 288], ["off_policy_algorithm.OffPolicyAlgorithm._setup_learn", "callback.on_training_start", "callback.on_training_end", "locals", "globals", "off_policy_algorithm.OffPolicyAlgorithm.collect_rollouts", "off_policy_algorithm.OffPolicyAlgorithm.train"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._setup_learn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_start", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_end", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.collect_rollouts", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.train"], ["", "def", "learn", "(", "\n", "self", ",", "\n", "total_timesteps", ":", "int", ",", "\n", "callback", ":", "MaybeCallback", "=", "None", ",", "\n", "log_interval", ":", "int", "=", "4", ",", "\n", "eval_env", ":", "Optional", "[", "GymEnv", "]", "=", "None", ",", "\n", "eval_freq", ":", "int", "=", "-", "1", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "tb_log_name", ":", "str", "=", "\"run\"", ",", "\n", "eval_log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", ")", "->", "\"OffPolicyAlgorithm\"", ":", "\n", "\n", "        ", "total_timesteps", ",", "callback", "=", "self", ".", "_setup_learn", "(", "\n", "total_timesteps", ",", "eval_env", ",", "callback", ",", "eval_freq", ",", "n_eval_episodes", ",", "eval_log_path", ",", "reset_num_timesteps", ",", "tb_log_name", "\n", ")", "\n", "\n", "callback", ".", "on_training_start", "(", "locals", "(", ")", ",", "globals", "(", ")", ")", "\n", "\n", "while", "self", ".", "num_timesteps", "<", "total_timesteps", ":", "\n", "            ", "rollout", "=", "self", ".", "collect_rollouts", "(", "\n", "self", ".", "env", ",", "\n", "train_freq", "=", "self", ".", "train_freq", ",", "\n", "action_noise", "=", "self", ".", "action_noise", ",", "\n", "callback", "=", "callback", ",", "\n", "learning_starts", "=", "self", ".", "learning_starts", ",", "\n", "replay_buffer", "=", "self", ".", "replay_buffer", ",", "\n", "log_interval", "=", "log_interval", ",", "\n", ")", "\n", "\n", "if", "rollout", ".", "continue_training", "is", "False", ":", "\n", "                ", "break", "\n", "\n", "", "if", "self", ".", "num_timesteps", ">", "0", "and", "self", ".", "num_timesteps", ">", "self", ".", "learning_starts", ":", "\n", "# If no `gradient_steps` is specified,", "\n", "# do as many gradients steps as steps performed during the rollout", "\n", "                ", "gradient_steps", "=", "self", ".", "gradient_steps", "if", "self", ".", "gradient_steps", ">", "0", "else", "rollout", ".", "episode_timesteps", "\n", "self", ".", "train", "(", "batch_size", "=", "self", ".", "batch_size", ",", "gradient_steps", "=", "gradient_steps", ")", "\n", "\n", "", "", "callback", ".", "on_training_end", "(", ")", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.train": [[289, 295], ["NotImplementedError"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "gradient_steps", ":", "int", ",", "batch_size", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sample the replay buffer and do the updates\n        (gradient descent and update target networks)\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._sample_action": [[296, 339], ["isinstance", "numpy.array", "off_policy_algorithm.OffPolicyAlgorithm.predict", "off_policy_algorithm.OffPolicyAlgorithm.policy.scale_action", "off_policy_algorithm.OffPolicyAlgorithm.policy.unscale_action", "numpy.clip", "off_policy_algorithm.OffPolicyAlgorithm.attacker_action_space.sample", "action_noise"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.predict", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.scale_action", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BasePolicy.unscale_action", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "_sample_action", "(", "\n", "self", ",", "learning_starts", ":", "int", ",", "action_noise", ":", "Optional", "[", "ActionNoise", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Sample an action according to the exploration policy.\n        This is either done by sampling the probability distribution of the policy,\n        or sampling a random action (from a uniform distribution over the action space)\n        or by adding noise to the deterministic output.\n\n        :param action_noise: Action noise that will be used for exploration\n            Required for deterministic policy (e.g. TD3). This can also be used\n            in addition to the stochastic policy for SAC.\n        :param learning_starts: Number of steps before learning for the warm-up phase.\n        :return: action to take in the environment\n            and scaled action that will be stored in the replay buffer.\n            The two differs when the action space is not normalized (bounds are not [-1, 1]).\n        \"\"\"", "\n", "# Select action randomly or according to policy", "\n", "if", "self", ".", "num_timesteps", "<", "learning_starts", "and", "not", "(", "self", ".", "use_sde", "and", "self", ".", "use_sde_at_warmup", ")", ":", "\n", "# Warmup phase", "\n", "            ", "unscaled_action", "=", "np", ".", "array", "(", "[", "self", ".", "attacker_action_space", ".", "sample", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "# Note: when using continuous actions,", "\n", "# we assume that the policy uses tanh to scale the action", "\n", "# We use non-deterministic action in the case of SAC, for TD3, it does not matter", "\n", "            ", "unscaled_action", ",", "_", "=", "self", ".", "predict", "(", "self", ".", "_last_obs", ",", "deterministic", "=", "False", ")", "\n", "\n", "# Rescale the action from [low, high] to [-1, 1]", "\n", "", "if", "isinstance", "(", "self", ".", "attacker_action_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "            ", "scaled_action", "=", "self", ".", "policy", ".", "scale_action", "(", "unscaled_action", ")", "\n", "\n", "# Add noise to the action (improve exploration)", "\n", "if", "action_noise", "is", "not", "None", ":", "\n", "                ", "scaled_action", "=", "np", ".", "clip", "(", "scaled_action", "+", "action_noise", "(", ")", ",", "-", "1", ",", "1", ")", "\n", "\n", "# We store the scaled action in the buffer", "\n", "", "buffer_action", "=", "scaled_action", "\n", "action", "=", "self", ".", "policy", ".", "unscale_action", "(", "scaled_action", ")", "\n", "", "else", ":", "\n", "# Discrete case, no need to normalize or clip", "\n", "            ", "buffer_action", "=", "unscaled_action", "\n", "action", "=", "buffer_action", "\n", "", "return", "action", ",", "buffer_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._dump_logs": [[340, 359], ["int", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.dump", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "int", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "len", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.record", "len", "len", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.safe_mean", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.safe_mean", "off_policy_algorithm.OffPolicyAlgorithm.actor.get_std().mean().item", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.safe_mean", "time.time", "time.time", "off_policy_algorithm.OffPolicyAlgorithm.actor.get_std().mean", "off_policy_algorithm.OffPolicyAlgorithm.actor.get_std"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.record", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.safe_mean", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.safe_mean", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.safe_mean", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.get_std"], ["", "def", "_dump_logs", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write log.\n        \"\"\"", "\n", "fps", "=", "int", "(", "self", ".", "num_timesteps", "/", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", ")", "\n", "logger", ".", "record", "(", "\"time/episodes\"", ",", "self", ".", "_episode_num", ",", "exclude", "=", "\"tensorboard\"", ")", "\n", "if", "len", "(", "self", ".", "ep_info_buffer", ")", ">", "0", "and", "len", "(", "self", ".", "ep_info_buffer", "[", "0", "]", ")", ">", "0", ":", "\n", "            ", "logger", ".", "record", "(", "\"rollout/ep_rew_mean\"", ",", "safe_mean", "(", "[", "ep_info", "[", "\"r\"", "]", "for", "ep_info", "in", "self", ".", "ep_info_buffer", "]", ")", ")", "\n", "logger", ".", "record", "(", "\"rollout/ep_len_mean\"", ",", "safe_mean", "(", "[", "ep_info", "[", "\"l\"", "]", "for", "ep_info", "in", "self", ".", "ep_info_buffer", "]", ")", ")", "\n", "", "logger", ".", "record", "(", "\"time/fps\"", ",", "fps", ")", "\n", "logger", ".", "record", "(", "\"time/time_elapsed\"", ",", "int", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", ",", "exclude", "=", "\"tensorboard\"", ")", "\n", "logger", ".", "record", "(", "\"time/total timesteps\"", ",", "self", ".", "num_timesteps", ",", "exclude", "=", "\"tensorboard\"", ")", "\n", "if", "self", ".", "use_sde", ":", "\n", "            ", "logger", ".", "record", "(", "\"train/std\"", ",", "(", "self", ".", "actor", ".", "get_std", "(", ")", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "ep_success_buffer", ")", ">", "0", ":", "\n", "            ", "logger", ".", "record", "(", "\"rollout/success rate\"", ",", "safe_mean", "(", "self", ".", "ep_success_buffer", ")", ")", "\n", "# Pass the number of timesteps for tensorboard", "\n", "", "logger", ".", "dump", "(", "step", "=", "self", ".", "num_timesteps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._on_step": [[360, 367], ["None"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Method called after each step in the environment.\n        It is meant to trigger DQN target network update\n        but can be used for other purposes\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._store_transition": [[368, 415], ["replay_buffer.add", "off_policy_algorithm.OffPolicyAlgorithm._vec_normalize_env.get_original_obs", "off_policy_algorithm.OffPolicyAlgorithm._vec_normalize_env.get_original_reward", "infos[].get", "off_policy_algorithm.OffPolicyAlgorithm._vec_normalize_env.unnormalize_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.get_original_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.get_original_reward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.unnormalize_obs"], ["", "def", "_store_transition", "(", "\n", "self", ",", "\n", "replay_buffer", ":", "ReplayBuffer", ",", "\n", "buffer_action", ":", "np", ".", "ndarray", ",", "\n", "new_obs", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "infos", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Store transition in the replay buffer.\n        We store the normalized action and the unnormalized observation.\n        It also handles terminal observations (because VecEnv resets automatically).\n\n        :param replay_buffer: Replay buffer object where to store the transition.\n        :param buffer_action: normalized action\n        :param new_obs: next observation in the current episode\n            or first observation of the episode (when done is True)\n        :param reward: reward for the current transition\n        :param done: Termination signal\n        :param infos: List of additional information about the transition.\n            It contains the terminal observations.\n        \"\"\"", "\n", "# Store only the unnormalized version", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "            ", "new_obs_", "=", "self", ".", "_vec_normalize_env", ".", "get_original_obs", "(", ")", "\n", "reward_", "=", "self", ".", "_vec_normalize_env", ".", "get_original_reward", "(", ")", "\n", "", "else", ":", "\n", "# Avoid changing the original ones", "\n", "            ", "self", ".", "_last_original_obs", ",", "new_obs_", ",", "reward_", "=", "self", ".", "_last_obs", ",", "new_obs", ",", "reward", "\n", "\n", "# As the VecEnv resets automatically, new_obs is already the", "\n", "# first observation of the next episode", "\n", "", "if", "done", "and", "infos", "[", "0", "]", ".", "get", "(", "\"terminal_observation\"", ")", "is", "not", "None", ":", "\n", "            ", "next_obs", "=", "infos", "[", "0", "]", "[", "\"terminal_observation\"", "]", "\n", "# VecNormalize normalizes the terminal observation", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "                ", "next_obs", "=", "self", ".", "_vec_normalize_env", ".", "unnormalize_obs", "(", "next_obs", ")", "\n", "", "", "else", ":", "\n", "            ", "next_obs", "=", "new_obs_", "\n", "\n", "", "replay_buffer", ".", "add", "(", "self", ".", "_last_original_obs", ",", "next_obs", ",", "buffer_action", ",", "reward_", ",", "done", ")", "\n", "\n", "self", ".", "_last_obs", "=", "new_obs", "\n", "# Save the unnormalized observation", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "            ", "self", ".", "_last_original_obs", "=", "new_obs_", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm.collect_rollouts": [[416, 521], ["isinstance", "callback.on_rollout_start", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.should_collect_more_steps", "callback.on_rollout_end", "gym_optimal_intrusion_response.agents.openai_baselines.common.type_aliases.RolloutReturn", "off_policy_algorithm.OffPolicyAlgorithm.actor.reset_noise", "numpy.mean", "off_policy_algorithm.OffPolicyAlgorithm._sample_action", "env.step", "callback.update_locals", "off_policy_algorithm.OffPolicyAlgorithm._update_info_buffer", "off_policy_algorithm.OffPolicyAlgorithm._store_transition", "off_policy_algorithm.OffPolicyAlgorithm._update_current_progress_remaining", "off_policy_algorithm.OffPolicyAlgorithm._on_step", "episode_rewards.append", "total_timesteps.append", "off_policy_algorithm.OffPolicyAlgorithm.actor.reset_noise", "locals", "callback.on_step", "gym_optimal_intrusion_response.agents.openai_baselines.common.type_aliases.RolloutReturn", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.should_collect_more_steps", "action_noise.reset", "off_policy_algorithm.OffPolicyAlgorithm._dump_logs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_rollout_start", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.should_collect_more_steps", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_rollout_end", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._sample_action", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.update_locals", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._store_transition", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._update_current_progress_remaining", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnMaxEpisodes._on_step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.should_collect_more_steps", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.off_policy_algorithm.OffPolicyAlgorithm._dump_logs"], ["", "", "def", "collect_rollouts", "(", "\n", "self", ",", "\n", "env", ":", "VecEnv", ",", "\n", "callback", ":", "BaseCallback", ",", "\n", "train_freq", ":", "TrainFreq", ",", "\n", "replay_buffer", ":", "ReplayBuffer", ",", "\n", "action_noise", ":", "Optional", "[", "ActionNoise", "]", "=", "None", ",", "\n", "learning_starts", ":", "int", "=", "0", ",", "\n", "log_interval", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "RolloutReturn", ":", "\n", "        ", "\"\"\"\n        Collect experiences and store them into a ``ReplayBuffer``.\n\n        :param env: The training environment\n        :param callback: Callback that will be called at each step\n            (and at the beginning and end of the rollout)\n        :param train_freq: How much experience to collect\n            by doing rollouts of current policy.\n            Either ``TrainFreq(<n>, TrainFrequencyUnit.STEP)``\n            or ``TrainFreq(<n>, TrainFrequencyUnit.EPISODE)``\n            with ``<n>`` being an integer greater than 0.\n        :param action_noise: Action noise that will be used for exploration\n            Required for deterministic policy (e.g. TD3). This can also be used\n            in addition to the stochastic policy for SAC.\n        :param learning_starts: Number of steps before learning for the warm-up phase.\n        :param replay_buffer:\n        :param log_interval: Log data every ``log_interval`` episodes\n        :return:\n        \"\"\"", "\n", "episode_rewards", ",", "total_timesteps", "=", "[", "]", ",", "[", "]", "\n", "num_collected_steps", ",", "num_collected_episodes", "=", "0", ",", "0", "\n", "\n", "assert", "isinstance", "(", "env", ",", "VecEnv", ")", ",", "\"You must pass a VecEnv\"", "\n", "assert", "env", ".", "num_envs", "==", "1", ",", "\"OffPolicyAlgorithm only support single environment\"", "\n", "assert", "train_freq", ".", "frequency", ">", "0", ",", "\"Should at least collect one step or episode.\"", "\n", "\n", "if", "self", ".", "use_sde", ":", "\n", "            ", "self", ".", "actor", ".", "reset_noise", "(", ")", "\n", "\n", "", "callback", ".", "on_rollout_start", "(", ")", "\n", "continue_training", "=", "True", "\n", "\n", "while", "should_collect_more_steps", "(", "train_freq", ",", "num_collected_steps", ",", "num_collected_episodes", ")", ":", "\n", "            ", "done", "=", "False", "\n", "episode_reward", ",", "episode_timesteps", "=", "0.0", ",", "0", "\n", "\n", "while", "not", "done", ":", "\n", "\n", "                ", "if", "self", ".", "use_sde", "and", "self", ".", "sde_sample_freq", ">", "0", "and", "num_collected_steps", "%", "self", ".", "sde_sample_freq", "==", "0", ":", "\n", "# Sample a new noise matrix", "\n", "                    ", "self", ".", "actor", ".", "reset_noise", "(", ")", "\n", "\n", "# Select action randomly or according to policy", "\n", "", "action", ",", "buffer_action", "=", "self", ".", "_sample_action", "(", "learning_starts", ",", "action_noise", ")", "\n", "\n", "# Rescale and perform action", "\n", "new_obs", ",", "reward", ",", "done", ",", "infos", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "self", ".", "num_timesteps", "+=", "1", "\n", "episode_timesteps", "+=", "1", "\n", "num_collected_steps", "+=", "1", "\n", "\n", "# Give access to local variables", "\n", "callback", ".", "update_locals", "(", "locals", "(", ")", ")", "\n", "# Only stop training if return value is False, not when it is None.", "\n", "if", "callback", ".", "on_step", "(", ")", "is", "False", ":", "\n", "                    ", "return", "RolloutReturn", "(", "0.0", ",", "num_collected_steps", ",", "num_collected_episodes", ",", "continue_training", "=", "False", ")", "\n", "\n", "", "episode_reward", "+=", "reward", "\n", "\n", "# Retrieve reward and episode length if using Monitor wrapper", "\n", "self", ".", "_update_info_buffer", "(", "infos", ",", "done", ")", "\n", "\n", "# Store data in replay buffer (normalized action and unnormalized observation)", "\n", "self", ".", "_store_transition", "(", "replay_buffer", ",", "buffer_action", ",", "new_obs", ",", "reward", ",", "done", ",", "infos", ")", "\n", "\n", "self", ".", "_update_current_progress_remaining", "(", "self", ".", "num_timesteps", ",", "self", ".", "_total_timesteps", ")", "\n", "\n", "# For DQN, check if the target network should be updated", "\n", "# and update the exploration schedule", "\n", "# For SAC/TD3, the update is done as the same time as the gradient update", "\n", "# see https://github.com/hill-a/stable-baselines/issues/900", "\n", "self", ".", "_on_step", "(", ")", "\n", "\n", "if", "not", "should_collect_more_steps", "(", "train_freq", ",", "num_collected_steps", ",", "num_collected_episodes", ")", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "done", ":", "\n", "                ", "num_collected_episodes", "+=", "1", "\n", "self", ".", "_episode_num", "+=", "1", "\n", "episode_rewards", ".", "append", "(", "episode_reward", ")", "\n", "total_timesteps", ".", "append", "(", "episode_timesteps", ")", "\n", "\n", "if", "action_noise", "is", "not", "None", ":", "\n", "                    ", "action_noise", ".", "reset", "(", ")", "\n", "\n", "# Log training infos", "\n", "", "if", "log_interval", "is", "not", "None", "and", "self", ".", "_episode_num", "%", "log_interval", "==", "0", ":", "\n", "                    ", "self", ".", "_dump_logs", "(", ")", "\n", "\n", "", "", "", "mean_reward", "=", "np", ".", "mean", "(", "episode_rewards", ")", "if", "num_collected_episodes", ">", "0", "else", "0.0", "\n", "\n", "callback", ".", "on_rollout_end", "(", ")", "\n", "\n", "return", "RolloutReturn", "(", "mean_reward", ",", "num_collected_steps", ",", "num_collected_episodes", ",", "continue_training", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space_channels_first": [[10, 25], ["numpy.argmin().item", "warnings.warn", "numpy.argmin"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["def", "is_image_space_channels_first", "(", "observation_space", ":", "spaces", ".", "Box", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Check if an image observation space (see ``is_image_space``)\n    is channels-first (CxHxW, True) or channels-last (HxWxC, False).\n\n    Use a heuristic that channel dimension is the smallest of the three.\n    If second dimension is smallest, raise an exception (no support).\n\n    :param observation_space:\n    :return: True if observation space is channels-first image, False if channels-last.\n    \"\"\"", "\n", "smallest_dimension", "=", "np", ".", "argmin", "(", "observation_space", ".", "shape", ")", ".", "item", "(", ")", "\n", "if", "smallest_dimension", "==", "1", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"Treating image space as channels-last, while second dimension was smallest of the three.\"", ")", "\n", "", "return", "smallest_dimension", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space": [[27, 62], ["isinstance", "len", "numpy.any", "numpy.any"], "function", ["None"], ["", "def", "is_image_space", "(", "observation_space", ":", "spaces", ".", "Space", ",", "channels_last", ":", "bool", "=", "True", ",", "check_channels", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Check if a observation space has the shape, limits and dtype\n    of a valid image.\n    The check is conservative, so that it returns False\n    if there is a doubt.\n\n    Valid images: RGB, RGBD, GrayScale with values in [0, 255]\n\n    :param observation_space:\n    :param channels_last:\n    :param check_channels: Whether to do or not the check for the number of channels.\n        e.g., with frame-stacking, the observation space may have more channels than expected.\n    :return:\n    \"\"\"", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Box", ")", "and", "len", "(", "observation_space", ".", "shape", ")", "==", "3", ":", "\n", "# Check the type", "\n", "        ", "if", "observation_space", ".", "dtype", "!=", "np", ".", "uint8", ":", "\n", "            ", "return", "False", "\n", "\n", "# Check the value range", "\n", "", "if", "np", ".", "any", "(", "observation_space", ".", "low", "!=", "0", ")", "or", "np", ".", "any", "(", "observation_space", ".", "high", "!=", "255", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "# Skip channels check", "\n", "", "if", "not", "check_channels", ":", "\n", "            ", "return", "True", "\n", "# Check the number of channels", "\n", "", "if", "channels_last", ":", "\n", "            ", "n_channels", "=", "observation_space", ".", "shape", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "n_channels", "=", "observation_space", ".", "shape", "[", "0", "]", "\n", "# RGB, RGBD, GrayScale", "\n", "", "return", "n_channels", "in", "[", "1", ",", "3", ",", "4", "]", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.maybe_transpose": [[64, 82], ["preprocessing.is_image_space", "VecTransposeImage.transpose_image"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_image"], ["", "def", "maybe_transpose", "(", "observation", ":", "np", ".", "ndarray", ",", "observation_space", ":", "spaces", ".", "Space", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Handle the different cases for images as PyTorch use channel first format.\n\n    :param observation:\n    :param observation_space:\n    :return: channel first observation if observation is an image\n    \"\"\"", "\n", "# Avoid circular import", "\n", "from", "stable_baselines3", ".", "common", ".", "vec_env", "import", "VecTransposeImage", "\n", "\n", "if", "is_image_space", "(", "observation_space", ")", ":", "\n", "        ", "if", "not", "(", "observation", ".", "shape", "==", "observation_space", ".", "shape", "or", "observation", ".", "shape", "[", "1", ":", "]", "==", "observation_space", ".", "shape", ")", ":", "\n", "# Try to re-order the channels", "\n", "            ", "transpose_obs", "=", "VecTransposeImage", ".", "transpose_image", "(", "observation", ")", "\n", "if", "transpose_obs", ".", "shape", "==", "observation_space", ".", "shape", "or", "transpose_obs", ".", "shape", "[", "1", ":", "]", "==", "observation_space", ".", "shape", ":", "\n", "                ", "observation", "=", "transpose_obs", "\n", "", "", "", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.preprocess_obs": [[84, 120], ["isinstance", "obs.float", "isinstance", "preprocessing.is_image_space", "torch.nn.functional.one_hot().float", "isinstance", "obs.float", "torch.cat().view", "isinstance", "torch.nn.functional.one_hot", "sum", "obs.float", "NotImplementedError", "obs.long", "torch.cat", "torch.nn.functional.one_hot().float", "enumerate", "torch.nn.functional.one_hot", "torch.split", "obs_.long", "obs.long", "int"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space"], ["", "def", "preprocess_obs", "(", "obs", ":", "th", ".", "Tensor", ",", "observation_space", ":", "spaces", ".", "Space", ",", "normalize_images", ":", "bool", "=", "True", ")", "->", "th", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Preprocess observation to be to a neural network.\n    For images, it normalizes the values by dividing them by 255 (to have values in [0, 1])\n    For discrete observations, it create a one hot vector.\n\n    :param obs: Observation\n    :param observation_space:\n    :param normalize_images: Whether to normalize images or not\n        (True by default)\n    :return:\n    \"\"\"", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Box", ")", ":", "\n", "        ", "if", "is_image_space", "(", "observation_space", ")", "and", "normalize_images", ":", "\n", "            ", "return", "obs", ".", "float", "(", ")", "/", "255.0", "\n", "", "return", "obs", ".", "float", "(", ")", "\n", "\n", "", "elif", "isinstance", "(", "observation_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "# One hot encoding and convert to float to avoid errors", "\n", "        ", "return", "F", ".", "one_hot", "(", "obs", ".", "long", "(", ")", ",", "num_classes", "=", "observation_space", ".", "n", ")", ".", "float", "(", ")", "\n", "\n", "", "elif", "isinstance", "(", "observation_space", ",", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "# Tensor concatenation of one hot encodings of each Categorical sub-space", "\n", "        ", "return", "th", ".", "cat", "(", "\n", "[", "\n", "F", ".", "one_hot", "(", "obs_", ".", "long", "(", ")", ",", "num_classes", "=", "int", "(", "observation_space", ".", "nvec", "[", "idx", "]", ")", ")", ".", "float", "(", ")", "\n", "for", "idx", ",", "obs_", "in", "enumerate", "(", "th", ".", "split", "(", "obs", ".", "long", "(", ")", ",", "1", ",", "dim", "=", "1", ")", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", ".", "view", "(", "obs", ".", "shape", "[", "0", "]", ",", "sum", "(", "observation_space", ".", "nvec", ")", ")", "\n", "\n", "", "elif", "isinstance", "(", "observation_space", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "        ", "return", "obs", ".", "float", "(", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Preprocessing not implemented for {observation_space}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_obs_shape": [[122, 142], ["isinstance", "isinstance", "isinstance", "isinstance", "int", "NotImplementedError", "len", "int"], "function", ["None"], ["", "", "def", "get_obs_shape", "(", "observation_space", ":", "spaces", ".", "Space", ")", "->", "Tuple", "[", "int", ",", "...", "]", ":", "\n", "    ", "\"\"\"\n    Get the shape of the observation (useful for the buffers).\n\n    :param observation_space:\n    :return:\n    \"\"\"", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Box", ")", ":", "\n", "        ", "return", "observation_space", ".", "shape", "\n", "", "elif", "isinstance", "(", "observation_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "# Observation is an int", "\n", "        ", "return", "(", "1", ",", ")", "\n", "", "elif", "isinstance", "(", "observation_space", ",", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "# Number of discrete features", "\n", "        ", "return", "(", "int", "(", "len", "(", "observation_space", ".", "nvec", ")", ")", ",", ")", "\n", "", "elif", "isinstance", "(", "observation_space", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "# Number of binary features", "\n", "        ", "return", "(", "int", "(", "observation_space", ".", "n", ")", ",", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"{observation_space} observation space is not supported\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_flattened_obs_dim": [[144, 159], ["isinstance", "sum", "gym.spaces.utils.flatdim"], "function", ["None"], ["", "", "def", "get_flattened_obs_dim", "(", "observation_space", ":", "spaces", ".", "Space", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Get the dimension of the observation space when flattened.\n    It does not apply to image observation space.\n\n    :param observation_space:\n    :return:\n    \"\"\"", "\n", "# See issue https://github.com/openai/gym/issues/1915", "\n", "# it may be a problem for Dict/Tuple spaces too...", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "        ", "return", "sum", "(", "observation_space", ".", "nvec", ")", "\n", "", "else", ":", "\n", "# Use Gym internal method", "\n", "        ", "return", "spaces", ".", "utils", ".", "flatdim", "(", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_action_dim": [[161, 181], ["isinstance", "int", "isinstance", "numpy.prod", "isinstance", "int", "isinstance", "len", "int", "NotImplementedError"], "function", ["None"], ["", "", "def", "get_action_dim", "(", "action_space", ":", "spaces", ".", "Space", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Get the dimension of the action space.\n\n    :param action_space:\n    :return:\n    \"\"\"", "\n", "if", "isinstance", "(", "action_space", ",", "spaces", ".", "Box", ")", ":", "\n", "        ", "return", "int", "(", "np", ".", "prod", "(", "action_space", ".", "shape", ")", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "# Action is an int", "\n", "        ", "return", "1", "\n", "", "elif", "isinstance", "(", "action_space", ",", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "# Number of discrete actions", "\n", "        ", "return", "int", "(", "len", "(", "action_space", ".", "nvec", ")", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "# Number of binary actions", "\n", "        ", "return", "int", "(", "action_space", ".", "n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"{action_space} action space is not supported\"", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.__init__": [[18, 20], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Distribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.proba_distribution_net": [[21, 27], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "proba_distribution_net", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Union", "[", "nn", ".", "Module", ",", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Parameter", "]", "]", ":", "\n", "        ", "\"\"\"Create the layers and parameters that represent the distribution.\n\n        Subclasses must define this, but the arguments and return type vary between\n        concrete classes.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.proba_distribution": [[28, 34], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "proba_distribution", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "\"Distribution\"", ":", "\n", "        ", "\"\"\"Set parameters of the distribution.\n\n        :return: self\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.log_prob": [[35, 43], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "log_prob", "(", "self", ",", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns the log likelihood\n\n        :param x: the taken action\n        :return: The log likelihood of the distribution\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.entropy": [[44, 51], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "entropy", "(", "self", ")", "->", "Optional", "[", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Returns Shannon's entropy of the probability\n\n        :return: the entropy, or None if no analytical form is known\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.sample": [[52, 59], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns a sample from the probability distribution\n\n        :return: the stochastic action\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.mode": [[60, 68], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns the most likely action (deterministic output)\n        from the probability distribution\n\n        :return: the stochastic action\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions": [[69, 79], ["distributions.Distribution.sample", "distributions.Distribution.mode"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.mode"], ["", "def", "get_actions", "(", "self", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Return actions according to the probability distribution.\n\n        :param deterministic:\n        :return:\n        \"\"\"", "\n", "if", "deterministic", ":", "\n", "            ", "return", "self", ".", "mode", "(", ")", "\n", "", "return", "self", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.actions_from_params": [[80, 88], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "actions_from_params", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns samples from the probability distribution\n        given its parameters.\n\n        :return: actions\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.log_prob_from_params": [[89, 97], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "log_prob_from_params", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Returns samples and the associated log probabilities\n        from the probability distribution given its parameters.\n\n        :return: actions and log prob\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.__init__": [[121, 127], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ")", ":", "\n", "        ", "super", "(", "DiagGaussianDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "mean_actions", "=", "None", "\n", "self", ".", "log_std", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.proba_distribution_net": [[128, 142], ["torch.nn.Linear", "torch.nn.Parameter", "torch.ones"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ",", "log_std_init", ":", "float", "=", "0.0", ")", "->", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Parameter", "]", ":", "\n", "        ", "\"\"\"\n        Create the layers and parameter that represent the distribution:\n        one output will be the mean of the Gaussian, the other parameter will be the\n        standard deviation (log std in fact to allow negative values)\n\n        :param latent_dim: Dimension of the last layer of the policy (before the action layer)\n        :param log_std_init: Initial value for the log standard deviation\n        :return:\n        \"\"\"", "\n", "mean_actions", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dim", ")", "\n", "# TODO: allow action dependent std", "\n", "log_std", "=", "nn", ".", "Parameter", "(", "th", ".", "ones", "(", "self", ".", "action_dim", ")", "*", "log_std_init", ",", "requires_grad", "=", "True", ")", "\n", "return", "mean_actions", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.proba_distribution": [[143, 154], ["torch.distributions.Normal", "torch.ones_like", "log_std.exp"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ")", "->", "\"DiagGaussianDistribution\"", ":", "\n", "        ", "\"\"\"\n        Create the distribution given its parameters (mean, std)\n\n        :param mean_actions:\n        :param log_std:\n        :return:\n        \"\"\"", "\n", "action_std", "=", "th", ".", "ones_like", "(", "mean_actions", ")", "*", "log_std", ".", "exp", "(", ")", "\n", "self", ".", "distribution", "=", "Normal", "(", "mean_actions", ",", "action_std", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.log_prob": [[155, 165], ["distributions.DiagGaussianDistribution.distribution.log_prob", "distributions.sum_independent_dims"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.sum_independent_dims"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the log probabilities of actions according to the distribution.\n        Note that you must first call the ``proba_distribution()`` method.\n\n        :param actions:\n        :return:\n        \"\"\"", "\n", "log_prob", "=", "self", ".", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "return", "sum_independent_dims", "(", "log_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.entropy": [[166, 168], ["distributions.sum_independent_dims", "distributions.DiagGaussianDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.sum_independent_dims", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "sum_independent_dims", "(", "self", ".", "distribution", ".", "entropy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.sample": [[169, 172], ["distributions.DiagGaussianDistribution.distribution.rsample"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "# Reparametrization trick to pass gradients", "\n", "        ", "return", "self", ".", "distribution", ".", "rsample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.mode": [[173, 175], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.actions_from_params": [[176, 180], ["distributions.DiagGaussianDistribution.proba_distribution", "distributions.DiagGaussianDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "mean_actions", ",", "log_std", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.DiagGaussianDistribution.log_prob_from_params": [[181, 193], ["distributions.DiagGaussianDistribution.actions_from_params", "distributions.DiagGaussianDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Compute the log probability of taking an action\n        given the distribution parameters.\n\n        :param mean_actions:\n        :param log_std:\n        :return:\n        \"\"\"", "\n", "actions", "=", "self", ".", "actions_from_params", "(", "mean_actions", ",", "log_std", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.__init__": [[203, 208], ["distributions.DiagGaussianDistribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ",", "epsilon", ":", "float", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "SquashedDiagGaussianDistribution", ",", "self", ")", ".", "__init__", "(", "action_dim", ")", "\n", "# Avoid NaN (prevents division by zero or log of zero)", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "gaussian_actions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.proba_distribution": [[209, 212], ["distributions.DiagGaussianDistribution.proba_distribution"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution"], ["", "def", "proba_distribution", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ")", "->", "\"SquashedDiagGaussianDistribution\"", ":", "\n", "        ", "super", "(", "SquashedDiagGaussianDistribution", ",", "self", ")", ".", "proba_distribution", "(", "mean_actions", ",", "log_std", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.log_prob": [[213, 227], ["distributions.DiagGaussianDistribution.log_prob", "torch.sum", "distributions.TanhBijector.inverse", "torch.log"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.inverse", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ",", "gaussian_actions", ":", "Optional", "[", "th", ".", "Tensor", "]", "=", "None", ")", "->", "th", ".", "Tensor", ":", "\n", "# Inverse tanh", "\n", "# Naive implementation (not stable): 0.5 * torch.log((1 + x) / (1 - x))", "\n", "# We use numpy to avoid numerical instability", "\n", "        ", "if", "gaussian_actions", "is", "None", ":", "\n", "# It will be clipped to avoid NaN when inversing tanh", "\n", "            ", "gaussian_actions", "=", "TanhBijector", ".", "inverse", "(", "actions", ")", "\n", "\n", "# Log likelihood for a Gaussian distribution", "\n", "", "log_prob", "=", "super", "(", "SquashedDiagGaussianDistribution", ",", "self", ")", ".", "log_prob", "(", "gaussian_actions", ")", "\n", "# Squash correction (from original SAC implementation)", "\n", "# this comes from the fact that tanh is bijective and differentiable", "\n", "log_prob", "-=", "th", ".", "sum", "(", "th", ".", "log", "(", "1", "-", "actions", "**", "2", "+", "self", ".", "epsilon", ")", ",", "dim", "=", "1", ")", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.entropy": [[228, 232], ["None"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", "->", "Optional", "[", "th", ".", "Tensor", "]", ":", "\n", "# No analytical form,", "\n", "# entropy needs to be estimated using -log_prob.mean()", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.sample": [[233, 237], ["distributions.DiagGaussianDistribution.sample", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "# Reparametrization trick to pass gradients", "\n", "        ", "self", ".", "gaussian_actions", "=", "super", "(", ")", ".", "sample", "(", ")", "\n", "return", "th", ".", "tanh", "(", "self", ".", "gaussian_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.mode": [[238, 242], ["distributions.DiagGaussianDistribution.mode", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.mode"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "self", ".", "gaussian_actions", "=", "super", "(", ")", ".", "mode", "(", ")", "\n", "# Squash the output", "\n", "return", "th", ".", "tanh", "(", "self", ".", "gaussian_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.SquashedDiagGaussianDistribution.log_prob_from_params": [[243, 247], ["distributions.SquashedDiagGaussianDistribution.actions_from_params", "distributions.SquashedDiagGaussianDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "action", "=", "self", ".", "actions_from_params", "(", "mean_actions", ",", "log_std", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "action", ",", "self", ".", "gaussian_actions", ")", "\n", "return", "action", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.__init__": [[256, 260], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ")", ":", "\n", "        ", "super", "(", "CategoricalDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.proba_distribution_net": [[261, 273], ["torch.nn.Linear"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"\n        Create the layer that represents the distribution:\n        it will be the logits of the Categorical distribution.\n        You can then get probabilities using a softmax.\n\n        :param latent_dim: Dimension of the last layer\n            of the policy network (before the action layer)\n        :return:\n        \"\"\"", "\n", "action_logits", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dim", ")", "\n", "return", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.proba_distribution": [[274, 277], ["torch.distributions.Categorical"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "\"CategoricalDistribution\"", ":", "\n", "        ", "self", ".", "distribution", "=", "Categorical", "(", "logits", "=", "action_logits", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.log_prob": [[278, 280], ["distributions.CategoricalDistribution.distribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.entropy": [[281, 283], ["distributions.CategoricalDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.sample": [[284, 286], ["distributions.CategoricalDistribution.distribution.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.mode": [[287, 289], ["torch.argmax"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "argmax", "(", "self", ".", "distribution", ".", "probs", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.actions_from_params": [[290, 294], ["distributions.CategoricalDistribution.proba_distribution", "distributions.CategoricalDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "action_logits", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.CategoricalDistribution.log_prob_from_params": [[295, 299], ["distributions.CategoricalDistribution.actions_from_params", "distributions.CategoricalDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "action_logits", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.__init__": [[308, 312], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "action_dims", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "super", "(", "MultiCategoricalDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_dims", "=", "action_dims", "\n", "self", ".", "distributions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.proba_distribution_net": [[313, 326], ["torch.nn.Linear", "sum"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"\n        Create the layer that represents the distribution:\n        it will be the logits (flattened) of the MultiCategorical distribution.\n        You can then get probabilities using a softmax on each sub-space.\n\n        :param latent_dim: Dimension of the last layer\n            of the policy network (before the action layer)\n        :return:\n        \"\"\"", "\n", "\n", "action_logits", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "sum", "(", "self", ".", "action_dims", ")", ")", "\n", "return", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.proba_distribution": [[327, 330], ["torch.distributions.Categorical", "torch.split", "tuple"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "\"MultiCategoricalDistribution\"", ":", "\n", "        ", "self", ".", "distributions", "=", "[", "Categorical", "(", "logits", "=", "split", ")", "for", "split", "in", "th", ".", "split", "(", "action_logits", ",", "tuple", "(", "self", ".", "action_dims", ")", ",", "dim", "=", "1", ")", "]", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.log_prob": [[331, 336], ["torch.stack().sum", "torch.stack", "dist.log_prob", "zip", "torch.unbind"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "# Extract each discrete action and compute log prob for their respective distributions", "\n", "        ", "return", "th", ".", "stack", "(", "\n", "[", "dist", ".", "log_prob", "(", "action", ")", "for", "dist", ",", "action", "in", "zip", "(", "self", ".", "distributions", ",", "th", ".", "unbind", "(", "actions", ",", "dim", "=", "1", ")", ")", "]", ",", "dim", "=", "1", "\n", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.entropy": [[337, 339], ["torch.stack().sum", "torch.stack", "dist.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "stack", "(", "[", "dist", ".", "entropy", "(", ")", "for", "dist", "in", "self", ".", "distributions", "]", ",", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.sample": [[340, 342], ["torch.stack", "dist.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "stack", "(", "[", "dist", ".", "sample", "(", ")", "for", "dist", "in", "self", ".", "distributions", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.mode": [[343, 345], ["torch.stack", "torch.argmax"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "stack", "(", "[", "th", ".", "argmax", "(", "dist", ".", "probs", ",", "dim", "=", "1", ")", "for", "dist", "in", "self", ".", "distributions", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.actions_from_params": [[346, 350], ["distributions.MultiCategoricalDistribution.proba_distribution", "distributions.MultiCategoricalDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "action_logits", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.MultiCategoricalDistribution.log_prob_from_params": [[351, 355], ["distributions.MultiCategoricalDistribution.actions_from_params", "distributions.MultiCategoricalDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "action_logits", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.__init__": [[364, 368], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "action_dims", ":", "int", ")", ":", "\n", "        ", "super", "(", "BernoulliDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dims", "=", "action_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.proba_distribution_net": [[369, 380], ["torch.nn.Linear"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"\n        Create the layer that represents the distribution:\n        it will be the logits of the Bernoulli distribution.\n\n        :param latent_dim: Dimension of the last layer\n            of the policy network (before the action layer)\n        :return:\n        \"\"\"", "\n", "action_logits", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dims", ")", "\n", "return", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.proba_distribution": [[381, 384], ["torch.distributions.Bernoulli"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "\"BernoulliDistribution\"", ":", "\n", "        ", "self", ".", "distribution", "=", "Bernoulli", "(", "logits", "=", "action_logits", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.log_prob": [[385, 387], ["distributions.BernoulliDistribution.distribution.log_prob().sum", "distributions.BernoulliDistribution.distribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "log_prob", "(", "actions", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.entropy": [[388, 390], ["distributions.BernoulliDistribution.distribution.entropy().sum", "distributions.BernoulliDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "entropy", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.sample": [[391, 393], ["distributions.BernoulliDistribution.distribution.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.mode": [[394, 396], ["torch.round"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "round", "(", "self", ".", "distribution", ".", "probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.actions_from_params": [[397, 401], ["distributions.BernoulliDistribution.proba_distribution", "distributions.BernoulliDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "action_logits", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.BernoulliDistribution.log_prob_from_params": [[402, 406], ["distributions.BernoulliDistribution.actions_from_params", "distributions.BernoulliDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "action_logits", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.__init__": [[430, 457], ["distributions.Distribution.__init__", "distributions.TanhBijector"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "action_dim", ":", "int", ",", "\n", "full_std", ":", "bool", "=", "True", ",", "\n", "use_expln", ":", "bool", "=", "False", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "learn_features", ":", "bool", "=", "False", ",", "\n", "epsilon", ":", "float", "=", "1e-6", ",", "\n", ")", ":", "\n", "        ", "super", "(", "StateDependentNoiseDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "latent_sde_dim", "=", "None", "\n", "self", ".", "mean_actions", "=", "None", "\n", "self", ".", "log_std", "=", "None", "\n", "self", ".", "weights_dist", "=", "None", "\n", "self", ".", "exploration_mat", "=", "None", "\n", "self", ".", "exploration_matrices", "=", "None", "\n", "self", ".", "_latent_sde", "=", "None", "\n", "self", ".", "use_expln", "=", "use_expln", "\n", "self", ".", "full_std", "=", "full_std", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "learn_features", "=", "learn_features", "\n", "if", "squash_output", ":", "\n", "            ", "self", ".", "bijector", "=", "TanhBijector", "(", "epsilon", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bijector", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.get_std": [[458, 482], ["torch.exp", "torch.ones().to", "torch.exp", "torch.log1p", "torch.ones"], "methods", ["None"], ["", "", "def", "get_std", "(", "self", ",", "log_std", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the standard deviation from the learned parameter\n        (log of it by default). This ensures that the std is positive.\n\n        :param log_std:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "use_expln", ":", "\n", "# From gSDE paper, it allows to keep variance", "\n", "# above zero and prevent it from growing too fast", "\n", "            ", "below_threshold", "=", "th", ".", "exp", "(", "log_std", ")", "*", "(", "log_std", "<=", "0", ")", "\n", "# Avoid NaN: zeros values that are below zero", "\n", "safe_log_std", "=", "log_std", "*", "(", "log_std", ">", "0", ")", "+", "self", ".", "epsilon", "\n", "above_threshold", "=", "(", "th", ".", "log1p", "(", "safe_log_std", ")", "+", "1.0", ")", "*", "(", "log_std", ">", "0", ")", "\n", "std", "=", "below_threshold", "+", "above_threshold", "\n", "", "else", ":", "\n", "# Use normal exponential", "\n", "            ", "std", "=", "th", ".", "exp", "(", "log_std", ")", "\n", "\n", "", "if", "self", ".", "full_std", ":", "\n", "            ", "return", "std", "\n", "# Reduce the number of parameters:", "\n", "", "return", "th", ".", "ones", "(", "self", ".", "latent_sde_dim", ",", "self", ".", "action_dim", ")", ".", "to", "(", "log_std", ".", "device", ")", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.sample_weights": [[483, 497], ["distributions.StateDependentNoiseDistribution.get_std", "torch.distributions.Normal", "distributions.StateDependentNoiseDistribution.weights_dist.rsample", "distributions.StateDependentNoiseDistribution.weights_dist.rsample", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.get_std"], ["", "def", "sample_weights", "(", "self", ",", "log_std", ":", "th", ".", "Tensor", ",", "batch_size", ":", "int", "=", "1", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sample weights for the noise exploration matrix,\n        using a centered Gaussian distribution.\n\n        :param log_std:\n        :param batch_size:\n        \"\"\"", "\n", "std", "=", "self", ".", "get_std", "(", "log_std", ")", "\n", "self", ".", "weights_dist", "=", "Normal", "(", "th", ".", "zeros_like", "(", "std", ")", ",", "std", ")", "\n", "# Reparametrization trick to pass gradients", "\n", "self", ".", "exploration_mat", "=", "self", ".", "weights_dist", ".", "rsample", "(", ")", "\n", "# Pre-compute matrices in case of parallel exploration", "\n", "self", ".", "exploration_matrices", "=", "self", ".", "weights_dist", ".", "rsample", "(", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution_net": [[498, 524], ["torch.nn.Linear", "torch.nn.Parameter", "distributions.StateDependentNoiseDistribution.sample_weights", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.sample_weights"], ["", "def", "proba_distribution_net", "(", "\n", "self", ",", "latent_dim", ":", "int", ",", "log_std_init", ":", "float", "=", "-", "2.0", ",", "latent_sde_dim", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Parameter", "]", ":", "\n", "        ", "\"\"\"\n        Create the layers and parameter that represent the distribution:\n        one output will be the deterministic action, the other parameter will be the\n        standard deviation of the distribution that control the weights of the noise matrix.\n\n        :param latent_dim: Dimension of the last layer of the policy (before the action layer)\n        :param log_std_init: Initial value for the log standard deviation\n        :param latent_sde_dim: Dimension of the last layer of the features extractor\n            for gSDE. By default, it is shared with the policy network.\n        :return:\n        \"\"\"", "\n", "# Network for the deterministic action, it represents the mean of the distribution", "\n", "mean_actions_net", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dim", ")", "\n", "# When we learn features for the noise, the feature dimension", "\n", "# can be different between the policy and the noise network", "\n", "self", ".", "latent_sde_dim", "=", "latent_dim", "if", "latent_sde_dim", "is", "None", "else", "latent_sde_dim", "\n", "# Reduce the number of parameters if needed", "\n", "log_std", "=", "th", ".", "ones", "(", "self", ".", "latent_sde_dim", ",", "self", ".", "action_dim", ")", "if", "self", ".", "full_std", "else", "th", ".", "ones", "(", "self", ".", "latent_sde_dim", ",", "1", ")", "\n", "# Transform it to a parameter so it can be optimized", "\n", "log_std", "=", "nn", ".", "Parameter", "(", "log_std", "*", "log_std_init", ",", "requires_grad", "=", "True", ")", "\n", "# Sample an exploration matrix", "\n", "self", ".", "sample_weights", "(", "log_std", ")", "\n", "return", "mean_actions_net", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution": [[525, 541], ["torch.mm", "torch.distributions.Normal", "latent_sde.detach", "torch.sqrt", "distributions.StateDependentNoiseDistribution.get_std"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.get_std"], ["", "def", "proba_distribution", "(", "\n", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ",", "latent_sde", ":", "th", ".", "Tensor", "\n", ")", "->", "\"StateDependentNoiseDistribution\"", ":", "\n", "        ", "\"\"\"\n        Create the distribution given its parameters (mean, std)\n\n        :param mean_actions:\n        :param log_std:\n        :param latent_sde:\n        :return:\n        \"\"\"", "\n", "# Stop gradient if we don't want to influence the features", "\n", "self", ".", "_latent_sde", "=", "latent_sde", "if", "self", ".", "learn_features", "else", "latent_sde", ".", "detach", "(", ")", "\n", "variance", "=", "th", ".", "mm", "(", "self", ".", "_latent_sde", "**", "2", ",", "self", ".", "get_std", "(", "log_std", ")", "**", "2", ")", "\n", "self", ".", "distribution", "=", "Normal", "(", "mean_actions", ",", "th", ".", "sqrt", "(", "variance", "+", "self", ".", "epsilon", ")", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob": [[542, 556], ["distributions.StateDependentNoiseDistribution.distribution.log_prob", "distributions.sum_independent_dims", "distributions.StateDependentNoiseDistribution.bijector.inverse", "torch.sum", "distributions.StateDependentNoiseDistribution.bijector.log_prob_correction"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.sum_independent_dims", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.inverse", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.log_prob_correction"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "gaussian_actions", "=", "self", ".", "bijector", ".", "inverse", "(", "actions", ")", "\n", "", "else", ":", "\n", "            ", "gaussian_actions", "=", "actions", "\n", "# log likelihood for a gaussian", "\n", "", "log_prob", "=", "self", ".", "distribution", ".", "log_prob", "(", "gaussian_actions", ")", "\n", "# Sum along action dim", "\n", "log_prob", "=", "sum_independent_dims", "(", "log_prob", ")", "\n", "\n", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "# Squash correction (from original SAC implementation)", "\n", "            ", "log_prob", "-=", "th", ".", "sum", "(", "self", ".", "bijector", ".", "log_prob_correction", "(", "gaussian_actions", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy": [[557, 563], ["distributions.sum_independent_dims", "distributions.StateDependentNoiseDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.sum_independent_dims", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "Optional", "[", "th", ".", "Tensor", "]", ":", "\n", "        ", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "# No analytical form,", "\n", "# entropy needs to be estimated using -log_prob.mean()", "\n", "            ", "return", "None", "\n", "", "return", "sum_independent_dims", "(", "self", ".", "distribution", ".", "entropy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.sample": [[564, 570], ["distributions.StateDependentNoiseDistribution.get_noise", "distributions.StateDependentNoiseDistribution.bijector.forward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.get_noise", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.forward"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "noise", "=", "self", ".", "get_noise", "(", "self", ".", "_latent_sde", ")", "\n", "actions", "=", "self", ".", "distribution", ".", "mean", "+", "noise", "\n", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "bijector", ".", "forward", "(", "actions", ")", "\n", "", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.mode": [[571, 576], ["distributions.StateDependentNoiseDistribution.bijector.forward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.forward"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "actions", "=", "self", ".", "distribution", ".", "mean", "\n", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "bijector", ".", "forward", "(", "actions", ")", "\n", "", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.get_noise": [[577, 588], ["latent_sde.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm.squeeze", "latent_sde.unsqueeze.unsqueeze.detach", "torch.mm", "len", "len", "len"], "methods", ["None"], ["", "def", "get_noise", "(", "self", ",", "latent_sde", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "latent_sde", "=", "latent_sde", "if", "self", ".", "learn_features", "else", "latent_sde", ".", "detach", "(", ")", "\n", "# Default case: only one exploration matrix", "\n", "if", "len", "(", "latent_sde", ")", "==", "1", "or", "len", "(", "latent_sde", ")", "!=", "len", "(", "self", ".", "exploration_matrices", ")", ":", "\n", "            ", "return", "th", ".", "mm", "(", "latent_sde", ",", "self", ".", "exploration_mat", ")", "\n", "# Use batch matrix multiplication for efficient computation", "\n", "# (batch_size, n_features) -> (batch_size, 1, n_features)", "\n", "", "latent_sde", "=", "latent_sde", ".", "unsqueeze", "(", "1", ")", "\n", "# (batch_size, 1, n_actions)", "\n", "noise", "=", "th", ".", "bmm", "(", "latent_sde", ",", "self", ".", "exploration_matrices", ")", "\n", "return", "noise", ".", "squeeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params": [[589, 595], ["distributions.StateDependentNoiseDistribution.proba_distribution", "distributions.StateDependentNoiseDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "\n", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ",", "latent_sde", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", "\n", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "mean_actions", ",", "log_std", ",", "latent_sde", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob_from_params": [[596, 602], ["distributions.StateDependentNoiseDistribution.actions_from_params", "distributions.StateDependentNoiseDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "\n", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "log_std", ":", "th", ".", "Tensor", ",", "latent_sde", ":", "th", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "mean_actions", ",", "log_std", ",", "latent_sde", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.__init__": [[613, 616], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "epsilon", ":", "float", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "TanhBijector", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.forward": [[617, 620], ["torch.tanh"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "tanh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.atanh": [[621, 630], ["x.log1p"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "atanh", "(", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Inverse of Tanh\n\n        Taken from Pyro: https://github.com/pyro-ppl/pyro\n        0.5 * torch.log((1 + x ) / (1 - x))\n        \"\"\"", "\n", "return", "0.5", "*", "(", "x", ".", "log1p", "(", ")", "-", "(", "-", "x", ")", ".", "log1p", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.inverse": [[631, 642], ["distributions.TanhBijector.atanh", "torch.finfo", "y.clamp"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.atanh"], ["", "@", "staticmethod", "\n", "def", "inverse", "(", "y", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Inverse tanh.\n\n        :param y:\n        :return:\n        \"\"\"", "\n", "eps", "=", "th", ".", "finfo", "(", "y", ".", "dtype", ")", ".", "eps", "\n", "# Clip the action to avoid NaN", "\n", "return", "TanhBijector", ".", "atanh", "(", "y", ".", "clamp", "(", "min", "=", "-", "1.0", "+", "eps", ",", "max", "=", "1.0", "-", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.TanhBijector.log_prob_correction": [[643, 646], ["torch.log", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.log"], ["", "def", "log_prob_correction", "(", "self", ",", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "# Squash correction (from original SAC implementation)", "\n", "        ", "return", "th", ".", "log", "(", "1.0", "-", "th", ".", "tanh", "(", "x", ")", "**", "2", "+", "self", ".", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.sum_independent_dims": [[99, 112], ["len", "tensor.sum.sum", "tensor.sum.sum"], "function", ["None"], ["", "", "def", "sum_independent_dims", "(", "tensor", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Continuous actions are usually considered to be independent,\n    so we can sum components of the ``log_prob`` or the entropy.\n\n    :param tensor: shape: (n_batch, n_actions) or (n_batch,)\n    :return: shape: (n_batch,)\n    \"\"\"", "\n", "if", "len", "(", "tensor", ".", "shape", ")", ">", "1", ":", "\n", "        ", "tensor", "=", "tensor", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "tensor", "=", "tensor", ".", "sum", "(", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.distributions.make_proba_distribution": [[648, 654], ["distributions.CategoricalDistribution"], "function", ["None"], ["", "", "def", "make_proba_distribution", "(", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "dist_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", "\n", ")", "->", "Distribution", ":", "\n", "    ", "if", "dist_kwargs", "is", "None", ":", "\n", "        ", "dist_kwargs", "=", "{", "}", "\n", "", "return", "CategoricalDistribution", "(", "action_space", ".", "n", ",", "**", "dist_kwargs", ")", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.NoopResetEnv.__init__": [[24, 30], ["gym.Wrapper.__init__", "env.unwrapped.get_action_meanings"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "env", ":", "gym", ".", "Env", ",", "noop_max", ":", "int", "=", "30", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "noop_max", "=", "noop_max", "\n", "self", ".", "override_num_noops", "=", "None", "\n", "self", ".", "noop_action", "=", "0", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "0", "]", "==", "\"NOOP\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.NoopResetEnv.reset": [[31, 44], ["atari_wrappers.NoopResetEnv.env.reset", "numpy.zeros", "range", "atari_wrappers.NoopResetEnv.unwrapped.np_random.randint", "atari_wrappers.NoopResetEnv.env.step", "atari_wrappers.NoopResetEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "if", "self", ".", "override_num_noops", "is", "not", "None", ":", "\n", "            ", "noops", "=", "self", ".", "override_num_noops", "\n", "", "else", ":", "\n", "            ", "noops", "=", "self", ".", "unwrapped", ".", "np_random", ".", "randint", "(", "1", ",", "self", ".", "noop_max", "+", "1", ")", "\n", "", "assert", "noops", ">", "0", "\n", "obs", "=", "np", ".", "zeros", "(", "0", ")", "\n", "for", "_", "in", "range", "(", "noops", ")", ":", "\n", "            ", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "self", ".", "noop_action", ")", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.FireResetEnv.__init__": [[53, 57], ["gym.Wrapper.__init__", "len", "env.unwrapped.get_action_meanings", "env.unwrapped.get_action_meanings"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "env", ":", "gym", ".", "Env", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "1", "]", "==", "\"FIRE\"", "\n", "assert", "len", "(", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ")", ">=", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.FireResetEnv.reset": [[58, 67], ["atari_wrappers.FireResetEnv.env.reset", "atari_wrappers.FireResetEnv.env.step", "atari_wrappers.FireResetEnv.env.step", "atari_wrappers.FireResetEnv.env.reset", "atari_wrappers.FireResetEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "1", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "2", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.EpisodicLifeEnv.__init__": [[77, 81], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "env", ":", "gym", ".", "Env", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "lives", "=", "0", "\n", "self", ".", "was_real_done", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.EpisodicLifeEnv.step": [[82, 95], ["atari_wrappers.EpisodicLifeEnv.env.step", "atari_wrappers.EpisodicLifeEnv.env.unwrapped.ale.lives"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["", "def", "step", "(", "self", ",", "action", ":", "int", ")", "->", "GymStepReturn", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "was_real_done", "=", "done", "\n", "# check current lives, make loss of life terminal,", "\n", "# then update lives to handle bonus lives", "\n", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "\n", "if", "0", "<", "lives", "<", "self", ".", "lives", ":", "\n", "# for Qbert sometimes we stay in lives == 0 condtion for a few frames", "\n", "# so its important to keep lives > 0, so that we only reset once", "\n", "# the environment advertises done.", "\n", "            ", "done", "=", "True", "\n", "", "self", ".", "lives", "=", "lives", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.EpisodicLifeEnv.reset": [[96, 112], ["atari_wrappers.EpisodicLifeEnv.env.unwrapped.ale.lives", "atari_wrappers.EpisodicLifeEnv.env.reset", "atari_wrappers.EpisodicLifeEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Calls the Gym environment reset, only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n\n        :param kwargs: Extra keywords passed to env.reset() call\n        :return: the first observation of the environment\n        \"\"\"", "\n", "if", "self", ".", "was_real_done", ":", "\n", "            ", "obs", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# no-op step to advance from terminal/lost life state", "\n", "            ", "obs", ",", "_", ",", "_", ",", "_", "=", "self", ".", "env", ".", "step", "(", "0", ")", "\n", "", "self", ".", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.MaxAndSkipEnv.__init__": [[122, 127], ["gym.Wrapper.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "env", ":", "gym", ".", "Env", ",", "skip", ":", "int", "=", "4", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "# most recent raw observations (for max pooling across time steps)", "\n", "self", ".", "_obs_buffer", "=", "np", ".", "zeros", "(", "(", "2", ",", ")", "+", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "env", ".", "observation_space", ".", "dtype", ")", "\n", "self", ".", "_skip", "=", "skip", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.MaxAndSkipEnv.step": [[128, 152], ["range", "atari_wrappers.MaxAndSkipEnv._obs_buffer.max", "atari_wrappers.MaxAndSkipEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["", "def", "step", "(", "self", ",", "action", ":", "int", ")", "->", "GymStepReturn", ":", "\n", "        ", "\"\"\"\n        Step the environment with the given action\n        Repeat action, sum reward, and max over last observations.\n\n        :param action: the action\n        :return: observation, reward, done, information\n        \"\"\"", "\n", "total_reward", "=", "0.0", "\n", "done", "=", "None", "\n", "for", "i", "in", "range", "(", "self", ".", "_skip", ")", ":", "\n", "            ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "i", "==", "self", ".", "_skip", "-", "2", ":", "\n", "                ", "self", ".", "_obs_buffer", "[", "0", "]", "=", "obs", "\n", "", "if", "i", "==", "self", ".", "_skip", "-", "1", ":", "\n", "                ", "self", ".", "_obs_buffer", "[", "1", "]", "=", "obs", "\n", "", "total_reward", "+=", "reward", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "# Note that the observation on the done=True frame", "\n", "# doesn't matter", "\n", "", "", "max_frame", "=", "self", ".", "_obs_buffer", ".", "max", "(", "axis", "=", "0", ")", "\n", "\n", "return", "max_frame", ",", "total_reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.MaxAndSkipEnv.reset": [[153, 155], ["atari_wrappers.MaxAndSkipEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "GymObs", ":", "\n", "        ", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.ClipRewardEnv.__init__": [[164, 166], ["gym.RewardWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "env", ":", "gym", ".", "Env", ")", ":", "\n", "        ", "gym", ".", "RewardWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.ClipRewardEnv.reward": [[167, 175], ["numpy.sign"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "reward", ":", "float", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Bin reward to {+1, 0, -1} by its sign.\n\n        :param reward:\n        :return:\n        \"\"\"", "\n", "return", "np", ".", "sign", "(", "reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.WarpFrame.__init__": [[187, 193], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "env", ":", "gym", ".", "Env", ",", "width", ":", "int", "=", "84", ",", "height", ":", "int", "=", "84", ")", ":", "\n", "        ", "gym", ".", "ObservationWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "(", "self", ".", "height", ",", "self", ".", "width", ",", "1", ")", ",", "dtype", "=", "env", ".", "observation_space", ".", "dtype", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.WarpFrame.observation": [[195, 205], ["cv2.cvtColor", "cv2.resize"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "frame", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        returns the current observation from a frame\n\n        :param frame: environment frame\n        :return: the observation\n        \"\"\"", "\n", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "frame", "=", "cv2", ".", "resize", "(", "frame", ",", "(", "self", ".", "width", ",", "self", ".", "height", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "\n", "return", "frame", "[", ":", ",", ":", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.atari_wrappers.AtariWrapper.__init__": [[229, 249], ["atari_wrappers.NoopResetEnv", "atari_wrappers.MaxAndSkipEnv", "atari_wrappers.WarpFrame", "gym.Wrapper.__init__", "atari_wrappers.EpisodicLifeEnv", "ClipRewardEnv.unwrapped.get_action_meanings", "atari_wrappers.FireResetEnv", "atari_wrappers.ClipRewardEnv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "env", ":", "gym", ".", "Env", ",", "\n", "noop_max", ":", "int", "=", "30", ",", "\n", "frame_skip", ":", "int", "=", "4", ",", "\n", "screen_size", ":", "int", "=", "84", ",", "\n", "terminal_on_life_loss", ":", "bool", "=", "True", ",", "\n", "clip_reward", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "env", "=", "NoopResetEnv", "(", "env", ",", "noop_max", "=", "noop_max", ")", "\n", "env", "=", "MaxAndSkipEnv", "(", "env", ",", "skip", "=", "frame_skip", ")", "\n", "if", "terminal_on_life_loss", ":", "\n", "            ", "env", "=", "EpisodicLifeEnv", "(", "env", ")", "\n", "", "if", "\"FIRE\"", "in", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ":", "\n", "            ", "env", "=", "FireResetEnv", "(", "env", ")", "\n", "", "env", "=", "WarpFrame", "(", "env", ",", "width", "=", "screen_size", ",", "height", "=", "screen_size", ")", "\n", "if", "clip_reward", ":", "\n", "            ", "env", "=", "ClipRewardEnv", "(", "env", ")", "\n", "\n", "", "super", "(", "AtariWrapper", ",", "self", ")", ".", "__init__", "(", "env", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.__init__": [[49, 133], ["stable_baselines3.common.utils.get_device", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.unwrap_vec_normalize", "gym_optimal_intrusion_response.dao.experiment.experiment_result.ExperimentResult", "gym_optimal_intrusion_response.dao.experiment.experiment_result.ExperimentResult", "time.time", "torch.utils.tensorboard.SummaryWriter", "base_class.BaseAlgorithm.tensorboard_writer.add_hparams", "isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.policies.get_policy_from_name", "isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.policies.get_policy_from_name", "base_class.maybe_make_env", "base_class.BaseAlgorithm._wrap_env", "base_class.BaseAlgorithm.attacker_agent_config.hparams_dict", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_device", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.unwrap_vec_normalize", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.get_policy_from_name", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.get_policy_from_name", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.maybe_make_env", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._wrap_env", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.hparams_dict"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "attacker_policy", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "defender_policy", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "env", ":", "Union", "[", "GymEnv", ",", "str", ",", "None", "]", ",", "\n", "policy_base", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "attacker_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", ",", "\n", "defender_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", ",", "\n", "attacker_policy_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "defender_policy_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "tensorboard_log", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ",", "\n", "attacker_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "defender_agent_config", ":", "AgentConfig", "=", "None", "\n", ")", ":", "\n", "        ", "self", ".", "attacker_agent_config", "=", "attacker_agent_config", "\n", "self", ".", "defender_agent_config", "=", "defender_agent_config", "\n", "try", ":", "\n", "            ", "self", ".", "tensorboard_writer", "=", "SummaryWriter", "(", "self", ".", "attacker_agent_config", ".", "tensorboard_dir", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_hparams", "(", "self", ".", "attacker_agent_config", ".", "hparams_dict", "(", ")", ",", "{", "}", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"error creating tensorboard writer\"", ")", "\n", "# try:", "\n", "#     self.tensorboard_writer = SummaryWriter(self.attacker_agent_config.tensorboard_dir)", "\n", "#     self.tensorboard_writer.add_hparams(self.attacker_agent_config.hparams_dict(), {})", "\n", "# except:", "\n", "#     print(\"error creating tensorboard writer\")", "\n", "\n", "", "if", "isinstance", "(", "attacker_policy", ",", "str", ")", "and", "policy_base", "is", "not", "None", ":", "\n", "            ", "self", ".", "attacker_policy_class", "=", "get_policy_from_name", "(", "policy_base", ",", "attacker_policy", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attacker_policy_class", "=", "attacker_policy", "\n", "\n", "", "if", "isinstance", "(", "defender_policy", ",", "str", ")", "and", "policy_base", "is", "not", "None", ":", "\n", "            ", "self", ".", "defender_policy_class", "=", "get_policy_from_name", "(", "policy_base", ",", "defender_policy", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "defender_policy_class", "=", "defender_policy", "\n", "\n", "", "self", ".", "device", "=", "get_device", "(", "device", ")", "\n", "self", ".", "env", "=", "None", "\n", "self", ".", "_vec_normalize_env", "=", "unwrap_vec_normalize", "(", "env", ")", "\n", "self", ".", "attacker_policy_kwargs", "=", "{", "}", "if", "attacker_policy_kwargs", "is", "None", "else", "attacker_policy_kwargs", "\n", "self", ".", "defender_policy_kwargs", "=", "{", "}", "if", "defender_policy_kwargs", "is", "None", "else", "defender_policy_kwargs", "\n", "self", ".", "attacker_observation_space", "=", "None", "\n", "self", ".", "attacker_action_space", "=", "None", "\n", "self", ".", "defender_observation_space", "=", "None", "\n", "self", ".", "defender_action_space", "=", "None", "\n", "self", ".", "n_envs", "=", "None", "\n", "self", ".", "num_timesteps", "=", "0", "\n", "# Used for updating schedules", "\n", "self", ".", "_total_timesteps", "=", "0", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "start_time", "=", "None", "\n", "self", ".", "attacker_policy", "=", "None", "\n", "self", ".", "defender_policy", "=", "None", "\n", "self", ".", "attacker_learning_rate", "=", "attacker_learning_rate", "\n", "self", ".", "defender_learning_rate", "=", "defender_learning_rate", "\n", "self", ".", "tensorboard_log", "=", "tensorboard_log", "\n", "self", ".", "_last_obs", "=", "None", "\n", "self", ".", "_last_episode_starts", "=", "None", "\n", "self", ".", "_last_original_obs", "=", "None", "\n", "self", ".", "_last_dones", "=", "None", "\n", "self", ".", "_episode_num", "=", "0", "\n", "self", ".", "_current_progress_remaining", "=", "1", "\n", "self", ".", "ep_info_buffer", "=", "None", "\n", "self", ".", "ep_success_buffer", "=", "None", "\n", "self", ".", "_n_updates", "=", "0", "\n", "self", ".", "train_mode", "=", "train_mode", "\n", "self", ".", "train_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "training_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Create and wrap the env if needed", "\n", "if", "env", "is", "not", "None", ":", "\n", "            ", "env", "=", "maybe_make_env", "(", "env", ")", "\n", "env", "=", "self", ".", "_wrap_env", "(", "env", ")", "\n", "self", ".", "attacker_observation_space", "=", "env", ".", "attacker_observation_space", "\n", "self", ".", "attacker_action_space", "=", "env", ".", "attacker_action_space", "\n", "self", ".", "defender_observation_space", "=", "env", ".", "defender_observation_space", "\n", "self", ".", "defender_action_space", "=", "env", ".", "defender_action_space", "\n", "self", ".", "n_envs", "=", "env", ".", "num_envs", "\n", "self", ".", "env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._wrap_env": [[134, 139], ["isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.DummyVecEnv"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_wrap_env", "(", "env", ":", "GymEnv", ")", "->", "VecEnv", ":", "\n", "        ", "if", "not", "isinstance", "(", "env", ",", "VecEnv", ")", ":", "\n", "            ", "env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "env", "]", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._setup_model": [[140, 143], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_setup_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Create networks, buffer and optimizers.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._update_current_progress_remaining": [[144, 152], ["float", "float"], "methods", ["None"], ["", "def", "_update_current_progress_remaining", "(", "self", ",", "num_timesteps", ":", "int", ",", "total_timesteps", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Compute current progress remaining (starts from 1 and ends to 0)\n\n        :param num_timesteps: current number of timesteps\n        :param total_timesteps:\n        \"\"\"", "\n", "self", ".", "_current_progress_remaining", "=", "1.0", "-", "float", "(", "num_timesteps", ")", "/", "float", "(", "total_timesteps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._excluded_save_params": [[153, 169], ["None"], "methods", ["None"], ["", "def", "_excluded_save_params", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Returns the names of the parameters that should be excluded from being\n        saved by pickling. E.g. replay buffers are skipped by default\n        as they take up a lot of space. PyTorch variables should be excluded\n        with this so they can be stored with ``th.save``.\n\n        :return: List of parameters that should be excluded from being saved with pickle.\n        \"\"\"", "\n", "return", "[", "\n", "\"policy\"", ",", "\n", "\"device\"", ",", "\n", "\"env\"", ",", "\n", "\"replay_buffer\"", ",", "\n", "\"rollout_buffer\"", ",", "\n", "\"_vec_normalize_env\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._get_torch_save_params": [[171, 174], ["None"], "methods", ["None"], ["", "def", "_get_torch_save_params", "(", "self", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "state_dicts", "=", "[", "\"policy\"", "]", "\n", "return", "state_dicts", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._setup_learn": [[175, 208], ["time.time", "collections.deque", "collections.deque", "base_class.BaseAlgorithm.env.reset", "numpy.ones", "base_class.BaseAlgorithm._vec_normalize_env.get_original_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.get_original_obs"], ["", "def", "_setup_learn", "(", "\n", "self", ",", "\n", "total_timesteps", ":", "int", ",", "\n", "eval_freq", ":", "int", "=", "10000", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", "tb_log_name", ":", "str", "=", "\"run\"", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "ep_info_buffer", "is", "None", "or", "reset_num_timesteps", ":", "\n", "# Initialize buffers if they don't exist, or reinitialize if resetting counters", "\n", "            ", "self", ".", "ep_info_buffer", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "self", ".", "ep_success_buffer", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "\n", "", "if", "reset_num_timesteps", ":", "\n", "            ", "self", ".", "num_timesteps", "=", "0", "\n", "self", ".", "_episode_num", "=", "0", "\n", "", "else", ":", "\n", "# Make sure training timesteps are ahead of the internal counter", "\n", "            ", "total_timesteps", "+=", "self", ".", "num_timesteps", "\n", "", "self", ".", "_total_timesteps", "=", "total_timesteps", "\n", "\n", "# Avoid resetting the environment when calling ``.learn()`` consecutive times", "\n", "if", "reset_num_timesteps", "or", "self", ".", "_last_obs", "is", "None", ":", "\n", "            ", "self", ".", "_last_obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "_last_episode_starts", "=", "np", ".", "ones", "(", "(", "self", ".", "env", ".", "num_envs", ",", ")", ",", "dtype", "=", "bool", ")", "\n", "# Retrieve unnormalized observation for saving into the buffer", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "                ", "self", ".", "_last_original_obs", "=", "self", ".", "_vec_normalize_env", ".", "get_original_obs", "(", ")", "\n", "\n", "", "", "return", "total_timesteps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.get_env": [[209, 216], ["None"], "methods", ["None"], ["", "def", "get_env", "(", "self", ")", "->", "Optional", "[", "VecEnv", "]", ":", "\n", "        ", "\"\"\"\n        Returns the current environment (can be None if not defined).\n\n        :return: The current environment\n        \"\"\"", "\n", "return", "self", ".", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.set_env": [[217, 221], ["base_class.BaseAlgorithm._wrap_env"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._wrap_env"], ["", "def", "set_env", "(", "self", ",", "env", ":", "GymEnv", ")", "->", "None", ":", "\n", "        ", "env", "=", "self", ".", "_wrap_env", "(", "env", ")", "\n", "self", ".", "n_envs", "=", "env", ".", "num_envs", "\n", "self", ".", "env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.learn": [[222, 245], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "learn", "(", "\n", "self", ",", "\n", "total_timesteps", ":", "int", ",", "\n", "log_interval", ":", "int", "=", "100", ",", "\n", "tb_log_name", ":", "str", "=", "\"run\"", ",", "\n", "eval_freq", ":", "int", "=", "-", "1", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "eval_log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", ")", "->", "\"BaseAlgorithm\"", ":", "\n", "        ", "\"\"\"\n        Return a trained model.\n\n        :param total_timesteps: The total number of samples (env steps) to train on\n        :param log_interval: The number of timesteps before logging.\n        :param tb_log_name: the name of the run for TensorBoard logging\n        :param eval_freq: Evaluate the agent every ``eval_freq`` timesteps (this may vary a little)\n        :param n_eval_episodes: Number of episode to evaluate the agent\n        :param eval_log_path: Path to a folder where the evaluations will be saved\n        :param reset_num_timesteps: whether or not to reset the current timestep number (used in logging)\n        :return: the trained model\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.predict": [[246, 259], ["base_class.BaseAlgorithm.attacker_policy.predict", "base_class.BaseAlgorithm.defender_policy.predict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.predict", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.predict"], ["", "def", "predict", "(", "\n", "self", ",", "\n", "observation", ":", "np", ".", "ndarray", ",", "\n", "state", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "mask", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "deterministic", ":", "bool", "=", "False", ",", "\n", "attacker", ":", "bool", "=", "True", ",", "\n", "env", "=", "None", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "Optional", "[", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "if", "attacker", ":", "\n", "            ", "return", "self", ".", "attacker_policy", ".", "predict", "(", "observation", ",", "state", ",", "mask", ",", "deterministic", ",", "attacker", "=", "attacker", ",", "env", "=", "env", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "defender_policy", ".", "predict", "(", "observation", ",", "state", ",", "mask", ",", "deterministic", ",", "attacker", "=", "attacker", ",", "env", "=", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.set_random_seed": [[260, 273], ["stable_baselines3.common.utils.set_random_seed", "base_class.BaseAlgorithm.attacker_action_space.seed", "base_class.BaseAlgorithm.env.seed", "torch.device"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.set_random_seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.device"], ["", "", "def", "set_random_seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set the seed of the pseudo-random generators\n        (python, numpy, pytorch, gym, action_space)\n\n        :param seed:\n        \"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "return", "\n", "", "set_random_seed", "(", "seed", ",", "using_cuda", "=", "self", ".", "device", ".", "type", "==", "th", ".", "device", "(", "\"cuda\"", ")", ".", "type", ")", "\n", "self", ".", "attacker_action_space", ".", "seed", "(", "seed", ")", "\n", "if", "self", ".", "env", "is", "not", "None", ":", "\n", "            ", "self", ".", "env", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.set_parameters": [[274, 339], ["isinstance", "set", "set", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.load_from_zip_file", "isinstance", "set.add", "ValueError", "base_class.BaseAlgorithm._get_torch_save_params", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_getattr", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_getattr.load_state_dict", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_getattr.load_state_dict", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.load_from_zip_file", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._get_torch_save_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_getattr"], ["", "", "def", "set_parameters", "(", "\n", "self", ",", "\n", "load_path_or_dict", ":", "Union", "[", "str", ",", "Dict", "[", "str", ",", "Dict", "]", "]", ",", "\n", "exact_match", ":", "bool", "=", "True", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Load parameters from a given zip-file or a nested dictionary containing parameters for\n        different modules (see ``get_parameters``).\n\n        :param load_path_or_iter: Location of the saved data (path or file-like, see ``save``), or a nested\n            dictionary containing nn.Module parameters used by the policy. The dictionary maps\n            object names to a state-dictionary returned by ``torch.nn.Module.state_dict()``.\n        :param exact_match: If True, the given parameters should include parameters for each\n            module and each of their parameters, otherwise raises an Exception. If set to False, this\n            can be used to update only specific parameters.\n        :param device: Device on which the code should run.\n        \"\"\"", "\n", "params", "=", "None", "\n", "if", "isinstance", "(", "load_path_or_dict", ",", "dict", ")", ":", "\n", "            ", "params", "=", "load_path_or_dict", "\n", "", "else", ":", "\n", "            ", "_", ",", "params", ",", "_", "=", "load_from_zip_file", "(", "load_path_or_dict", ",", "device", "=", "device", ")", "\n", "\n", "# Keep track which objects were updated.", "\n", "# `_get_torch_save_params` returns [params, other_pytorch_variables].", "\n", "# We are only interested in former here.", "\n", "", "objects_needing_update", "=", "set", "(", "self", ".", "_get_torch_save_params", "(", ")", "[", "0", "]", ")", "\n", "updated_objects", "=", "set", "(", ")", "\n", "\n", "for", "name", "in", "params", ":", "\n", "            ", "attr", "=", "None", "\n", "try", ":", "\n", "                ", "attr", "=", "recursive_getattr", "(", "self", ",", "name", ")", "\n", "", "except", "Exception", ":", "\n", "# What errors recursive_getattr could throw? KeyError, but", "\n", "# possible something else too (e.g. if key is an int?).", "\n", "# Catch anything for now.", "\n", "                ", "raise", "ValueError", "(", "f\"Key {name} is an invalid object name.\"", ")", "\n", "\n", "", "if", "isinstance", "(", "attr", ",", "th", ".", "optim", ".", "Optimizer", ")", ":", "\n", "# Optimizers do not support \"strict\" keyword...", "\n", "# Seems like they will just replace the whole", "\n", "# optimizer state with the given one.", "\n", "# On top of this, optimizer state-dict", "\n", "# seems to change (e.g. first ``optim.step()``),", "\n", "# which makes comparing state dictionary keys", "\n", "# invalid (there is also a nesting of dictionaries", "\n", "# with lists with dictionaries with ...), adding to the", "\n", "# mess.", "\n", "#", "\n", "# TL;DR: We might not be able to reliably say", "\n", "# if given state-dict is missing keys.", "\n", "#", "\n", "# Solution: Just load the state-dict as is, and trust", "\n", "# the user has provided a sensible state dictionary.", "\n", "                ", "attr", ".", "load_state_dict", "(", "params", "[", "name", "]", ")", "\n", "", "else", ":", "\n", "# Assume attr is th.nn.Module", "\n", "                ", "attr", ".", "load_state_dict", "(", "params", "[", "name", "]", ",", "strict", "=", "exact_match", ")", "\n", "", "updated_objects", ".", "add", "(", "name", ")", "\n", "\n", "", "if", "exact_match", "and", "updated_objects", "!=", "objects_needing_update", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Names of parameters do not match agents' parameters: \"", "\n", "f\"expected {objects_needing_update}, got {updated_objects}\"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.load": [[342, 413], ["gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.load_from_zip_file", "cls", "cls.__dict__.update", "cls.__dict__.update", "cls._setup_model", "cls.set_parameters", "ValueError", "cls._wrap_env", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_setattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.load_from_zip_file", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO._setup_model", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.set_parameters", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._wrap_env", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_setattr"], ["", "", "@", "classmethod", "\n", "def", "load", "(", "\n", "cls", ",", "\n", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "\n", "env", ":", "Optional", "[", "GymEnv", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", "custom_objects", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "\"BaseAlgorithm\"", ":", "\n", "        ", "\"\"\"\n        Load the model from a zip-file\n\n        :param path: path to the file (or a file-like) where to\n            load the agent from\n        :param env: the new environment to run the loaded model on\n            (can be None if you only need prediction from a trained model) has priority over any saved environment\n        :param device: Device on which the code should run.\n        :param custom_objects: Dictionary of objects to replace\n            upon loading. If a variable is present in this dictionary as a\n            key, it will not be deserialized and the corresponding item\n            will be used instead. Similar to custom_objects in\n            ``keras.models.load_model``. Useful when you have an object in\n            file that can not be deserialized.\n        :param kwargs: extra arguments to change the model when loading\n        \"\"\"", "\n", "data", ",", "params", ",", "pytorch_variables", "=", "load_from_zip_file", "(", "path", ",", "device", "=", "device", ",", "custom_objects", "=", "custom_objects", ")", "\n", "\n", "# Remove stored device information and replace with ours", "\n", "if", "\"policy_kwargs\"", "in", "data", ":", "\n", "            ", "if", "\"device\"", "in", "data", "[", "\"policy_kwargs\"", "]", ":", "\n", "                ", "del", "data", "[", "\"policy_kwargs\"", "]", "[", "\"device\"", "]", "\n", "\n", "", "", "if", "\"policy_kwargs\"", "in", "kwargs", "and", "kwargs", "[", "\"policy_kwargs\"", "]", "!=", "data", "[", "\"policy_kwargs\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The specified policy kwargs do not equal the stored policy kwargs.\"", "\n", "f\"Stored kwargs: {data['policy_kwargs']}, specified kwargs: {kwargs['policy_kwargs']}\"", "\n", ")", "\n", "\n", "", "if", "env", "is", "not", "None", ":", "\n", "# Wrap first if needed", "\n", "            ", "env", "=", "cls", ".", "_wrap_env", "(", "env", ")", "\n", "", "else", ":", "\n", "# Use stored env, if one exists. If not, continue as is (can be used for predict)", "\n", "            ", "if", "\"env\"", "in", "data", ":", "\n", "                ", "env", "=", "data", "[", "\"env\"", "]", "\n", "\n", "# noinspection PyArgumentList", "\n", "", "", "model", "=", "cls", "(", "# pytype: disable=not-instantiable,wrong-keyword-args", "\n", "attacker_policy", "=", "data", "[", "\"attacker_policy_class\"", "]", ",", "\n", "defender_policy", "=", "data", "[", "\"defender_policy_class\"", "]", ",", "\n", "env", "=", "env", ",", "\n", "device", "=", "device", ",", "\n", "_init_setup_model", "=", "False", ",", "# pytype: disable=not-instantiable,wrong-keyword-args", "\n", ")", "\n", "\n", "# load parameters", "\n", "model", ".", "__dict__", ".", "update", "(", "data", ")", "\n", "model", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "model", ".", "_setup_model", "(", ")", "\n", "\n", "# put state_dicts back in place", "\n", "model", ".", "set_parameters", "(", "params", ",", "exact_match", "=", "True", ",", "device", "=", "device", ")", "\n", "\n", "# put other pytorch variables back in place", "\n", "if", "pytorch_variables", "is", "not", "None", ":", "\n", "            ", "for", "name", "in", "pytorch_variables", ":", "\n", "# Set the data attribute directly to avoid issue when using optimizers", "\n", "# See https://github.com/DLR-RM/stable-baselines3/issues/391", "\n", "                ", "recursive_setattr", "(", "model", ",", "name", "+", "\".data\"", ",", "pytorch_variables", "[", "name", "]", ".", "data", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.get_parameters": [[414, 428], ["base_class.BaseAlgorithm._get_torch_save_params", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_getattr", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_getattr.state_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._get_torch_save_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_getattr"], ["", "def", "get_parameters", "(", "self", ")", "->", "Dict", "[", "str", ",", "Dict", "]", ":", "\n", "        ", "\"\"\"\n        Return the parameters of the agent. This includes parameters from different networks, e.g.\n        critics (value functions) and policies (pi functions).\n\n        :return: Mapping of from names of the objects to PyTorch state-dicts.\n        \"\"\"", "\n", "state_dicts_names", ",", "_", "=", "self", ".", "_get_torch_save_params", "(", ")", "\n", "params", "=", "{", "}", "\n", "for", "name", "in", "state_dicts_names", ":", "\n", "            ", "attr", "=", "recursive_getattr", "(", "self", ",", "name", ")", "\n", "# Retrieve state dict", "\n", "params", "[", "name", "]", "=", "attr", ".", "state_dict", "(", ")", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.save": [[429, 478], ["base_class.BaseAlgorithm.__dict__.copy", "set().union", "base_class.BaseAlgorithm._get_torch_save_params", "base_class.BaseAlgorithm.get_parameters", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.save_to_zip_file", "base_class.BaseAlgorithm._excluded_save_params", "exclude.difference.difference.difference", "exclude.difference.difference.add", "base_class.BaseAlgorithm.pop", "set", "torch_var.split", "gym_optimal_intrusion_response.agents.openai_baselines.common.save_util.recursive_getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._get_torch_save_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.get_parameters", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.save_to_zip_file", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm._excluded_save_params", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.save_util.recursive_getattr"], ["", "def", "save", "(", "\n", "self", ",", "\n", "path", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", ",", "io", ".", "BufferedIOBase", "]", ",", "\n", "exclude", ":", "Optional", "[", "Iterable", "[", "str", "]", "]", "=", "None", ",", "\n", "include", ":", "Optional", "[", "Iterable", "[", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save all the attributes of the object and the model parameters in a zip-file.\n\n        :param path: path to the file where the rl agent should be saved\n        :param exclude: name of parameters that should be excluded in addition to the default ones\n        :param include: name of parameters that might be excluded but should be included anyway\n        \"\"\"", "\n", "# Copy parameter list so we don't mutate the original dict", "\n", "data", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "\n", "# Exclude is union of specified parameters (if any) and standard exclusions", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "]", "\n", "", "exclude", "=", "set", "(", "exclude", ")", ".", "union", "(", "self", ".", "_excluded_save_params", "(", ")", ")", "\n", "\n", "# Do not exclude params if they are specifically included", "\n", "if", "include", "is", "not", "None", ":", "\n", "            ", "exclude", "=", "exclude", ".", "difference", "(", "include", ")", "\n", "\n", "", "state_dicts_names", ",", "torch_variable_names", "=", "self", ".", "_get_torch_save_params", "(", ")", "\n", "all_pytorch_variables", "=", "state_dicts_names", "+", "torch_variable_names", "\n", "for", "torch_var", "in", "all_pytorch_variables", ":", "\n", "# We need to get only the name of the top most module as we'll remove that", "\n", "            ", "var_name", "=", "torch_var", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "# Any params that are in the save vars must not be saved by data", "\n", "exclude", ".", "add", "(", "var_name", ")", "\n", "\n", "# Remove parameter entries of parameters which are to be excluded", "\n", "", "for", "param_name", "in", "exclude", ":", "\n", "            ", "data", ".", "pop", "(", "param_name", ",", "None", ")", "\n", "\n", "# Build dict of torch variables", "\n", "", "pytorch_variables", "=", "None", "\n", "if", "torch_variable_names", "is", "not", "None", ":", "\n", "            ", "pytorch_variables", "=", "{", "}", "\n", "for", "name", "in", "torch_variable_names", ":", "\n", "                ", "attr", "=", "recursive_getattr", "(", "self", ",", "name", ")", "\n", "pytorch_variables", "[", "name", "]", "=", "attr", "\n", "\n", "# Build dict of state_dicts", "\n", "", "", "params_to_save", "=", "self", ".", "get_parameters", "(", ")", "\n", "\n", "save_to_zip_file", "(", "path", ",", "data", "=", "data", ",", "params", "=", "params_to_save", ",", "pytorch_variables", "=", "pytorch_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.save_model": [[480, 506], ["str", "time.time", "base_class.BaseAlgorithm.attacker_agent_config.logger.info", "base_class.BaseAlgorithm.defender_agent_config.logger.info", "base_class.BaseAlgorithm.save", "base_class.BaseAlgorithm.attacker_agent_config.logger.warning", "print", "base_class.BaseAlgorithm.defender_agent_config.logger.warning", "print", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save"], ["", "def", "save_model", "(", "self", ",", "iteration", ":", "int", "=", "1", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves the PyTorch Model Weights\n\n        :return: None\n        \"\"\"", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "save_dir", "=", "self", ".", "attacker_agent_config", ".", "save_dir", "\n", "seed", "=", "self", ".", "attacker_agent_config", ".", "random_seed", "\n", "", "else", ":", "\n", "            ", "save_dir", "=", "self", ".", "defender_agent_config", ".", "save_dir", "\n", "seed", "=", "self", ".", "defender_agent_config", ".", "random_seed", "\n", "\n", "", "if", "save_dir", "is", "not", "None", ":", "\n", "            ", "path", "=", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_\"", "+", "str", "(", "seed", ")", "+", "\"_\"", "+", "str", "(", "iteration", ")", "+", "\"_policy_network.zip\"", "\n", "self", ".", "attacker_agent_config", ".", "logger", ".", "info", "(", "\"Saving policy-network to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "self", ".", "defender_agent_config", ".", "logger", ".", "info", "(", "\"Saving policy-network to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "self", ".", "save", "(", "path", ",", "exclude", "=", "[", "\"tensorboard_writer\"", ",", "\"eval_env\"", ",", "\"env_2\"", ",", "\"env\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "attacker_agent_config", "is", "not", "None", ":", "\n", "                ", "self", ".", "attacker_agent_config", ".", "logger", ".", "warning", "(", "\"Save path not defined, not saving policy-networks to disk\"", ")", "\n", "print", "(", "\"Save path not defined, not saving policy-networks to disk\"", ")", "\n", "", "if", "self", ".", "defender_agent_config", "is", "not", "None", ":", "\n", "                ", "self", ".", "defender_agent_config", ".", "logger", ".", "warning", "(", "\"Save path not defined, not saving policy-networks to disk\"", ")", "\n", "print", "(", "\"Save path not defined, not saving policy-networks to disk\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.log_metrics_attacker": [[508, 521], ["gym_optimal_intrusion_response.agents.util.log_util.LogUtil.log_metrics_attacker"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.log_metrics_attacker"], ["", "", "", "def", "log_metrics_attacker", "(", "self", ",", "train_log_dto", ":", "TrainAgentLogDTO", ",", "eps", ":", "float", "=", "None", ",", "eval", ":", "bool", "=", "False", ")", "->", "TrainAgentLogDTO", ":", "\n", "        ", "\"\"\"\n        Logs average metrics for the last <self.config.log_frequency> episodes\n\n        :param train_log_dto: DTO with the information to log\n        :param eps: machine eps\n        :param eval: flag whether it is evaluation or not\n        :return: the updated train agent log dto\n        \"\"\"", "\n", "return", "LogUtil", ".", "log_metrics_attacker", "(", "train_log_dto", "=", "train_log_dto", ",", "eps", "=", "eps", ",", "eval", "=", "eval", ",", "\n", "attacker_agent_config", "=", "self", ".", "attacker_agent_config", ",", "\n", "tensorboard_writer", "=", "self", ".", "tensorboard_writer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.log_metrics_defender": [[522, 535], ["gym_optimal_intrusion_response.agents.util.log_util.LogUtil.log_metrics_defender"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.log_metrics_defender"], ["", "def", "log_metrics_defender", "(", "self", ",", "train_log_dto", ":", "TrainAgentLogDTO", ",", "eps", ":", "float", "=", "None", ",", "eval", ":", "bool", "=", "False", ")", "->", "TrainAgentLogDTO", ":", "\n", "        ", "\"\"\"\n        Logs average metrics for the last <self.config.log_frequency> episodes\n\n        :param train_log_dto: DTO with the information to log\n        :param eps: machine eps\n        :param eval: flag whether it is evaluation or not\n        :return: the updated train agent log dto\n        \"\"\"", "\n", "return", "LogUtil", ".", "log_metrics_defender", "(", "train_log_dto", "=", "train_log_dto", ",", "eps", "=", "eps", ",", "eval", "=", "eval", ",", "\n", "defender_agent_config", "=", "self", ".", "defender_agent_config", ",", "\n", "tensorboard_writer", "=", "self", ".", "tensorboard_writer", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.maybe_make_env": [[36, 45], ["isinstance", "gym.make"], "function", ["None"], ["def", "maybe_make_env", "(", "env", ":", "Union", "[", "GymEnv", ",", "str", ",", "None", "]", ")", "->", "Optional", "[", "GymEnv", "]", ":", "\n", "    ", "\"\"\"If env is a string, make the environment; otherwise, return env.\n\n    :param env: The environment to learn from.\n    :return A Gym (vector) environment.\n    \"\"\"", "\n", "if", "isinstance", "(", "env", ",", "str", ")", ":", "\n", "        ", "env", "=", "gym", ".", "make", "(", "env", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.__init__": [[20, 37], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "BaseCallback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# The RL model", "\n", "self", ".", "model", "=", "None", "\n", "# An alias for self.model.get_env(), the environment used for training", "\n", "self", ".", "training_env", "=", "None", "\n", "# Number of time the callback was called", "\n", "self", ".", "n_calls", "=", "0", "# type: int", "\n", "# n_envs * n times env.step() was called", "\n", "self", ".", "num_timesteps", "=", "0", "# type: int", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "locals", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "self", ".", "globals", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "self", ".", "logger", "=", "None", "\n", "# Sometimes, for event callback, it is useful", "\n", "# to have access to the parent object", "\n", "self", ".", "parent", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.init_callback": [[39, 48], ["model.get_env", "callbacks.BaseCallback._init_callback"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.get_env", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnMaxEpisodes._init_callback"], ["", "def", "init_callback", "(", "self", ",", "model", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initialize the callback by saving references to the\n        RL model and the training environment for convenience.\n        \"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "training_env", "=", "model", ".", "get_env", "(", ")", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "_init_callback", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback._init_callback": [[49, 51], ["None"], "methods", ["None"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_start": [[52, 57], ["callbacks.BaseCallback._on_training_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_training_start"], ["", "def", "on_training_start", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ",", "globals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "# Those are reference and will be updated automatically", "\n", "        ", "self", ".", "locals", "=", "locals_", "\n", "self", ".", "globals", "=", "globals_", "\n", "self", ".", "_on_training_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback._on_training_start": [[58, 60], ["None"], "methods", ["None"], ["", "def", "_on_training_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_rollout_start": [[61, 63], ["callbacks.BaseCallback._on_rollout_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_rollout_start"], ["", "def", "on_rollout_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_on_rollout_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback._on_rollout_start": [[64, 66], ["None"], "methods", ["None"], ["", "def", "_on_rollout_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback._on_step": [[67, 73], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        :return: If the callback returns False, training is aborted early.\n        \"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_step": [[74, 88], ["callbacks.BaseCallback._on_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnMaxEpisodes._on_step"], ["", "def", "on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        This method will be called by the model after each call to ``env.step()``.\n\n        For child callback (of an ``EventCallback``), this will be called\n        when the event is triggered.\n\n        :return: If the callback returns False, training is aborted early.\n        \"\"\"", "\n", "self", ".", "n_calls", "+=", "1", "\n", "# timesteps start at zero", "\n", "self", ".", "num_timesteps", "=", "self", ".", "model", ".", "num_timesteps", "\n", "\n", "return", "self", ".", "_on_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_end": [[89, 91], ["callbacks.BaseCallback._on_training_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_training_end"], ["", "def", "on_training_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_on_training_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback._on_training_end": [[92, 94], ["None"], "methods", ["None"], ["", "def", "_on_training_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_rollout_end": [[95, 97], ["callbacks.BaseCallback._on_rollout_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_rollout_end"], ["", "def", "on_rollout_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_on_rollout_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback._on_rollout_end": [[98, 100], ["None"], "methods", ["None"], ["", "def", "_on_rollout_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.update_locals": [[101, 109], ["callbacks.BaseCallback.locals.update", "callbacks.BaseCallback.update_child_locals"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EvalCallback.update_child_locals"], ["", "def", "update_locals", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the references to the local variables.\n\n        :param locals_: the local variables during rollout collection\n        \"\"\"", "\n", "self", ".", "locals", ".", "update", "(", "locals_", ")", "\n", "self", ".", "update_child_locals", "(", "locals_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.update_child_locals": [[110, 117], ["None"], "methods", ["None"], ["", "def", "update_child_locals", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the references to the local variables on sub callbacks.\n\n        :param locals_: the local variables during rollout collection\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback.__init__": [[128, 134], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "callback", ":", "Optional", "[", "BaseCallback", "]", "=", "None", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "EventCallback", ",", "self", ")", ".", "__init__", "(", "verbose", "=", "verbose", ")", "\n", "self", ".", "callback", "=", "callback", "\n", "# Give access to the parent", "\n", "if", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "parent", "=", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback.init_callback": [[135, 139], ["callbacks.BaseCallback.init_callback", "callbacks.EventCallback.callback.init_callback"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback.init_callback", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback.init_callback"], ["", "", "def", "init_callback", "(", "self", ",", "model", ")", "->", "None", ":", "\n", "        ", "super", "(", "EventCallback", ",", "self", ")", ".", "init_callback", "(", "model", ")", "\n", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "init_callback", "(", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback._on_training_start": [[140, 143], ["callbacks.EventCallback.callback.on_training_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_start"], ["", "", "def", "_on_training_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "on_training_start", "(", "self", ".", "locals", ",", "self", ".", "globals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback._on_event": [[144, 148], ["callbacks.EventCallback.callback.on_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_step"], ["", "", "def", "_on_event", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "callback", ".", "on_step", "(", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback._on_step": [[149, 151], ["None"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback.update_child_locals": [[152, 160], ["callbacks.EventCallback.callback.update_locals"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.update_locals"], ["", "def", "update_child_locals", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the references to the local variables.\n\n        :param locals_: the local variables during rollout collection\n        \"\"\"", "\n", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "update_locals", "(", "locals_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList.__init__": [[170, 174], ["callbacks.BaseCallback.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "callbacks", ":", "List", "[", "BaseCallback", "]", ")", ":", "\n", "        ", "super", "(", "CallbackList", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "callbacks", ",", "list", ")", "\n", "self", ".", "callbacks", "=", "callbacks", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._init_callback": [[175, 178], ["callback.init_callback"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback.init_callback"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "init_callback", "(", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_training_start": [[179, 182], ["callback.on_training_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_start"], ["", "", "def", "_on_training_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_training_start", "(", "self", ".", "locals", ",", "self", ".", "globals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_rollout_start": [[183, 186], ["callback.on_rollout_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_rollout_start"], ["", "", "def", "_on_rollout_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_rollout_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_step": [[187, 193], ["callback.on_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_step"], ["", "", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "continue_training", "=", "True", "\n", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "# Return False (stop training) if at least one callback returns False", "\n", "            ", "continue_training", "=", "callback", ".", "on_step", "(", ")", "and", "continue_training", "\n", "", "return", "continue_training", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_rollout_end": [[194, 197], ["callback.on_rollout_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_rollout_end"], ["", "def", "_on_rollout_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_rollout_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList._on_training_end": [[198, 201], ["callback.on_training_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.on_training_end"], ["", "", "def", "_on_training_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_training_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CallbackList.update_child_locals": [[202, 210], ["callback.update_locals"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.update_locals"], ["", "", "def", "update_child_locals", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the references to the local variables.\n\n        :param locals_: the local variables during rollout collection\n        \"\"\"", "\n", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "update_locals", "(", "locals_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CheckpointCallback.__init__": [[222, 227], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "save_freq", ":", "int", ",", "save_path", ":", "str", ",", "name_prefix", ":", "str", "=", "\"rl_model\"", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "CheckpointCallback", ",", "self", ")", ".", "__init__", "(", "verbose", ")", "\n", "self", ".", "save_freq", "=", "save_freq", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "name_prefix", "=", "name_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CheckpointCallback._init_callback": [[228, 232], ["os.makedirs"], "methods", ["None"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "# Create folder if needed", "\n", "        ", "if", "self", ".", "save_path", "is", "not", "None", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.CheckpointCallback._on_step": [[233, 240], ["os.path.join", "callbacks.CheckpointCallback.model.save", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save"], ["", "", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "n_calls", "%", "self", ".", "save_freq", "==", "0", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_path", ",", "f\"{self.name_prefix}_{self.num_timesteps}_steps\"", ")", "\n", "self", ".", "model", ".", "save", "(", "path", ")", "\n", "if", "self", ".", "verbose", ">", "1", ":", "\n", "                ", "print", "(", "f\"Saving model checkpoint to {path}\"", ")", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.ConvertCallback.__init__": [[250, 253], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "callback", ":", "Callable", "[", "[", "Dict", "[", "str", ",", "Any", "]", ",", "Dict", "[", "str", ",", "Any", "]", "]", ",", "bool", "]", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "ConvertCallback", ",", "self", ")", ".", "__init__", "(", "verbose", ")", "\n", "self", ".", "callback", "=", "callback", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.ConvertCallback._on_step": [[254, 258], ["callbacks.ConvertCallback.callback"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "callback", "(", "self", ".", "locals", ",", "self", ".", "globals", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EvalCallback.__init__": [[281, 322], ["callbacks.EventCallback.__init__", "isinstance", "isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.DummyVecEnv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "eval_env", ":", "Union", "[", "gym", ".", "Env", ",", "VecEnv", "]", ",", "\n", "callback_on_new_best", ":", "Optional", "[", "BaseCallback", "]", "=", "None", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "eval_freq", ":", "int", "=", "10000", ",", "\n", "log_path", ":", "str", "=", "None", ",", "\n", "best_model_save_path", ":", "str", "=", "None", ",", "\n", "deterministic", ":", "bool", "=", "True", ",", "\n", "render", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", "warn", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", "EvalCallback", ",", "self", ")", ".", "__init__", "(", "callback_on_new_best", ",", "verbose", "=", "verbose", ")", "\n", "self", ".", "n_eval_episodes", "=", "n_eval_episodes", "\n", "self", ".", "eval_freq", "=", "eval_freq", "\n", "self", ".", "best_mean_reward", "=", "-", "np", ".", "inf", "\n", "self", ".", "last_mean_reward", "=", "-", "np", ".", "inf", "\n", "self", ".", "deterministic", "=", "deterministic", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "warn", "=", "warn", "\n", "\n", "# Convert to VecEnv for consistency", "\n", "if", "not", "isinstance", "(", "eval_env", ",", "VecEnv", ")", ":", "\n", "            ", "eval_env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "eval_env", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "eval_env", ",", "VecEnv", ")", ":", "\n", "            ", "assert", "eval_env", ".", "num_envs", "==", "1", ",", "\"You must pass only one environment for evaluation\"", "\n", "\n", "", "self", ".", "eval_env", "=", "eval_env", "\n", "self", ".", "best_model_save_path", "=", "best_model_save_path", "\n", "# Logs will be written in ``evaluations.npz``", "\n", "if", "log_path", "is", "not", "None", ":", "\n", "            ", "log_path", "=", "os", ".", "path", ".", "join", "(", "log_path", ",", "\"evaluations\"", ")", "\n", "", "self", ".", "log_path", "=", "log_path", "\n", "self", ".", "evaluations_results", "=", "[", "]", "\n", "self", ".", "evaluations_timesteps", "=", "[", "]", "\n", "self", ".", "evaluations_length", "=", "[", "]", "\n", "# For computing success rate", "\n", "self", ".", "_is_success_buffer", "=", "[", "]", "\n", "self", ".", "evaluations_successes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EvalCallback._init_callback": [[323, 333], ["isinstance", "warnings.warn", "os.makedirs", "os.makedirs", "type", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "# Does not work in some corner cases, where the wrapper is not the same", "\n", "        ", "if", "not", "isinstance", "(", "self", ".", "training_env", ",", "type", "(", "self", ".", "eval_env", ")", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Training and eval env are not of the same type\"", "f\"{self.training_env} != {self.eval_env}\"", ")", "\n", "\n", "# Create folders if needed", "\n", "", "if", "self", ".", "best_model_save_path", "is", "not", "None", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "best_model_save_path", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "self", ".", "log_path", "is", "not", "None", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "log_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EvalCallback._log_success_callback": [[334, 352], ["isinstance", "info.get", "callbacks.EvalCallback._is_success_buffer.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get"], ["", "", "def", "_log_success_callback", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ",", "globals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Callback passed to the  ``evaluate_policy`` function\n        in order to log the success rate (when applicable),\n        for instance when using HER.\n\n        :param locals_:\n        :param globals_:\n        \"\"\"", "\n", "info", "=", "locals_", "[", "\"info\"", "]", "\n", "# VecEnv: unpack", "\n", "if", "not", "isinstance", "(", "info", ",", "dict", ")", ":", "\n", "            ", "info", "=", "info", "[", "0", "]", "\n", "\n", "", "if", "locals_", "[", "\"done\"", "]", ":", "\n", "            ", "maybe_is_success", "=", "info", ".", "get", "(", "\"is_success\"", ")", "\n", "if", "maybe_is_success", "is", "not", "None", ":", "\n", "                ", "self", ".", "_is_success_buffer", ".", "append", "(", "maybe_is_success", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EvalCallback._on_step": [[353, 420], ["None"], "methods", ["None"], ["", "", "", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "\n", "# if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:", "\n", "#     # Sync training and eval env if there is VecNormalize", "\n", "#     sync_envs_normalization(self.training_env, self.eval_env)", "\n", "#", "\n", "#     # Reset success rate buffer", "\n", "#     self._is_success_buffer = []", "\n", "#", "\n", "#     episode_rewards, episode_lengths = evaluate_policy(", "\n", "#         self.model,", "\n", "#         self.eval_env,", "\n", "#         n_eval_episodes=self.n_eval_episodes,", "\n", "#         render=self.render,", "\n", "#         deterministic=self.deterministic,", "\n", "#         return_episode_rewards=True,", "\n", "#         warn=self.warn,", "\n", "#         callback=self._log_success_callback,", "\n", "#     )", "\n", "#", "\n", "#     if self.log_path is not None:", "\n", "#         self.evaluations_timesteps.append(self.num_timesteps)", "\n", "#         self.evaluations_results.append(episode_rewards)", "\n", "#         self.evaluations_length.append(episode_lengths)", "\n", "#", "\n", "#         kwargs = {}", "\n", "#         # Save success log if present", "\n", "#         if len(self._is_success_buffer) > 0:", "\n", "#             self.evaluations_successes.append(self._is_success_buffer)", "\n", "#             kwargs = dict(successes=self.evaluations_successes)", "\n", "#", "\n", "#         np.savez(", "\n", "#             self.log_path,", "\n", "#             timesteps=self.evaluations_timesteps,", "\n", "#             results=self.evaluations_results,", "\n", "#             ep_lengths=self.evaluations_length,", "\n", "#             **kwargs,", "\n", "#         )", "\n", "#", "\n", "#     mean_reward, std_reward = np.mean(episode_rewards), np.std(episode_rewards)", "\n", "#     mean_ep_length, std_ep_length = np.mean(episode_lengths), np.std(episode_lengths)", "\n", "#     self.last_mean_reward = mean_reward", "\n", "#", "\n", "#     if self.verbose > 0:", "\n", "#         print(f\"Eval num_timesteps={self.num_timesteps}, \" f\"episode_reward={mean_reward:.2f} +/- {std_reward:.2f}\")", "\n", "#         print(f\"Episode length: {mean_ep_length:.2f} +/- {std_ep_length:.2f}\")", "\n", "#     # Add to current Logger", "\n", "#     self.logger.record(\"eval/mean_reward\", float(mean_reward))", "\n", "#     self.logger.record(\"eval/mean_ep_length\", mean_ep_length)", "\n", "#", "\n", "#     if len(self._is_success_buffer) > 0:", "\n", "#         success_rate = np.mean(self._is_success_buffer)", "\n", "#         if self.verbose > 0:", "\n", "#             print(f\"Success rate: {100 * success_rate:.2f}%\")", "\n", "#         self.logger.record(\"eval/success_rate\", success_rate)", "\n", "#", "\n", "#     if mean_reward > self.best_mean_reward:", "\n", "#         if self.verbose > 0:", "\n", "#             print(\"New best mean reward!\")", "\n", "#         if self.best_model_save_path is not None:", "\n", "#             self.model.save(os.path.join(self.best_model_save_path, \"best_model\"))", "\n", "#         self.best_mean_reward = mean_reward", "\n", "#         # Trigger callback if needed", "\n", "#         if self.callback is not None:", "\n", "#             return self._on_event()", "\n", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EvalCallback.update_child_locals": [[421, 429], ["callbacks.EvalCallback.callback.update_locals"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.BaseCallback.update_locals"], ["", "def", "update_child_locals", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the references to the local variables.\n\n        :param locals_: the local variables during rollout collection\n        \"\"\"", "\n", "if", "self", ".", "callback", ":", "\n", "            ", "self", ".", "callback", ".", "update_locals", "(", "locals_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnRewardThreshold.__init__": [[443, 446], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "reward_threshold", ":", "float", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "StopTrainingOnRewardThreshold", ",", "self", ")", ".", "__init__", "(", "verbose", "=", "verbose", ")", "\n", "self", ".", "reward_threshold", "=", "reward_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnRewardThreshold._on_step": [[447, 457], ["bool", "print"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "assert", "self", ".", "parent", "is", "not", "None", ",", "\"``StopTrainingOnMinimumReward`` callback must be used \"", "\"with an ``EvalCallback``\"", "\n", "# Convert np.bool_ to bool, otherwise callback() is False won't work", "\n", "continue_training", "=", "bool", "(", "self", ".", "parent", ".", "best_mean_reward", "<", "self", ".", "reward_threshold", ")", "\n", "if", "self", ".", "verbose", ">", "0", "and", "not", "continue_training", ":", "\n", "            ", "print", "(", "\n", "f\"Stopping training because the mean reward {self.parent.best_mean_reward:.2f} \"", "\n", "f\" is above the threshold {self.reward_threshold}\"", "\n", ")", "\n", "", "return", "continue_training", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EveryNTimesteps.__init__": [[468, 472], ["callbacks.EventCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "n_steps", ":", "int", ",", "callback", ":", "BaseCallback", ")", ":", "\n", "        ", "super", "(", "EveryNTimesteps", ",", "self", ")", ".", "__init__", "(", "callback", ")", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "last_time_trigger", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EveryNTimesteps._on_step": [[473, 478], ["callbacks.EveryNTimesteps._on_event"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.EventCallback._on_event"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "(", "self", ".", "num_timesteps", "-", "self", ".", "last_time_trigger", ")", ">=", "self", ".", "n_steps", ":", "\n", "            ", "self", ".", "last_time_trigger", "=", "self", ".", "num_timesteps", "\n", "return", "self", ".", "_on_event", "(", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnMaxEpisodes.__init__": [[491, 496], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "max_episodes", ":", "int", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "StopTrainingOnMaxEpisodes", ",", "self", ")", ".", "__init__", "(", "verbose", "=", "verbose", ")", "\n", "self", ".", "max_episodes", "=", "max_episodes", "\n", "self", ".", "_total_max_episodes", "=", "max_episodes", "\n", "self", ".", "n_episodes", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnMaxEpisodes._init_callback": [[497, 500], ["None"], "methods", ["None"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "# At start set total max according to number of envirnments", "\n", "        ", "self", ".", "_total_max_episodes", "=", "self", ".", "max_episodes", "*", "self", ".", "training_env", ".", "num_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.callbacks.StopTrainingOnMaxEpisodes._on_step": [[501, 523], ["numpy.array", "numpy.sum().item", "print", "callbacks.StopTrainingOnMaxEpisodes.locals.get", "callbacks.StopTrainingOnMaxEpisodes.locals.get", "numpy.sum", "callbacks.StopTrainingOnMaxEpisodes.locals.get", "callbacks.StopTrainingOnMaxEpisodes.locals.get"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "# Checking for both 'done' and 'dones' keywords because:", "\n", "# Some models use keyword 'done' (e.g.,: SAC, TD3, DQN, DDPG)", "\n", "# While some models use keyword 'dones' (e.g.,: A2C, PPO)", "\n", "        ", "done_array", "=", "np", ".", "array", "(", "self", ".", "locals", ".", "get", "(", "\"done\"", ")", "if", "self", ".", "locals", ".", "get", "(", "\"done\"", ")", "is", "not", "None", "else", "self", ".", "locals", ".", "get", "(", "\"dones\"", ")", ")", "\n", "self", ".", "n_episodes", "+=", "np", ".", "sum", "(", "done_array", ")", ".", "item", "(", ")", "\n", "\n", "continue_training", "=", "self", ".", "n_episodes", "<", "self", ".", "_total_max_episodes", "\n", "\n", "if", "self", ".", "verbose", ">", "0", "and", "not", "continue_training", ":", "\n", "            ", "mean_episodes_per_env", "=", "self", ".", "n_episodes", "/", "self", ".", "training_env", ".", "num_envs", "\n", "mean_ep_str", "=", "(", "\n", "f\"with an average of {mean_episodes_per_env:.2f} episodes per env\"", "if", "self", ".", "training_env", ".", "num_envs", ">", "1", "else", "\"\"", "\n", ")", "\n", "\n", "print", "(", "\n", "f\"Stopping training with a total of {self.num_timesteps} steps because the \"", "\n", "f\"{self.locals.get('tb_log_name')} model reached max_episodes={self.max_episodes}, \"", "\n", "f\"by playing for {self.n_episodes} episodes \"", "\n", "f\"{mean_ep_str}\"", "\n", ")", "\n", "", "return", "continue_training", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.set_random_seed": [[22, 40], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed"], ["def", "set_random_seed", "(", "seed", ":", "int", ",", "using_cuda", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Seed the different random generators.\n\n    :param seed:\n    :param using_cuda:\n    \"\"\"", "\n", "# Seed python RNG", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "# Seed numpy RNG", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "# seed the RNG for all devices (both CPU and CUDA)", "\n", "th", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "if", "using_cuda", ":", "\n", "# Deterministic operations for CuDNN, it may impact performances", "\n", "        ", "th", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "th", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.explained_variance": [[43, 60], ["numpy.var", "numpy.var"], "function", ["None"], ["", "", "def", "explained_variance", "(", "y_pred", ":", "np", ".", "ndarray", ",", "y_true", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Computes fraction of variance that ypred explains about y.\n    Returns 1 - Var[y-ypred] / Var[y]\n\n    interpretation:\n        ev=0  =>  might as well have predicted zero\n        ev=1  =>  perfect prediction\n        ev<0  =>  worse than just predicting zero\n\n    :param y_pred: the prediction\n    :param y_true: the expected value\n    :return: explained variance of ypred and y\n    \"\"\"", "\n", "assert", "y_true", ".", "ndim", "==", "1", "and", "y_pred", ".", "ndim", "==", "1", "\n", "var_y", "=", "np", ".", "var", "(", "y_true", ")", "\n", "return", "np", ".", "nan", "if", "var_y", "==", "0", "else", "1", "-", "np", ".", "var", "(", "y_true", "-", "y_pred", ")", "/", "var_y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.update_learning_rate": [[62, 72], ["None"], "function", ["None"], ["", "def", "update_learning_rate", "(", "optimizer", ":", "th", ".", "optim", ".", "Optimizer", ",", "learning_rate", ":", "float", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Update the learning rate for a given optimizer.\n    Useful when doing linear schedule.\n\n    :param optimizer:\n    :param learning_rate:\n    \"\"\"", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "\"lr\"", "]", "=", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_schedule_fn": [[74, 90], ["isinstance", "utils.constant_fn", "callable", "float"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.constant_fn"], ["", "", "def", "get_schedule_fn", "(", "value_schedule", ":", "Union", "[", "Schedule", ",", "float", ",", "int", "]", ")", "->", "Schedule", ":", "\n", "    ", "\"\"\"\n    Transform (if needed) learning rate and clip range (for PPO)\n    to callable.\n\n    :param value_schedule:\n    :return:\n    \"\"\"", "\n", "# If the passed schedule is a float", "\n", "# create a constant function", "\n", "if", "isinstance", "(", "value_schedule", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "# Cast to float to avoid errors", "\n", "        ", "value_schedule", "=", "constant_fn", "(", "float", "(", "value_schedule", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "callable", "(", "value_schedule", ")", "\n", "", "return", "value_schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_linear_fn": [[92, 114], ["None"], "function", ["None"], ["", "def", "get_linear_fn", "(", "start", ":", "float", ",", "end", ":", "float", ",", "end_fraction", ":", "float", ")", "->", "Schedule", ":", "\n", "    ", "\"\"\"\n    Create a function that interpolates linearly between start and end\n    between ``progress_remaining`` = 1 and ``progress_remaining`` = ``end_fraction``.\n    This is used in DQN for linearly annealing the exploration fraction\n    (epsilon for the epsilon-greedy strategy).\n\n    :params start: value to start with if ``progress_remaining`` = 1\n    :params end: value to end with if ``progress_remaining`` = 0\n    :params end_fraction: fraction of ``progress_remaining``\n        where end is reached e.g 0.1 then end is reached after 10%\n        of the complete training process.\n    :return:\n    \"\"\"", "\n", "\n", "def", "func", "(", "progress_remaining", ":", "float", ")", "->", "float", ":", "\n", "        ", "if", "(", "1", "-", "progress_remaining", ")", ">", "end_fraction", ":", "\n", "            ", "return", "end", "\n", "", "else", ":", "\n", "            ", "return", "start", "+", "(", "1", "-", "progress_remaining", ")", "*", "(", "end", "-", "start", ")", "/", "end_fraction", "\n", "\n", "", "", "return", "func", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.constant_fn": [[116, 129], ["None"], "function", ["None"], ["", "def", "constant_fn", "(", "val", ":", "float", ")", "->", "Schedule", ":", "\n", "    ", "\"\"\"\n    Create a function that returns a constant\n    It is useful for learning rate schedule (to avoid code duplication)\n\n    :param val:\n    :return:\n    \"\"\"", "\n", "\n", "def", "func", "(", "_", ")", ":", "\n", "        ", "return", "val", "\n", "\n", "", "return", "func", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_device": [[131, 152], ["torch.device", "torch.device", "torch.cuda.is_available", "torch.device"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.device", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.device", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.BaseModel.device"], ["", "def", "get_device", "(", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ")", "->", "th", ".", "device", ":", "\n", "    ", "\"\"\"\n    Retrieve PyTorch device.\n    It checks that the requested device is available first.\n    For now, it supports only cpu and cuda.\n    By default, it tries to use the gpu.\n\n    :param device: One for 'auto', 'cuda', 'cpu'\n    :return:\n    \"\"\"", "\n", "# Cuda by default", "\n", "if", "device", "==", "\"auto\"", ":", "\n", "        ", "device", "=", "\"cuda\"", "\n", "# Force conversion to th.device", "\n", "", "device", "=", "th", ".", "device", "(", "device", ")", "\n", "\n", "# Cuda not available", "\n", "if", "device", ".", "type", "==", "th", ".", "device", "(", "\"cuda\"", ")", ".", "type", "and", "not", "th", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "th", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_latest_run_id": [[154, 168], ["glob.glob", "path.split", "file_name.split", "ext.isdigit", "int", "int", "file_name.split"], "function", ["None"], ["", "def", "get_latest_run_id", "(", "log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "log_name", ":", "str", "=", "\"\"", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns the latest run number for the given log name and log path,\n    by finding the greatest number in the directories.\n\n    :return: latest run number\n    \"\"\"", "\n", "max_run_id", "=", "0", "\n", "for", "path", "in", "glob", ".", "glob", "(", "f\"{log_path}/{log_name}_[0-9]*\"", ")", ":", "\n", "        ", "file_name", "=", "path", ".", "split", "(", "os", ".", "sep", ")", "[", "-", "1", "]", "\n", "ext", "=", "file_name", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "\n", "if", "log_name", "==", "\"_\"", ".", "join", "(", "file_name", ".", "split", "(", "\"_\"", ")", "[", ":", "-", "1", "]", ")", "and", "ext", ".", "isdigit", "(", ")", "and", "int", "(", "ext", ")", ">", "max_run_id", ":", "\n", "            ", "max_run_id", "=", "int", "(", "ext", ")", "\n", "", "", "return", "max_run_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.configure_logger": [[170, 192], ["utils.get_latest_run_id", "os.path.join", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.configure", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.configure", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.configure"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.get_latest_run_id", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.configure", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.configure", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.configure"], ["", "def", "configure_logger", "(", "\n", "verbose", ":", "int", "=", "0", ",", "tensorboard_log", ":", "Optional", "[", "str", "]", "=", "None", ",", "tb_log_name", ":", "str", "=", "\"\"", ",", "reset_num_timesteps", ":", "bool", "=", "True", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Configure the logger's outputs.\n\n    :param verbose: the verbosity level: 0 no output, 1 info, 2 debug\n    :param tensorboard_log: the log location for tensorboard (if None, no logging)\n    :param tb_log_name: tensorboard log\n    \"\"\"", "\n", "if", "tensorboard_log", "is", "not", "None", "and", "SummaryWriter", "is", "not", "None", ":", "\n", "        ", "latest_run_id", "=", "get_latest_run_id", "(", "tensorboard_log", ",", "tb_log_name", ")", "\n", "if", "not", "reset_num_timesteps", ":", "\n", "# Continue training in the same directory", "\n", "            ", "latest_run_id", "-=", "1", "\n", "", "save_path", "=", "os", ".", "path", ".", "join", "(", "tensorboard_log", ",", "f\"{tb_log_name}_{latest_run_id + 1}\"", ")", "\n", "if", "verbose", ">=", "1", ":", "\n", "            ", "logger", ".", "configure", "(", "save_path", ",", "[", "\"stdout\"", ",", "\"tensorboard\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "configure", "(", "save_path", ",", "[", "\"tensorboard\"", "]", ")", "\n", "", "", "elif", "verbose", "==", "0", ":", "\n", "        ", "logger", ".", "configure", "(", "format_strings", "=", "[", "\"\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.check_for_correct_spaces": [[194, 210], ["ValueError", "ValueError"], "function", ["None"], ["", "", "def", "check_for_correct_spaces", "(", "env", ":", "GymEnv", ",", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "action_space", ":", "gym", ".", "spaces", ".", "Space", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Checks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\n    spaces match after loading the model with given env.\n    Checked parameters:\n    - observation_space\n    - action_space\n\n    :param env: Environment to check for valid spaces\n    :param observation_space: Observation space to check against\n    :param action_space: Action space to check against\n    \"\"\"", "\n", "if", "observation_space", "!=", "env", ".", "observation_space", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Observation spaces do not match: {observation_space} != {env.observation_space}\"", ")", "\n", "", "if", "action_space", "!=", "env", ".", "action_space", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Action spaces do not match: {action_space} != {env.action_space}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.is_vectorized_observation": [[212, 268], ["isinstance", "isinstance", "isinstance", "ValueError", "isinstance", "len", "ValueError", "ValueError", "len", "ValueError", "len", "len", "ValueError", "map", "len", "len", "len"], "function", ["None"], ["", "", "def", "is_vectorized_observation", "(", "observation", ":", "np", ".", "ndarray", ",", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    For every observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"", "\n", "if", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "        ", "if", "observation", ".", "shape", "==", "observation_space", ".", "shape", ":", "\n", "            ", "return", "False", "\n", "", "elif", "observation", ".", "shape", "[", "1", ":", "]", "==", "observation_space", ".", "shape", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Error: Unexpected observation shape {observation.shape} for \"", "\n", "+", "f\"Box environment, please use {observation_space.shape} \"", "\n", "+", "\"or (n_env, {}) for the observation shape.\"", ".", "format", "(", "\", \"", ".", "join", "(", "map", "(", "str", ",", "observation_space", ".", "shape", ")", ")", ")", "\n", ")", "\n", "", "", "elif", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "        ", "if", "observation", ".", "shape", "==", "(", ")", ":", "# A numpy array of a number, has shape empty tuple '()'", "\n", "            ", "return", "False", "\n", "", "elif", "len", "(", "observation", ".", "shape", ")", "==", "1", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Error: Unexpected observation shape {observation.shape} for \"", "\n", "+", "\"Discrete environment, please use (1,) or (n_env, 1) for the observation shape.\"", "\n", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "        ", "if", "observation", ".", "shape", "==", "(", "len", "(", "observation_space", ".", "nvec", ")", ",", ")", ":", "\n", "            ", "return", "False", "\n", "", "elif", "len", "(", "observation", ".", "shape", ")", "==", "2", "and", "observation", ".", "shape", "[", "1", "]", "==", "len", "(", "observation_space", ".", "nvec", ")", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Error: Unexpected observation shape {observation.shape} for MultiDiscrete \"", "\n", "+", "f\"environment, please use ({len(observation_space.nvec)},) or \"", "\n", "+", "f\"(n_env, {len(observation_space.nvec)}) for the observation shape.\"", "\n", ")", "\n", "", "", "elif", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "MultiBinary", ")", ":", "\n", "        ", "if", "observation", ".", "shape", "==", "(", "observation_space", ".", "n", ",", ")", ":", "\n", "            ", "return", "False", "\n", "", "elif", "len", "(", "observation", ".", "shape", ")", "==", "2", "and", "observation", ".", "shape", "[", "1", "]", "==", "observation_space", ".", "n", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Error: Unexpected observation shape {observation.shape} for MultiBinary \"", "\n", "+", "f\"environment, please use ({observation_space.n},) or \"", "\n", "+", "f\"(n_env, {observation_space.n}) for the observation shape.\"", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Error: Cannot determine if the observation is vectorized \"", "+", "f\" with the space type {observation_space}.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.safe_mean": [[271, 280], ["numpy.mean", "len"], "function", ["None"], ["", "", "def", "safe_mean", "(", "arr", ":", "Union", "[", "np", ".", "ndarray", ",", "list", ",", "deque", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Compute the mean of an array if there is at least one element.\n    For empty array, return NaN. It is used for logging only.\n\n    :param arr:\n    :return:\n    \"\"\"", "\n", "return", "np", ".", "nan", "if", "len", "(", "arr", ")", "==", "0", "else", "np", ".", "mean", "(", "arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.zip_strict": [[282, 298], ["object", "itertools.zip_longest", "ValueError"], "function", ["None"], ["", "def", "zip_strict", "(", "*", "iterables", ":", "Iterable", ")", "->", "Iterable", ":", "\n", "    ", "r\"\"\"\n    ``zip()`` function but enforces that iterables are of equal length.\n    Raises ``ValueError`` if iterables not of equal length.\n    Code inspired by Stackoverflow answer for question #32954486.\n\n    :param \\*iterables: iterables to ``zip()``\n    \"\"\"", "\n", "# As in Stackoverflow #32954486, use", "\n", "# new object for \"empty\" in case we have", "\n", "# Nones in iterable.", "\n", "sentinel", "=", "object", "(", ")", "\n", "for", "combo", "in", "zip_longest", "(", "*", "iterables", ",", "fillvalue", "=", "sentinel", ")", ":", "\n", "        ", "if", "sentinel", "in", "combo", ":", "\n", "            ", "raise", "ValueError", "(", "\"Iterables have different lengths\"", ")", "\n", "", "yield", "combo", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.polyak_update": [[300, 321], ["torch.no_grad", "utils.zip_strict", "target_param.data.mul_", "torch.add"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.zip_strict", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add"], ["", "", "def", "polyak_update", "(", "params", ":", "Iterable", "[", "th", ".", "nn", ".", "Parameter", "]", ",", "target_params", ":", "Iterable", "[", "th", ".", "nn", ".", "Parameter", "]", ",", "tau", ":", "float", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Perform a Polyak average update on ``target_params`` using ``params``:\n    target parameters are slowly updated towards the main parameters.\n    ``tau``, the soft update coefficient controls the interpolation:\n    ``tau=1`` corresponds to copying the parameters to the target ones whereas nothing happens when ``tau=0``.\n    The Polyak update is done in place, with ``no_grad``, and therefore does not create intermediate tensors,\n    or a computation graph, reducing memory cost and improving performance.  We scale the target params\n    by ``1-tau`` (in-place), add the new weights, scaled by ``tau`` and store the result of the sum in the target\n    params (in place).\n    See https://github.com/DLR-RM/stable-baselines3/issues/93\n\n    :param params: parameters to use to update the target params\n    :param target_params: parameters to update\n    :param tau: the soft update coefficient (\"Polyak update\", between 0 and 1)\n    \"\"\"", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "# zip does not raise an exception if length of parameters does not match.", "\n", "        ", "for", "param", ",", "target_param", "in", "zip_strict", "(", "params", ",", "target_params", ")", ":", "\n", "            ", "target_param", ".", "data", ".", "mul_", "(", "1", "-", "tau", ")", "\n", "th", ".", "add", "(", "target_param", ".", "data", ",", "param", ".", "data", ",", "alpha", "=", "tau", ",", "out", "=", "target_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.should_collect_more_steps": [[323, 347], ["ValueError"], "function", ["None"], ["", "", "", "def", "should_collect_more_steps", "(", "\n", "train_freq", ":", "TrainFreq", ",", "\n", "num_collected_steps", ":", "int", ",", "\n", "num_collected_episodes", ":", "int", ",", "\n", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Helper used in ``collect_rollouts()`` of off-policy algorithms\n    to determine the termination condition.\n\n    :param train_freq: How much experience should be collected before updating the policy.\n    :param num_collected_steps: The number of already collected steps.\n    :param num_collected_episodes: The number of already collected episodes.\n    :return: Whether to continue or not collecting experience\n        by doing rollouts of the current policy.\n    \"\"\"", "\n", "if", "train_freq", ".", "unit", "==", "TrainFrequencyUnit", ".", "STEP", ":", "\n", "        ", "return", "num_collected_steps", "<", "train_freq", ".", "frequency", "\n", "\n", "", "elif", "train_freq", ".", "unit", "==", "TrainFrequencyUnit", ".", "EPISODE", ":", "\n", "        ", "return", "num_collected_episodes", "<", "train_freq", ".", "frequency", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"The unit of the `train_freq` must be either TrainFrequencyUnit.STEP \"", "\n", "f\"or TrainFrequencyUnit.EPISODE not '{train_freq.unit}'!\"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.__init__": [[31, 59], ["gym.Wrapper.__init__", "time.time", "monitor.ResultsWriter"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "env", ":", "gym", ".", "Env", ",", "\n", "filename", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "allow_early_resets", ":", "bool", "=", "True", ",", "\n", "reset_keywords", ":", "Tuple", "[", "str", ",", "...", "]", "=", "(", ")", ",", "\n", "info_keywords", ":", "Tuple", "[", "str", ",", "...", "]", "=", "(", ")", ",", "\n", ")", ":", "\n", "        ", "super", "(", "Monitor", ",", "self", ")", ".", "__init__", "(", "env", "=", "env", ")", "\n", "self", ".", "t_start", "=", "time", ".", "time", "(", ")", "\n", "if", "filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "results_writer", "=", "ResultsWriter", "(", "\n", "filename", ",", "\n", "header", "=", "{", "\"t_start\"", ":", "self", ".", "t_start", ",", "\"env_id\"", ":", "env", ".", "spec", "and", "env", ".", "spec", ".", "id", "}", ",", "\n", "extra_keys", "=", "reset_keywords", "+", "info_keywords", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "results_writer", "=", "None", "\n", "", "self", ".", "reset_keywords", "=", "reset_keywords", "\n", "self", ".", "info_keywords", "=", "info_keywords", "\n", "self", ".", "allow_early_resets", "=", "allow_early_resets", "\n", "self", ".", "rewards", "=", "None", "\n", "self", ".", "needs_reset", "=", "True", "\n", "self", ".", "episode_returns", "=", "[", "]", "\n", "self", ".", "episode_lengths", "=", "[", "]", "\n", "self", ".", "episode_times", "=", "[", "]", "\n", "self", ".", "total_steps", "=", "0", "\n", "self", ".", "current_reset_info", "=", "{", "}", "# extra info about the current episode, that was passed in during reset()", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.reset": [[60, 80], ["monitor.Monitor.env.reset", "RuntimeError", "kwargs.get", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "GymObs", ":", "\n", "        ", "\"\"\"\n        Calls the Gym environment reset. Can only be called if the environment is over, or if allow_early_resets is True\n\n        :param kwargs: Extra keywords saved for the next episode. only if defined by reset_keywords\n        :return: the first observation of the environment\n        \"\"\"", "\n", "if", "not", "self", ".", "allow_early_resets", "and", "not", "self", ".", "needs_reset", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Tried to reset an environment before done. If you want to allow early resets, \"", "\n", "\"wrap your env with Monitor(env, path, allow_early_resets=True)\"", "\n", ")", "\n", "", "self", ".", "rewards", "=", "[", "]", "\n", "self", ".", "needs_reset", "=", "False", "\n", "for", "key", "in", "self", ".", "reset_keywords", ":", "\n", "            ", "value", "=", "kwargs", ".", "get", "(", "key", ")", "\n", "if", "value", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Expected you to pass keyword argument {key} into reset\"", ")", "\n", "", "self", ".", "current_reset_info", "[", "key", "]", "=", "value", "\n", "", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.step": [[81, 108], ["monitor.Monitor.env.step", "monitor.Monitor.rewards.append", "RuntimeError", "sum", "len", "monitor.Monitor.episode_returns.append", "monitor.Monitor.episode_lengths.append", "monitor.Monitor.episode_times.append", "ep_info.update", "round", "round", "monitor.Monitor.results_writer.write_row", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.ResultsWriter.write_row"], ["", "def", "step", "(", "self", ",", "action", ":", "Union", "[", "np", ".", "ndarray", ",", "int", "]", ")", "->", "GymStepReturn", ":", "\n", "        ", "\"\"\"\n        Step the environment with the given action\n\n        :param action: the action\n        :return: observation, reward, done, information\n        \"\"\"", "\n", "if", "self", ".", "needs_reset", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Tried to step environment that needs reset\"", ")", "\n", "", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "needs_reset", "=", "True", "\n", "ep_rew", "=", "sum", "(", "self", ".", "rewards", ")", "\n", "ep_len", "=", "len", "(", "self", ".", "rewards", ")", "\n", "ep_info", "=", "{", "\"r\"", ":", "round", "(", "ep_rew", ",", "6", ")", ",", "\"l\"", ":", "ep_len", ",", "\"t\"", ":", "round", "(", "time", ".", "time", "(", ")", "-", "self", ".", "t_start", ",", "6", ")", "}", "\n", "for", "key", "in", "self", ".", "info_keywords", ":", "\n", "                ", "ep_info", "[", "key", "]", "=", "info", "[", "key", "]", "\n", "", "self", ".", "episode_returns", ".", "append", "(", "ep_rew", ")", "\n", "self", ".", "episode_lengths", ".", "append", "(", "ep_len", ")", "\n", "self", ".", "episode_times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "self", ".", "t_start", ")", "\n", "ep_info", ".", "update", "(", "self", ".", "current_reset_info", ")", "\n", "if", "self", ".", "results_writer", ":", "\n", "                ", "self", ".", "results_writer", ".", "write_row", "(", "ep_info", ")", "\n", "", "info", "[", "\"episode\"", "]", "=", "ep_info", "\n", "", "self", ".", "total_steps", "+=", "1", "\n", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.close": [[109, 116], ["super().close", "monitor.Monitor.results_writer.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Closes the environment\n        \"\"\"", "\n", "super", "(", "Monitor", ",", "self", ")", ".", "close", "(", ")", "\n", "if", "self", ".", "results_writer", "is", "not", "None", ":", "\n", "            ", "self", ".", "results_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.get_total_steps": [[117, 124], ["None"], "methods", ["None"], ["", "", "def", "get_total_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the total number of timesteps\n\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "total_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.get_episode_rewards": [[125, 132], ["None"], "methods", ["None"], ["", "def", "get_episode_rewards", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "\"\"\"\n        Returns the rewards of all the episodes\n\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "episode_returns", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.get_episode_lengths": [[133, 140], ["None"], "methods", ["None"], ["", "def", "get_episode_lengths", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns the number of timesteps of all the episodes\n\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "episode_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.Monitor.get_episode_times": [[141, 148], ["None"], "methods", ["None"], ["", "def", "get_episode_times", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "\"\"\"\n        Returns the runtime in seconds of all the episodes\n\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "episode_times", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.ResultsWriter.__init__": [[168, 186], ["open", "monitor.ResultsWriter.file_handler.write", "csv.DictWriter", "monitor.ResultsWriter.logger.writeheader", "monitor.ResultsWriter.file_handler.flush", "os.path.join.endswith", "os.path.isdir", "os.path.join", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write"], ["def", "__init__", "(", "\n", "self", ",", "\n", "filename", ":", "str", "=", "\"\"", ",", "\n", "header", ":", "Dict", "[", "str", ",", "Union", "[", "float", ",", "str", "]", "]", "=", "None", ",", "\n", "extra_keys", ":", "Tuple", "[", "str", ",", "...", "]", "=", "(", ")", ",", "\n", ")", ":", "\n", "        ", "if", "header", "is", "None", ":", "\n", "            ", "header", "=", "{", "}", "\n", "", "if", "not", "filename", ".", "endswith", "(", "Monitor", ".", "EXT", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isdir", "(", "filename", ")", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "filename", ",", "Monitor", ".", "EXT", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "filename", "+", "\".\"", "+", "Monitor", ".", "EXT", "\n", "", "", "self", ".", "file_handler", "=", "open", "(", "filename", ",", "\"wt\"", ")", "\n", "self", ".", "file_handler", ".", "write", "(", "\"#%s\\n\"", "%", "json", ".", "dumps", "(", "header", ")", ")", "\n", "self", ".", "logger", "=", "csv", ".", "DictWriter", "(", "self", ".", "file_handler", ",", "fieldnames", "=", "(", "\"r\"", ",", "\"l\"", ",", "\"t\"", ")", "+", "extra_keys", ")", "\n", "self", ".", "logger", ".", "writeheader", "(", ")", "\n", "self", ".", "file_handler", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.ResultsWriter.write_row": [[187, 196], ["monitor.ResultsWriter.logger.writerow", "monitor.ResultsWriter.file_handler.flush"], "methods", ["None"], ["", "def", "write_row", "(", "self", ",", "epinfo", ":", "Dict", "[", "str", ",", "Union", "[", "float", ",", "int", "]", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Close the file handler\n\n        :param epinfo: the information on episodic return, length, and time\n        \"\"\"", "\n", "if", "self", ".", "logger", ":", "\n", "            ", "self", ".", "logger", ".", "writerow", "(", "epinfo", ")", "\n", "self", ".", "file_handler", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.ResultsWriter.close": [[197, 202], ["monitor.ResultsWriter.file_handler.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Close the file handler\n        \"\"\"", "\n", "self", ".", "file_handler", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.get_monitor_files": [[204, 212], ["glob.glob", "os.path.join"], "function", ["None"], ["", "", "def", "get_monitor_files", "(", "path", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    get all the monitor files in the given path\n\n    :param path: the logging folder\n    :return: the log files\n    \"\"\"", "\n", "return", "glob", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"*\"", "+", "Monitor", ".", "EXT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.load_results": [[214, 239], ["monitor.get_monitor_files", "pandas.concat", "pandas.read_csv.sort_values", "pandas.read_csv.reset_index", "min", "len", "monitor.LoadMonitorResultsError", "data_frames.append", "open", "file_handler.readline", "json.loads", "pandas.read_csv", "headers.append"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.get_monitor_files", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.read_csv"], ["", "def", "load_results", "(", "path", ":", "str", ")", "->", "pandas", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Load all Monitor logs from a given directory path matching ``*monitor.csv``\n\n    :param path: the directory path containing the log file(s)\n    :return: the logged data\n    \"\"\"", "\n", "monitor_files", "=", "get_monitor_files", "(", "path", ")", "\n", "if", "len", "(", "monitor_files", ")", "==", "0", ":", "\n", "        ", "raise", "LoadMonitorResultsError", "(", "f\"No monitor files of the form *{Monitor.EXT} found in {path}\"", ")", "\n", "", "data_frames", ",", "headers", "=", "[", "]", ",", "[", "]", "\n", "for", "file_name", "in", "monitor_files", ":", "\n", "        ", "with", "open", "(", "file_name", ",", "\"rt\"", ")", "as", "file_handler", ":", "\n", "            ", "first_line", "=", "file_handler", ".", "readline", "(", ")", "\n", "assert", "first_line", "[", "0", "]", "==", "\"#\"", "\n", "header", "=", "json", ".", "loads", "(", "first_line", "[", "1", ":", "]", ")", "\n", "data_frame", "=", "pandas", ".", "read_csv", "(", "file_handler", ",", "index_col", "=", "None", ")", "\n", "headers", ".", "append", "(", "header", ")", "\n", "data_frame", "[", "\"t\"", "]", "+=", "header", "[", "\"t_start\"", "]", "\n", "", "data_frames", ".", "append", "(", "data_frame", ")", "\n", "", "data_frame", "=", "pandas", ".", "concat", "(", "data_frames", ")", "\n", "data_frame", ".", "sort_values", "(", "\"t\"", ",", "inplace", "=", "True", ")", "\n", "data_frame", ".", "reset_index", "(", "inplace", "=", "True", ")", "\n", "data_frame", "[", "\"t\"", "]", "-=", "min", "(", "header", "[", "\"t_start\"", "]", "for", "header", "in", "headers", ")", "\n", "return", "data_frame", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.evaluation.quick_evaluate_policy": [[10, 25], ["evaluation._quick_eval_helper"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.evaluation._quick_eval_helper"], ["def", "quick_evaluate_policy", "(", "attacker_model", ",", "defender_model", ",", "\n", "env", ":", "Union", "[", "gym", ".", "Env", ",", "VecEnv", "]", ",", "\n", "n_eval_episodes_train", ":", "int", "=", "10", ",", "\n", "deterministic", ":", "bool", "=", "True", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ",", "\n", "train_dto", ":", "TrainAgentLogDTO", "=", "None", "\n", ")", ":", "\n", "\n", "    ", "train_dto", "=", "_quick_eval_helper", "(", "\n", "env", "=", "env", ",", "attacker_model", "=", "attacker_model", ",", "defender_model", "=", "defender_model", ",", "\n", "n_eval_episodes", "=", "n_eval_episodes_train", ",", "deterministic", "=", "deterministic", ",", "\n", "train_mode", "=", "train_mode", ",", "\n", "train_log_dto", "=", "train_dto", ")", "\n", "\n", "return", "train_dto", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.evaluation._quick_eval_helper": [[27, 83], ["range", "range", "env.envs[].reset", "train_log_dto.attacker_eval_episode_rewards.append", "train_log_dto.defender_eval_episode_rewards.append", "train_log_dto.eval_episode_steps.append", "train_log_dto.eval_episode_flags.append", "train_log_dto.eval_episode_caught.append", "train_log_dto.eval_episode_early_stopped.append", "train_log_dto.eval_episode_successful_intrusion.append", "train_log_dto.eval_episode_snort_severe_baseline_rewards.append", "train_log_dto.eval_episode_snort_warning_baseline_rewards.append", "train_log_dto.eval_episode_snort_critical_baseline_rewards.append", "train_log_dto.eval_episode_var_log_baseline_rewards.append", "train_log_dto.eval_episode_flags_percentage.append", "train_log_dto.eval_attacker_action_costs.append", "train_log_dto.eval_attacker_action_costs_norm.append", "train_log_dto.eval_attacker_action_alerts.append", "train_log_dto.eval_attacker_action_alerts_norm.append", "env.envs[].reset", "env.envs[].step", "attacker_model.predict", "defender_model.predict", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.predict", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.predict"], ["", "def", "_quick_eval_helper", "(", "env", ",", "attacker_model", ",", "defender_model", ",", "\n", "n_eval_episodes", ",", "deterministic", ",", "train_mode", ",", "\n", "train_log_dto", ":", "TrainAgentLogDTO", "=", "None", ")", ":", "\n", "\n", "    ", "for", "episode", "in", "range", "(", "n_eval_episodes", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "env", ".", "num_envs", ")", ":", "\n", "            ", "obs", "=", "env", ".", "envs", "[", "i", "]", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "state", "=", "None", "\n", "attacker_episode_reward", "=", "0.0", "\n", "defender_episode_reward", "=", "0.0", "\n", "episode_length", "=", "0", "\n", "while", "not", "done", ":", "\n", "                ", "obs_attacker", ",", "obs_defender", "=", "obs", "\n", "attacker_actions", "=", "None", "\n", "defender_actions", "=", "[", "None", "]", "\n", "if", "train_mode", "==", "train_mode", ".", "TRAIN_ATTACKER", "or", "train_mode", "==", "train_mode", ".", "SELF_PLAY", ":", "\n", "                    ", "attacker_actions", ",", "state", "=", "attacker_model", ".", "predict", "(", "np", ".", "array", "(", "[", "obs_attacker", "]", ")", ",", "state", "=", "state", ",", "\n", "deterministic", "=", "deterministic", ",", "\n", "attacker", "=", "True", ",", "env", "=", "env", ")", "\n", "", "if", "train_mode", "==", "train_mode", ".", "TRAIN_DEFENDER", "or", "train_mode", "==", "train_mode", ".", "SELF_PLAY", ":", "\n", "                    ", "defender_actions", ",", "state", "=", "defender_model", ".", "predict", "(", "np", ".", "array", "(", "[", "obs_defender", "]", ")", ",", "state", "=", "state", ",", "\n", "deterministic", "=", "deterministic", ",", "\n", "attacker", "=", "False", ",", "env", "=", "env", ")", "\n", "if", "attacker_actions", "is", "None", ":", "\n", "                        ", "attacker_actions", "=", "np", ".", "array", "(", "[", "None", "]", ")", "\n", "", "", "defender_action", "=", "defender_actions", "[", "0", "]", "\n", "attacker_action", "=", "attacker_actions", "[", "0", "]", "\n", "action", "=", "(", "attacker_action", ",", "defender_action", ")", "\n", "obs", ",", "reward", ",", "done", ",", "_info", "=", "env", ".", "envs", "[", "i", "]", ".", "step", "(", "action", ")", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "attacker_episode_reward", "+=", "attacker_reward", "\n", "defender_episode_reward", "+=", "defender_reward", "\n", "episode_length", "+=", "1", "\n", "\n", "# Record episode metrics", "\n", "", "train_log_dto", ".", "attacker_eval_episode_rewards", ".", "append", "(", "attacker_episode_reward", ")", "\n", "train_log_dto", ".", "defender_eval_episode_rewards", ".", "append", "(", "defender_episode_reward", ")", "\n", "train_log_dto", ".", "eval_episode_steps", ".", "append", "(", "episode_length", ")", "\n", "train_log_dto", ".", "eval_episode_flags", ".", "append", "(", "_info", "[", "\"flags\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_caught", ".", "append", "(", "_info", "[", "\"caught_attacker\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_early_stopped", ".", "append", "(", "_info", "[", "\"early_stopped\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_successful_intrusion", ".", "append", "(", "_info", "[", "\"successful_intrusion\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_snort_severe_baseline_rewards", ".", "append", "(", "_info", "[", "\"snort_severe_baseline_reward\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_snort_warning_baseline_rewards", ".", "append", "(", "_info", "[", "\"snort_warning_baseline_reward\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_snort_critical_baseline_rewards", ".", "append", "(", "_info", "[", "\"snort_critical_baseline_reward\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_var_log_baseline_rewards", ".", "append", "(", "_info", "[", "\"var_log_baseline_reward\"", "]", ")", "\n", "train_log_dto", ".", "eval_episode_flags_percentage", ".", "append", "(", "_info", "[", "\"flags\"", "]", "/", "1", ")", "\n", "train_log_dto", ".", "eval_attacker_action_costs", ".", "append", "(", "_info", "[", "\"attacker_cost\"", "]", ")", "\n", "train_log_dto", ".", "eval_attacker_action_costs_norm", ".", "append", "(", "_info", "[", "\"attacker_cost_norm\"", "]", ")", "\n", "train_log_dto", ".", "eval_attacker_action_alerts", ".", "append", "(", "_info", "[", "\"attacker_alerts\"", "]", ")", "\n", "train_log_dto", ".", "eval_attacker_action_alerts_norm", ".", "append", "(", "_info", "[", "\"attacker_alerts_norm\"", "]", ")", "\n", "\n", "obs", "=", "env", ".", "envs", "[", "i", "]", ".", "reset", "(", ")", "\n", "\n", "", "", "return", "train_log_dto", "\n", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.__init__": [[32, 50], ["abc.ABC.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.get_obs_shape", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.get_action_dim"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_obs_shape", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.get_action_dim"], ["def", "__init__", "(", "\n", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"cpu\"", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", "BaseBuffer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "observation_space", "=", "observation_space", "\n", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "obs_shape", "=", "get_obs_shape", "(", "observation_space", ")", "\n", "self", ".", "action_dim", "=", "get_action_dim", "(", "action_space", ")", "\n", "self", ".", "pos", "=", "0", "\n", "self", ".", "full", "=", "False", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "n_envs", "=", "n_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.swap_and_flatten": [[51, 65], ["arr.swapaxes().reshape", "len", "arr.swapaxes"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "swap_and_flatten", "(", "arr", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)\n        to convert shape from [n_steps, n_envs, ...] (when ... is the shape of the features)\n        to [n_steps * n_envs, ...] (which maintain the order)\n\n        :param arr:\n        :return:\n        \"\"\"", "\n", "shape", "=", "arr", ".", "shape", "\n", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "shape", "=", "shape", "+", "(", "1", ",", ")", "\n", "", "return", "arr", ".", "swapaxes", "(", "0", ",", "1", ")", ".", "reshape", "(", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "*", "shape", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.size": [[66, 73], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: The current size of the buffer\n        \"\"\"", "\n", "if", "self", ".", "full", ":", "\n", "            ", "return", "self", ".", "buffer_size", "\n", "", "return", "self", ".", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.add": [[74, 79], ["NotImplementedError"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add elements to the buffer.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.extend": [[80, 87], ["zip", "buffers.BaseBuffer.add"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add"], ["", "def", "extend", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add a new batch of transitions to the buffer\n        \"\"\"", "\n", "# Do a for loop along the batch axis", "\n", "for", "data", "in", "zip", "(", "*", "args", ")", ":", "\n", "            ", "self", ".", "add", "(", "*", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.reset": [[88, 94], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reset the buffer.\n        \"\"\"", "\n", "self", ".", "pos", "=", "0", "\n", "self", ".", "full", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.sample": [[95, 105], ["numpy.random.randint", "buffers.BaseBuffer._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer._get_samples"], ["", "def", "sample", "(", "self", ",", "batch_size", ":", "int", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param batch_size: Number of element to sample\n        :param env: associated gym VecEnv\n            to normalize the observations/rewards when sampling\n        :return:\n        \"\"\"", "\n", "upper_bound", "=", "self", ".", "buffer_size", "if", "self", ".", "full", "else", "self", ".", "pos", "\n", "batch_inds", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "upper_bound", ",", "size", "=", "batch_size", ")", "\n", "return", "self", ".", "_get_samples", "(", "batch_inds", ",", "env", "=", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer._get_samples": [[106, 116], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_get_samples", "(", "\n", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", "\n", ")", "->", "Union", "[", "ReplayBufferSamples", ",", "RolloutBufferSamples", "]", ":", "\n", "        ", "\"\"\"\n        :param batch_inds:\n        :param env:\n        :return:\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.to_torch": [[117, 130], ["torch.as_tensor().to", "torch.tensor().to", "torch.as_tensor", "torch.tensor"], "methods", ["None"], ["", "def", "to_torch", "(", "self", ",", "array", ":", "np", ".", "ndarray", ",", "copy", ":", "bool", "=", "True", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Convert a numpy array to a PyTorch tensor.\n        Note: it copies the data by default\n\n        :param array:\n        :param copy: Whether to copy or not the data\n            (may be useful to avoid changing things be reference)\n        :return:\n        \"\"\"", "\n", "if", "copy", ":", "\n", "            ", "return", "th", ".", "tensor", "(", "array", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "return", "th", ".", "as_tensor", "(", "array", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer._normalize_obs": [[131, 138], ["env.normalize_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_obs"], ["", "@", "staticmethod", "\n", "def", "_normalize_obs", "(", "\n", "obs", ":", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", "\n", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "if", "env", "is", "not", "None", ":", "\n", "            ", "return", "env", ".", "normalize_obs", "(", "obs", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer._normalize_reward": [[139, 144], ["env.normalize_reward().astype", "env.normalize_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_reward"], ["", "@", "staticmethod", "\n", "def", "_normalize_reward", "(", "reward", ":", "np", ".", "ndarray", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "if", "env", "is", "not", "None", ":", "\n", "            ", "return", "env", ".", "normalize_reward", "(", "reward", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.__init__": [[162, 201], ["buffers.BaseBuffer.__init__", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "psutil.virtual_memory", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["def", "__init__", "(", "\n", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"cpu\"", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "optimize_memory_usage", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "ReplayBuffer", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "\n", "assert", "n_envs", "==", "1", ",", "\"Replay buffer only support single environment for now\"", "\n", "\n", "# Check that the replay buffer can fit into the memory", "\n", "if", "psutil", "is", "not", "None", ":", "\n", "            ", "mem_available", "=", "psutil", ".", "virtual_memory", "(", ")", ".", "available", "\n", "\n", "", "self", ".", "optimize_memory_usage", "=", "optimize_memory_usage", "\n", "self", ".", "observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "observation_space", ".", "dtype", ")", "\n", "if", "optimize_memory_usage", ":", "\n", "# `observations` contains also the next observation", "\n", "            ", "self", ".", "next_observations", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "next_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "observation_space", ".", "dtype", ")", "\n", "", "self", ".", "actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "action_space", ".", "dtype", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "if", "psutil", "is", "not", "None", ":", "\n", "            ", "total_memory_usage", "=", "self", ".", "observations", ".", "nbytes", "+", "self", ".", "actions", ".", "nbytes", "+", "self", ".", "rewards", ".", "nbytes", "+", "self", ".", "dones", ".", "nbytes", "\n", "if", "self", ".", "next_observations", "is", "not", "None", ":", "\n", "                ", "total_memory_usage", "+=", "self", ".", "next_observations", ".", "nbytes", "\n", "\n", "", "if", "total_memory_usage", ">", "mem_available", ":", "\n", "# Convert to GB", "\n", "                ", "total_memory_usage", "/=", "1e9", "\n", "mem_available", "/=", "1e9", "\n", "warnings", ".", "warn", "(", "\n", "\"This system does not have apparently enough memory to store the complete \"", "\n", "f\"replay buffer {total_memory_usage:.2f}GB > {mem_available:.2f}GB\"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.add": [[204, 220], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "", "", "def", "add", "(", "self", ",", "obs", ":", "np", ".", "ndarray", ",", "next_obs", ":", "np", ".", "ndarray", ",", "action", ":", "np", ".", "ndarray", ",", "reward", ":", "np", ".", "ndarray", ",", "done", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "# Copy to avoid modification by reference", "\n", "        ", "self", ".", "observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs", ")", ".", "copy", "(", ")", "\n", "if", "self", ".", "optimize_memory_usage", ":", "\n", "            ", "self", ".", "observations", "[", "(", "self", ".", "pos", "+", "1", ")", "%", "self", ".", "buffer_size", "]", "=", "np", ".", "array", "(", "next_obs", ")", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "next_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "next_obs", ")", ".", "copy", "(", ")", "\n", "\n", "", "self", ".", "actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "self", ".", "pos", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample": [[221, 242], ["buffers.ReplayBuffer._get_samples", "buffers.BaseBuffer.sample", "numpy.random.randint", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer._get_samples", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer.sample"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ":", "int", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "ReplayBufferSamples", ":", "\n", "        ", "\"\"\"\n        Sample elements from the replay buffer.\n        Custom sampling when using memory efficient variant,\n        as we should not sample the element with index `self.pos`\n        See https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n\n        :param batch_size: Number of element to sample\n        :param env: associated gym VecEnv\n            to normalize the observations/rewards when sampling\n        :return:\n        \"\"\"", "\n", "if", "not", "self", ".", "optimize_memory_usage", ":", "\n", "            ", "return", "super", "(", ")", ".", "sample", "(", "batch_size", "=", "batch_size", ",", "env", "=", "env", ")", "\n", "# Do not sample the element with index `self.pos` as the transitions is invalid", "\n", "# (we use only one array to store `obs` and `next_obs`)", "\n", "", "if", "self", ".", "full", ":", "\n", "            ", "batch_inds", "=", "(", "np", ".", "random", ".", "randint", "(", "1", ",", "self", ".", "buffer_size", ",", "size", "=", "batch_size", ")", "+", "self", ".", "pos", ")", "%", "self", ".", "buffer_size", "\n", "", "else", ":", "\n", "            ", "batch_inds", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "pos", ",", "size", "=", "batch_size", ")", "\n", "", "return", "self", ".", "_get_samples", "(", "batch_inds", ",", "env", "=", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.ReplayBuffer._get_samples": [[243, 257], ["gym_optimal_intrusion_response.agents.openai_baselines.common.type_aliases.ReplayBufferSamples", "buffers.ReplayBuffer._normalize_obs", "buffers.ReplayBuffer._normalize_obs", "buffers.ReplayBuffer._normalize_obs", "buffers.ReplayBuffer._normalize_reward", "tuple", "map"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer._normalize_reward"], ["", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "ReplayBufferSamples", ":", "\n", "        ", "if", "self", ".", "optimize_memory_usage", ":", "\n", "            ", "next_obs", "=", "self", ".", "_normalize_obs", "(", "self", ".", "observations", "[", "(", "batch_inds", "+", "1", ")", "%", "self", ".", "buffer_size", ",", "0", ",", ":", "]", ",", "env", ")", "\n", "", "else", ":", "\n", "            ", "next_obs", "=", "self", ".", "_normalize_obs", "(", "self", ".", "next_observations", "[", "batch_inds", ",", "0", ",", ":", "]", ",", "env", ")", "\n", "\n", "", "data", "=", "(", "\n", "self", ".", "_normalize_obs", "(", "self", ".", "observations", "[", "batch_inds", ",", "0", ",", ":", "]", ",", "env", ")", ",", "\n", "self", ".", "actions", "[", "batch_inds", ",", "0", ",", ":", "]", ",", "\n", "next_obs", ",", "\n", "self", ".", "dones", "[", "batch_inds", "]", ",", "\n", "self", ".", "_normalize_reward", "(", "self", ".", "rewards", "[", "batch_inds", "]", ",", "env", ")", ",", "\n", ")", "\n", "return", "ReplayBufferSamples", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.__init__": [[282, 300], ["buffers.BaseBuffer.__init__", "buffers.RolloutBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["def", "__init__", "(", "\n", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"cpu\"", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBuffer", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "observations", ",", "self", ".", "actions", ",", "self", ".", "rewards", ",", "self", ".", "advantages", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "returns", ",", "self", ".", "episode_starts", ",", "self", ".", "values", ",", "self", ".", "log_probs", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.reset": [[301, 312], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "episode_starts", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "super", "(", "RolloutBuffer", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.compute_returns_and_advantage": [[313, 350], ["last_values.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "range", "last_values.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "last_values.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_values.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "last_values", ":", "th", ".", "Tensor", ",", "dones", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the lambda-return (TD(lambda) estimate)\n        and GAE(lambda) advantage.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        The TD(lambda) estimator has also two special cases:\n        - TD(1) is Monte-Carlo estimate (sum of discounted rewards)\n        - TD(0) is one-step estimate with bootstrapping (r_t + gamma * v(s_{t+1}))\n\n        For more information, see discussion in https://github.com/DLR-RM/stable-baselines3/pull/375.\n\n        :param last_values: state value estimation for the last step (one for each env)\n        :param dones: if the last step was a terminal step (one bool for each env).\n\n        \"\"\"", "\n", "# Convert to numpy", "\n", "last_values", "=", "last_values", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "            ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_values", "=", "last_values", "\n", "", "else", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "self", ".", "episode_starts", "[", "step", "+", "1", "]", "\n", "next_values", "=", "self", ".", "values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_values", "*", "next_non_terminal", "-", "self", ".", "values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "# TD(lambda) estimator, see Github PR #375 or \"Telescoping in TD(lambda)\"", "\n", "# in David Silver Lecture 4: https://www.youtube.com/watch?v=PnHCvfgC_ZA", "\n", "", "self", ".", "returns", "=", "self", ".", "advantages", "+", "self", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.add": [[351, 388], ["isinstance", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "value.clone().cpu().numpy().flatten", "log_prob.reshape.reshape.clone().cpu().numpy", "len", "log_prob.reshape.reshape.reshape", "obs.reshape.reshape.reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "value.clone().cpu().numpy", "log_prob.reshape.reshape.clone().cpu", "value.clone().cpu", "log_prob.reshape.reshape.clone", "value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "add", "(", "\n", "self", ",", "\n", "obs", ":", "np", ".", "ndarray", ",", "\n", "action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "episode_start", ":", "np", ".", "ndarray", ",", "\n", "value", ":", "th", ".", "Tensor", ",", "\n", "log_prob", ":", "th", ".", "Tensor", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param obs: Observation\n        :param action: Action\n        :param reward:\n        :param episode_start: Start of episode signal.\n        :param value: estimated value of the current state\n            following the current policy.\n        :param log_prob: log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "log_prob", "=", "log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "# Reshape needed when using multiple envs with discrete observations", "\n", "# as numpy cannot broadcast (n_discrete,) to (n_discrete, 1)", "\n", "", "if", "isinstance", "(", "self", ".", "observation_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "            ", "obs", "=", "obs", ".", "reshape", "(", "(", "self", ".", "n_envs", ",", ")", "+", "self", ".", "obs_shape", ")", "\n", "\n", "", "self", ".", "observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "episode_starts", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "episode_start", ")", ".", "copy", "(", ")", "\n", "self", ".", "values", "[", "self", ".", "pos", "]", "=", "value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "log_probs", "[", "self", ".", "pos", "]", "=", "log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get": [[389, 406], ["numpy.random.permutation", "buffers.RolloutBuffer.swap_and_flatten", "buffers.RolloutBuffer._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamples", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "\"\"", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "\"observations\"", ",", "\"actions\"", ",", "\"values\"", ",", "\"log_probs\"", ",", "\"advantages\"", ",", "\"returns\"", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer._get_samples": [[407, 417], ["gym_optimal_intrusion_response.agents.openai_baselines.common.type_aliases.RolloutBufferSamples", "buffers.RolloutBuffer.values[].flatten", "buffers.RolloutBuffer.log_probs[].flatten", "buffers.RolloutBuffer.advantages[].flatten", "buffers.RolloutBuffer.returns[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamples", ":", "\n", "        ", "data", "=", "(", "\n", "self", ".", "observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", ")", "\n", "return", "RolloutBufferSamples", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_extract_dict_obs.VecExtractDictObs.__init__": [[14, 17], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ",", "key", ":", "str", ")", ":", "\n", "        ", "self", ".", "key", "=", "key", "\n", "super", "(", ")", ".", "__init__", "(", "venv", "=", "venv", ",", "observation_space", "=", "venv", ".", "observation_space", ".", "spaces", "[", "self", ".", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_extract_dict_obs.VecExtractDictObs.reset": [[18, 21], ["vec_extract_dict_obs.VecExtractDictObs.venv.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "return", "obs", "[", "self", ".", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_extract_dict_obs.VecExtractDictObs.step_wait": [[22, 25], ["vec_extract_dict_obs.VecExtractDictObs.venv.step_wait"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "return", "obs", "[", "self", ".", "key", "]", ",", "reward", ",", "done", ",", "info", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan.__init__": [[19, 27], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ",", "raise_exception", ":", "bool", "=", "False", ",", "warn_once", ":", "bool", "=", "True", ",", "check_inf", ":", "bool", "=", "True", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "raise_exception", "=", "raise_exception", "\n", "self", ".", "warn_once", "=", "warn_once", "\n", "self", ".", "check_inf", "=", "check_inf", "\n", "self", ".", "_actions", "=", "None", "\n", "self", ".", "_observations", "=", "None", "\n", "self", ".", "_user_warned", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan.step_async": [[28, 33], ["vec_check_nan.VecCheckNan._check_val", "vec_check_nan.VecCheckNan.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan._check_val", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "self", ".", "_check_val", "(", "async_step", "=", "True", ",", "actions", "=", "actions", ")", "\n", "\n", "self", ".", "_actions", "=", "actions", "\n", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan.step_wait": [[34, 41], ["vec_check_nan.VecCheckNan.venv.step_wait", "vec_check_nan.VecCheckNan._check_val"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan._check_val"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "observations", ",", "rewards", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n", "self", ".", "_check_val", "(", "async_step", "=", "False", ",", "observations", "=", "observations", ",", "rewards", "=", "rewards", ",", "news", "=", "news", ")", "\n", "\n", "self", ".", "_observations", "=", "observations", "\n", "return", "observations", ",", "rewards", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan.reset": [[42, 50], ["vec_check_nan.VecCheckNan.venv.reset", "vec_check_nan.VecCheckNan._check_val"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan._check_val"], ["", "def", "reset", "(", "self", ")", "->", "VecEnvObs", ":", "\n", "        ", "observations", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "_actions", "=", "None", "\n", "\n", "self", ".", "_check_val", "(", "async_step", "=", "False", ",", "observations", "=", "observations", ")", "\n", "\n", "self", ".", "_observations", "=", "observations", "\n", "return", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_check_nan.VecCheckNan._check_val": [[51, 87], ["kwargs.items", "numpy.any", "enumerate", "numpy.isnan", "numpy.any", "found.append", "found.append", "ValueError", "warnings.warn", "numpy.isinf", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "_check_val", "(", "self", ",", "*", ",", "async_step", ":", "bool", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "# if warn and warn once and have warned once: then stop checking", "\n", "        ", "if", "not", "self", ".", "raise_exception", "and", "self", ".", "warn_once", "and", "self", ".", "_user_warned", ":", "\n", "            ", "return", "\n", "\n", "", "found", "=", "[", "]", "\n", "for", "name", ",", "val", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "has_nan", "=", "np", ".", "any", "(", "np", ".", "isnan", "(", "val", ")", ")", "\n", "has_inf", "=", "self", ".", "check_inf", "and", "np", ".", "any", "(", "np", ".", "isinf", "(", "val", ")", ")", "\n", "if", "has_inf", ":", "\n", "                ", "found", ".", "append", "(", "(", "name", ",", "\"inf\"", ")", ")", "\n", "", "if", "has_nan", ":", "\n", "                ", "found", ".", "append", "(", "(", "name", ",", "\"nan\"", ")", ")", "\n", "\n", "", "", "if", "found", ":", "\n", "            ", "self", ".", "_user_warned", "=", "True", "\n", "msg", "=", "\"\"", "\n", "for", "i", ",", "(", "name", ",", "type_val", ")", "in", "enumerate", "(", "found", ")", ":", "\n", "                ", "msg", "+=", "f\"found {type_val} in {name}\"", "\n", "if", "i", "!=", "len", "(", "found", ")", "-", "1", ":", "\n", "                    ", "msg", "+=", "\", \"", "\n", "\n", "", "", "msg", "+=", "\".\\r\\nOriginated from the \"", "\n", "\n", "if", "not", "async_step", ":", "\n", "                ", "if", "self", ".", "_actions", "is", "None", ":", "\n", "                    ", "msg", "+=", "\"environment observation (at reset)\"", "\n", "", "else", ":", "\n", "                    ", "msg", "+=", "f\"environment, Last given value was: \\r\\n\\taction={self._actions}\"", "\n", "", "", "else", ":", "\n", "                ", "msg", "+=", "f\"RL model, Last given value was: \\r\\n\\tobservations={self._observations}\"", "\n", "\n", "", "if", "self", ".", "raise_exception", ":", "\n", "                ", "raise", "ValueError", "(", "msg", ")", "\n", "", "else", ":", "\n", "                ", "warnings", ".", "warn", "(", "msg", ",", "UserWarning", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_frame_stack.VecFrameStack.__init__": [[26, 53], ["isinstance", "numpy.repeat", "numpy.repeat", "numpy.zeros", "gym.spaces.Box", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.is_image_space", "gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.is_image_space_channels_first"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space_channels_first"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ",", "n_stack", ":", "int", ",", "channels_order", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "self", ".", "n_stack", "=", "n_stack", "\n", "\n", "wrapped_obs_space", "=", "venv", ".", "observation_space", "\n", "assert", "isinstance", "(", "wrapped_obs_space", ",", "spaces", ".", "Box", ")", ",", "\"VecFrameStack only work with gym.spaces.Box observation space\"", "\n", "\n", "if", "channels_order", "is", "None", ":", "\n", "# Detect channel location automatically for images", "\n", "            ", "if", "is_image_space", "(", "wrapped_obs_space", ")", ":", "\n", "                ", "self", ".", "channels_first", "=", "is_image_space_channels_first", "(", "wrapped_obs_space", ")", "\n", "", "else", ":", "\n", "# Default behavior for non-image space, stack on the last axis", "\n", "                ", "self", ".", "channels_first", "=", "False", "\n", "", "", "else", ":", "\n", "            ", "assert", "channels_order", "in", "{", "\"last\"", ",", "\"first\"", "}", ",", "\"`channels_order` must be one of following: 'last', 'first'\"", "\n", "\n", "self", ".", "channels_first", "=", "channels_order", "==", "\"first\"", "\n", "\n", "# This includes the vec-env dimension (first)", "\n", "", "self", ".", "stack_dimension", "=", "1", "if", "self", ".", "channels_first", "else", "-", "1", "\n", "repeat_axis", "=", "0", "if", "self", ".", "channels_first", "else", "-", "1", "\n", "low", "=", "np", ".", "repeat", "(", "wrapped_obs_space", ".", "low", ",", "self", ".", "n_stack", ",", "axis", "=", "repeat_axis", ")", "\n", "high", "=", "np", ".", "repeat", "(", "wrapped_obs_space", ".", "high", ",", "self", ".", "n_stack", ",", "axis", "=", "repeat_axis", ")", "\n", "self", ".", "stackedobs", "=", "np", ".", "zeros", "(", "(", "venv", ".", "num_envs", ",", ")", "+", "low", ".", "shape", ",", "low", ".", "dtype", ")", "\n", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "venv", ".", "observation_space", ".", "dtype", ")", "\n", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ",", "observation_space", "=", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_frame_stack.VecFrameStack.step_wait": [[54, 82], ["vec_frame_stack.VecFrameStack.venv.step_wait", "isinstance", "numpy.roll", "enumerate", "warnings.warn", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "step_wait", "(", "self", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "]", ":", "\n", "        ", "observations", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "# Let pytype know that observation is not a dict", "\n", "assert", "isinstance", "(", "observations", ",", "np", ".", "ndarray", ")", "\n", "stack_ax_size", "=", "observations", ".", "shape", "[", "self", ".", "stack_dimension", "]", "\n", "self", ".", "stackedobs", "=", "np", ".", "roll", "(", "self", ".", "stackedobs", ",", "shift", "=", "-", "stack_ax_size", ",", "axis", "=", "self", ".", "stack_dimension", ")", "\n", "for", "i", ",", "done", "in", "enumerate", "(", "dones", ")", ":", "\n", "            ", "if", "done", ":", "\n", "                ", "if", "\"terminal_observation\"", "in", "infos", "[", "i", "]", ":", "\n", "                    ", "old_terminal", "=", "infos", "[", "i", "]", "[", "\"terminal_observation\"", "]", "\n", "if", "self", ".", "channels_first", ":", "\n", "                        ", "new_terminal", "=", "np", ".", "concatenate", "(", "\n", "(", "self", ".", "stackedobs", "[", "i", ",", ":", "-", "stack_ax_size", ",", "...", "]", ",", "old_terminal", ")", ",", "axis", "=", "self", ".", "stack_dimension", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "new_terminal", "=", "np", ".", "concatenate", "(", "\n", "(", "self", ".", "stackedobs", "[", "i", ",", "...", ",", ":", "-", "stack_ax_size", "]", ",", "old_terminal", ")", ",", "axis", "=", "self", ".", "stack_dimension", "\n", ")", "\n", "", "infos", "[", "i", "]", "[", "\"terminal_observation\"", "]", "=", "new_terminal", "\n", "", "else", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\"VecFrameStack wrapping a VecEnv without terminal_observation info\"", ")", "\n", "", "self", ".", "stackedobs", "[", "i", "]", "=", "0", "\n", "", "", "if", "self", ".", "channels_first", ":", "\n", "            ", "self", ".", "stackedobs", "[", ":", ",", "-", "observations", ".", "shape", "[", "self", ".", "stack_dimension", "]", ":", ",", "...", "]", "=", "observations", "\n", "", "else", ":", "\n", "            ", "self", ".", "stackedobs", "[", "...", ",", "-", "observations", ".", "shape", "[", "self", ".", "stack_dimension", "]", ":", "]", "=", "observations", "\n", "\n", "", "return", "self", ".", "stackedobs", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_frame_stack.VecFrameStack.reset": [[83, 94], ["vec_frame_stack.VecFrameStack.venv.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "obs", ":", "np", ".", "ndarray", "=", "self", ".", "venv", ".", "reset", "(", ")", "# pytype:disable=annotation-type-mismatch", "\n", "self", ".", "stackedobs", "[", "...", "]", "=", "0", "\n", "if", "self", ".", "channels_first", ":", "\n", "            ", "self", ".", "stackedobs", "[", ":", ",", "-", "obs", ".", "shape", "[", "self", ".", "stack_dimension", "]", ":", ",", "...", "]", "=", "obs", "\n", "", "else", ":", "\n", "            ", "self", ".", "stackedobs", "[", "...", ",", "-", "obs", ".", "shape", "[", "self", ".", "stack_dimension", "]", ":", "]", "=", "obs", "\n", "", "return", "self", ".", "stackedobs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_frame_stack.VecFrameStack.close": [[95, 97], ["vec_frame_stack.VecFrameStack.venv.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "venv", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.__init__": [[87, 113], ["len", "multiprocessing.get_context", "zip", "zip", "subproc_vec_env.SubprocVecEnv.remotes[].send", "subproc_vec_env.SubprocVecEnv.remotes[].recv", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnv.__init__", "multiprocessing.get_context.Process", "mp.get_context.Process.start", "subproc_vec_env.SubprocVecEnv.processes.append", "work_remote.close", "len", "multiprocessing.get_all_start_methods", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.CloudpickleWrapper", "multiprocessing.get_context.Pipe", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["def", "__init__", "(", "self", ",", "env_fns", ":", "List", "[", "Callable", "[", "[", "]", ",", "gym", ".", "Env", "]", "]", ",", "start_method", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "waiting", "=", "False", "\n", "self", ".", "closed", "=", "False", "\n", "n_envs", "=", "len", "(", "env_fns", ")", "\n", "\n", "if", "start_method", "is", "None", ":", "\n", "# Fork is not a thread safe method (see issue #217)", "\n", "# but is more user friendly (does not require to wrap the code in", "\n", "# a `if __name__ == \"__main__\":`)", "\n", "            ", "forkserver_available", "=", "\"forkserver\"", "in", "mp", ".", "get_all_start_methods", "(", ")", "\n", "start_method", "=", "\"forkserver\"", "if", "forkserver_available", "else", "\"spawn\"", "\n", "", "ctx", "=", "mp", ".", "get_context", "(", "start_method", ")", "\n", "\n", "self", ".", "remotes", ",", "self", ".", "work_remotes", "=", "zip", "(", "*", "[", "ctx", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", ")", "\n", "self", ".", "processes", "=", "[", "]", "\n", "for", "work_remote", ",", "remote", ",", "env_fn", "in", "zip", "(", "self", ".", "work_remotes", ",", "self", ".", "remotes", ",", "env_fns", ")", ":", "\n", "            ", "args", "=", "(", "work_remote", ",", "remote", ",", "CloudpickleWrapper", "(", "env_fn", ")", ")", "\n", "# daemon=True: if the main process crashes, we should not cause things to hang", "\n", "process", "=", "ctx", ".", "Process", "(", "target", "=", "_worker", ",", "args", "=", "args", ",", "daemon", "=", "True", ")", "# pytype:disable=attribute-error", "\n", "process", ".", "start", "(", ")", "\n", "self", ".", "processes", ".", "append", "(", "process", ")", "\n", "work_remote", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "\"get_spaces\"", ",", "None", ")", ")", "\n", "observation_space", ",", "action_space", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "observation_space", ",", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.step_async": [[114, 118], ["zip", "remote.send"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "for", "remote", ",", "action", "in", "zip", "(", "self", ".", "remotes", ",", "actions", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"step\"", ",", "action", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.step_wait": [[119, 124], ["zip", "remote.recv", "subproc_vec_env._flatten_obs", "numpy.stack", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env._flatten_obs"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "self", ".", "waiting", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "results", ")", "\n", "return", "_flatten_obs", "(", "obs", ",", "self", ".", "observation_space", ")", ",", "np", ".", "stack", "(", "rews", ")", ",", "np", ".", "stack", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.seed": [[125, 129], ["enumerate", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "List", "[", "Union", "[", "None", ",", "int", "]", "]", ":", "\n", "        ", "for", "idx", ",", "remote", "in", "enumerate", "(", "self", ".", "remotes", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"seed\"", ",", "seed", "+", "idx", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.reset": [[130, 135], ["subproc_vec_env._flatten_obs", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env._flatten_obs"], ["", "def", "reset", "(", "self", ")", "->", "VecEnvObs", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"reset\"", ",", "None", ")", ")", "\n", "", "obs", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "return", "_flatten_obs", "(", "obs", ",", "self", ".", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.close": [[136, 147], ["remote.send", "process.join", "remote.recv"], "methods", ["None"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "closed", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "waiting", ":", "\n", "            ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "                ", "remote", ".", "recv", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"close\"", ",", "None", ")", ")", "\n", "", "for", "process", "in", "self", ".", "processes", ":", "\n", "            ", "process", ".", "join", "(", ")", "\n", "", "self", ".", "closed", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.get_images": [[148, 155], ["pipe.send", "pipe.recv"], "methods", ["None"], ["", "def", "get_images", "(", "self", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "for", "pipe", "in", "self", ".", "remotes", ":", "\n", "# gather images from subprocesses", "\n", "# `mode` will be taken into account later", "\n", "            ", "pipe", ".", "send", "(", "(", "\"render\"", ",", "\"rgb_array\"", ")", ")", "\n", "", "imgs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "remotes", "]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.get_attr": [[156, 162], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ":", "str", ",", "indices", ":", "VecEnvIndices", "=", "None", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "\"\"\"Return attribute from vectorized environment (see base class).\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"get_attr\"", ",", "attr_name", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.set_attr": [[163, 170], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ":", "str", ",", "value", ":", "Any", ",", "indices", ":", "VecEnvIndices", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"Set attribute inside vectorized environments (see base class).\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"set_attr\"", ",", "(", "attr_name", ",", "value", ")", ")", ")", "\n", "", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "recv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.env_method": [[171, 177], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "", "def", "env_method", "(", "self", ",", "method_name", ":", "str", ",", "*", "method_args", ",", "indices", ":", "VecEnvIndices", "=", "None", ",", "**", "method_kwargs", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "\"\"\"Call instance methods of vectorized environments.\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"env_method\"", ",", "(", "method_name", ",", "method_args", ",", "method_kwargs", ")", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv.env_is_wrapped": [[178, 184], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "env_is_wrapped", "(", "self", ",", "wrapper_class", ":", "Type", "[", "gym", ".", "Wrapper", "]", ",", "indices", ":", "VecEnvIndices", "=", "None", ")", "->", "List", "[", "bool", "]", ":", "\n", "        ", "\"\"\"Check if worker environments are wrapped with a given wrapper\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "\"is_wrapped\"", ",", "wrapper_class", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes": [[185, 195], ["subproc_vec_env.SubprocVecEnv._get_indices"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv._get_indices"], ["", "def", "_get_target_remotes", "(", "self", ",", "indices", ":", "VecEnvIndices", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Get the connection object needed to communicate with the wanted\n        envs that are in subprocesses.\n\n        :param indices: refers to indices of envs.\n        :return: Connection object to communicate between processes.\n        \"\"\"", "\n", "indices", "=", "self", ".", "_get_indices", "(", "indices", ")", "\n", "return", "[", "self", ".", "remotes", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env._worker": [[17, 61], ["parent_remote.close", "env_fn_wrapper.var", "remote.recv", "env_fn_wrapper.var.step", "remote.send", "env_fn_wrapper.var.reset", "remote.send", "env_fn_wrapper.var.seed", "env_fn_wrapper.var.reset", "remote.send", "remote.send", "env_fn_wrapper.var.render", "env_fn_wrapper.var.close", "remote.close", "remote.send", "getattr", "remote.send", "getattr.", "remote.send", "getattr", "remote.send", "setattr", "remote.send", "NotImplementedError", "is_wrapped"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.is_wrapped"], ["def", "_worker", "(", "\n", "remote", ":", "mp", ".", "connection", ".", "Connection", ",", "parent_remote", ":", "mp", ".", "connection", ".", "Connection", ",", "env_fn_wrapper", ":", "CloudpickleWrapper", "\n", ")", "->", "None", ":", "\n", "# Import here to avoid a circular import", "\n", "    ", "from", "gym_optimal_intrusion_response", ".", "agents", ".", "openai_baselines", ".", "common", ".", "env_util", "import", "is_wrapped", "\n", "\n", "parent_remote", ".", "close", "(", ")", "\n", "env", "=", "env_fn_wrapper", ".", "var", "(", ")", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "cmd", ",", "data", "=", "remote", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "\"step\"", ":", "\n", "                ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "\n", "if", "done", ":", "\n", "# save final observation where user can get it, then reset", "\n", "                    ", "info", "[", "\"terminal_observation\"", "]", "=", "observation", "\n", "observation", "=", "env", ".", "reset", "(", ")", "\n", "", "remote", ".", "send", "(", "(", "observation", ",", "reward", ",", "done", ",", "info", ")", ")", "\n", "", "elif", "cmd", "==", "\"seed\"", ":", "\n", "                ", "remote", ".", "send", "(", "env", ".", "seed", "(", "data", ")", ")", "\n", "", "elif", "cmd", "==", "\"reset\"", ":", "\n", "                ", "observation", "=", "env", ".", "reset", "(", ")", "\n", "remote", ".", "send", "(", "observation", ")", "\n", "", "elif", "cmd", "==", "\"render\"", ":", "\n", "                ", "remote", ".", "send", "(", "env", ".", "render", "(", "data", ")", ")", "\n", "", "elif", "cmd", "==", "\"close\"", ":", "\n", "                ", "env", ".", "close", "(", ")", "\n", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "\"get_spaces\"", ":", "\n", "                ", "remote", ".", "send", "(", "(", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", ")", "\n", "", "elif", "cmd", "==", "\"env_method\"", ":", "\n", "                ", "method", "=", "getattr", "(", "env", ",", "data", "[", "0", "]", ")", "\n", "remote", ".", "send", "(", "method", "(", "*", "data", "[", "1", "]", ",", "**", "data", "[", "2", "]", ")", ")", "\n", "", "elif", "cmd", "==", "\"get_attr\"", ":", "\n", "                ", "remote", ".", "send", "(", "getattr", "(", "env", ",", "data", ")", ")", "\n", "", "elif", "cmd", "==", "\"set_attr\"", ":", "\n", "                ", "remote", ".", "send", "(", "setattr", "(", "env", ",", "data", "[", "0", "]", ",", "data", "[", "1", "]", ")", ")", "\n", "", "elif", "cmd", "==", "\"is_wrapped\"", ":", "\n", "                ", "remote", ".", "send", "(", "is_wrapped", "(", "env", ",", "data", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "f\"`{cmd}` is not implemented in the worker\"", ")", "\n", "", "", "except", "EOFError", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.subproc_vec_env._flatten_obs": [[197, 221], ["isinstance", "isinstance", "len", "isinstance", "isinstance", "collections.OrderedDict", "isinstance", "isinstance", "len", "tuple", "numpy.stack", "numpy.stack", "space.spaces.keys", "numpy.stack", "range"], "function", ["None"], ["", "", "def", "_flatten_obs", "(", "obs", ":", "Union", "[", "List", "[", "VecEnvObs", "]", ",", "Tuple", "[", "VecEnvObs", "]", "]", ",", "space", ":", "gym", ".", "spaces", ".", "Space", ")", "->", "VecEnvObs", ":", "\n", "    ", "\"\"\"\n    Flatten observations, depending on the observation space.\n\n    :param obs: observations.\n                A list or tuple of observations, one per environment.\n                Each environment observation may be a NumPy array, or a dict or tuple of NumPy arrays.\n    :return: flattened observations.\n            A flattened NumPy array or an OrderedDict or tuple of flattened numpy arrays.\n            Each NumPy array has the environment index as its first axis.\n    \"\"\"", "\n", "assert", "isinstance", "(", "obs", ",", "(", "list", ",", "tuple", ")", ")", ",", "\"expected list or tuple of observations per environment\"", "\n", "assert", "len", "(", "obs", ")", ">", "0", ",", "\"need observations from at least one environment\"", "\n", "\n", "if", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "        ", "assert", "isinstance", "(", "space", ".", "spaces", ",", "OrderedDict", ")", ",", "\"Dict space must have ordered subspaces\"", "\n", "assert", "isinstance", "(", "obs", "[", "0", "]", ",", "dict", ")", ",", "\"non-dict observation for environment with Dict observation space\"", "\n", "return", "OrderedDict", "(", "[", "(", "k", ",", "np", ".", "stack", "(", "[", "o", "[", "k", "]", "for", "o", "in", "obs", "]", ")", ")", "for", "k", "in", "space", ".", "spaces", ".", "keys", "(", ")", "]", ")", "\n", "", "elif", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "assert", "isinstance", "(", "obs", "[", "0", "]", ",", "tuple", ")", ",", "\"non-tuple observation for environment with Tuple observation space\"", "\n", "obs_len", "=", "len", "(", "space", ".", "spaces", ")", "\n", "return", "tuple", "(", "(", "np", ".", "stack", "(", "[", "o", "[", "i", "]", "for", "o", "in", "obs", "]", ")", "for", "i", "in", "range", "(", "obs_len", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "stack", "(", "obs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.obs_dict_wrapper.ObsDictWrapper.__init__": [[16, 49], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.VecEnvWrapper.__init__", "list", "isinstance", "isinstance", "venv.observation_space.spaces.values", "numpy.concatenate", "numpy.concatenate", "gym.spaces.Box", "isinstance", "gym.spaces.MultiBinary", "isinstance", "gym.spaces.MultiDiscrete", "NotImplementedError", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ")", ":", "\n", "        ", "super", "(", "ObsDictWrapper", ",", "self", ")", ".", "__init__", "(", "venv", ",", "venv", ".", "observation_space", ",", "venv", ".", "action_space", ")", "\n", "\n", "self", ".", "venv", "=", "venv", "\n", "\n", "self", ".", "spaces", "=", "list", "(", "venv", ".", "observation_space", ".", "spaces", ".", "values", "(", ")", ")", "\n", "\n", "# get dimensions of observation and goal", "\n", "if", "isinstance", "(", "self", ".", "spaces", "[", "0", "]", ",", "spaces", ".", "Discrete", ")", ":", "\n", "            ", "self", ".", "obs_dim", "=", "1", "\n", "self", ".", "goal_dim", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "obs_dim", "=", "venv", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "goal_dim", "=", "venv", ".", "observation_space", ".", "spaces", "[", "\"achieved_goal\"", "]", ".", "shape", "[", "0", "]", "\n", "\n", "# new observation space with concatenated observation and (desired) goal", "\n", "# for the different types of spaces", "\n", "", "if", "isinstance", "(", "self", ".", "spaces", "[", "0", "]", ",", "spaces", ".", "Box", ")", ":", "\n", "            ", "low_values", "=", "np", ".", "concatenate", "(", "\n", "[", "venv", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", ".", "low", ",", "venv", ".", "observation_space", ".", "spaces", "[", "\"desired_goal\"", "]", ".", "low", "]", "\n", ")", "\n", "high_values", "=", "np", ".", "concatenate", "(", "\n", "[", "venv", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", ".", "high", ",", "venv", ".", "observation_space", ".", "spaces", "[", "\"desired_goal\"", "]", ".", "high", "]", "\n", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "low_values", ",", "high_values", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "spaces", "[", "0", "]", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "            ", "total_dim", "=", "self", ".", "obs_dim", "+", "self", ".", "goal_dim", "\n", "self", ".", "observation_space", "=", "spaces", ".", "MultiBinary", "(", "total_dim", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "spaces", "[", "0", "]", ",", "spaces", ".", "Discrete", ")", ":", "\n", "            ", "dimensions", "=", "[", "venv", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", ".", "n", ",", "venv", ".", "observation_space", ".", "spaces", "[", "\"desired_goal\"", "]", ".", "n", "]", "\n", "self", ".", "observation_space", "=", "spaces", ".", "MultiDiscrete", "(", "dimensions", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"{type(self.spaces[0])} space is not supported\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.obs_dict_wrapper.ObsDictWrapper.reset": [[50, 52], ["obs_dict_wrapper.ObsDictWrapper.venv.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.obs_dict_wrapper.ObsDictWrapper.step_wait": [[53, 55], ["obs_dict_wrapper.ObsDictWrapper.venv.step_wait"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.obs_dict_wrapper.ObsDictWrapper.convert_dict": [[56, 69], ["numpy.concatenate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_dict", "(", "\n", "observation_dict", ":", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ",", "observation_key", ":", "str", "=", "\"observation\"", ",", "goal_key", ":", "str", "=", "\"desired_goal\"", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Concatenate observation and (desired) goal of observation dict.\n\n        :param observation_dict: Dictionary with observation.\n        :param observation_key: Key of observation in dictionary.\n        :param goal_key: Key of (desired) goal in dictionary.\n        :return: Concatenated observation.\n        \"\"\"", "\n", "return", "np", ".", "concatenate", "(", "[", "observation_dict", "[", "observation_key", "]", ",", "observation_dict", "[", "goal_key", "]", "]", ",", "axis", "=", "-", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.__init__": [[23, 46], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnv.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.util.obs_space_info", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.util.obs_space_info", "collections.OrderedDict", "collections.OrderedDict", "numpy.zeros", "numpy.zeros", "numpy.zeros", "dummy_vec_env.DummyVecEnv.envs.append", "fn", "len", "fn", "range", "numpy.zeros", "numpy.zeros", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.obs_space_info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.obs_space_info"], ["def", "__init__", "(", "self", ",", "env_fns", ":", "List", "[", "Callable", "[", "[", "]", ",", "gym", ".", "Env", "]", "]", ",", "env_config", "=", "None", ")", ":", "\n", "        ", "self", ".", "envs", "=", "[", "]", "\n", "for", "fn", "in", "env_fns", ":", "\n", "            ", "self", ".", "envs", ".", "append", "(", "fn", "(", ")", ")", "\n", "", "self", ".", "envs", "=", "[", "fn", "(", ")", "for", "fn", "in", "env_fns", "]", "\n", "env", "=", "self", ".", "envs", "[", "0", "]", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "env", ".", "attacker_observation_space", ",", "env", ".", "attacker_action_space", ",", "\n", "env", ".", "defender_observation_space", ",", "env", ".", "defender_action_space", ")", "\n", "attacker_obs_space", "=", "env", ".", "attacker_observation_space", "\n", "self", ".", "attacker_keys", ",", "attacker_shapes", ",", "attacker_dtypes", "=", "obs_space_info", "(", "attacker_obs_space", ")", "\n", "defender_obs_space", "=", "env", ".", "defender_observation_space", "\n", "self", ".", "defender_keys", ",", "defender_shapes", ",", "defender_dtypes", "=", "obs_space_info", "(", "defender_obs_space", ")", "\n", "\n", "self", ".", "buf_obs_attacker", "=", "OrderedDict", "(", "[", "(", "k", ",", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", "+", "tuple", "(", "attacker_shapes", "[", "k", "]", ")", ",", "\n", "dtype", "=", "attacker_dtypes", "[", "k", "]", ")", ")", "for", "k", "in", "self", ".", "attacker_keys", "]", ")", "\n", "self", ".", "buf_obs_defender", "=", "OrderedDict", "(", "[", "(", "k", ",", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", "+", "tuple", "(", "defender_shapes", "[", "k", "]", ")", ",", "\n", "dtype", "=", "defender_dtypes", "[", "k", "]", ")", ")", "for", "k", "in", "self", ".", "defender_keys", "]", ")", "\n", "self", ".", "buf_dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "self", ".", "buf_rews_attacker", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "buf_rews_defender", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "buf_infos", "=", "[", "{", "}", "for", "i", "in", "range", "(", "self", ".", "num_envs", ")", "]", "\n", "self", ".", "actions", "=", "None", "\n", "self", ".", "metadata", "=", "env", ".", "metadata", "\n", "#self.initial_illegal_actions = self.envs[0].initial_illegal_actions", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.step_async": [[49, 51], ["None"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.step_wait": [[52, 69], ["range", "dummy_vec_env.DummyVecEnv.envs[].step", "dummy_vec_env.DummyVecEnv._save_obs", "dummy_vec_env.DummyVecEnv._obs_from_buf", "numpy.copy", "copy.deepcopy", "dummy_vec_env.DummyVecEnv.envs[].reset", "numpy.copy", "numpy.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._save_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "for", "env_idx", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "            ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "step", "(", "self", ".", "actions", "[", "env_idx", "]", ")", "\n", "attacker_rew", ",", "defender_rew", "=", "rew", "\n", "self", ".", "buf_rews_attacker", "[", "env_idx", "]", "=", "attacker_rew", "\n", "self", ".", "buf_rews_defender", "[", "env_idx", "]", "=", "defender_rew", "\n", "self", ".", "buf_dones", "[", "env_idx", "]", "=", "done", "\n", "self", ".", "buf_infos", "[", "env_idx", "]", "=", "info", "\n", "#self.buf_infos[env_idx][\"idx\"] = self.envs[env_idx].idx", "\n", "\n", "\n", "if", "self", ".", "buf_dones", "[", "env_idx", "]", ":", "\n", "# save final observation where user can get it, then reset", "\n", "                ", "self", ".", "buf_infos", "[", "env_idx", "]", "[", "\"terminal_observation\"", "]", "=", "obs", "\n", "obs", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "reset", "(", ")", "\n", "", "self", ".", "_save_obs", "(", "env_idx", ",", "obs", ")", "\n", "", "return", "(", "self", ".", "_obs_from_buf", "(", ")", ",", "(", "np", ".", "copy", "(", "self", ".", "buf_rews_attacker", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_rews_defender", ")", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_dones", ")", ",", "deepcopy", "(", "self", ".", "buf_infos", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.seed": [[70, 75], ["list", "enumerate", "list.append", "env.seed"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "seeds", "=", "list", "(", ")", "\n", "for", "idx", ",", "env", "in", "enumerate", "(", "self", ".", "envs", ")", ":", "\n", "            ", "seeds", ".", "append", "(", "env", ".", "seed", "(", "seed", "+", "idx", ")", ")", "\n", "", "return", "seeds", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.reset": [[76, 82], ["range", "dummy_vec_env.DummyVecEnv._obs_from_buf", "dummy_vec_env.DummyVecEnv.envs[].reset", "dummy_vec_env.DummyVecEnv._save_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._save_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "env_idx", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "            ", "obs", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "reset", "(", ")", "\n", "self", ".", "_save_obs", "(", "env_idx", ",", "obs", ")", "\n", "", "o", "=", "self", ".", "_obs_from_buf", "(", ")", "\n", "return", "o", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.close": [[83, 86], ["env.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "env", "in", "self", ".", "envs", ":", "\n", "            ", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.cleanup": [[87, 90], ["env.cleanup"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.cleanup"], ["", "", "def", "cleanup", "(", "self", ")", ":", "\n", "        ", "for", "env", "in", "self", ".", "envs", ":", "\n", "            ", "env", ".", "cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.get_images": [[91, 93], ["env.render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render"], ["", "", "def", "get_images", "(", "self", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "return", "[", "env", ".", "render", "(", "mode", "=", "\"rgb_array\"", ")", "for", "env", "in", "self", ".", "envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.render": [[94, 110], ["dummy_vec_env.DummyVecEnv.envs[].render", "super().render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "\"human\"", ")", ":", "\n", "        ", "\"\"\"\n        Gym environment rendering. If there are multiple environments then\n        they are tiled together in one image via ``BaseVecEnv.render()``.\n        Otherwise (if ``self.num_envs == 1``), we pass the render call directly to the\n        underlying environment.\n\n        Therefore, some arguments such as ``mode`` will have values that are valid\n        only when ``num_envs == 1``.\n\n        :param mode: The rendering type.\n        \"\"\"", "\n", "if", "self", ".", "num_envs", "==", "1", ":", "\n", "            ", "return", "self", ".", "envs", "[", "0", "]", ".", "render", "(", "mode", "=", "mode", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "render", "(", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._save_obs": [[111, 124], ["None"], "methods", ["None"], ["", "", "def", "_save_obs", "(", "self", ",", "env_idx", ",", "obs", ")", ":", "\n", "        ", "obs_attacker", ",", "obs_defender", "=", "obs", "\n", "for", "key", "in", "self", ".", "attacker_keys", ":", "\n", "            ", "if", "key", "is", "None", ":", "\n", "                ", "self", ".", "buf_obs_attacker", "[", "key", "]", "[", "env_idx", "]", "=", "obs_attacker", "\n", "", "else", ":", "\n", "                ", "self", ".", "buf_obs_attacker", "[", "key", "]", "[", "env_idx", "]", "=", "obs_attacker", "[", "key", "]", "\n", "\n", "", "", "for", "key", "in", "self", ".", "defender_keys", ":", "\n", "            ", "if", "key", "is", "None", ":", "\n", "                ", "self", ".", "buf_obs_defender", "[", "key", "]", "[", "env_idx", "]", "=", "obs_defender", "\n", "", "else", ":", "\n", "                ", "self", ".", "buf_obs_defender", "[", "key", "]", "[", "env_idx", "]", "=", "obs_defender", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf": [[126, 130], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.util.dict_to_obs", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.util.dict_to_obs", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.util.copy_obs_dict", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.util.copy_obs_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.dict_to_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.dict_to_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.copy_obs_dict", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.copy_obs_dict"], ["", "", "", "def", "_obs_from_buf", "(", "self", ")", ":", "\n", "        ", "attacker_obs", "=", "dict_to_obs", "(", "self", ".", "attacker_observation_space", ",", "copy_obs_dict", "(", "self", ".", "buf_obs_attacker", ")", ")", "\n", "defender_obs", "=", "dict_to_obs", "(", "self", ".", "defender_observation_space", ",", "copy_obs_dict", "(", "self", ".", "buf_obs_defender", ")", ")", "\n", "return", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.get_attr": [[131, 135], ["dummy_vec_env.DummyVecEnv._get_target_envs", "getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return attribute from vectorized environment (see base class).\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "return", "[", "getattr", "(", "env_i", ",", "attr_name", ")", "for", "env_i", "in", "target_envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.set_attr": [[136, 141], ["dummy_vec_env.DummyVecEnv._get_target_envs", "setattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Set attribute inside vectorized environments (see base class).\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "for", "env_i", "in", "target_envs", ":", "\n", "            ", "setattr", "(", "env_i", ",", "attr_name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.env_method": [[142, 146], ["dummy_vec_env.DummyVecEnv._get_target_envs", "getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "        ", "\"\"\"Call instance methods of vectorized environments.\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "return", "[", "getattr", "(", "env_i", ",", "method_name", ")", "(", "*", "method_args", ",", "**", "method_kwargs", ")", "for", "env_i", "in", "target_envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs": [[147, 150], ["dummy_vec_env.DummyVecEnv._get_indices"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv._get_indices"], ["", "def", "_get_target_envs", "(", "self", ",", "indices", ")", ":", "\n", "        ", "indices", "=", "self", ".", "_get_indices", "(", "indices", ")", "\n", "return", "[", "self", ".", "envs", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.env_is_wrapped": [[151, 158], ["dummy_vec_env.DummyVecEnv._get_target_envs", "env_util.is_wrapped"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.env_util.is_wrapped"], ["", "def", "env_is_wrapped", "(", "self", ",", "wrapper_class", ",", "indices", ")", "->", "List", "[", "bool", "]", ":", "\n", "        ", "\"\"\"Check if worker environments are wrapped with a given wrapper\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "# Import here to avoid a circular import", "\n", "from", "gym_optimal_intrusion_response", ".", "agents", ".", "openai_baselines", ".", "common", "import", "env_util", "\n", "\n", "return", "[", "env_util", ".", "is_wrapped", "(", "env_i", ",", "wrapper_class", ")", "for", "env_i", "in", "target_envs", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.__init__": [[59, 68], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_envs", ":", "int", ",", "attacker_observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "attacker_action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "defender_observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "defender_action_space", ":", "gym", ".", "spaces", ".", "Space", ")", ":", "\n", "        ", "self", ".", "num_envs", "=", "num_envs", "\n", "self", ".", "attacker_observation_space", "=", "attacker_observation_space", "\n", "self", ".", "attacker_action_space", "=", "attacker_action_space", "\n", "self", ".", "defender_observation_space", "=", "defender_observation_space", "\n", "self", ".", "defender_action_space", "=", "defender_action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.reset": [[69, 82], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", "->", "VecEnvObs", ":", "\n", "        ", "\"\"\"\n        Reset all the environments and return an array of\n        observations, or a tuple of observation arrays.\n\n        If step_async is still doing work, that work will\n        be cancelled and step_wait() should not be called\n        until step_async() is invoked again.\n\n        :return: (VecEnvObs) observation\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.step_async": [[83, 94], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_async", "(", "self", ",", "actions", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Tell all the environments to start taking a step\n        with the given actions.\n        Call step_wait() to get the results of the step.\n\n        You should not call this if a step_async run is\n        already pending.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.step_wait": [[95, 103], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "\"\"\"\n        Wait for the step taken with step_async().\n\n        :return: observation, reward, done, information\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.close": [[104, 110], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Clean up the environment's resources.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.get_attr": [[111, 121], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_attr", "(", "self", ",", "attr_name", ":", "str", ",", "indices", ":", "\"VecEnvIndices\"", "=", "None", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Return attribute from vectorized environment.\n\n        :param attr_name: (str) The name of the attribute whose value to return\n        :param indices: (list,int) Indices of envs to get attribute from\n        :return: (list) List of values of 'attr_name' in all environments\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.set_attr": [[122, 133], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_attr", "(", "self", ",", "attr_name", ":", "str", ",", "value", ":", "Any", ",", "indices", ":", "\"VecEnvIndices\"", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set attribute inside vectorized environments.\n\n        :param attr_name: (str) The name of attribute to assign new value\n        :param value: (obj) Value to assign to `attr_name`\n        :param indices: (list,int) Indices of envs to assign value\n        :return: (NoneType)\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.env_method": [[134, 146], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "env_method", "(", "self", ",", "method_name", ":", "str", ",", "*", "method_args", ",", "indices", ":", "\"VecEnvIndices\"", "=", "None", ",", "**", "method_kwargs", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Call instance methods of vectorized environments.\n\n        :param method_name: (str) The name of the environment method to invoke.\n        :param indices: (list,int) Indices of envs whose method to call\n        :param method_args: (tuple) Any positional arguments to provide in the call\n        :param method_kwargs: (dict) Any keyword arguments to provide in the call\n        :return: (list) List of items returned by the environment's method call\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.step": [[147, 156], ["base_vec_env.VecEnv.step_async", "base_vec_env.VecEnv.step_wait"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.step_async", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait"], ["", "def", "step", "(", "self", ",", "actions", ":", "np", ".", "ndarray", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "\"\"\"\n        Step the environments with the given action\n\n        :param actions: (np.ndarray) the action\n        :return: (VecEnvStepReturn) observation, reward, done, information\n        \"\"\"", "\n", "self", ".", "step_async", "(", "actions", ")", "\n", "return", "self", ".", "step_wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.get_images": [[157, 162], ["None"], "methods", ["None"], ["", "def", "get_images", "(", "self", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Return RGB images from each environment\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.render": [[163, 186], ["base_vec_env.tile_images", "base_vec_env.VecEnv.get_images", "cv2.imshow", "cv2.waitKey", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.warn", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.tile_images", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.get_images", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "\"human\"", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Gym environment rendering\n\n        :param mode: the rendering type\n        \"\"\"", "\n", "try", ":", "\n", "            ", "imgs", "=", "self", ".", "get_images", "(", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "            ", "logger", ".", "warn", "(", "f\"Render not defined for {self}\"", ")", "\n", "return", "\n", "\n", "# Create a big image by tiling images from subprocesses", "\n", "", "bigimg", "=", "tile_images", "(", "imgs", ")", "\n", "if", "mode", "==", "\"human\"", ":", "\n", "            ", "import", "cv2", "# pytype:disable=import-error", "\n", "\n", "cv2", ".", "imshow", "(", "\"vecenv\"", ",", "bigimg", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "cv2", ".", "waitKey", "(", "1", ")", "\n", "", "elif", "mode", "==", "\"rgb_array\"", ":", "\n", "            ", "return", "bigimg", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Render mode {mode} is not supported by VecEnvs\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.seed": [[187, 198], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "List", "[", "Union", "[", "None", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Sets the random seeds for all environments, based on a given seed.\n        Each individual environment will still get its own seed, by incrementing the given seed.\n\n        :param seed: (Optional[int]) The random seed. May be None for completely random seeding.\n        :return: (List[Union[None, int]]) Returns a list containing the seeds for each individual env.\n            Note that all list elements may be None, if the env does not return anything when being seeded.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.unwrapped": [[199, 205], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "unwrapped", "(", "self", ")", "->", "\"VecEnv\"", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "VecEnvWrapper", ")", ":", "\n", "            ", "return", "self", ".", "venv", ".", "unwrapped", "\n", "", "else", ":", "\n", "            ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv.getattr_depth_check": [[206, 217], ["hasattr", "type", "type"], "methods", ["None"], ["", "", "def", "getattr_depth_check", "(", "self", ",", "name", ":", "str", ",", "already_found", ":", "bool", ")", "->", "Optional", "[", "str", "]", ":", "\n", "        ", "\"\"\"Check if an attribute reference is being hidden in a recursive call to __getattr__\n\n        :param name: (str) name of attribute to check for\n        :param already_found: (bool) whether this attribute has already been found in a wrapper\n        :return: (Optional[str]) name of module whose attribute is being shadowed, if any.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "name", ")", "and", "already_found", ":", "\n", "            ", "return", "f\"{type(self).__module__}.{type(self).__name__}\"", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnv._get_indices": [[218, 230], ["range", "isinstance"], "methods", ["None"], ["", "", "def", "_get_indices", "(", "self", ",", "indices", ":", "\"VecEnvIndices\"", ")", "->", "Iterable", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Convert a flexibly-typed reference to environment indices to an implied list of indices.\n\n        :param indices: (None,int,Iterable) refers to indices of envs.\n        :return: (list) the implied list of indices.\n        \"\"\"", "\n", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "range", "(", "self", ".", "num_envs", ")", "\n", "", "elif", "isinstance", "(", "indices", ",", "int", ")", ":", "\n", "            ", "indices", "=", "[", "indices", "]", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.__init__": [[241, 255], ["base_vec_env.VecEnv.__init__", "dict", "inspect.getmembers"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "venv", ":", "VecEnv", ",", "\n", "attacker_observation_space", ":", "Optional", "[", "gym", ".", "spaces", ".", "Space", "]", "=", "None", ",", "\n", "attacker_action_space", ":", "Optional", "[", "gym", ".", "spaces", ".", "Space", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "VecEnv", ".", "__init__", "(", "\n", "self", ",", "\n", "num_envs", "=", "venv", ".", "num_envs", ",", "\n", "attacker_observation_space", "=", "attacker_observation_space", "or", "venv", ".", "attacker_observation_space", ",", "\n", "attacker_action_space", "=", "attacker_action_space", "or", "venv", ".", "attacker_action_space", ",", "\n", ")", "\n", "self", ".", "class_attributes", "=", "dict", "(", "inspect", ".", "getmembers", "(", "self", ".", "__class__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.step_async": [[256, 258], ["base_vec_env.VecEnvWrapper.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.reset": [[259, 262], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", "->", "VecEnvObs", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.step_wait": [[263, 266], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed": [[267, 269], ["base_vec_env.VecEnvWrapper.venv.seed"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.close": [[270, 272], ["base_vec_env.VecEnvWrapper.venv.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "return", "self", ".", "venv", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render": [[273, 275], ["base_vec_env.VecEnvWrapper.venv.render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.render"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "\"human\"", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "return", "self", ".", "venv", ".", "render", "(", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.get_images": [[276, 278], ["base_vec_env.VecEnvWrapper.venv.get_images"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.get_images"], ["", "def", "get_images", "(", "self", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.get_attr": [[279, 281], ["base_vec_env.VecEnvWrapper.venv.get_attr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.get_attr"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_attr", "(", "attr_name", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.set_attr": [[282, 284], ["base_vec_env.VecEnvWrapper.venv.set_attr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.set_attr"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "set_attr", "(", "attr_name", ",", "value", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.env_method": [[285, 287], ["base_vec_env.VecEnvWrapper.venv.env_method"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.env_method"], ["", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "env_method", "(", "method_name", ",", "*", "method_args", ",", "indices", "=", "indices", ",", "**", "method_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.__getattr__": [[288, 303], ["base_vec_env.VecEnvWrapper.getattr_depth_check", "base_vec_env.VecEnvWrapper.getattr_recursive", "AttributeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_recursive"], ["", "def", "__getattr__", "(", "self", ",", "name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "\"\"\"Find attribute from wrapped venv(s) if this wrapper does not have it.\n        Useful for accessing attributes from venvs which are wrapped with multiple wrappers\n        which have unique attributes of interest.\n        \"\"\"", "\n", "blocked_class", "=", "self", ".", "getattr_depth_check", "(", "name", ",", "already_found", "=", "False", ")", "\n", "if", "blocked_class", "is", "not", "None", ":", "\n", "            ", "own_class", "=", "f\"{type(self).__module__}.{type(self).__name__}\"", "\n", "error_str", "=", "(", "\n", "f\"Error: Recursive attribute lookup for {name} from {own_class} is \"", "\n", "\"ambiguous and hides attribute from {blocked_class}\"", "\n", ")", "\n", "raise", "AttributeError", "(", "error_str", ")", "\n", "\n", "", "return", "self", ".", "getattr_recursive", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper._get_all_attributes": [[304, 312], ["base_vec_env.VecEnvWrapper.__dict__.copy", "base_vec_env.VecEnvWrapper.update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update"], ["", "def", "_get_all_attributes", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Get all (inherited) instance and class attributes\n\n        :return: (Dict[str, Any]) all_attributes\n        \"\"\"", "\n", "all_attributes", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "all_attributes", ".", "update", "(", "self", ".", "class_attributes", ")", "\n", "return", "all_attributes", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_recursive": [[313, 330], ["base_vec_env.VecEnvWrapper._get_all_attributes", "getattr", "hasattr", "base_vec_env.VecEnvWrapper.venv.getattr_recursive", "getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper._get_all_attributes", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_recursive"], ["", "def", "getattr_recursive", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "        ", "\"\"\"Recursively check wrappers to find attribute.\n\n        :param name (str) name of attribute to look for\n        :return: (object) attribute\n        \"\"\"", "\n", "all_attributes", "=", "self", ".", "_get_all_attributes", "(", ")", "\n", "if", "name", "in", "all_attributes", ":", "# attribute is present in this wrapper", "\n", "            ", "attr", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "elif", "hasattr", "(", "self", ".", "venv", ",", "\"getattr_recursive\"", ")", ":", "\n", "# Attribute not present, child is wrapper. Call getattr_recursive rather than getattr", "\n", "# to avoid a duplicate call to getattr_depth_check.", "\n", "            ", "attr", "=", "self", ".", "venv", ".", "getattr_recursive", "(", "name", ")", "\n", "", "else", ":", "# attribute not present, child is an unwrapped VecEnv", "\n", "            ", "attr", "=", "getattr", "(", "self", ".", "venv", ",", "name", ")", "\n", "\n", "", "return", "attr", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check": [[331, 348], ["base_vec_env.VecEnvWrapper._get_all_attributes", "base_vec_env.VecEnvWrapper.venv.getattr_depth_check", "base_vec_env.VecEnvWrapper.venv.getattr_depth_check", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper._get_all_attributes", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check"], ["", "def", "getattr_depth_check", "(", "self", ",", "name", ":", "str", ",", "already_found", ":", "bool", ")", ":", "\n", "        ", "\"\"\"See base class.\n\n        :return: (str or None) name of module whose attribute is being shadowed, if any.\n        \"\"\"", "\n", "all_attributes", "=", "self", ".", "_get_all_attributes", "(", ")", "\n", "if", "name", "in", "all_attributes", "and", "already_found", ":", "\n", "# this venv's attribute is being hidden because of a higher venv.", "\n", "            ", "shadowed_wrapper_class", "=", "f\"{type(self).__module__}.{type(self).__name__}\"", "\n", "", "elif", "name", "in", "all_attributes", "and", "not", "already_found", ":", "\n", "# we have found the first reference to the attribute. Now check for duplicates.", "\n", "            ", "shadowed_wrapper_class", "=", "self", ".", "venv", ".", "getattr_depth_check", "(", "name", ",", "True", ")", "\n", "", "else", ":", "\n", "# this wrapper does not have the attribute. Keep searching.", "\n", "            ", "shadowed_wrapper_class", "=", "self", ".", "venv", ".", "getattr_depth_check", "(", "name", ",", "already_found", ")", "\n", "\n", "", "return", "shadowed_wrapper_class", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.CloudpickleWrapper.__init__": [[357, 359], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "var", ":", "Any", ")", ":", "\n", "        ", "self", ".", "var", "=", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.CloudpickleWrapper.__getstate__": [[360, 362], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", "->", "Any", ":", "\n", "        ", "return", "cloudpickle", ".", "dumps", "(", "self", ".", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.CloudpickleWrapper.__setstate__": [[363, 365], ["cloudpickle.loads"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "var", ":", "Any", ")", "->", "None", ":", "\n", "        ", "self", ".", "var", "=", "cloudpickle", ".", "loads", "(", "var", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.tile_images": [[22, 46], ["numpy.asarray", "int", "int", "numpy.array", "np.array.reshape", "out_image.reshape.transpose", "out_image.reshape.reshape", "numpy.ceil", "numpy.ceil", "numpy.sqrt", "list", "float", "range"], "function", ["None"], ["def", "tile_images", "(", "img_nhwc", ":", "Sequence", "[", "np", ".", "ndarray", "]", ")", "->", "np", ".", "ndarray", ":", "# pragma: no cover", "\n", "    ", "\"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n\n    :param img_nhwc: (Sequence[np.ndarray]) list or array of images, ndim=4 once turned into array. img nhwc\n        n = batch index, h = height, w = width, c = channel\n    :return: (np.ndarray) img_HWc, ndim=3\n    \"\"\"", "\n", "img_nhwc", "=", "np", ".", "asarray", "(", "img_nhwc", ")", "\n", "n_images", ",", "height", ",", "width", ",", "n_channels", "=", "img_nhwc", ".", "shape", "\n", "# new_height was named H before", "\n", "new_height", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_images", ")", ")", ")", "\n", "# new_width was named W before", "\n", "new_width", "=", "int", "(", "np", ".", "ceil", "(", "float", "(", "n_images", ")", "/", "new_height", ")", ")", "\n", "img_nhwc", "=", "np", ".", "array", "(", "list", "(", "img_nhwc", ")", "+", "[", "img_nhwc", "[", "0", "]", "*", "0", "for", "_", "in", "range", "(", "n_images", ",", "new_height", "*", "new_width", ")", "]", ")", "\n", "# img_HWhwc", "\n", "out_image", "=", "img_nhwc", ".", "reshape", "(", "(", "new_height", ",", "new_width", ",", "height", ",", "width", ",", "n_channels", ")", ")", "\n", "# img_HhWwc", "\n", "out_image", "=", "out_image", ".", "transpose", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "# img_Hh_Ww_c", "\n", "out_image", "=", "out_image", ".", "reshape", "(", "(", "new_height", "*", "height", ",", "new_width", "*", "width", ",", "n_channels", ")", ")", "\n", "return", "out_image", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.__init__": [[16, 21], ["gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.is_image_space", "vec_transpose.VecTransposeImage.transpose_space", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_space", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ")", ":", "\n", "        ", "assert", "is_image_space", "(", "venv", ".", "observation_space", ")", ",", "\"The observation space must be an image\"", "\n", "\n", "observation_space", "=", "self", ".", "transpose_space", "(", "venv", ".", "observation_space", ")", "\n", "super", "(", "VecTransposeImage", ",", "self", ")", ".", "__init__", "(", "venv", ",", "observation_space", "=", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_space": [[22, 34], ["gym_optimal_intrusion_response.agents.openai_baselines.common.preprocessing.is_image_space", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.preprocessing.is_image_space"], ["", "@", "staticmethod", "\n", "def", "transpose_space", "(", "observation_space", ":", "spaces", ".", "Box", ")", "->", "spaces", ".", "Box", ":", "\n", "        ", "\"\"\"\n        Transpose an observation space (re-order channels).\n\n        :param observation_space:\n        :return:\n        \"\"\"", "\n", "assert", "is_image_space", "(", "observation_space", ")", ",", "\"The observation space must be an image\"", "\n", "width", ",", "height", ",", "channels", "=", "observation_space", ".", "shape", "\n", "new_shape", "=", "(", "channels", ",", "width", ",", "height", ")", "\n", "return", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "new_shape", ",", "dtype", "=", "observation_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_image": [[35, 46], ["numpy.transpose", "len", "numpy.transpose"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "transpose_image", "(", "image", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Transpose an image or batch of images (re-order channels).\n\n        :param image:\n        :return:\n        \"\"\"", "\n", "if", "len", "(", "image", ".", "shape", ")", "==", "3", ":", "\n", "            ", "return", "np", ".", "transpose", "(", "image", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "return", "np", ".", "transpose", "(", "image", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.step_wait": [[47, 58], ["vec_transpose.VecTransposeImage.venv.step_wait", "enumerate", "vec_transpose.VecTransposeImage.transpose_image", "vec_transpose.VecTransposeImage.transpose_image"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_image", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_image"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "observations", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n", "# Transpose the terminal observations", "\n", "for", "idx", ",", "done", "in", "enumerate", "(", "dones", ")", ":", "\n", "            ", "if", "not", "done", ":", "\n", "                ", "continue", "\n", "", "if", "\"terminal_observation\"", "in", "infos", "[", "idx", "]", ":", "\n", "                ", "infos", "[", "idx", "]", "[", "\"terminal_observation\"", "]", "=", "self", ".", "transpose_image", "(", "infos", "[", "idx", "]", "[", "\"terminal_observation\"", "]", ")", "\n", "\n", "", "", "return", "self", ".", "transpose_image", "(", "observations", ")", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.reset": [[59, 64], ["vec_transpose.VecTransposeImage.transpose_image", "vec_transpose.VecTransposeImage.venv.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.transpose_image", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "return", "self", ".", "transpose_image", "(", "self", ".", "venv", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_transpose.VecTransposeImage.close": [[65, 67], ["vec_transpose.VecTransposeImage.venv.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "venv", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.__init__": [[26, 66], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "isinstance", "os.path.abspath", "os.makedirs", "isinstance", "isinstance", "temp_env.get_attr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.get_attr"], ["def", "__init__", "(", "\n", "self", ",", "\n", "venv", ":", "VecEnv", ",", "\n", "video_folder", ":", "str", ",", "\n", "record_video_trigger", ":", "Callable", "[", "[", "int", "]", ",", "bool", "]", ",", "\n", "video_length", ":", "int", "=", "200", ",", "\n", "name_prefix", ":", "str", "=", "\"rl-video\"", ",", "\n", ")", ":", "\n", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "\n", "self", ".", "env", "=", "venv", "\n", "# Temp variable to retrieve metadata", "\n", "temp_env", "=", "venv", "\n", "\n", "# Unwrap to retrieve metadata dict", "\n", "# that will be used by gym recorder", "\n", "while", "isinstance", "(", "temp_env", ",", "VecEnvWrapper", ")", ":", "\n", "            ", "temp_env", "=", "temp_env", ".", "venv", "\n", "\n", "", "if", "isinstance", "(", "temp_env", ",", "DummyVecEnv", ")", "or", "isinstance", "(", "temp_env", ",", "SubprocVecEnv", ")", ":", "\n", "            ", "metadata", "=", "temp_env", ".", "get_attr", "(", "\"metadata\"", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "metadata", "=", "temp_env", ".", "metadata", "\n", "\n", "", "self", ".", "env", ".", "metadata", "=", "metadata", "\n", "\n", "self", ".", "record_video_trigger", "=", "record_video_trigger", "\n", "self", ".", "video_recorder", "=", "None", "\n", "\n", "self", ".", "video_folder", "=", "os", ".", "path", ".", "abspath", "(", "video_folder", ")", "\n", "# Create output folder if needed", "\n", "os", ".", "makedirs", "(", "self", ".", "video_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "name_prefix", "=", "name_prefix", "\n", "self", ".", "step_id", "=", "0", "\n", "self", ".", "video_length", "=", "video_length", "\n", "\n", "self", ".", "recording", "=", "False", "\n", "self", ".", "recorded_frames", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.reset": [[67, 71], ["vec_video_recorder.VecVideoRecorder.venv.reset", "vec_video_recorder.VecVideoRecorder.start_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder"], ["", "def", "reset", "(", "self", ")", "->", "VecEnvObs", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "start_video_recorder", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder": [[72, 84], ["vec_video_recorder.VecVideoRecorder.close_video_recorder", "os.path.join", "gym.wrappers.monitoring.video_recorder.VideoRecorder", "vec_video_recorder.VecVideoRecorder.video_recorder.capture_frame"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder"], ["", "def", "start_video_recorder", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "close_video_recorder", "(", ")", "\n", "\n", "video_name", "=", "f\"{self.name_prefix}-step-{self.step_id}-to-step-{self.step_id + self.video_length}\"", "\n", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "video_folder", ",", "video_name", ")", "\n", "self", ".", "video_recorder", "=", "video_recorder", ".", "VideoRecorder", "(", "\n", "env", "=", "self", ".", "env", ",", "base_path", "=", "base_path", ",", "metadata", "=", "{", "\"step_id\"", ":", "self", ".", "step_id", "}", "\n", ")", "\n", "\n", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "self", ".", "recorded_frames", "=", "1", "\n", "self", ".", "recording", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder._video_enabled": [[85, 87], ["vec_video_recorder.VecVideoRecorder.record_video_trigger"], "methods", ["None"], ["", "def", "_video_enabled", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "record_video_trigger", "(", "self", ".", "step_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.step_wait": [[88, 102], ["vec_video_recorder.VecVideoRecorder.venv.step_wait", "vec_video_recorder.VecVideoRecorder.video_recorder.capture_frame", "vec_video_recorder.VecVideoRecorder._video_enabled", "gym_optimal_intrusion_response.agents.openai_baselines.common.logger.info", "vec_video_recorder.VecVideoRecorder.close_video_recorder", "vec_video_recorder.VecVideoRecorder.start_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder._video_enabled", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n", "self", ".", "step_id", "+=", "1", "\n", "if", "self", ".", "recording", ":", "\n", "            ", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "self", ".", "recorded_frames", "+=", "1", "\n", "if", "self", ".", "recorded_frames", ">", "self", ".", "video_length", ":", "\n", "                ", "logger", ".", "info", "(", "\"Saving video to \"", ",", "self", ".", "video_recorder", ".", "path", ")", "\n", "self", ".", "close_video_recorder", "(", ")", "\n", "", "", "elif", "self", ".", "_video_enabled", "(", ")", ":", "\n", "            ", "self", ".", "start_video_recorder", "(", ")", "\n", "\n", "", "return", "obs", ",", "rews", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder": [[103, 108], ["vec_video_recorder.VecVideoRecorder.video_recorder.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close_video_recorder", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "recording", ":", "\n", "            ", "self", ".", "video_recorder", ".", "close", "(", ")", "\n", "", "self", ".", "recording", "=", "False", "\n", "self", ".", "recorded_frames", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.close": [[109, 112], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.close", "vec_video_recorder.VecVideoRecorder.close_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "VecEnvWrapper", ".", "close", "(", "self", ")", "\n", "self", ".", "close_video_recorder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_video_recorder.VecVideoRecorder.__del__": [[113, 115], ["vec_video_recorder.VecVideoRecorder.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.__init__": [[28, 65], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "isinstance", "isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.running_mean_std.RunningMeanStd", "numpy.zeros", "numpy.array", "numpy.array", "set", "gym_optimal_intrusion_response.agents.openai_baselines.common.running_mean_std.RunningMeanStd", "vec_normalize.VecNormalize.observation_space.spaces.keys", "gym_optimal_intrusion_response.agents.openai_baselines.common.running_mean_std.RunningMeanStd", "vec_normalize.VecNormalize.obs_spaces.items"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "venv", ":", "VecEnv", ",", "\n", "training", ":", "bool", "=", "True", ",", "\n", "norm_obs", ":", "bool", "=", "True", ",", "\n", "norm_reward", ":", "bool", "=", "True", ",", "\n", "clip_obs", ":", "float", "=", "10.0", ",", "\n", "clip_reward", ":", "float", "=", "10.0", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "epsilon", ":", "float", "=", "1e-8", ",", "\n", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "\n", "assert", "isinstance", "(", "\n", "self", ".", "observation_space", ",", "(", "gym", ".", "spaces", ".", "Box", ",", "gym", ".", "spaces", ".", "Dict", ")", "\n", ")", ",", "\"VecNormalize only support `gym.spaces.Box` and `gym.spaces.Dict` observation spaces\"", "\n", "\n", "if", "isinstance", "(", "self", ".", "observation_space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "            ", "self", ".", "obs_keys", "=", "set", "(", "self", ".", "observation_space", ".", "spaces", ".", "keys", "(", ")", ")", "\n", "self", ".", "obs_spaces", "=", "self", ".", "observation_space", ".", "spaces", "\n", "self", ".", "obs_rms", "=", "{", "key", ":", "RunningMeanStd", "(", "shape", "=", "space", ".", "shape", ")", "for", "key", ",", "space", "in", "self", ".", "obs_spaces", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "obs_keys", ",", "self", ".", "obs_spaces", "=", "None", ",", "None", "\n", "self", ".", "obs_rms", "=", "RunningMeanStd", "(", "shape", "=", "self", ".", "observation_space", ".", "shape", ")", "\n", "\n", "", "self", ".", "ret_rms", "=", "RunningMeanStd", "(", "shape", "=", "(", ")", ")", "\n", "self", ".", "clip_obs", "=", "clip_obs", "\n", "self", ".", "clip_reward", "=", "clip_reward", "\n", "# Returns: discounted rewards", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "norm_obs", "=", "norm_obs", "\n", "self", ".", "norm_reward", "=", "norm_reward", "\n", "self", ".", "old_obs", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "self", ".", "old_reward", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.__getstate__": [[66, 78], ["vec_normalize.VecNormalize.__dict__.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "__getstate__", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Gets state for pickling.\n\n        Excludes self.venv, as in general VecEnv's may not be pickleable.\"\"\"", "\n", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "# these attributes are not pickleable", "\n", "del", "state", "[", "\"venv\"", "]", "\n", "del", "state", "[", "\"class_attributes\"", "]", "\n", "# these attributes depend on the above and so we would prefer not to pickle", "\n", "del", "state", "[", "\"ret\"", "]", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.__setstate__": [[79, 89], ["vec_normalize.VecNormalize.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update"], ["", "def", "__setstate__", "(", "self", ",", "state", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Restores pickled state.\n\n        User must call set_venv() after unpickling before using.\n\n        :param state:\"\"\"", "\n", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "assert", "\"venv\"", "not", "in", "state", "\n", "self", ".", "venv", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.set_venv": [[90, 105], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.check_for_correct_spaces", "numpy.zeros", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.check_for_correct_spaces"], ["", "def", "set_venv", "(", "self", ",", "venv", ":", "VecEnv", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the vector environment to wrap to venv.\n\n        Also sets attributes derived from this such as `num_env`.\n\n        :param venv:\n        \"\"\"", "\n", "if", "self", ".", "venv", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Trying to set venv of already initialized VecNormalize wrapper.\"", ")", "\n", "", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "\n", "# Check only that the observation_space match", "\n", "utils", ".", "check_for_correct_spaces", "(", "venv", ",", "self", ".", "observation_space", ",", "venv", ".", "action_space", ")", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.step_wait": [[106, 139], ["vec_normalize.VecNormalize.venv.step_wait", "vec_normalize.VecNormalize.normalize_obs", "vec_normalize.VecNormalize.normalize_reward", "enumerate", "vec_normalize.VecNormalize._update_reward", "isinstance", "isinstance", "vec_normalize.VecNormalize.obs_rms.keys", "vec_normalize.VecNormalize.obs_rms.update", "vec_normalize.VecNormalize.normalize_obs", "vec_normalize.VecNormalize.obs_rms[].update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_reward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._update_reward", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "\"\"\"\n        Apply sequence of actions to sequence of environments\n        actions -> (observations, rewards, dones)\n\n        where ``dones`` is a boolean vector indicating whether each element is new.\n        \"\"\"", "\n", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "old_obs", "=", "obs", "\n", "self", ".", "old_reward", "=", "rewards", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "isinstance", "(", "obs", ",", "dict", ")", "and", "isinstance", "(", "self", ".", "obs_rms", ",", "dict", ")", ":", "\n", "                ", "for", "key", "in", "self", ".", "obs_rms", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "obs_rms", "[", "key", "]", ".", "update", "(", "obs", "[", "key", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "obs_rms", ".", "update", "(", "obs", ")", "\n", "\n", "", "", "obs", "=", "self", ".", "normalize_obs", "(", "obs", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "_update_reward", "(", "rewards", ")", "\n", "", "rewards", "=", "self", ".", "normalize_reward", "(", "rewards", ")", "\n", "\n", "# Normalize the terminal observations", "\n", "for", "idx", ",", "done", "in", "enumerate", "(", "dones", ")", ":", "\n", "            ", "if", "not", "done", ":", "\n", "                ", "continue", "\n", "", "if", "\"terminal_observation\"", "in", "infos", "[", "idx", "]", ":", "\n", "                ", "infos", "[", "idx", "]", "[", "\"terminal_observation\"", "]", "=", "self", ".", "normalize_obs", "(", "infos", "[", "idx", "]", "[", "\"terminal_observation\"", "]", ")", "\n", "\n", "", "", "self", ".", "ret", "[", "dones", "]", "=", "0", "\n", "return", "obs", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._update_reward": [[140, 144], ["vec_normalize.VecNormalize.ret_rms.update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update"], ["", "def", "_update_reward", "(", "self", ",", "reward", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "\"\"\"Update reward normalization statistics.\"\"\"", "\n", "self", ".", "ret", "=", "self", ".", "ret", "*", "self", ".", "gamma", "+", "reward", "\n", "self", ".", "ret_rms", ".", "update", "(", "self", ".", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._normalize_obs": [[145, 153], ["numpy.clip", "numpy.sqrt"], "methods", ["None"], ["", "def", "_normalize_obs", "(", "self", ",", "obs", ":", "np", ".", "ndarray", ",", "obs_rms", ":", "RunningMeanStd", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Helper to normalize observation.\n        :param obs:\n        :param obs_rms: associated statistics\n        :return: normalized observation\n        \"\"\"", "\n", "return", "np", ".", "clip", "(", "(", "obs", "-", "obs_rms", ".", "mean", ")", "/", "np", ".", "sqrt", "(", "obs_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._unnormalize_obs": [[154, 162], ["numpy.sqrt"], "methods", ["None"], ["", "def", "_unnormalize_obs", "(", "self", ",", "obs", ":", "np", ".", "ndarray", ",", "obs_rms", ":", "RunningMeanStd", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Helper to unnormalize observation.\n        :param obs:\n        :param obs_rms: associated statistics\n        :return: unnormalized observation\n        \"\"\"", "\n", "return", "(", "obs", "*", "np", ".", "sqrt", "(", "obs_rms", ".", "var", "+", "self", ".", "epsilon", ")", ")", "+", "obs_rms", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_obs": [[163, 177], ["copy.deepcopy", "isinstance", "isinstance", "vec_normalize.VecNormalize.obs_rms.keys", "vec_normalize.VecNormalize._normalize_obs().astype", "vec_normalize.VecNormalize._normalize_obs().astype", "vec_normalize.VecNormalize._normalize_obs", "vec_normalize.VecNormalize._normalize_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._normalize_obs"], ["", "def", "normalize_obs", "(", "self", ",", "obs", ":", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Normalize observations using this VecNormalize's observations statistics.\n        Calling this method does not update statistics.\n        \"\"\"", "\n", "# Avoid modifying by reference the original object", "\n", "obs_", "=", "deepcopy", "(", "obs", ")", "\n", "if", "self", ".", "norm_obs", ":", "\n", "            ", "if", "isinstance", "(", "obs", ",", "dict", ")", "and", "isinstance", "(", "self", ".", "obs_rms", ",", "dict", ")", ":", "\n", "                ", "for", "key", "in", "self", ".", "obs_rms", ".", "keys", "(", ")", ":", "\n", "                    ", "obs_", "[", "key", "]", "=", "self", ".", "_normalize_obs", "(", "obs", "[", "key", "]", ",", "self", ".", "obs_rms", "[", "key", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "", "else", ":", "\n", "                ", "obs_", "=", "self", ".", "_normalize_obs", "(", "obs", ",", "self", ".", "obs_rms", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "", "return", "obs_", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_reward": [[178, 186], ["numpy.clip", "numpy.sqrt"], "methods", ["None"], ["", "def", "normalize_reward", "(", "self", ",", "reward", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Normalize rewards using this VecNormalize's rewards statistics.\n        Calling this method does not update statistics.\n        \"\"\"", "\n", "if", "self", ".", "norm_reward", ":", "\n", "            ", "reward", "=", "np", ".", "clip", "(", "reward", "/", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clip_reward", ",", "self", ".", "clip_reward", ")", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.unnormalize_obs": [[187, 197], ["copy.deepcopy", "isinstance", "isinstance", "vec_normalize.VecNormalize.obs_rms.keys", "vec_normalize.VecNormalize._unnormalize_obs", "vec_normalize.VecNormalize._unnormalize_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._unnormalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._unnormalize_obs"], ["", "def", "unnormalize_obs", "(", "self", ",", "obs", ":", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "# Avoid modifying by reference the original object", "\n", "        ", "obs_", "=", "deepcopy", "(", "obs", ")", "\n", "if", "self", ".", "norm_obs", ":", "\n", "            ", "if", "isinstance", "(", "obs", ",", "dict", ")", "and", "isinstance", "(", "self", ".", "obs_rms", ",", "dict", ")", ":", "\n", "                ", "for", "key", "in", "self", ".", "obs_rms", ".", "keys", "(", ")", ":", "\n", "                    ", "obs_", "[", "key", "]", "=", "self", ".", "_unnormalize_obs", "(", "obs", "[", "key", "]", ",", "self", ".", "obs_rms", "[", "key", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "obs_", "=", "self", ".", "_unnormalize_obs", "(", "obs", ",", "self", ".", "obs_rms", ")", "\n", "", "", "return", "obs_", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.unnormalize_reward": [[198, 202], ["numpy.sqrt"], "methods", ["None"], ["", "def", "unnormalize_reward", "(", "self", ",", "reward", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "if", "self", ".", "norm_reward", ":", "\n", "            ", "return", "reward", "*", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.get_original_obs": [[203, 209], ["copy.deepcopy"], "methods", ["None"], ["", "def", "get_original_obs", "(", "self", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns an unnormalized version of the observations from the most recent\n        step or reset.\n        \"\"\"", "\n", "return", "deepcopy", "(", "self", ".", "old_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.get_original_reward": [[210, 215], ["vec_normalize.VecNormalize.old_reward.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "get_original_reward", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Returns an unnormalized version of the rewards from the most recent step.\n        \"\"\"", "\n", "return", "self", ".", "old_reward", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.reset": [[216, 227], ["vec_normalize.VecNormalize.venv.reset", "numpy.zeros", "vec_normalize.VecNormalize.normalize_obs", "vec_normalize.VecNormalize._update_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize._update_reward"], ["", "def", "reset", "(", "self", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        :return: first observation of the episode\n        \"\"\"", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "old_obs", "=", "obs", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "_update_reward", "(", "self", ".", "ret", ")", "\n", "", "return", "self", ".", "normalize_obs", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load": [[228, 241], ["pickle.load.set_venv", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.set_venv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "load", "(", "load_path", ":", "str", ",", "venv", ":", "VecEnv", ")", "->", "\"VecNormalize\"", ":", "\n", "        ", "\"\"\"\n        Loads a saved VecNormalize object.\n\n        :param load_path: the path to load from.\n        :param venv: the VecEnv to wrap.\n        :return:\n        \"\"\"", "\n", "with", "open", "(", "load_path", ",", "\"rb\"", ")", "as", "file_handler", ":", "\n", "            ", "vec_normalize", "=", "pickle", ".", "load", "(", "file_handler", ")", "\n", "", "vec_normalize", ".", "set_venv", "(", "venv", ")", "\n", "return", "vec_normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.save": [[242, 251], ["open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.dump"], ["", "def", "save", "(", "self", ",", "save_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save current VecNormalize object with\n        all running statistics and settings (e.g. clip_obs)\n\n        :param save_path: The path to save to\n        \"\"\"", "\n", "with", "open", "(", "save_path", ",", "\"wb\"", ")", "as", "file_handler", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ",", "file_handler", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.__init__": [[26, 68], ["gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "time.time", "warnings.warn", "hasattr", "ResultsWriter", "venv.env_is_wrapped"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.dummy_vec_env.DummyVecEnv.env_is_wrapped"], ["def", "__init__", "(", "\n", "self", ",", "\n", "venv", ":", "VecEnv", ",", "\n", "filename", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "info_keywords", ":", "Tuple", "[", "str", ",", "...", "]", "=", "(", ")", ",", "\n", ")", ":", "\n", "# Avoid circular import", "\n", "        ", "from", "stable_baselines3", ".", "common", ".", "monitor", "import", "Monitor", ",", "ResultsWriter", "\n", "\n", "# This check is not valid for special `VecEnv`", "\n", "# like the ones created by Procgen, that does follow completely", "\n", "# the `VecEnv` interface", "\n", "try", ":", "\n", "            ", "is_wrapped_with_monitor", "=", "venv", ".", "env_is_wrapped", "(", "Monitor", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "            ", "is_wrapped_with_monitor", "=", "False", "\n", "\n", "", "if", "is_wrapped_with_monitor", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The environment is already wrapped with a `Monitor` wrapper\"", "\n", "\"but you are wrapping it with a `VecMonitor` wrapper, the `Monitor` statistics will be\"", "\n", "\"overwritten by the `VecMonitor` ones.\"", ",", "\n", "UserWarning", ",", "\n", ")", "\n", "\n", "", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "episode_returns", "=", "None", "\n", "self", ".", "episode_lengths", "=", "None", "\n", "self", ".", "episode_count", "=", "0", "\n", "self", ".", "t_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "env_id", "=", "None", "\n", "if", "hasattr", "(", "venv", ",", "\"spec\"", ")", "and", "venv", ".", "spec", "is", "not", "None", ":", "\n", "            ", "env_id", "=", "venv", ".", "spec", ".", "id", "\n", "\n", "", "if", "filename", ":", "\n", "            ", "self", ".", "results_writer", "=", "ResultsWriter", "(", "\n", "filename", ",", "header", "=", "{", "\"t_start\"", ":", "self", ".", "t_start", ",", "\"env_id\"", ":", "env_id", "}", ",", "extra_keys", "=", "info_keywords", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "results_writer", "=", "None", "\n", "", "self", ".", "info_keywords", "=", "info_keywords", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.reset": [[69, 74], ["vec_monitor.VecMonitor.venv.reset", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset"], ["", "def", "reset", "(", "self", ")", "->", "VecEnvObs", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "episode_returns", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "episode_lengths", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait": [[75, 94], ["vec_monitor.VecMonitor.venv.step_wait", "list", "range", "len", "infos[].copy", "round", "vec_monitor.VecMonitor.results_writer.write_row", "time.time"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.monitor.ResultsWriter.write_row"], ["", "def", "step_wait", "(", "self", ")", "->", "VecEnvStepReturn", ":", "\n", "        ", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "episode_returns", "+=", "rewards", "\n", "self", ".", "episode_lengths", "+=", "1", "\n", "new_infos", "=", "list", "(", "infos", "[", ":", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dones", ")", ")", ":", "\n", "            ", "if", "dones", "[", "i", "]", ":", "\n", "                ", "info", "=", "infos", "[", "i", "]", ".", "copy", "(", ")", "\n", "episode_return", "=", "self", ".", "episode_returns", "[", "i", "]", "\n", "episode_length", "=", "self", ".", "episode_lengths", "[", "i", "]", "\n", "episode_info", "=", "{", "\"r\"", ":", "episode_return", ",", "\"l\"", ":", "episode_length", ",", "\"t\"", ":", "round", "(", "time", ".", "time", "(", ")", "-", "self", ".", "t_start", ",", "6", ")", "}", "\n", "info", "[", "\"episode\"", "]", "=", "episode_info", "\n", "self", ".", "episode_count", "+=", "1", "\n", "self", ".", "episode_returns", "[", "i", "]", "=", "0", "\n", "self", ".", "episode_lengths", "[", "i", "]", "=", "0", "\n", "if", "self", ".", "results_writer", ":", "\n", "                    ", "self", ".", "results_writer", ".", "write_row", "(", "episode_info", ")", "\n", "", "new_infos", "[", "i", "]", "=", "info", "\n", "", "", "return", "obs", ",", "rewards", ",", "dones", ",", "new_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close": [[95, 99], ["vec_monitor.VecMonitor.venv.close", "vec_monitor.VecMonitor.results_writer.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "results_writer", ":", "\n", "            ", "self", ".", "results_writer", ".", "close", "(", ")", "\n", "", "return", "self", ".", "venv", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.unwrap_vec_wrapper": [[21, 35], ["isinstance", "isinstance", "gym_optimal_intrusion_response.agents.openai_baselines.common.vec_env.vec_normalize.VecNormalize"], "function", ["None"], ["# -------- Difficulty Version: V3 ------------", "\n", "register", "(", "\n", "id", "=", "'optimal-intrusion-response-v3'", ",", "\n", "entry_point", "=", "'gym_optimal_intrusion_response.envs.derived_envs.optimal_intrusion_response_env_v3:OptimalIntrusionResponseEnvV3'", ",", "\n", "kwargs", "=", "{", "\"traces_dir\"", ":", "\"\"", ",", "\"traces_filename\"", ":", "\"\"", "}", "\n", ")", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.unwrap_vec_normalize": [[37, 43], ["__init__.unwrap_vec_wrapper"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.unwrap_vec_wrapper"], []], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.is_vecenv_wrapped": [[45, 54], ["__init__.unwrap_vec_wrapper"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.unwrap_vec_wrapper"], []], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.__init__.sync_envs_normalization": [[57, 71], ["isinstance", "isinstance", "copy.deepcopy", "copy.deepcopy"], "function", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.copy_obs_dict": [[13, 22], ["isinstance", "collections.OrderedDict", "type", "numpy.copy", "obs.items"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["def", "copy_obs_dict", "(", "obs", ":", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ")", "->", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Deep-copy a dict of numpy arrays.\n\n    :param obs: a dict of numpy arrays.\n    :return: a dict of copied numpy arrays.\n    \"\"\"", "\n", "assert", "isinstance", "(", "obs", ",", "OrderedDict", ")", ",", "f\"unexpected type for observations '{type(obs)}'\"", "\n", "return", "OrderedDict", "(", "[", "(", "k", ",", "np", ".", "copy", "(", "v", ")", ")", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.dict_to_obs": [[24, 43], ["isinstance", "isinstance", "tuple", "len", "len", "set", "obs_dict.keys", "range", "len"], "function", ["None"], ["", "def", "dict_to_obs", "(", "space", ":", "gym", ".", "spaces", ".", "Space", ",", "obs_dict", ":", "Dict", "[", "Any", ",", "np", ".", "ndarray", "]", ")", "->", "VecEnvObs", ":", "\n", "    ", "\"\"\"\n    Convert an internal representation raw_obs into the appropriate type\n    specified by space.\n\n    :param space: an observation space.\n    :param obs_dict: a dict of numpy arrays.\n    :return: returns an observation of the same type as space.\n        If space is Dict, function is identity; if space is Tuple, converts dict to Tuple;\n        otherwise, space is unstructured and returns the value raw_obs[None].\n    \"\"\"", "\n", "if", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "        ", "return", "obs_dict", "\n", "", "elif", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "assert", "len", "(", "obs_dict", ")", "==", "len", "(", "space", ".", "spaces", ")", ",", "\"size of observation does not match size of observation space\"", "\n", "return", "tuple", "(", "(", "obs_dict", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "space", ".", "spaces", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "set", "(", "obs_dict", ".", "keys", "(", ")", ")", "==", "{", "None", "}", ",", "\"multiple observation keys for unstructured observation space\"", "\n", "return", "obs_dict", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.util.obs_space_info": [[45, 75], ["isinstance", "subspaces.items", "isinstance", "isinstance", "keys.append", "hasattr", "enumerate", "type"], "function", ["None"], ["", "", "def", "obs_space_info", "(", "obs_space", ":", "gym", ".", "spaces", ".", "Space", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "Dict", "[", "Any", ",", "Tuple", "[", "int", ",", "...", "]", "]", ",", "Dict", "[", "Any", ",", "np", ".", "dtype", "]", "]", ":", "\n", "    ", "\"\"\"\n    Get dict-structured information about a gym.Space.\n\n    Dict spaces are represented directly by their dict of subspaces.\n    Tuple spaces are converted into a dict with keys indexing into the tuple.\n    Unstructured spaces are represented by {None: obs_space}.\n\n    :param obs_space: an observation space\n    :return: A tuple (keys, shapes, dtypes):\n        keys: a list of dict keys.\n        shapes: a dict mapping keys to shapes.\n        dtypes: a dict mapping keys to dtypes.\n    \"\"\"", "\n", "if", "isinstance", "(", "obs_space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "        ", "assert", "isinstance", "(", "obs_space", ".", "spaces", ",", "OrderedDict", ")", ",", "\"Dict space must have ordered subspaces\"", "\n", "subspaces", "=", "obs_space", ".", "spaces", "\n", "", "elif", "isinstance", "(", "obs_space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "subspaces", "=", "{", "i", ":", "space", "for", "i", ",", "space", "in", "enumerate", "(", "obs_space", ".", "spaces", ")", "}", "\n", "", "else", ":", "\n", "        ", "assert", "not", "hasattr", "(", "obs_space", ",", "\"spaces\"", ")", ",", "f\"Unsupported structured space '{type(obs_space)}'\"", "\n", "subspaces", "=", "{", "None", ":", "obs_space", "}", "\n", "", "keys", "=", "[", "]", "\n", "shapes", "=", "{", "}", "\n", "dtypes", "=", "{", "}", "\n", "for", "key", ",", "box", "in", "subspaces", ".", "items", "(", ")", ":", "\n", "        ", "keys", ".", "append", "(", "key", ")", "\n", "shapes", "[", "key", "]", "=", "box", ".", "shape", "\n", "dtypes", "[", "key", "]", "=", "box", ".", "dtype", "\n", "", "return", "keys", ",", "shapes", ",", "dtypes", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.manual.manual_defender_agent.ManualDefenderAgent.__init__": [[13, 93], ["numpy.array", "env.reset", "range", "list", "print", "input", "raw_input.strip.strip.strip", "list", "range", "filter", "print", "env.reset", "env.is_defense_action_legal", "print", "str", "print", "numpy.random.choice", "manual_defender_agent.ManualDefenderAgent.env.step", "history.append", "print", "print", "print", "print", "print", "print", "print", "raw_input.strip.strip.split", "any", "print", "list", "any", "map", "env.is_defense_action_legal", "manual_defender_agent.ManualDefenderAgent.env.step", "print", "print", "history.append", "print", "char.isdigit", "int", "print", "print", "list", "filter"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["def", "__init__", "(", "self", ",", "env", ":", "OptimalIntrusionResponseEnv", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "num_actions", "=", "env", ".", "defender_action_space", ".", "n", "\n", "actions", "=", "np", ".", "array", "(", "list", "(", "range", "(", "num_actions", ")", ")", ")", "\n", "cumulative_reward", "=", "0", "\n", "latest_obs", "=", "None", "\n", "latest_rew", "=", "None", "\n", "latest_obs", "=", "env", ".", "reset", "(", ")", "\n", "history", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "env", ".", "env_config", ".", "num_nodes", "*", "env", ".", "env_config", ".", "num_attributes", ")", ":", "\n", "            ", "print", "(", "\"action:{}, attribute:{}, node:{}\"", ".", "format", "(", "i", ",", "i", "%", "env", ".", "env_config", ".", "num_attributes", ",", "i", "//", "env", ".", "env_config", ".", "num_attributes", ")", ")", "\n", "", "while", "True", ":", "\n", "            ", "raw_input", "=", "input", "(", "\">\"", ")", "\n", "raw_input", "=", "raw_input", ".", "strip", "(", ")", "\n", "legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "x", ":", "env", ".", "is_defense_action_legal", "(", "x", ")", ",", "actions", ")", ")", "\n", "if", "raw_input", "==", "\"help\"", ":", "\n", "                ", "print", "(", "\"Enter an action id to execute the action, \"", "\n", "\"press R to reset, press S to print the state, press A to print the actions, \"", "\n", "\"press L to print the legal actions, press x to select a random legal action,\"", "\n", "\"press H to print the history of actions\"", ")", "\n", "", "elif", "raw_input", "==", "\"R\"", ":", "\n", "                ", "latest_obs", "=", "env", ".", "reset", "(", ")", "\n", "cumulative_reward", "=", "0", "\n", "", "elif", "raw_input", "==", "\"S\"", ":", "\n", "                ", "print", "(", "str", "(", "env", ".", "env_state", ".", "attacker_obs_state", ")", ")", "\n", "", "elif", "raw_input", "==", "\"L\"", ":", "\n", "                ", "print", "(", "legal_actions", ")", "\n", "", "elif", "raw_input", "==", "\"x\"", ":", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "_", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "history", ".", "append", "(", "a", ")", "\n", "if", "done", ":", "\n", "                    ", "print", "(", "\"done:{}\"", ".", "format", "(", "done", ")", ")", "\n", "", "", "elif", "raw_input", "==", "\"H\"", ":", "\n", "                ", "print", "(", "history", ")", "\n", "", "elif", "raw_input", "==", "\"O\"", ":", "\n", "                ", "print", "(", "latest_obs", ")", "\n", "print", "(", "latest_obs", "[", "0", "]", ".", "shape", ")", "\n", "print", "(", "latest_obs", "[", "1", "]", ".", "shape", ")", "\n", "", "elif", "raw_input", "==", "\"U\"", ":", "\n", "                ", "print", "(", "latest_rew", ")", "\n", "", "elif", "raw_input", "==", "\"P\"", ":", "\n", "                ", "print", "(", "cumulative_reward", ")", "\n", "", "else", ":", "\n", "                ", "actions_str", "=", "raw_input", ".", "split", "(", "\",\"", ")", "\n", "digits_only", "=", "any", "(", "any", "(", "char", ".", "isdigit", "(", ")", "for", "char", "in", "x", ")", "for", "x", "in", "actions_str", ")", "\n", "attacker_action", "=", "None", "\n", "if", "not", "digits_only", ":", "\n", "                    ", "print", "(", "\"Invalid action. Actions must be integers.\"", ")", "\n", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "actions_str", ")", ")", "\n", "for", "a", "in", "actions", ":", "\n", "                        ", "if", "env", ".", "is_defense_action_legal", "(", "a", ")", ":", "\n", "                            ", "action", "=", "(", "attacker_action", ",", "a", ")", "\n", "latest_obs", ",", "latest_rew", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "attacker_rew", ",", "defender_rew", "=", "latest_rew", "\n", "print", "(", "\"cumulative:{}, rew:{}\"", ".", "format", "(", "cumulative_reward", ",", "defender_rew", ")", ")", "\n", "cumulative_reward", "+=", "defender_rew", "\n", "print", "(", "\"cumulative_prime:{}\"", ".", "format", "(", "cumulative_reward", ")", ")", "\n", "history", ".", "append", "(", "a", ")", "\n", "if", "done", ":", "\n", "                                ", "if", "not", "env", ".", "env_config", ".", "traces", ":", "\n", "                                    ", "target_compromised", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "target_component", ",", "env", ".", "env_state", ".", "nodes", ")", ")", "[", "0", "]", ".", "compromised", "\n", "print", "(", "\"done:{}, attacker_caught:{}, stopped:{}, target_compromised:{} rew:{}\"", ".", "format", "(", "\n", "done", ",", "env", ".", "env_state", ".", "caught", ",", "\n", "env", ".", "env_state", ".", "stopped", ",", "\n", "target_compromised", ",", "latest_rew", "\n", ")", ")", "\n", "", "else", ":", "\n", "                                    ", "target_compromised", "=", "env", ".", "env_state", ".", "target_compromised", "\n", "print", "(", "\n", "\"done:{}, attacker_caught:{}, stopped:{}, target_compromised:{} \"", "\n", "\"last rew:{}, cumulative rew:{}\"", ".", "format", "(", "\n", "done", ",", "env", ".", "env_state", ".", "caught", ",", "\n", "env", ".", "env_state", ".", "stopped", ",", "\n", "target_compromised", ",", "latest_rew", ",", "cumulative_reward", "\n", ")", ")", "\n", "", "", "", "else", ":", "\n", "                            ", "print", "(", "\"action:{} is illegal\"", ".", "format", "(", "a", ")", ")", "\n", "", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.manual.manual_attacker_agent.ManualAttackerAgent.__init__": [[13, 85], ["numpy.array", "env.reset", "range", "list", "input", "raw_input.strip.strip.strip", "list", "range", "print", "print", "filter", "print", "env.reset", "env.is_attack_action_legal", "print", "print", "numpy.random.choice", "manual_attacker_agent.ManualAttackerAgent.env.step", "history.append", "print", "print", "print", "print", "print", "print", "print", "raw_input.strip.strip.split", "any", "print", "list", "any", "map", "env.is_attack_action_legal", "manual_attacker_agent.ManualAttackerAgent.env.step", "history.append", "print", "char.isdigit", "int", "print", "list", "filter"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["def", "__init__", "(", "self", ",", "env", ":", "OptimalIntrusionResponseEnv", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "num_actions", "=", "env", ".", "attacker_action_space", ".", "n", "\n", "actions", "=", "np", ".", "array", "(", "list", "(", "range", "(", "num_actions", ")", ")", ")", "\n", "cumulative_reward", "=", "0", "\n", "latest_obs", "=", "None", "\n", "latest_rew", "=", "None", "\n", "latest_obs", "=", "env", ".", "reset", "(", ")", "\n", "history", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "env", ".", "env_config", ".", "num_nodes", "*", "(", "env", ".", "env_config", ".", "num_attributes", "+", "1", ")", ")", ":", "\n", "            ", "if", "(", "i", "%", "(", "env", ".", "env_config", ".", "num_attributes", "+", "1", ")", ")", "!=", "env", ".", "env_config", ".", "recon_attribute", ":", "\n", "                ", "print", "(", "\"action:{}, attribute:{}, node:{}\"", ".", "format", "(", "i", ",", "i", "%", "env", ".", "env_config", ".", "num_attributes", ",", "i", "//", "(", "env", ".", "env_config", ".", "num_attributes", "+", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"action:{}, recon, node:{}\"", ".", "format", "(", "i", ",", "i", "//", "(", "env", ".", "env_config", ".", "num_attributes", "+", "1", ")", ")", ")", "\n", "", "", "while", "True", ":", "\n", "            ", "raw_input", "=", "input", "(", "\">\"", ")", "\n", "raw_input", "=", "raw_input", ".", "strip", "(", ")", "\n", "legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "x", ":", "env", ".", "is_attack_action_legal", "(", "\n", "x", ",", "env_config", "=", "env", ".", "env_config", ",", "env_state", "=", "env", ".", "env_state", ")", ",", "actions", ")", ")", "\n", "if", "raw_input", "==", "\"help\"", ":", "\n", "                ", "print", "(", "\"Enter an action id to execute the action, \"", "\n", "\"press R to reset, press S to print the state, press A to print the actions, \"", "\n", "\"press L to print the legal actions, press x to select a random legal action,\"", "\n", "\"press H to print the history of actions\"", ")", "\n", "", "elif", "raw_input", "==", "\"R\"", ":", "\n", "                ", "latest_obs", "=", "env", ".", "reset", "(", ")", "\n", "cumulative_reward", "=", "0", "\n", "", "elif", "raw_input", "==", "\"S\"", ":", "\n", "                ", "print", "(", "env", ".", "env_state", ")", "\n", "", "elif", "raw_input", "==", "\"L\"", ":", "\n", "                ", "print", "(", "legal_actions", ")", "\n", "", "elif", "raw_input", "==", "\"x\"", ":", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "_", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "history", ".", "append", "(", "a", ")", "\n", "if", "done", ":", "\n", "                    ", "print", "(", "\"done:{}\"", ".", "format", "(", "done", ")", ")", "\n", "", "", "elif", "raw_input", "==", "\"H\"", ":", "\n", "                ", "print", "(", "history", ")", "\n", "", "elif", "raw_input", "==", "\"O\"", ":", "\n", "                ", "print", "(", "latest_obs", ")", "\n", "print", "(", "latest_obs", "[", "0", "]", ".", "shape", ")", "\n", "print", "(", "latest_obs", "[", "1", "]", ".", "shape", ")", "\n", "", "elif", "raw_input", "==", "\"U\"", ":", "\n", "                ", "print", "(", "latest_rew", ")", "\n", "", "elif", "raw_input", "==", "\"P\"", ":", "\n", "                ", "print", "(", "cumulative_reward", ")", "\n", "", "else", ":", "\n", "                ", "actions_str", "=", "raw_input", ".", "split", "(", "\",\"", ")", "\n", "digits_only", "=", "any", "(", "any", "(", "char", ".", "isdigit", "(", ")", "for", "char", "in", "x", ")", "for", "x", "in", "actions_str", ")", "\n", "defender_action", "=", "None", "\n", "if", "not", "digits_only", ":", "\n", "                    ", "print", "(", "\"Invalid action. Actions must be integers.\"", ")", "\n", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "actions_str", ")", ")", "\n", "for", "a", "in", "actions", ":", "\n", "                        ", "if", "env", ".", "is_attack_action_legal", "(", "a", ",", "env_config", "=", "env", ".", "env_config", ",", "env_state", "=", "env", ".", "env_state", ")", ":", "\n", "                            ", "action", "=", "(", "a", ",", "defender_action", ")", "\n", "latest_obs", ",", "latest_rew", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "attacker_rew", ",", "defender_rew", "=", "latest_rew", "\n", "cumulative_reward", "+=", "attacker_rew", "\n", "history", ".", "append", "(", "a", ")", "\n", "if", "done", ":", "\n", "                                ", "target_compromised", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "target_component", ",", "env", ".", "env_state", ".", "nodes", ")", ")", "[", "0", "]", ".", "compromised", "\n", "print", "(", "\"done:{}, attacker_caught:{}, stopped:{}, target_compromised:{} rew:{}\"", ".", "format", "(", "\n", "done", ",", "env", ".", "env_state", ".", "caught", ",", "\n", "env", ".", "env_state", ".", "stopped", ",", "\n", "target_compromised", ",", "latest_rew", "\n", ")", ")", "\n", "", "", "else", ":", "\n", "                            ", "print", "(", "\"action:{} is illegal\"", ".", "format", "(", "a", ")", ")", "\n", "", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.__init__": [[12, 131], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gamma", ":", "float", "=", "0.8", ",", "alpha", ":", "float", "=", "0.1", ",", "\n", "epsilon", ":", "float", "=", "0.9", ",", "render", ":", "bool", "=", "False", ",", "\n", "eval_sleep", ":", "float", "=", "0.35", ",", "\n", "epsilon_decay", ":", "float", "=", "0.999", ",", "min_epsilon", ":", "float", "=", "0.1", ",", "eval_episodes", ":", "int", "=", "1", ",", "\n", "train_log_frequency", ":", "int", "=", "100", ",", "\n", "eval_log_frequency", ":", "int", "=", "1", ",", "video", ":", "bool", "=", "False", ",", "video_fps", ":", "int", "=", "5", ",", "video_dir", ":", "bool", "=", "None", ",", "\n", "num_episodes", ":", "int", "=", "5000", ",", "\n", "eval_render", ":", "bool", "=", "False", ",", "gifs", ":", "bool", "=", "False", ",", "gif_dir", ":", "str", "=", "None", ",", "eval_frequency", ":", "int", "=", "1000", ",", "\n", "video_frequency", ":", "int", "=", "101", ",", "\n", "save_dir", ":", "str", "=", "None", ",", "load_path", ":", "str", "=", "None", ",", "\n", "checkpoint_freq", ":", "int", "=", "100000", ",", "random_seed", ":", "int", "=", "0", ",", "eval_epsilon", ":", "float", "=", "0.0", ",", "\n", "input_dim", ":", "int", "=", "30", ",", "output_dim", ":", "int", "=", "30", ",", "\n", "pi_hidden_dim", ":", "int", "=", "64", ",", "batch_size", ":", "int", "=", "64", ",", "pi_hidden_layers", "=", "2", ",", "\n", "vf_hidden_layers", "=", "2", ",", "vf_hidden_dim", ":", "int", "=", "64", ",", "\n", "gpu", ":", "bool", "=", "False", ",", "tensorboard", ":", "bool", "=", "False", ",", "tensorboard_dir", ":", "str", "=", "\"\"", ",", "\n", "optimizer", ":", "str", "=", "\"Adam\"", ",", "lr_exp_decay", ":", "bool", "=", "False", ",", "\n", "lr_decay_rate", ":", "float", "=", "0.96", ",", "hidden_activation", ":", "str", "=", "\"ReLU\"", ",", "clip_gradient", "=", "False", ",", "\n", "max_gradient_norm", "=", "40", ",", "critic_loss_fn", ":", "str", "=", "\"MSE\"", ",", "state_length", "=", "1", ",", "\n", "gpu_id", ":", "int", "=", "0", ",", "eps_clip", ":", "float", "=", "0.2", ",", "lr_progress_decay", ":", "bool", "=", "False", ",", "\n", "lr_progress_power_decay", ":", "int", "=", "1", ",", "optimization_iterations", ":", "int", "=", "28", ",", "\n", "gae_lambda", ":", "float", "=", "0.95", ",", "features_dim", ":", "int", "=", "44", ",", "\n", "ent_coef", ":", "float", "=", "0.0", ",", "vf_coef", ":", "float", "=", "0.5", ",", "use_sde", ":", "bool", "=", "False", ",", "sde_sample_freq", ":", "int", "=", "4", ",", "\n", "shared_hidden_dim", ":", "int", "=", "64", ",", "shared_hidden_layers", "=", "4", ",", "\n", "mini_batch_size", ":", "int", "=", "64", ",", "render_steps", ":", "int", "=", "20", ",", "num_iterations", ":", "int", "=", "50", ",", "\n", "multi_input_channel", ":", "bool", "=", "False", ",", "\n", "ar_policy", ":", "bool", "=", "False", ",", "illegal_action_logit", "=", "-", "100", ",", "buffer_size", ":", "int", "=", "1000000", ",", "\n", "tau", ":", "float", "=", "1.0", ",", "learning_starts", ":", "int", "=", "50000", ",", "train_freq", ":", "int", "=", "4", ",", "gradient_steps", ":", "int", "=", "1", ",", "\n", "target_update_interval", ":", "int", "=", "10000", ",", "exploration_fraction", ":", "float", "=", "0.1", ",", "\n", "exploration_initial_eps", ":", "float", "=", "1.0", ",", "exploration_final_eps", ":", "float", "=", "0.05", ",", "\n", "policy_delay", ":", "int", "=", "2", ",", "target_policy_noise", ":", "float", "=", "0.2", ",", "target_noise_clip", ":", "float", "=", "0.5", ",", "\n", "input_dim_2", ":", "int", "=", "30", ",", "output_dim_2", ":", "int", "=", "30", ",", "pi_hidden_dim_2", ":", "int", "=", "64", ",", "\n", "pi_hidden_layers_2", ":", "int", "=", "2", ",", "vf_hidden_layers_2", ":", "int", "=", "2", ",", "vf_hidden_dim_2", ":", "int", "=", "64", ",", "\n", "filter_illegal_actions", ":", "bool", "=", "False", ",", "\n", "eval_deterministic", ":", "bool", "=", "False", ",", "\n", "running_avg", ":", "int", "=", "10", "\n", ")", ":", "\n", "        ", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "eval_sleep", "=", "eval_sleep", "\n", "self", ".", "epsilon_decay", "=", "epsilon_decay", "\n", "self", ".", "min_epsilon", "=", "min_epsilon", "\n", "self", ".", "eval_episodes", "=", "eval_episodes", "\n", "self", ".", "train_log_frequency", "=", "train_log_frequency", "\n", "self", ".", "eval_log_frequency", "=", "eval_log_frequency", "\n", "self", ".", "video", "=", "video", "\n", "self", ".", "video_fps", "=", "video_fps", "\n", "self", ".", "video_dir", "=", "video_dir", "\n", "self", ".", "num_episodes", "=", "num_episodes", "\n", "self", ".", "eval_render", "=", "eval_render", "\n", "self", ".", "gifs", "=", "gifs", "\n", "self", ".", "gif_dir", "=", "gif_dir", "\n", "self", ".", "eval_frequency", "=", "eval_frequency", "\n", "self", ".", "logger", "=", "None", "\n", "self", ".", "video_frequency", "=", "video_frequency", "\n", "self", ".", "save_dir", "=", "save_dir", "\n", "self", ".", "load_path", "=", "load_path", "\n", "self", ".", "checkpoint_freq", "=", "checkpoint_freq", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "eval_epsilon", "=", "eval_epsilon", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "pi_hidden_dim", "=", "pi_hidden_dim", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "pi_hidden_layers", "=", "pi_hidden_layers", "\n", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "tensorboard", "=", "tensorboard", "\n", "self", ".", "tensorboard_dir", "=", "tensorboard_dir", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr_exp_decay", "=", "lr_exp_decay", "\n", "self", ".", "lr_decay_rate", "=", "lr_decay_rate", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "self", ".", "clip_gradient", "=", "clip_gradient", "\n", "self", ".", "max_gradient_norm", "=", "max_gradient_norm", "\n", "self", ".", "critic_loss_fn", "=", "critic_loss_fn", "\n", "self", ".", "state_length", "=", "state_length", "\n", "self", ".", "gpu_id", "=", "gpu_id", "\n", "self", ".", "eps_clip", "=", "eps_clip", "\n", "self", ".", "lr_progress_decay", "=", "lr_progress_decay", "\n", "self", ".", "lr_progress_power_decay", "=", "lr_progress_power_decay", "\n", "self", ".", "optimization_iterations", "=", "optimization_iterations", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "features_dim", "=", "features_dim", "\n", "self", ".", "ent_coef", "=", "ent_coef", "\n", "self", ".", "vf_coef", "=", "vf_coef", "\n", "self", ".", "use_sde", "=", "use_sde", "\n", "self", ".", "sde_sample_freq", "=", "sde_sample_freq", "\n", "self", ".", "vf_hidden_dim", "=", "vf_hidden_dim", "\n", "self", ".", "vf_hidden_layers", "=", "vf_hidden_layers", "\n", "self", ".", "shared_layers", "=", "shared_hidden_layers", "\n", "self", ".", "shared_hidden_dim", "=", "shared_hidden_dim", "\n", "self", ".", "mini_batch_size", "=", "mini_batch_size", "\n", "self", ".", "render_steps", "=", "render_steps", "\n", "self", ".", "num_iterations", "=", "num_iterations", "\n", "self", ".", "multi_input_channel", "=", "multi_input_channel", "\n", "self", ".", "ar_policy", "=", "ar_policy", "\n", "self", ".", "illegal_action_logit", "=", "illegal_action_logit", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "tau", "=", "tau", "\n", "self", ".", "learning_starts", "=", "learning_starts", "\n", "self", ".", "train_freq", "=", "train_freq", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "target_update_interval", "=", "target_update_interval", "\n", "self", ".", "exploration_fraction", "=", "exploration_fraction", "\n", "self", ".", "exploration_initial_eps", "=", "exploration_initial_eps", "\n", "self", ".", "exploration_final_eps", "=", "exploration_final_eps", "\n", "self", ".", "policy_delay", "=", "policy_delay", "\n", "self", ".", "target_policy_noise", "=", "target_policy_noise", "\n", "self", ".", "target_noise_clip", "=", "target_noise_clip", "\n", "self", ".", "input_dim_2", "=", "input_dim_2", "\n", "self", ".", "output_dim_2", "=", "output_dim_2", "\n", "self", ".", "pi_hidden_dim_2", "=", "pi_hidden_dim_2", "\n", "self", ".", "pi_hidden_layers_2", "=", "pi_hidden_layers_2", "\n", "self", ".", "vf_hidden_layers_2", "=", "vf_hidden_layers_2", "\n", "self", ".", "vf_hidden_dim_2", "=", "vf_hidden_dim_2", "\n", "self", ".", "filter_illegal_actions", "=", "filter_illegal_actions", "\n", "self", ".", "eval_deterministic", "=", "eval_deterministic", "\n", "self", ".", "running_avg", "=", "running_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_str": [[133, 174], ["None"], "methods", ["None"], ["", "def", "to_str", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string with information about all of the parameters\n        \"\"\"", "\n", "return", "\"Hyperparameters: gamma:{0},alpha:{1},epsilon:{2},render:{3},eval_sleep:{4},\"", "\"epsilon_decay:{5},min_epsilon:{6},eval_episodes:{7},train_log_frequency:{8},\"", "\"eval_log_frequency:{9},video:{10},video_fps:{11},\"", "\"video_dir:{12},num_episodes:{13},eval_render:{14},gifs:{15},\"", "\"gifdir:{16},eval_frequency:{17},video_frequency:{18}\"", "\"checkpoint_freq:{19},random_seed:{20},eval_epsilon:{21},clip_gradient:{22},max_gradient_norm:{23},\"", "\"output_dim:{24},critic_loss_fn:{25},state_length:{26}\"", "\"gpu_id:{27},eps_clip:{28},input_dim:{29},lr_progress_decay:{30},lr_progress_power_decay:{31},\"", "\"optimization_iterations:{32},gae_lambda:{33},features_dim:{34},\"", "\"ent_coef:{35},vf_coef:{36},use_sde:{37},sde_sample_freq:{38},illegal_action_logit:{39},\"", "\"save_dir:{40}, load_path:{41}, pi_hidden_dim:{42}, pi_hidden_layers:{43},\"", "\"vf_hidden_layers:{44},vf_hidden_dim:{45},gpu:{46},tensorboard:{47},tensorboard_dir:{48},\"", "\"optimizer:{50},lr_exp_decay:{51},hidden_activation:{52},render_steps:{53},\"", "\"num_iterations:{54},mini_batch_size:{55},shared_hidden_dim:{56},shared_hidden_layers:{57},\"", "\"ar_policy:{58},buffer_size:{59},tau:{60},learning_starts:{61},train_freq:{62},\"", "\"gradient_steps:{63},target_update_interval:{64},exploration_fraction:{65},\"", "\"exploration_initial_eps:{66},exploration_final_eps:{67},policy_delay:{68},\"", "\"target_policy_noise:{69},target_noise_clip:{70},input_dim_2:{71},\"", "\"output_dim_2:{72},pi_hidden_dim_2:{73},pi_hidden_layers_2:{74},\"", "\"vf_hidden_layers_2:{75},vf_hidden_dim_2:{76},filter_illegal_actions:{77},eval_deterministic:{78}\"", ".", "format", "(", "\n", "self", ".", "gamma", ",", "self", ".", "alpha", ",", "self", ".", "epsilon", ",", "self", ".", "render", ",", "self", ".", "eval_sleep", ",", "self", ".", "epsilon_decay", ",", "\n", "self", ".", "min_epsilon", ",", "self", ".", "eval_episodes", ",", "self", ".", "train_log_frequency", ",", "self", ".", "eval_log_frequency", ",", "self", ".", "video", ",", "\n", "self", ".", "video_fps", ",", "self", ".", "video_dir", ",", "self", ".", "num_episodes", ",", "self", ".", "eval_render", ",", "self", ".", "gifs", ",", "self", ".", "gif_dir", ",", "\n", "self", ".", "eval_frequency", ",", "self", ".", "video_frequency", ",", "self", ".", "checkpoint_freq", ",", "\n", "self", ".", "random_seed", ",", "self", ".", "eval_epsilon", ",", "self", ".", "clip_gradient", ",", "self", ".", "max_gradient_norm", ",", "self", ".", "output_dim", ",", "\n", "self", ".", "critic_loss_fn", ",", "self", ".", "state_length", ",", "self", ".", "gpu_id", ",", "self", ".", "eps_clip", ",", "self", ".", "input_dim", ",", "self", ".", "lr_progress_decay", ",", "\n", "self", ".", "lr_progress_power_decay", ",", "self", ".", "optimization_iterations", ",", "self", ".", "gae_lambda", ",", "self", ".", "features_dim", ",", "\n", "self", ".", "ent_coef", ",", "self", ".", "vf_coef", ",", "self", ".", "use_sde", ",", "self", ".", "sde_sample_freq", ",", "self", ".", "illegal_action_logit", ",", "\n", "self", ".", "save_dir", ",", "self", ".", "load_path", ",", "self", ".", "pi_hidden_dim", ",", "self", ".", "pi_hidden_layers", ",", "self", ".", "vf_hidden_layers", ",", "\n", "self", ".", "vf_hidden_dim", ",", "self", ".", "gpu", ",", "self", ".", "tensorboard", ",", "self", ".", "tensorboard_dir", ",", "self", ".", "optimizer", ",", "\n", "self", ".", "lr_exp_decay", ",", "self", ".", "hidden_activation", ",", "self", ".", "render_steps", ",", "self", ".", "num_iterations", ",", "self", ".", "mini_batch_size", ",", "\n", "self", ".", "shared_hidden_dim", ",", "self", ".", "shared_layers", ",", "self", ".", "ar_policy", ",", "self", ".", "buffer_size", ",", "self", ".", "tau", ",", "\n", "self", ".", "learning_starts", ",", "self", ".", "train_freq", ",", "self", ".", "gradient_steps", ",", "self", ".", "target_update_interval", ",", "\n", "self", ".", "target_update_interval", ",", "self", ".", "exploration_fraction", ",", "self", ".", "exploration_initial_eps", ",", "\n", "self", ".", "exploration_final_eps", ",", "self", ".", "policy_delay", ",", "self", ".", "target_policy_noise", ",", "self", ".", "target_noise_clip", ",", "\n", "self", ".", "input_dim_2", ",", "self", ".", "output_dim_2", ",", "self", ".", "pi_hidden_dim_2", ",", "self", ".", "pi_hidden_layers_2", ",", "self", ".", "vf_hidden_layers_2", ",", "\n", "self", ".", "vf_hidden_dim_2", ",", "self", ".", "filter_illegal_actions", ",", "self", ".", "eval_deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv": [[175, 257], ["open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write parameters to csv file\n\n        :param file_path: path to the file\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"parameter\"", ",", "\"value\"", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gamma\"", ",", "str", "(", "self", ".", "gamma", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"alpha\"", ",", "str", "(", "self", ".", "alpha", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"epsilon\"", ",", "str", "(", "self", ".", "epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"render\"", ",", "str", "(", "self", ".", "render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_sleep\"", ",", "str", "(", "self", ".", "eval_sleep", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"epsilon_decay\"", ",", "str", "(", "self", ".", "epsilon_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"min_epsilon\"", ",", "str", "(", "self", ".", "min_epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_episodes\"", ",", "str", "(", "self", ".", "eval_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"train_log_frequency\"", ",", "str", "(", "self", ".", "train_log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_log_frequency\"", ",", "str", "(", "self", ".", "eval_log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video\"", ",", "str", "(", "self", ".", "video", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_fps\"", ",", "str", "(", "self", ".", "video_fps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_dir\"", ",", "str", "(", "self", ".", "video_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_episodes\"", ",", "str", "(", "self", ".", "num_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_render\"", ",", "str", "(", "self", ".", "eval_render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifs\"", ",", "str", "(", "self", ".", "gifs", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifdir\"", ",", "str", "(", "self", ".", "gif_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_frequency\"", ",", "str", "(", "self", ".", "eval_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_frequency\"", ",", "str", "(", "self", ".", "video_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"checkpoint_freq\"", ",", "str", "(", "self", ".", "checkpoint_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"random_seed\"", ",", "str", "(", "self", ".", "random_seed", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_epsilon\"", ",", "str", "(", "self", ".", "eval_epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"input\"", ",", "str", "(", "self", ".", "input_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"output_dim\"", ",", "str", "(", "self", ".", "output_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_dim\"", ",", "str", "(", "self", ".", "pi_hidden_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"batch_size\"", ",", "str", "(", "self", ".", "batch_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gpu\"", ",", "str", "(", "self", ".", "gpu", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard\"", ",", "str", "(", "self", ".", "tensorboard", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard_dir\"", ",", "str", "(", "self", ".", "tensorboard_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"optimizer\"", ",", "str", "(", "self", ".", "optimizer", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_hidden_layers\"", ",", "str", "(", "self", ".", "pi_hidden_layers", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_exp_decay\"", ",", "str", "(", "self", ".", "lr_exp_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_decay_rate\"", ",", "str", "(", "self", ".", "lr_decay_rate", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_activation\"", ",", "str", "(", "self", ".", "hidden_activation", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"clip_gradient\"", ",", "str", "(", "self", ".", "clip_gradient", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"max_gradient_norm\"", ",", "str", "(", "self", ".", "max_gradient_norm", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"output_dim\"", ",", "str", "(", "self", ".", "output_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"critic_loss_fn\"", ",", "str", "(", "self", ".", "critic_loss_fn", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"state_length\"", ",", "str", "(", "self", ".", "state_length", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gpu_id\"", ",", "str", "(", "self", ".", "gpu_id", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eps_clip\"", ",", "str", "(", "self", ".", "eps_clip", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_progress_decay\"", ",", "str", "(", "self", ".", "lr_progress_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_progress_power_decay\"", ",", "str", "(", "self", ".", "lr_progress_power_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"optimization_iterations\"", ",", "str", "(", "self", ".", "optimization_iterations", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gae_lambda\"", ",", "str", "(", "self", ".", "gae_lambda", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"features_dim\"", ",", "str", "(", "self", ".", "features_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"ent_coef\"", ",", "str", "(", "self", ".", "ent_coef", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"vf_coef\"", ",", "str", "(", "self", ".", "vf_coef", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"use_sde\"", ",", "str", "(", "self", ".", "use_sde", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"sde_sample_freq\"", ",", "str", "(", "self", ".", "sde_sample_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"illegal_action_logit\"", ",", "str", "(", "self", ".", "illegal_action_logit", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"buffer_size\"", ",", "str", "(", "self", ".", "buffer_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tau\"", ",", "str", "(", "self", ".", "tau", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"learning_starts\"", ",", "str", "(", "self", ".", "learning_starts", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"train_freq\"", ",", "str", "(", "self", ".", "train_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gradient_steps\"", ",", "str", "(", "self", ".", "gradient_steps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_update_interval\"", ",", "str", "(", "self", ".", "target_update_interval", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"exploration_fraction\"", ",", "str", "(", "self", ".", "exploration_fraction", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"exploration_initial_eps\"", ",", "str", "(", "self", ".", "exploration_initial_eps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"exploration_final_eps\"", ",", "str", "(", "self", ".", "exploration_final_eps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"policy_delay\"", ",", "str", "(", "self", ".", "policy_delay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_policy_noise\"", ",", "str", "(", "self", ".", "target_policy_noise", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_noise_clip\"", ",", "str", "(", "self", ".", "target_noise_clip", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"input_dim_2\"", ",", "str", "(", "self", ".", "input_dim_2", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"output_dim_2\"", ",", "str", "(", "self", ".", "output_dim_2", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pi_hidden_dim_2\"", ",", "str", "(", "self", ".", "pi_hidden_dim_2", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pi_hidden_layers_2\"", ",", "str", "(", "self", ".", "pi_hidden_layers_2", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"vf_hidden_layers_2\"", ",", "str", "(", "self", ".", "vf_hidden_layers_2", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"vf_hidden_dim_2\"", ",", "str", "(", "self", ".", "vf_hidden_dim_2", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"filter_illegal_actions\"", ",", "str", "(", "self", ".", "filter_illegal_actions", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_deterministic\"", ",", "str", "(", "self", ".", "eval_deterministic", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"running_avg\"", ",", "str", "(", "self", ".", "running_avg", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.hparams_dict": [[259, 326], ["None"], "methods", ["None"], ["", "", "def", "hparams_dict", "(", "self", ")", "->", "dict", ":", "\n", "        ", "\"\"\"\n        Returns a dict with all of the hyperparameters\n        :return:\n        \"\"\"", "\n", "hparams", "=", "{", "}", "\n", "hparams", "[", "\"gamma\"", "]", "=", "self", ".", "gamma", "\n", "hparams", "[", "\"alpha\"", "]", "=", "self", ".", "alpha", "\n", "hparams", "[", "\"epsilon\"", "]", "=", "self", ".", "epsilon", "\n", "hparams", "[", "\"epsilon_decay\"", "]", "=", "self", ".", "epsilon_decay", "\n", "hparams", "[", "\"min_epsilon\"", "]", "=", "self", ".", "min_epsilon", "\n", "hparams", "[", "\"eval_episodes\"", "]", "=", "self", ".", "eval_episodes", "\n", "hparams", "[", "\"train_log_frequency\"", "]", "=", "self", ".", "train_log_frequency", "\n", "hparams", "[", "\"eval_log_frequency\"", "]", "=", "self", ".", "eval_log_frequency", "\n", "hparams", "[", "\"num_episodes\"", "]", "=", "self", ".", "num_episodes", "\n", "hparams", "[", "\"eval_frequency\"", "]", "=", "self", ".", "eval_frequency", "\n", "hparams", "[", "\"checkpoint_freq\"", "]", "=", "self", ".", "checkpoint_freq", "\n", "hparams", "[", "\"random_seed\"", "]", "=", "self", ".", "random_seed", "\n", "hparams", "[", "\"eval_epsilon\"", "]", "=", "self", ".", "eval_epsilon", "\n", "hparams", "[", "\"input_dim\"", "]", "=", "self", ".", "input_dim", "\n", "hparams", "[", "\"output_dim\"", "]", "=", "self", ".", "output_dim", "\n", "hparams", "[", "\"hidden_dim\"", "]", "=", "self", ".", "pi_hidden_dim", "\n", "hparams", "[", "\"batch_size\"", "]", "=", "self", ".", "batch_size", "\n", "hparams", "[", "\"num_hidden_layers\"", "]", "=", "self", ".", "pi_hidden_layers", "\n", "hparams", "[", "\"gpu\"", "]", "=", "self", ".", "gpu", "\n", "hparams", "[", "\"optimizer\"", "]", "=", "self", ".", "optimizer", "\n", "hparams", "[", "\"lr_exp_decay\"", "]", "=", "self", ".", "lr_exp_decay", "\n", "hparams", "[", "\"lr_decay_rate\"", "]", "=", "self", ".", "lr_decay_rate", "\n", "hparams", "[", "\"hidden_activation\"", "]", "=", "self", ".", "hidden_activation", "\n", "hparams", "[", "\"clip_gradient\"", "]", "=", "self", ".", "clip_gradient", "\n", "hparams", "[", "\"max_gradient_norm\"", "]", "=", "self", ".", "max_gradient_norm", "\n", "hparams", "[", "\"output_dim\"", "]", "=", "self", ".", "output_dim", "\n", "hparams", "[", "\"critic_loss_fn\"", "]", "=", "self", ".", "critic_loss_fn", "\n", "hparams", "[", "\"state_length\"", "]", "=", "self", ".", "state_length", "\n", "hparams", "[", "\"gpu_id\"", "]", "=", "self", ".", "gpu_id", "\n", "hparams", "[", "\"eps_clip\"", "]", "=", "self", ".", "eps_clip", "\n", "hparams", "[", "\"lr_progress_decay\"", "]", "=", "self", ".", "lr_progress_decay", "\n", "hparams", "[", "\"lr_progress_power_decay\"", "]", "=", "self", ".", "lr_progress_power_decay", "\n", "hparams", "[", "\"optimization_iterations\"", "]", "=", "self", ".", "optimization_iterations", "\n", "hparams", "[", "\"gae_lambda\"", "]", "=", "self", ".", "gae_lambda", "\n", "hparams", "[", "\"features_dim\"", "]", "=", "self", ".", "features_dim", "\n", "hparams", "[", "\"ent_coef\"", "]", "=", "self", ".", "ent_coef", "\n", "hparams", "[", "\"vf_coef\"", "]", "=", "self", ".", "vf_coef", "\n", "hparams", "[", "\"use_sde\"", "]", "=", "self", ".", "use_sde", "\n", "hparams", "[", "\"sde_sample_freq\"", "]", "=", "self", ".", "sde_sample_freq", "\n", "hparams", "[", "\"illegal_action_logit\"", "]", "=", "self", ".", "illegal_action_logit", "\n", "hparams", "[", "\"buffer_size\"", "]", "=", "self", ".", "buffer_size", "\n", "hparams", "[", "\"tau\"", "]", "=", "self", ".", "tau", "\n", "hparams", "[", "\"learning_starts\"", "]", "=", "self", ".", "learning_starts", "\n", "hparams", "[", "\"train_freq\"", "]", "=", "self", ".", "train_freq", "\n", "hparams", "[", "\"gradient_steps\"", "]", "=", "self", ".", "gradient_steps", "\n", "hparams", "[", "\"target_update_interval\"", "]", "=", "self", ".", "target_update_interval", "\n", "hparams", "[", "\"exploration_fraction\"", "]", "=", "self", ".", "exploration_fraction", "\n", "hparams", "[", "\"exploration_initial_eps\"", "]", "=", "self", ".", "exploration_initial_eps", "\n", "hparams", "[", "\"exploration_final_eps\"", "]", "=", "self", ".", "exploration_final_eps", "\n", "hparams", "[", "\"policy_delay\"", "]", "=", "self", ".", "policy_delay", "\n", "hparams", "[", "\"target_policy_noise\"", "]", "=", "self", ".", "target_policy_noise", "\n", "hparams", "[", "\"target_noise_clip\"", "]", "=", "self", ".", "target_noise_clip", "\n", "hparams", "[", "\"input_dim_2\"", "]", "=", "self", ".", "input_dim_2", "\n", "hparams", "[", "\"output_dim_2\"", "]", "=", "self", ".", "output_dim_2", "\n", "hparams", "[", "\"pi_hidden_dim_2\"", "]", "=", "self", ".", "pi_hidden_dim_2", "\n", "hparams", "[", "\"pi_hidden_layers_2\"", "]", "=", "self", ".", "pi_hidden_layers_2", "\n", "hparams", "[", "\"vf_hidden_layers_2\"", "]", "=", "self", ".", "vf_hidden_layers_2", "\n", "hparams", "[", "\"vf_hidden_dim_2\"", "]", "=", "self", ".", "vf_hidden_dim_2", "\n", "hparams", "[", "\"filter_illegal_actions\"", "]", "=", "self", ".", "filter_illegal_actions", "\n", "hparams", "[", "\"running_avg\"", "]", "=", "self", ".", "running_avg", "\n", "return", "hparams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.log_metrics_attacker": [[17, 227], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "gym_optimal_intrusion_response.dao.agent.tensorboard_data_dto.TensorboardDataDTO", "gym_optimal_intrusion_response.dao.agent.tensorboard_data_dto.TensorboardDataDTO.log_str_attacker", "attacker_agent_config.logger.info", "print", "sys.stdout.flush", "result.avg_episode_steps.append", "result.attacker_avg_episode_rewards.append", "result.epsilon_values.append", "result.attacker_avg_episode_loss.append", "result.avg_episode_flags.append", "result.avg_episode_flags_percentage.append", "result.attacker_eval_avg_episode_rewards.append", "result.eval_avg_episode_steps.append", "result.eval_avg_episode_flags.append", "result.eval_avg_episode_flags_percentage.append", "result.lr_list.append", "result.attacker_avg_regret.append", "result.attacker_avg_opt_frac.append", "result.attacker_eval_avg_regret.append", "result.attacker_eval_avg_opt_frac.append", "result.caught_frac.append", "result.early_stopping_frac.append", "result.intrusion_frac.append", "result.eval_caught_frac.append", "result.eval_early_stopping_frac.append", "result.eval_intrusion_frac.append", "result.attacker_action_costs.append", "result.attacker_action_costs_norm.append", "result.attacker_action_alerts.append", "result.attacker_action_alerts_norm.append", "result.eval_attacker_action_costs.append", "result.eval_attacker_action_costs_norm.append", "result.eval_attacker_action_alerts.append", "result.eval_attacker_action_alerts_norm.append", "result.time_elapsed.append", "time.time", "gym_optimal_intrusion_response.running_average", "gym_optimal_intrusion_response.running_average", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "gym_optimal_intrusion_response.dao.agent.tensorboard_data_dto.TensorboardDataDTO.log_tensorboard_attacker", "sum", "sum", "sum", "max", "sum", "max", "sum", "max", "sum", "max", "sum", "max", "sum", "max", "sum", "sum", "list", "sum", "sum", "list", "list", "list", "list", "list", "list", "list", "list", "list", "map", "list", "list", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_str_attacker", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.util.running_average", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.util.running_average", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_tensorboard_attacker"], ["@", "staticmethod", "\n", "def", "log_metrics_attacker", "(", "train_log_dto", ":", "TrainAgentLogDTO", ",", "eps", ":", "float", "=", "None", ",", "eval", ":", "bool", "=", "False", ",", "\n", "attacker_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "tensorboard_writer", "=", "None", ")", "->", "TrainAgentLogDTO", ":", "\n", "        ", "if", "eps", "is", "None", ":", "\n", "            ", "eps", "=", "0.0", "\n", "\n", "", "if", "not", "eval", ":", "\n", "            ", "result", "=", "train_log_dto", ".", "train_result", "\n", "", "else", ":", "\n", "            ", "result", "=", "train_log_dto", ".", "eval_result", "\n", "\n", "", "training_time", "=", "time", ".", "time", "(", ")", "-", "train_log_dto", ".", "start_time", "\n", "training_time_hours", "=", "training_time", "/", "3600", "\n", "avg_episode_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_episode_rewards", ")", "\n", "avg_episode_flags", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_flags", ")", "\n", "avg_episode_flags_percentage", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_flags_percentage", ")", "\n", "avg_episode_steps", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_steps", ")", "\n", "avg_episode_costs", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_costs", ")", "\n", "avg_episode_costs_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_costs_norm", ")", "\n", "avg_episode_alerts", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_alerts", ")", "\n", "avg_episode_alerts_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_alerts_norm", ")", "\n", "\n", "if", "train_log_dto", ".", "episode_caught", "is", "not", "None", "and", "train_log_dto", ".", "episode_early_stopped", "is", "not", "None", "and", "train_log_dto", ".", "episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "total_c_s_i", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_caught", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_early_stopped", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_successful_intrusion", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "total_c_s_i", "=", "1", "\n", "", "if", "train_log_dto", ".", "eval_episode_caught", "is", "not", "None", "and", "train_log_dto", ".", "eval_episode_early_stopped", "is", "not", "None", "and", "train_log_dto", ".", "eval_episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "eval_total_c_s_i", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "eval_episode_caught", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "eval_episode_early_stopped", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "eval_episode_successful_intrusion", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "eval_total_c_s_i", "=", "1", "\n", "", "if", "train_log_dto", ".", "episode_caught", "is", "not", "None", ":", "\n", "            ", "episode_caught_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_caught", ")", ")", ")", "/", "max", "(", "1", ",", "total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "episode_caught_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "episode_early_stopped", "is", "not", "None", ":", "\n", "            ", "episode_early_stopped_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "episode_early_stopped", ")", ")", ")", "/", "max", "(", "1", ",", "total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "episode_early_stopped_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "episode_successful_intrusion_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "episode_successful_intrusion", ")", ")", ")", "/", "max", "(", "1", ",", "\n", "total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "episode_successful_intrusion_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "eval_episode_caught", "is", "not", "None", ":", "\n", "            ", "eval_episode_caught_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "eval_episode_caught", ")", ")", ")", "/", "max", "(", "1", ",", "eval_total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "eval_episode_caught_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "eval_episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "eval_episode_successful_intrusion_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "eval_episode_successful_intrusion", ")", ")", ")", "/", "max", "(", "\n", "1", ",", "eval_total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "eval_episode_successful_intrusion_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "eval_episode_early_stopped", "is", "not", "None", ":", "\n", "            ", "eval_episode_early_stopped_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "eval_episode_early_stopped", ")", ")", ")", "/", "max", "(", "1", ",", "\n", "eval_total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "eval_episode_early_stopped_frac", "=", "0", "\n", "\n", "", "if", "result", ".", "attacker_avg_episode_rewards", "is", "not", "None", ":", "\n", "            ", "rolling_avg_rewards", "=", "os_util", ".", "running_average", "(", "result", ".", "attacker_avg_episode_rewards", "+", "[", "avg_episode_rewards", "]", ",", "\n", "attacker_agent_config", ".", "running_avg", ")", "\n", "", "else", ":", "\n", "            ", "rolling_avg_rewards", "=", "0.0", "\n", "\n", "", "if", "result", ".", "avg_episode_steps", "is", "not", "None", ":", "\n", "            ", "rolling_avg_steps", "=", "os_util", ".", "running_average", "(", "result", ".", "avg_episode_steps", "+", "[", "avg_episode_steps", "]", ",", "\n", "attacker_agent_config", ".", "running_avg", ")", "\n", "", "else", ":", "\n", "            ", "rolling_avg_steps", "=", "0.0", "\n", "\n", "", "if", "train_log_dto", ".", "attacker_lr", "is", "None", ":", "\n", "            ", "lr", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "lr", "=", "train_log_dto", ".", "attacker_lr", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "attacker_episode_avg_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_loss", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_episode_avg_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_loss", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "attacker_eval_episode_rewards", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_eval_episode_rewards", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_rewards", "=", "0.0", "\n", "\n", "", "avg_regret", "=", "0.0", "\n", "avg_eval_regret", "=", "0.0", "\n", "avg_opt_frac", "=", "0.0", "\n", "eval_avg_opt_frac", "=", "0.0", "\n", "\n", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_flags", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_flags", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_episode_flags", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_flags", "=", "0.0", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_flags_percentage", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_flags_percentage", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_episode_flags_percentage", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_flags_percentage", "=", "0.0", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_steps", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_steps", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_episode_steps", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_steps", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_costs", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_costs", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_costs", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_costs", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_costs_norm", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_costs_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_costs_norm", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_costs_norm", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_alerts", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_alerts", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_alerts", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_alerts", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_alerts_norm", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_alerts_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_alerts_norm", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_alerts_norm", "=", "0.0", "\n", "\n", "", "tensorboard_data_dto", "=", "TensorboardDataDTO", "(", "\n", "iteration", "=", "train_log_dto", ".", "iteration", ",", "avg_episode_rewards", "=", "avg_episode_rewards", ",", "\n", "avg_episode_steps", "=", "avg_episode_steps", ",", "\n", "avg_episode_loss", "=", "avg_episode_loss", ",", "eps", "=", "eps", ",", "lr", "=", "lr", ",", "eval", "=", "eval", ",", "\n", "avg_flags_catched", "=", "avg_episode_flags", ",", "avg_episode_flags_percentage", "=", "avg_episode_flags_percentage", ",", "\n", "eval_avg_episode_rewards", "=", "eval_avg_episode_rewards", ",", "eval_avg_episode_steps", "=", "eval_avg_episode_steps", ",", "\n", "eval_avg_episode_flags", "=", "eval_avg_episode_flags", ",", "\n", "eval_avg_episode_flags_percentage", "=", "eval_avg_episode_flags_percentage", ",", "\n", "rolling_avg_episode_rewards", "=", "rolling_avg_rewards", ",", "\n", "rolling_avg_episode_steps", "=", "rolling_avg_steps", ",", "\n", "tensorboard_writer", "=", "tensorboard_writer", ",", "\n", "episode_caught_frac", "=", "episode_caught_frac", ",", "\n", "episode_early_stopped_frac", "=", "episode_early_stopped_frac", ",", "\n", "episode_successful_intrusion_frac", "=", "episode_successful_intrusion_frac", ",", "\n", "eval_episode_caught_frac", "=", "eval_episode_caught_frac", ",", "\n", "eval_episode_early_stopped_frac", "=", "eval_episode_early_stopped_frac", ",", "\n", "eval_episode_successful_intrusion_frac", "=", "eval_episode_successful_intrusion_frac", ",", "\n", "avg_regret", "=", "avg_regret", ",", "avg_opt_frac", "=", "avg_opt_frac", ",", "rolling_avg_rewards", "=", "rolling_avg_rewards", ",", "\n", "rolling_avg_steps", "=", "rolling_avg_steps", ",", "avg_episode_flags", "=", "avg_episode_flags", ",", "\n", "n_af", "=", "train_log_dto", ".", "n_af", ",", "n_d", "=", "train_log_dto", ".", "n_d", ",", "avg_episode_costs", "=", "avg_episode_costs", ",", "\n", "avg_episode_costs_norm", "=", "avg_episode_costs_norm", ",", "\n", "avg_episode_alerts", "=", "avg_episode_alerts", ",", "avg_episode_alerts_norm", "=", "avg_episode_alerts_norm", ",", "\n", "eval_avg_episode_costs", "=", "eval_avg_episode_costs", ",", "eval_avg_episode_costs_norm", "=", "eval_avg_episode_costs_norm", ",", "\n", "eval_avg_episode_alerts", "=", "eval_avg_episode_alerts", ",", "eval_avg_episode_alerts_norm", "=", "eval_avg_episode_alerts_norm", ",", "\n", "total_num_episodes", "=", "train_log_dto", ".", "total_num_episodes", ",", "avg_eval_regret", "=", "avg_eval_regret", ",", "\n", "eval_avg_opt_frac", "=", "eval_avg_opt_frac", ",", "\n", "epsilon", "=", "attacker_agent_config", ".", "epsilon", ",", "\n", "training_time_hours", "=", "training_time_hours", ")", "\n", "log_str", "=", "tensorboard_data_dto", ".", "log_str_attacker", "(", ")", "\n", "attacker_agent_config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "print", "(", "log_str", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "if", "attacker_agent_config", ".", "tensorboard", ":", "\n", "            ", "tensorboard_data_dto", ".", "log_tensorboard_attacker", "(", ")", "\n", "\n", "", "result", ".", "avg_episode_steps", ".", "append", "(", "avg_episode_steps", ")", "\n", "result", ".", "attacker_avg_episode_rewards", ".", "append", "(", "avg_episode_rewards", ")", "\n", "result", ".", "epsilon_values", ".", "append", "(", "attacker_agent_config", ".", "epsilon", ")", "\n", "result", ".", "attacker_avg_episode_loss", ".", "append", "(", "avg_episode_loss", ")", "\n", "result", ".", "avg_episode_flags", ".", "append", "(", "avg_episode_flags", ")", "\n", "result", ".", "avg_episode_flags_percentage", ".", "append", "(", "avg_episode_flags_percentage", ")", "\n", "result", ".", "attacker_eval_avg_episode_rewards", ".", "append", "(", "eval_avg_episode_rewards", ")", "\n", "result", ".", "eval_avg_episode_steps", ".", "append", "(", "eval_avg_episode_steps", ")", "\n", "result", ".", "eval_avg_episode_flags", ".", "append", "(", "eval_avg_episode_flags", ")", "\n", "result", ".", "eval_avg_episode_flags_percentage", ".", "append", "(", "eval_avg_episode_flags_percentage", ")", "\n", "result", ".", "lr_list", ".", "append", "(", "train_log_dto", ".", "attacker_lr", ")", "\n", "result", ".", "attacker_avg_regret", ".", "append", "(", "avg_regret", ")", "\n", "result", ".", "attacker_avg_opt_frac", ".", "append", "(", "avg_opt_frac", ")", "\n", "result", ".", "attacker_eval_avg_regret", ".", "append", "(", "avg_eval_regret", ")", "\n", "result", ".", "attacker_eval_avg_opt_frac", ".", "append", "(", "eval_avg_opt_frac", ")", "\n", "result", ".", "caught_frac", ".", "append", "(", "episode_caught_frac", ")", "\n", "result", ".", "early_stopping_frac", ".", "append", "(", "episode_early_stopped_frac", ")", "\n", "result", ".", "intrusion_frac", ".", "append", "(", "episode_successful_intrusion_frac", ")", "\n", "result", ".", "eval_caught_frac", ".", "append", "(", "eval_episode_caught_frac", ")", "\n", "result", ".", "eval_early_stopping_frac", ".", "append", "(", "eval_episode_early_stopped_frac", ")", "\n", "result", ".", "eval_intrusion_frac", ".", "append", "(", "eval_episode_successful_intrusion_frac", ")", "\n", "result", ".", "attacker_action_costs", ".", "append", "(", "avg_episode_costs", ")", "\n", "result", ".", "attacker_action_costs_norm", ".", "append", "(", "avg_episode_costs_norm", ")", "\n", "result", ".", "attacker_action_alerts", ".", "append", "(", "avg_episode_alerts", ")", "\n", "result", ".", "attacker_action_alerts_norm", ".", "append", "(", "avg_episode_alerts_norm", ")", "\n", "result", ".", "eval_attacker_action_costs", ".", "append", "(", "eval_avg_episode_costs", ")", "\n", "result", ".", "eval_attacker_action_costs_norm", ".", "append", "(", "eval_avg_episode_costs_norm", ")", "\n", "result", ".", "eval_attacker_action_alerts", ".", "append", "(", "eval_avg_episode_alerts", ")", "\n", "result", ".", "eval_attacker_action_alerts_norm", ".", "append", "(", "eval_avg_episode_alerts_norm", ")", "\n", "result", ".", "time_elapsed", ".", "append", "(", "training_time", ")", "\n", "\n", "if", "not", "eval", ":", "\n", "            ", "train_log_dto", ".", "train_result", "=", "result", "\n", "", "else", ":", "\n", "            ", "train_log_dto", ".", "eval_result", "=", "result", "\n", "", "return", "train_log_dto", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.log_metrics_defender": [[229, 500], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "gym_optimal_intrusion_response.dao.agent.tensorboard_data_dto.TensorboardDataDTO", "gym_optimal_intrusion_response.dao.agent.tensorboard_data_dto.TensorboardDataDTO.log_str_defender", "defender_agent_config.logger.info", "print", "sys.stdout.flush", "result.defender_avg_episode_rewards.append", "result.defender_avg_episode_loss.append", "result.defender_eval_avg_episode_rewards.append", "result.defender_avg_regret.append", "result.defender_avg_opt_frac.append", "result.defender_eval_avg_regret.append", "result.defender_eval_avg_opt_frac.append", "result.snort_severe_baseline_rewards.append", "result.snort_warning_baseline_rewards.append", "result.eval_snort_severe_baseline_rewards.append", "result.eval_snort_warning_baseline_rewards.append", "result.snort_critical_baseline_rewards.append", "result.var_log_baseline_rewards.append", "result.eval_snort_critical_baseline_rewards.append", "result.eval_var_log_baseline_rewards.append", "time.time", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "gym_optimal_intrusion_response.running_average", "gym_optimal_intrusion_response.running_average", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "gym_optimal_intrusion_response.dao.agent.tensorboard_data_dto.TensorboardDataDTO.log_tensorboard_defender", "result.avg_episode_steps.append", "result.epsilon_values.append", "result.eval_avg_episode_steps.append", "result.lr_list.append", "result.caught_frac.append", "result.early_stopping_frac.append", "result.intrusion_frac.append", "result.eval_caught_frac.append", "result.eval_early_stopping_frac.append", "result.eval_intrusion_frac.append", "result.attacker_action_costs.append", "result.attacker_action_costs_norm.append", "result.attacker_action_alerts.append", "result.attacker_action_alerts_norm.append", "result.eval_attacker_action_costs.append", "result.eval_attacker_action_costs_norm.append", "result.eval_attacker_action_alerts.append", "result.eval_attacker_action_alerts_norm.append", "result.avg_episode_flags.append", "result.avg_episode_flags_percentage.append", "result.eval_avg_episode_flags.append", "result.eval_avg_episode_flags_percentage.append", "result.optimal_rewards.append", "result.optimal_steps.append", "result.intrusion_steps.append", "sum", "sum", "sum", "max", "sum", "max", "sum", "max", "sum", "max", "sum", "max", "sum", "max", "sum", "sum", "list", "sum", "sum", "list", "list", "list", "list", "list", "list", "list", "list", "list", "map", "list", "list", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_str_defender", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.util.running_average", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.util.running_average", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.tensorboard_data_dto.TensorboardDataDTO.log_tensorboard_defender"], ["", "@", "staticmethod", "\n", "def", "log_metrics_defender", "(", "train_log_dto", ":", "TrainAgentLogDTO", ",", "eps", ":", "float", "=", "None", ",", "eval", ":", "bool", "=", "False", ",", "\n", "defender_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "tensorboard_writer", "=", "None", ",", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ")", "->", "TrainAgentLogDTO", ":", "\n", "        ", "if", "eps", "is", "None", ":", "\n", "            ", "eps", "=", "0.0", "\n", "\n", "", "if", "not", "eval", ":", "\n", "            ", "result", "=", "train_log_dto", ".", "train_result", "\n", "", "else", ":", "\n", "            ", "result", "=", "train_log_dto", ".", "eval_result", "\n", "\n", "", "training_time", "=", "time", ".", "time", "(", ")", "-", "train_log_dto", ".", "start_time", "\n", "training_time_hours", "=", "training_time", "/", "3600", "\n", "\n", "avg_episode_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "defender_episode_rewards", ")", "\n", "avg_episode_steps", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_steps", ")", "\n", "avg_episode_snort_severe_baseline_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_snort_severe_baseline_rewards", ")", "\n", "avg_episode_snort_warning_baseline_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_snort_warning_baseline_rewards", ")", "\n", "avg_episode_snort_critical_baseline_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_snort_critical_baseline_rewards", ")", "\n", "avg_episode_var_log_baseline_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_var_log_baseline_rewards", ")", "\n", "avg_episode_costs", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_costs", ")", "\n", "avg_episode_costs_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_costs_norm", ")", "\n", "avg_episode_alerts", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_alerts", ")", "\n", "avg_episode_alerts_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "attacker_action_alerts_norm", ")", "\n", "\n", "avg_episode_optimal_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "optimal_rewards", ")", "\n", "avg_episode_optimal_steps", "=", "np", ".", "mean", "(", "train_log_dto", ".", "optimal_steps", ")", "\n", "avg_intrusion_steps", "=", "np", ".", "mean", "(", "train_log_dto", ".", "intrusion_steps", ")", "\n", "\n", "avg_episode_flags", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_flags", ")", "\n", "avg_episode_flags_percentage", "=", "np", ".", "mean", "(", "train_log_dto", ".", "episode_flags_percentage", ")", "\n", "\n", "if", "train_log_dto", ".", "episode_caught", "is", "not", "None", "and", "train_log_dto", ".", "episode_early_stopped", "is", "not", "None", "and", "train_log_dto", ".", "episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "total_c_s_i", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_caught", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_early_stopped", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_successful_intrusion", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "total_c_s_i", "=", "1", "\n", "", "if", "train_log_dto", ".", "eval_episode_caught", "is", "not", "None", "and", "train_log_dto", ".", "eval_episode_early_stopped", "is", "not", "None", "and", "train_log_dto", ".", "eval_episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "eval_total_c_s_i", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "eval_episode_caught", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "eval_episode_early_stopped", ")", ")", ")", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "eval_episode_successful_intrusion", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "eval_total_c_s_i", "=", "1", "\n", "", "if", "train_log_dto", ".", "episode_caught", "is", "not", "None", ":", "\n", "            ", "episode_caught_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "train_log_dto", ".", "episode_caught", ")", ")", ")", "/", "max", "(", "1", ",", "total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "episode_caught_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "episode_early_stopped", "is", "not", "None", ":", "\n", "            ", "episode_early_stopped_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "episode_early_stopped", ")", ")", ")", "/", "max", "(", "1", ",", "total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "episode_early_stopped_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "episode_successful_intrusion_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "episode_successful_intrusion", ")", ")", ")", "/", "max", "(", "1", ",", "\n", "total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "episode_successful_intrusion_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "eval_episode_caught", "is", "not", "None", ":", "\n", "            ", "eval_episode_caught_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "eval_episode_caught", ")", ")", ")", "/", "max", "(", "1", ",", "eval_total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "eval_episode_caught_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "eval_episode_successful_intrusion", "is", "not", "None", ":", "\n", "            ", "eval_episode_successful_intrusion_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "eval_episode_successful_intrusion", ")", ")", ")", "/", "max", "(", "\n", "1", ",", "eval_total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "eval_episode_successful_intrusion_frac", "=", "0", "\n", "\n", "", "if", "train_log_dto", ".", "eval_episode_early_stopped", "is", "not", "None", ":", "\n", "            ", "eval_episode_early_stopped_frac", "=", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "\n", "train_log_dto", ".", "eval_episode_early_stopped", ")", ")", ")", "/", "max", "(", "1", ",", "\n", "eval_total_c_s_i", ")", "\n", "", "else", ":", "\n", "            ", "eval_episode_early_stopped_frac", "=", "0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_flags", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_flags", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_episode_flags", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_flags", "=", "0.0", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_flags_percentage", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_flags_percentage", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_episode_flags_percentage", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_flags_percentage", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_steps", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_steps", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_episode_steps", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_steps", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_costs", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_costs", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_costs", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_costs", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_costs_norm", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_costs_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_costs_norm", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_costs_norm", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_alerts", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_alerts", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_alerts", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_alerts", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_attacker_action_alerts_norm", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_alerts_norm", "=", "np", ".", "mean", "(", "train_log_dto", ".", "eval_attacker_action_alerts_norm", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_alerts_norm", "=", "0.0", "\n", "\n", "", "if", "result", ".", "defender_avg_episode_rewards", "is", "not", "None", ":", "\n", "            ", "rolling_avg_rewards", "=", "os_util", ".", "running_average", "(", "result", ".", "defender_avg_episode_rewards", "+", "[", "avg_episode_rewards", "]", ",", "\n", "defender_agent_config", ".", "running_avg", ")", "\n", "", "else", ":", "\n", "            ", "rolling_avg_rewards", "=", "0.0", "\n", "\n", "", "if", "result", ".", "avg_episode_steps", "is", "not", "None", ":", "\n", "            ", "rolling_avg_steps", "=", "os_util", ".", "running_average", "(", "result", ".", "avg_episode_steps", "+", "[", "avg_episode_steps", "]", ",", "\n", "defender_agent_config", ".", "running_avg", ")", "\n", "", "else", ":", "\n", "            ", "rolling_avg_steps", "=", "0.0", "\n", "\n", "", "if", "train_log_dto", ".", "defender_lr", "is", "None", ":", "\n", "            ", "lr", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "lr", "=", "train_log_dto", ".", "defender_lr", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "defender_episode_avg_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_loss", "=", "np", ".", "mean", "(", "train_log_dto", ".", "defender_episode_avg_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_loss", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "defender_eval_episode_rewards", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_rewards", "=", "np", ".", "mean", "(", "train_log_dto", ".", "defender_eval_episode_rewards", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_rewards", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_snort_severe_baseline_rewards", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_snort_severe_baseline_rewards", "=", "np", ".", "mean", "(", "\n", "train_log_dto", ".", "eval_episode_snort_severe_baseline_rewards", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_snort_severe_baseline_rewards", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_snort_warning_baseline_rewards", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_snort_warning_baseline_rewards", "=", "np", ".", "mean", "(", "\n", "train_log_dto", ".", "eval_episode_snort_warning_baseline_rewards", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_snort_warning_baseline_rewards", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_snort_critical_baseline_rewards", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_snort_critical_baseline_rewards", "=", "np", ".", "mean", "(", "\n", "train_log_dto", ".", "eval_episode_snort_critical_baseline_rewards", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_snort_critical_baseline_rewards", "=", "0.0", "\n", "\n", "", "if", "not", "eval", "and", "train_log_dto", ".", "eval_episode_var_log_baseline_rewards", "is", "not", "None", ":", "\n", "            ", "eval_avg_episode_var_log_baseline_rewards", "=", "np", ".", "mean", "(", "\n", "train_log_dto", ".", "eval_episode_var_log_baseline_rewards", ")", "\n", "", "else", ":", "\n", "            ", "eval_avg_episode_var_log_baseline_rewards", "=", "0.0", "\n", "", "avg_regret", "=", "0.0", "\n", "avg_eval_regret", "=", "0.0", "\n", "avg_opt_frac", "=", "0.0", "\n", "eval_avg_opt_frac", "=", "0.0", "\n", "\n", "tensorboard_data_dto", "=", "TensorboardDataDTO", "(", "\n", "iteration", "=", "train_log_dto", ".", "iteration", ",", "avg_episode_rewards", "=", "avg_episode_rewards", ",", "\n", "avg_episode_steps", "=", "avg_episode_steps", ",", "\n", "avg_episode_loss", "=", "avg_episode_loss", ",", "eps", "=", "eps", ",", "lr", "=", "lr", ",", "eval", "=", "eval", ",", "\n", "eval_avg_episode_rewards", "=", "eval_avg_episode_rewards", ",", "eval_avg_episode_steps", "=", "eval_avg_episode_steps", ",", "\n", "rolling_avg_episode_rewards", "=", "rolling_avg_rewards", ",", "\n", "rolling_avg_episode_steps", "=", "rolling_avg_steps", ",", "\n", "tensorboard_writer", "=", "tensorboard_writer", ",", "\n", "episode_caught_frac", "=", "episode_caught_frac", ",", "\n", "episode_early_stopped_frac", "=", "episode_early_stopped_frac", ",", "\n", "episode_successful_intrusion_frac", "=", "episode_successful_intrusion_frac", ",", "\n", "eval_episode_caught_frac", "=", "eval_episode_caught_frac", ",", "\n", "eval_episode_early_stopped_frac", "=", "eval_episode_early_stopped_frac", ",", "\n", "eval_episode_successful_intrusion_frac", "=", "eval_episode_successful_intrusion_frac", ",", "\n", "avg_regret", "=", "avg_regret", ",", "avg_opt_frac", "=", "avg_opt_frac", ",", "rolling_avg_rewards", "=", "rolling_avg_rewards", ",", "\n", "rolling_avg_steps", "=", "rolling_avg_steps", ",", "\n", "n_af", "=", "train_log_dto", ".", "n_af", ",", "n_d", "=", "train_log_dto", ".", "n_d", ",", "avg_episode_costs", "=", "avg_episode_costs", ",", "\n", "avg_episode_costs_norm", "=", "avg_episode_costs_norm", ",", "\n", "avg_episode_alerts", "=", "avg_episode_alerts", ",", "avg_episode_alerts_norm", "=", "avg_episode_alerts_norm", ",", "\n", "eval_avg_episode_costs", "=", "eval_avg_episode_costs", ",", "eval_avg_episode_costs_norm", "=", "eval_avg_episode_costs_norm", ",", "\n", "eval_avg_episode_alerts", "=", "eval_avg_episode_alerts", ",", "eval_avg_episode_alerts_norm", "=", "eval_avg_episode_alerts_norm", ",", "\n", "total_num_episodes", "=", "train_log_dto", ".", "total_num_episodes", ",", "avg_eval_regret", "=", "avg_eval_regret", ",", "\n", "eval_avg_opt_frac", "=", "eval_avg_opt_frac", ",", "\n", "epsilon", "=", "defender_agent_config", ".", "epsilon", ",", "training_time_hours", "=", "training_time_hours", ",", "\n", "avg_episode_snort_severe_baseline_rewards", "=", "avg_episode_snort_severe_baseline_rewards", ",", "\n", "avg_episode_snort_warning_baseline_rewards", "=", "avg_episode_snort_warning_baseline_rewards", ",", "\n", "eval_avg_episode_snort_severe_baseline_rewards", "=", "eval_avg_episode_snort_severe_baseline_rewards", ",", "\n", "eval_avg_episode_snort_warning_baseline_rewards", "=", "eval_avg_episode_snort_warning_baseline_rewards", ",", "\n", "avg_episode_snort_critical_baseline_rewards", "=", "avg_episode_snort_critical_baseline_rewards", ",", "\n", "avg_episode_var_log_baseline_rewards", "=", "avg_episode_var_log_baseline_rewards", ",", "\n", "eval_avg_episode_snort_critical_baseline_rewards", "=", "eval_avg_episode_snort_critical_baseline_rewards", ",", "\n", "eval_avg_episode_var_log_baseline_rewards", "=", "eval_avg_episode_var_log_baseline_rewards", ",", "\n", "avg_flags_catched", "=", "avg_episode_flags", ",", "avg_episode_flags_percentage", "=", "avg_episode_flags_percentage", ",", "\n", "eval_avg_episode_flags", "=", "eval_avg_episode_flags", ",", "\n", "eval_avg_episode_flags_percentage", "=", "eval_avg_episode_flags_percentage", ",", "\n", "avg_optimal_reward", "=", "avg_episode_optimal_rewards", ",", "\n", "avg_optimal_steps", "=", "avg_episode_optimal_steps", ",", "\n", "avg_intrusion_steps", "=", "avg_intrusion_steps", "\n", ")", "\n", "log_str", "=", "tensorboard_data_dto", ".", "log_str_defender", "(", ")", "\n", "defender_agent_config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "print", "(", "log_str", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "if", "defender_agent_config", ".", "tensorboard", ":", "\n", "            ", "tensorboard_data_dto", ".", "log_tensorboard_defender", "(", ")", "\n", "\n", "# Defender specific metrics", "\n", "", "result", ".", "defender_avg_episode_rewards", ".", "append", "(", "avg_episode_rewards", ")", "\n", "result", ".", "defender_avg_episode_loss", ".", "append", "(", "avg_episode_loss", ")", "\n", "result", ".", "defender_eval_avg_episode_rewards", ".", "append", "(", "eval_avg_episode_rewards", ")", "\n", "result", ".", "defender_avg_regret", ".", "append", "(", "avg_regret", ")", "\n", "result", ".", "defender_avg_opt_frac", ".", "append", "(", "avg_opt_frac", ")", "\n", "result", ".", "defender_eval_avg_regret", ".", "append", "(", "avg_eval_regret", ")", "\n", "result", ".", "defender_eval_avg_opt_frac", ".", "append", "(", "eval_avg_opt_frac", ")", "\n", "result", ".", "snort_severe_baseline_rewards", ".", "append", "(", "avg_episode_snort_severe_baseline_rewards", ")", "\n", "result", ".", "snort_warning_baseline_rewards", ".", "append", "(", "avg_episode_snort_warning_baseline_rewards", ")", "\n", "result", ".", "eval_snort_severe_baseline_rewards", ".", "append", "(", "eval_avg_episode_snort_severe_baseline_rewards", ")", "\n", "result", ".", "eval_snort_warning_baseline_rewards", ".", "append", "(", "eval_avg_episode_snort_warning_baseline_rewards", ")", "\n", "result", ".", "snort_critical_baseline_rewards", ".", "append", "(", "avg_episode_snort_critical_baseline_rewards", ")", "\n", "result", ".", "var_log_baseline_rewards", ".", "append", "(", "avg_episode_var_log_baseline_rewards", ")", "\n", "result", ".", "eval_snort_critical_baseline_rewards", ".", "append", "(", "eval_avg_episode_snort_critical_baseline_rewards", ")", "\n", "result", ".", "eval_var_log_baseline_rewards", ".", "append", "(", "eval_avg_episode_var_log_baseline_rewards", ")", "\n", "\n", "\n", "# General metrics", "\n", "if", "not", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "result", ".", "avg_episode_steps", ".", "append", "(", "avg_episode_steps", ")", "\n", "result", ".", "epsilon_values", ".", "append", "(", "defender_agent_config", ".", "epsilon", ")", "\n", "result", ".", "eval_avg_episode_steps", ".", "append", "(", "eval_avg_episode_steps", ")", "\n", "result", ".", "lr_list", ".", "append", "(", "train_log_dto", ".", "defender_lr", ")", "\n", "result", ".", "caught_frac", ".", "append", "(", "episode_caught_frac", ")", "\n", "result", ".", "early_stopping_frac", ".", "append", "(", "episode_early_stopped_frac", ")", "\n", "result", ".", "intrusion_frac", ".", "append", "(", "episode_successful_intrusion_frac", ")", "\n", "result", ".", "eval_caught_frac", ".", "append", "(", "eval_episode_caught_frac", ")", "\n", "result", ".", "eval_early_stopping_frac", ".", "append", "(", "eval_episode_early_stopped_frac", ")", "\n", "result", ".", "eval_intrusion_frac", ".", "append", "(", "eval_episode_successful_intrusion_frac", ")", "\n", "result", ".", "attacker_action_costs", ".", "append", "(", "avg_episode_costs", ")", "\n", "result", ".", "attacker_action_costs_norm", ".", "append", "(", "avg_episode_costs_norm", ")", "\n", "result", ".", "attacker_action_alerts", ".", "append", "(", "avg_episode_alerts", ")", "\n", "result", ".", "attacker_action_alerts_norm", ".", "append", "(", "avg_episode_alerts_norm", ")", "\n", "result", ".", "eval_attacker_action_costs", ".", "append", "(", "eval_avg_episode_costs", ")", "\n", "result", ".", "eval_attacker_action_costs_norm", ".", "append", "(", "eval_avg_episode_costs_norm", ")", "\n", "result", ".", "eval_attacker_action_alerts", ".", "append", "(", "eval_avg_episode_alerts", ")", "\n", "result", ".", "eval_attacker_action_alerts_norm", ".", "append", "(", "eval_avg_episode_alerts_norm", ")", "\n", "result", ".", "avg_episode_flags", ".", "append", "(", "avg_episode_flags", ")", "\n", "result", ".", "avg_episode_flags_percentage", ".", "append", "(", "avg_episode_flags_percentage", ")", "\n", "result", ".", "eval_avg_episode_flags", ".", "append", "(", "eval_avg_episode_flags", ")", "\n", "result", ".", "eval_avg_episode_flags_percentage", ".", "append", "(", "eval_avg_episode_flags_percentage", ")", "\n", "result", ".", "optimal_rewards", ".", "append", "(", "avg_episode_optimal_rewards", ")", "\n", "result", ".", "optimal_steps", ".", "append", "(", "avg_episode_optimal_steps", ")", "\n", "result", ".", "intrusion_steps", ".", "append", "(", "avg_intrusion_steps", ")", "\n", "\n", "if", "not", "eval", ":", "\n", "                ", "train_log_dto", ".", "train_result", "=", "result", "\n", "", "else", ":", "\n", "                ", "train_log_dto", ".", "eval_result", "=", "result", "\n", "", "return", "train_log_dto", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.compute_opt_frac": [[501, 517], ["abs"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "compute_opt_frac", "(", "r", ":", "float", ",", "opt_r", ":", "float", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Utility function for computing fraction of optimal reward\n\n        :param r: reward\n        :param opt_r: optimal reward\n        :return: fraction of optimal reward\n        \"\"\"", "\n", "abs_difference", "=", "abs", "(", "opt_r", "-", "r", ")", "\n", "if", "(", "r", ">=", "0", "and", "opt_r", ">=", "0", ")", "or", "(", "r", "<=", "0", "and", "opt_r", "<=", "0", ")", ":", "\n", "            ", "return", "r", "/", "opt_r", "\n", "", "elif", "r", "<", "0", "and", "opt_r", ">", "0", ":", "\n", "            ", "return", "1", "/", "abs_difference", "\n", "", "else", ":", "\n", "            ", "return", "1", "/", "abs_difference", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.log_util.LogUtil.compute_regret": [[518, 528], ["abs"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "compute_regret", "(", "r", ":", "float", ",", "opt_r", ":", "float", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Utility function for computing the regret\n\n        :param r: the reward\n        :param opt_r: the optimal reward\n        :return: the regret\n        \"\"\"", "\n", "return", "abs", "(", "opt_r", "-", "r", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.run_experiment": [[18, 62], ["str", "experiments_util.create_artifact_dirs", "experiments_util.setup_logger", "time.time", "config.attacker_agent_config.to_csv", "Runner.run", "Runner.run", "len", "train_result.to_csv", "len", "eval_result.to_csv", "str", "str", "str", "str", "str", "str", "experiments_util.default_output_dir", "experiments_util.default_output_dir", "experiments_util.default_output_dir", "experiments_util.default_output_dir", "experiments_util.default_output_dir", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.create_artifact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["def", "run_experiment", "(", "config", ":", "ClientConfig", ",", "random_seed", ":", "int", ",", "title", ":", "str", "=", "\"v0\"", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    Runs an individual experiment\n\n    :param config: the config of the experiment\n    :param random_seed: random seed\n    :param title: title of the experiment\n    :return: train_csv_path, eval_csv_path\n    \"\"\"", "\n", "from", "gym_optimal_intrusion_response", ".", "runner", ".", "runner", "import", "Runner", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "create_artifact_dirs", "(", "config", ".", "output_dir", ",", "random_seed", ")", "\n", "logger", "=", "setup_logger", "(", "title", ",", "config", ".", "output_dir", "+", "\"/results/logs/\"", "+", "\n", "str", "(", "random_seed", ")", "+", "\"/\"", ",", "\n", "time_str", "=", "time_str", ")", "\n", "if", "config", ".", "attacker_agent_config", "is", "not", "None", ":", "\n", "        ", "config", ".", "attacker_agent_config", ".", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "\n", "config", ".", "attacker_agent_config", ".", "video_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/videos/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "\n", "config", ".", "attacker_agent_config", ".", "gif_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "\n", "config", ".", "attacker_agent_config", ".", "tensorboard_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "\n", "config", ".", "env_checkpoint_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/env_data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "\n", "config", ".", "attacker_agent_config", ".", "logger", "=", "logger", "\n", "config", ".", "attacker_agent_config", ".", "random_seed", "=", "random_seed", "\n", "config", ".", "attacker_agent_config", ".", "to_csv", "(", "\n", "config", ".", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "+", "time_str", "+", "\".csv\"", ")", "\n", "\n", "\n", "", "config", ".", "logger", "=", "logger", "\n", "config", ".", "random_seed", "=", "random_seed", "\n", "train_csv_path", "=", "\"\"", "\n", "eval_csv_path", "=", "\"\"", "\n", "if", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", "or", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", "or", "config", ".", "mode", "==", "RunnerMode", ".", "SIMULATE", ".", "value", ":", "\n", "        ", "train_result", ",", "eval_result", "=", "Runner", ".", "run", "(", "config", ")", "\n", "if", "len", "(", "train_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "train_csv_path", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "+", "time_str", "+", "\"_train\"", "+", "\".csv\"", "\n", "train_result", ".", "to_csv", "(", "train_csv_path", ")", "\n", "", "if", "len", "(", "eval_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "eval_csv_path", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", "+", "time_str", "+", "\"_eval\"", "+", "\".csv\"", "\n", "eval_result", ".", "to_csv", "(", "eval_csv_path", ")", "\n", "", "return", "train_csv_path", ",", "eval_csv_path", "\n", "", "else", ":", "\n", "        ", "Runner", ".", "run", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.create_artifact_dirs": [[64, 86], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "", "def", "create_artifact_dirs", "(", "output_dir", ":", "str", ",", "random_seed", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Creates artefact directories if they do not already exist\n\n    :param output_dir: the base directory\n    :param random_seed: the random seed of the experiment\n    :return: None\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/logs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/logs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/env_data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/env_data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.setup_logger": [[88, 116], ["logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "str", "time.time"], "function", ["None"], ["", "", "def", "setup_logger", "(", "name", ":", "str", ",", "logdir", ":", "str", ",", "time_str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Configures the logger for writing log-data of experiments\n\n    :param name: name of the logger\n    :param logdir: directory to save log files\n    :param time_str: time string for file names\n    :return: None\n    \"\"\"", "\n", "# create formatter", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s,%(message)s'", ")", "\n", "# log to console", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "# log to file", "\n", "if", "time_str", "is", "None", ":", "\n", "        ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "", "fh", "=", "logging", ".", "FileHandler", "(", "logdir", "+", "\"/\"", "+", "time_str", "+", "\"_\"", "+", "name", "+", "\".log\"", ",", "mode", "=", "\"w\"", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "# add the handlers to the logger", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.write_config_file": [[118, 129], ["json.dumps", "json.loads", "io.open", "f.write", "jsonpickle.encode"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.TensorBoardOutputFormat.write"], ["", "def", "write_config_file", "(", "config", ":", "ClientConfig", ",", "path", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Writes a config object to a config file\n\n    :param config: the config to write\n    :param path: the path to write the file\n    :return: None\n    \"\"\"", "\n", "json_str", "=", "json", ".", "dumps", "(", "json", ".", "loads", "(", "jsonpickle", ".", "encode", "(", "config", ")", ")", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "with", "io", ".", "open", "(", "path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.read_config": [[131, 142], ["jsonpickle.decode", "io.open", "f.read"], "function", ["None"], ["", "", "def", "read_config", "(", "config_path", ")", "->", "ClientConfig", ":", "\n", "    ", "\"\"\"\n    Reads configuration of the experiment from a json file\n\n    :param config_path: the path to the configuration file\n    :return: the configuration\n    \"\"\"", "\n", "with", "io", ".", "open", "(", "config_path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "json_str", "=", "f", ".", "read", "(", ")", "\n", "", "client_config", ":", "ClientConfig", "=", "jsonpickle", ".", "decode", "(", "json_str", ")", "\n", "return", "client_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.parse_args": [[144, 161], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.parse_args"], ["", "def", "parse_args", "(", "default_config_path", ")", ":", "\n", "    ", "\"\"\"\n    Parses the commandline arguments with argparse\n\n    :param default_config_path: default path to config file\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Parse flags to configure the json parsing'", ")", "\n", "parser", ".", "add_argument", "(", "\"-cp\"", ",", "\"--configpath\"", ",", "help", "=", "\"Path to configuration file\"", ",", "\n", "default", "=", "default_config_path", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"-po\"", ",", "\"--plotonly\"", ",", "help", "=", "\"Boolean parameter, if true, only plot\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-nc\"", ",", "\"--noconfig\"", ",", "help", "=", "\"Boolean parameter, if true always override config\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-cs\"", ",", "\"--csvfile\"", ",", "help", "=", "\"CSV file for plotting\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"-rd\"", ",", "\"--resultdirs\"", ",", "help", "=", "\"List of comma-separated result dirs to combine for plotting\"", ",", "type", "=", "str", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.get_script_path": [[163, 168], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["", "def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir": [[170, 176], ["experiments_util.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_config_path": [[178, 188], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_config_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to configuration file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./config.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_topology_path": [[190, 200], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_topology_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to topology file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./topology.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./topology.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_users_path": [[202, 212], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_users_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to users file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./users.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./users.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_flags_path": [[214, 224], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_flags_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to flags file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./flags.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./flags.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_vulnerabilities_path": [[226, 236], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_vulnerabilities_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to vuln file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./vulnerabilities.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./vulnerabilities.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_containers_path": [[238, 248], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_containers_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to containers config file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./containers.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./containers.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_traffic_path": [[249, 259], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_traffic_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to traffic config file\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./traffic.json'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./traffic.json'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_containers_folders_path": [[261, 271], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_containers_folders_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to container folders\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./containers'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'containers'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_container_makefile_template_path": [[273, 283], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_container_makefile_template_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to makefile tempalte\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./Container_Makefile_template'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'Container_Makefile_template'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_makefile_template_path": [[285, 295], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_makefile_template_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to makefile tempalte\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./Makefile_template'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./Makefile_template'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_makefile_path": [[297, 307], ["os.path.join", "os.path.join", "experiments_util.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.default_output_dir"], ["", "def", "default_makefile_path", "(", "out_dir", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :param out_dir: directory to write\n    :return: the default path to makefile tempalte\n    \"\"\"", "\n", "if", "out_dir", "is", "None", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./Makefile'", ")", "\n", "", "else", ":", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'./Makefile'", ")", "\n", "", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.round_batch_size": [[309, 311], ["None"], "function", ["None"], ["", "def", "round_batch_size", "(", "x", ":", "int", ")", ":", "\n", "    ", "return", "x", "if", "x", "%", "100", "==", "0", "else", "x", "+", "100", "-", "x", "%", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.running_average": [[313, 323], ["len", "numpy.copy", "numpy.convolve", "numpy.zeros_like", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "running_average", "(", "x", ",", "N", ")", ":", "\n", "    ", "''' Function used to compute the running average\n        of the last N elements of a vector x\n    '''", "\n", "if", "len", "(", "x", ")", ">=", "N", ":", "\n", "        ", "y", "=", "np", ".", "copy", "(", "x", ")", "\n", "y", "[", "N", "-", "1", ":", "]", "=", "np", ".", "convolve", "(", "x", ",", "np", ".", "ones", "(", "(", "N", ",", ")", ")", "/", "N", ",", "mode", "=", "'valid'", ")", "\n", "", "else", ":", "\n", "        ", "y", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.experiments_util.running_average_list": [[325, 335], ["len", "numpy.copy", "numpy.convolve", "numpy.zeros_like", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["", "def", "running_average_list", "(", "x", ",", "N", ")", ":", "\n", "    ", "''' Function used to compute the running average\n        of the last N elements of a vector x\n    '''", "\n", "if", "len", "(", "x", ")", ">=", "N", ":", "\n", "        ", "y", "=", "np", ".", "copy", "(", "x", ")", "\n", "y", "[", "N", "-", "1", ":", "]", "=", "np", ".", "convolve", "(", "x", ",", "np", ".", "ones", "(", "(", "N", ",", ")", ")", "/", "N", ",", "mode", "=", "'valid'", ")", "\n", "", "else", ":", "\n", "        ", "y", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "", "return", "y", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.util.running_average": [[3, 17], ["len", "numpy.copy", "numpy.convolve", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["\n", "from", "collections", "import", "OrderedDict", "\n", "from", "typing", "import", "Any", ",", "Dict", ",", "List", ",", "Tuple", "\n", "\n", "import", "gym", "\n", "import", "numpy", "as", "np", "\n", "\n", "from", "gym_optimal_intrusion_response", ".", "agents", ".", "openai_baselines", ".", "common", ".", "vec_env", ".", "base_vec_env", "import", "VecEnvObs", "\n", "\n", "\n", "def", "copy_obs_dict", "(", "obs", ":", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ")", "->", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.util.util.running_average_list": [[19, 33], ["len", "numpy.copy", "numpy.convolve", "numpy.zeros_like", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.agent.train_agent_log_dto.TrainAgentLogDTO.copy"], ["\n", "assert", "isinstance", "(", "obs", ",", "OrderedDict", ")", ",", "f\"unexpected type for observations '{type(obs)}'\"", "\n", "return", "OrderedDict", "(", "[", "(", "k", ",", "np", ".", "copy", "(", "v", ")", ")", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", "]", ")", "\n", "\n", "\n", "", "def", "dict_to_obs", "(", "space", ":", "gym", ".", "spaces", ".", "Space", ",", "obs_dict", ":", "Dict", "[", "Any", ",", "np", ".", "ndarray", "]", ")", "->", "VecEnvObs", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.__init__": [[13, 24], ["gym_optimal_intrusion_response.agents.train_agent.TrainAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "attacker_agent_config", ":", "AgentConfig", ",", "\n", "defender_agent_config", ":", "AgentConfig", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param attacker_agent_config: the configuration\n        \"\"\"", "\n", "super", "(", "PPOBaselineAgent", ",", "self", ")", ".", "__init__", "(", "env", ",", "attacker_agent_config", ",", "\n", "defender_agent_config", ",", "\n", "train_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.train": [[25, 150], ["gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO.learn", "range", "range", "range", "attacker_net_arch.append", "dict", "range", "range", "range", "defender_net_arch.append", "dict", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO.load", "ppo_baseline_agent.PPOBaselineAgent.attacker_config.logger.info", "ppo_baseline_agent.PPOBaselineAgent.defender_config.logger.info", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO.save_model", "str", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO.train_result.to_csv", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO.eval_result.to_csv", "attacker_net_arch.append", "attacker_pi_arch.append", "attacker_vf_arch.append", "defender_net_arch.append", "defender_pi_arch.append", "defender_vf_arch.append", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.impl.ppo.ppo.PPO.load", "print", "time.time", "ppo_baseline_agent.PPOBaselineAgent.get_hidden_activation_attacker", "str", "ppo_baseline_agent.PPOBaselineAgent.get_hidden_activation_defender", "str", "math.pow", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.learn", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.info", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.base_class.BaseAlgorithm.save_model", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.config.agent_config.AgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.get_hidden_activation_attacker", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.get_hidden_activation_defender"], ["", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Starts the training loop and returns the result when complete\n\n        :return: the training result\n        \"\"\"", "\n", "\n", "# Setup Attacker", "\n", "if", "self", ".", "attacker_config", "is", "not", "None", ":", "\n", "# Custom MLP policy for attacker", "\n", "            ", "attacker_net_arch", "=", "[", "]", "\n", "attacker_pi_arch", "=", "[", "]", "\n", "attacker_vf_arch", "=", "[", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "attacker_config", ".", "shared_layers", ")", ":", "\n", "                ", "attacker_net_arch", ".", "append", "(", "self", ".", "attacker_config", ".", "shared_hidden_dim", ")", "\n", "", "for", "l", "in", "range", "(", "self", ".", "attacker_config", ".", "pi_hidden_layers", ")", ":", "\n", "                ", "attacker_pi_arch", ".", "append", "(", "self", ".", "attacker_config", ".", "pi_hidden_dim", ")", "\n", "", "for", "l", "in", "range", "(", "self", ".", "attacker_config", ".", "vf_hidden_layers", ")", ":", "\n", "                ", "attacker_vf_arch", ".", "append", "(", "self", ".", "attacker_config", ".", "vf_hidden_dim", ")", "\n", "\n", "", "net_dict_attacker", "=", "{", "\"pi\"", ":", "attacker_pi_arch", ",", "\"vf\"", ":", "attacker_vf_arch", "}", "\n", "attacker_net_arch", ".", "append", "(", "net_dict_attacker", ")", "\n", "\n", "policy_kwargs_attacker", "=", "dict", "(", "activation_fn", "=", "self", ".", "get_hidden_activation_attacker", "(", ")", ",", "net_arch", "=", "attacker_net_arch", ")", "\n", "device_attacker", "=", "\"cpu\"", "if", "not", "self", ".", "attacker_config", ".", "gpu", "else", "\"cuda:\"", "+", "str", "(", "self", ".", "attacker_config", ".", "gpu_id", ")", "\n", "policy_attacker", "=", "\"MlpPolicy\"", "\n", "\n", "if", "self", ".", "attacker_config", ".", "lr_progress_decay", ":", "\n", "                ", "temp", "=", "self", ".", "attacker_config", ".", "alpha", "\n", "lr_decay_func", "=", "lambda", "x", ":", "temp", "*", "math", ".", "pow", "(", "x", ",", "self", ".", "attacker_config", ".", "lr_progress_power_decay", ")", "\n", "self", ".", "attacker_config", ".", "alpha", "=", "lr_decay_func", "\n", "\n", "# Setup Defender", "\n", "", "", "if", "self", ".", "defender_config", "is", "not", "None", ":", "\n", "# Custom MLP policy for attacker", "\n", "            ", "defender_net_arch", "=", "[", "]", "\n", "defender_pi_arch", "=", "[", "]", "\n", "defender_vf_arch", "=", "[", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "defender_config", ".", "shared_layers", ")", ":", "\n", "                ", "defender_net_arch", ".", "append", "(", "self", ".", "defender_config", ".", "shared_hidden_dim", ")", "\n", "", "for", "l", "in", "range", "(", "self", ".", "defender_config", ".", "pi_hidden_layers", ")", ":", "\n", "                ", "defender_pi_arch", ".", "append", "(", "self", ".", "defender_config", ".", "pi_hidden_dim", ")", "\n", "", "for", "l", "in", "range", "(", "self", ".", "defender_config", ".", "vf_hidden_layers", ")", ":", "\n", "                ", "defender_vf_arch", ".", "append", "(", "self", ".", "defender_config", ".", "vf_hidden_dim", ")", "\n", "\n", "", "net_dict_defender", "=", "{", "\"pi\"", ":", "defender_pi_arch", ",", "\"vf\"", ":", "defender_vf_arch", "}", "\n", "defender_net_arch", ".", "append", "(", "net_dict_defender", ")", "\n", "\n", "policy_kwargs_defender", "=", "dict", "(", "activation_fn", "=", "self", ".", "get_hidden_activation_defender", "(", ")", ",", "net_arch", "=", "defender_net_arch", ")", "\n", "device_defender", "=", "\"cpu\"", "if", "not", "self", ".", "defender_config", ".", "gpu", "else", "\"cuda:\"", "+", "str", "(", "self", ".", "defender_config", ".", "gpu_id", ")", "\n", "policy_defender", "=", "\"MlpPolicy\"", "\n", "\n", "# Create model", "\n", "", "model", "=", "PPO", "(", "policy_attacker", ",", "policy_defender", ",", "\n", "self", ".", "env", ",", "\n", "batch_size", "=", "self", ".", "attacker_config", ".", "batch_size", ",", "\n", "attacker_learning_rate", "=", "self", ".", "attacker_config", ".", "alpha", ",", "\n", "defender_learning_rate", "=", "self", ".", "defender_config", ".", "alpha", ",", "\n", "n_steps", "=", "self", ".", "attacker_config", ".", "batch_size", ",", "\n", "n_epochs", "=", "self", ".", "attacker_config", ".", "optimization_iterations", ",", "\n", "attacker_gamma", "=", "self", ".", "attacker_config", ".", "gamma", ",", "\n", "defender_gamma", "=", "self", ".", "defender_config", ".", "gamma", ",", "\n", "attacker_gae_lambda", "=", "self", ".", "attacker_config", ".", "gae_lambda", ",", "\n", "defender_gae_lambda", "=", "self", ".", "defender_config", ".", "gae_lambda", ",", "\n", "attacker_clip_range", "=", "self", ".", "attacker_config", ".", "eps_clip", ",", "\n", "defender_clip_range", "=", "self", ".", "defender_config", ".", "eps_clip", ",", "\n", "max_grad_norm", "=", "self", ".", "attacker_config", ".", "max_gradient_norm", ",", "\n", "seed", "=", "self", ".", "attacker_config", ".", "random_seed", ",", "\n", "attacker_policy_kwargs", "=", "policy_kwargs_attacker", ",", "\n", "defender_policy_kwargs", "=", "policy_kwargs_defender", ",", "\n", "device", "=", "device_attacker", ",", "\n", "attacker_agent_config", "=", "self", ".", "attacker_config", ",", "\n", "defender_agent_config", "=", "self", ".", "defender_config", ",", "\n", "attacker_vf_coef", "=", "self", ".", "attacker_config", ".", "vf_coef", ",", "\n", "defender_vf_coef", "=", "self", ".", "defender_config", ".", "vf_coef", ",", "\n", "attacker_ent_coef", "=", "self", ".", "attacker_config", ".", "ent_coef", ",", "\n", "defender_ent_coef", "=", "self", ".", "defender_config", ".", "ent_coef", ",", "\n", "train_mode", "=", "self", ".", "train_mode", "\n", ")", "\n", "\n", "if", "self", ".", "attacker_config", ".", "load_path", "is", "not", "None", ":", "\n", "            ", "PPO", ".", "load", "(", "self", ".", "attacker_config", ".", "load_path", ",", "policy_attacker", ",", "agent_config", "=", "self", ".", "attacker_config", ")", "\n", "\n", "", "elif", "self", ".", "defender_config", ".", "load_path", "is", "not", "None", ":", "\n", "            ", "PPO", ".", "load", "(", "self", ".", "defender_config", ".", "load_path", ",", "policy_defender", ",", "agent_config", "=", "self", ".", "defender_config", ")", "\n", "\n", "# Eval config", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "total_timesteps", "=", "self", ".", "attacker_config", ".", "num_episodes", "\n", "train_log_frequency", "=", "self", ".", "attacker_config", ".", "train_log_frequency", "\n", "eval_frequency", "=", "self", ".", "attacker_config", ".", "eval_frequency", "\n", "eval_episodes", "=", "self", ".", "attacker_config", ".", "eval_episodes", "\n", "save_dir", "=", "self", ".", "attacker_config", ".", "save_dir", "\n", "", "else", ":", "\n", "            ", "total_timesteps", "=", "self", ".", "defender_config", ".", "num_episodes", "\n", "train_log_frequency", "=", "self", ".", "defender_config", ".", "train_log_frequency", "\n", "eval_frequency", "=", "self", ".", "defender_config", ".", "eval_frequency", "\n", "eval_episodes", "=", "self", ".", "defender_config", ".", "eval_episodes", "\n", "save_dir", "=", "self", ".", "defender_config", ".", "save_dir", "\n", "\n", "", "model", ".", "learn", "(", "total_timesteps", "=", "total_timesteps", ",", "\n", "log_interval", "=", "train_log_frequency", ",", "\n", "eval_freq", "=", "eval_frequency", ",", "\n", "n_eval_episodes", "=", "eval_episodes", ")", "\n", "\n", "if", "self", ".", "attacker_config", "is", "not", "None", ":", "\n", "            ", "self", ".", "attacker_config", ".", "logger", ".", "info", "(", "\"Training Complete\"", ")", "\n", "", "if", "self", ".", "defender_config", "is", "not", "None", ":", "\n", "            ", "self", ".", "defender_config", ".", "logger", ".", "info", "(", "\"Training Complete\"", ")", "\n", "\n", "# Save networks", "\n", "", "try", ":", "\n", "            ", "model", ".", "save_model", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"There was en error saving the model:{}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "\n", "# Save other game data", "\n", "", "if", "save_dir", "is", "not", "None", ":", "\n", "            ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "model", ".", "train_result", ".", "to_csv", "(", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_train_results_checkpoint.csv\"", ")", "\n", "model", ".", "eval_result", ".", "to_csv", "(", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_eval_results_checkpoint.csv\"", ")", "\n", "\n", "", "self", ".", "train_result", "=", "model", ".", "train_result", "\n", "self", ".", "eval_result", "=", "model", ".", "eval_result", "\n", "return", "model", ".", "train_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.get_hidden_activation_attacker": [[151, 174], ["ValueError"], "methods", ["None"], ["", "def", "get_hidden_activation_attacker", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "return", "torch", ".", "nn", ".", "Tanh", "\n", "if", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "\n", "", "elif", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "\n", "", "elif", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "\n", "", "elif", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "\n", "", "elif", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "\n", "", "elif", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "\n", "", "elif", "self", ".", "attacker_config", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "attacker_config", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.get_hidden_activation_defender": [[175, 198], ["ValueError"], "methods", ["None"], ["", "", "def", "get_hidden_activation_defender", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "return", "torch", ".", "nn", ".", "Tanh", "\n", "if", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "\n", "", "elif", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "\n", "", "elif", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "\n", "", "elif", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "\n", "", "elif", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "\n", "", "elif", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "\n", "", "elif", "self", ".", "defender_config", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "defender_config", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.get_action": [[200, 202], ["NotImplemented"], "methods", ["None"], ["", "", "def", "get_action", "(", "self", ",", "s", ",", "eval", "=", "False", ",", "attacker", "=", "True", ")", "->", "int", ":", "\n", "        ", "raise", "NotImplemented", "(", "\"not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.eval": [[203, 205], ["NotImplemented"], "methods", ["None"], ["", "def", "eval", "(", "self", ",", "log", "=", "True", ")", "->", "ExperimentResult", ":", "\n", "        ", "raise", "NotImplemented", "(", "\"not implemented\"", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.__init__": [[20, 103], ["gym_optimal_intrusion_response.agents.openai_baselines.common.on_policy_algorithm.OnPolicyAlgorithm.__init__", "ppo.PPO._setup_model", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO._setup_model", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.logger.warn"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "attacker_policy", ":", "Union", "[", "str", ",", "Type", "[", "ActorCriticPolicy", "]", "]", ",", "\n", "defender_policy", ":", "Union", "[", "str", ",", "Type", "[", "ActorCriticPolicy", "]", "]", ",", "\n", "env", ":", "Union", "[", "GymEnv", ",", "str", "]", ",", "\n", "attacker_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", "=", "3e-4", ",", "\n", "defender_learning_rate", ":", "Union", "[", "float", ",", "Schedule", "]", "=", "3e-4", ",", "\n", "n_steps", ":", "int", "=", "2048", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "64", ",", "\n", "n_epochs", ":", "int", "=", "10", ",", "\n", "attacker_gamma", ":", "float", "=", "0.99", ",", "\n", "defender_gamma", ":", "float", "=", "0.99", ",", "\n", "attacker_gae_lambda", ":", "float", "=", "0.95", ",", "\n", "defender_gae_lambda", ":", "float", "=", "0.95", ",", "\n", "attacker_ent_coef", ":", "float", "=", "0.0", ",", "\n", "defender_ent_coef", ":", "float", "=", "0.0", ",", "\n", "attacker_vf_coef", ":", "float", "=", "0.5", ",", "\n", "defender_vf_coef", ":", "float", "=", "0.5", ",", "\n", "attacker_clip_range", ":", "float", "=", "0.2", ",", "\n", "defender_clip_range", ":", "float", "=", "0.2", ",", "\n", "max_grad_norm", ":", "float", "=", "0.5", ",", "\n", "tensorboard_log", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "attacker_policy_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "defender_policy_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "\"auto\"", ",", "\n", "_init_setup_model", ":", "bool", "=", "True", ",", "\n", "train_mode", ":", "TrainMode", "=", "TrainMode", ".", "TRAIN_ATTACKER", ",", "\n", "attacker_agent_config", ":", "AgentConfig", "=", "None", ",", "\n", "defender_agent_config", ":", "AgentConfig", "=", "None", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "PPO", ",", "self", ")", ".", "__init__", "(", "\n", "attacker_policy", ",", "\n", "defender_policy", ",", "\n", "env", ",", "\n", "attacker_learning_rate", "=", "attacker_learning_rate", ",", "\n", "defender_learning_rate", "=", "defender_learning_rate", ",", "\n", "n_steps", "=", "n_steps", ",", "\n", "attacker_gamma", "=", "attacker_gamma", ",", "\n", "defender_gamma", "=", "defender_gamma", ",", "\n", "attacker_gae_lambda", "=", "attacker_gae_lambda", ",", "\n", "defender_gae_lambda", "=", "defender_gae_lambda", ",", "\n", "attacker_ent_coef", "=", "attacker_ent_coef", ",", "\n", "defender_ent_coef", "=", "defender_ent_coef", ",", "\n", "attacker_vf_coef", "=", "attacker_vf_coef", ",", "\n", "defender_vf_coef", "=", "defender_vf_coef", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ",", "\n", "tensorboard_log", "=", "tensorboard_log", ",", "\n", "attacker_policy_kwargs", "=", "attacker_policy_kwargs", ",", "\n", "defender_policy_kwargs", "=", "defender_policy_kwargs", ",", "\n", "device", "=", "device", ",", "\n", "seed", "=", "seed", ",", "\n", "_init_setup_model", "=", "False", ",", "\n", "attacker_agent_config", "=", "attacker_agent_config", ",", "\n", "defender_agent_config", "=", "defender_agent_config", ",", "\n", "train_mode", "=", "train_mode", "\n", ")", "\n", "if", "self", ".", "env", "is", "not", "None", ":", "\n", "# Check that `n_steps * n_envs > 1` to avoid NaN", "\n", "# when doing advantage normalization", "\n", "            ", "buffer_size", "=", "self", ".", "env", ".", "num_envs", "*", "self", ".", "n_steps", "\n", "assert", "(", "\n", "buffer_size", ">", "1", "\n", ")", ",", "f\"`n_steps * n_envs` must be greater than 1. Currently n_steps={self.n_steps} and n_envs={self.env.num_envs}\"", "\n", "# Check that the rollout buffer size is a multiple of the mini-batch size", "\n", "untruncated_batches", "=", "buffer_size", "//", "batch_size", "\n", "if", "buffer_size", "%", "batch_size", ">", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "f\"You have specified a mini-batch size of {batch_size},\"", "\n", "f\" but because the `RolloutBuffer` is of size `n_steps * n_envs = {buffer_size}`,\"", "\n", "f\" after every {untruncated_batches} untruncated mini-batches,\"", "\n", "f\" there will be a truncated mini-batch of size {buffer_size % batch_size}\\n\"", "\n", "f\"We recommend using a `batch_size` that is a multiple of `n_steps * n_envs`.\\n\"", "\n", "f\"Info: (n_steps={self.n_steps} and n_envs={self.env.num_envs})\"", "\n", ")", "\n", "", "", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "attacker_clip_range", "=", "attacker_clip_range", "\n", "self", ".", "defender_clip_range", "=", "defender_clip_range", "\n", "\n", "if", "_init_setup_model", ":", "\n", "            ", "self", ".", "_setup_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO._setup_model": [[104, 106], ["super()._setup_model"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO._setup_model"], ["", "", "def", "_setup_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "super", "(", "PPO", ",", "self", ")", ".", "_setup_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.train": [[107, 167], ["range", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.explained_variance", "gym_optimal_intrusion_response.agents.openai_baselines.common.utils.explained_variance", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "ppo.PPO.attacker_rollout_buffer_pass", "ppo.PPO.defender_rollout_buffer_pass", "ppo.PPO.attacker_rollout_buffer.returns.flatten", "ppo.PPO.attacker_rollout_buffer.values.flatten", "ppo.PPO.defender_rollout_buffer.returns.flatten", "ppo.PPO.defender_rollout_buffer.values.flatten"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.explained_variance", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.utils.explained_variance", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.attacker_rollout_buffer_pass", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.defender_rollout_buffer_pass"], ["", "def", "train", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update policy using the currently gathered\n        rollout buffer.\n        \"\"\"", "\n", "# Update optimizer learning rate", "\n", "lr_attacker", "=", "self", ".", "attacker_policy", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "\n", "lr_defender", "=", "self", ".", "defender_policy", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "\n", "\n", "# Optional: clip range for the value function", "\n", "attacker_clip_range_vf", "=", "None", "\n", "defender_clip_range_vf", "=", "None", "\n", "\n", "entropy_losses_attacker", ",", "all_kl_divs_attacker", "=", "[", "]", ",", "[", "]", "\n", "pg_losses_attacker", ",", "value_losses_attacker", "=", "[", "]", ",", "[", "]", "\n", "clip_fractions_attacker", "=", "[", "]", "\n", "grad_comp_times_attacker", "=", "[", "]", "\n", "weight_update_times_attacker", "=", "[", "]", "\n", "\n", "entropy_losses_defender", ",", "all_kl_divs_defender", "=", "[", "]", ",", "[", "]", "\n", "pg_losses_defender", ",", "value_losses_defender", "=", "[", "]", ",", "[", "]", "\n", "clip_fractions_defender", "=", "[", "]", "\n", "grad_comp_times_defender", "=", "[", "]", "\n", "weight_update_times_defender", "=", "[", "]", "\n", "\n", "# train for gradient_steps epochs", "\n", "for", "epoch", "in", "range", "(", "self", ".", "n_epochs", ")", ":", "\n", "\n", "            ", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "                ", "attacker_clip_range", ",", "pg_losses_attacker", ",", "clip_fractions_attacker", ",", "value_losses_attacker", ",", "entropy_losses_attacker", "=", "self", ".", "attacker_rollout_buffer_pass", "(", "\n", "self", ".", "attacker_clip_range", ",", "pg_losses_attacker", ",", "clip_fractions_attacker", ",", "\n", "value_losses_attacker", ",", "entropy_losses_attacker", ")", "\n", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_DEFENDER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "                ", "defender_clip_range", ",", "pg_losses_defender", ",", "clip_fractions_defender", ",", "value_losses_defender", ",", "entropy_losses_defender", "=", "self", ".", "defender_rollout_buffer_pass", "(", "\n", "self", ".", "defender_clip_range", ",", "pg_losses_defender", ",", "clip_fractions_defender", ",", "\n", "value_losses_defender", ",", "entropy_losses_defender", ")", "\n", "\n", "\n", "", "", "self", ".", "_n_updates", "+=", "self", ".", "n_epochs", "\n", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_ATTACKER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "explained_var_attacker", "=", "explained_variance", "(", "self", ".", "attacker_rollout_buffer", ".", "returns", ".", "flatten", "(", ")", ",", "\n", "self", ".", "attacker_rollout_buffer", ".", "values", ".", "flatten", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "train_mode", "==", "TrainMode", ".", "TRAIN_DEFENDER", "or", "self", ".", "train_mode", "==", "TrainMode", ".", "SELF_PLAY", ":", "\n", "            ", "explained_var_defender", "=", "explained_variance", "(", "self", ".", "defender_rollout_buffer", ".", "returns", ".", "flatten", "(", ")", ",", "\n", "self", ".", "defender_rollout_buffer", ".", "values", ".", "flatten", "(", ")", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "entropy_losses_attacker", ")", ",", "np", ".", "mean", "(", "pg_losses_attacker", ")", ",", "np", ".", "mean", "(", "value_losses_attacker", ")", ",", "lr_attacker", ",", "np", ".", "mean", "(", "entropy_losses_defender", ")", ",", "np", ".", "mean", "(", "pg_losses_defender", ")", ",", "np", ".", "mean", "(", "value_losses_defender", ")", ",", "lr_defender", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.attacker_rollout_buffer_pass": [[168, 224], ["ppo.PPO.attacker_rollout_buffer.get", "isinstance", "ppo.PPO.attacker_policy.evaluate_actions", "values.flatten.flatten.flatten", "torch.exp", "pg_losses_attacker.append", "torch.mean().item", "clip_fractions_attacker.append", "torch.nn.functional.mse_loss", "value_losses_attacker.append", "entropy_losses_attacker.append", "ppo.PPO.attacker_policy.optimizer.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.attacker_policy.optimizer.step", "rollout_data.actions.long().flatten", "torch.clamp", "torch.min().mean", "policy_loss.item", "torch.nn.functional.mse_loss.item", "entropy_loss.item", "ppo.PPO.attacker_policy.parameters", "advantages.mean", "advantages.std", "torch.mean", "torch.mean", "torch.mean", "rollout_data.actions.long", "torch.min", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["", "def", "attacker_rollout_buffer_pass", "(", "self", ",", "attacker_clip_range", ",", "pg_losses_attacker", ",", "clip_fractions_attacker", ",", "\n", "value_losses_attacker", ",", "entropy_losses_attacker", ")", ":", "\n", "# Do a complete pass on the attacker's rollout buffer", "\n", "        ", "for", "rollout_data", "in", "self", ".", "attacker_rollout_buffer", ".", "get", "(", "self", ".", "batch_size", ")", ":", "\n", "\n", "            ", "actions", "=", "rollout_data", ".", "actions", "\n", "if", "isinstance", "(", "self", ".", "attacker_action_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "# Convert discrete action from float to long", "\n", "                ", "actions", "=", "rollout_data", ".", "actions", ".", "long", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "", "values", ",", "log_prob", ",", "entropy", "=", "self", ".", "attacker_policy", ".", "evaluate_actions", "(", "rollout_data", ".", "observations", ",", "actions", ")", "\n", "values", "=", "values", ".", "flatten", "(", ")", "\n", "# Normalize advantage", "\n", "advantages", "=", "rollout_data", ".", "advantages", "\n", "advantages", "=", "(", "advantages", "-", "advantages", ".", "mean", "(", ")", ")", "/", "(", "advantages", ".", "std", "(", ")", "+", "1e-8", ")", "\n", "\n", "# ratio between old and new policy, should be one at the first iteration", "\n", "ratio", "=", "th", ".", "exp", "(", "log_prob", "-", "rollout_data", ".", "old_log_prob", ")", "\n", "\n", "# clipped surrogate loss", "\n", "policy_loss_1", "=", "advantages", "*", "ratio", "\n", "policy_loss_2", "=", "advantages", "*", "th", ".", "clamp", "(", "ratio", ",", "1", "-", "attacker_clip_range", ",", "1", "+", "attacker_clip_range", ")", "\n", "policy_loss", "=", "-", "th", ".", "min", "(", "policy_loss_1", ",", "policy_loss_2", ")", ".", "mean", "(", ")", "\n", "\n", "# Logging", "\n", "pg_losses_attacker", ".", "append", "(", "policy_loss", ".", "item", "(", ")", ")", "\n", "clip_fraction", "=", "th", ".", "mean", "(", "(", "th", ".", "abs", "(", "ratio", "-", "1", ")", ">", "attacker_clip_range", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", "\n", "clip_fractions_attacker", ".", "append", "(", "clip_fraction", ")", "\n", "\n", "values_pred", "=", "values", "\n", "\n", "# Value loss using the TD(gae_lambda) target", "\n", "value_loss", "=", "F", ".", "mse_loss", "(", "rollout_data", ".", "returns", ",", "values_pred", ")", "\n", "value_losses_attacker", ".", "append", "(", "value_loss", ".", "item", "(", ")", ")", "\n", "\n", "# Entropy loss favor exploration", "\n", "if", "entropy", "is", "None", ":", "\n", "# Approximate entropy when no analytical form", "\n", "                ", "entropy_loss", "=", "-", "th", ".", "mean", "(", "-", "log_prob", ")", "\n", "", "else", ":", "\n", "                ", "entropy_loss", "=", "-", "th", ".", "mean", "(", "entropy", ")", "\n", "\n", "", "entropy_losses_attacker", ".", "append", "(", "entropy_loss", ".", "item", "(", ")", ")", "\n", "\n", "loss", "=", "policy_loss", "+", "self", ".", "attacker_ent_coef", "*", "entropy_loss", "+", "self", ".", "attacker_vf_coef", "*", "value_loss", "\n", "\n", "# Optimization step", "\n", "self", ".", "attacker_policy", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Clip grad norm", "\n", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "attacker_policy", ".", "parameters", "(", ")", ",", "self", ".", "max_grad_norm", ")", "\n", "self", ".", "attacker_policy", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "attacker_clip_range", ",", "pg_losses_attacker", ",", "clip_fractions_attacker", ",", "value_losses_attacker", ",", "entropy_losses_attacker", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.defender_rollout_buffer_pass": [[225, 284], ["ppo.PPO.defender_rollout_buffer.get", "isinstance", "ppo.PPO.defender_policy.evaluate_actions", "values.flatten.flatten.flatten", "torch.exp", "pg_losses_defender.append", "torch.mean().item", "clip_fractions_defender.append", "torch.nn.functional.mse_loss", "value_losses_defender.append", "entropy_losses_defender.append", "ppo.PPO.defender_policy.optimizer.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.defender_policy.optimizer.step", "rollout_data.actions.long().flatten", "torch.clamp", "torch.min().mean", "policy_loss.item", "torch.nn.functional.mse_loss.item", "entropy_loss.item", "ppo.PPO.defender_policy.parameters", "advantages.mean", "advantages.std", "torch.mean", "torch.mean", "torch.mean", "rollout_data.actions.long", "torch.min", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.buffers.RolloutBuffer.get", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.policies.ActorCriticPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step"], ["", "def", "defender_rollout_buffer_pass", "(", "self", ",", "defender_clip_range", ",", "pg_losses_defender", ",", "clip_fractions_defender", ",", "\n", "value_losses_defender", ",", "entropy_losses_defender", ")", ":", "\n", "\n", "# Do a complete pass on the defender's rollout buffer", "\n", "        ", "for", "rollout_data", "in", "self", ".", "defender_rollout_buffer", ".", "get", "(", "self", ".", "batch_size", ")", ":", "\n", "\n", "            ", "actions", "=", "rollout_data", ".", "actions", "\n", "if", "isinstance", "(", "self", ".", "defender_action_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "# Convert discrete action from float to long", "\n", "                ", "actions", "=", "rollout_data", ".", "actions", ".", "long", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "", "values", ",", "log_prob", ",", "entropy", "=", "self", ".", "defender_policy", ".", "evaluate_actions", "(", "rollout_data", ".", "observations", ",", "actions", ")", "\n", "values", "=", "values", ".", "flatten", "(", ")", "\n", "# Normalize advantage", "\n", "advantages", "=", "rollout_data", ".", "advantages", "\n", "advantages", "=", "(", "advantages", "-", "advantages", ".", "mean", "(", ")", ")", "/", "(", "advantages", ".", "std", "(", ")", "+", "1e-8", ")", "\n", "\n", "# ratio between old and new policy, should be one at the first iteration", "\n", "ratio", "=", "th", ".", "exp", "(", "log_prob", "-", "rollout_data", ".", "old_log_prob", ")", "\n", "\n", "# clipped surrogate loss", "\n", "policy_loss_1", "=", "advantages", "*", "ratio", "\n", "policy_loss_2", "=", "advantages", "*", "th", ".", "clamp", "(", "ratio", ",", "1", "-", "defender_clip_range", ",", "1", "+", "defender_clip_range", ")", "\n", "policy_loss", "=", "-", "th", ".", "min", "(", "policy_loss_1", ",", "policy_loss_2", ")", ".", "mean", "(", ")", "\n", "\n", "# Logging", "\n", "pg_losses_defender", ".", "append", "(", "policy_loss", ".", "item", "(", ")", ")", "\n", "clip_fraction", "=", "th", ".", "mean", "(", "(", "th", ".", "abs", "(", "ratio", "-", "1", ")", ">", "defender_clip_range", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", "\n", "clip_fractions_defender", ".", "append", "(", "clip_fraction", ")", "\n", "\n", "# No clipping", "\n", "values_pred", "=", "values", "\n", "\n", "# Value loss using the TD(gae_lambda) target", "\n", "value_loss", "=", "F", ".", "mse_loss", "(", "rollout_data", ".", "returns", ",", "values_pred", ")", "\n", "value_losses_defender", ".", "append", "(", "value_loss", ".", "item", "(", ")", ")", "\n", "\n", "# Entropy loss favor exploration", "\n", "if", "entropy", "is", "None", ":", "\n", "# Approximate entropy when no analytical form", "\n", "                ", "entropy_loss", "=", "-", "th", ".", "mean", "(", "-", "log_prob", ")", "\n", "", "else", ":", "\n", "                ", "entropy_loss", "=", "-", "th", ".", "mean", "(", "entropy", ")", "\n", "\n", "", "entropy_losses_defender", ".", "append", "(", "entropy_loss", ".", "item", "(", ")", ")", "\n", "\n", "loss", "=", "policy_loss", "+", "self", ".", "defender_ent_coef", "*", "entropy_loss", "+", "self", ".", "defender_vf_coef", "*", "value_loss", "\n", "\n", "# Optimization step", "\n", "self", ".", "defender_policy", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Clip grad norm", "\n", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "defender_policy", ".", "parameters", "(", ")", ",", "self", ".", "max_grad_norm", ")", "\n", "\n", "self", ".", "defender_policy", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "defender_clip_range", ",", "pg_losses_defender", ",", "clip_fractions_defender", ",", "value_losses_defender", ",", "entropy_losses_defender", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.learn": [[285, 305], ["super().learn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.ppo.ppo.PPO.learn"], ["", "def", "learn", "(", "\n", "self", ",", "\n", "total_timesteps", ":", "int", ",", "\n", "log_interval", ":", "int", "=", "1", ",", "\n", "eval_env", ":", "Optional", "[", "GymEnv", "]", "=", "None", ",", "\n", "eval_freq", ":", "int", "=", "-", "1", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "tb_log_name", ":", "str", "=", "\"PPO\"", ",", "\n", "eval_log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", ")", "->", "\"PPO\"", ":", "\n", "\n", "        ", "return", "super", "(", "PPO", ",", "self", ")", ".", "learn", "(", "\n", "total_timesteps", "=", "total_timesteps", ",", "\n", "log_interval", "=", "log_interval", ",", "\n", "eval_freq", "=", "eval_freq", ",", "\n", "n_eval_episodes", "=", "n_eval_episodes", ",", "\n", "tb_log_name", "=", "tb_log_name", ",", "\n", "eval_log_path", "=", "eval_log_path", ",", "\n", "reset_num_timesteps", "=", "reset_num_timesteps", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.__init__": [[15, 23], ["gym_optimal_intrusion_response.dao.game.env_state.EnvState"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_config", ":", "EnvConfig", ")", ":", "\n", "        ", "self", ".", "env_config", "=", "env_config", "\n", "self", ".", "env_state", "=", "EnvState", "(", "env_config", "=", "env_config", ")", "\n", "self", ".", "attacker_observation_space", "=", "self", ".", "env_state", ".", "attacker_observation_space", "\n", "self", ".", "defender_observation_space", "=", "self", ".", "env_state", ".", "defender_observation_space", "\n", "self", ".", "attacker_action_space", "=", "self", ".", "env_state", ".", "attacker_action_space", "\n", "self", ".", "defender_action_space", "=", "self", ".", "env_state", ".", "defender_action_space", "\n", "self", ".", "time_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step": [[26, 122], ["int", "int", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step_defender", "gym_optimal_intrusion_response.logic.transition_operator.TransitionOperator.update_defender_state", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_defender_observation().flatten", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_attacker_observation().flatten", "isinstance", "isinstance", "print", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_config.attacker_static_opponent.action", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_config.defender_static_opponent.action", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step_attacker", "defender_info.items", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_defender_observation", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_attacker_observation", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_config.attacker_static_opponent.action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step_defender", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.update_defender_state", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_attacker.RandomAttacker.action", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_attacker.RandomAttacker.action", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step_attacker", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_defender_observation", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.static_opponents.random_attacker.RandomAttacker.action"], ["", "def", "step", "(", "self", ",", "action_id", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "Tuple", "[", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ",", "Tuple", "[", "int", ",", "int", "]", ",", "bool", ",", "dict", "]", ":", "\n", "        ", "\"\"\"\n        Takes a step in the environment\n\n        :param action_id: (attacker action id, defender action id)\n        :return: ((attacker obs, defender obs), (attacker reward, defender reward), done, info)\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "action_id", ",", "int", ")", "or", "isinstance", "(", "action_id", ",", "np", ".", "int64", ")", ":", "\n", "            ", "action_id", "=", "(", "action_id", ",", "None", ")", "\n", "print", "(", "\"[WARNING]: This is a multi-agent environment where the input should be \"", "\n", "\"(attacker_action, defender_action)\"", ")", "\n", "\n", "", "attack_t", "=", "self", ".", "env_state", ".", "t", "\n", "attack_action_id", ",", "defense_action_id", "=", "action_id", "\n", "if", "attack_action_id", "is", "None", ":", "\n", "            ", "attack_action_id", ",", "attack_t", "=", "self", ".", "env_config", ".", "attacker_static_opponent", ".", "action", "(", "env", "=", "self", ",", "t", "=", "self", ".", "env_state", ".", "t", ")", "\n", "\n", "", "if", "defense_action_id", "is", "None", ":", "\n", "            ", "defense_action_id", "=", "self", ".", "env_config", ".", "defender_static_opponent", ".", "action", "(", "env", "=", "self", ")", "\n", "\n", "", "attack_action_id", "=", "int", "(", "attack_action_id", ")", "\n", "defense_action_id", "=", "int", "(", "defense_action_id", ")", "\n", "attacker_reward", ",", "defender_reward", ",", "done", ",", "defender_info", "=", "self", ".", "step_defender", "(", "defense_action_id", ")", "\n", "\n", "info", "=", "{", "}", "\n", "info", "[", "\"flags\"", "]", "=", "0", "\n", "info", "[", "\"caught_attacker\"", "]", "=", "0", "\n", "info", "[", "\"early_stopped\"", "]", "=", "0", "\n", "info", "[", "\"snort_severe_baseline_reward\"", "]", "=", "0", "\n", "info", "[", "\"snort_warning_baseline_reward\"", "]", "=", "0", "\n", "info", "[", "\"snort_critical_baseline_reward\"", "]", "=", "0", "\n", "info", "[", "\"var_log_baseline_reward\"", "]", "=", "0", "\n", "info", "[", "\"successful_intrusion\"", "]", "=", "False", "\n", "info", "[", "\"attacker_cost\"", "]", "=", "0", "\n", "info", "[", "\"attacker_cost_norm\"", "]", "=", "0", "\n", "info", "[", "\"attacker_alerts\"", "]", "=", "0", "\n", "info", "[", "\"attacker_alerts_norm\"", "]", "=", "0", "\n", "info", "[", "\"flags\"", "]", "=", "0", "\n", "info", "[", "\"optimal_step\"", "]", "=", "0", "\n", "info", "[", "\"optimal_reward\"", "]", "=", "0", "\n", "info", "[", "\"intrusion_steps\"", "]", "=", "0", "\n", "\n", "if", "not", "done", "and", "not", "self", ".", "env_config", ".", "dp", "and", "not", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "attacker_reward", ",", "defender_reward_2", ",", "done", ",", "info", "=", "self", ".", "step_attacker", "(", "attack_action_id", ")", "\n", "defender_reward", "=", "defender_reward", "+", "defender_reward_2", "\n", "", "elif", "self", ".", "env_config", ".", "traces", ":", "\n", "            ", "key", "=", "(", "attack_action_id", ",", "attack_t", ")", "\n", "logged_in_ips_str", ",", "done2", ",", "intrusion_in_progress", "=", "self", ".", "env_config", ".", "action_to_state", "[", "(", "attack_action_id", ",", "attack_t", ")", "]", "\n", "if", "not", "self", ".", "env_state", ".", "intrusion_in_progress", ":", "\n", "                ", "self", ".", "env_state", ".", "intrusion_in_progress", "=", "intrusion_in_progress", "\n", "if", "intrusion_in_progress", ":", "\n", "                    ", "self", ".", "env_state", ".", "intrusion_t", "=", "self", ".", "env_state", ".", "t", "-", "1", "\n", "", "", "if", "self", ".", "env_state", ".", "intrusion_in_progress", ":", "\n", "                ", "info", "[", "\"optimal_step\"", "]", "=", "self", ".", "env_state", ".", "intrusion_t", "+", "1", "\n", "info", "[", "\"optimal_reward\"", "]", "=", "self", ".", "env_state", ".", "intrusion_t", "*", "self", ".", "env_config", ".", "defender_continue_reward", "+", "self", ".", "env_config", ".", "defender_intrusion_prevention_reward", "\n", "", "if", "done2", ":", "\n", "                ", "self", ".", "env_state", ".", "target_compromised", "=", "True", "\n", "done", "=", "True", "\n", "defender_reward", "=", "self", ".", "env_config", ".", "defender_target_compromised_reward", "\n", "", "", "d3", "=", "TransitionOperator", ".", "update_defender_state", "(", "self", ".", "env_state", ",", "attacker_action", "=", "attack_action_id", ",", "t", "=", "attack_t", ")", "\n", "if", "not", "done", ":", "\n", "            ", "done", "=", "d3", "\n", "\n", "", "if", "done", ":", "\n", "            ", "if", "not", "self", ".", "env_state", ".", "intrusion_in_progress", ":", "\n", "                ", "intrusion_started", "=", "False", "\n", "int_t", "=", "-", "1", "\n", "while", "not", "intrusion_started", ":", "\n", "                    ", "attack_action_id", ",", "attack_t", "=", "self", ".", "env_config", ".", "attacker_static_opponent", ".", "action", "(", "\n", "env", "=", "self", ",", "t", "=", "self", ".", "env_state", ".", "t", ")", "\n", "self", ".", "env_state", ".", "t", "+=", "1", "\n", "logged_in_ips_str", ",", "done2", ",", "intrusion_in_progress", "=", "self", ".", "env_config", ".", "action_to_state", "[", "\n", "(", "attack_action_id", ",", "attack_t", ")", "]", "\n", "if", "intrusion_in_progress", ":", "\n", "                        ", "intrusion_started", "=", "True", "\n", "int_t", "=", "self", ".", "env_state", ".", "t", "-", "1", "\n", "", "", "info", "[", "\"optimal_step\"", "]", "=", "int_t", "+", "1", "\n", "info", "[", "\"optimal_reward\"", "]", "=", "int_t", "*", "self", ".", "env_config", ".", "defender_continue_reward", "+", "self", ".", "env_config", ".", "defender_intrusion_prevention_reward", "\n", "\n", "\n", "# Merge infos", "\n", "", "", "if", "info", "is", "None", ":", "\n", "            ", "info", "=", "defender_info", "\n", "", "else", ":", "\n", "            ", "if", "defender_info", "is", "not", "None", ":", "\n", "                ", "for", "k", ",", "v", "in", "defender_info", ".", "items", "(", ")", ":", "\n", "                    ", "info", "[", "k", "]", "=", "v", "\n", "\n", "", "", "", "defender_obs", "=", "self", ".", "env_state", ".", "get_defender_observation", "(", ")", ".", "flatten", "(", ")", "\n", "attacker_obs", "=", "self", ".", "env_state", ".", "get_attacker_observation", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "time_step", "+=", "1", "\n", "\n", "return", "(", "attacker_obs", ",", "defender_obs", ")", ",", "(", "attacker_reward", ",", "defender_reward", ")", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step_defender": [[123, 134], ["gym_optimal_intrusion_response.logic.transition_operator.TransitionOperator.transition_defender"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.transition_defender"], ["", "def", "step_defender", "(", "self", ",", "defender_action_id", ":", "int", ")", "->", "Tuple", "[", "int", ",", "int", ",", "bool", ",", "dict", "]", ":", "\n", "        ", "\"\"\"\n        Takes a step with a defender action\n\n        :param defender_action_id: the id of the defender action\n        :return: attacker reward, defender reward, done, info\n        \"\"\"", "\n", "s", ",", "attacker_reward", ",", "defender_reward", ",", "done", ",", "info", "=", "TransitionOperator", ".", "transition_defender", "(", "\n", "defender_action_id", "=", "defender_action_id", ",", "env_state", "=", "self", ".", "env_state", ",", "env_config", "=", "self", ".", "env_config", ")", "\n", "self", ".", "env_state", "=", "s", "\n", "return", "attacker_reward", ",", "defender_reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.step_attacker": [[135, 146], ["gym_optimal_intrusion_response.logic.transition_operator.TransitionOperator.transition_attacker"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.logic.transition_operator.TransitionOperator.transition_attacker"], ["", "def", "step_attacker", "(", "self", ",", "attacker_action_id", ":", "int", ")", "->", "Tuple", "[", "int", ",", "int", ",", "bool", ",", "dict", "]", ":", "\n", "        ", "\"\"\"\n        Takes a step with an attacker action\n\n        :param attacker_action_id: the id of the attacker action\n        :return: attacker reward, defender reward, done, info\n        \"\"\"", "\n", "s", ",", "attacker_reward", ",", "defender_reward", ",", "done", "=", "TransitionOperator", ".", "transition_attacker", "(", "\n", "attacker_action_id", "=", "attacker_action_id", ",", "env_state", "=", "self", ".", "env_state", ",", "env_config", "=", "self", ".", "env_config", ")", "\n", "self", ".", "env_state", "=", "s", "\n", "return", "attacker_reward", ",", "defender_reward", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_attack_action_legal": [[147, 168], ["gym_optimal_intrusion_response.dao.game.env_state.EnvState.get_attacked_node", "gym_optimal_intrusion_response.dao.game.env_state.EnvState.get_attacked_attribute", "env_state.attacker_reachable"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacked_node", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacked_attribute", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.attacker_reachable"], ["", "@", "staticmethod", "\n", "def", "is_attack_action_legal", "(", "a_id", ":", "int", ",", "env_config", ":", "EnvConfig", ",", "env_state", ":", "EnvState", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Utility function for checking if an attack action is legal or not\n\n        :param a_id: the id of the attack action\n        :param env_config: the environment configuration\n        :param env_state: the state of the environment\n        :return: true if legal, otherwise false\n        \"\"\"", "\n", "node_id", "=", "EnvState", ".", "get_attacked_node", "(", "a_id", ",", "env_config", ")", "\n", "attribute_id", "=", "EnvState", ".", "get_attacked_attribute", "(", "a_id", ",", "env_config", ")", "\n", "if", "not", "env_state", ".", "attacker_reachable", "(", "node_id", ")", ":", "\n", "            ", "return", "False", "\n", "", "if", "env_state", ".", "nodes", "[", "node_id", "]", ".", "compromised", ":", "\n", "            ", "return", "False", "\n", "", "if", "attribute_id", "==", "env_config", ".", "recon_attribute", "and", "env_state", ".", "nodes", "[", "node_id", "]", ".", "recon_done", ":", "\n", "            ", "return", "False", "\n", "", "if", "attribute_id", "!=", "env_config", ".", "recon_attribute", "and", "env_state", ".", "nodes", "[", "node_id", "]", ".", "attack_attributes", "[", "attribute_id", "]", ">=", "env_config", ".", "max_attribute_value", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.is_defense_action_legal": [[169, 177], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_defense_action_legal", "(", "d_id", ":", "int", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Utility function for checking if a defense action is legal or not\n        :param d_id: the id of the defense action\n        :return: True if legal otherwise  false\n        \"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset": [[178, 189], ["optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.reset", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_config.attacker_static_opponent.reset", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_defender_observation().flatten", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_attacker_observation().flatten", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_defender_observation", "optimal_intrusion_response_env.OptimalIntrusionResponseEnv.env_state.get_attacker_observation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.reset", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_defender_observation", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.game.env_state.EnvState.get_attacker_observation"], ["", "def", "reset", "(", "self", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Resets the environment\n\n        :return: Initial attacker obs, initial defender obs\n        \"\"\"", "\n", "self", ".", "env_state", ".", "reset", "(", ")", "\n", "self", ".", "env_config", ".", "attacker_static_opponent", ".", "reset", "(", ")", "\n", "defender_obs", "=", "self", ".", "env_state", ".", "get_defender_observation", "(", ")", ".", "flatten", "(", ")", "\n", "attacker_obs", "=", "self", ".", "env_state", ".", "get_attacker_observation", "(", ")", ".", "flatten", "(", ")", "\n", "return", "attacker_obs", ",", "defender_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.derived_envs.optimal_intrusion_response_env_v2.OptimalIntrusionResponseEnvV2.__init__": [[13, 134], ["gym_optimal_intrusion_response.logic.static_opponents.custom_attacker.CustomAttacker", "range", "gym_optimal_intrusion_response.logic.static_opponents.random_defender.RandomDefender", "gym_optimal_intrusion_response.dao.game.env_config.EnvConfig", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "traces_dir", ":", "str", "=", "\"\"", ",", "traces_filename", ":", "str", "=", "\"\"", ")", ":", "\n", "        ", "num_nodes", "=", "4", "\n", "num_attributes", "=", "4", "\n", "# random_attacker = RandomAttacker(num_actions=(num_nodes*num_attributes))", "\n", "\n", "custom_attacker", "=", "CustomAttacker", "(", "\n", "num_actions", "=", "(", "num_nodes", "*", "num_attributes", ")", ",", "\n", "strategy", "=", "[", "99", ",", "33", ",", "104", ",", "105", ",", "106", ",", "1", ",", "104", ",", "105", ",", "\n", "106", ",", "70", ",", "104", ",", "105", ",", "107", ",", "99", ",", "165", ",", "104", ",", "105", ",", "106", ",", "\n", "200", ",", "104", ",", "105", ",", "106", ",", "58", ",", "104", ",", "105", ",", "331", ",", "\n", "105", ",", "99", ",", "266", ",", "104", ",", "105", ",", "106", ",", "99", ",", "113", ",", "104", ",", "105", "]", ",", "\n", "continue_prob", "=", "0.8", "\n", ")", "\n", "\n", "attack_idx_to_id", "=", "{", "}", "\n", "attack_idx_to_id", "[", "372", "]", "=", "85", "\n", "attack_idx_to_id", "[", "99", "]", "=", "19", "\n", "attack_idx_to_id", "[", "100", "]", "=", "20", "\n", "attack_idx_to_id", "[", "33", "]", "=", "11", "\n", "attack_idx_to_id", "[", "104", "]", "=", "38", "\n", "attack_idx_to_id", "[", "105", "]", "=", "39", "\n", "attack_idx_to_id", "[", "106", "]", "=", "51", "\n", "attack_idx_to_id", "[", "1", "]", "=", "10", "\n", "attack_idx_to_id", "[", "70", "]", "=", "12", "\n", "attack_idx_to_id", "[", "107", "]", "=", "52", "\n", "attack_idx_to_id", "[", "165", "]", "=", "54", "\n", "attack_idx_to_id", "[", "200", "]", "=", "55", "\n", "attack_idx_to_id", "[", "58", "]", "=", "11", "\n", "attack_idx_to_id", "[", "331", "]", "=", "59", "\n", "attack_idx_to_id", "[", "266", "]", "=", "57", "\n", "attack_idx_to_id", "[", "113", "]", "=", "53", "\n", "\n", "action_to_state", "=", "{", "}", "\n", "action_to_state", "[", "(", "99", ",", "1", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "100", ",", "1", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "33", ",", "2", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "3", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "4", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "5", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "1", ",", "6", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "7", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "8", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "9", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "70", ",", "10", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "11", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "12", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "107", ",", "13", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "14", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "14", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "165", ",", "15", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "16", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=0_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "17", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=0_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "18", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "200", ",", "19", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "20", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=0_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "21", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=0_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "22", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "58", ",", "23", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "24", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=0_root=0_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "25", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=0_root=0_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "331", ",", "26", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "27", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "28", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "28", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "266", ",", "29", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "30", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.62_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "31", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.62_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "32", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "33", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "33", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "113", ",", "34", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "35", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1_172.18.9.7_tools=0_backdoor=1_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "36", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1_172.18.9.7_tools=0_backdoor=1_root=1\"", ",", "True", ",", "True", ")", "\n", "#172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "            ", "action_to_state", "[", "(", "372", ",", "i", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "False", ")", "\n", "\n", "\n", "", "random_defender", "=", "RandomDefender", "(", "num_actions", "=", "2", ",", "stopping_probability", "=", "0.005", ")", "\n", "initial_defense_attributes", "=", "[", "\n", "[", "3", ",", "4", ",", "0", ",", "1", "]", ",", "\n", "[", "7", ",", "8", ",", "5", ",", "2", "]", ",", "\n", "[", "4", ",", "1", ",", "6", ",", "6", "]", ",", "\n", "[", "5", ",", "5", ",", "5", ",", "1", "]", "\n", "]", "\n", "adjacency_matrix", "=", "[", "\n", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "1", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "1", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", "]", "\n", "]", "\n", "\n", "initial_reachable", "=", "[", "0", ",", "1", "]", "\n", "env_config", "=", "EnvConfig", "(", "attacker_static_opponent", "=", "custom_attacker", ",", "\n", "defender_static_opponent", "=", "random_defender", ",", "\n", "adjacency_matrix", "=", "adjacency_matrix", ",", "\n", "initial_reachable", "=", "initial_reachable", ",", "\n", "num_nodes", "=", "num_nodes", ",", "\n", "num_attributes", "=", "num_attributes", ",", "\n", "initial_attack_attributes", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_attributes", ")", ")", ",", "\n", "initial_defense_attributes", "=", "initial_defense_attributes", ",", "\n", "max_attribute_value", "=", "10", ",", "\n", "recon_attribute", "=", "4", ",", "\n", "attacker_target_compromised_reward", "=", "100", ",", "\n", "defender_target_compromised_reward", "=", "-", "100", ",", "\n", "defender_early_stopping_reward", "=", "-", "100", ",", "\n", "attacker_early_stopping_reward", "=", "0", ",", "\n", "defender_intrusion_prevented_reward", "=", "100", ",", "\n", "attacker_intrusion_prevented_reward", "=", "-", "100", ",", "\n", "defender_continue_reward", "=", "10", ",", "\n", "attacker_continue_reward", "=", "0", ",", "\n", "target_id", "=", "3", ",", "\n", "dp", "=", "False", ",", "\n", "dp_load", "=", "False", ",", "\n", "traces", "=", "True", ",", "\n", "action_to_state", "=", "action_to_state", ",", "\n", "attack_idx_to_id", "=", "attack_idx_to_id", ",", "\n", "save_dynamics_model_dir", "=", "traces_dir", ",", "\n", "dynamics_model_name", "=", "traces_filename", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "env_config", "=", "env_config", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.derived_envs.optimal_intrusion_response_env_v3.OptimalIntrusionResponseEnvV3.__init__": [[13, 135], ["gym_optimal_intrusion_response.logic.static_opponents.custom_attacker.CustomAttacker", "range", "gym_optimal_intrusion_response.logic.static_opponents.random_defender.RandomDefender", "gym_optimal_intrusion_response.dao.game.env_config.EnvConfig", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "traces_dir", ":", "str", "=", "\"\"", ",", "traces_filename", ":", "str", "=", "\"\"", ")", ":", "\n", "        ", "num_nodes", "=", "4", "\n", "num_attributes", "=", "4", "\n", "# random_attacker = RandomAttacker(num_actions=(num_nodes*num_attributes))", "\n", "\n", "custom_attacker", "=", "CustomAttacker", "(", "\n", "num_actions", "=", "(", "num_nodes", "*", "num_attributes", ")", ",", "\n", "strategy", "=", "[", "100", ",", "33", ",", "104", ",", "105", ",", "106", ",", "1", ",", "104", ",", "105", ",", "\n", "106", ",", "70", ",", "104", ",", "105", ",", "107", ",", "100", ",", "165", ",", "104", ",", "105", ",", "106", ",", "\n", "200", ",", "104", ",", "105", ",", "106", ",", "58", ",", "104", ",", "105", ",", "331", ",", "\n", "105", ",", "100", ",", "266", ",", "104", ",", "105", ",", "106", ",", "100", ",", "113", ",", "104", ",", "105", "]", ",", "\n", "continue_prob", "=", "0.8", "\n", ")", "\n", "\n", "attack_idx_to_id", "=", "{", "}", "\n", "attack_idx_to_id", "[", "372", "]", "=", "85", "\n", "attack_idx_to_id", "[", "99", "]", "=", "19", "\n", "attack_idx_to_id", "[", "100", "]", "=", "20", "\n", "attack_idx_to_id", "[", "33", "]", "=", "11", "\n", "attack_idx_to_id", "[", "104", "]", "=", "38", "\n", "attack_idx_to_id", "[", "105", "]", "=", "39", "\n", "attack_idx_to_id", "[", "106", "]", "=", "51", "\n", "attack_idx_to_id", "[", "1", "]", "=", "10", "\n", "attack_idx_to_id", "[", "70", "]", "=", "12", "\n", "attack_idx_to_id", "[", "107", "]", "=", "52", "\n", "attack_idx_to_id", "[", "165", "]", "=", "54", "\n", "attack_idx_to_id", "[", "200", "]", "=", "55", "\n", "attack_idx_to_id", "[", "58", "]", "=", "11", "\n", "attack_idx_to_id", "[", "331", "]", "=", "59", "\n", "attack_idx_to_id", "[", "266", "]", "=", "57", "\n", "attack_idx_to_id", "[", "113", "]", "=", "53", "\n", "\n", "action_to_state", "=", "{", "}", "\n", "action_to_state", "[", "(", "99", ",", "1", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "100", ",", "1", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "33", ",", "2", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "3", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "4", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "5", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "1", ",", "6", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "7", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "8", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "9", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "70", ",", "10", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "11", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "12", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=0_root=1_172.18.9.3_tools=1_backdoor=0_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "107", ",", "13", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "14", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "100", ",", "14", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "165", ",", "15", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "16", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=0_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "17", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=0_backdoor=1_root=1_172.18.9.79_tools=0_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "18", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "200", ",", "19", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "20", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=0_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "21", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=0_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "22", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "58", ",", "23", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "24", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=0_root=0_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "25", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=0_root=0_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "331", ",", "26", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "27", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "28", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "100", ",", "28", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "266", ",", "29", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "30", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.62_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "31", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=0_backdoor=1_root=1_172.18.9.62_tools=0_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "106", ",", "32", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "99", ",", "33", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "100", ",", "33", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "113", ",", "34", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "104", ",", "35", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1_172.18.9.7_tools=0_backdoor=1_root=1\"", ",", "False", ",", "True", ")", "\n", "action_to_state", "[", "(", "105", ",", "36", ")", "]", "=", "(", "\"172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1_172.18.9.7_tools=0_backdoor=1_root=1\"", ",", "True", ",", "True", ")", "\n", "#172.18.9.191_172.18.9.2_tools=1_backdoor=1_root=1_172.18.9.3_tools=1_backdoor=1_root=1_172.18.9.54_tools=1_backdoor=1_root=1_172.18.9.61_tools=1_backdoor=1_root=1_172.18.9.62_tools=1_backdoor=1_root=1_172.18.9.74_tools=1_backdoor=1_root=1_172.18.9.79_tools=1_backdoor=0_root=1", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "            ", "action_to_state", "[", "(", "372", ",", "i", ")", "]", "=", "(", "\"172.18.9.191\"", ",", "False", ",", "False", ")", "\n", "\n", "\n", "", "random_defender", "=", "RandomDefender", "(", "num_actions", "=", "2", ",", "stopping_probability", "=", "0.005", ")", "\n", "initial_defense_attributes", "=", "[", "\n", "[", "3", ",", "4", ",", "0", ",", "1", "]", ",", "\n", "[", "7", ",", "8", ",", "5", ",", "2", "]", ",", "\n", "[", "4", ",", "1", ",", "6", ",", "6", "]", ",", "\n", "[", "5", ",", "5", ",", "5", ",", "1", "]", "\n", "]", "\n", "adjacency_matrix", "=", "[", "\n", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "1", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "1", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", "]", "\n", "]", "\n", "\n", "initial_reachable", "=", "[", "0", ",", "1", "]", "\n", "\n", "env_config", "=", "EnvConfig", "(", "attacker_static_opponent", "=", "custom_attacker", ",", "\n", "defender_static_opponent", "=", "random_defender", ",", "\n", "adjacency_matrix", "=", "adjacency_matrix", ",", "\n", "initial_reachable", "=", "initial_reachable", ",", "\n", "num_nodes", "=", "num_nodes", ",", "\n", "num_attributes", "=", "num_attributes", ",", "\n", "initial_attack_attributes", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_attributes", ")", ")", ",", "\n", "initial_defense_attributes", "=", "initial_defense_attributes", ",", "\n", "max_attribute_value", "=", "10", ",", "\n", "recon_attribute", "=", "4", ",", "\n", "attacker_target_compromised_reward", "=", "100", ",", "\n", "defender_target_compromised_reward", "=", "-", "100", ",", "\n", "defender_early_stopping_reward", "=", "-", "100", ",", "\n", "attacker_early_stopping_reward", "=", "0", ",", "\n", "defender_intrusion_prevented_reward", "=", "100", ",", "\n", "attacker_intrusion_prevented_reward", "=", "-", "100", ",", "\n", "defender_continue_reward", "=", "10", ",", "\n", "attacker_continue_reward", "=", "0", ",", "\n", "target_id", "=", "3", ",", "\n", "dp", "=", "False", ",", "\n", "dp_load", "=", "False", ",", "\n", "traces", "=", "True", ",", "\n", "action_to_state", "=", "action_to_state", ",", "\n", "attack_idx_to_id", "=", "attack_idx_to_id", ",", "\n", "save_dynamics_model_dir", "=", "traces_dir", ",", "\n", "dynamics_model_name", "=", "traces_filename", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "env_config", "=", "env_config", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.derived_envs.optimal_intrusion_response_env_v1.OptimalIntrusionResponseEnvV1.__init__": [[13, 56], ["gym_optimal_intrusion_response.logic.static_opponents.random_attacker.RandomAttacker", "gym_optimal_intrusion_response.logic.static_opponents.random_defender.RandomDefender", "gym_optimal_intrusion_response.dao.game.env_config.EnvConfig", "gym_optimal_intrusion_response.envs.optimal_intrusion_response_env.OptimalIntrusionResponseEnv.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__"], ["def", "__init__", "(", "self", ",", "traces_dir", ":", "str", "=", "\"\"", ",", "traces_filename", ":", "str", "=", "\"\"", ")", ":", "\n", "        ", "num_nodes", "=", "4", "\n", "num_attributes", "=", "4", "\n", "random_attacker", "=", "RandomAttacker", "(", "num_actions", "=", "(", "num_nodes", "*", "num_attributes", ")", ")", "\n", "random_defender", "=", "RandomDefender", "(", "num_actions", "=", "2", ",", "stopping_probability", "=", "0.005", ")", "\n", "initial_defense_attributes", "=", "[", "\n", "[", "3", ",", "4", ",", "0", ",", "1", "]", ",", "\n", "[", "7", ",", "8", ",", "5", ",", "2", "]", ",", "\n", "[", "4", ",", "1", ",", "6", ",", "6", "]", ",", "\n", "[", "5", ",", "5", ",", "5", ",", "1", "]", "\n", "]", "\n", "adjacency_matrix", "=", "[", "\n", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "1", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "1", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", "]", "\n", "]", "\n", "\n", "initial_reachable", "=", "[", "0", ",", "1", "]", "\n", "\n", "env_config", "=", "EnvConfig", "(", "attacker_static_opponent", "=", "random_attacker", ",", "\n", "defender_static_opponent", "=", "random_defender", ",", "\n", "adjacency_matrix", "=", "adjacency_matrix", ",", "\n", "initial_reachable", "=", "initial_reachable", ",", "\n", "num_nodes", "=", "num_nodes", ",", "\n", "num_attributes", "=", "num_attributes", ",", "\n", "initial_attack_attributes", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_attributes", ")", ")", ",", "\n", "initial_defense_attributes", "=", "initial_defense_attributes", ",", "\n", "max_attribute_value", "=", "10", ",", "\n", "recon_attribute", "=", "4", ",", "\n", "attacker_target_compromised_reward", "=", "1", ",", "\n", "defender_target_compromised_reward", "=", "-", "1", ",", "\n", "defender_early_stopping_reward", "=", "-", "1", ",", "\n", "attacker_early_stopping_reward", "=", "0", ",", "\n", "defender_intrusion_prevented_reward", "=", "1", ",", "\n", "attacker_intrusion_prevented_reward", "=", "-", "1", ",", "\n", "target_id", "=", "3", ",", "\n", "dp", "=", "True", ",", "\n", "dp_load", "=", "False", ",", "\n", "save_dynamics_model_dir", "=", "traces_dir", ",", "\n", "dynamics_model_name", "=", "traces_filename", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "env_config", "=", "env_config", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.read_model": [[11, 18], ["gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel", "gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel.read_model_path", "gym_pycr_ctf.dao.defender_dynamics.defender_dynamics_model.DefenderDynamicsModel.normalize"], "function", ["None"], ["def", "read_model", "(", "model_path", ")", ":", "\n", "#model_path = \"/Users/kimham/workspace/pycr/python-envs/minigames/network_intrusion/ctf/gym-pycr-ctf/examples/difficulty_level_4/hello_world/defender_dynamics_model.json\"", "\n", "#model_path = \"/home/kim/storage/workspace/pycr/python-envs/minigames/network_intrusion/ctf/gym-pycr-ctf/examples/difficulty_level_4/hello_world/defender_dynamics_model_server.json\"", "\n", "    ", "defender_dynamics_model", "=", "DefenderDynamicsModel", "(", ")", "\n", "defender_dynamics_model", ".", "read_model_path", "(", "model_path", ")", "\n", "defender_dynamics_model", ".", "normalize", "(", ")", "\n", "return", "defender_dynamics_model", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_all": [[19, 37], ["gym_pycr_ctf.envs.derived_envs.level4.emulation.pycr_ctf_level4_emulation_env.PyCrCTFLevel4Base.attacker_all_actions_conf", "plot_dynamics_model.plot_machines_dynamics", "plot_dynamics_model.plot_ids_dynamics", "plot_dynamics_model.plot_complete_model_full_span", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_machines_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_complete_model_full_span"], ["", "def", "plot_all", "(", "defender_dynamics_model", ",", "num_colors", ":", "int", "=", "75", ")", ":", "\n", "    ", "action_cfg", "=", "PyCrCTFLevel4Base", ".", "attacker_all_actions_conf", "(", "num_nodes", "=", "10", ",", "subnet_mask", "=", "\"test\"", ",", "hacker_ip", "=", "\"test\"", ")", "\n", "total_row_dists", ",", "total_row_xks", ",", "total_row_a_ids", ",", "total_row_b_ids", ",", "total_row_short_titles", ",", "total_row_x_labels", ",", "total_row_y_labels", ",", "row_labels", ",", "total_row_a_ids_orig", "=", "plot_machines_dynamics", "(", "defender_dynamics_model", "=", "defender_dynamics_model", ",", "action_cfg", "=", "action_cfg", ")", "\n", "\n", "ids_row_dists", ",", "ids_row_xks", ",", "ids_row_a_ids", ",", "ids_row_b_ids", ",", "ids_row_subtitles", ",", "ids_row_x_labels", ",", "ids_row_y_labels", ",", "row_a_ids_orig", "=", "plot_ids_dynamics", "(", "defender_dynamics_model", "=", "defender_dynamics_model", ",", "action_cfg", "=", "action_cfg", ")", "\n", "\n", "plot_complete_model_full_span", "(", "total_row_dists", ",", "total_row_xks", ",", "total_row_a_ids", ",", "total_row_b_ids", ",", "\n", "total_row_short_titles", ",", "\n", "total_row_x_labels", ",", "total_row_y_labels", ",", "\n", "ids_row_dists", ",", "ids_row_xks", ",", "ids_row_a_ids", ",", "ids_row_b_ids", ",", "ids_row_subtitles", ",", "\n", "ids_row_x_labels", ",", "ids_row_y_labels", ",", "\n", "file_name", "=", "\"total_model_full\"", ",", "\n", "ncols", "=", "len", "(", "total_row_x_labels", "[", "0", "]", ")", ",", "\n", "nrows", "=", "len", "(", "total_row_x_labels", ")", ",", "figsize", "=", "(", "3", ",", "2.2", ")", ",", "fontsize", "=", "3.2", ",", "labelsize", "=", "2.5", ",", "\n", "suptitle", "=", "\"Estimated Emulation Dynamics\"", ",", "ms", "=", "0.4", ",", "title_fontsize", "=", "4.5", ",", "lw", "=", "0.2", ",", "\n", "row_labels", "=", "row_labels", ",", "wspace", "=", "0.03", ",", "hspace", "=", "0.18", ",", "top", "=", "0.92", ",", "num_colors", "=", "num_colors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_machines_dynamics": [[38, 72], ["defender_dynamics_model.machines_dynamics_model.items", "plot_dynamics_model.plot_machine_dynamics", "total_row_dists.append", "total_row_xks.append", "total_row_a_ids.append", "total_row_a_ids_orig.append", "total_row_b_ids.append", "total_row_subtitles.append", "total_row_x_labels.append", "total_row_y_labels.append", "row_labels.append", "total_row_short_titles.append"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_machine_dynamics"], ["", "def", "plot_machines_dynamics", "(", "defender_dynamics_model", ",", "action_cfg", ")", ":", "\n", "    ", "total_row_dists", "=", "[", "]", "\n", "total_row_xks", "=", "[", "]", "\n", "total_row_a_ids", "=", "[", "]", "\n", "total_row_a_ids_orig", "=", "[", "]", "\n", "total_row_b_ids", "=", "[", "]", "\n", "total_row_subtitles", "=", "[", "]", "\n", "total_row_x_labels", "=", "[", "]", "\n", "total_row_y_labels", "=", "[", "]", "\n", "total_row_short_titles", "=", "[", "]", "\n", "row_labels", "=", "[", "]", "\n", "\n", "for", "machine_ip", ",", "v", "in", "defender_dynamics_model", ".", "machines_dynamics_model", ".", "items", "(", ")", ":", "\n", "        ", "row_dists", ",", "row_xks", ",", "row_a_ids", ",", "row_b_ids", ",", "row_subtitles", ",", "row_x_labels", ",", "row_y_labels", ",", "row_short_titles", ",", "row_a_ids_orig", "=", "plot_machine_dynamics", "(", "machine_ip", ",", "v", ",", "action_cfg", ")", "\n", "total_row_dists", ".", "append", "(", "row_dists", ")", "\n", "total_row_xks", ".", "append", "(", "row_xks", ")", "\n", "total_row_a_ids", ".", "append", "(", "row_a_ids", ")", "\n", "total_row_a_ids_orig", ".", "append", "(", "row_a_ids_orig", ")", "\n", "total_row_b_ids", ".", "append", "(", "row_b_ids", ")", "\n", "total_row_subtitles", ".", "append", "(", "row_subtitles", ")", "\n", "total_row_x_labels", ".", "append", "(", "row_x_labels", ")", "\n", "total_row_y_labels", ".", "append", "(", "row_y_labels", ")", "\n", "row_labels", ".", "append", "(", "machine_ip", ")", "\n", "total_row_short_titles", ".", "append", "(", "row_short_titles", ")", "\n", "\n", "# plot_complete_model(total_row_dists, total_row_xks, total_row_a_ids, total_row_b_ids, total_row_short_titles,", "\n", "#                     total_row_x_labels, total_row_y_labels, file_name=\"total_model_machines\", ncols=len(total_row_x_labels[0]),", "\n", "#                     nrows=len(total_row_x_labels), figsize=(3,2.1), fontsize=3.5, labelsize=1.75,", "\n", "#                     suptitle=\"Estimated Dynamics of Nodes in the Emulation\", ms=0.45, title_fontsize=4, lw=0.2,", "\n", "#                     row_labels=row_labels, wspace=0.00, hspace=0.00, top=0.925,", "\n", "#                     num_colors = 75)", "\n", "", "return", "total_row_dists", ",", "total_row_xks", ",", "total_row_a_ids", ",", "total_row_b_ids", ",", "total_row_short_titles", ",", "total_row_x_labels", ",", "total_row_y_labels", ",", "row_labels", ",", "total_row_a_ids_orig", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics_2": [[74, 158], ["gym_pycr_ctf.envs.derived_envs.level9.emulation.pycr_ctf_level9_emulation_env.PyCrCTFLevel9Base.attacker_all_actions_conf", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_ids_dynamics_two_row"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics_two_row"], ["", "def", "plot_ids_dynamics_2", "(", "defender_dynamics_model", ")", ":", "\n", "    ", "action_cfg", "=", "PyCrCTFLevel9Base", ".", "attacker_all_actions_conf", "(", "num_nodes", "=", "10", ",", "subnet_mask", "=", "\"test\"", ",", "hacker_ip", "=", "\"test\"", ")", "\n", "row_dists", "=", "[", "]", "\n", "row_xks", "=", "[", "]", "\n", "row_a_ids", "=", "[", "]", "\n", "row_b_ids", "=", "[", "]", "\n", "row_subtitles", "=", "[", "]", "\n", "row_x_labels", "=", "[", "]", "\n", "row_y_labels", "=", "[", "]", "\n", "\n", "subtitle", "=", "\"IDS Alerts\"", "\n", "xlabel", "=", "r\"\\# IDS Alerts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_alerts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"ids_alerts\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "subtitle", "=", "\"Severe IDS Alerts\"", "\n", "xlabel", "=", "r\"\\# Severe IDS Alerts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_severe_alerts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"severe_ids_alerts\"", "\n", ")", "\n", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "subtitle", "=", "\"Warning IDS Alerts\"", "\n", "xlabel", "=", "r\"\\# Warning IDS Alerts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_warning_alerts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"warning_ids_alerts\"", "\n", ")", "\n", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "subtitle", "=", "\"IDS Alert Priorities\"", "\n", "xlabel", "=", "r\"\\# IDS Alert Priorities\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_priority", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"priority_ids_alerts\"", "\n", ")", "\n", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "plot_ids_dynamics_two_row", "(", "row_dists", ",", "row_xks", ",", "row_a_ids", ",", "row_b_ids", ",", "row_subtitles", ",", "row_x_labels", ",", "row_y_labels", ",", "\n", "\"ids_dynamics_row\"", ",", "suptitle", "=", "\"IDS Dynamics\"", ",", "lw", "=", "1.5", ",", "ms", "=", "4", ")", ",", "\n", "return", "row_dists", ",", "row_xks", ",", "row_a_ids", ",", "row_b_ids", ",", "row_subtitles", ",", "row_x_labels", ",", "row_y_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_machine_dynamics": [[160, 304], ["plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "row_short_titles.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "row_short_titles.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "row_short_titles.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "row_short_titles.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "row_short_titles.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "row_short_titles.append"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics"], ["", "def", "plot_machine_dynamics", "(", "machine_ip", ",", "machine_dynamics", ",", "action_cfg", ")", ":", "\n", "    ", "row_dists", "=", "[", "]", "\n", "row_xks", "=", "[", "]", "\n", "row_a_ids", "=", "[", "]", "\n", "row_a_ids_orig", "=", "[", "]", "\n", "row_b_ids", "=", "[", "]", "\n", "row_subtitles", "=", "[", "]", "\n", "row_x_labels", "=", "[", "]", "\n", "row_y_labels", "=", "[", "]", "\n", "row_short_titles", "=", "[", "]", "\n", "\n", "subtitle", "=", "\"New TCP/UDP Connections\"", "\n", "short_title", "=", "\"Connections\"", "\n", "xlabel", "=", "r\"\\# New TCP/UDP Connections\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "\n", "machine_dynamics", ".", "norm_num_new_open_connections", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "machine_ip", "+", "\"_open_connections\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "row_short_titles", ".", "append", "(", "short_title", ")", "\n", "\n", "subtitle", "=", "\"New Failed Login Attempts\"", "\n", "short_title", "=", "\"Failed Logins\"", "\n", "xlabel", "=", "r\"\\# New Failed Login Attempts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "\n", "machine_dynamics", ".", "norm_num_new_failed_login_attempts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "machine_ip", "+", "\"_failed_logins\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "row_short_titles", ".", "append", "(", "short_title", ")", "\n", "\n", "subtitle", "=", "\"Created User Accounts\"", "\n", "short_title", "=", "\"Accounts\"", "\n", "xlabel", "=", "r\"\\# Created User Accounts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "\n", "machine_dynamics", ".", "norm_num_new_users", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "machine_ip", "+", "\"_users\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "row_short_titles", ".", "append", "(", "short_title", ")", "\n", "\n", "subtitle", "=", "\"New Logged in Users\"", "\n", "short_title", "=", "\"Online Users\"", "\n", "xlabel", "=", "r\"\\# New Logged in Users\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "\n", "machine_dynamics", ".", "norm_num_new_logged_in_users", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "machine_ip", "+", "\"_logged_in_users\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "row_short_titles", ".", "append", "(", "short_title", ")", "\n", "\n", "subtitle", "=", "\"New Login Events\"", "\n", "short_title", "=", "\"Logins\"", "\n", "xlabel", "=", "r\"\\# Login Events\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "\n", "machine_dynamics", ".", "norm_num_new_login_events", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "machine_ip", "+", "\"_login_events\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "row_short_titles", ".", "append", "(", "short_title", ")", "\n", "\n", "subtitle", "=", "\"Created Processes\"", "\n", "short_title", "=", "\"Processes\"", "\n", "xlabel", "=", "r\"\\# Created Processes\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "\n", "machine_dynamics", ".", "norm_num_new_processes", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "machine_ip", "+", "\"_created_processes\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "row_short_titles", ".", "append", "(", "short_title", ")", "\n", "\n", "# plot_ids_dynamics_two_row(row_dists, row_xks, row_a_ids, row_b_ids, row_subtitles, row_x_labels, row_y_labels,", "\n", "#                           machine_ip + \"_row_dynamics\", ncols=3, ip=machine_ip, figsize=(8, 4.5),", "\n", "#                           fontsize=8, labelsize=6, suptitle=\"Node IP: \" + machine_ip,", "\n", "#                           lw=1.5, ms=4)", "\n", "\n", "\n", "return", "row_dists", ",", "row_xks", ",", "row_a_ids", ",", "row_b_ids", ",", "row_subtitles", ",", "row_x_labels", ",", "row_y_labels", ",", "row_short_titles", ",", "row_a_ids_orig", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics": [[307, 395], ["plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_specific_dynamics", "row_dists.append", "row_xks.append", "row_a_ids.append", "row_a_ids_orig.append", "row_b_ids.append", "row_subtitles.append", "row_x_labels.append", "row_y_labels.append", "plot_dynamics_model.plot_ids_dynamics_two_row"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics_two_row"], ["", "def", "plot_ids_dynamics", "(", "defender_dynamics_model", ",", "action_cfg", ")", ":", "\n", "    ", "row_dists", "=", "[", "]", "\n", "row_xks", "=", "[", "]", "\n", "row_a_ids", "=", "[", "]", "\n", "row_a_ids_orig", "=", "[", "]", "\n", "row_b_ids", "=", "[", "]", "\n", "row_subtitles", "=", "[", "]", "\n", "row_x_labels", "=", "[", "]", "\n", "row_y_labels", "=", "[", "]", "\n", "\n", "subtitle", "=", "\"IDS Alerts\"", "\n", "xlabel", "=", "r\"\\# IDS Alerts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_alerts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"ids_alerts\"", "\n", ")", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "subtitle", "=", "\"Severe IDS Alerts\"", "\n", "xlabel", "=", "r\"\\# Severe IDS Alerts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_severe_alerts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"severe_ids_alerts\"", "\n", ")", "\n", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "subtitle", "=", "\"Warning IDS Alerts\"", "\n", "xlabel", "=", "r\"\\# Warning IDS Alerts\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_warning_alerts", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"warning_ids_alerts\"", "\n", ")", "\n", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "subtitle", "=", "\"IDS Alert Priorities\"", "\n", "xlabel", "=", "r\"\\# IDS Alert Priorities\"", "\n", "ylabel", "=", "r\"$\\mathbb{P}[ \\cdot | (b_i, a_i)]$\"", "\n", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "=", "plot_specific_dynamics", "(", "defender_dynamics_model", ".", "norm_num_new_priority", ",", "action_cfg", ",", "\n", "subtitle", "=", "subtitle", ",", "\n", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "file_name", "=", "\"priority_ids_alerts\"", "\n", ")", "\n", "\n", "row_dists", ".", "append", "(", "total_dists", ")", "\n", "row_xks", ".", "append", "(", "total_xks", ")", "\n", "row_a_ids", ".", "append", "(", "total_a_ids", ")", "\n", "row_a_ids_orig", ".", "append", "(", "total_a_ids_orig", ")", "\n", "row_b_ids", ".", "append", "(", "total_b_ids", ")", "\n", "row_subtitles", ".", "append", "(", "subtitle", ")", "\n", "row_x_labels", ".", "append", "(", "xlabel", ")", "\n", "row_y_labels", ".", "append", "(", "ylabel", ")", "\n", "\n", "plot_ids_dynamics_two_row", "(", "row_dists", ",", "row_xks", ",", "row_a_ids", ",", "row_b_ids", ",", "row_subtitles", ",", "row_x_labels", ",", "row_y_labels", ",", "\n", "\"ids_dynamics_row\"", ",", "suptitle", "=", "\"IDS Dynamics\"", ",", "lw", "=", "1.5", ",", "ms", "=", "4", ")", ",", "\n", "return", "row_dists", ",", "row_xks", ",", "row_a_ids", ",", "row_b_ids", ",", "row_subtitles", ",", "row_x_labels", ",", "row_y_labels", ",", "row_a_ids_orig", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_specific_dynamics": [[397, 447], ["data_dict.items", "gym_pycr_ctf.dao.action.attacker.attacker_action_id.AttackerActionId", "action_cfg.get_action_by_id", "total_a_ids_orig.append", "total_a_ids.append", "total_b_ids.append", "numpy.arange", "numpy.array", "total_xks.append", "total_dists.append", "list", "dist.support", "dist.support", "dist.support", "dist.support", "dist.support", "filter", "dist.support", "np.array.tolist", "dist.pmf"], "function", ["None"], ["", "def", "plot_specific_dynamics", "(", "data_dict", ",", "action_cfg", ",", "subtitle", ",", "xlabel", ",", "ylabel", ",", "file_name", ")", ":", "\n", "    ", "total_xks", "=", "[", "]", "\n", "total_dists", "=", "[", "]", "\n", "total_a_ids", "=", "[", "]", "\n", "total_b_ids", "=", "[", "]", "\n", "\n", "total_a_ids_orig", "=", "[", "]", "\n", "min_support", "=", "0", "\n", "max_support", "=", "0", "\n", "\n", "action_ids", "=", "{", "}", "\n", "action_count", "=", "0", "\n", "state_ids", "=", "{", "}", "\n", "state_count", "=", "0", "\n", "\n", "for", "k", ",", "v", "in", "data_dict", ".", "items", "(", ")", ":", "\n", "        ", "action_id_val", "=", "k", "[", "0", "]", "\n", "action_id", "=", "AttackerActionId", "(", "action_id_val", ")", "\n", "action_dto", "=", "action_cfg", ".", "get_action_by_id", "(", "action_id", "=", "action_id", ")", "\n", "logged_in_ips", "=", "k", "[", "1", "]", "\n", "\n", "if", "action_id_val", "not", "in", "action_ids", ":", "\n", "            ", "action_ids", "[", "action_id_val", "]", "=", "action_count", "\n", "action_count", "+=", "1", "\n", "\n", "", "if", "logged_in_ips", "not", "in", "total_b_ids", ":", "\n", "            ", "state_ids", "[", "logged_in_ips", "]", "=", "state_count", "\n", "state_count", "+=", "1", "\n", "", "total_a_ids_orig", ".", "append", "(", "action_id_val", ")", "\n", "total_a_ids", ".", "append", "(", "action_ids", "[", "action_id_val", "]", ")", "\n", "total_b_ids", ".", "append", "(", "state_ids", "[", "logged_in_ips", "]", ")", "\n", "\n", "dist", "=", "data_dict", "[", "k", "]", "\n", "if", "dist", ".", "support", "(", ")", "[", "0", "]", "<", "min_support", ":", "\n", "            ", "min_support", "=", "dist", ".", "support", "(", ")", "[", "0", "]", "\n", "", "if", "dist", ".", "support", "(", ")", "[", "0", "]", ">", "max_support", ":", "\n", "            ", "max_support", "=", "dist", ".", "support", "(", ")", "[", "1", "]", "\n", "\n", "", "xk", "=", "np", ".", "arange", "(", "dist", ".", "support", "(", ")", "[", "0", "]", ",", "dist", ".", "support", "(", ")", "[", "1", "]", "+", "1", ")", "\n", "xk", "=", "np", ".", "array", "(", "list", "(", "filter", "(", "lambda", "x", ":", "dist", ".", "pmf", "(", "x", ")", ">", "0", ",", "xk", ".", "tolist", "(", ")", ")", ")", ")", "\n", "total_xks", ".", "append", "(", "xk", ")", "\n", "total_dists", ".", "append", "(", "dist", ")", "\n", "\n", "# plot_multiple(total_dists, total_xks, min_support, max_support, total_a_ids, total_b_ids,", "\n", "#               subtitle=subtitle,", "\n", "#               xlabel=xlabel,", "\n", "#               ylabel=ylabel, file_name=file_name)", "\n", "# print(\"total a ids:{}\".format(total_a_ids_orig))", "\n", "\n", "", "return", "total_dists", ",", "total_xks", ",", "total_a_ids", ",", "total_b_ids", ",", "total_a_ids_orig", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_complete_model": [[449, 536], ["matplotlib.cm.get_cmap", "matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "matplotlib.rcParams.update", "range", "fig.suptitle", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "matplotlib.close", "matplotlib.cm.viridis", "matplotlib.cm.GnBu", "range", "numpy.linspace", "numpy.linspace", "range", "[].yaxis.get_label", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].spines[].set_color", "[].spines[].set_color", "[].set_ylim", "len", "[].set_title", "[].set_ylabel", "[].set_xticks", "[].set_yticks", "[].plot", "[].vlines", "[].pmf", "[].pmf", "[].plot", "[].vlines", "[].plot", "[].vlines", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_complete_model", "(", "dists", ",", "xks", ",", "a_ids", ",", "b_ids", ",", "subtitles", ",", "xlabels", ",", "ylabels", ",", "file_name", ",", "ncols", "=", "6", ",", "\n", "figsize", "=", "(", "6", ",", "4.5", ")", ",", "fontsize", "=", "10", ",", "labelsize", "=", "6", ",", "suptitle", "=", "\"\"", ",", "nrows", "=", "6", ",", "ms", "=", "2.5", ",", "\n", "title_fontsize", "=", "8", ",", "lw", "=", "0.5", ",", "row_labels", "=", "None", ",", "wspace", "=", "0.03", ",", "hspace", "=", "0.07", ",", "top", "=", "0.9", ",", "\n", "num_colors", ":", "int", "=", "75", ")", ":", "\n", "    ", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "plt", ".", "rcParams", "[", "'axes.titlepad'", "]", "=", "0", "\n", "plt", ".", "rcParams", "[", "'xtick.major.pad'", "]", "=", "0.5", "\n", "plt", ".", "rcParams", "[", "'ytick.major.pad'", "]", "=", "0.5", "\n", "plt", ".", "rcParams", "[", "'axes.labelpad'", "]", "=", "0.8", "\n", "plt", ".", "rcParams", "[", "'axes.linewidth'", "]", "=", "0.1", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", ",", "ncols", "=", "ncols", ",", "figsize", "=", "figsize", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "for", "row", "in", "range", "(", "nrows", ")", ":", "\n", "        ", "rowtitles", "=", "subtitles", "[", "row", "]", "\n", "row_dists", "=", "dists", "[", "row", "]", "\n", "row_xks", "=", "xks", "[", "row", "]", "\n", "row_xlabels", "=", "xlabels", "[", "row", "]", "\n", "row_ylabels", "=", "ylabels", "[", "row", "]", "\n", "row_a_ids", "=", "a_ids", "[", "row", "]", "\n", "row_b_ids", "=", "b_ids", "[", "row", "]", "\n", "for", "col", "in", "range", "(", "ncols", ")", ":", "\n", "            ", "title", "=", "rowtitles", "[", "col", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "row_xks", "[", "col", "]", ")", ")", ":", "\n", "                ", "if", "i", "<", "2", ":", "\n", "                    ", "label", "=", "\"$(b_{\"", "+", "str", "(", "row_b_ids", "[", "col", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "row_a_ids", "[", "col", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "plot", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "vlines", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "0", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                    ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                        ", "ax", "[", "row", "]", "[", "col", "]", ".", "plot", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "vlines", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "0", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                        ", "ax", "[", "row", "]", "[", "col", "]", ".", "plot", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "vlines", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "0", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "", "", "if", "row", "==", "0", ":", "\n", "                ", "ax", "[", "row", "]", "[", "col", "]", ".", "set_title", "(", "title", ",", "fontsize", "=", "fontsize", ")", "\n", "#ax[row][col].set_xlabel(row_xlabels[col], fontsize=labelsize)", "\n", "", "if", "col", "==", "0", ":", "\n", "                ", "ax", "[", "row", "]", "[", "col", "]", ".", "set_ylabel", "(", "row_labels", "[", "row", "]", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "# set the grid on", "\n", "#ax[row][col].grid('on')", "\n", "\n", "# tweak the axis labels", "\n", "#xlab = ax[row][col].xaxis.get_label()", "\n", "", "ylab", "=", "ax", "[", "row", "]", "[", "col", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "#xlab.set_size(labelsize)", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "if", "row", "!=", "nrows", "-", "1", ":", "\n", "                ", "ax", "[", "row", "]", "[", "col", "]", ".", "set_xticks", "(", "[", "]", ")", "\n", "", "if", "col", "!=", "0", ":", "\n", "                ", "ax", "[", "row", "]", "[", "col", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "", "ax", "[", "row", "]", "[", "col", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "\n", "# handles, labels = ax[0][0].get_legend_handles_labels()", "\n", "# fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.52, 0.08),", "\n", "#            ncol=4, fancybox=True, shadow=True)", "\n", "\n", "", "", "fig", ".", "suptitle", "(", "suptitle", ",", "fontsize", "=", "title_fontsize", ",", "fontweight", "=", "\"bold\"", ",", "fontname", "=", "\"Times New Roman Bold\"", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "#fig.subplots_adjust(bottom=0.15,top=0.25)", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "top", "=", "top", ")", "\n", "#bottom=0.35", "\n", "#wspace=0.135, hspace=0.08", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "#plt.show()", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_complete_model_full_span": [[541, 759], ["matplotlib.cm.get_cmap", "matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "matplotlib.rcParams.update", "matplotlib.subplot", "range", "matplotlib.title", "matplotlib.ylabel", "matplotlib.yticks", "matplotlib.xticks", "matplotlib.tick_params", "matplotlib.tick_params", "matplotlib.ylim", "matplotlib.subplot", "range", "matplotlib.title", "matplotlib.yticks", "matplotlib.xticks", "matplotlib.tick_params", "matplotlib.tick_params", "matplotlib.ylim", "matplotlib.subplot", "range", "matplotlib.title", "matplotlib.yticks", "matplotlib.xticks", "matplotlib.tick_params", "matplotlib.tick_params", "matplotlib.ylim", "matplotlib.subplot", "range", "matplotlib.title", "matplotlib.yticks", "matplotlib.xticks", "matplotlib.tick_params", "matplotlib.tick_params", "matplotlib.ylim", "range", "fig.suptitle", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "matplotlib.close", "matplotlib.cm.GnBu", "matplotlib.cm.viridis", "len", "len", "len", "len", "range", "numpy.linspace", "numpy.linspace", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "range", "[].yaxis.get_label", "[].yaxis.get_label.set_size", "[].set_xticks", "[].set_yticks", "[].tick_params", "[].tick_params", "[].spines[].set_color", "[].spines[].set_color", "[].set_ylim", "[].pmf", "[].pmf", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "[].pmf", "[].pmf", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "[].pmf", "[].pmf", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "[].pmf", "[].pmf", "matplotlib.plot", "matplotlib.vlines", "matplotlib.plot", "matplotlib.vlines", "len", "[].set_title", "[].set_ylabel", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].plot", "[].vlines", "[].pmf", "[].pmf", "[].plot", "[].vlines", "[].plot", "[].vlines", "str", "str", "str", "str", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_complete_model_full_span", "(", "dists", ",", "xks", ",", "a_ids", ",", "b_ids", ",", "subtitles", ",", "xlabels", ",", "ylabels", ",", "\n", "ids_row_dists", ",", "ids_row_xks", ",", "ids_row_a_ids", ",", "ids_row_b_ids", ",", "ids_row_subtitles", ",", "\n", "ids_row_x_labels", ",", "ids_row_y_labels", ",", "file_name", ",", "ncols", "=", "6", ",", "\n", "figsize", "=", "(", "6", ",", "4.5", ")", ",", "fontsize", "=", "10", ",", "labelsize", "=", "6", ",", "suptitle", "=", "\"\"", ",", "nrows", "=", "6", ",", "ms", "=", "2.5", ",", "\n", "title_fontsize", "=", "8", ",", "lw", "=", "0.5", ",", "row_labels", "=", "None", ",", "wspace", "=", "0.03", ",", "hspace", "=", "0.07", ",", "top", "=", "0.9", ",", "\n", "num_colors", ":", "int", "=", "75", ")", ":", "\n", "    ", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "plt", ".", "rcParams", "[", "'axes.titlepad'", "]", "=", "0", "\n", "plt", ".", "rcParams", "[", "'xtick.major.pad'", "]", "=", "0.5", "\n", "plt", ".", "rcParams", "[", "'ytick.major.pad'", "]", "=", "0.5", "\n", "plt", ".", "rcParams", "[", "'axes.labelpad'", "]", "=", "0.8", "\n", "plt", ".", "rcParams", "[", "'axes.linewidth'", "]", "=", "0.1", "\n", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", "+", "1", ",", "ncols", "=", "ncols", ",", "figsize", "=", "figsize", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "plt", ".", "subplot", "(", "6", ",", "6", ",", "(", "1", ",", "2", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "i", "<", "2", ":", "\n", "            ", "label", "=", "\"$(b_{\"", "+", "str", "(", "ids_row_b_ids", "[", "0", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "ids_row_a_ids", "[", "0", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "plt", ".", "plot", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "", "", "plt", ".", "title", "(", "\"Alerts\"", ",", "fontsize", "=", "fontsize", ")", "\n", "plt", ".", "ylabel", "(", "\"IDS\"", ",", "fontsize", "=", "fontsize", ")", "\n", "#plt.yticks([])", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "plt", ".", "subplot", "(", "6", ",", "6", ",", "(", "3", ",", "4", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "3", "]", ")", ")", ":", "\n", "        ", "if", "i", "<", "2", ":", "\n", "            ", "label", "=", "\"$(b_{\"", "+", "str", "(", "ids_row_b_ids", "[", "3", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "ids_row_a_ids", "[", "3", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "plt", ".", "plot", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "\n", "", "", "", "plt", ".", "title", "(", "\"Alert Priorities\"", ",", "fontsize", "=", "fontsize", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "\n", "plt", ".", "subplot", "(", "6", ",", "6", ",", "5", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "i", "<", "2", ":", "\n", "            ", "label", "=", "\"$(b_{\"", "+", "str", "(", "ids_row_b_ids", "[", "1", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "ids_row_a_ids", "[", "1", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "plt", ".", "plot", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "", "", "plt", ".", "title", "(", "\"Severe Alerts\"", ",", "fontsize", "=", "fontsize", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "plt", ".", "subplot", "(", "6", ",", "6", ",", "6", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "2", "]", ")", ")", ":", "\n", "        ", "if", "i", "<", "2", ":", "\n", "            ", "label", "=", "\"$(b_{\"", "+", "str", "(", "ids_row_b_ids", "[", "2", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "ids_row_a_ids", "[", "2", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "plt", ".", "plot", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "plot", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "plt", ".", "vlines", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "", "", "", "plt", ".", "title", "(", "\"Warning Alerts\"", ",", "fontsize", "=", "fontsize", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "plt", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "for", "row", "in", "range", "(", "1", ",", "nrows", "+", "1", ")", ":", "\n", "        ", "rowtitles", "=", "subtitles", "[", "row", "-", "1", "]", "\n", "row_dists", "=", "dists", "[", "row", "-", "1", "]", "\n", "row_xks", "=", "xks", "[", "row", "-", "1", "]", "\n", "row_xlabels", "=", "xlabels", "[", "row", "-", "1", "]", "\n", "row_ylabels", "=", "ylabels", "[", "row", "-", "1", "]", "\n", "row_a_ids", "=", "a_ids", "[", "row", "-", "1", "]", "\n", "row_b_ids", "=", "b_ids", "[", "row", "-", "1", "]", "\n", "for", "col", "in", "range", "(", "ncols", ")", ":", "\n", "            ", "title", "=", "rowtitles", "[", "col", "]", "\n", "#l = \"r$(b_{\" + b_ids[i] + \"},a_{\" + a_ids[i] + \"})$\"", "\n", "for", "i", "in", "range", "(", "len", "(", "row_xks", "[", "col", "]", ")", ")", ":", "\n", "                ", "if", "i", "<", "2", ":", "\n", "                    ", "label", "=", "\"$(b_{\"", "+", "str", "(", "row_b_ids", "[", "col", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "row_a_ids", "[", "col", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "plot", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "vlines", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "0", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                    ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                        ", "ax", "[", "row", "]", "[", "col", "]", ".", "plot", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "vlines", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "0", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                        ", "ax", "[", "row", "]", "[", "col", "]", ".", "plot", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "vlines", "(", "row_xks", "[", "col", "]", "[", "i", "]", ",", "0", ",", "row_dists", "[", "col", "]", "[", "i", "]", ".", "pmf", "(", "row_xks", "[", "col", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "", "", "if", "row", "==", "1", ":", "\n", "                ", "ax", "[", "row", "]", "[", "col", "]", ".", "set_title", "(", "title", ",", "fontsize", "=", "fontsize", ")", "\n", "#ax[row][col].set_xlabel(row_xlabels[col], fontsize=labelsize)", "\n", "", "if", "col", "==", "0", ":", "\n", "                ", "ax", "[", "row", "]", "[", "col", "]", ".", "set_ylabel", "(", "row_labels", "[", "row", "-", "1", "]", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "# set the grid on", "\n", "#ax[row][col].grid('on')", "\n", "\n", "# tweak the axis labels", "\n", "#xlab = ax[row][col].xaxis.get_label()", "\n", "", "ylab", "=", "ax", "[", "row", "]", "[", "col", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "#xlab.set_size(labelsize)", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "#if row != nrows:", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "set_xticks", "(", "[", "]", ")", "\n", "#if col != 0:", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "row", "]", "[", "col", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "\n", "# handles, labels = ax[0][0].get_legend_handles_labels()", "\n", "# fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.52, 0.08),", "\n", "#            ncol=4, fancybox=True, shadow=True)", "\n", "\n", "", "", "fig", ".", "suptitle", "(", "suptitle", ",", "fontsize", "=", "title_fontsize", ",", "fontweight", "=", "\"bold\"", ",", "fontname", "=", "\"Times New Roman Bold\"", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "#fig.subplots_adjust(bottom=0.15,top=0.25)", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "top", "=", "top", ")", "\n", "#bottom=0.35", "\n", "#wspace=0.135, hspace=0.08", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "#plt.show()", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics_two_row": [[762, 839], ["print", "matplotlib.cm.get_cmap", "matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "matplotlib.rcParams.update", "range", "[].get_legend_handles_labels", "fig.legend", "fig.suptitle", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "matplotlib.close", "matplotlib.cm.GnBu", "matplotlib.cm.viridis", "len", "range", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].spines[].set_color", "[].spines[].set_color", "[].set_ylim", "numpy.linspace", "numpy.linspace", "len", "[].plot", "[].vlines", "[].pmf", "[].pmf", "[].plot", "[].vlines", "[].plot", "[].vlines", "len", "str", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_ids_dynamics_two_row", "(", "dists", ",", "xks", ",", "\n", "a_ids", ",", "b_ids", ",", "\n", "subtitles", ",", "\n", "xlabels", ",", "ylabels", ",", "file_name", ",", "ncols", "=", "2", ",", "ip", "=", "None", ",", "\n", "figsize", "=", "(", "6", ",", "4.5", ")", ",", "fontsize", "=", "10", ",", "labelsize", "=", "6", ",", "\n", "suptitle", "=", "\"\"", ",", "num_colors", "=", "75", ",", "lw", "=", "2", ",", "ms", "=", "8", ")", ":", "\n", "    ", "print", "(", "subtitles", ")", "\n", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "2", ",", "ncols", "=", "ncols", ",", "figsize", "=", "figsize", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "k", "=", "0", "\n", "row", "=", "0", "\n", "for", "j", "in", "range", "(", "len", "(", "dists", ")", ")", ":", "\n", "        ", "title", "=", "subtitles", "[", "j", "]", "\n", "if", "j", ">", "(", "len", "(", "dists", ")", "/", "2", ")", "-", "1", "and", "row", "==", "0", ":", "\n", "            ", "row", "=", "1", "\n", "k", "=", "0", "\n", "\n", "#l = \"r$(b_{\" + b_ids[i] + \"},a_{\" + a_ids[i] + \"})$\"", "\n", "", "for", "i", "in", "range", "(", "len", "(", "xks", "[", "j", "]", ")", ")", ":", "\n", "            ", "if", "i", "<", "2", ":", "\n", "                ", "label", "=", "\"$(b_{\"", "+", "str", "(", "b_ids", "[", "j", "]", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "a_ids", "[", "j", "]", "[", "i", "]", ")", "+", "\"})$\"", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "plot", "(", "xks", "[", "j", "]", "[", "i", "]", ",", "dists", "[", "j", "]", "[", "i", "]", ".", "pmf", "(", "xks", "[", "j", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "vlines", "(", "xks", "[", "j", "]", "[", "i", "]", ",", "0", ",", "dists", "[", "j", "]", "[", "i", "]", ".", "pmf", "(", "xks", "[", "j", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                    ", "ax", "[", "row", "]", "[", "k", "]", ".", "plot", "(", "xks", "[", "j", "]", "[", "i", "]", ",", "dists", "[", "j", "]", "[", "i", "]", ".", "pmf", "(", "xks", "[", "j", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "vlines", "(", "xks", "[", "j", "]", "[", "i", "]", ",", "0", ",", "dists", "[", "j", "]", "[", "i", "]", ".", "pmf", "(", "xks", "[", "j", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "", "else", ":", "\n", "                    ", "ax", "[", "row", "]", "[", "k", "]", ".", "plot", "(", "xks", "[", "j", "]", "[", "i", "]", ",", "dists", "[", "j", "]", "[", "i", "]", ".", "pmf", "(", "xks", "[", "j", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "vlines", "(", "xks", "[", "j", "]", "[", "i", "]", ",", "0", ",", "dists", "[", "j", "]", "[", "i", "]", ".", "pmf", "(", "xks", "[", "j", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "", "", "ax", "[", "row", "]", "[", "k", "]", ".", "set_title", "(", "title", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "set_xlabel", "(", "xlabels", "[", "j", "]", ",", "fontsize", "=", "labelsize", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "set_ylabel", "(", "ylabels", "[", "j", "]", ",", "fontsize", "=", "labelsize", ")", "\n", "\n", "# set the grid on", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "row", "]", "[", "k", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "row", "]", "[", "k", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "labelsize", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "row", "]", "[", "k", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "\n", "k", "+=", "1", "\n", "\n", "", "handles", ",", "labels", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "get_legend_handles_labels", "(", ")", "\n", "fig", ".", "legend", "(", "handles", ",", "labels", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.52", ",", "0.08", ")", ",", "\n", "ncol", "=", "4", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ")", "\n", "\n", "fig", ".", "suptitle", "(", "suptitle", ",", "fontsize", "=", "12", ",", "fontweight", "=", "\"bold\"", ",", "fontname", "=", "\"Times New Roman Bold\"", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ",", "top", "=", "0.85", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "#plt.show()", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_multiple": [[842, 909], ["matplotlib.cm.get_cmap", "matplotlib.cm.viridis", "matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "matplotlib.rcParams.update", "range", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.set_tick_params", "ax.yaxis.set_tick_params", "ax.spines[].set_color", "ax.spines[].set_color", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.set_ylim", "ax.legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "matplotlib.cm.GnBu", "len", "numpy.linspace", "numpy.linspace", "ax.plot", "ax.vlines", "dists[].pmf", "dists[].pmf", "ax.plot", "ax.vlines", "ax.plot", "ax.vlines", "str", "dists[].pmf", "dists[].pmf", "dists[].pmf", "dists[].pmf", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.vec_monitor.VecMonitor.close", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_multiple", "(", "dists", ",", "xks", ",", "min_support", ",", "max_support", ",", "\n", "a_ids", ",", "b_ids", ",", "\n", "subtitle", ":", "str", ",", "\n", "xlabel", ":", "str", ",", "ylabel", ":", "str", ",", "file_name", ":", "str", ",", "num_colors", "=", "75", ")", ":", "\n", "    ", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", "[", "-", "num_colors", ":", "]", ")", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "4.5", ",", "4", ")", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "10", "}", ")", "\n", "title", "=", "r\"PMF: $\\mathbb{P}[b^{\\prime} | b, a]$ - \"", "+", "subtitle", "\n", "\n", "#l = \"r$(b_{\" + b_ids[i] + \"},a_{\" + a_ids[i] + \"})$\"", "\n", "for", "i", "in", "range", "(", "len", "(", "xks", ")", ")", ":", "\n", "        ", "if", "i", "<", "2", ":", "\n", "            ", "label", "=", "\"$(b_{\"", "+", "str", "(", "b_ids", "[", "i", "]", ")", "+", "\"},a_{\"", "+", "str", "(", "a_ids", "[", "i", "]", ")", "+", "\"})$\"", "\n", "ax", ".", "plot", "(", "xks", "[", "i", "]", ",", "dists", "[", "i", "]", ".", "pmf", "(", "xks", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "8", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", ".", "vlines", "(", "xks", "[", "i", "]", ",", "0", ",", "dists", "[", "i", "]", ".", "pmf", "(", "xks", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "\"...\"", "\n", "if", "i", ">", "2", ":", "\n", "                ", "ax", ".", "plot", "(", "xks", "[", "i", "]", ",", "dists", "[", "i", "]", ".", "pmf", "(", "xks", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "8", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ")", "\n", "ax", ".", "vlines", "(", "xks", "[", "i", "]", ",", "0", ",", "dists", "[", "i", "]", ".", "pmf", "(", "xks", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "2", ")", "\n", "", "else", ":", "\n", "                ", "ax", ".", "plot", "(", "xks", "[", "i", "]", ",", "dists", "[", "i", "]", ".", "pmf", "(", "xks", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "8", ",", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "label", ")", "\n", "ax", ".", "vlines", "(", "xks", "[", "i", "]", ",", "0", ",", "dists", "[", "i", "]", ".", "pmf", "(", "xks", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "2", ")", "\n", "\n", "", "", "", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ",", "fontsize", "=", "20", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ",", "fontsize", "=", "20", ")", "\n", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# remove tick marks", "\n", "ax", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "#ax.margins(x=1)", "\n", "ax", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "# ax.set_xlim((0, 260))", "\n", "#ax.set_xlim(min_support-2 , max_support+2)", "\n", "#if len(labels) > 1:", "\n", "#ax.legend(loc=\"upper right\")", "\n", "ax", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.15", ")", ",", "\n", "ncol", "=", "3", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "ax", ".", "xmargin", "=", "10", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "#plt.show()", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot": [[912, 954], ["matplotlib.cm.get_cmap", "matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "matplotlib.rcParams.update", "ax.plot", "ax.vlines", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.set_tick_params", "ax.yaxis.set_tick_params", "ax.spines[].set_color", "ax.spines[].set_color", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.set_xlim", "fig.tight_layout", "matplotlib.show", "matplotlib.cm.GnBu", "matplotlib.cm.viridis", "dist.pmf", "dist.pmf", "numpy.linspace", "numpy.linspace", "dist.support", "dist.support"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot", "(", "dist", ",", "xk", ",", "k", ",", "action_dto", ":", "AttackerAction", ",", "logged_in_ips", ",", "subtitle", ":", "str", ",", "\n", "xlabel", ":", "str", ",", "ylabel", ":", "str", ")", ":", "\n", "    ", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "4", ")", ")", "[", "-", "4", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "4", ")", ")", "[", "-", "4", ":", "]", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "5", ",", "3.5", ")", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "10", "}", ")", "\n", "title", "=", "\"PMF: {} - {}\"", ".", "format", "(", "action_dto", ".", "name", ",", "subtitle", ")", "\n", "\n", "ax", ".", "plot", "(", "xk", ",", "dist", ".", "pmf", "(", "xk", ")", ",", "'ro'", ",", "ms", "=", "8", ",", "mec", "=", "colors", "[", "0", "]", ",", "color", "=", "colors", "[", "0", "]", ")", "\n", "ax", ".", "vlines", "(", "xk", ",", "0", ",", "dist", ".", "pmf", "(", "xk", ")", ",", "colors", "=", "colors", "[", "0", "]", ",", "linestyles", "=", "'-'", ",", "lw", "=", "2", ")", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ",", "fontsize", "=", "20", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ",", "fontsize", "=", "20", ")", "\n", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# remove tick marks", "\n", "ax", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "# ax.set_xlim((0, 260))", "\n", "ax", ".", "set_xlim", "(", "(", "dist", ".", "support", "(", ")", "[", "0", "]", "-", "1", ",", "dist", ".", "support", "(", ")", "[", "1", "]", "+", "1", ")", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_infra_and_one_machine": [[955, 1003], ["gym_pycr_ctf.envs.derived_envs.level9.emulation.pycr_ctf_level9_emulation_env.PyCrCTFLevel9Base.attacker_all_actions_conf", "plot_dynamics_model.plot_machines_dynamics", "print", "print", "print", "print", "plot_dynamics_model.plot_ids_dynamics", "print", "plot_dynamics_model.plot_ids_infra_and_one_machine_impl"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_machines_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_infra_and_one_machine_impl"], ["", "def", "plot_ids_infra_and_one_machine", "(", "defender_dynamics_model", ")", ":", "\n", "    ", "action_cfg", "=", "PyCrCTFLevel9Base", ".", "attacker_all_actions_conf", "(", "num_nodes", "=", "10", ",", "subnet_mask", "=", "\"test\"", ",", "hacker_ip", "=", "\"test\"", ")", "\n", "machine_row_dists", ",", "machine_row_xks", ",", "machine_row_a_ids", ",", "machine_row_b_ids", ",", "machine_row_short_titles", ",", "machine_row_x_labels", ",", "machine_row_y_labels", ",", "machine_row_labels", ",", "total_row_a_ids_orig", "=", "plot_machines_dynamics", "(", "\n", "defender_dynamics_model", "=", "defender_dynamics_model", ",", "action_cfg", "=", "action_cfg", ")", "\n", "machine_row_dists", "=", "machine_row_dists", "[", "0", ":", "2", "]", "\n", "machine_row_xks", "=", "machine_row_xks", "[", "0", ":", "2", "]", "\n", "machine_row_a_ids", "=", "machine_row_a_ids", "[", "0", ":", "2", "]", "\n", "machine_row_b_ids", "=", "machine_row_b_ids", "[", "0", ":", "2", "]", "\n", "machine_row_short_titles", "=", "machine_row_short_titles", "[", "0", ":", "2", "]", "\n", "machine_row_x_labels", "=", "machine_row_x_labels", "[", "0", ":", "2", "]", "\n", "machine_row_y_labels", "=", "machine_row_y_labels", "[", "0", ":", "2", "]", "\n", "machine_row_labels", "=", "machine_row_labels", "[", "0", ":", "2", "]", "\n", "\n", "print", "(", "machine_row_short_titles", ")", "\n", "print", "(", "machine_row_x_labels", ")", "\n", "print", "(", "machine_row_y_labels", ")", "\n", "print", "(", "machine_row_labels", ")", "\n", "\n", "ids_row_dists", ",", "ids_row_xks", ",", "ids_row_a_ids", ",", "ids_row_b_ids", ",", "ids_row_subtitles", ",", "ids_row_x_labels", ",", "ids_row_y_labels", ",", "row_a_ids_orig", "=", "plot_ids_dynamics", "(", "defender_dynamics_model", "=", "defender_dynamics_model", ",", "action_cfg", "=", "action_cfg", ")", "\n", "\n", "ids_row_dists", "=", "ids_row_dists", "\n", "ids_row_xks", "=", "ids_row_xks", "\n", "ids_row_a_ids", "=", "ids_row_a_ids", "\n", "ids_row_b_ids", "=", "ids_row_b_ids", "\n", "ids_row_subtitles", "=", "ids_row_subtitles", "\n", "ids_row_x_labels", "=", "ids_row_x_labels", "\n", "ids_row_y_labels", "=", "ids_row_y_labels", "\n", "\n", "print", "(", "ids_row_subtitles", ")", "\n", "\n", "# path = \"/Users/kimham/workspace/pycr/python-envs/minigames/network_intrusion/ctf/gym-pycr-ctf/examples/difficulty_level_6/plots/merged.zip\"", "\n", "# costs_data, costs_data_factors, bin_edges, costs_factors = plotting_action_costs.read_action_costs(", "\n", "#     zip_file=path,", "\n", "#     num_bins=100, factors=[2, 3, 4])", "\n", "# print(\"loaded the data\")", "\n", "\n", "plot_ids_infra_and_one_machine_impl", "(", "num_colors", "=", "75", ",", "machine_row_dists", "=", "machine_row_dists", ",", "\n", "machine_row_xks", "=", "machine_row_xks", ",", "\n", "machine_row_short_titles", "=", "machine_row_short_titles", ",", "\n", "machine_row_x_labels", "=", "machine_row_x_labels", ",", "\n", "machine_row_y_labels", "=", "machine_row_y_labels", ",", "\n", "ids_row_xks", "=", "ids_row_xks", ",", "ids_row_a_ids", "=", "ids_row_a_ids", ",", "\n", "ids_row_b_ids", "=", "ids_row_b_ids", ",", "ids_row_x_labels", "=", "ids_row_x_labels", ",", "\n", "ids_row_y_labels", "=", "ids_row_y_labels", ",", "ids_row_dists", "=", "ids_row_dists", ",", "\n", "ids_row_subtitles", "=", "ids_row_subtitles", ",", "machine_row_labels", "=", "machine_row_labels", ",", "\n", "file_name", "=", "\"ids_infra_one_macine\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_infra_and_one_machine_2": [[1005, 1055], ["gym_pycr_ctf.envs.derived_envs.level9.emulation.pycr_ctf_level9_emulation_env.PyCrCTFLevel9Base.attacker_all_actions_conf", "plot_dynamics_model.plot_machines_dynamics", "print", "print", "print", "print", "print", "plot_dynamics_model.plot_ids_dynamics", "print", "plot_dynamics_model.plot_ids_infra_and_one_machine_impl_int_non_int"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_machines_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_dynamics", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_infra_and_one_machine_impl_int_non_int"], ["", "def", "plot_ids_infra_and_one_machine_2", "(", "defender_dynamics_model", ")", ":", "\n", "    ", "action_cfg", "=", "PyCrCTFLevel9Base", ".", "attacker_all_actions_conf", "(", "num_nodes", "=", "10", ",", "subnet_mask", "=", "\"test\"", ",", "hacker_ip", "=", "\"test\"", ")", "\n", "machine_row_dists", ",", "machine_row_xks", ",", "machine_row_a_ids", ",", "machine_row_b_ids", ",", "machine_row_short_titles", ",", "machine_row_x_labels", ",", "machine_row_y_labels", ",", "machine_row_labels", ",", "total_row_a_ids_orig", "=", "plot_machines_dynamics", "(", "\n", "defender_dynamics_model", "=", "defender_dynamics_model", ",", "action_cfg", "=", "action_cfg", ")", "\n", "machine_row_dists", "=", "machine_row_dists", "[", "0", ":", "2", "]", "\n", "machine_row_xks", "=", "machine_row_xks", "[", "0", ":", "2", "]", "\n", "machine_row_a_ids", "=", "machine_row_a_ids", "[", "0", ":", "2", "]", "\n", "total_row_a_ids_orig", "=", "total_row_a_ids_orig", "[", "0", ":", "2", "]", "\n", "print", "(", "\"machine a row ids:{}\"", ".", "format", "(", "total_row_a_ids_orig", ")", ")", "\n", "machine_row_short_titles", "=", "machine_row_short_titles", "[", "0", ":", "2", "]", "\n", "machine_row_x_labels", "=", "machine_row_x_labels", "[", "0", ":", "2", "]", "\n", "machine_row_y_labels", "=", "machine_row_y_labels", "[", "0", ":", "2", "]", "\n", "machine_row_labels", "=", "machine_row_labels", "[", "0", ":", "2", "]", "\n", "\n", "print", "(", "machine_row_short_titles", ")", "\n", "print", "(", "machine_row_x_labels", ")", "\n", "print", "(", "machine_row_y_labels", ")", "\n", "print", "(", "machine_row_labels", ")", "\n", "\n", "ids_row_dists", ",", "ids_row_xks", ",", "ids_row_a_ids", ",", "ids_row_b_ids", ",", "ids_row_subtitles", ",", "ids_row_x_labels", ",", "ids_row_y_labels", ",", "total_row_a_ids_orig", "=", "plot_ids_dynamics", "(", "defender_dynamics_model", "=", "defender_dynamics_model", ",", "action_cfg", "=", "action_cfg", ")", "\n", "\n", "ids_row_dists", "=", "ids_row_dists", "\n", "ids_row_xks", "=", "ids_row_xks", "\n", "ids_row_a_ids", "=", "ids_row_a_ids", "\n", "ids_row_b_ids", "=", "ids_row_b_ids", "\n", "ids_row_subtitles", "=", "ids_row_subtitles", "\n", "ids_row_x_labels", "=", "ids_row_x_labels", "\n", "ids_row_y_labels", "=", "ids_row_y_labels", "\n", "\n", "print", "(", "ids_row_subtitles", ")", "\n", "\n", "# path = \"/Users/kimham/workspace/pycr/python-envs/minigames/network_intrusion/ctf/gym-pycr-ctf/examples/difficulty_level_6/plots/merged.zip\"", "\n", "# costs_data, costs_data_factors, bin_edges, costs_factors = plotting_action_costs.read_action_costs(", "\n", "#     zip_file=path,", "\n", "#     num_bins=100, factors=[2, 3, 4])", "\n", "# print(\"loaded the data\")", "\n", "\n", "plot_ids_infra_and_one_machine_impl_int_non_int", "(", "num_colors", "=", "75", ",", "machine_row_dists", "=", "machine_row_dists", ",", "\n", "machine_row_xks", "=", "machine_row_xks", ",", "\n", "machine_row_short_titles", "=", "machine_row_short_titles", ",", "\n", "machine_row_x_labels", "=", "machine_row_x_labels", ",", "\n", "machine_row_y_labels", "=", "machine_row_y_labels", ",", "\n", "ids_row_xks", "=", "ids_row_xks", ",", "ids_row_a_ids", "=", "ids_row_a_ids", ",", "\n", "ids_row_b_ids", "=", "ids_row_b_ids", ",", "ids_row_x_labels", "=", "ids_row_x_labels", ",", "\n", "ids_row_y_labels", "=", "ids_row_y_labels", ",", "ids_row_dists", "=", "ids_row_dists", ",", "\n", "ids_row_subtitles", "=", "ids_row_subtitles", ",", "machine_row_labels", "=", "machine_row_labels", ",", "\n", "file_name", "=", "\"ids_infra_one_macine_int_non_int\"", ",", "\n", "total_row_a_ids_orig", "=", "total_row_a_ids_orig", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_infra_and_one_machine_impl": [[1057, 1234], ["matplotlib.cm.get_cmap", "matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.subplots", "range", "range", "range", "range", "[].grid", "[].set_ylabel", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].set_yticks", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].grid", "[].set_ylabel", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].set_yticks", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "range", "range", "[].grid", "[].set_ylabel", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].grid", "[].set_yticks", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "matplotlib.cm.GnBu", "matplotlib.cm.viridis", "len", "[].plot", "[].vlines", "len", "[].plot", "[].vlines", "len", "[].plot", "[].vlines", "len", "[].plot", "[].vlines", "len", "[].plot", "[].vlines", "len", "[].plot", "[].vlines", "numpy.linspace", "numpy.linspace", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_ids_infra_and_one_machine_impl", "(", "num_colors", ":", "int", "=", "75", ",", "fontsize", ":", "int", "=", "6.5", ",", "figsize", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "3.75", ",", "3.4", ")", ",", "\n", "nrows", ":", "int", "=", "3", ",", "ncols", ":", "int", "=", "2", ",", "file_name", "=", "\"test\"", ",", "\n", "machine_row_dists", "=", "None", ",", "machine_row_xks", "=", "None", ",", "\n", "machine_row_short_titles", "=", "None", ",", "\n", "machine_row_x_labels", "=", "None", ",", "machine_row_y_labels", "=", "None", ",", "ids_row_dists", "=", "None", ",", "\n", "ids_row_xks", "=", "None", ",", "ids_row_a_ids", "=", "None", ",", "ids_row_b_ids", "=", "None", ",", "\n", "ids_row_x_labels", "=", "None", ",", "ids_row_y_labels", "=", "None", ",", "ms", "=", "2.5", ",", "\n", "title_fontsize", "=", "8", ",", "lw", "=", "0.5", ",", "wspace", "=", "0.02", ",", "hspace", "=", "0.3", ",", "top", "=", "0.9", ",", "\n", "labelsize", "=", "6", ",", "ids_row_subtitles", "=", "None", ",", "machine_row_labels", "=", "None", "\n", ")", ":", "\n", "    ", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "plt", ".", "rcParams", "[", "'axes.titlepad'", "]", "=", "0.02", "\n", "# plt.rcParams['xtick.major.pad'] = 0.5", "\n", "plt", ".", "rcParams", "[", "'ytick.major.pad'", "]", "=", "0.05", "\n", "#plt.rcParams['axes.labelpad'] = 0.8", "\n", "plt", ".", "rcParams", "[", "'axes.linewidth'", "]", "=", "0.1", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", ",", "ncols", "=", "ncols", ",", "figsize", "=", "figsize", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "0", "]", ")", ")", ":", "\n", "        ", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "\n", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "label", "=", "\"\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "vlines", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "0", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "0", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "1", "]", ")", ")", ":", "\n", "        ", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "\n", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "\"\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "vlines", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "2", "]", ")", ")", ":", "\n", "        ", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "\n", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "\"\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "vlines", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "3", "]", ")", ")", ":", "\n", "        ", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "\n", "mec", "=", "colors", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ",", "label", "=", "\"\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "vlines", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "3", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "3", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "ax", "[", "0", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "#ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_title", "(", "\"\\# New IDS Alerts\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "#ax[0][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_title", "(", "\"\\# New Severe IDS Alerts\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "\"\\# New Warning IDS Alerts\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "\"\\# New IDS Priority\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", ")", ")", ":", "\n", "        ", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ",", "machine_row_dists", "[", "0", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "\"\"", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "vlines", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ",", "0", ",", "machine_row_dists", "[", "0", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "\n", "lw", "=", "lw", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", ")", ")", ":", "\n", "        ", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ",", "machine_row_dists", "[", "1", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms", ",", "mec", "=", "colors", "[", "i", "]", ",", "\n", "color", "=", "colors", "[", "i", "]", ",", "\n", "label", "=", "\"\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "vlines", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ",", "0", ",", "machine_row_dists", "[", "1", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "colors", "[", "i", "]", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "ax", "[", "2", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_ylabel", "(", "r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_title", "(", "\"\\# New Failed Logins 172.18.9.2\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "#ax[1][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_title", "(", "\"\\# New Failed Logins 172.18.9.3\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "# plt.subplot(nrows, ncols, (5, 6))", "\n", "#", "\n", "# colors = plt.cm.viridis(np.linspace(0.3, 1, 4))[-4:]", "\n", "#", "\n", "# histo, bin_edges = np.histogram(costs_factors[3], 30, (0, 2300))", "\n", "# bin_middles = 0.5 * (bin_edges[1:] + bin_edges[:-1])", "\n", "# print(np.array(costs_factors[3]) * 0.01)", "\n", "# plt.hist(costs_factors[3], bins=30, alpha=1, range=(0, 2300),", "\n", "#               label=\"test\", stacked=False, log=True, color=colors[0], density=True, edgecolor='black', ls=\"-\")", "\n", "#", "\n", "# normalisation = 30 / (len(costs_factors[3]) * (2300 - 0))", "\n", "# y_err = np.sqrt(histo) * normalisation", "\n", "# y = histo * normalisation", "\n", "# y_err[0] = y_err[0] + 0.0025", "\n", "# y_err[1] = y_err[1] + 0.0001", "\n", "# plt.errorbar(bin_middles, y, fmt='.k', color=\"black\", yerr=y_err)", "\n", "#", "\n", "# plt.grid('on')", "\n", "#plt.set_yticks([])", "\n", "# ax[1][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "# xlab = plt.xaxis.get_label()", "\n", "# ylab = plt.yaxis.get_label()", "\n", "# xlab.set_size(labelsize)", "\n", "# ylab.set_size(fontsize)", "\n", "# plt.ylabel(r\"Normalized frequency\", fontsize=labelsize)", "\n", "# plt.tick_params(axis='both', which='major', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# plt.tick_params(axis='both', which='minor', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# #plt.ylim(0, 1.1)", "\n", "# plt.xlim(0, 2300)", "\n", "# plt.title(\"Wallclock time (s) of executing actions\", fontsize=fontsize)", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "top", "=", "top", ")", "\n", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot_ids_infra_and_one_machine_impl_int_non_int": [[1237, 1490], ["matplotlib.cm.get_cmap", "matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.subplots", "print", "print", "range", "range", "range", "range", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].set_yticks", "[].set_ylabel", "range", "range", "range", "range", "[].grid", "[].set_ylabel", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].grid", "[].set_yticks", "[].set_ylabel", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].tick_params", "[].tick_params", "[].set_ylim", "[].set_title", "[].tick_params", "[].tick_params", "[].tick_params", "[].tick_params", "[].get_legend_handles_labels", "print", "print", "fig.legend", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "matplotlib.cm.GnBu", "matplotlib.cm.viridis", "len", "len", "len", "len", "len", "len", "len", "len", "numpy.linspace", "numpy.linspace", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].plot", "[].vlines", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf", "[].pmf"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_ids_infra_and_one_machine_impl_int_non_int", "(", "num_colors", ":", "int", "=", "75", ",", "fontsize", ":", "int", "=", "8", ",", "figsize", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "4.1", ",", "2.9", ")", ",", "\n", "nrows", ":", "int", "=", "3", ",", "ncols", ":", "int", "=", "2", ",", "file_name", "=", "\"test\"", ",", "\n", "machine_row_dists", "=", "None", ",", "machine_row_xks", "=", "None", ",", "\n", "machine_row_short_titles", "=", "None", ",", "\n", "machine_row_x_labels", "=", "None", ",", "machine_row_y_labels", "=", "None", ",", "ids_row_dists", "=", "None", ",", "\n", "ids_row_xks", "=", "None", ",", "ids_row_a_ids", "=", "None", ",", "ids_row_b_ids", "=", "None", ",", "\n", "ids_row_x_labels", "=", "None", ",", "ids_row_y_labels", "=", "None", ",", "ms", "=", "2.5", ",", "\n", "title_fontsize", "=", "8", ",", "lw", "=", "0.5", ",", "wspace", "=", "0.14", ",", "hspace", "=", "0.35", ",", "top", "=", "0.9", ",", "\n", "labelsize", "=", "7.5", ",", "ids_row_subtitles", "=", "None", ",", "machine_row_labels", "=", "None", ",", "\n", "total_row_a_ids_orig", "=", "None", "\n", ")", ":", "\n", "    ", "cm", "=", "plt", ".", "cm", ".", "get_cmap", "(", "'RdYlBu_r'", ")", "\n", "colors", "=", "plt", ".", "cm", ".", "GnBu", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "colors", "=", "plt", ".", "cm", ".", "viridis", "(", "np", ".", "linspace", "(", "0.3", ",", "1", ",", "num_colors", ")", ")", "[", "-", "num_colors", ":", "]", "\n", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "plt", ".", "rcParams", "[", "'axes.titlepad'", "]", "=", "0.02", "\n", "# plt.rcParams['xtick.major.pad'] = 0.5", "\n", "plt", ".", "rcParams", "[", "'ytick.major.pad'", "]", "=", "0.05", "\n", "#plt.rcParams['axes.labelpad'] = 0.8", "\n", "plt", ".", "rcParams", "[", "'axes.linewidth'", "]", "=", "0.1", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "2", ",", "ncols", "=", "ncols", ",", "figsize", "=", "figsize", ")", "\n", "\n", "print", "(", "\"total row a ids orig:{}\"", ".", "format", "(", "total_row_a_ids_orig", ")", ")", "\n", "print", "(", "total_row_a_ids_orig", ")", "\n", "# print(\"len row orig:{}\".format(len(total_row_a_ids_orig[0][0])))", "\n", "# print(\"len row a:{}\".format(len(ids_row_a_ids[0])))", "\n", "ms1", "=", "3", "\n", "ms2", "=", "2.25", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "1", "]", "[", "i", "]", "==", "85", ":", "\n", "            ", "color", "=", "colors", "[", "0", "]", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms1", ",", "\n", "mec", "=", "color", ",", "color", "=", "color", ",", "label", "=", "\"\"", ",", "alpha", "=", "1", ",", "marker", "=", "\"s\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "vlines", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "color", ",", "\n", "linestyles", "=", "'solid'", ",", "\n", "lw", "=", "lw", ",", "alpha", "=", "1", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "1", "]", "[", "i", "]", "!=", "85", ":", "\n", "            ", "color", "=", "\"#f9a65a\"", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms2", ",", "\n", "mec", "=", "color", ",", "color", "=", "color", ",", "label", "=", "\"\"", ",", "alpha", "=", "1", ",", "marker", "=", "\"o\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "vlines", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "color", ",", "\n", "linestyles", "=", "'dashed'", ",", "\n", "lw", "=", "lw", ",", "alpha", "=", "1", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "2", "]", "[", "i", "]", "==", "85", ":", "\n", "            ", "color", "=", "colors", "[", "0", "]", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms1", ",", "\n", "mec", "=", "color", ",", "color", "=", "color", ",", "\n", "label", "=", "\"\"", ",", "marker", "=", "\"s\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "vlines", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "colors", "=", "color", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "ids_row_dists", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "2", "]", "[", "i", "]", "!=", "85", ":", "\n", "            ", "color", "=", "\"#f9a65a\"", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "'ro'", ",", "ms", "=", "ms2", ",", "\n", "mec", "=", "color", ",", "color", "=", "color", ",", "label", "=", "\"\"", ",", "marker", "=", "\"o\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "vlines", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ",", "0", ",", "ids_row_dists", "[", "2", "]", "[", "i", "]", ".", "pmf", "(", "ids_row_xks", "[", "2", "]", "[", "i", "]", ")", ",", "colors", "=", "color", ",", "\n", "linestyles", "=", "'-'", ",", "lw", "=", "lw", ")", "\n", "\n", "\n", "# for i in range(len(ids_row_dists[2])):", "\n", "#     ax[1][0].plot(ids_row_xks[2][i], ids_row_dists[2][i].pmf(ids_row_xks[2][i]), 'ro', ms=ms,", "\n", "#                   mec=colors[i], color=colors[i],", "\n", "#                   label=\"\")", "\n", "#     ax[1][0].vlines(ids_row_xks[2][i], 0, ids_row_dists[2][i].pmf(ids_row_xks[2][i]), colors=colors[i],", "\n", "#                     linestyles='-', lw=lw)", "\n", "#", "\n", "# for i in range(len(ids_row_dists[3])):", "\n", "#     ax[1][1].plot(ids_row_xks[3][i], ids_row_dists[3][i].pmf(ids_row_xks[3][i]), 'ro', ms=ms,", "\n", "#                   mec=colors[i], color=colors[i], label=\"\")", "\n", "#     ax[1][1].vlines(ids_row_xks[3][i], 0, ids_row_dists[3][i].pmf(ids_row_xks[3][i]), colors=colors[i],", "\n", "#                     linestyles='-', lw=lw)", "\n", "\n", "# ax[0][0].grid('on')", "\n", "# #ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "# ax[0][0].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "# xlab = ax[0][0].xaxis.get_label()", "\n", "# ylab = ax[0][0].yaxis.get_label()", "\n", "# xlab.set_size(labelsize)", "\n", "# ylab.set_size(fontsize)", "\n", "# ax[0][0].tick_params(axis='both', which='major', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# ax[0][0].tick_params(axis='both', which='minor', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# ax[0][0].set_ylim(0, 1.1)", "\n", "# ax[0][0].set_title(\"\\# New IDS Alerts\", fontsize=fontsize)", "\n", "\n", "", "", "ax", "[", "0", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "#ax[0][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "# ax[0][0].set_yticks([])", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_title", "(", "r\"\\# Severe IDS Alerts $\\Delta x$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "#ax[0][0].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "r\"$\\hat{f}_X(\\Delta x|i_t,t)$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_title", "(", "r\"\\# Warning IDS Alerts $\\Delta y$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylabel", "(", "r\"$\\hat{f}_Y(\\Delta y|i_t,t)$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "\n", "# ax[1][1].grid('on')", "\n", "# # ax[0][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "# xlab = ax[1][1].xaxis.get_label()", "\n", "# ylab = ax[1][1].yaxis.get_label()", "\n", "# ax[1][1].set_yticks([])", "\n", "# xlab.set_size(labelsize)", "\n", "# ylab.set_size(fontsize)", "\n", "# ax[1][1].tick_params(axis='both', which='major', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# ax[1][1].tick_params(axis='both', which='minor', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# ax[1][1].set_ylim(0, 1.1)", "\n", "# ax[1][1].set_title(\"\\# New IDS Priority\", fontsize=fontsize)", "\n", "\n", "label_set", "=", "False", "\n", "for", "i", "in", "range", "(", "len", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "1", "]", "[", "i", "]", "==", "85", ":", "\n", "            ", "color", "=", "colors", "[", "0", "]", "\n", "label", "=", "\"\"", "\n", "if", "not", "label_set", ":", "\n", "                ", "label", "=", "\"normal operation\"", "\n", "label_set", "=", "True", "\n", "", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ",", "machine_row_dists", "[", "0", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "\n", "ms", "=", "ms1", ",", "mec", "=", "color", ",", "color", "=", "color", ",", "label", "=", "label", ",", "marker", "=", "\"s\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "vlines", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ",", "0", ",", "machine_row_dists", "[", "0", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "color", ",", "\n", "linestyles", "=", "'solid'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "", "label_set", "=", "False", "\n", "for", "i", "in", "range", "(", "len", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "1", "]", "[", "i", "]", "!=", "85", ":", "\n", "            ", "color", "=", "\"#f9a65a\"", "\n", "label", "=", "\"\"", "\n", "if", "not", "label_set", ":", "\n", "                ", "label", "=", "\"intrusion in progress\"", "\n", "label_set", "=", "True", "\n", "", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ",", "machine_row_dists", "[", "0", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "\n", "ms", "=", "ms2", ",", "mec", "=", "color", ",", "color", "=", "color", ",", "label", "=", "label", ",", "marker", "=", "\"o\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "vlines", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ",", "0", ",", "machine_row_dists", "[", "0", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "0", "]", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "colors", "=", "color", ",", "\n", "linestyles", "=", "'dashed'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "1", "]", "[", "i", "]", "==", "85", ":", "\n", "            ", "color", "=", "colors", "[", "0", "]", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ",", "machine_row_dists", "[", "1", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "\n", "ms", "=", "ms1", ",", "mec", "=", "color", ",", "\n", "color", "=", "color", ",", "label", "=", "\"\"", ",", "marker", "=", "\"s\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "vlines", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ",", "0", ",", "machine_row_dists", "[", "1", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ")", ",", "colors", "=", "color", ",", "\n", "linestyles", "=", "'solid'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", ")", ")", ":", "\n", "        ", "if", "total_row_a_ids_orig", "[", "1", "]", "[", "i", "]", "!=", "85", ":", "\n", "            ", "color", "=", "\"#f9a65a\"", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ",", "machine_row_dists", "[", "1", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ")", ",", "'ro'", ",", "\n", "ms", "=", "ms2", ",", "mec", "=", "color", ",", "\n", "color", "=", "color", ",", "label", "=", "\"\"", ",", "marker", "=", "\"o\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "vlines", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ",", "0", ",", "machine_row_dists", "[", "1", "]", "[", "1", "]", "[", "i", "]", ".", "pmf", "(", "machine_row_xks", "[", "1", "]", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "colors", "=", "color", ",", "\n", "linestyles", "=", "'dashed'", ",", "lw", "=", "lw", ")", "\n", "\n", "", "", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "#ax[1][0].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "r\"$\\hat{f}_Z(\\Delta z|i_t,t)$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "r\"\\# Failed Logins $\\Delta z$ 172.18.9.2\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "#ax[1][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylabel", "(", "r\"$\\hat{f}_Z(\\Delta z|i_t,t)$\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "1.2", ",", "width", "=", "0.2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylim", "(", "0", ",", "1.1", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "r\"\\# Failed Logins $\\Delta z$ 172.18.9.3\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "# plt.subplot(nrows, ncols, (5, 6))", "\n", "#", "\n", "# colors = plt.cm.viridis(np.linspace(0.3, 1, 4))[-4:]", "\n", "#", "\n", "# histo, bin_edges = np.histogram(costs_factors[3], 30, (0, 2300))", "\n", "# bin_middles = 0.5 * (bin_edges[1:] + bin_edges[:-1])", "\n", "# print(np.array(costs_factors[3]) * 0.01)", "\n", "# plt.hist(costs_factors[3], bins=30, alpha=1, range=(0, 2300),", "\n", "#               label=\"test\", stacked=False, log=True, color=colors[0], density=True, edgecolor='black', ls=\"-\")", "\n", "#", "\n", "# normalisation = 30 / (len(costs_factors[3]) * (2300 - 0))", "\n", "# y_err = np.sqrt(histo) * normalisation", "\n", "# y = histo * normalisation", "\n", "# y_err[0] = y_err[0] + 0.0025", "\n", "# y_err[1] = y_err[1] + 0.0001", "\n", "# plt.errorbar(bin_middles, y, fmt='.k', color=\"black\", yerr=y_err)", "\n", "#", "\n", "# plt.grid('on')", "\n", "#plt.set_yticks([])", "\n", "# ax[1][1].set_ylabel(r\"$\\mathbb{P}[ \\cdot | (s_i, a_i)]$\", fontsize=labelsize)", "\n", "# xlab = plt.xaxis.get_label()", "\n", "# ylab = plt.yaxis.get_label()", "\n", "# xlab.set_size(labelsize)", "\n", "# ylab.set_size(fontsize)", "\n", "# plt.ylabel(r\"Normalized frequency\", fontsize=labelsize)", "\n", "# plt.tick_params(axis='both', which='major', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# plt.tick_params(axis='both', which='minor', labelsize=labelsize, length=1.2, width=0.2)", "\n", "# #plt.ylim(0, 1.1)", "\n", "# plt.xlim(0, 2300)", "\n", "# plt.title(\"Wallclock time (s) of executing actions\", fontsize=fontsize)", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "\n", "handles", ",", "labels", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "get_legend_handles_labels", "(", ")", "\n", "print", "(", "handles", ")", "\n", "print", "(", "labels", ")", "\n", "fig", ".", "legend", "(", "handles", ",", "labels", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.52", ",", "0.11", ")", ",", "\n", "ncol", "=", "4", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "top", "=", "top", ",", "bottom", "=", "0.142", ")", "\n", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plotting_util_defender.plot_flags_int_r_steps_costs_alerts": [[7, 203], ["matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.subplots", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].plot", "ax[].plot", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].plot", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].fill_between", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].plot", "ax[].plot", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].plot", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].get_legend_handles_labels", "fig.legend", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "numpy.array", "len", "numpy.array", "len", "numpy.array", "len", "numpy.array", "numpy.array", "list", "numpy.array", "len", "numpy.array", "len", "len", "numpy.array", "numpy.array", "numpy.array", "len", "numpy.array", "len", "len", "numpy.array", "numpy.array", "len", "list", "numpy.array", "len", "numpy.array", "len", "numpy.array", "numpy.array", "numpy.array", "len", "numpy.array", "len", "len", "list", "list", "list", "range", "list", "list", "list", "list", "list", "list", "list", "list", "range", "list", "list", "list", "list", "list", "list", "range", "range", "range", "len", "range", "range", "range", "range", "range", "range", "range", "range", "len", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["def", "plot_flags_int_r_steps_costs_alerts", "(", "\n", "avg_train_rewards_data_v1", ",", "avg_train_rewards_means_v1", ",", "\n", "avg_train_rewards_stds_v1", ",", "\n", "avg_train_steps_data_v1", ",", "avg_train_steps_means_v1", ",", "avg_train_steps_stds_v1", ",", "\n", "avg_train_caught_frac_data_v1", ",", "avg_train_caught_frac_means_v1", ",", "\n", "avg_train_caught_frac_stds_v1", ",", "\n", "avg_train_early_stopping_frac_data_v1", ",", "avg_train_early_stopping_means_v1", ",", "\n", "avg_train_early_stopping_stds_v1", ",", "avg_train_intrusion_frac_data_v1", ",", "\n", "avg_train_intrusion_means_v1", ",", "\n", "avg_train_intrusion_stds_v1", ",", "\n", "fontsize", ":", "int", "=", "6.5", ",", "figsize", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "3.75", ",", "3.4", ")", ",", "\n", "title_fontsize", "=", "8", ",", "lw", "=", "0.5", ",", "wspace", "=", "0.02", ",", "hspace", "=", "0.3", ",", "top", "=", "0.9", ",", "\n", "labelsize", "=", "6", ",", "markevery", "=", "10", ",", "optimal_reward", "=", "95", ",", "sample_step", "=", "1", ",", "\n", "eval_only", "=", "False", ",", "plot_opt", "=", "False", ",", "iterations_per_step", ":", "int", "=", "1", ",", "optimal_int", "=", "1.0", ",", "\n", "optimal_flag", "=", "1.0", ",", "file_name", "=", "\"test\"", ",", "markersize", "=", "5", ",", "bottom", "=", "0.02", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts,amsmath}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "plt", ".", "rcParams", "[", "'axes.titlepad'", "]", "=", "0.02", "\n", "# plt.rcParams['xtick.major.pad'] = 0.5", "\n", "plt", ".", "rcParams", "[", "'ytick.major.pad'", "]", "=", "0.05", "\n", "plt", ".", "rcParams", "[", "'axes.labelpad'", "]", "=", "0.8", "\n", "plt", ".", "rcParams", "[", "'axes.linewidth'", "]", "=", "0.1", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "4", ",", "figsize", "=", "figsize", ")", "\n", "\n", "\n", "# Plot flags", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$\\pi_{\\theta}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_rewards_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_rewards_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "*", "iterations_per_step", ",", "\n", "[", "165", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ",", "label", "=", "r\"Optimal $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "113", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_0$\"", ",", "\n", "color", "=", "\"#599ad3\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"d\"", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "71", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_5$\"", ",", "\n", "color", "=", "\"#f9a65a\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"h\"", ")", "\n", "\n", "# ax[0][0].plot(np.array(list(range(len(avg_train_flags_means_v1)))) * iterations_per_step,", "\n", "#         [optimal_flag*100] * len(avg_train_flags_means_v1), label=r\"upper bound\",", "\n", "#         color=\"black\", linestyle=\"dashed\", markersize=markersize, dashes=(4, 2), lw=lw)", "\n", "\n", "ax", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "#ax[0][0].set_ylabel(r\"\\% Flags captured\", fontsize=labelsize)", "\n", "ax", "[", "0", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "# ax[0].set_ylim(0, 50)", "\n", "ax", "[", "0", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "0", "]", ".", "set_title", "(", "r\"Reward per episode\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "\n", "# % intrusions", "\n", "\n", "# ax[1].plot(", "\n", "#     np.array(list(range(len(avg_train_caught_frac_means_v1[::sample_step])))) * sample_step * iterations_per_step,", "\n", "#     avg_train_caught_frac_means_v1[::sample_step], label=r\"$\\mathbb{P}[detected]$ $\\pi_{\\theta}$ emulation\",", "\n", "#     marker=\"p\", ls='-', color=\"#599ad3\",", "\n", "#     markevery=markevery, markersize=markersize, lw=lw)", "\n", "# ax[1].fill_between(", "\n", "#     np.array(list(range(len(avg_train_caught_frac_means_v1[::sample_step])))) * sample_step * iterations_per_step,", "\n", "#     avg_train_caught_frac_means_v1[::sample_step] - avg_train_rewards_stds_v1[::sample_step],", "\n", "#     avg_train_caught_frac_means_v1[::sample_step] + avg_train_rewards_stds_v1[::sample_step],", "\n", "#     alpha=0.35, color=\"#599ad3\")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$\\mathbb{P}[detected]$ $\\pi_{\\theta}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_steps_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_steps_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "8", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_0$\"", ",", "\n", "color", "=", "\"#599ad3\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"d\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "6", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_5$\"", ",", "\n", "color", "=", "\"#f9a65a\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"h\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "#ax[0][1].set_ylabel(r\"$\\mathbb{P}[\\text{detected}]$\", fontsize=labelsize)", "\n", "ax", "[", "1", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "1", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "1", "]", ".", "set_title", "(", "r\"Episode length (steps)\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Learned $\\pi_{\\theta}$\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_caught_frac_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_caught_frac_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "#ax[0][2].set_ylabel(r\"Reward\", fontsize=labelsize)", "\n", "ax", "[", "2", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "2", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "2", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "# ax[2].set_ylim(-100, 110)", "\n", "# ax[2].set_ylim(0, 1)", "\n", "ax", "[", "2", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "2", "]", ".", "set_title", "(", "r\"$\\mathbb{P}[\\text{attacker detected}]$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "*", "iterations_per_step", ",", "\n", "[", "0.84", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ",", "label", "=", "r\"Optimal $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "0.6", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_0$\"", ",", "\n", "color", "=", "\"#599ad3\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"d\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "0.01", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_5$\"", ",", "\n", "color", "=", "\"#f9a65a\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"h\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Defender $\\pi_{\\theta^D}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_early_stopping_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_early_stopping_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "0.4", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_0$\"", ",", "\n", "color", "=", "\"#599ad3\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"d\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "[", ":", ":", "sample_step", "]", "*", "iterations_per_step", ",", "\n", "(", "[", "0.99", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ")", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$TTC_5$\"", ",", "\n", "color", "=", "\"#f9a65a\"", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ",", "markevery", "=", "markevery", ",", "marker", "=", "\"h\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][2].set_ylabel(r\"Reward\", fontsize=labelsize)", "\n", "ax", "[", "3", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "3", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "3", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "3", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "# ax[2].set_ylim(-100, 110)", "\n", "# ax[3].set_ylim(0, 1)", "\n", "ax", "[", "3", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "3", "]", ".", "set_title", "(", "r\"$\\mathbb{P}[\\text{early stopping}]$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "*", "iterations_per_step", ",", "\n", "[", "0.16", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ",", "label", "=", "r\"Optimal $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "\n", "handles", ",", "labels", "=", "ax", "[", "2", "]", ".", "get_legend_handles_labels", "(", ")", "\n", "fig", ".", "legend", "(", "handles", ",", "labels", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.52", ",", "0.165", ")", ",", "\n", "ncol", "=", "5", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "#fig.subplots_adjust(wspace=wspace, hspace=hspace, top=top, bottom=bottom)", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "bottom", "=", "bottom", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plotting_util_defender.plot_flags_int_r_steps_costs_alerts_two_versions": [[647, 1084], ["matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.subplots", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "print", "print", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_ylim", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_ylim", "ax[].set_xlim", "ax[].set_title", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].grid", "ax[].set_xlabel", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].tick_params", "ax[].tick_params", "ax[].set_ylim", "ax[].set_xlim", "ax[].set_title", "ax[].get_legend_handles_labels", "fig.legend", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "len", "numpy.array", "len", "numpy.array", "len", "numpy.array", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "list", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "list", "len", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "range", "list", "list", "list", "list", "list", "list", "list", "list", "range", "list", "list", "list", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "range", "range", "range", "range", "range", "range", "range", "range", "len", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.common.running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.plots.plot_dynamics_model.plot"], ["", "def", "plot_flags_int_r_steps_costs_alerts_two_versions", "(", "\n", "avg_train_rewards_data_v1", ",", "avg_train_rewards_means_v1", ",", "\n", "avg_train_rewards_stds_v1", ",", "\n", "avg_train_steps_data_v1", ",", "avg_train_steps_means_v1", ",", "avg_train_steps_stds_v1", ",", "\n", "avg_train_caught_frac_data_v1", ",", "avg_train_caught_frac_means_v1", ",", "\n", "avg_train_caught_frac_stds_v1", ",", "\n", "avg_train_early_stopping_frac_data_v1", ",", "avg_train_early_stopping_means_v1", ",", "\n", "avg_train_early_stopping_stds_v1", ",", "avg_train_intrusion_frac_data_v1", ",", "\n", "avg_train_intrusion_means_v1", ",", "\n", "avg_train_intrusion_stds_v1", ",", "\n", "\n", "avg_train_rewards_data_v2", ",", "avg_train_rewards_means_v2", ",", "\n", "avg_train_rewards_stds_v2", ",", "\n", "avg_train_steps_data_v2", ",", "avg_train_steps_means_v2", ",", "avg_train_steps_stds_v2", ",", "\n", "avg_train_caught_frac_data_v2", ",", "avg_train_caught_frac_means_v2", ",", "\n", "avg_train_caught_frac_stds_v2", ",", "\n", "avg_train_early_stopping_frac_data_v2", ",", "avg_train_early_stopping_means_v2", ",", "\n", "avg_train_early_stopping_stds_v2", ",", "avg_train_intrusion_frac_data_v2", ",", "\n", "avg_train_intrusion_means_v2", ",", "\n", "avg_train_intrusion_stds_v2", ",", "\n", "optimal_rewards_v3_data", ",", "optimal_rewards_v3_means", ",", "optimal_rewards_v3_stds", ",", "\n", "optimal_steps_v3_data", ",", "optimal_steps_v3_means", ",", "optimal_steps_v3_stds", ",", "\n", "optimal_steps_v2_data", ",", "optimal_steps_v2_means", ",", "optimal_steps_v2_stds", ",", "\n", "optimal_rewards_v2_data", ",", "optimal_rewards_v2_means", ",", "optimal_rewards_v2_stds", ",", "\n", "\n", "t_baseline_rewards_data", ",", "t_baseline_rewards_means", ",", "t_baseline_rewards_stds", ",", "\n", "t_baseline_early_stopping_data", ",", "t_baseline_early_stopping_means", ",", "t_baseline_early_stopping_stds", ",", "\n", "t_baseline_caught_data", ",", "t_baseline_caught_means", ",", "t_baseline_caught_stds", ",", "\n", "\n", "a_baseline_rewards_data", ",", "a_baseline_rewards_means", ",", "a_baseline_rewards_stds", ",", "\n", "a_baseline_early_stopping_data", ",", "a_baseline_early_stopping_means", ",", "a_baseline_early_stopping_stds", ",", "\n", "a_baseline_caught_data", ",", "a_baseline_caught_means", ",", "a_baseline_caught_stds", ",", "\n", "\n", "a_baseline_steps_data", ",", "a_baseline_steps_means", ",", "a_baseline_steps_stds", ",", "\n", "\n", "t_baseline_i_steps_data", ",", "t_baseline_i_steps_means", ",", "t_baseline_i_steps_stds", ",", "\n", "a_baseline_i_steps_data", ",", "a_baseline_i_steps_means", ",", "a_baseline_i_steps_stds", ",", "\n", "\n", "avg_train_i_steps_data_v3", ",", "avg_train_i_steps_means_v3", ",", "avg_train_i_steps_stds_v3", ",", "\n", "avg_train_i_steps_data_v2", ",", "avg_train_i_steps_means_v2", ",", "avg_train_i_steps_stds_v2", ",", "\n", "\n", "fontsize", ":", "int", "=", "6.5", ",", "figsize", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "3.75", ",", "3.4", ")", ",", "\n", "title_fontsize", "=", "8", ",", "lw", "=", "0.5", ",", "wspace", "=", "0.02", ",", "hspace", "=", "0.3", ",", "top", "=", "0.9", ",", "\n", "labelsize", "=", "6", ",", "markevery", "=", "10", ",", "optimal_reward", "=", "95", ",", "sample_step", "=", "1", ",", "\n", "eval_only", "=", "False", ",", "plot_opt", "=", "False", ",", "iterations_per_step", ":", "int", "=", "1", ",", "optimal_int", "=", "1.0", ",", "\n", "optimal_flag", "=", "1.0", ",", "file_name", "=", "\"test\"", ",", "markersize", "=", "5", ",", "bottom", "=", "0.02", ")", ":", "\n", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts,amsmath}'", ")", "\n", "plt", ".", "rcParams", "[", "'font.family'", "]", "=", "[", "'serif'", "]", "\n", "plt", ".", "rcParams", "[", "'axes.titlepad'", "]", "=", "0.02", "\n", "# plt.rcParams['xtick.major.pad'] = 0.5", "\n", "plt", ".", "rcParams", "[", "'ytick.major.pad'", "]", "=", "0.05", "\n", "plt", ".", "rcParams", "[", "'axes.labelpad'", "]", "=", "0.8", "\n", "plt", ".", "rcParams", "[", "'axes.linewidth'", "]", "=", "0.1", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "fontsize", "}", ")", "\n", "\n", "# plt.rcParams['font.serif'] = ['Times New Roman']", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "5", ",", "figsize", "=", "figsize", ")", "\n", "\n", "\n", "# Plot flags", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_rewards_means_v2", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$\\pi_{\\theta}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_rewards_means_v2", "[", ":", ":", "sample_step", "]", "-", "avg_train_rewards_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_rewards_means_v2", "[", ":", ":", "sample_step", "]", "+", "avg_train_rewards_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$\\pi_{\\theta}$ simulation\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_rewards_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_rewards_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_rewards_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_rewards_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#f9a65a\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_rewards_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_rewards_means", "[", ":", ":", "sample_step", "]", "-", "t_baseline_rewards_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "t_baseline_rewards_means", "[", ":", ":", "sample_step", "]", "+", "t_baseline_rewards_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#f9a65a\"", ",", "lw", "=", "lw", ")", "\n", "\n", "print", "(", "\"t:{}\"", ".", "format", "(", "t_baseline_rewards_means", ")", ")", "\n", "print", "(", "\"a:{}\"", ".", "format", "(", "a_baseline_rewards_means", ")", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_rewards_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_rewards_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$a=1$ baseline\"", ",", "\n", "marker", "=", "\"h\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#E7298A\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_rewards_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_rewards_means", "[", ":", ":", "sample_step", "]", "-", "a_baseline_rewards_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "a_baseline_rewards_means", "[", ":", ":", "sample_step", "]", "+", "a_baseline_rewards_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#E7298A\"", ",", "lw", "=", "lw", ")", "\n", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "optimal_rewards_v2_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Optimal $\\pi^{*}$ vs \\textsc{NoisyAttacker}\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "optimal_rewards_v2_means", "[", ":", ":", "sample_step", "]", "-", "optimal_rewards_v2_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "optimal_rewards_v2_means", "[", ":", ":", "sample_step", "]", "+", "optimal_rewards_v2_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"black\"", ")", "\n", "\n", "\n", "# ax[0].plot(np.array(list(range(len(avg_train_rewards_means_v1))))[::sample_step] * iterations_per_step,", "\n", "#            ([113] * len(avg_train_rewards_means_v1))[::sample_step], label=r\"$TTC_0$\",", "\n", "#            color=\"#599ad3\", markersize=markersize, lw=lw, markevery=markevery, marker=\"d\")", "\n", "#", "\n", "# ax[0].plot(np.array(list(range(len(avg_train_rewards_means_v1))))[::sample_step] * iterations_per_step,", "\n", "#            ([71] * len(avg_train_rewards_means_v1))[::sample_step], label=r\"$TTC_5$\",", "\n", "#            color=\"#f9a65a\", markersize=markersize, lw=lw, markevery=markevery, marker=\"h\")", "\n", "\n", "# ax[0][0].plot(np.array(list(range(len(avg_train_flags_means_v1)))) * iterations_per_step,", "\n", "#         [optimal_flag*100] * len(avg_train_flags_means_v1), label=r\"upper bound\",", "\n", "#         color=\"black\", linestyle=\"dashed\", markersize=markersize, dashes=(4, 2), lw=lw)", "\n", "\n", "ax", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "#ax[0][0].set_ylabel(r\"\\% Flags captured\", fontsize=labelsize)", "\n", "ax", "[", "0", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "0", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "0", "]", ".", "set_ylim", "(", "-", "130", ",", "200", ")", "\n", "ax", "[", "0", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "0", "]", ".", "set_title", "(", "r\"Reward per episode\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "\n", "# % intrusions", "\n", "\n", "# ax[1].plot(", "\n", "#     np.array(list(range(len(avg_train_caught_frac_means_v1[::sample_step])))) * sample_step * iterations_per_step,", "\n", "#     avg_train_caught_frac_means_v1[::sample_step], label=r\"$\\mathbb{P}[detected]$ $\\pi_{\\theta}$ emulation\",", "\n", "#     marker=\"p\", ls='-', color=\"#599ad3\",", "\n", "#     markevery=markevery, markersize=markersize, lw=lw)", "\n", "# ax[1].fill_between(", "\n", "#     np.array(list(range(len(avg_train_caught_frac_means_v1[::sample_step])))) * sample_step * iterations_per_step,", "\n", "#     avg_train_caught_frac_means_v1[::sample_step] - avg_train_rewards_stds_v1[::sample_step],", "\n", "#     avg_train_caught_frac_means_v1[::sample_step] + avg_train_rewards_stds_v1[::sample_step],", "\n", "#     alpha=0.35, color=\"#599ad3\")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_steps_means_v2", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$\\mathbb{P}[detected]$ $\\pi_{\\theta}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_steps_means_v2", "[", ":", ":", "sample_step", "]", "-", "avg_train_steps_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_steps_means_v2", "[", ":", ":", "sample_step", "]", "+", "avg_train_steps_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$\\mathbb{P}[detected]$ $\\pi_{\\theta}$ simulation\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_steps_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_steps_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "[", "6", "]", "*", "len", "(", "optimal_steps_v2_means", "[", ":", ":", "sample_step", "]", ")", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#f9a65a\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_steps_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_steps_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$a=1$ baseline\"", ",", "\n", "marker", "=", "\"h\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#E7298A\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_steps_means", "[", ":", ":", "sample_step", "]", "-", "a_baseline_steps_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "a_baseline_steps_means", "[", ":", ":", "sample_step", "]", "+", "a_baseline_steps_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#E7298A\"", ")", "\n", "\n", "\n", "# ax[1].fill_between(", "\n", "#     np.array(list(range(len(t_baseline_rewards_means[::sample_step])))) * sample_step * iterations_per_step,", "\n", "#     t_baseline_rewards_means[::sample_step] - t_baseline_rewards_stds[::sample_step],", "\n", "#     t_baseline_rewards_means[::sample_step] + t_baseline_rewards_stds[::sample_step],", "\n", "#     alpha=0.35, color=\"#f9a65a\", lw=lw)", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "optimal_steps_v2_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Optimal $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "0.5", ",", "0.5", ")", ",", "lw", "=", "lw", ",", "markevery", "=", "100", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_steps_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "optimal_steps_v2_means", "[", ":", ":", "sample_step", "]", "-", "optimal_steps_v2_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "optimal_steps_v2_means", "[", ":", ":", "sample_step", "]", "+", "optimal_steps_v2_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"black\"", ")", "\n", "\n", "# ax[1].plot(np.array(list(range(len(avg_train_rewards_means_v1))))[::sample_step] * iterations_per_step,", "\n", "#            ([8] * len(avg_train_rewards_means_v1))[::sample_step], label=r\"$TTC_0$\",", "\n", "#            color=\"#599ad3\", markersize=markersize, lw=lw, markevery=markevery, marker=\"d\")", "\n", "#", "\n", "# ax[1].plot(np.array(list(range(len(avg_train_rewards_means_v1))))[::sample_step] * iterations_per_step,", "\n", "#            ([6] * len(avg_train_rewards_means_v1))[::sample_step], label=r\"$TTC_5$\",", "\n", "#            color=\"#f9a65a\", markersize=markersize, lw=lw, markevery=markevery, marker=\"h\")", "\n", "\n", "ax", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][0].set_xlabel(\"\", fontsize=labelsize)", "\n", "#ax[0][1].set_ylabel(r\"$\\mathbb{P}[\\text{detected}]$\", fontsize=labelsize)", "\n", "ax", "[", "1", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "1", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "1", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "1", "]", ".", "set_title", "(", "r\"Episode length (steps)\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_caught_frac_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_caught_frac_means_v2", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Learned $\\pi_{\\theta}$ vs \\textsc{NoisyAttacker}\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_caught_frac_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_caught_frac_means_v2", "[", ":", ":", "sample_step", "]", "-", "avg_train_caught_frac_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_caught_frac_means_v2", "[", ":", ":", "sample_step", "]", "+", "avg_train_caught_frac_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Learned $\\pi_{\\theta}$ vs \\textsc{StealthyAttacker}\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_caught_frac_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_caught_frac_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_caught_frac_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_caught_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_caught_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#f9a65a\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_caught_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_caught_means", "[", ":", ":", "sample_step", "]", "-", "t_baseline_caught_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "t_baseline_caught_means", "[", ":", ":", "sample_step", "]", "+", "t_baseline_caught_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#f9a65a\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_caught_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_caught_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$(x+y)\\geq 1$ baseline\"", ",", "\n", "marker", "=", "\"h\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#E7298A\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_caught_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_caught_means", "[", ":", ":", "sample_step", "]", "-", "a_baseline_caught_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "a_baseline_caught_means", "[", ":", ":", "sample_step", "]", "+", "a_baseline_caught_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#E7298A\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "#ax[0][2].set_ylabel(r\"Reward\", fontsize=labelsize)", "\n", "ax", "[", "2", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "2", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "2", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "# ax[2].set_ylim(-100, 110)", "\n", "# ax[2].set_ylim(0, 1)", "\n", "ax", "[", "2", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "2", "]", ".", "set_title", "(", "r\"$\\mathbb{P}[\\text{intrusion interrupted}]$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "*", "iterations_per_step", ",", "\n", "[", "1.00", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ",", "label", "=", "r\"Upper bound $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "#label=r\"Optimal $\\pi^{*}$\"", "\n", "\n", "# ax[2].plot(np.array(list(range(len(avg_train_rewards_means_v1))))[::sample_step] * iterations_per_step,", "\n", "#            ([0.6] * len(avg_train_rewards_means_v1))[::sample_step], label=r\"$TTC_0$\",", "\n", "#            color=\"#599ad3\", markersize=markersize, lw=lw, markevery=markevery, marker=\"d\")", "\n", "#", "\n", "# ax[2].plot(np.array(list(range(len(avg_train_rewards_means_v1))))[::sample_step] * iterations_per_step,", "\n", "#            ([0.01] * len(avg_train_rewards_means_v1))[::sample_step], label=r\"$TTC_5$\",", "\n", "#            color=\"#f9a65a\", markersize=markersize, lw=lw, markevery=markevery, marker=\"h\")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_early_stopping_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_early_stopping_means_v2", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Defender $\\pi_{\\theta^D}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_early_stopping_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_early_stopping_means_v2", "[", ":", ":", "sample_step", "]", "-", "avg_train_early_stopping_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_early_stopping_means_v2", "[", ":", ":", "sample_step", "]", "+", "avg_train_early_stopping_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Defender $\\pi_{\\theta^D}$ simulation\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", "-", "avg_train_early_stopping_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_early_stopping_means_v1", "[", ":", ":", "sample_step", "]", "+", "avg_train_early_stopping_stds_v1", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#f9a65a\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", "-", "t_baseline_early_stopping_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "t_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", "+", "t_baseline_early_stopping_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#f9a65a\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"h\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#E7298A\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", "-", "a_baseline_early_stopping_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "a_baseline_early_stopping_means", "[", ":", ":", "sample_step", "]", "+", "a_baseline_early_stopping_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#E7298A\"", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "3", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "*", "iterations_per_step", ",", "\n", "[", "0.0", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ",", "label", "=", "r\"Optimal $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "3", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][2].set_ylabel(r\"Reward\", fontsize=labelsize)", "\n", "ax", "[", "3", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "3", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "3", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "3", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "# ax[2].set_ylim(-100, 110)", "\n", "ax", "[", "3", "]", ".", "set_ylim", "(", "0", ",", "1", ")", "\n", "ax", "[", "3", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "3", "]", ".", "set_title", "(", "r\"$\\mathbb{P}[\\text{early stopping}]$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "ax", "[", "4", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_i_steps_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_i_steps_means_v2", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Defender $\\pi_{\\theta^D}$ simulation\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"r\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "4", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_i_steps_means_v2", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_i_steps_means_v2", "[", ":", ":", "sample_step", "]", "-", "avg_train_early_stopping_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_i_steps_means_v2", "[", ":", ":", "sample_step", "]", "+", "avg_train_i_steps_stds_v2", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"r\"", ")", "\n", "\n", "ax", "[", "4", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_i_steps_means_v3", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_i_steps_means_v3", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"Defender $\\pi_{\\theta^D}$ simulation\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "4", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "\n", "list", "(", "range", "(", "len", "(", "avg_train_i_steps_means_v3", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "avg_train_i_steps_means_v3", "[", ":", ":", "sample_step", "]", "-", "avg_train_i_steps_stds_v3", "[", ":", ":", "sample_step", "]", ",", "\n", "avg_train_i_steps_means_v3", "[", ":", ":", "sample_step", "]", "+", "avg_train_i_steps_stds_v3", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "4", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#f9a65a\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "4", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "t_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "t_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", "-", "t_baseline_i_steps_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "t_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", "+", "t_baseline_i_steps_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#f9a65a\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "4", "]", ".", "plot", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", ",", "label", "=", "r\"$t=6$ baseline\"", ",", "\n", "marker", "=", "\"h\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#E7298A\"", ",", "markevery", "=", "markevery", ",", "markersize", "=", "markersize", ",", "lw", "=", "lw", ")", "\n", "ax", "[", "4", "]", ".", "fill_between", "(", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", ")", ")", ")", ")", "*", "sample_step", "*", "iterations_per_step", ",", "\n", "a_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", "-", "a_baseline_i_steps_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "a_baseline_i_steps_means", "[", ":", ":", "sample_step", "]", "+", "a_baseline_i_steps_stds", "[", ":", ":", "sample_step", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#E7298A\"", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "4", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_train_rewards_means_v1", ")", ")", ")", ")", "*", "iterations_per_step", ",", "\n", "[", "1.0", "]", "*", "len", "(", "avg_train_rewards_means_v1", ")", ",", "label", "=", "r\"Optimal $\\pi^{*}$\"", ",", "\n", "color", "=", "\"black\"", ",", "linestyle", "=", "\"dashed\"", ",", "markersize", "=", "markersize", ",", "dashes", "=", "(", "4", ",", "2", ")", ",", "lw", "=", "lw", ")", "\n", "\n", "ax", "[", "4", "]", ".", "grid", "(", "'on'", ")", "\n", "# ax[0][2].set_ylabel(r\"Reward\", fontsize=labelsize)", "\n", "ax", "[", "4", "]", ".", "set_xlabel", "(", "r\"\\# policy updates\"", ",", "fontsize", "=", "labelsize", ")", "\n", "xlab", "=", "ax", "[", "4", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "labelsize", ")", "\n", "ylab", ".", "set_size", "(", "fontsize", ")", "\n", "ax", "[", "4", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "ax", "[", "4", "]", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "labelsize", ",", "length", "=", "2.2", ",", "width", "=", "0.6", ")", "\n", "# ax[2].set_ylim(-100, 110)", "\n", "ax", "[", "4", "]", ".", "set_ylim", "(", "1", ",", "4", ")", "\n", "ax", "[", "4", "]", ".", "set_xlim", "(", "0", ",", "len", "(", "avg_train_rewards_means_v1", "[", ":", ":", "sample_step", "]", ")", "*", "sample_step", "*", "iterations_per_step", ")", "\n", "ax", "[", "4", "]", ".", "set_title", "(", "r\"Uninterrupted intrusion $t$\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "\n", "handles", ",", "labels", "=", "ax", "[", "2", "]", ".", "get_legend_handles_labels", "(", ")", "\n", "fig", ".", "legend", "(", "handles", ",", "labels", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.505", ",", "0.165", ")", ",", "\n", "ncol", "=", "5", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "handletextpad", "=", "0.4", ",", "labelspacing", "=", "0.5", ",", "columnspacing", "=", "0.65", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "#fig.subplots_adjust(wspace=wspace, hspace=hspace, top=top, bottom=bottom)", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "bottom", "=", "bottom", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.run": [[16, 29], ["runner.Runner.train", "AssertionError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.train"], ["@", "staticmethod", "\n", "def", "run", "(", "config", ":", "ClientConfig", ")", "->", "Tuple", "[", "ExperimentResult", ",", "ExperimentResult", "]", ":", "\n", "        ", "\"\"\"\n        Runs an experiment with the given configuration\n\n        :param config: the client configuration\n        :return: the experiment results\n        \"\"\"", "\n", "if", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", "or", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", "or", "config", ".", "mode", "==", "RunnerMode", ".", "SELF_PLAY", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "train", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Runner mode not recognized: {}\"", ".", "format", "(", "config", ".", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.train": [[30, 56], ["runner.Runner.regular_env_creation", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent.train", "runner.Runner.regular_env_creation", "runner.Runner.regular_env_creation", "gym_optimal_intrusion_response.agents.policy_gradient.ppo_baseline.ppo_baseline_agent.PPOBaselineAgent", "AssertionError", "gym_optimal_intrusion_response.dao.agent.train_mode.TrainMode"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.regular_env_creation", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.train", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.regular_env_creation", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.regular_env_creation"], ["", "", "@", "staticmethod", "\n", "def", "train", "(", "config", ":", "ClientConfig", ")", "->", "Tuple", "[", "ExperimentResult", ",", "ExperimentResult", "]", ":", "\n", "        ", "\"\"\"\n        Starts a training process with the given configuration\n\n        :param config: the client configuration\n        :return: the training results\n        \"\"\"", "\n", "env", "=", "Runner", ".", "regular_env_creation", "(", "config", "=", "config", ")", "\n", "if", "config", ".", "agent_type", "==", "AgentType", ".", "PPO_BASELINE", ".", "value", ":", "\n", "            ", "if", "config", ".", "defender_agent_config", "is", "not", "None", ":", "\n", "                ", "config", ".", "defender_agent_config", ".", "random_seed", "=", "config", ".", "random_seed", "\n", "", "if", "config", ".", "attacker_agent_config", "is", "not", "None", ":", "\n", "                ", "config", ".", "attacker_agent_config", ".", "random_seed", "=", "config", ".", "random_seed", "\n", "", "agent", "=", "PPOBaselineAgent", "(", "env", ",", "\n", "attacker_agent_config", "=", "config", ".", "defender_agent_config", ",", "\n", "defender_agent_config", "=", "config", ".", "defender_agent_config", ",", "\n", "train_mode", "=", "TrainMode", "(", "config", ".", "train_mode", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Train agent type not recognized: {}\"", ".", "format", "(", "config", ".", "agent_type", ")", ")", "\n", "", "agent", ".", "train", "(", ")", "\n", "train_result", "=", "agent", ".", "train_result", "\n", "eval_result", "=", "agent", ".", "eval_result", "\n", "env", ".", "cleanup", "(", ")", "\n", "env", ".", "close", "(", ")", "\n", "return", "train_result", ",", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.runner.runner.Runner.regular_env_creation": [[57, 67], ["gym.make"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "regular_env_creation", "(", "config", ":", "ClientConfig", ")", ":", "\n", "        ", "\"\"\"\n        Creates the environment\n\n        :param config: the client configuration\n        :return: the created env\n        \"\"\"", "\n", "env", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "traces_dir", "=", "config", ".", "traces_dir", ",", "traces_filename", "=", "config", ".", "traces_filename", ")", "\n", "return", "env", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__init__": [[327, 330], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "r", "=", "1", ",", "p", "=", "2", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "self", ".", "r", "=", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.Bernoulli.__call__": [[331, 333], ["random.choice", "random.choice", "random.choice", "random.choice", "range"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "return", "[", "random", ".", "choice", "(", "(", "-", "self", ".", "r", ",", "self", ".", "r", ")", ")", "for", "_", "in", "range", "(", "self", ".", "p", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.set_seed": [[16, 25], ["random.seed", "random.seed", "numpy.random.seed"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.vec_env.base_vec_env.VecEnvWrapper.seed"], ["def", "set_seed", "(", "seed", ":", "float", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Deterministic seed config\n\n    :param seed: random seed for the PRNG\n    :return: None\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.initial_theta": [[27, 35], ["range", "numpy.array", "numpy.random.uniform", "np.array.append"], "function", ["None"], ["", "def", "initial_theta", "(", "L", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "theta_0", "=", "[", "]", "\n", "upper_bound", "=", "3", "\n", "for", "k", "in", "range", "(", "L", ")", ":", "\n", "        ", "upper_bound", "=", "np", ".", "random", ".", "uniform", "(", "-", "3", ",", "upper_bound", ")", "\n", "theta_0", ".", "append", "(", "upper_bound", ")", "\n", "", "theta_0", "=", "np", ".", "array", "(", "theta_0", ")", "\n", "return", "theta_0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sample_next_state": [[37, 44], ["numpy.random.choice", "state_probs.append", "numpy.arange", "len"], "function", ["None"], ["", "def", "sample_next_state", "(", "T", ":", "np", ".", "ndarray", ",", "s", ":", "int", ",", "a", ":", "int", ",", "S", ":", "np", ".", "ndarray", ")", "->", "int", ":", "\n", "    ", "state_probs", "=", "[", "]", "\n", "for", "s_prime", "in", "S", ":", "\n", "        ", "state_probs", ".", "append", "(", "T", "[", "a", "]", "[", "s", "]", "[", "s_prime", "]", ")", "\n", "# print(f\"state probs:{state_probs}\")", "\n", "", "s_prime", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "0", ",", "len", "(", "S", ")", ")", ",", "p", "=", "state_probs", ")", "\n", "return", "s_prime", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sample_next_observation": [[46, 52], ["numpy.random.choice", "observation_probs.append", "numpy.arange", "len"], "function", ["None"], ["", "def", "sample_next_observation", "(", "Z", ":", "np", ".", "ndarray", ",", "s_prime", ":", "int", ",", "a", ":", "int", ",", "O", ":", "np", ".", "ndarray", ")", "->", "int", ":", "\n", "    ", "observation_probs", "=", "[", "]", "\n", "for", "o", "in", "O", ":", "\n", "        ", "observation_probs", ".", "append", "(", "Z", "[", "a", "]", "[", "s_prime", "]", "[", "o", "]", ")", "\n", "", "o", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "0", ",", "len", "(", "O", ")", ")", ",", "p", "=", "observation_probs", ")", "\n", "return", "o", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.smooth_threshold": [[53, 62], ["math.pow", "random.uniform", "random.uniform", "math.pow"], "function", ["None"], ["", "def", "smooth_threshold", "(", "threshold", ",", "b1", ")", ":", "\n", "    ", "v", "=", "20", "\n", "prob", "=", "math", ".", "pow", "(", "1", "+", "math", ".", "pow", "(", "(", "(", "b1", "*", "(", "1", "-", "threshold", ")", ")", "/", "(", "threshold", "*", "(", "1", "-", "b1", ")", ")", ")", ",", "-", "v", ")", ",", "-", "1", ")", "\n", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", ">=", "prob", ":", "\n", "# print(f\"threshold:{threshold}, prob:{prob}, action:0\")", "\n", "        ", "return", "0", "\n", "", "else", ":", "\n", "# print(f\"threshold:{threshold}, prob:{prob}, action:1\")", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.eval_theta": [[64, 160], ["range", "round", "round", "round", "round", "round", "round", "round", "round", "tnsm_21_revision.reward_tensor", "tnsm_21_revision.transition_tensor", "cumulative_rewards.append", "snort_baseline_rewards.append", "optimal_rewards.append", "episode_lengths.append", "optimal_episode_lengths.append", "intrusion_lengths.append", "sum", "sum", "spsa.sample_next_state", "spsa.sample_next_observation", "tnsm_21_revision.next_belief", "sum", "sum", "sum", "sum", "sum", "sum", "range", "spsa.sigmoid", "math.pow", "tnsm_21_revision.reward_tensor", "tnsm_21_revision.transition_tensor", "sum", "spsa.smooth_threshold", "snort_episode_lengths.append", "list", "spsa.sigmoid", "random.random", "random.random", "snort_intrusion_lengths.append", "map", "max", "list", "range"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sample_next_state", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sample_next_observation", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sigmoid", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.smooth_threshold", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sigmoid"], ["", "", "def", "eval_theta", "(", "theta", ":", "np", ".", "ndarray", ",", "b0", ":", "np", ".", "ndarray", ",", "L", ":", "int", ",", "s0", ":", "int", ",", "Z", ":", "np", ".", "ndarray", ",", "\n", "O", ":", "np", ".", "ndarray", ",", "S", ":", "np", ".", "ndarray", ",", "batch_size", ":", "int", ",", "max_iterations", ":", "int", "=", "1000", ",", "\n", "sigmoid_transform", ":", "bool", "=", "False", ",", "gamma", ":", "float", "=", "0.9", ",", "stochastic_policy", "=", "False", ")", "->", "float", ":", "\n", "    ", "cumulative_rewards", "=", "[", "]", "\n", "optimal_rewards", "=", "[", "]", "\n", "episode_lengths", "=", "[", "]", "\n", "early_stopping_count", "=", "0", "\n", "snort_early_stopping_count", "=", "0", "\n", "intrusion_lengths", "=", "[", "]", "\n", "snort_intrusion_lengths", "=", "[", "]", "\n", "snort_episode_lengths", "=", "[", "]", "\n", "optimal_episode_lengths", "=", "[", "]", "\n", "\n", "snort_baseline_rewards", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "b", "=", "b0", "\n", "s", "=", "s0", "\n", "l", "=", "L", "\n", "R", "=", "stopping_pomdp", ".", "reward_tensor", "(", "L", "=", "L", ",", "l", "=", "l", ")", "\n", "T", "=", "stopping_pomdp", ".", "transition_tensor", "(", "l", "=", "l", ")", "\n", "cumulative_reward", "=", "0", "\n", "iter", "=", "0", "\n", "intrusion_time", "=", "100", "\n", "intrusion_length", "=", "0", "\n", "snort_baseline_reward", "=", "0", "\n", "snort_baseline_stops_remaining", "=", "L", "\n", "while", "b", "[", "2", "]", "!=", "1", "and", "l", ">", "0", "and", "iter", "<=", "max_iterations", ":", "\n", "            ", "threshold", "=", "theta", "[", "l", "-", "1", "]", "\n", "if", "sigmoid_transform", ":", "\n", "                ", "upper_bound", "=", "1", "\n", "for", "k", "in", "range", "(", "0", ",", "l", "-", "1", ")", ":", "\n", "                    ", "if", "k", ">=", "1", ":", "\n", "                        ", "upper_bound", "=", "sigmoid", "(", "theta", "[", "k", "-", "1", "]", ",", "upper_bound", "=", "upper_bound", ")", "\n", "", "", "threshold", "=", "sigmoid", "(", "theta", "[", "l", "-", "1", "]", ",", "upper_bound", "=", "upper_bound", ")", "\n", "", "if", "b", "[", "1", "]", ">=", "threshold", ":", "\n", "                ", "if", "not", "stochastic_policy", ":", "\n", "                    ", "a", "=", "1", "\n", "", "else", ":", "\n", "                    ", "a", "=", "smooth_threshold", "(", "threshold", "=", "threshold", ",", "b1", "=", "b", "[", "1", "]", ")", "\n", "", "", "elif", "stochastic_policy", "and", "random", ".", "random", "(", ")", ">=", "threshold", ":", "\n", "                ", "a", "=", "1", "\n", "", "else", ":", "\n", "                ", "a", "=", "0", "\n", "", "r", "=", "R", "[", "a", "]", "[", "s", "]", "\n", "cumulative_reward", "+=", "math", ".", "pow", "(", "gamma", ",", "iter", ")", "*", "r", "\n", "previous_state", "=", "s", "\n", "if", "s", "!=", "1", "and", "(", "l", "-", "a", ")", "==", "0", ":", "\n", "                ", "early_stopping_count", "+=", "1", "\n", "", "s", "=", "sample_next_state", "(", "T", "=", "T", ",", "s", "=", "s", ",", "a", "=", "a", ",", "S", "=", "S", ")", "\n", "if", "s", "==", "1", "and", "previous_state", "==", "0", ":", "\n", "                ", "intrusion_time", "=", "iter", "\n", "", "if", "s", "==", "1", "and", "previous_state", "==", "1", ":", "\n", "                ", "intrusion_length", "+=", "1", "\n", "", "o", "=", "sample_next_observation", "(", "Z", "=", "Z", ",", "s_prime", "=", "s", ",", "a", "=", "a", ",", "O", "=", "O", ")", "\n", "if", "snort_baseline_stops_remaining", ">", "0", ":", "\n", "                ", "if", "o", ">", "0", ":", "\n", "                    ", "snort_baseline_reward", "+=", "R", "[", "1", "]", "[", "s", "]", "\n", "snort_baseline_stops_remaining", "=", "snort_baseline_stops_remaining", "-", "1", "\n", "if", "snort_baseline_stops_remaining", "==", "0", "and", "s", "!=", "1", ":", "\n", "                        ", "snort_early_stopping_count", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "snort_intrusion_lengths", ".", "append", "(", "max", "(", "0", ",", "iter", "-", "intrusion_time", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "snort_baseline_reward", "+=", "R", "[", "0", "]", "[", "s", "]", "\n", "", "if", "snort_baseline_stops_remaining", "==", "0", ":", "\n", "                    ", "snort_episode_lengths", ".", "append", "(", "iter", ")", "\n", "", "", "b", "=", "hsvi", ".", "next_belief", "(", "o", "=", "o", ",", "a", "=", "a", ",", "b", "=", "b", ",", "S", "=", "S", ",", "Z", "=", "Z", ",", "T", "=", "T", ")", "\n", "l", "=", "l", "-", "a", "\n", "if", "a", "==", "1", "and", "l", ">", "0", ":", "\n", "                ", "R", "=", "stopping_pomdp", ".", "reward_tensor", "(", "L", "=", "L", ",", "l", "=", "l", ")", "\n", "T", "=", "stopping_pomdp", ".", "transition_tensor", "(", "l", "=", "l", ")", "\n", "# print(f\"s:{s}, b:{b}, a:{a}, c_r:{cumulative_reward}, r:{r}, theta:{theta}, l:{l}\")", "\n", "", "iter", "+=", "1", "\n", "# sys.exit(0)", "\n", "# print(f\"c_r:{cumulative_reward}\")", "\n", "", "cumulative_rewards", ".", "append", "(", "cumulative_reward", ")", "\n", "snort_baseline_rewards", ".", "append", "(", "snort_baseline_reward", ")", "\n", "optimal_rewards", ".", "append", "(", "intrusion_time", "*", "stopping_pomdp", ".", "R_sla", "+", "sum", "(", "list", "(", "map", "(", "lambda", "x", ":", "stopping_pomdp", ".", "R_st", "/", "(", "3", "*", "x", ")", ",", "list", "(", "range", "(", "1", ",", "L", "+", "1", ")", ")", ")", ")", ")", ")", "\n", "episode_lengths", ".", "append", "(", "iter", ")", "\n", "optimal_episode_lengths", ".", "append", "(", "intrusion_time", "+", "1", ")", "\n", "intrusion_lengths", ".", "append", "(", "intrusion_length", ")", "\n", "", "avg_cumulative_rewards", "=", "sum", "(", "cumulative_rewards", ")", "/", "batch_size", "\n", "avg_optimal_rewards", "=", "sum", "(", "optimal_rewards", ")", "/", "batch_size", "\n", "early_stopping_prob", "=", "round", "(", "early_stopping_count", "/", "batch_size", ",", "5", ")", "\n", "intrusion_prevented_prob", "=", "1", "-", "early_stopping_prob", "\n", "snort_early_stopping_prob", "=", "round", "(", "snort_early_stopping_count", "/", "batch_size", ",", "5", ")", "\n", "snort_intrusion_prevented_prob", "=", "1", "-", "snort_early_stopping_prob", "\n", "avg_ep_len", "=", "round", "(", "sum", "(", "episode_lengths", ")", "/", "batch_size", ",", "2", ")", "\n", "avg_intrusion_len", "=", "round", "(", "sum", "(", "intrusion_lengths", ")", "/", "batch_size", ",", "2", ")", "\n", "avg_snort_baseline_r", "=", "round", "(", "sum", "(", "snort_baseline_rewards", ")", "/", "batch_size", ",", "2", ")", "\n", "avg_snort_ep_len", "=", "round", "(", "sum", "(", "snort_episode_lengths", ")", "/", "batch_size", ",", "2", ")", "\n", "avg_snort_intrusion_len", "=", "round", "(", "sum", "(", "snort_intrusion_lengths", ")", "/", "batch_size", ",", "2", ")", "\n", "avg_optimal_ep_len", "=", "round", "(", "sum", "(", "optimal_episode_lengths", ")", "/", "batch_size", ",", "2", ")", "\n", "return", "avg_cumulative_rewards", ",", "avg_optimal_rewards", ",", "early_stopping_prob", ",", "intrusion_prevented_prob", ",", "avg_ep_len", ",", "avg_intrusion_len", ",", "avg_snort_baseline_r", ",", "snort_early_stopping_prob", ",", "snort_intrusion_prevented_prob", ",", "avg_snort_ep_len", ",", "avg_snort_intrusion_len", ",", "avg_optimal_ep_len", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sigmoid": [[161, 163], ["math.exp"], "function", ["None"], ["", "def", "sigmoid", "(", "x", ",", "upper_bound", ")", ":", "\n", "    ", "return", "1", "/", "(", "1", "+", "math", ".", "exp", "(", "-", "x", ")", ")", "\n", "# return 1/(1 + math.exp(-x))*(upper_bound)", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.get_thresholds": [[166, 173], ["range", "len", "spsa.sigmoid", "thresholds.append"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.sigmoid"], ["", "def", "get_thresholds", "(", "theta", ")", ":", "\n", "    ", "upper_bound", "=", "1", "\n", "thresholds", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "theta", ")", ")", ":", "\n", "        ", "upper_bound", "=", "sigmoid", "(", "theta", "[", "k", "]", ",", "upper_bound", "=", "upper_bound", ")", "\n", "thresholds", ".", "append", "(", "upper_bound", ")", "\n", "", "return", "thresholds", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.save_csv_files": [[175, 194], ["open", "csv.writer", "range", "csv.writer.writerow", "range", "labels.append", "len", "range", "csv.writer.writerow", "row.append", "round"], "function", ["None"], ["", "def", "save_csv_files", "(", "times", ",", "values", ",", "optimal_values", ",", "thetas", ",", "early_stopping_probs", ",", "\n", "intrusion_prevented_probs", ",", "episode_lenghts", ",", "intrusion_lengths", ",", "\n", "snort_rewards", ",", "snort_intrusion_prevented_probs", ",", "snort_early_stopping_probs", ",", "\n", "snort_ep_lens", ",", "optimal_ep_lens", ",", "snort_intrusion_lens", ",", "file_name", ",", "L", ")", ":", "\n", "    ", "with", "open", "(", "file_name", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "labels", "=", "[", "\"t\"", ",", "\"J\"", ",", "\"J_opt\"", ",", "\"early_stopping_prob\"", ",", "\"intrusion_prevented_prob\"", ",", "\"T\"", ",", "\"intrusion_length\"", ",", "\n", "\"snort_R\"", ",", "\"snort_intrusion_prevented_prob\"", ",", "\"snort_early_stopping_prob\"", ",", "\"snort_ep_len\"", ",", "\n", "\"optimal_ep_len\"", ",", "\"snort_intrusion_len\"", ",", "]", "\n", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "            ", "labels", ".", "append", "(", "f\"alpha_{l}\"", ")", "\n", "", "writer", ".", "writerow", "(", "labels", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "times", ")", ")", ":", "\n", "            ", "row", "=", "[", "times", "[", "i", "]", ",", "values", "[", "i", "]", ",", "optimal_values", "[", "i", "]", ",", "early_stopping_probs", "[", "i", "]", ",", "intrusion_prevented_probs", "[", "i", "]", ",", "\n", "episode_lenghts", "[", "i", "]", ",", "intrusion_lengths", "[", "i", "]", ",", "snort_rewards", "[", "i", "]", ",", "snort_intrusion_prevented_probs", "[", "i", "]", ",", "\n", "snort_early_stopping_probs", "[", "i", "]", ",", "snort_ep_lens", "[", "i", "]", ",", "optimal_ep_lens", "[", "i", "]", ",", "snort_intrusion_lens", "[", "i", "]", "]", "\n", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "                ", "row", ".", "append", "(", "round", "(", "thetas", "[", "i", "]", "[", "l", "]", ",", "5", ")", ")", "\n", "", "writer", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.SPSA": [[195, 287], ["spsa.eval_theta", "round", "round", "values.append", "optimal_values.append", "round", "times.append", "thetas.append", "early_stopping_probs.append", "intrusion_prevented_probs.append", "episode_lengths.append", "intrusion_lengths.append", "snort_rewards.append", "snort_early_stopping_probs.append", "snort_intrusion_prevented_probs.append", "snort_ep_lens.append", "optimal_ep_lens.append", "snort_intrusion_lens.append", "print", "range", "spsa.get_thresholds", "spsa.standard_ak", "spsa.standard_ck", "spsa.estimate_gk", "constraint", "range", "spsa.eval_theta", "round", "round", "round", "times.append", "values.append", "optimal_values.append", "thetas.append", "early_stopping_probs.append", "episode_lengths.append", "intrusion_prevented_probs.append", "intrusion_lengths.append", "snort_rewards.append", "snort_intrusion_prevented_probs.append", "snort_early_stopping_probs.append", "snort_ep_lens.append", "optimal_ep_lens.append", "snort_intrusion_lens.append", "print", "spsa.get_thresholds", "time.time", "spsa.get_thresholds", "zip", "len", "random.random", "random.random", "time.time", "spsa.get_thresholds", "random.random", "random.random"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.eval_theta", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.get_thresholds", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.standard_ak", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.standard_ck", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.estimate_gk", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.eval_theta", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.get_thresholds", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.get_thresholds", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.get_thresholds"], ["", "", "", "def", "SPSA", "(", "t0", ",", "iterations", ",", "alpha", ",", "gamma", ",", "c", ",", "a", ",", "delta", ",", "b0", ",", "s0", ",", "Z", ",", "A", ",", "O", ",", "S", ",", "eval_batch_size", ",", "L", ",", "start", ",", "\n", "discount_factor", "=", "1", ",", "constraint", "=", "identity", ",", "stochastic_policy", "=", "False", ")", ":", "\n", "    ", "theta", "=", "t0", "\n", "thetas", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "times", "=", "[", "]", "\n", "optimal_values", "=", "[", "]", "\n", "early_stopping_probs", "=", "[", "]", "\n", "intrusion_prevented_probs", "=", "[", "]", "\n", "episode_lengths", "=", "[", "]", "\n", "intrusion_lengths", "=", "[", "]", "\n", "snort_rewards", "=", "[", "]", "\n", "snort_ep_lens", "=", "[", "]", "\n", "snort_intrusion_prevented_probs", "=", "[", "]", "\n", "snort_early_stopping_probs", "=", "[", "]", "\n", "snort_intrusion_lens", "=", "[", "]", "\n", "optimal_ep_lens", "=", "[", "]", "\n", "J", ",", "J_opt", ",", "early_stopping_prob", ",", "intrusion_prevented_prob", ",", "avg_ep_len", ",", "avg_intrusion_len", ",", "avg_snort_reward", ",", "snort_early_stopping_prob", ",", "snort_intrusion_prevented_prob", ",", "avg_snort_ep_len", ",", "avg_snort_intrusion_len", ",", "avg_optimal_ep_len", "=", "eval_theta", "(", "theta", "=", "theta", ",", "b0", "=", "b0", ",", "L", "=", "L", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "O", "=", "O", ",", "S", "=", "S", ",", "batch_size", "=", "eval_batch_size", ",", "\n", "sigmoid_transform", "=", "True", ",", "gamma", "=", "discount_factor", ",", "stochastic_policy", "=", "stochastic_policy", ")", "\n", "J", "=", "round", "(", "J", ",", "5", ")", "\n", "J_opt", "=", "round", "(", "J_opt", ",", "5", ")", "\n", "values", ".", "append", "(", "J", ")", "\n", "optimal_values", ".", "append", "(", "J_opt", ")", "\n", "t", "=", "round", "(", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60.0", ",", "3", ")", "\n", "times", ".", "append", "(", "t", ")", "\n", "thetas", ".", "append", "(", "get_thresholds", "(", "theta", "=", "theta", ")", ")", "\n", "early_stopping_probs", ".", "append", "(", "early_stopping_prob", ")", "\n", "intrusion_prevented_probs", ".", "append", "(", "intrusion_prevented_prob", ")", "\n", "episode_lengths", ".", "append", "(", "avg_ep_len", ")", "\n", "intrusion_lengths", ".", "append", "(", "avg_intrusion_len", ")", "\n", "snort_rewards", ".", "append", "(", "avg_snort_reward", ")", "\n", "snort_early_stopping_probs", ".", "append", "(", "snort_early_stopping_prob", ")", "\n", "snort_intrusion_prevented_probs", ".", "append", "(", "snort_intrusion_prevented_prob", ")", "\n", "snort_ep_lens", ".", "append", "(", "avg_snort_ep_len", ")", "\n", "optimal_ep_lens", ".", "append", "(", "avg_optimal_ep_len", ")", "\n", "snort_intrusion_lens", ".", "append", "(", "avg_snort_intrusion_len", ")", "\n", "print", "(", "f\"i:{0}, theta1:{get_thresholds(theta=theta)}, J:{J}, J_Opt:{J_opt}, early_stopping: {early_stopping_prob}, \"", "\n", "f\"ep len:{avg_ep_len}, intrusion len:{avg_intrusion_len}\"", "\n", "f\"t:{t}, snort_R:{avg_snort_reward}, snort_ep_len:{avg_snort_ep_len}, snort_es:{snort_early_stopping_prob}, \"", "\n", "f\"snort_intrusion_len:{avg_snort_intrusion_len}\"", "\n", "f\"optimal_ep_len:{avg_optimal_ep_len}\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "iterations", ")", ":", "\n", "        ", "ak", "=", "standard_ak", "(", "a", "=", "a", ",", "A", "=", "A", ",", "alpha", "=", "alpha", ",", "k", "=", "i", ")", "\n", "ck", "=", "standard_ck", "(", "c", "=", "c", ",", "gamma", "=", "gamma", ",", "k", "=", "i", ")", "\n", "# Get estimated gradient", "\n", "gk", "=", "estimate_gk", "(", "theta", ",", "delta", ",", "ck", ",", "b0", ",", "s0", ",", "Z", ",", "O", ",", "S", ",", "eval_batch_size", ",", "L", ",", "stochastic_policy", "=", "stochastic_policy", ")", "\n", "\n", "# Adjust theta using SA", "\n", "theta", "=", "[", "t", "+", "ak", "*", "gkk", "for", "t", ",", "gkk", "in", "zip", "(", "theta", ",", "gk", ")", "]", "\n", "\n", "# Constrain", "\n", "theta", "=", "constraint", "(", "theta", ")", "\n", "# print(theta)", "\n", "for", "j", "in", "range", "(", "len", "(", "theta", ")", "-", "1", ")", ":", "\n", "            ", "if", "theta", "[", "j", "+", "1", "]", ">", "theta", "[", "j", "]", ":", "\n", "# print(\"sec upd\")", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.8", ":", "\n", "                    ", "theta", "[", "j", "]", "=", "theta", "[", "j", "+", "1", "]", "+", "random", ".", "random", "(", ")", "/", "10", "\n", "", "", "", "J", ",", "J_opt", ",", "early_stopping_prob", ",", "intrusion_prevented_prob", ",", "avg_ep_len", ",", "avg_intrusion_len", ",", "avg_snort_reward", ",", "snort_early_stopping_prob", ",", "snort_intrusion_prevented_prob", ",", "avg_snort_ep_len", ",", "avg_snort_intrusion_len", ",", "avg_optimal_ep_len", "=", "eval_theta", "(", "theta", "=", "theta", ",", "b0", "=", "b0", ",", "L", "=", "L", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "O", "=", "O", ",", "S", "=", "S", ",", "batch_size", "=", "eval_batch_size", ",", "\n", "gamma", "=", "discount_factor", ",", "sigmoid_transform", "=", "True", ",", "stochastic_policy", "=", "stochastic_policy", ")", "\n", "J", "=", "round", "(", "J", ",", "5", ")", "\n", "J_opt", "=", "round", "(", "J_opt", ",", "5", ")", "\n", "t", "=", "round", "(", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60.0", ",", "3", ")", "\n", "times", ".", "append", "(", "t", ")", "\n", "values", ".", "append", "(", "J", ")", "\n", "optimal_values", ".", "append", "(", "J_opt", ")", "\n", "thetas", ".", "append", "(", "get_thresholds", "(", "theta", "=", "theta", ")", ")", "\n", "early_stopping_probs", ".", "append", "(", "early_stopping_prob", ")", "\n", "episode_lengths", ".", "append", "(", "avg_ep_len", ")", "\n", "intrusion_prevented_probs", ".", "append", "(", "intrusion_prevented_prob", ")", "\n", "intrusion_lengths", ".", "append", "(", "avg_intrusion_len", ")", "\n", "snort_rewards", ".", "append", "(", "avg_snort_reward", ")", "\n", "snort_intrusion_prevented_probs", ".", "append", "(", "snort_intrusion_prevented_prob", ")", "\n", "snort_early_stopping_probs", ".", "append", "(", "snort_early_stopping_prob", ")", "\n", "snort_ep_lens", ".", "append", "(", "avg_snort_ep_len", ")", "\n", "optimal_ep_lens", ".", "append", "(", "avg_optimal_ep_len", ")", "\n", "snort_intrusion_lens", ".", "append", "(", "avg_snort_intrusion_len", ")", "\n", "print", "(", "f\"i:{i}, theta:{get_thresholds(theta=theta)}, J:{J}, J_Opt:{J_opt}, \"", "\n", "f\"early_stopping: {early_stopping_prob}, t:{t}, int len:{avg_intrusion_len}, ep len:{avg_ep_len},\"", "\n", "f\"snort_rew:{avg_snort_reward}, snort_es:{snort_early_stopping_prob}, snort_ep_len:{avg_snort_ep_len}, \"", "\n", "f\"avg_snort_intrusio_len:{avg_snort_intrusion_len}, avg_optimal_len:{avg_optimal_ep_len}\"", ")", "\n", "\n", "", "return", "thetas", ",", "values", ",", "times", ",", "optimal_values", ",", "early_stopping_probs", ",", "intrusion_prevented_probs", ",", "episode_lengths", ",", "intrusion_lengths", ",", "snort_rewards", ",", "snort_intrusion_prevented_probs", ",", "snort_early_stopping_probs", ",", "snort_ep_lens", ",", "optimal_ep_lens", ",", "snort_intrusion_lens", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.estimate_gk": [[289, 307], ["delta", "spsa.eval_theta", "spsa.eval_theta", "round", "round", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.eval_theta", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.eval_theta"], ["", "def", "estimate_gk", "(", "theta", ",", "delta", ",", "ck", ",", "b0", ",", "s0", ",", "Z", ",", "O", ",", "S", ",", "eval_batch_size", ",", "L", ",", "stochastic_policy", ")", ":", "\n", "    ", "'''Helper function to estimate gk from SPSA'''", "\n", "# Generate Delta vector", "\n", "delta_k", "=", "delta", "(", ")", "\n", "\n", "# Get the two perturbed values of theta", "\n", "# list comprehensions like this are quite nice", "\n", "ta", "=", "[", "t", "+", "ck", "*", "dk", "for", "t", ",", "dk", "in", "zip", "(", "theta", ",", "delta_k", ")", "]", "\n", "tb", "=", "[", "t", "-", "ck", "*", "dk", "for", "t", ",", "dk", "in", "zip", "(", "theta", ",", "delta_k", ")", "]", "\n", "\n", "# Calculate g_k(theta_k)", "\n", "ya", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "eval_theta", "(", "theta", "=", "ta", ",", "b0", "=", "b0", ",", "L", "=", "L", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "O", "=", "O", ",", "S", "=", "S", ",", "batch_size", "=", "eval_batch_size", ",", "sigmoid_transform", "=", "True", ",", "stochastic_policy", "=", "stochastic_policy", ")", "\n", "yb", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "eval_theta", "(", "theta", "=", "tb", ",", "b0", "=", "b0", ",", "L", "=", "L", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "O", "=", "O", ",", "S", "=", "S", ",", "batch_size", "=", "eval_batch_size", ",", "sigmoid_transform", "=", "True", ",", "stochastic_policy", "=", "stochastic_policy", ")", "\n", "ya", "=", "round", "(", "ya", ",", "5", ")", "\n", "yb", "=", "round", "(", "yb", ",", "5", ")", "\n", "gk", "=", "[", "(", "ya", "-", "yb", ")", "/", "(", "2", "*", "ck", "*", "dk", ")", "for", "dk", "in", "delta_k", "]", "\n", "\n", "return", "gk", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.standard_ak": [[309, 314], ["None"], "function", ["None"], ["", "def", "standard_ak", "(", "a", ",", "A", ",", "alpha", ",", "k", ")", ":", "\n", "    ", "'''Create a generator for values of a_k in the standard form.'''", "\n", "# Parentheses makes this an iterator comprehension", "\n", "# count() is an infinite iterator as 0, 1, 2, ...", "\n", "return", "a", "/", "(", "k", "+", "1", "+", "A", ")", "**", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.standard_ck": [[316, 319], ["None"], "function", ["None"], ["", "def", "standard_ck", "(", "c", ",", "gamma", ",", "k", ")", ":", "\n", "    ", "'''Create a generator for values of c_k in the standard form.'''", "\n", "return", "c", "/", "(", "k", "+", "1", ")", "**", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.run_spsa": [[335, 441], ["tnsm_21_revision.initial_state", "tnsm_21_revision.initial_belief", "tnsm_21_revision.observation_tensor_and_space", "tnsm_21_revision.actions", "tnsm_21_revision.states", "spsa.Bernoulli", "spsa.set_seed", "time.time", "spsa.SPSA", "spsa.save_csv_files", "spsa.set_seed", "time.time", "spsa.SPSA", "spsa.save_csv_files", "spsa.set_seed", "time.time", "spsa.SPSA", "spsa.save_csv_files"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.defender_dynamics.dp.DP.actions", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.set_seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.SPSA", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.save_csv_files", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.set_seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.SPSA", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.save_csv_files", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.set_seed", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.SPSA", "home.repos.pwc.inspect_result.Limmen_gym-optimal-intrusion-response.spsa.spsa.save_csv_files"], ["", "", "def", "run_spsa", "(", "iterations", "=", "1000", ",", "replications", "=", "40", ")", ":", "\n", "    ", "L", "=", "3", "\n", "s0", "=", "stopping_pomdp", ".", "initial_state", "(", ")", "\n", "b0", "=", "stopping_pomdp", ".", "initial_belief", "(", ")", "\n", "O_novice", ",", "O_experienced", ",", "O_expert", ",", "Z_novice", ",", "Z_experienced", ",", "Z_expert", "=", "stopping_pomdp", ".", "observation_tensor_and_space", "(", "\"/home/kim/workspace/tnsm_21_revision/tnsm_21_revision\"", ")", "\n", "A", ",", "_", "=", "stopping_pomdp", ".", "actions", "(", ")", "\n", "S", ",", "_", "=", "stopping_pomdp", ".", "states", "(", ")", "\n", "discount", "=", "1", "\n", "\n", "# p = 3", "\n", "# c=1", "\n", "# gamma=.101", "\n", "# alpha = .602", "\n", "# A=100", "\n", "# a=1", "\n", "\n", "p", "=", "3", "\n", "c", "=", "10", "\n", "gamma", "=", ".101", "\n", "# gamma=.05", "\n", "alpha", "=", ".602", "\n", "A", "=", "100", "\n", "a", "=", "50", "\n", "\n", "\n", "delta", "=", "Bernoulli", "(", "p", "=", "p", ")", "\n", "eval_batch_size", "=", "100", "\n", "\n", "# seeds = [0, 399, 999]", "\n", "seeds", "=", "[", "0", ",", "399", ",", "999", "]", "\n", "\n", "L", "=", "1", "\n", "Z", "=", "Z_novice", "\n", "O", "=", "O_novice", "\n", "theta0", "=", "[", "-", "4", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "set_seed", "(", "seed", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "thetas", ",", "values", ",", "times", ",", "optimal_values", ",", "early_stopping_probs", ",", "intrusion_prevented_probs", ",", "episode_lengths", ",", "intrusion_lengths", ",", "snort_rewards", ",", "snort_intrusion_prevented_probs", ",", "snort_early_stopping_probs", ",", "snort_ep_lens", ",", "optimal_ep_lens", ",", "snort_intrusion_lens", "=", "SPSA", "(", "iterations", "=", "iterations", ",", "t0", "=", "theta0", ",", "delta", "=", "delta", ",", "b0", "=", "b0", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "A", "=", "A", ",", "O", "=", "O", ",", "S", "=", "S", ",", "\n", "eval_batch_size", "=", "eval_batch_size", ",", "L", "=", "L", ",", "discount_factor", "=", "discount", ",", "start", "=", "start", ",", "alpha", "=", "alpha", ",", "\n", "gamma", "=", "gamma", ",", "c", "=", "c", ",", "a", "=", "a", ",", "stochastic_policy", "=", "True", ")", "\n", "save_csv_files", "(", "times", "=", "times", ",", "values", "=", "values", ",", "optimal_values", "=", "optimal_values", ",", "thetas", "=", "thetas", ",", "\n", "early_stopping_probs", "=", "early_stopping_probs", ",", "\n", "intrusion_prevented_probs", "=", "intrusion_prevented_probs", ",", "\n", "episode_lenghts", "=", "episode_lengths", ",", "\n", "intrusion_lengths", "=", "intrusion_lengths", ",", "\n", "snort_rewards", "=", "snort_rewards", ",", "\n", "snort_intrusion_prevented_probs", "=", "snort_intrusion_prevented_probs", ",", "\n", "snort_early_stopping_probs", "=", "snort_early_stopping_probs", ",", "\n", "snort_ep_lens", "=", "snort_ep_lens", ",", "optimal_ep_lens", "=", "optimal_ep_lens", ",", "\n", "snort_intrusion_lens", "=", "snort_intrusion_lens", ",", "\n", "file_name", "=", "f\"novice_spsa_{seed}.csv\"", ",", "L", "=", "L", ")", "\n", "\n", "", "L", "=", "2", "\n", "Z", "=", "Z_experienced", "\n", "O", "=", "O_experienced", "\n", "theta0", "=", "[", "-", "4", ",", "-", "4", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "set_seed", "(", "seed", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "thetas", ",", "values", ",", "times", ",", "optimal_values", ",", "early_stopping_probs", ",", "intrusion_prevented_probs", ",", "episode_lengths", ",", "intrusion_lengths", ",", "snort_rewards", ",", "snort_intrusion_prevented_probs", ",", "snort_early_stopping_probs", ",", "snort_ep_lens", ",", "optimal_ep_lens", ",", "snort_intrusion_lens", "=", "SPSA", "(", "iterations", "=", "iterations", ",", "t0", "=", "theta0", ",", "delta", "=", "delta", ",", "b0", "=", "b0", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "A", "=", "A", ",", "O", "=", "O", ",", "S", "=", "S", ",", "\n", "eval_batch_size", "=", "eval_batch_size", ",", "L", "=", "L", ",", "discount_factor", "=", "discount", ",", "start", "=", "start", ",", "alpha", "=", "alpha", ",", "gamma", "=", "gamma", ",", "c", "=", "c", ",", "a", "=", "a", ")", "\n", "save_csv_files", "(", "times", "=", "times", ",", "values", "=", "values", ",", "optimal_values", "=", "optimal_values", ",", "thetas", "=", "thetas", ",", "\n", "early_stopping_probs", "=", "early_stopping_probs", ",", "\n", "intrusion_prevented_probs", "=", "intrusion_prevented_probs", ",", "\n", "episode_lenghts", "=", "episode_lengths", ",", "\n", "intrusion_lengths", "=", "intrusion_lengths", ",", "\n", "snort_rewards", "=", "snort_rewards", ",", "\n", "snort_intrusion_prevented_probs", "=", "snort_intrusion_prevented_probs", ",", "\n", "snort_early_stopping_probs", "=", "snort_early_stopping_probs", ",", "\n", "snort_ep_lens", "=", "snort_ep_lens", ",", "optimal_ep_lens", "=", "optimal_ep_lens", ",", "\n", "snort_intrusion_lens", "=", "snort_intrusion_lens", ",", "\n", "file_name", "=", "f\"experienced_spsa_{seed}.csv\"", ",", "L", "=", "L", ")", "\n", "\n", "\n", "", "Z", "=", "Z_expert", "\n", "O", "=", "O_expert", "\n", "theta0", "=", "[", "-", "4", ",", "-", "4", ",", "-", "4", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "set_seed", "(", "seed", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "thetas", ",", "values", ",", "times", ",", "optimal_values", ",", "early_stopping_probs", ",", "intrusion_prevented_probs", ",", "episode_lengths", ",", "intrusion_lengths", ",", "snort_rewards", ",", "snort_intrusion_prevented_probs", ",", "snort_early_stopping_probs", ",", "snort_ep_lens", ",", "optimal_ep_lens", ",", "snort_intrusion_lens", "=", "SPSA", "(", "iterations", "=", "iterations", ",", "t0", "=", "theta0", ",", "delta", "=", "delta", ",", "b0", "=", "b0", ",", "s0", "=", "s0", ",", "Z", "=", "Z", ",", "A", "=", "A", ",", "O", "=", "O", ",", "S", "=", "S", ",", "\n", "eval_batch_size", "=", "eval_batch_size", ",", "L", "=", "L", ",", "discount_factor", "=", "discount", ",", "start", "=", "start", ",", "alpha", "=", "alpha", ",", "\n", "gamma", "=", "gamma", ",", "c", "=", "c", ",", "a", "=", "a", ",", "stochastic_policy", "=", "True", ")", "\n", "save_csv_files", "(", "times", "=", "times", ",", "values", "=", "values", ",", "optimal_values", "=", "optimal_values", ",", "thetas", "=", "thetas", ",", "\n", "early_stopping_probs", "=", "early_stopping_probs", ",", "\n", "intrusion_prevented_probs", "=", "intrusion_prevented_probs", ",", "\n", "episode_lenghts", "=", "episode_lengths", ",", "\n", "intrusion_lengths", "=", "intrusion_lengths", ",", "\n", "snort_rewards", "=", "snort_rewards", ",", "\n", "snort_intrusion_prevented_probs", "=", "snort_intrusion_prevented_probs", ",", "\n", "snort_early_stopping_probs", "=", "snort_early_stopping_probs", ",", "\n", "snort_ep_lens", "=", "snort_ep_lens", ",", "optimal_ep_lens", "=", "optimal_ep_lens", ",", "\n", "snort_intrusion_lens", "=", "snort_intrusion_lens", ",", "\n", "file_name", "=", "f\"expert_spsa_{seed}.csv\"", ",", "L", "=", "L", ")", "\n", "\n", "", "return", "values", "\n", "\n"]]}