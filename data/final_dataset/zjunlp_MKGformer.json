{"home.repos.pwc.inspect_result.zjunlp_MKGformer.MRE.run.set_seed": [[60, 67], ["torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed"], "function", ["None"], ["def", "set_seed", "(", "seed", "=", "2021", ")", ":", "\n", "    ", "\"\"\"set random seed\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.MRE.run.main": [[68, 149], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torchvision.transforms.Compose", "run.set_seed", "print", "os.path.join", "transformers.models.clip.CLIPProcessor.from_pretrained", "transformers.models.clip.CLIPProcessor.from_pretrained", "transformers.models.clip.CLIPProcessor.from_pretrained", "models.modeling_clip.CLIPModel.from_pretrained", "data_process", "dataset_class", "torch.utils.data.DataLoader", "dataset_class", "torch.utils.data.DataLoader", "dataset_class", "torch.utils.data.DataLoader", "data_process.get_relation_dict", "len", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "clip_vit.state_dict", "BertModel.from_pretrained.state_dict", "models.unimo_model.UnimoREModel", "modules.train.BertTrainer", "modules.train.BertTrainer.train", "torch.cuda.empty_cache", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.exists", "os.makedirs", "str", "transformers.CLIPConfig.from_pretrained", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.set_seed", "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREProcessor.get_relation_dict", "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "default", "=", "'bert'", ",", "type", "=", "str", ",", "help", "=", "\"The name of bert.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vit_name'", ",", "default", "=", "'vit'", ",", "type", "=", "str", ",", "help", "=", "\"The name of vit.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_name'", ",", "default", "=", "'twitter15'", ",", "type", "=", "str", ",", "help", "=", "\"The name of dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_name'", ",", "default", "=", "'bert-base'", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained language model name, bart-base or bart-large\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"Training epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "default", "=", "'cuda'", ",", "type", "=", "str", ",", "help", "=", "\"cuda or cpu\"", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "\"batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "2e-5", ",", "type", "=", "float", ",", "help", "=", "\"learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_ratio'", ",", "default", "=", "0.01", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_begin_epoch'", ",", "default", "=", "16", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"random seed, default is 1\"", ")", "\n", "parser", ".", "add_argument", "(", "'--load_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Load model from load_path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"save model at save_path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--write_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"do_test=True, predictions will be write in write_path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--notes'", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"input some remarks for making save path dir.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--do_train'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do_test'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do_predict'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--prompt_len'", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq'", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--aux_size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "help", "=", "\"aux size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rcnn_size'", ",", "default", "=", "64", ",", "type", "=", "int", ",", "help", "=", "\"rcnn size\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data_path", ",", "img_path", ",", "aux_path", "=", "DATA_PATH", "[", "args", ".", "dataset_name", "]", ",", "IMG_PATH", "[", "args", ".", "dataset_name", "]", ",", "AUX_PATH", "[", "args", ".", "dataset_name", "]", "\n", "data_process", ",", "dataset_class", "=", "MODEL_CLASS", "[", "args", ".", "model_name", "]", "\n", "re_path", "=", "'data/ours_rel2id.json'", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n", "set_seed", "(", "args", ".", "seed", ")", "# set seed, default is 1", "\n", "if", "args", ".", "save_path", "is", "not", "None", ":", "# make save_path dir", "\n", "        ", "args", ".", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "args", ".", "model_name", ",", "args", ".", "dataset_name", "+", "\"_\"", "+", "str", "(", "args", ".", "batch_size", ")", "+", "\"_\"", "+", "str", "(", "args", ".", "lr", ")", "+", "\"_\"", "+", "args", ".", "notes", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "", "", "print", "(", "args", ")", "\n", "logdir", "=", "\"logs/\"", "+", "args", ".", "model_name", "+", "\"_\"", "+", "args", ".", "dataset_name", "+", "\"_\"", "+", "str", "(", "args", ".", "batch_size", ")", "+", "\"_\"", "+", "str", "(", "args", ".", "lr", ")", "+", "args", ".", "notes", "\n", "# writer = SummaryWriter(logdir=logdir)", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "clip_vit", ",", "clip_processor", ",", "aux_processor", ",", "rcnn_processor", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "clip_processor", "=", "CLIPProcessor", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "aux_processor", "=", "CLIPProcessor", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "aux_processor", ".", "feature_extractor", ".", "size", ",", "aux_processor", ".", "feature_extractor", ".", "crop_size", "=", "args", ".", "aux_size", ",", "args", ".", "aux_size", "\n", "rcnn_processor", "=", "CLIPProcessor", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "rcnn_processor", ".", "feature_extractor", ".", "size", ",", "rcnn_processor", ".", "feature_extractor", ".", "crop_size", "=", "args", ".", "rcnn_size", ",", "args", ".", "rcnn_size", "\n", "clip_model", "=", "CLIPModel", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "clip_vit", "=", "clip_model", ".", "vision_model", "\n", "\n", "processor", "=", "data_process", "(", "data_path", ",", "re_path", ",", "args", ".", "bert_name", ",", "clip_processor", "=", "clip_processor", ",", "aux_processor", "=", "aux_processor", ",", "rcnn_processor", "=", "rcnn_processor", ")", "\n", "train_dataset", "=", "dataset_class", "(", "processor", ",", "transform", ",", "img_path", ",", "aux_path", ",", "args", ".", "max_seq", ",", "aux_size", "=", "args", ".", "aux_size", ",", "rcnn_size", "=", "args", ".", "rcnn_size", ",", "mode", "=", "'train'", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "dev_dataset", "=", "dataset_class", "(", "processor", ",", "transform", ",", "img_path", ",", "aux_path", ",", "args", ".", "max_seq", ",", "aux_size", "=", "args", ".", "aux_size", ",", "rcnn_size", "=", "args", ".", "rcnn_size", ",", "mode", "=", "'dev'", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "test_dataset", "=", "dataset_class", "(", "processor", ",", "transform", ",", "img_path", ",", "aux_path", ",", "args", ".", "max_seq", ",", "aux_size", "=", "args", ".", "aux_size", ",", "rcnn_size", "=", "args", ".", "rcnn_size", ",", "mode", "=", "'test'", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "re_dict", "=", "processor", ".", "get_relation_dict", "(", ")", "\n", "num_labels", "=", "len", "(", "re_dict", ")", "\n", "tokenizer", "=", "processor", ".", "tokenizer", "\n", "\n", "# test", "\n", "vision_config", "=", "CLIPConfig", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", ".", "vision_config", "\n", "text_config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_name", ")", "\n", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_name", ")", "\n", "clip_model_dict", "=", "clip_vit", ".", "state_dict", "(", ")", "\n", "text_model_dict", "=", "bert", ".", "state_dict", "(", ")", "\n", "model", "=", "UnimoREModel", "(", "num_labels", ",", "tokenizer", ",", "args", ",", "vision_config", ",", "text_config", ",", "clip_model_dict", ",", "text_model_dict", ")", "\n", "\n", "trainer", "=", "BertTrainer", "(", "train_data", "=", "train_dataloader", ",", "dev_data", "=", "dev_dataloader", ",", "test_data", "=", "test_dataloader", ",", "re_dict", "=", "re_dict", ",", "model", "=", "model", ",", "args", "=", "args", ",", "logger", "=", "logger", ",", "writer", "=", "None", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "# writer.close()", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREProcessor.__init__": [[15, 23], ["transformers.BertTokenizer.from_pretrained", "dataset.MMREProcessor.tokenizer.add_special_tokens"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ",", "re_path", ",", "bert_name", ",", "clip_processor", "=", "None", ",", "aux_processor", "=", "None", ",", "rcnn_processor", "=", "None", ")", ":", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "re_path", "=", "re_path", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_name", ",", "do_lower_case", "=", "True", ")", "\n", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "[", "'<s>'", ",", "'</s>'", ",", "'<o>'", ",", "'</o>'", "]", "}", ")", "\n", "self", ".", "clip_processor", "=", "clip_processor", "\n", "self", ".", "aux_processor", "=", "aux_processor", "\n", "self", ".", "rcnn_processor", "=", "rcnn_processor", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREProcessor.load_from_file": [[24, 46], ["logger.info", "torch.load", "torch.load", "open", "f.readlines", "enumerate", "len", "len", "len", "len", "len", "ast.literal_eval", "words.append", "relations.append", "heads.append", "tails.append", "imgids.append", "dataid.append"], "methods", ["None"], ["", "def", "load_from_file", "(", "self", ",", "mode", "=", "\"train\"", ")", ":", "\n", "        ", "load_file", "=", "self", ".", "data_path", "[", "mode", "]", "\n", "logger", ".", "info", "(", "\"Loading data from {}\"", ".", "format", "(", "load_file", ")", ")", "\n", "with", "open", "(", "load_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "words", ",", "relations", ",", "heads", ",", "tails", ",", "imgids", ",", "dataid", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "line", "=", "ast", ".", "literal_eval", "(", "line", ")", "# str to dict", "\n", "words", ".", "append", "(", "line", "[", "'token'", "]", ")", "\n", "relations", ".", "append", "(", "line", "[", "'relation'", "]", ")", "\n", "heads", ".", "append", "(", "line", "[", "'h'", "]", ")", "# {name, pos}", "\n", "tails", ".", "append", "(", "line", "[", "'t'", "]", ")", "\n", "imgids", ".", "append", "(", "line", "[", "'img_id'", "]", ")", "\n", "dataid", ".", "append", "(", "i", ")", "\n", "\n", "", "", "assert", "len", "(", "words", ")", "==", "len", "(", "relations", ")", "==", "len", "(", "heads", ")", "==", "len", "(", "tails", ")", "==", "(", "len", "(", "imgids", ")", ")", "\n", "\n", "aux_imgs", "=", "None", "\n", "aux_path", "=", "self", ".", "data_path", "[", "mode", "+", "\"_auximgs\"", "]", "\n", "aux_imgs", "=", "torch", ".", "load", "(", "aux_path", ")", "\n", "rcnn_imgs", "=", "torch", ".", "load", "(", "self", ".", "data_path", "[", "mode", "+", "'_img2crop'", "]", ")", "\n", "return", "{", "'words'", ":", "words", ",", "'relations'", ":", "relations", ",", "'heads'", ":", "heads", ",", "'tails'", ":", "tails", ",", "'imgids'", ":", "imgids", ",", "'dataid'", ":", "dataid", ",", "'aux_imgs'", ":", "aux_imgs", ",", "\"rcnn_imgs\"", ":", "rcnn_imgs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREProcessor.get_relation_dict": [[48, 53], ["open", "json.loads", "f.readlines"], "methods", ["None"], ["", "def", "get_relation_dict", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "re_path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "line", "=", "f", ".", "readlines", "(", ")", "[", "0", "]", "\n", "re_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "", "return", "re_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREProcessor.get_rel2id": [[54, 66], ["open", "json.loads", "open", "f.readlines", "enumerate", "f.readlines", "json.loads.keys", "ast.literal_eval", "re2id[].append"], "methods", ["None"], ["", "def", "get_rel2id", "(", "self", ",", "train_path", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "re_path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "line", "=", "f", ".", "readlines", "(", ")", "[", "0", "]", "\n", "re_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "", "re2id", "=", "{", "key", ":", "[", "]", "for", "key", "in", "re_dict", ".", "keys", "(", ")", "}", "\n", "with", "open", "(", "train_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "line", "=", "ast", ".", "literal_eval", "(", "line", ")", "# str to dict", "\n", "assert", "line", "[", "'relation'", "]", "in", "re2id", "\n", "re2id", "[", "line", "[", "'relation'", "]", "]", ".", "append", "(", "i", ")", "\n", "", "", "return", "re2id", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREDataset.__init__": [[69, 85], ["dataset.MMREDataset.processor.load_from_file", "dataset.MMREDataset.processor.get_relation_dict"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertProcessor.load_from_file", "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREProcessor.get_relation_dict"], ["    ", "def", "__init__", "(", "self", ",", "processor", ",", "transform", ",", "img_path", "=", "None", ",", "aux_img_path", "=", "None", ",", "max_seq", "=", "40", ",", "aux_size", "=", "128", ",", "rcnn_size", "=", "64", ",", "mode", "=", "\"train\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "processor", "=", "processor", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "max_seq", "=", "max_seq", "\n", "self", ".", "img_path", "=", "img_path", "[", "mode", "]", "if", "img_path", "is", "not", "None", "else", "img_path", "\n", "self", ".", "aux_img_path", "=", "aux_img_path", "[", "mode", "]", "if", "aux_img_path", "is", "not", "None", "else", "aux_img_path", "\n", "self", ".", "rcnn_img_path", "=", "'data'", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "data_dict", "=", "self", ".", "processor", ".", "load_from_file", "(", "mode", ")", "\n", "self", ".", "re_dict", "=", "self", ".", "processor", ".", "get_relation_dict", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "processor", ".", "tokenizer", "\n", "self", ".", "clip_processor", "=", "self", ".", "processor", ".", "clip_processor", "\n", "self", ".", "aux_processor", "=", "self", ".", "processor", ".", "aux_processor", "\n", "self", ".", "rcnn_processor", "=", "self", ".", "processor", ".", "rcnn_processor", "\n", "self", ".", "aux_size", "=", "aux_size", "\n", "self", ".", "rcnn_size", "=", "rcnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREDataset.__len__": [[86, 88], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_dict", "[", "'words'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.dataset.MMREDataset.__getitem__": [[89, 170], ["range", "dataset.MMREDataset.tokenizer.encode_plus", "len", "extend_word_list.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "extend_word_list.append", "extend_word_list.append", "extend_word_list.append", "extend_word_list.append", "os.path.join", "PIL.Image.open().convert", "[].squeeze", "range", "range", "torch.stack", "os.path.join", "PIL.Image.open().convert", "[].squeeze", "imgid.split", "min", "PIL.Image.open().convert", "[].squeeze", "torch.stack.append", "torch.stack.append", "len", "range", "range", "torch.stack", "torch.tensor", "PIL.Image.open", "os.path.join", "len", "len", "torch.zeros", "min", "PIL.Image.open().convert", "[].squeeze", "torch.stack.append", "torch.stack.append", "len", "torch.tensor", "dataset.MMREDataset.clip_processor", "PIL.Image.open", "PIL.Image.open", "os.path.join", "len", "len", "torch.zeros", "dataset.MMREDataset.clip_processor", "dataset.MMREDataset.aux_processor", "PIL.Image.open", "dataset.MMREDataset.rcnn_processor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "word_list", ",", "relation", ",", "head_d", ",", "tail_d", ",", "imgid", "=", "self", ".", "data_dict", "[", "'words'", "]", "[", "idx", "]", ",", "self", ".", "data_dict", "[", "'relations'", "]", "[", "idx", "]", ",", "self", ".", "data_dict", "[", "'heads'", "]", "[", "idx", "]", ",", "self", ".", "data_dict", "[", "'tails'", "]", "[", "idx", "]", ",", "self", ".", "data_dict", "[", "'imgids'", "]", "[", "idx", "]", "\n", "item_id", "=", "self", ".", "data_dict", "[", "'dataid'", "]", "[", "idx", "]", "\n", "# [CLS] ... <s> head </s> ... <o> tail <o/> .. [SEP]", "\n", "head_pos", ",", "tail_pos", "=", "head_d", "[", "'pos'", "]", ",", "tail_d", "[", "'pos'", "]", "\n", "# insert <s> <s/> <o> <o/>", "\n", "extend_word_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "word_list", ")", ")", ":", "\n", "            ", "if", "i", "==", "head_pos", "[", "0", "]", ":", "\n", "                ", "extend_word_list", ".", "append", "(", "'<s>'", ")", "\n", "", "if", "i", "==", "head_pos", "[", "1", "]", ":", "\n", "                ", "extend_word_list", ".", "append", "(", "'</s>'", ")", "\n", "", "if", "i", "==", "tail_pos", "[", "0", "]", ":", "\n", "                ", "extend_word_list", ".", "append", "(", "'<o>'", ")", "\n", "", "if", "i", "==", "tail_pos", "[", "1", "]", ":", "\n", "                ", "extend_word_list", ".", "append", "(", "'</o>'", ")", "\n", "", "extend_word_list", ".", "append", "(", "word_list", "[", "i", "]", ")", "\n", "", "extend_word_list", "=", "\" \"", ".", "join", "(", "extend_word_list", ")", "\n", "encode_dict", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "text", "=", "extend_word_list", ",", "max_length", "=", "self", ".", "max_seq", ",", "truncation", "=", "True", ",", "padding", "=", "'max_length'", ")", "\n", "input_ids", ",", "token_type_ids", ",", "attention_mask", "=", "encode_dict", "[", "'input_ids'", "]", ",", "encode_dict", "[", "'token_type_ids'", "]", ",", "encode_dict", "[", "'attention_mask'", "]", "\n", "input_ids", ",", "token_type_ids", ",", "attention_mask", "=", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "token_type_ids", ")", ",", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "\n", "re_label", "=", "self", ".", "re_dict", "[", "relation", "]", "# label to id", "\n", "\n", "# image process", "\n", "if", "self", ".", "img_path", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_path", ",", "imgid", ")", "\n", "image", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "self", ".", "clip_processor", "(", "images", "=", "image", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "", "except", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_path", ",", "'inf.png'", ")", "\n", "image", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "self", ".", "clip_processor", "(", "images", "=", "image", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "", "if", "self", ".", "aux_img_path", "is", "not", "None", ":", "\n", "# detected object img", "\n", "                ", "aux_imgs", "=", "[", "]", "\n", "aux_img_paths", "=", "[", "]", "\n", "imgid", "=", "imgid", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "if", "item_id", "in", "self", ".", "data_dict", "[", "'aux_imgs'", "]", ":", "\n", "                    ", "aux_img_paths", "=", "self", ".", "data_dict", "[", "'aux_imgs'", "]", "[", "item_id", "]", "\n", "aux_img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "aux_img_path", ",", "path", ")", "for", "path", "in", "aux_img_paths", "]", "\n", "\n", "# select 3 img", "\n", "", "for", "i", "in", "range", "(", "min", "(", "3", ",", "len", "(", "aux_img_paths", ")", ")", ")", ":", "\n", "                    ", "aux_img", "=", "Image", ".", "open", "(", "aux_img_paths", "[", "i", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "aux_img", "=", "self", ".", "aux_processor", "(", "images", "=", "aux_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "aux_imgs", ".", "append", "(", "aux_img", ")", "\n", "\n", "# padding", "\n", "", "for", "i", "in", "range", "(", "3", "-", "len", "(", "aux_imgs", ")", ")", ":", "\n", "                    ", "aux_imgs", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "self", ".", "aux_size", ",", "self", ".", "aux_size", ")", ")", ")", "\n", "\n", "", "aux_imgs", "=", "torch", ".", "stack", "(", "aux_imgs", ",", "dim", "=", "0", ")", "\n", "assert", "len", "(", "aux_imgs", ")", "==", "3", "\n", "\n", "if", "self", ".", "rcnn_img_path", "is", "not", "None", ":", "\n", "                    ", "rcnn_imgs", "=", "[", "]", "\n", "rcnn_img_paths", "=", "[", "]", "\n", "if", "imgid", "in", "self", ".", "data_dict", "[", "'rcnn_imgs'", "]", ":", "\n", "                        ", "rcnn_img_paths", "=", "self", ".", "data_dict", "[", "'rcnn_imgs'", "]", "[", "imgid", "]", "\n", "rcnn_img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "rcnn_img_path", ",", "path", ")", "for", "path", "in", "rcnn_img_paths", "]", "\n", "\n", "# select 3 img", "\n", "", "for", "i", "in", "range", "(", "min", "(", "3", ",", "len", "(", "rcnn_img_paths", ")", ")", ")", ":", "\n", "                        ", "rcnn_img", "=", "Image", ".", "open", "(", "rcnn_img_paths", "[", "i", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "rcnn_img", "=", "self", ".", "rcnn_processor", "(", "images", "=", "rcnn_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "rcnn_imgs", ".", "append", "(", "rcnn_img", ")", "\n", "\n", "# padding", "\n", "", "for", "i", "in", "range", "(", "3", "-", "len", "(", "rcnn_imgs", ")", ")", ":", "\n", "                        ", "rcnn_imgs", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "self", ".", "rcnn_size", ",", "self", ".", "rcnn_size", ")", ")", ")", "\n", "\n", "", "rcnn_imgs", "=", "torch", ".", "stack", "(", "rcnn_imgs", ",", "dim", "=", "0", ")", "\n", "assert", "len", "(", "rcnn_imgs", ")", "==", "3", "\n", "return", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "torch", ".", "tensor", "(", "re_label", ")", ",", "image", ",", "aux_imgs", ",", "rcnn_imgs", "\n", "\n", "", "return", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "torch", ".", "tensor", "(", "re_label", ")", ",", "image", ",", "aux_imgs", "\n", "\n", "\n", "", "", "return", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "torch", ".", "tensor", "(", "re_label", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertProcessor.__init__": [[12, 18], ["transformers.BertTokenizer.from_pretrained"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ",", "bert_name", ",", "clip_processor", "=", "None", ",", "aux_processor", "=", "None", ",", "rcnn_processor", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_name", ",", "do_lower_case", "=", "True", ")", "\n", "self", ".", "clip_processor", "=", "clip_processor", "\n", "self", ".", "aux_processor", "=", "aux_processor", "\n", "self", ".", "rcnn_processor", "=", "rcnn_processor", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertProcessor.load_from_file": [[19, 51], ["logger.info", "torch.load", "torch.load", "open", "f.readlines", "len", "len", "len", "len", "len", "len", "line.startswith", "imgs.append", "raw_word.append", "raw_target.append", "raw_words.append", "raw_targets.append", "line.strip().split", "line.split", "line.split", "line.strip"], "methods", ["None"], ["", "def", "load_from_file", "(", "self", ",", "mode", "=", "\"train\"", ")", ":", "\n", "        ", "load_file", "=", "self", ".", "data_path", "[", "mode", "]", "\n", "logger", ".", "info", "(", "\"Loading data from {}\"", ".", "format", "(", "load_file", ")", ")", "\n", "with", "open", "(", "load_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "raw_words", ",", "raw_targets", "=", "[", "]", ",", "[", "]", "\n", "raw_word", ",", "raw_target", "=", "[", "]", ",", "[", "]", "\n", "imgs", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "if", "line", ".", "startswith", "(", "\"IMGID:\"", ")", ":", "\n", "                    ", "img_id", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'IMGID:'", ")", "[", "1", "]", "+", "'.jpg'", "\n", "imgs", ".", "append", "(", "img_id", ")", "\n", "continue", "\n", "", "if", "line", "!=", "\"\\n\"", ":", "\n", "                    ", "raw_word", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", "[", "0", "]", ")", "\n", "label", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "1", "]", "[", ":", "-", "1", "]", "\n", "if", "'OTHER'", "in", "label", ":", "\n", "                        ", "label", "=", "label", "[", ":", "2", "]", "+", "'MISC'", "\n", "", "raw_target", ".", "append", "(", "label", ")", "\n", "", "else", ":", "\n", "                    ", "raw_words", ".", "append", "(", "raw_word", ")", "\n", "raw_targets", ".", "append", "(", "raw_target", ")", "\n", "raw_word", ",", "raw_target", "=", "[", "]", ",", "[", "]", "\n", "\n", "", "", "", "assert", "len", "(", "raw_words", ")", "==", "len", "(", "raw_targets", ")", "==", "len", "(", "imgs", ")", ",", "\"{}, {}, {}\"", ".", "format", "(", "len", "(", "raw_words", ")", ",", "len", "(", "raw_targets", ")", ",", "len", "(", "imgs", ")", ")", "\n", "aux_imgs", "=", "None", "\n", "aux_path", "=", "self", ".", "data_path", "[", "mode", "+", "\"_auximgs\"", "]", "\n", "aux_imgs", "=", "torch", ".", "load", "(", "aux_path", ")", "\n", "\n", "rcnn_imgs", "=", "torch", ".", "load", "(", "self", ".", "data_path", "[", "'img2crop'", "]", ")", "\n", "\n", "return", "{", "\"words\"", ":", "raw_words", ",", "\"targets\"", ":", "raw_targets", ",", "\"imgs\"", ":", "imgs", ",", "\"aux_imgs\"", ":", "aux_imgs", ",", "\"rcnn_imgs\"", ":", "rcnn_imgs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertDataset.__init__": [[54, 71], ["processor.load_from_file"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertProcessor.load_from_file"], ["    ", "def", "__init__", "(", "self", ",", "processor", ",", "label_mapping", ",", "transform", ",", "img_path", "=", "None", ",", "aux_path", "=", "None", ",", "max_seq", "=", "40", ",", "ignore_idx", "=", "-", "100", ",", "aux_size", "=", "128", ",", "rcnn_size", "=", "64", ",", "mode", "=", "'train'", ")", "->", "None", ":", "\n", "        ", "self", ".", "processor", "=", "processor", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "data_dict", "=", "processor", ".", "load_from_file", "(", "mode", ")", "\n", "self", ".", "tokenizer", "=", "processor", ".", "tokenizer", "\n", "self", ".", "label_mapping", "=", "label_mapping", "\n", "self", ".", "max_seq", "=", "max_seq", "\n", "self", ".", "ignore_idx", "=", "ignore_idx", "\n", "self", ".", "img_path", "=", "img_path", "\n", "self", ".", "aux_img_path", "=", "aux_path", "[", "mode", "]", "if", "aux_path", "is", "not", "None", "else", "None", "\n", "self", ".", "rcnn_img_path", "=", "'data'", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "clip_processor", "=", "self", ".", "processor", ".", "clip_processor", "\n", "self", ".", "aux_processor", "=", "self", ".", "processor", ".", "aux_processor", "\n", "self", ".", "rcnn_processor", "=", "self", ".", "processor", ".", "rcnn_processor", "\n", "self", ".", "aux_size", "=", "aux_size", "\n", "self", ".", "rcnn_size", "=", "rcnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertDataset.__len__": [[72, 74], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_dict", "[", "'words'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.processor.datasets.MMPNERBertDataset.__getitem__": [[75, 147], ["enumerate", "datasets.MMPNERBertDataset.tokenizer.encode_plus", "datasets.MMPNERBertDataset.tokenizer.tokenize", "tokens.extend", "range", "len", "len", "len", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "os.path.join", "PIL.Image.open().convert", "[].squeeze", "range", "range", "torch.stack", "labels.append", "labels.append", "os.path.join", "PIL.Image.open().convert", "[].squeeze", "min", "PIL.Image.open().convert", "[].squeeze", "torch.stack.append", "torch.stack.append", "len", "range", "range", "torch.stack", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "PIL.Image.open", "os.path.join", "len", "len", "torch.zeros", "img.split", "min", "PIL.Image.open().convert", "[].squeeze", "torch.stack.append", "torch.stack.append", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "datasets.MMPNERBertDataset.clip_processor", "PIL.Image.open", "PIL.Image.open", "os.path.join", "len", "len", "torch.zeros", "datasets.MMPNERBertDataset.clip_processor", "datasets.MMPNERBertDataset.aux_processor", "PIL.Image.open", "datasets.MMPNERBertDataset.rcnn_processor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "word_list", ",", "label_list", ",", "img", "=", "self", ".", "data_dict", "[", "'words'", "]", "[", "idx", "]", ",", "self", ".", "data_dict", "[", "'targets'", "]", "[", "idx", "]", ",", "self", ".", "data_dict", "[", "'imgs'", "]", "[", "idx", "]", "\n", "tokens", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "word_list", ")", ":", "\n", "            ", "token", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokens", ".", "extend", "(", "token", ")", "\n", "label", "=", "label_list", "[", "i", "]", "\n", "for", "m", "in", "range", "(", "len", "(", "token", ")", ")", ":", "\n", "                ", "if", "m", "==", "0", ":", "\n", "                    ", "labels", ".", "append", "(", "self", ".", "label_mapping", "[", "label", "]", ")", "\n", "", "else", ":", "\n", "                    ", "labels", ".", "append", "(", "self", ".", "label_mapping", "[", "\"X\"", "]", ")", "\n", "", "", "", "if", "len", "(", "tokens", ")", ">=", "self", ".", "max_seq", "-", "1", ":", "\n", "            ", "tokens", "=", "tokens", "[", "0", ":", "(", "self", ".", "max_seq", "-", "2", ")", "]", "\n", "labels", "=", "labels", "[", "0", ":", "(", "self", ".", "max_seq", "-", "2", ")", "]", "\n", "\n", "", "encode_dict", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "tokens", ",", "max_length", "=", "self", ".", "max_seq", ",", "truncation", "=", "True", ",", "padding", "=", "'max_length'", ")", "\n", "input_ids", ",", "token_type_ids", ",", "attention_mask", "=", "encode_dict", "[", "'input_ids'", "]", ",", "encode_dict", "[", "'token_type_ids'", "]", ",", "encode_dict", "[", "'attention_mask'", "]", "\n", "# labels = [self.ignore_idx] + labels + [self.ignore_idx]*(self.max_seq-len(labels)-1)", "\n", "labels", "=", "[", "self", ".", "label_mapping", "[", "\"[CLS]\"", "]", "]", "+", "labels", "+", "[", "self", ".", "label_mapping", "[", "\"[SEP]\"", "]", "]", "+", "[", "self", ".", "ignore_idx", "]", "*", "(", "self", ".", "max_seq", "-", "len", "(", "labels", ")", "-", "2", ")", "\n", "\n", "if", "self", ".", "img_path", "is", "not", "None", ":", "\n", "# image process", "\n", "            ", "try", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_path", ",", "img", ")", "\n", "image", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "self", ".", "clip_processor", "(", "images", "=", "image", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "", "except", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_path", ",", "'inf.png'", ")", "\n", "image", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "self", ".", "clip_processor", "(", "images", "=", "image", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "self", ".", "aux_img_path", "is", "not", "None", ":", "\n", "                ", "aux_imgs", "=", "[", "]", "\n", "aux_img_paths", "=", "[", "]", "\n", "if", "img", "in", "self", ".", "data_dict", "[", "'aux_imgs'", "]", ":", "\n", "                    ", "aux_img_paths", "=", "self", ".", "data_dict", "[", "'aux_imgs'", "]", "[", "img", "]", "\n", "aux_img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "aux_img_path", ",", "path", ")", "for", "path", "in", "aux_img_paths", "]", "\n", "", "for", "i", "in", "range", "(", "min", "(", "3", ",", "len", "(", "aux_img_paths", ")", ")", ")", ":", "\n", "                    ", "aux_img", "=", "Image", ".", "open", "(", "aux_img_paths", "[", "i", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "aux_img", "=", "self", ".", "aux_processor", "(", "images", "=", "aux_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "aux_imgs", ".", "append", "(", "aux_img", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "3", "-", "len", "(", "aux_imgs", ")", ")", ":", "\n", "                    ", "aux_imgs", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "self", ".", "aux_size", ",", "self", ".", "aux_size", ")", ")", ")", "\n", "\n", "", "aux_imgs", "=", "torch", ".", "stack", "(", "aux_imgs", ",", "dim", "=", "0", ")", "\n", "assert", "len", "(", "aux_imgs", ")", "==", "3", "\n", "\n", "if", "self", ".", "rcnn_img_path", "is", "not", "None", ":", "\n", "                    ", "rcnn_imgs", "=", "[", "]", "\n", "rcnn_img_paths", "=", "[", "]", "\n", "img", "=", "img", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "img", "in", "self", ".", "data_dict", "[", "'rcnn_imgs'", "]", ":", "\n", "                        ", "rcnn_img_paths", "=", "self", ".", "data_dict", "[", "'rcnn_imgs'", "]", "[", "img", "]", "\n", "rcnn_img_paths", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "rcnn_img_path", ",", "path", ")", "for", "path", "in", "rcnn_img_paths", "]", "\n", "", "for", "i", "in", "range", "(", "min", "(", "3", ",", "len", "(", "rcnn_img_paths", ")", ")", ")", ":", "\n", "                        ", "rcnn_img", "=", "Image", ".", "open", "(", "rcnn_img_paths", "[", "i", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "rcnn_img", "=", "self", ".", "rcnn_processor", "(", "images", "=", "rcnn_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "rcnn_imgs", ".", "append", "(", "rcnn_img", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "3", "-", "len", "(", "rcnn_imgs", ")", ")", ":", "\n", "                        ", "rcnn_imgs", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "self", ".", "rcnn_size", ",", "self", ".", "rcnn_size", ")", ")", ")", "\n", "\n", "", "rcnn_imgs", "=", "torch", ".", "stack", "(", "rcnn_imgs", ",", "dim", "=", "0", ")", "\n", "assert", "len", "(", "rcnn_imgs", ")", "==", "3", "\n", "return", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "token_type_ids", ")", ",", "torch", ".", "tensor", "(", "attention_mask", ")", ",", "torch", ".", "tensor", "(", "labels", ")", ",", "image", ",", "aux_imgs", ",", "rcnn_imgs", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "token_type_ids", ")", ",", "torch", ".", "tensor", "(", "attention_mask", ")", ",", "torch", ".", "tensor", "(", "labels", ")", ",", "image", ",", "aux_imgs", "\n", "\n", "", "", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "token_type_ids", ")", "==", "len", "(", "attention_mask", ")", "==", "len", "(", "labels", ")", "\n", "return", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "token_type_ids", ")", ",", "torch", ".", "tensor", "(", "attention_mask", ")", ",", "torch", ".", "tensor", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics.eval_result": [[1, 47], ["len", "range", "logger.info", "float", "float", "float", "float", "float", "float"], "function", ["None"], ["def", "eval_result", "(", "true_labels", ",", "pred_result", ",", "rel2id", ",", "logger", ",", "use_name", "=", "False", ")", ":", "\n", "    ", "correct", "=", "0", "\n", "total", "=", "len", "(", "true_labels", ")", "\n", "correct_positive", "=", "0", "\n", "pred_positive", "=", "0", "\n", "gold_positive", "=", "0", "\n", "\n", "neg", "=", "-", "1", "\n", "for", "name", "in", "[", "'NA'", ",", "'na'", ",", "'no_relation'", ",", "'Other'", ",", "'Others'", ",", "'none'", ",", "'None'", "]", ":", "\n", "        ", "if", "name", "in", "rel2id", ":", "\n", "            ", "if", "use_name", ":", "\n", "                ", "neg", "=", "name", "\n", "", "else", ":", "\n", "                ", "neg", "=", "rel2id", "[", "name", "]", "\n", "", "break", "\n", "", "", "for", "i", "in", "range", "(", "total", ")", ":", "\n", "        ", "if", "use_name", ":", "\n", "            ", "golden", "=", "true_labels", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "golden", "=", "true_labels", "[", "i", "]", "\n", "\n", "", "if", "golden", "==", "pred_result", "[", "i", "]", ":", "\n", "            ", "correct", "+=", "1", "\n", "if", "golden", "!=", "neg", ":", "\n", "                ", "correct_positive", "+=", "1", "\n", "", "", "if", "golden", "!=", "neg", ":", "\n", "            ", "gold_positive", "+=", "1", "\n", "", "if", "pred_result", "[", "i", "]", "!=", "neg", ":", "\n", "            ", "pred_positive", "+=", "1", "\n", "", "", "acc", "=", "float", "(", "correct", ")", "/", "float", "(", "total", ")", "\n", "try", ":", "\n", "        ", "micro_p", "=", "float", "(", "correct_positive", ")", "/", "float", "(", "pred_positive", ")", "\n", "", "except", ":", "\n", "        ", "micro_p", "=", "0", "\n", "", "try", ":", "\n", "        ", "micro_r", "=", "float", "(", "correct_positive", ")", "/", "float", "(", "gold_positive", ")", "\n", "", "except", ":", "\n", "        ", "micro_r", "=", "0", "\n", "", "try", ":", "\n", "        ", "micro_f1", "=", "2", "*", "micro_p", "*", "micro_r", "/", "(", "micro_p", "+", "micro_r", ")", "\n", "", "except", ":", "\n", "        ", "micro_f1", "=", "0", "\n", "\n", "", "result", "=", "{", "'acc'", ":", "acc", ",", "'micro_p'", ":", "micro_p", ",", "'micro_r'", ":", "micro_r", ",", "'micro_f1'", ":", "micro_f1", "}", "\n", "logger", ".", "info", "(", "'Evaluation result: {}.'", ".", "format", "(", "result", ")", ")", "\n", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.__init__": [[11, 33], ["train.BertTrainer.multiModal_before_train", "len"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.multiModal_before_train"], ["        ", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "dev_data", "=", "dev_data", "\n", "self", ".", "test_data", "=", "test_data", "\n", "self", ".", "re_dict", "=", "re_dict", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "process", "=", "process", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "writer", "=", "writer", "\n", "self", ".", "refresh_step", "=", "2", "\n", "self", ".", "best_dev_metric", "=", "0", "\n", "self", ".", "best_test_metric", "=", "0", "\n", "self", ".", "best_dev_epoch", "=", "None", "\n", "self", ".", "best_test_epoch", "=", "None", "\n", "self", ".", "optimizer", "=", "None", "\n", "if", "self", ".", "train_data", "is", "not", "None", ":", "\n", "            ", "self", ".", "train_num_steps", "=", "len", "(", "self", ".", "train_data", ")", "*", "args", ".", "num_epochs", "\n", "", "self", ".", "step", "=", "0", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "before_multimodal_train", "(", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "step", "=", "0", "\n", "self", ".", "model", ".", "train", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.train": [[34, 140], ["train.BertTrainer.model.train", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.model.state_dict", "train.BertTrainer.model.load_state_dict", "train.BertTrainer.logger.info", "train.BertTrainer.model.load_state_dict", "train.BertTrainer.logger.info", "len", "len", "len", "len", "tqdm.tqdm.tqdm", "range", "torch.cuda.empty_cache", "pbar.close", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "len", "torch.load", "name.replace().replace", "len", "len", "len", "len", "pbar.set_description_str", "seqeval.metrics.classification_report", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "float", "train.BertTrainer.logger.info", "vision_names.append", "name.replace().replace", "train.BertTrainer._step", "loss.detach().cpu().item", "loss.backward", "train.BertTrainer.optimizer.step", "train.BertTrainer.scheduler.step", "train.BertTrainer.optimizer.zero_grad", "isinstance", "labels.to().numpy", "attention_mask.to().numpy", "enumerate", "train.BertTrainer.writer.add_scalar", "train.BertTrainer.evaluate", "train.BertTrainer.test", "name.replace", "text_names.append", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy", "enumerate", "y_true.append", "y_pred.append", "y_true_idx.append", "y_pred_idx.append", "pbar.update", "pbar.set_postfix_str", "[].split", "name.replace", "isinstance", "tup.to", "loss.detach().cpu", "labels.to", "attention_mask.to", "train.BertTrainer.label_map.items", "float", "train.BertTrainer.writer.add_scalar", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax().detach().cpu", "loss.detach", "temp_1.append", "temp_2.append", "temp_1_idx.append", "temp_2_idx.append", "[].split", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax().detach", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax", "seqeval.metrics.classification_report.split"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.train", "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer._step", "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.evaluate", "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.test", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update"], ["self", ".", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Num instance = %d\"", ",", "len", "(", "self", ".", "train_data", ")", "*", "self", ".", "args", ".", "batch_size", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Num epoch = %d\"", ",", "self", ".", "args", ".", "num_epochs", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "self", ".", "args", ".", "batch_size", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Learning rate = {}\"", ".", "format", "(", "self", ".", "args", ".", "lr", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Evaluate begin = %d\"", ",", "self", ".", "args", ".", "eval_begin_epoch", ")", "\n", "\n", "if", "self", ".", "args", ".", "load_path", "is", "not", "None", ":", "# load model from load_path", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading model from {}\"", ".", "format", "(", "self", ".", "args", ".", "load_path", ")", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "args", ".", "load_path", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Load model successful!\"", ")", "\n", "\n", "", "with", "tqdm", "(", "total", "=", "self", ".", "train_num_steps", ",", "postfix", "=", "'loss:{0:<6.5f}'", ",", "leave", "=", "False", ",", "dynamic_ncols", "=", "True", ",", "initial", "=", "self", ".", "step", ")", "as", "pbar", ":", "\n", "            ", "self", ".", "pbar", "=", "pbar", "\n", "avg_loss", "=", "0", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "args", ".", "num_epochs", "+", "1", ")", ":", "\n", "                ", "pbar", ".", "set_description_str", "(", "desc", "=", "\"Epoch {}/{}\"", ".", "format", "(", "epoch", ",", "self", ".", "args", ".", "num_epochs", ")", ")", "\n", "for", "batch", "in", "self", ".", "train_data", ":", "\n", "                    ", "self", ".", "step", "+=", "1", "\n", "batch", "=", "(", "tup", ".", "to", "(", "self", ".", "args", ".", "device", ")", "if", "isinstance", "(", "tup", ",", "torch", ".", "Tensor", ")", "else", "tup", "for", "tup", "in", "batch", ")", "\n", "(", "loss", ",", "logits", ")", ",", "labels", "=", "self", ".", "_step", "(", "batch", ",", "mode", "=", "\"train\"", ")", "\n", "avg_loss", "+=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "refresh_step", "==", "0", ":", "\n", "                        ", "avg_loss", "=", "float", "(", "avg_loss", ")", "/", "self", ".", "refresh_step", "\n", "print_output", "=", "\"loss:{:<6.5f}\"", ".", "format", "(", "avg_loss", ")", "\n", "pbar", ".", "update", "(", "self", ".", "refresh_step", ")", "\n", "pbar", ".", "set_postfix_str", "(", "print_output", ")", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                            ", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'train_loss'", ",", "scalar_value", "=", "avg_loss", ",", "global_step", "=", "self", ".", "step", ")", "# tensorbordx", "\n", "", "avg_loss", "=", "0", "\n", "\n", "", "", "if", "epoch", ">=", "self", ".", "args", ".", "eval_begin_epoch", ":", "\n", "                    ", "self", ".", "evaluate", "(", "epoch", ")", "# generator to dev.", "\n", "self", ".", "test", "(", "epoch", ")", "\n", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "self", ".", "pbar", "=", "None", "\n", "self", ".", "logger", ".", "info", "(", "\"Get best dev performance at epoch {}, best dev f1 score is {}\"", ".", "format", "(", "self", ".", "best_dev_epoch", ",", "self", ".", "best_dev_metric", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Get best test performance at epoch {}, best test f1 score is {}\"", ".", "format", "(", "self", ".", "best_test_epoch", ",", "self", ".", "best_test_metric", ")", ")", "\n", "\n", "", "", "def", "evaluate", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"***** Running evaluate *****\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Num instance = %d\"", ",", "len", "(", "self", ".", "dev_data", ")", "*", "self", ".", "args", ".", "batch_size", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "self", ".", "args", ".", "batch_size", ")", "\n", "step", "=", "0", "\n", "true_labels", ",", "pred_labels", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "with", "tqdm", "(", "total", "=", "len", "(", "self", ".", "dev_data", ")", ",", "leave", "=", "False", ",", "dynamic_ncols", "=", "True", ")", "as", "pbar", ":", "\n", "                ", "pbar", ".", "set_description_str", "(", "desc", "=", "\"Dev\"", ")", "\n", "total_loss", "=", "0", "\n", "for", "batch", "in", "self", ".", "dev_data", ":", "\n", "                    ", "step", "+=", "1", "\n", "batch", "=", "(", "tup", ".", "to", "(", "self", ".", "args", ".", "device", ")", "if", "isinstance", "(", "tup", ",", "torch", ".", "Tensor", ")", "else", "tup", "for", "tup", "in", "batch", ")", "# to cpu/cuda device", "\n", "(", "loss", ",", "logits", ")", ",", "labels", "=", "self", ".", "_step", "(", "batch", ",", "mode", "=", "\"dev\"", ")", "# logits: batch, 3", "\n", "total_loss", "+=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "preds", "=", "logits", ".", "argmax", "(", "-", "1", ")", "\n", "true_labels", ".", "extend", "(", "labels", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "pred_labels", ".", "extend", "(", "preds", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "pbar", ".", "update", "(", ")", "\n", "# evaluate done", "\n", "", "pbar", ".", "close", "(", ")", "\n", "sk_result", "=", "classification_report", "(", "y_true", "=", "true_labels", ",", "y_pred", "=", "pred_labels", ",", "labels", "=", "list", "(", "self", ".", "re_dict", ".", "values", "(", ")", ")", "[", "1", ":", "]", ",", "target_names", "=", "list", "(", "self", ".", "re_dict", ".", "keys", "(", ")", ")", "[", "1", ":", "]", ",", "digits", "=", "4", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"%s\\n\"", ",", "sk_result", ")", "\n", "result", "=", "eval_result", "(", "true_labels", ",", "pred_labels", ",", "self", ".", "re_dict", ",", "self", ".", "logger", ")", "\n", "acc", ",", "micro_f1", "=", "round", "(", "result", "[", "'acc'", "]", "*", "100", ",", "4", ")", ",", "round", "(", "result", "[", "'micro_f1'", "]", "*", "100", ",", "4", ")", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'dev_acc'", ",", "scalar_value", "=", "acc", ",", "global_step", "=", "epoch", ")", "# tensorbordx", "\n", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'dev_f1'", ",", "scalar_value", "=", "micro_f1", ",", "global_step", "=", "epoch", ")", "# tensorbordx", "\n", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'dev_loss'", ",", "scalar_value", "=", "total_loss", "/", "len", "(", "self", ".", "test_data", ")", ",", "global_step", "=", "epoch", ")", "# tensorbordx", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Epoch {}/{}, best dev f1: {}, best epoch: {}, current dev f1 score: {}, acc: {}.\"", ".", "format", "(", "epoch", ",", "self", ".", "args", ".", "num_epochs", ",", "self", ".", "best_dev_metric", ",", "self", ".", "best_dev_epoch", ",", "micro_f1", ",", "acc", ")", ")", "\n", "if", "micro_f1", ">=", "self", ".", "best_dev_metric", ":", "# this epoch get best performance", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "\"Get better performance at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "best_dev_epoch", "=", "epoch", "\n", "self", ".", "best_dev_metric", "=", "micro_f1", "# update best metric(f1 score)", "\n", "if", "self", ".", "args", ".", "save_path", "is", "not", "None", ":", "# save model", "\n", "                        ", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "self", ".", "args", ".", "save_path", "+", "\"/best_model.pth\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Save best model at {}\"", ".", "format", "(", "self", ".", "args", ".", "save_path", ")", ")", "\n", "\n", "\n", "", "", "", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "", "def", "test", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"\\n***** Running testing *****\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Num instance = %d\"", ",", "len", "(", "self", ".", "test_data", ")", "*", "self", ".", "args", ".", "batch_size", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "self", ".", "args", ".", "batch_size", ")", "\n", "\n", "if", "self", ".", "args", ".", "load_path", "is", "not", "None", ":", "# load model from load_path", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading model from {}\"", ".", "format", "(", "self", ".", "args", ".", "load_path", ")", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "args", ".", "load_path", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Load model successful!\"", ")", "\n", "", "true_labels", ",", "pred_labels", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "with", "tqdm", "(", "total", "=", "len", "(", "self", ".", "test_data", ")", ",", "leave", "=", "False", ",", "dynamic_ncols", "=", "True", ")", "as", "pbar", ":", "\n", "                ", "pbar", ".", "set_description_str", "(", "desc", "=", "\"Testing\"", ")", "\n", "total_loss", "=", "0", "\n", "for", "batch", "in", "self", ".", "test_data", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.evaluate": [[142, 208], ["train.BertTrainer.model.eval", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.model.train", "torch.no_grad", "len", "tqdm.tqdm.tqdm", "pbar.set_description_str", "pbar.close", "seqeval.metrics.classification_report", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "float", "train.BertTrainer.logger.info", "train.BertTrainer._step", "loss.detach().cpu().item", "isinstance", "labels.detach().cpu().numpy", "attention_mask.detach().cpu().numpy", "enumerate", "pbar.update", "train.BertTrainer.writer.add_scalar", "train.BertTrainer.writer.add_scalar", "train.BertTrainer.logger.info", "len", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy", "enumerate", "y_true.append", "y_pred.append", "y_true_idx.append", "y_pred_idx.append", "[].split", "torch.save", "train.BertTrainer.logger.info", "isinstance", "tup.to", "loss.detach().cpu", "labels.detach().cpu", "attention_mask.detach().cpu", "train.BertTrainer.label_map.items", "train.BertTrainer.model.state_dict", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax().detach().cpu", "loss.detach", "labels.detach", "attention_mask.detach", "temp_1.append", "temp_2.append", "temp_1_idx.append", "temp_2_idx.append", "[].split", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax().detach", "logits.argmax().detach().cpu().numpy.argmax().detach().cpu().numpy.argmax", "seqeval.metrics.classification_report.split"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.train", "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer._step", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update"], ["(", "loss", ",", "logits", ")", ",", "labels", "=", "self", ".", "_step", "(", "batch", ",", "mode", "=", "\"dev\"", ")", "# logits: batch, 3", "\n", "total_loss", "+=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "preds", "=", "logits", ".", "argmax", "(", "-", "1", ")", "\n", "true_labels", ".", "extend", "(", "labels", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "pred_labels", ".", "extend", "(", "preds", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "pbar", ".", "update", "(", ")", "\n", "# evaluate done", "\n", "", "pbar", ".", "close", "(", ")", "\n", "sk_result", "=", "classification_report", "(", "y_true", "=", "true_labels", ",", "y_pred", "=", "pred_labels", ",", "labels", "=", "list", "(", "self", ".", "re_dict", ".", "values", "(", ")", ")", "[", "1", ":", "]", ",", "target_names", "=", "list", "(", "self", ".", "re_dict", ".", "keys", "(", ")", ")", "[", "1", ":", "]", ",", "digits", "=", "4", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"%s\\n\"", ",", "sk_result", ")", "\n", "result", "=", "eval_result", "(", "true_labels", ",", "pred_labels", ",", "self", ".", "re_dict", ",", "self", ".", "logger", ")", "\n", "acc", ",", "micro_f1", "=", "round", "(", "result", "[", "'acc'", "]", "*", "100", ",", "4", ")", ",", "round", "(", "result", "[", "'micro_f1'", "]", "*", "100", ",", "4", ")", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'test_acc'", ",", "scalar_value", "=", "acc", ",", "global_step", "=", "epoch", ")", "# tensorbordx", "\n", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'test_f1'", ",", "scalar_value", "=", "micro_f1", ",", "global_step", "=", "epoch", ")", "# tensorbordx", "\n", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "'test_loss'", ",", "scalar_value", "=", "total_loss", "/", "len", "(", "self", ".", "test_data", ")", ",", "global_step", "=", "epoch", ")", "# tensorbordx", "\n", "", "total_loss", "=", "0", "\n", "############", "\n", "self", ".", "logger", ".", "info", "(", "\"Epoch {}/{}, best test f1: {}, best epoch: {}, current test f1 score: {}, acc: {}\"", ".", "format", "(", "epoch", ",", "self", ".", "args", ".", "num_epochs", ",", "self", ".", "best_test_metric", ",", "self", ".", "best_test_epoch", ",", "micro_f1", ",", "acc", ")", ")", "\n", "if", "micro_f1", ">=", "self", ".", "best_test_metric", ":", "# this epoch get best performance", "\n", "                    ", "self", ".", "best_test_metric", "=", "micro_f1", "\n", "self", ".", "best_test_epoch", "=", "epoch", "\n", "\n", "", "", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "", "def", "_step", "(", "self", ",", "batch", ",", "mode", "=", "\"train\"", ")", ":", "\n", "        ", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "labels", ",", "images", ",", "aux_imgs", ",", "rcnn_imgs", "=", "batch", "\n", "outputs", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "labels", "=", "labels", ",", "images", "=", "images", ",", "aux_imgs", "=", "aux_imgs", ",", "rcnn_imgs", "=", "rcnn_imgs", ")", "\n", "return", "outputs", ",", "labels", "\n", "\n", "\n", "", "def", "before_multimodal_train", "(", "self", ")", ":", "\n", "        ", "optimizer_grouped_parameters", "=", "[", "]", "\n", "params", "=", "{", "'lr'", ":", "self", ".", "args", ".", "lr", ",", "'weight_decay'", ":", "1e-2", "}", "\n", "params", "[", "'params'", "]", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'model'", "in", "name", ":", "\n", "                ", "params", "[", "'params'", "]", ".", "append", "(", "param", ")", "\n", "", "", "optimizer_grouped_parameters", ".", "append", "(", "params", ")", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "\n", "self", ".", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_ratio", "*", "self", ".", "train_num_steps", ",", "\n", "num_training_steps", "=", "self", ".", "train_num_steps", ")", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "# for name, par in self.model.named_parameters():", "\n", "#     print(name, par.requires_grad)", "", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.test": [[210, 275], ["train.BertTrainer.model.eval", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "train.BertTrainer.model.train", "train.BertTrainer.logger.info", "train.BertTrainer.model.load_state_dict", "train.BertTrainer.logger.info", "torch.no_grad", "len", "torch.load", "tqdm.tqdm.tqdm", "pbar.set_description_str", "pbar.close", "seqeval.metrics.classification_report", "train.BertTrainer.logger.info", "train.BertTrainer.logger.info", "float", "train.BertTrainer.logger.info", "train.BertTrainer._step", "loss.detach().cpu().item", "isinstance", "labels.detach().cpu().numpy", "attention_mask.detach().cpu().numpy", "enumerate", "pbar.update", "train.BertTrainer.writer.add_scalar", "train.BertTrainer.writer.add_scalar", "len", "logits.argmax().detach().cpu().tolist.argmax().detach().cpu().tolist.argmax().detach().cpu().tolist", "enumerate", "y_true.append", "y_pred.append", "y_true_idx.append", "y_pred_idx.append", "[].split", "isinstance", "tup.to", "loss.detach().cpu", "labels.detach().cpu", "attention_mask.detach().cpu", "train.BertTrainer.label_map.items", "logits.argmax().detach().cpu().tolist.argmax().detach().cpu().tolist.argmax().detach().cpu", "len", "loss.detach", "labels.detach", "attention_mask.detach", "temp_1.append", "temp_2.append", "temp_1_idx.append", "temp_2_idx.append", "[].split", "logits.argmax().detach().cpu().tolist.argmax().detach().cpu().tolist.argmax().detach", "logits.argmax().detach().cpu().tolist.argmax().detach().cpu().tolist.argmax", "seqeval.metrics.classification_report.split"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.train", "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer._step", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer._step": [[277, 282], ["train.BertTrainer.model"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.before_multimodal_train": [[176, 190], ["train.BertTrainer.model.named_parameters", "optimizer_grouped_parameters.append", "torch.optim.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "train.BertTrainer.model.to", "params[].append"], "methods", ["None"], ["", "def", "before_multimodal_train", "(", "self", ")", ":", "\n", "        ", "optimizer_grouped_parameters", "=", "[", "]", "\n", "params", "=", "{", "'lr'", ":", "self", ".", "args", ".", "lr", ",", "'weight_decay'", ":", "1e-2", "}", "\n", "params", "[", "'params'", "]", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'model'", "in", "name", ":", "\n", "                ", "params", "[", "'params'", "]", ".", "append", "(", "param", ")", "\n", "", "", "optimizer_grouped_parameters", ".", "append", "(", "params", ")", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "\n", "self", ".", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_ratio", "*", "self", ".", "train_num_steps", ",", "\n", "num_training_steps", "=", "self", ".", "train_num_steps", ")", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "# for name, par in self.model.named_parameters():", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics.Seq2SeqSpanMetric.__init__": [[5, 16], ["None"], "methods", ["None"], ["pred_positive", "=", "0", "\n", "gold_positive", "=", "0", "\n", "\n", "neg", "=", "-", "1", "\n", "for", "name", "in", "[", "'NA'", ",", "'na'", ",", "'no_relation'", ",", "'Other'", ",", "'Others'", ",", "'none'", ",", "'None'", "]", ":", "\n", "        ", "if", "name", "in", "rel2id", ":", "\n", "            ", "if", "use_name", ":", "\n", "                ", "neg", "=", "name", "\n", "", "else", ":", "\n", "                ", "neg", "=", "rel2id", "[", "name", "]", "\n", "", "break", "\n", "", "", "for", "i", "in", "range", "(", "total", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics.Seq2SeqSpanMetric.evaluate": [[17, 56], ["pred.size", "pred.flip().eq().cumsum().long", "tgt_tokens.flip().eq().cumsum().long", "pred.flip().eq().cumsum().long.flip().eq().sum", "tgt_tokens.flip().eq().cumsum().long.flip().eq().sum", "enumerate", "zip", "len", "pred_spans.append", "metrics._compute_tp_fn_fp", "pred.flip().eq().cumsum", "tgt_tokens.flip().eq().cumsum", "pred.flip().eq().cumsum().long.flip().eq", "tgt_tokens.flip().eq().cumsum().long.flip().eq", "pred.tolist", "int", "pairs.copy", "pred.flip().eq", "tgt_tokens.flip().eq", "pred.flip().eq().cumsum().long.flip", "tgt_tokens.flip().eq().cumsum().long.flip", "tgt_tokens[].eq().sum().item", "cur_pair.append", "pred.flip", "tgt_tokens.flip", "tgt_tokens[].eq().sum", "all", "len", "all", "len", "pairs.append", "pairs.append", "tgt_tokens[].eq", "len", "tuple", "tuple", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics._compute_tp_fn_fp"], ["        ", "if", "use_name", ":", "\n", "            ", "golden", "=", "true_labels", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "golden", "=", "true_labels", "[", "i", "]", "\n", "\n", "", "if", "golden", "==", "pred_result", "[", "i", "]", ":", "\n", "            ", "correct", "+=", "1", "\n", "if", "golden", "!=", "neg", ":", "\n", "                ", "correct_positive", "+=", "1", "\n", "", "", "if", "golden", "!=", "neg", ":", "\n", "            ", "gold_positive", "+=", "1", "\n", "", "if", "pred_result", "[", "i", "]", "!=", "neg", ":", "\n", "            ", "pred_positive", "+=", "1", "\n", "", "", "acc", "=", "float", "(", "correct", ")", "/", "float", "(", "total", ")", "\n", "try", ":", "\n", "        ", "micro_p", "=", "float", "(", "correct_positive", ")", "/", "float", "(", "pred_positive", ")", "\n", "", "except", ":", "\n", "        ", "micro_p", "=", "0", "\n", "", "try", ":", "\n", "        ", "micro_r", "=", "float", "(", "correct_positive", ")", "/", "float", "(", "gold_positive", ")", "\n", "", "except", ":", "\n", "        ", "micro_r", "=", "0", "\n", "", "try", ":", "\n", "        ", "micro_f1", "=", "2", "*", "micro_p", "*", "micro_r", "/", "(", "micro_p", "+", "micro_r", ")", "\n", "", "except", ":", "\n", "        ", "micro_f1", "=", "0", "\n", "\n", "", "result", "=", "{", "'acc'", ":", "acc", ",", "'micro_p'", ":", "micro_p", ",", "'micro_r'", ":", "micro_r", ",", "'micro_f1'", ":", "micro_f1", "}", "\n", "logger", ".", "info", "(", "'Evaluation result: {}.'", ".", "format", "(", "result", ")", ")", "\n", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics.Seq2SeqSpanMetric.get_metric": [[57, 71], ["metrics._compute_f_pre_rec", "round", "round", "round", "round"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics._compute_f_pre_rec"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics._compute_f_pre_rec": [[72, 85], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.metrics._compute_tp_fn_fp": [[87, 110], ["ps.copy.copy", "isinstance", "isinstance", "ts.keys", "sum", "min", "max", "max", "ps.copy.values", "tuple", "tuple", "ps.copy.pop", "list", "list"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.multiModal_before_train": [[284, 319], ["train.BertTrainer.model.named_parameters", "parameters.append", "train.BertTrainer.model.named_parameters", "parameters.append", "train.BertTrainer.model.named_parameters", "parameters.append", "torch.optim.AdamW", "train.BertTrainer.model.to", "transformers.optimization.get_linear_schedule_with_warmup", "print", "params[].append", "print", "params[].append", "name.startswith", "params[].append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.unimo_model.UnimoREModel.__init__": [[14, 52], ["torch.nn.Module.__init__", "print", "print", "modeling_unimo.UnimoModel", "unimo_model.UnimoREModel.model.state_dict", "unimo_model.UnimoREModel.model.load_state_dict", "unimo_model.UnimoREModel.model.resize_token_embeddings", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "len", "len", "len", "len", "len", "name.replace().replace", "len", "len", "len", "len", "vision_names.append", "name.replace().replace", "name.replace", "text_names.append", "name.replace"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.resize_token_embeddings"], ["    ", "def", "__init__", "(", "self", ",", "num_labels", ",", "tokenizer", ",", "args", ",", "vision_config", ",", "text_config", ",", "clip_model_dict", ",", "bert_model_dict", ")", ":", "\n", "        ", "super", "(", "UnimoREModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "print", "(", "vision_config", ")", "\n", "print", "(", "text_config", ")", "\n", "self", ".", "vision_config", "=", "vision_config", "\n", "self", ".", "text_config", "=", "text_config", "\n", "\n", "# for re", "\n", "vision_config", ".", "device", "=", "args", ".", "device", "\n", "self", ".", "model", "=", "UnimoModel", "(", "vision_config", ",", "text_config", ")", "\n", "\n", "# test load:", "\n", "vision_names", ",", "text_names", "=", "[", "]", ",", "[", "]", "\n", "model_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "for", "name", "in", "model_dict", ":", "\n", "            ", "if", "'vision'", "in", "name", ":", "\n", "                ", "clip_name", "=", "name", ".", "replace", "(", "'vision_'", ",", "''", ")", ".", "replace", "(", "'model.'", ",", "''", ")", "\n", "if", "clip_name", "in", "clip_model_dict", ":", "\n", "                    ", "vision_names", ".", "append", "(", "clip_name", ")", "\n", "model_dict", "[", "name", "]", "=", "clip_model_dict", "[", "clip_name", "]", "\n", "", "", "elif", "'text'", "in", "name", ":", "\n", "                ", "text_name", "=", "name", ".", "replace", "(", "'text_'", ",", "''", ")", ".", "replace", "(", "'model.'", ",", "''", ")", "\n", "if", "text_name", "in", "bert_model_dict", ":", "\n", "                    ", "text_names", ".", "append", "(", "text_name", ")", "\n", "model_dict", "[", "name", "]", "=", "bert_model_dict", "[", "text_name", "]", "\n", "", "", "", "assert", "len", "(", "vision_names", ")", "==", "len", "(", "clip_model_dict", ")", "and", "len", "(", "text_names", ")", "==", "len", "(", "bert_model_dict", ")", ",", "(", "len", "(", "vision_names", ")", ",", "len", "(", "text_names", ")", ",", "len", "(", "clip_model_dict", ")", ",", "len", "(", "bert_model_dict", ")", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "text_config", ".", "hidden_size", "*", "2", ",", "num_labels", ")", "\n", "self", ".", "head_start", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\"<s>\"", ")", "\n", "self", ".", "tail_start", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\"<o>\"", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.unimo_model.UnimoREModel.forward": [[53, 89], ["input_ids.size", "unimo_model.UnimoREModel.model", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "entity_hidden_state.to.to.to", "unimo_model.UnimoREModel.classifier", "input_ids[].eq().nonzero().item", "input_ids[].eq().nonzero().item", "last_hidden_state[].squeeze", "last_hidden_state[].squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "input_ids[].eq().nonzero", "input_ids[].eq().nonzero", "labels.view", "input_ids[].eq", "input_ids[].eq"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "images", "=", "None", ",", "\n", "aux_imgs", "=", "None", ",", "\n", "rcnn_imgs", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "output", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "\n", "pixel_values", "=", "images", ",", "\n", "aux_values", "=", "aux_imgs", ",", "\n", "rcnn_values", "=", "rcnn_imgs", ",", "\n", "return_dict", "=", "True", ",", ")", "\n", "\n", "last_hidden_state", ",", "pooler_output", "=", "output", ".", "last_hidden_state", ",", "output", ".", "pooler_output", "\n", "bsz", ",", "seq_len", ",", "hidden_size", "=", "last_hidden_state", ".", "shape", "\n", "entity_hidden_state", "=", "torch", ".", "Tensor", "(", "bsz", ",", "2", "*", "hidden_size", ")", "# batch, 2*hidden", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "head_idx", "=", "input_ids", "[", "i", "]", ".", "eq", "(", "self", ".", "head_start", ")", ".", "nonzero", "(", ")", ".", "item", "(", ")", "\n", "tail_idx", "=", "input_ids", "[", "i", "]", ".", "eq", "(", "self", ".", "tail_start", ")", ".", "nonzero", "(", ")", ".", "item", "(", ")", "\n", "head_hidden", "=", "last_hidden_state", "[", "i", ",", "head_idx", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "tail_hidden", "=", "last_hidden_state", "[", "i", ",", "tail_idx", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "entity_hidden_state", "[", "i", "]", "=", "torch", ".", "cat", "(", "[", "head_hidden", ",", "tail_hidden", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "entity_hidden_state", "=", "entity_hidden_state", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "entity_hidden_state", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "return", "loss_fn", "(", "logits", ",", "labels", ".", "view", "(", "-", "1", ")", ")", ",", "logits", "\n", "", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPOutput.to_tuple": [[121, 125], ["tuple", "getattr().to_tuple", "modeling_clip.CLIPOutput.keys", "getattr"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.to_tuple"], ["def", "to_tuple", "(", "self", ")", "->", "Tuple", "[", "Any", "]", ":", "\n", "        ", "return", "tuple", "(", "\n", "self", "[", "k", "]", "if", "k", "not", "in", "[", "\"text_model_output\"", ",", "\"vision_model_output\"", "]", "else", "getattr", "(", "self", ",", "k", ")", ".", "to_tuple", "(", ")", "\n", "for", "k", "in", "self", ".", "keys", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionEmbeddings.__init__": [[129, 153], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_clip.CLIPVisionEmbeddings.register_buffer", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_clip.CLIPVisionEmbeddings.register_buffer", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_clip.CLIPVisionEmbeddings.register_buffer", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "CLIPVisionConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "embed_dim", "=", "config", ".", "hidden_size", "\n", "self", ".", "image_size", "=", "config", ".", "image_size", "\n", "self", ".", "patch_size", "=", "config", ".", "patch_size", "\n", "\n", "self", ".", "class_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "embed_dim", ")", ")", "\n", "\n", "self", ".", "patch_embedding", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "3", ",", "out_channels", "=", "self", ".", "embed_dim", ",", "kernel_size", "=", "self", ".", "patch_size", ",", "stride", "=", "self", ".", "patch_size", ",", "bias", "=", "False", "\n", ")", "\n", "\n", "self", ".", "num_patches", "=", "(", "self", ".", "image_size", "//", "self", ".", "patch_size", ")", "**", "2", "\n", "self", ".", "num_positions", "=", "self", ".", "num_patches", "+", "1", "\n", "self", ".", "position_embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "num_positions", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "register_buffer", "(", "\"position_ids\"", ",", "torch", ".", "arange", "(", "self", ".", "num_positions", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n", "# lilei:", "\n", "self", ".", "aux_position_embedding", "=", "nn", ".", "Embedding", "(", "48", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "register_buffer", "(", "\"aux_position_ids\"", ",", "torch", ".", "arange", "(", "48", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n", "self", ".", "rcnn_position_embedding", "=", "nn", ".", "Embedding", "(", "12", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "register_buffer", "(", "\"rcnn_position_ids\"", ",", "torch", ".", "arange", "(", "12", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionEmbeddings.forward": [[154, 186], ["modeling_clip.CLIPVisionEmbeddings.class_embedding.expand", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_clip.CLIPVisionEmbeddings.patch_embedding", "aux_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose().flatten", "torch.stack.append", "torch.stack.append", "modeling_clip.CLIPVisionEmbeddings.aux_position_embedding", "modeling_clip.CLIPVisionEmbeddings.patch_embedding", "rcnn_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose().flatten", "torch.stack.append", "torch.stack.append", "modeling_clip.CLIPVisionEmbeddings.rcnn_position_embedding", "aux_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose", "rcnn_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose", "aux_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten", "rcnn_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pixel_values", ",", "aux_embeddings", "=", "None", ",", "rcnn_embeddings", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "pixel_values", ".", "shape", "[", "0", "]", "\n", "# patch_embeds = self.patch_embedding(pixel_values)  # shape = [*, width, grid, grid]", "\n", "# patch_embeds = patch_embeds.flatten(2).transpose(1, 2)  # shape = [*, grid*grid, width]", "\n", "\n", "class_embeds", "=", "self", ".", "class_embedding", ".", "expand", "(", "batch_size", ",", "1", ",", "-", "1", ")", "\n", "# lilei", "\n", "embeddings", "=", "class_embeds", "\n", "# embeddings = torch.cat([class_embeds, patch_embeds], dim=1)", "\n", "# embeddings = embeddings + self.position_embedding(self.position_ids)", "\n", "\n", "# lilei:", "\n", "if", "aux_embeddings", "is", "not", "None", ":", "\n", "            ", "aux_embeds", "=", "[", "]", "\n", "for", "aux_embedding", "in", "aux_embeddings", ":", "\n", "                ", "aux_embed", "=", "self", ".", "patch_embedding", "(", "aux_embedding", ")", "\n", "aux_embed", "=", "aux_embed", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "flatten", "(", "0", ",", "1", ")", "# 3*16, 768 3\u4e2a\u5b50\u56fe", "\n", "aux_embeds", ".", "append", "(", "aux_embed", ")", "\n", "", "aux_embeds", "=", "torch", ".", "stack", "(", "aux_embeds", ")", "# bsz, 48, 768", "\n", "aux_embeds", "=", "aux_embeds", "+", "self", ".", "aux_position_embedding", "(", "self", ".", "aux_position_ids", ")", "\n", "embeddings", "=", "torch", ".", "cat", "(", "(", "embeddings", ",", "aux_embeds", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "rcnn_embeddings", "is", "not", "None", ":", "\n", "            ", "rcnn_embeds", "=", "[", "]", "\n", "for", "rcnn_embedding", "in", "rcnn_embeddings", ":", "\n", "                ", "rcnn_embed", "=", "self", ".", "patch_embedding", "(", "rcnn_embedding", ")", "\n", "rcnn_embed", "=", "rcnn_embed", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "flatten", "(", "0", ",", "1", ")", "# 3*4, 768 3\u4e2a\u5b50\u56fe", "\n", "rcnn_embeds", ".", "append", "(", "rcnn_embed", ")", "\n", "", "rcnn_embeds", "=", "torch", ".", "stack", "(", "rcnn_embeds", ")", "# bsz, 12, 768", "\n", "rcnn_embeds", "=", "rcnn_embeds", "+", "self", ".", "rcnn_position_embedding", "(", "self", ".", "rcnn_position_ids", ")", "\n", "embeddings", "=", "torch", ".", "cat", "(", "(", "embeddings", ",", "rcnn_embeds", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextEmbeddings.__init__": [[189, 198], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_clip.CLIPTextEmbeddings.register_buffer", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "CLIPTextConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "embed_dim", "=", "config", ".", "hidden_size", "\n", "\n", "self", ".", "token_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "embed_dim", ")", "\n", "self", ".", "position_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "embed_dim", ")", "\n", "\n", "# position_ids (1, len position emb) is contiguous in memory and exported when serialized", "\n", "self", ".", "register_buffer", "(", "\"position_ids\"", ",", "torch", ".", "arange", "(", "config", ".", "max_position_embeddings", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextEmbeddings.forward": [[199, 212], ["modeling_clip.CLIPTextEmbeddings.position_embedding", "modeling_clip.CLIPTextEmbeddings.token_embedding"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "shape", "[", "-", "2", "]", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "self", ".", "position_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "token_embedding", "(", "input_ids", ")", "\n", "\n", "", "position_embeddings", "=", "self", ".", "position_embedding", "(", "position_ids", ")", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "\n", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPAttention.__init__": [[217, 233], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "embed_dim", "=", "config", ".", "hidden_size", "\n", "self", ".", "num_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "head_dim", "=", "self", ".", "embed_dim", "//", "self", ".", "num_heads", "\n", "assert", "(", "\n", "self", ".", "head_dim", "*", "self", ".", "num_heads", "==", "self", ".", "embed_dim", "\n", ")", ",", "f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`: {self.num_heads}).\"", "\n", "self", ".", "scale", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "self", ".", "dropout", "=", "config", ".", "attention_dropout", "\n", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPAttention._shape": [[234, 236], ["tensor.view().transpose().contiguous", "tensor.view().transpose", "tensor.view"], "methods", ["None"], ["", "def", "_shape", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ",", "seq_len", ":", "int", ",", "bsz", ":", "int", ")", ":", "\n", "        ", "return", "tensor", ".", "view", "(", "bsz", ",", "seq_len", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPAttention.forward": [[237, 319], ["hidden_states.size", "modeling_clip.CLIPAttention._shape", "modeling_clip.CLIPAttention._shape", "modeling_clip.CLIPAttention._shape", "query_states.view.view.view", "key_states.view.view.view", "value_states.view.view.view", "key_states.view.view.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "modeling_clip.CLIPAttention.view", "modeling_clip.CLIPAttention.transpose", "modeling_clip.CLIPAttention.reshape", "modeling_clip.CLIPAttention.out_proj", "modeling_clip.CLIPAttention.q_proj", "modeling_clip.CLIPAttention.k_proj", "modeling_clip.CLIPAttention.v_proj", "key_states.view.view.transpose", "attn_weights.view.view.size", "ValueError", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights_reshaped.view.view.view", "modeling_clip.CLIPAttention.size", "ValueError", "causal_attention_mask.size", "ValueError", "attn_weights.view.view.view", "attention_mask.size", "ValueError", "attn_weights.view.view.view", "attn_weights.view.view.size", "modeling_clip.CLIPAttention.size", "causal_attention_mask.size", "attention_mask.size"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "causal_attention_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "output_attentions", ":", "bool", "=", "False", ",", "\n", "output_qks", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Batch x Time x Channel\"\"\"", "\n", "\n", "bsz", ",", "tgt_len", ",", "embed_dim", "=", "hidden_states", ".", "size", "(", ")", "\n", "\n", "# get query proj", "\n", "query_states", "=", "self", ".", "q_proj", "(", "hidden_states", ")", "*", "self", ".", "scale", "\n", "key_states", "=", "self", ".", "_shape", "(", "self", ".", "k_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "value_states", "=", "self", ".", "_shape", "(", "self", ".", "v_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "\n", "proj_shape", "=", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "query_states", "=", "self", ".", "_shape", "(", "query_states", ",", "tgt_len", ",", "bsz", ")", "\n", "\n", "qks", "=", "None", "\n", "if", "output_qks", ":", "\n", "            ", "qks", "=", "(", "query_states", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", ",", "key_states", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", ")", "# \u53bb\u6389cls", "\n", "\n", "", "query_states", "=", "query_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "key_states", "=", "key_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "value_states", "=", "value_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "\n", "src_len", "=", "key_states", ".", "size", "(", "1", ")", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "query_states", ",", "key_states", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "if", "attn_weights", ".", "size", "(", ")", "!=", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is {attn_weights.size()}\"", "\n", ")", "\n", "\n", "# apply the causal_attention_mask first", "\n", "", "if", "causal_attention_mask", "is", "not", "None", ":", "\n", "            ", "if", "causal_attention_mask", ".", "size", "(", ")", "!=", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {causal_attention_mask.size()}\"", "\n", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "+", "causal_attention_mask", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "if", "attention_mask", ".", "size", "(", ")", "!=", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"", "\n", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "+", "attention_mask", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_weights", "=", "nn", ".", "functional", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "# this operation is a bit akward, but it's required to", "\n", "# make sure that attn_weights keeps its gradient.", "\n", "# In order to do so, attn_weights have to reshaped", "\n", "# twice and have to be reused in the following", "\n", "            ", "attn_weights_reshaped", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights_reshaped", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights_reshaped", "=", "None", "\n", "\n", "", "attn_probs", "=", "nn", ".", "functional", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn_output", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "value_states", ")", "\n", "\n", "if", "attn_output", ".", "size", "(", ")", "!=", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is {attn_output.size()}\"", "\n", ")", "\n", "\n", "", "attn_output", "=", "attn_output", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "1", ",", "2", ")", "\n", "attn_output", "=", "attn_output", ".", "reshape", "(", "bsz", ",", "tgt_len", ",", "embed_dim", ")", "\n", "\n", "attn_output", "=", "self", ".", "out_proj", "(", "attn_output", ")", "\n", "\n", "# return attn_output, attn_weights_reshaped", "\n", "return", "attn_output", ",", "attn_output", ",", "qks", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPMLP.__init__": [[322, 328], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "activation_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPMLP.forward": [[329, 334], ["modeling_clip.CLIPMLP.fc1", "modeling_clip.CLIPMLP.activation_fn", "modeling_clip.CLIPMLP.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "fc1", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "activation_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "fc2", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPEncoderLayer.__init__": [[337, 344], ["torch.nn.Module.__init__", "modeling_clip.CLIPAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "modeling_clip.CLIPMLP", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "CLIPConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "hidden_size", "\n", "self", ".", "self_attn", "=", "CLIPAttention", "(", "config", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "mlp", "=", "CLIPMLP", "(", "config", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPEncoderLayer.forward": [[345, 390], ["modeling_clip.CLIPEncoderLayer.layer_norm1", "modeling_clip.CLIPEncoderLayer.self_attn", "modeling_clip.CLIPEncoderLayer.layer_norm2", "modeling_clip.CLIPEncoderLayer.mlp"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n", "attention_mask", ":", "torch", ".", "Tensor", ",", "\n", "causal_attention_mask", ":", "torch", ".", "Tensor", ",", "\n", "output_attentions", ":", "bool", "=", "False", ",", "\n", "output_qks", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            hidden_states (:obj:`torch.FloatTensor`): input to the layer of shape :obj:`(seq_len, batch, embed_dim)`\n            attention_mask (:obj:`torch.FloatTensor`): attention mask of size\n                :obj:`(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n            layer_head_mask (:obj:`torch.FloatTensor`): mask for attention heads in a given layer of size\n                :obj:`(config.encoder_attention_heads,)`.\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n        \"\"\"", "\n", "residual", "=", "hidden_states", "\n", "\n", "hidden_states", "=", "self", ".", "layer_norm1", "(", "hidden_states", ")", "\n", "hidden_states", ",", "attn_weights", ",", "qks", "=", "self", ".", "self_attn", "(", "\n", "hidden_states", "=", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "causal_attention_mask", "=", "causal_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_qks", "=", "output_qks", ",", "\n", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "\n", "residual", "=", "hidden_states", "\n", "hidden_states", "=", "self", ".", "layer_norm2", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "mlp", "(", "hidden_states", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", "+=", "(", "attn_weights", ",", ")", "\n", "\n", "", "if", "output_qks", ":", "\n", "            ", "outputs", "+=", "(", "qks", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPPreTrainedModel._init_weights": [[403, 445], ["isinstance", "isinstance", "module.token_embedding.weight.data.normal_", "module.position_embedding.weight.data.normal_", "isinstance", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "module.bias.data.zero_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "isinstance", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "isinstance", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "isinstance", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Initialize the weights\"\"\"", "\n", "factor", "=", "self", ".", "config", ".", "initializer_factor", "\n", "if", "isinstance", "(", "module", ",", "CLIPTextEmbeddings", ")", ":", "\n", "            ", "module", ".", "token_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "0.02", ")", "\n", "module", ".", "position_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "0.02", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "CLIPVisionEmbeddings", ")", ":", "\n", "            ", "factor", "=", "self", ".", "config", ".", "initializer_factor", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "class_embedding", ",", "mean", "=", "0.0", ",", "std", "=", "module", ".", "embed_dim", "**", "-", "0.5", "*", "factor", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "patch_embedding", ".", "weight", ",", "std", "=", "module", ".", "config", ".", "initializer_range", "*", "factor", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "position_embedding", ".", "weight", ",", "std", "=", "module", ".", "config", ".", "initializer_range", "*", "factor", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "CLIPAttention", ")", ":", "\n", "            ", "factor", "=", "self", ".", "config", ".", "initializer_factor", "\n", "in_proj_std", "=", "(", "module", ".", "embed_dim", "**", "-", "0.5", ")", "*", "(", "(", "2", "*", "module", ".", "config", ".", "num_hidden_layers", ")", "**", "-", "0.5", ")", "*", "factor", "\n", "out_proj_std", "=", "(", "module", ".", "embed_dim", "**", "-", "0.5", ")", "*", "factor", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "q_proj", ".", "weight", ",", "std", "=", "in_proj_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "k_proj", ".", "weight", ",", "std", "=", "in_proj_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "v_proj", ".", "weight", ",", "std", "=", "in_proj_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "out_proj", ".", "weight", ",", "std", "=", "out_proj_std", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "CLIPMLP", ")", ":", "\n", "            ", "factor", "=", "self", ".", "config", ".", "initializer_factor", "\n", "in_proj_std", "=", "(", "\n", "(", "module", ".", "config", ".", "hidden_size", "**", "-", "0.5", ")", "*", "(", "(", "2", "*", "module", ".", "config", ".", "num_hidden_layers", ")", "**", "-", "0.5", ")", "*", "factor", "\n", ")", "\n", "fc_std", "=", "(", "2", "*", "module", ".", "config", ".", "hidden_size", ")", "**", "-", "0.5", "*", "factor", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "fc1", ".", "weight", ",", "std", "=", "fc_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "module", ".", "fc2", ".", "weight", ",", "std", "=", "in_proj_std", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "CLIPModel", ")", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "\n", "module", ".", "text_projection", ".", "weight", ",", "\n", "std", "=", "module", ".", "text_embed_dim", "**", "-", "0.5", "*", "self", ".", "config", ".", "initializer_factor", ",", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "\n", "module", ".", "visual_projection", ".", "weight", ",", "\n", "std", "=", "module", ".", "vision_embed_dim", "**", "-", "0.5", "*", "self", ".", "config", ".", "initializer_factor", ",", "\n", ")", "\n", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPPreTrainedModel._set_gradient_checkpointing": [[446, 449], ["isinstance"], "methods", ["None"], ["", "", "def", "_set_gradient_checkpointing", "(", "self", ",", "module", ",", "value", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "CLIPEncoder", ")", ":", "\n", "            ", "module", ".", "gradient_checkpointing", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPEncoder.__init__": [[562, 567], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_clip.CLIPEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "CLIPConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "CLIPEncoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "self", ".", "gradient_checkpointing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPEncoder.forward": [[568, 658], ["enumerate", "modeling_clip.CLIPBaseModelOutput", "tuple", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "encoder_layer", "modeling_clip.CLIPEncoder.forward.create_custom_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "inputs_embeds", ",", "\n", "attention_mask", "=", "None", ",", "\n", "causal_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "output_qks", "=", "False", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Args:\n            inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n                Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded\n                representation. This is useful if you want more control over how to convert :obj:`input_ids` indices\n                into associated vectors than the model's internal embedding lookup matrix.\n            attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n\n                - 1 for tokens that are **not masked**,\n                - 0 for tokens that are **masked**.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n            causal_attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                Causal mask for the text model. Mask values selected in ``[0, 1]``:\n\n                - 1 for tokens that are **not masked**,\n                - 0 for tokens that are **masked**.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n            output_hidden_states (:obj:`bool`, `optional`):\n                Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors\n                for more detail.\n            return_dict (:obj:`bool`, `optional`):\n                Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "encoder_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_qks", "=", "(", ")", "if", "output_qks", "else", "None", "\n", "\n", "hidden_states", "=", "inputs_embeds", "\n", "for", "idx", ",", "encoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "encoder_states", "=", "encoder_states", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "gradient_checkpointing", "and", "self", ".", "training", ":", "\n", "\n", "                ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                        ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "encoder_layer", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "causal_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "encoder_layer", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "causal_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_qks", "=", "output_qks", "\n", ")", "\n", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "", "if", "output_qks", ":", "\n", "                ", "all_qks", "=", "all_qks", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "\n", "\n", "", "", "if", "output_hidden_states", ":", "\n", "            ", "encoder_states", "=", "encoder_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "encoder_states", ",", "all_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "CLIPBaseModelOutput", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "hidden_states", "=", "encoder_states", ",", "attentions", "=", "all_attentions", ",", "qks", "=", "all_qks", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextTransformer.__init__": [[662, 669], ["torch.nn.Module.__init__", "modeling_clip.CLIPTextEmbeddings", "modeling_clip.CLIPEncoder", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "CLIPTextConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "embed_dim", "=", "config", ".", "hidden_size", "\n", "self", ".", "embeddings", "=", "CLIPTextEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "CLIPEncoder", "(", "config", ")", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextTransformer.forward": [[670, 732], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "input_ids.view.view.size", "input_ids.view.view.view", "modeling_clip.CLIPTextTransformer.embeddings", "modeling_clip.CLIPTextTransformer._build_causal_attention_mask().to", "modeling_clip.CLIPTextTransformer.encoder", "modeling_clip.CLIPTextTransformer.final_layer_norm", "transformers.modeling_outputs.BaseModelOutputWithPooling", "ValueError", "modeling_clip._expand_mask", "modeling_clip.CLIPTextTransformer._build_causal_attention_mask", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "input_ids.view.view.argmax"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.replace_return_docstrings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip._expand_mask", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextTransformer._build_causal_attention_mask"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_TEXT_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "BaseModelOutputWithPooling", ",", "config_class", "=", "CLIPTextConfig", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids\"", ")", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "hidden_states", "=", "self", ".", "embeddings", "(", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ")", "\n", "\n", "bsz", ",", "seq_len", "=", "input_shape", "\n", "# CLIP's text model uses causal mask, prepare it here.", "\n", "# https://github.com/openai/CLIP/blob/cfcffb90e69f37bf2ff1e988237a0fbe41f33c04/clip/model.py#L324", "\n", "causal_attention_mask", "=", "self", ".", "_build_causal_attention_mask", "(", "bsz", ",", "seq_len", ")", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "# expand attention_mask", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]", "\n", "            ", "attention_mask", "=", "_expand_mask", "(", "attention_mask", ",", "hidden_states", ".", "dtype", ")", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "inputs_embeds", "=", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "causal_attention_mask", "=", "causal_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", "\n", "last_hidden_state", "=", "self", ".", "final_layer_norm", "(", "last_hidden_state", ")", "\n", "\n", "# text_embeds.shape = [batch_size, n_ctx, transformer.width]", "\n", "# take features from the eot embedding (eot_token is the highest number in each sequence)", "\n", "pooled_output", "=", "last_hidden_state", "[", "torch", ".", "arange", "(", "last_hidden_state", ".", "shape", "[", "0", "]", ")", ",", "input_ids", ".", "argmax", "(", "dim", "=", "-", "1", ")", "]", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "last_hidden_state", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPooling", "(", "\n", "last_hidden_state", "=", "last_hidden_state", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextTransformer._build_causal_attention_mask": [[734, 742], ["torch.empty", "torch.empty", "torch.empty", "torch.empty", "mask.unsqueeze.unsqueeze.fill_", "mask.unsqueeze.unsqueeze.triu_", "mask.unsqueeze.unsqueeze.unsqueeze", "float"], "methods", ["None"], ["", "def", "_build_causal_attention_mask", "(", "self", ",", "bsz", ",", "seq_len", ")", ":", "\n", "# lazily create causal attention mask, with full attention between the vision tokens", "\n", "# pytorch uses additive attention mask; fill with -inf", "\n", "        ", "mask", "=", "torch", ".", "empty", "(", "bsz", ",", "seq_len", ",", "seq_len", ")", "\n", "mask", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "mask", ".", "triu_", "(", "1", ")", "# zero out the lower diagonal", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# expand mask", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextModel.__init__": [[747, 751], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_clip.CLIPTextTransformer", "modeling_clip.CLIPTextModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "CLIPTextConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "text_model", "=", "CLIPTextTransformer", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextModel.get_input_embeddings": [[752, 754], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "return", "self", ".", "text_model", ".", "embeddings", ".", "token_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextModel.set_input_embeddings": [[755, 757], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "text_model", ".", "embeddings", ".", "token_embedding", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPTextModel.forward": [[758, 794], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_clip.CLIPTextModel.text_model"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.replace_return_docstrings"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_TEXT_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "BaseModelOutputWithPooling", ",", "config_class", "=", "CLIPTextConfig", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "output_qks", "=", "False", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        Examples::\n\n            >>> from transformers import CLIPTokenizer, CLIPTextModel\n\n            >>> model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n            >>> tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n            >>> inputs = tokenizer([\"a photo of a cat\", \"a photo of a dog\"],  padding=True, return_tensors=\"pt\")\n\n            >>> outputs = model(**inputs)\n            >>> last_hidden_state = outputs.last_hidden_state\n            >>> pooled_output = outputs.pooled_output # pooled (EOS token) states\n        \"\"\"", "\n", "return", "self", ".", "text_model", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "output_qks", "=", "output_qks", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionTransformer.__init__": [[798, 807], ["torch.nn.Module.__init__", "modeling_clip.CLIPVisionEmbeddings", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "modeling_clip.CLIPEncoder", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "CLIPVisionConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "embed_dim", "=", "config", ".", "hidden_size", "\n", "\n", "self", ".", "embeddings", "=", "CLIPVisionEmbeddings", "(", "config", ")", "\n", "self", ".", "pre_layrnorm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "encoder", "=", "CLIPEncoder", "(", "config", ")", "\n", "self", ".", "post_layernorm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionTransformer.forward": [[808, 858], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_clip.CLIPVisionTransformer.embeddings", "modeling_clip.CLIPVisionTransformer.pre_layrnorm", "modeling_clip.CLIPVisionTransformer.encoder", "modeling_clip.CLIPVisionTransformer.post_layernorm", "modeling_clip.CLIPBaseModelOutputWithPooling", "ValueError"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.replace_return_docstrings"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_VISION_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "BaseModelOutputWithPooling", ",", "config_class", "=", "CLIPVisionConfig", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "pixel_values", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "aux_embeddings", "=", "None", ",", "# lilei", "\n", "rcnn_embeddings", "=", "None", ",", "\n", "output_qks", "=", "False", ",", "# lilei", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "pixel_values", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify pixel_values\"", ")", "\n", "\n", "", "hidden_states", "=", "self", ".", "embeddings", "(", "pixel_values", ",", "aux_embeddings", ",", "rcnn_embeddings", ")", "\n", "# lilei: resnet", "\n", "# hidden_states = torch.cat((hidden_states, aux_embeddings), dim=1)", "\n", "hidden_states", "=", "self", ".", "pre_layrnorm", "(", "hidden_states", ")", "\n", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "inputs_embeds", "=", "hidden_states", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "output_qks", "=", "output_qks", "\n", ")", "\n", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "last_hidden_state", "[", ":", ",", "0", ",", ":", "]", "\n", "pooled_output", "=", "self", ".", "post_layernorm", "(", "pooled_output", ")", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "last_hidden_state", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "", "return", "CLIPBaseModelOutputWithPooling", "(", "\n", "last_hidden_state", "=", "last_hidden_state", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", "qks", "=", "encoder_outputs", ".", "qks", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionModel.__init__": [[864, 868], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_clip.CLIPVisionTransformer", "modeling_clip.CLIPVisionModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "CLIPVisionConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "vision_model", "=", "CLIPVisionTransformer", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionModel.get_input_embeddings": [[869, 871], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "return", "self", ".", "vision_model", ".", "embeddings", ".", "patch_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPVisionModel.forward": [[872, 907], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_clip.CLIPVisionModel.vision_model"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.replace_return_docstrings"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_VISION_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "BaseModelOutputWithPooling", ",", "config_class", "=", "CLIPVisionConfig", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "pixel_values", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        Examples::\n\n            >>> from PIL import Image\n            >>> import requests\n            >>> from transformers import CLIPProcessor, CLIPVisionModel\n\n            >>> model = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n            >>> processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n            >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n            >>> image = Image.open(requests.get(url, stream=True).raw)\n\n            >>> inputs = processor(images=image, return_tensors=\"pt\")\n\n            >>> outputs = model(**inputs)\n            >>> last_hidden_state = outputs.last_hidden_state\n            >>> pooled_output = outputs.pooled_output # pooled CLS states\n        \"\"\"", "\n", "return", "self", ".", "vision_model", "(", "\n", "pixel_values", "=", "pixel_values", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPModel.__init__": [[914, 942], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_clip.CLIPTextTransformer", "modeling_clip.CLIPVisionTransformer", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "modeling_clip.CLIPModel.init_weights", "isinstance", "ValueError", "isinstance", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "type", "type"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "CLIPConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "not", "isinstance", "(", "config", ".", "text_config", ",", "CLIPTextConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"config.text_config is expected to be of type CLIPTextConfig but is of type {type(config.text_config)}.\"", "\n", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "config", ".", "vision_config", ",", "CLIPVisionConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"config.vision_config is expected to be of type CLIPVisionConfig but is of type {type(config.vision_config)}.\"", "\n", ")", "\n", "\n", "", "text_config", "=", "config", ".", "text_config", "\n", "vision_config", "=", "config", ".", "vision_config", "\n", "\n", "self", ".", "projection_dim", "=", "config", ".", "projection_dim", "\n", "self", ".", "text_embed_dim", "=", "text_config", ".", "hidden_size", "\n", "self", ".", "vision_embed_dim", "=", "vision_config", ".", "hidden_size", "\n", "\n", "self", ".", "text_model", "=", "CLIPTextTransformer", "(", "text_config", ")", "\n", "self", ".", "vision_model", "=", "CLIPVisionTransformer", "(", "vision_config", ")", "\n", "\n", "self", ".", "visual_projection", "=", "nn", ".", "Linear", "(", "self", ".", "vision_embed_dim", ",", "self", ".", "projection_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "text_projection", "=", "nn", ".", "Linear", "(", "self", ".", "text_embed_dim", ",", "self", ".", "projection_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "logit_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "self", ".", "config", ".", "logit_scale_init_value", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPModel.get_text_features": [[943, 981], ["transformers.file_utils.add_start_docstrings_to_model_forward", "modeling_clip.CLIPModel.text_model", "modeling_clip.CLIPModel.text_projection"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_TEXT_INPUTS_DOCSTRING", ")", "\n", "def", "get_text_features", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n            text_features (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, output_dim`): The text embeddings\n            obtained by applying the projection layer to the pooled output of :class:`~transformers.CLIPTextModel`.\n\n        Examples::\n\n            >>> from transformers import CLIPTokenizer, CLIPModel\n\n            >>> model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n            >>> tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n            >>> inputs = tokenizer([\"a photo of a cat\", \"a photo of a dog\"],  padding=True, return_tensors=\"pt\")\n            >>> text_features = model.get_text_features(**inputs)\n        \"\"\"", "\n", "text_outputs", "=", "self", ".", "text_model", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "text_outputs", "[", "1", "]", "\n", "text_features", "=", "self", ".", "text_projection", "(", "pooled_output", ")", "\n", "\n", "return", "text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPModel.get_image_features": [[982, 1022], ["transformers.file_utils.add_start_docstrings_to_model_forward", "modeling_clip.CLIPModel.vision_model", "modeling_clip.CLIPModel.visual_projection"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_VISION_INPUTS_DOCSTRING", ")", "\n", "def", "get_image_features", "(", "\n", "self", ",", "\n", "pixel_values", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n            image_features (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, output_dim`): The image embeddings\n            obtained by applying the projection layer to the pooled output of :class:`~transformers.CLIPVisionModel`.\n\n        Examples::\n\n            >>> from PIL import Image\n            >>> import requests\n            >>> from transformers import CLIPProcessor, CLIPModel\n\n            >>> model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n            >>> processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n            >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n            >>> image = Image.open(requests.get(url, stream=True).raw)\n\n            >>> inputs = processor(images=image, return_tensors=\"pt\")\n\n            >>> image_features = model.get_image_features(**inputs)\n        \"\"\"", "\n", "vision_outputs", "=", "self", ".", "vision_model", "(", "\n", "pixel_values", "=", "pixel_values", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "vision_outputs", "[", "1", "]", "# pooled_output", "\n", "image_features", "=", "self", ".", "visual_projection", "(", "pooled_output", ")", "\n", "\n", "return", "image_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.CLIPModel.forward": [[1023, 1106], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_clip.CLIPModel.vision_model", "modeling_clip.CLIPModel.text_model", "modeling_clip.CLIPModel.visual_projection", "modeling_clip.CLIPModel.text_projection", "modeling_clip.CLIPModel.logit_scale.exp", "modeling_clip.CLIPOutput", "modeling_clip.CLIPModel.norm", "modeling_clip.CLIPModel.norm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_clip.clip_loss", "modeling_clip.CLIPModel.t"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.replace_return_docstrings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.clip_loss"], ["", "@", "add_start_docstrings_to_model_forward", "(", "CLIP_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "CLIPOutput", ",", "config_class", "=", "CLIPConfig", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "pixel_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "return_loss", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        Examples::\n\n            >>> from PIL import Image\n            >>> import requests\n            >>> from transformers import CLIPProcessor, CLIPModel\n\n            >>> model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n            >>> processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n            >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n            >>> image = Image.open(requests.get(url, stream=True).raw)\n\n            >>> inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n\n            >>> outputs = model(**inputs)\n            >>> logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n            >>> probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "return_dict", "\n", "vision_outputs", "=", "self", ".", "vision_model", "(", "\n", "pixel_values", "=", "pixel_values", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "text_outputs", "=", "self", ".", "text_model", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "image_embeds", "=", "vision_outputs", "[", "1", "]", "\n", "image_embeds", "=", "self", ".", "visual_projection", "(", "image_embeds", ")", "\n", "\n", "text_embeds", "=", "text_outputs", "[", "1", "]", "\n", "text_embeds", "=", "self", ".", "text_projection", "(", "text_embeds", ")", "\n", "\n", "# normalized features", "\n", "image_embeds", "=", "image_embeds", "/", "image_embeds", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "text_embeds", "=", "text_embeds", "/", "text_embeds", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# cosine similarity as logits", "\n", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_text", "=", "torch", ".", "matmul", "(", "text_embeds", ",", "image_embeds", ".", "t", "(", ")", ")", "*", "logit_scale", "\n", "logits_per_image", "=", "logits_per_text", ".", "T", "\n", "\n", "loss", "=", "None", "\n", "if", "return_loss", ":", "\n", "            ", "loss", "=", "clip_loss", "(", "logits_per_text", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits_per_image", ",", "logits_per_text", ",", "text_embeds", ",", "image_embeds", ",", "text_outputs", ",", "vision_outputs", ")", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "CLIPOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits_per_image", "=", "logits_per_image", ",", "\n", "logits_per_text", "=", "logits_per_text", ",", "\n", "text_embeds", "=", "text_embeds", ",", "\n", "image_embeds", "=", "image_embeds", ",", "\n", "text_model_output", "=", "text_outputs", ",", "\n", "vision_model_output", "=", "vision_outputs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip._expand_mask": [[49, 61], ["mask.size", "mask[].expand().to", "inverted_mask.masked_fill", "inverted_mask.bool", "mask[].expand", "torch.finfo", "torch.finfo"], "function", ["None"], ["def", "_expand_mask", "(", "mask", ":", "torch", ".", "Tensor", ",", "dtype", ":", "torch", ".", "dtype", ",", "tgt_len", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n    \"\"\"", "\n", "bsz", ",", "src_len", "=", "mask", ".", "size", "(", ")", "\n", "tgt_len", "=", "tgt_len", "if", "tgt_len", "is", "not", "None", "else", "src_len", "\n", "\n", "expanded_mask", "=", "mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", ".", "to", "(", "dtype", ")", "\n", "\n", "inverted_mask", "=", "1.0", "-", "expanded_mask", "\n", "\n", "return", "inverted_mask", ".", "masked_fill", "(", "inverted_mask", ".", "bool", "(", ")", ",", "torch", ".", "finfo", "(", "dtype", ")", ".", "min", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.contrastive_loss": [[65, 67], ["torch.nn.functional.cross_entropy", "torch.arange", "torch.arange", "len"], "function", ["None"], ["", "def", "contrastive_loss", "(", "logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "nn", ".", "functional", ".", "cross_entropy", "(", "logits", ",", "torch", ".", "arange", "(", "len", "(", "logits", ")", ",", "device", "=", "logits", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.clip_loss": [[69, 73], ["modeling_clip.contrastive_loss", "modeling_clip.contrastive_loss"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.contrastive_loss", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_clip.contrastive_loss"], ["", "def", "clip_loss", "(", "similarity", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "caption_loss", "=", "contrastive_loss", "(", "similarity", ")", "\n", "image_loss", "=", "contrastive_loss", "(", "similarity", ".", "T", ")", "\n", "return", "(", "caption_loss", "+", "image_loss", ")", "/", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPVisionEmbeddings.__init__": [[101, 125], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Conv2d", "torch.nn.Embedding", "modeling_unimo.CLIPVisionEmbeddings.register_buffer", "torch.nn.Embedding", "modeling_unimo.CLIPVisionEmbeddings.register_buffer", "torch.nn.Embedding", "modeling_unimo.CLIPVisionEmbeddings.register_buffer", "torch.randn", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["\n", "self", ".", "rcnn_position_embedding", "=", "nn", ".", "Embedding", "(", "12", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "register_buffer", "(", "\"rcnn_position_ids\"", ",", "torch", ".", "arange", "(", "12", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "pixel_values", ",", "aux_embeddings", "=", "None", ",", "rcnn_embeddings", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "pixel_values", ".", "shape", "[", "0", "]", "\n", "\n", "class_embeds", "=", "self", ".", "class_embedding", ".", "expand", "(", "batch_size", ",", "1", ",", "-", "1", ")", "\n", "embeddings", "=", "class_embeds", "\n", "\n", "if", "aux_embeddings", "is", "not", "None", ":", "\n", "            ", "aux_embeds", "=", "[", "]", "\n", "for", "aux_embedding", "in", "aux_embeddings", ":", "\n", "                ", "aux_embed", "=", "self", ".", "patch_embedding", "(", "aux_embedding", ")", "\n", "aux_embed", "=", "aux_embed", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "flatten", "(", "0", ",", "1", ")", "# 3*16, 768 3\u4e2a\u5b50\u56fe", "\n", "aux_embeds", ".", "append", "(", "aux_embed", ")", "\n", "", "aux_embeds", "=", "torch", ".", "stack", "(", "aux_embeds", ")", "# bsz, 48, 768", "\n", "aux_embeds", "=", "aux_embeds", "+", "self", ".", "aux_position_embedding", "(", "self", ".", "aux_position_ids", ")", "\n", "embeddings", "=", "torch", ".", "cat", "(", "(", "embeddings", ",", "aux_embeds", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "rcnn_embeddings", "is", "not", "None", ":", "\n", "            ", "rcnn_embeds", "=", "[", "]", "\n", "for", "rcnn_embedding", "in", "rcnn_embeddings", ":", "\n", "                ", "rcnn_embed", "=", "self", ".", "patch_embedding", "(", "rcnn_embedding", ")", "\n", "rcnn_embed", "=", "rcnn_embed", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "flatten", "(", "0", ",", "1", ")", "# 3*4, 768 3\u4e2a\u5b50\u56fe", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPVisionEmbeddings.forward": [[126, 158], ["modeling_unimo.CLIPVisionEmbeddings.patch_embedding", "patch_embeds.flatten().transpose.flatten().transpose.flatten().transpose", "modeling_unimo.CLIPVisionEmbeddings.class_embedding.expand", "torch.stack", "torch.cat", "torch.stack", "torch.cat", "patch_embeds.flatten().transpose.flatten().transpose.flatten", "modeling_unimo.CLIPVisionEmbeddings.patch_embedding", "aux_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose().flatten", "torch.stack.append", "modeling_unimo.CLIPVisionEmbeddings.patch_embedding", "rcnn_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose().flatten", "torch.stack.append", "aux_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose", "rcnn_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten().transpose", "aux_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten", "rcnn_embed.flatten().transpose().flatten.flatten().transpose().flatten.flatten"], "methods", ["None"], ["rcnn_embeds", ".", "append", "(", "rcnn_embed", ")", "\n", "", "rcnn_embeds", "=", "torch", ".", "stack", "(", "rcnn_embeds", ")", "# bsz, 12, 768", "\n", "rcnn_embeds", "=", "rcnn_embeds", "+", "self", ".", "rcnn_position_embedding", "(", "self", ".", "rcnn_position_ids", ")", "\n", "embeddings", "=", "torch", ".", "cat", "(", "(", "embeddings", ",", "rcnn_embeds", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "embeddings", "\n", "\n", "\n", "", "", "class", "BertEmbeddings", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "config", ".", "pad_token_id", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "# position_ids (1, len position emb) is contiguous in memory and exported when serialized", "\n", "self", ".", "position_embedding_type", "=", "getattr", "(", "config", ",", "\"position_embedding_type\"", ",", "\"absolute\"", ")", "\n", "self", ".", "register_buffer", "(", "\"position_ids\"", ",", "torch", ".", "arange", "(", "config", ".", "max_position_embeddings", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ",", "past_key_values_length", "=", "0", "\n", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertEmbeddings.__init__": [[163, 176], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.Dropout", "getattr", "modeling_unimo.BertEmbeddings.register_buffer", "torch.arange().expand", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["# Setting the token_type_ids to the registered buffer in constructor where it is all zeros, which usually occurs", "\n", "# when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves", "\n", "# issue #5664", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"token_type_ids\"", ")", ":", "\n", "                ", "buffered_token_type_ids", "=", "self", ".", "token_type_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "buffered_token_type_ids_expanded", "=", "buffered_token_type_ids", ".", "expand", "(", "input_shape", "[", "0", "]", ",", "seq_length", ")", "\n", "token_type_ids", "=", "buffered_token_type_ids_expanded", "\n", "", "else", ":", "\n", "                ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", "\n", "\n", "", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertEmbeddings.forward": [[177, 212], ["modeling_unimo.BertEmbeddings.token_type_embeddings", "modeling_unimo.BertEmbeddings.LayerNorm", "modeling_unimo.BertEmbeddings.dropout", "input_ids.size", "hasattr", "modeling_unimo.BertEmbeddings.word_embeddings", "modeling_unimo.BertEmbeddings.position_embeddings", "modeling_unimo.BertEmbeddings.size", "buffered_token_type_ids.expand", "torch.zeros"], "methods", ["None"], ["\n", "embeddings", "=", "inputs_embeds", "+", "token_type_embeddings", "\n", "if", "self", ".", "position_embedding_type", "==", "\"absolute\"", ":", "\n", "            ", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "embeddings", "+=", "position_embeddings", "\n", "", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n", "\n", "", "", "class", "CLIPAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "embed_dim", "=", "config", ".", "hidden_size", "\n", "self", ".", "num_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "head_dim", "=", "self", ".", "embed_dim", "//", "self", ".", "num_heads", "\n", "assert", "(", "\n", "self", ".", "head_dim", "*", "self", ".", "num_heads", "==", "self", ".", "embed_dim", "\n", ")", ",", "f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`: {self.num_heads}).\"", "\n", "self", ".", "scale", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "self", ".", "dropout", "=", "config", ".", "attention_dropout", "\n", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "", "def", "_shape", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ",", "seq_len", ":", "int", ",", "bsz", ":", "int", ")", ":", "\n", "        ", "return", "tensor", ".", "view", "(", "bsz", ",", "seq_len", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention.__init__": [[217, 233], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["        ", "\"\"\"Input shape: Batch x Time x Channel\"\"\"", "\n", "\n", "bsz", ",", "tgt_len", ",", "embed_dim", "=", "hidden_states", ".", "size", "(", ")", "\n", "\n", "# get query proj", "\n", "query_states", "=", "self", ".", "q_proj", "(", "hidden_states", ")", "*", "self", ".", "scale", "\n", "key_states", "=", "self", ".", "_shape", "(", "self", ".", "k_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "value_states", "=", "self", ".", "_shape", "(", "self", ".", "v_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "\n", "if", "past_key_values", "is", "not", "None", ":", "\n", "            ", "key_states", "=", "torch", ".", "cat", "(", "[", "past_key_values", "[", "0", "]", ",", "key_states", "]", ",", "dim", "=", "2", ")", "\n", "value_states", "=", "torch", ".", "cat", "(", "[", "past_key_values", "[", "1", "]", ",", "value_states", "]", ",", "dim", "=", "2", ")", "\n", "\n", "", "proj_shape", "=", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "query_states", "=", "self", ".", "_shape", "(", "query_states", ",", "tgt_len", ",", "bsz", ")", "\n", "\n", "query_states", "=", "query_states", ".", "view", "(", "*", "proj_shape", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape": [[234, 236], ["tensor.view().transpose().contiguous", "tensor.view().transpose", "tensor.view"], "methods", ["None"], ["key_states", "=", "key_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "value_states", "=", "value_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention.forward": [[237, 298], ["hidden_states.size", "modeling_unimo.CLIPAttention._shape", "modeling_unimo.CLIPAttention._shape", "modeling_unimo.CLIPAttention._shape", "query_states.view.view.view", "torch.cat.view", "torch.cat.view", "torch.cat.size", "torch.bmm", "torch.nn.functional.softmax", "torch.nn.functional.dropout", "torch.bmm", "modeling_unimo.CLIPAttention.view", "modeling_unimo.CLIPAttention.transpose", "modeling_unimo.CLIPAttention.reshape", "modeling_unimo.CLIPAttention.out_proj", "modeling_unimo.CLIPAttention.q_proj", "modeling_unimo.CLIPAttention.k_proj", "modeling_unimo.CLIPAttention.v_proj", "torch.cat", "torch.cat", "torch.cat.transpose", "attn_weights.view.view.size", "ValueError", "attn_weights.view.view.view", "attn_weights_reshaped.view.view.view", "modeling_unimo.CLIPAttention.size", "ValueError", "attn_weights.view.view.size", "modeling_unimo.CLIPAttention.size"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPAttention._shape"], ["src_len", "=", "key_states", ".", "size", "(", "1", ")", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "query_states", ",", "key_states", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "if", "attn_weights", ".", "size", "(", ")", "!=", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is {attn_weights.size()}\"", "\n", ")", "\n", "", "attn_weights", "=", "nn", ".", "functional", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "# this operation is a bit akward, but it's required to", "\n", "# make sure that attn_weights keeps its gradient.", "\n", "# In order to do so, attn_weights have to reshaped", "\n", "# twice and have to be reused in the following", "\n", "            ", "attn_weights_reshaped", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights_reshaped", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights_reshaped", "=", "None", "\n", "\n", "", "attn_probs", "=", "nn", ".", "functional", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn_output", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "value_states", ")", "\n", "\n", "if", "attn_output", ".", "size", "(", ")", "!=", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is {attn_output.size()}\"", "\n", ")", "\n", "\n", "", "attn_output", "=", "attn_output", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "1", ",", "2", ")", "\n", "attn_output", "=", "attn_output", ".", "reshape", "(", "bsz", ",", "tgt_len", ",", "embed_dim", ")", "\n", "\n", "attn_output", "=", "self", ".", "out_proj", "(", "attn_output", ")", "\n", "\n", "return", "attn_output", ",", "attn_weights_reshaped", "\n", "\n", "\n", "", "", "class", "CLIPMLP", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "activation_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "fc1", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "activation_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "fc2", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n", "\n", "", "", "class", "BertSelfAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "# 12", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "# 64", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "# 768", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPMLP.__init__": [[301, 307], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["self", ".", "fusion", "=", "BertFusion", "(", "config", ")", "# ", "\n", "\n", "", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPMLP.forward": [[308, 313], ["modeling_unimo.CLIPMLP.fc1", "modeling_unimo.CLIPMLP.activation_fn", "modeling_unimo.CLIPMLP.fc2"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfAttention.__init__": [[316, 328], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "modeling_unimo.BertFusion"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["current_layer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "hidden_states", ")", ")", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "\n", "qks", "=", "(", "key_layer", ",", "value_layer", ")", "if", "output_qks", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfAttention.transpose_for_scores": [[329, 333], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfAttention.forward": [[334, 381], ["modeling_unimo.BertSelfAttention.query", "modeling_unimo.BertSelfAttention.transpose_for_scores", "modeling_unimo.BertSelfAttention.transpose_for_scores", "modeling_unimo.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_unimo.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_unimo.BertSelfAttention.key", "modeling_unimo.BertSelfAttention.value", "modeling_unimo.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "modeling_unimo.BertSelfAttention.fusion", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfAttention.transpose_for_scores"], ["            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "# bsz, 128, 768", "\n", "\n", "fusion_output", "=", "self", ".", "fusion", "(", "context_layer", ",", "visual_hidden_state", ",", "current_layer", ")", "if", "visual_hidden_state", "is", "not", "None", "else", "None", "# add", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "\n", "return", "outputs", ",", "fusion_output", ",", "qks", "\n", "\n", "\n", "", "", "class", "BertSelfOutput", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n", "\n", "", "", "class", "BertFusion", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fusion_function", "=", "'softmax'", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "visual_hidden_state", "=", "None", ",", "\n", "current_layer", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfOutput.__init__": [[384, 389], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["if", "self", ".", "fusion_function", "==", "'softmax'", ":", "\n", "            ", "fusion_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "fusion_scores", ")", "\n", "fusion_output", "=", "torch", ".", "matmul", "(", "fusion_probs", ",", "visual_hidden_state", ")", "\n", "", "elif", "self", ".", "fusion_function", "==", "'max'", ":", "\n", "            ", "fusion_probs", "=", "fusion_scores", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "", "return", "fusion_output", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertSelfOutput.forward": [[390, 395], ["modeling_unimo.BertSelfOutput.dense", "modeling_unimo.BertSelfOutput.dropout", "modeling_unimo.BertSelfOutput.LayerNorm"], "methods", ["None"], ["\n", "\n", "", "", "class", "BertAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertFusion.__init__": [[398, 402], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertFusion.forward": [[403, 419], ["torch.matmul", "visual_hidden_state.transpose", "torch.matmul", "torch.nn.Softmax", "torch.matmul.max"], "methods", ["None"], ["head_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "visual_hidden_state", "=", "None", ",", "\n", "output_qks", "=", "None", ",", "\n", "current_layer", "=", "None", "\n", ")", ":", "\n", "        ", "self_outputs", ",", "fusion_output", ",", "qks", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", ",", "\n", "visual_hidden_state", ",", "\n", "output_qks", ",", "\n", "current_layer", "\n", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertAttention.__init__": [[422, 427], ["torch.nn.Module.__init__", "modeling_unimo.BertSelfAttention", "modeling_unimo.BertSelfOutput", "set"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["\n", "", "", "class", "BertIntermediate", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "fusion_dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertAttention.forward": [[428, 448], ["modeling_unimo.BertAttention.self", "modeling_unimo.BertAttention.output"], "methods", ["None"], ["if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "fusion_output", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "if", "fusion_output", "is", "not", "None", ":", "\n", "            ", "fusion_states", "=", "self", ".", "fusion_dense", "(", "fusion_output", ")", "\n", "hidden_states", "=", "hidden_states", "+", "fusion_states", "\n", "", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n", "\n", "", "", "class", "BertOutput", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertIntermediate.__init__": [[451, 459], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n", "\n", "", "", "class", "CLIPEncoderLayer", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "hidden_size", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertIntermediate.forward": [[460, 467], ["modeling_unimo.BertIntermediate.dense", "modeling_unimo.BertIntermediate.intermediate_act_fn", "modeling_unimo.BertIntermediate.fusion_dense"], "methods", ["None"], ["self", ".", "self_attn", "=", "CLIPAttention", "(", "config", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "mlp", "=", "CLIPMLP", "(", "config", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertOutput.__init__": [[470, 475], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["current_layer", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertOutput.forward": [[476, 481], ["modeling_unimo.BertOutput.dense", "modeling_unimo.BertOutput.dropout", "modeling_unimo.BertOutput.LayerNorm"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPEncoderLayer.__init__": [[484, 491], ["torch.nn.Module.__init__", "modeling_unimo.CLIPAttention", "torch.nn.LayerNorm", "modeling_unimo.CLIPMLP", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["\n", "hidden_states", "=", "self", ".", "layer_norm1", "(", "hidden_states", ")", "\n", "hidden_states", ",", "attn_weights", "=", "self", ".", "self_attn", "(", "\n", "hidden_states", "=", "hidden_states", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "current_layer", "=", "current_layer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.CLIPEncoderLayer.forward": [[492, 530], ["modeling_unimo.CLIPEncoderLayer.layer_norm1", "modeling_unimo.CLIPEncoderLayer.self_attn", "modeling_unimo.CLIPEncoderLayer.layer_norm2", "modeling_unimo.CLIPEncoderLayer.mlp"], "methods", ["None"], ["hidden_states", "=", "residual", "+", "hidden_states", "\n", "\n", "residual", "=", "hidden_states", "\n", "hidden_states", "=", "self", ".", "layer_norm2", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "mlp", "(", "hidden_states", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", "+=", "(", "attn_weights", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n", "\n", "", "", "class", "BertLayer", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chunk_size_feed_forward", "=", "config", ".", "chunk_size_feed_forward", "\n", "self", ".", "seq_len_dim", "=", "1", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "add_cross_attention", "=", "config", ".", "add_cross_attention", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "visual_hidden_state", "=", "None", ",", "\n", "output_qks", "=", "None", ",", "\n", "current_layer", "=", "None", ",", "\n", ")", ":", "\n", "# decoder uni-directional self-attention cached key/values tuple is at positions 1,2", "\n", "# self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None", "\n", "        ", "self_attention_outputs", ",", "fusion_output", ",", "qks", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertLayer.__init__": [[533, 541], ["torch.nn.Module.__init__", "modeling_unimo.BertAttention", "modeling_unimo.BertIntermediate", "modeling_unimo.BertOutput"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["output_attentions", "=", "output_attentions", ",", "\n", "visual_hidden_state", "=", "visual_hidden_state", ",", "\n", "output_qks", "=", "output_qks", ",", "\n", "current_layer", "=", "current_layer", ",", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertLayer.forward": [[542, 573], ["modeling_unimo.BertLayer.attention", "transformers.modeling_utils.apply_chunking_to_forward"], "methods", ["None"], ["layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", ",", "fusion_output", "\n", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "if", "output_qks", ":", "\n", "            ", "outputs", "+=", "(", "qks", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n", "", "def", "feed_forward_chunk", "(", "self", ",", "attention_output", ",", "fusion_output", ")", ":", "\n", "        ", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ",", "fusion_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n", "\n", "", "", "class", "UnimoEncoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "vision_config", ",", "text_config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vision_config", "=", "vision_config", "\n", "self", ".", "text_config", "=", "text_config", "\n", "\n", "self", ".", "vision_layers", "=", "nn", ".", "ModuleList", "(", "[", "CLIPEncoderLayer", "(", "vision_config", ")", "for", "_", "in", "range", "(", "vision_config", ".", "num_hidden_layers", ")", "]", ")", "\n", "self", ".", "text_layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "text_config", ")", "for", "_", "in", "range", "(", "text_config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "vision_embeds", "=", "None", ",", "\n", "text_embeds", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertLayer.feed_forward_chunk": [[574, 578], ["modeling_unimo.BertLayer.intermediate", "modeling_unimo.BertLayer.output"], "methods", ["None"], ["return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "assert", "self", ".", "vision_config", ".", "num_hidden_layers", "==", "self", ".", "text_config", ".", "num_hidden_layers", "\n", "\n", "all_vision_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoEncoder.__init__": [[581, 588], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_unimo.CLIPEncoderLayer", "modeling_unimo.BertLayer", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["all_text_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "\n", "vision_hidden_states", "=", "vision_embeds", "\n", "text_hidden_states", "=", "text_embeds", "\n", "for", "idx", "in", "range", "(", "self", ".", "vision_config", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_vision_hidden_states", "=", "all_vision_hidden_states", "+", "(", "vision_hidden_states", ",", ")", "\n", "all_text_hidden_states", "=", "all_text_hidden_states", "+", "(", "text_hidden_states", ",", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoEncoder.forward": [[589, 656], ["range", "transformers.modeling_outputs.BaseModelOutput", "vision_layer_module", "text_layer_module", "tuple"], "methods", ["None"], ["\n", "# vision", "\n", "# TODO: 9-12 layers past text as pkv to vision", "\n", "", "past_key_values", "=", "text_layer_output", "[", "-", "1", "]", "if", "idx", ">=", "8", "else", "None", "\n", "vision_layer_module", "=", "self", ".", "vision_layers", "[", "idx", "]", "\n", "vision_layer_output", "=", "vision_layer_module", "(", "\n", "vision_hidden_states", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "current_layer", "=", "idx", ",", "\n", ")", "\n", "vision_hidden_states", "=", "vision_layer_output", "[", "0", "]", "\n", "\n", "# text", "\n", "# TODO: 9-12 layers past vison qks to text", "\n", "last_hidden_state", "=", "vision_hidden_states", "if", "idx", ">=", "8", "else", "None", "\n", "output_qks", "=", "True", "if", "idx", ">=", "7", "else", "None", "\n", "layer_head_mask", "=", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", "\n", "text_layer_module", "=", "self", ".", "text_layer", "[", "idx", "]", "\n", "text_layer_output", "=", "text_layer_module", "(", "\n", "text_hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "layer_head_mask", ",", "\n", "visual_hidden_state", "=", "last_hidden_state", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_qks", "=", "output_qks", ",", "\n", "current_layer", "=", "idx", ",", "\n", ")", "\n", "text_hidden_states", "=", "text_layer_output", "[", "0", "]", "\n", "if", "output_attentions", ":", "\n", "                ", "all_vision_attentions", "=", "all_vision_attentions", "+", "(", "vision_layer_output", "[", "1", "]", ",", ")", "\n", "all_text_attentions", "=", "all_text_attentions", "+", "(", "text_layer_output", "[", "1", "]", ",", ")", "\n", "\n", "", "", "if", "output_hidden_states", ":", "\n", "                ", "all_vision_hidden_states", "=", "all_vision_hidden_states", "+", "(", "vision_hidden_states", ",", ")", "\n", "all_text_hidden_states", "=", "all_text_hidden_states", "+", "(", "text_hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "for", "v", "in", "[", "\n", "text_hidden_states", ",", "\n", "all_text_hidden_states", ",", "\n", "all_text_attentions", ",", "\n", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "text_hidden_states", ",", "hidden_states", "=", "all_text_hidden_states", ",", "attentions", "=", "all_text_attentions", "\n", ")", "\n", "\n", "\n", "", "", "class", "BertPooler", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n", "\n", "", "", "class", "UnimoModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "vision_config", ",", "text_config", ",", "add_pooling_layer", "=", "True", ")", ":", "\n", "        ", "super", "(", "UnimoModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# vision model", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertPooler.__init__": [[660, 664], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["self", ".", "vision_post_layernorm", "=", "nn", ".", "LayerNorm", "(", "vision_config", ".", "hidden_size", ")", "\n", "\n", "# text model", "\n", "self", ".", "text_config", "=", "text_config", "\n", "self", ".", "text_embeddings", "=", "BertEmbeddings", "(", "text_config", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertPooler.forward": [[665, 672], ["modeling_unimo.BertPooler.dense", "modeling_unimo.BertPooler.activation"], "methods", ["None"], ["self", ".", "text_pooler", "=", "BertPooler", "(", "text_config", ")", "if", "add_pooling_layer", "else", "None", "\n", "\n", "# all", "\n", "self", ".", "encoder", "=", "UnimoEncoder", "(", "vision_config", ",", "text_config", ")", "\n", "\n", "self", ".", "device", "=", "vision_config", ".", "device", "\n", "\n", "", "def", "forward", "(", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.__init__": [[675, 692], ["torch.nn.Module.__init__", "modeling_unimo.CLIPVisionEmbeddings", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "modeling_unimo.BertEmbeddings", "modeling_unimo.UnimoEncoder", "modeling_unimo.BertPooler"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "\n", "pixel_values", "=", "None", ",", "\n", "aux_values", "=", "None", ",", "\n", "rcnn_values", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "# pre vision", "\n", "        ", "vision_embedding_output", "=", "self", ".", "vision_embeddings", "(", "pixel_values", ",", "aux_values", ",", "rcnn_values", ")", "\n", "vision_embedding_output", "=", "self", ".", "vision_pre_layrnorm", "(", "vision_embedding_output", ")", "\n", "\n", "# pre text", "\n", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.forward": [[693, 756], ["modeling_unimo.UnimoModel.vision_embeddings", "modeling_unimo.UnimoModel.vision_pre_layrnorm", "input_ids.size", "modeling_unimo.get_extended_attention_mask", "modeling_unimo.get_head_mask", "modeling_unimo.UnimoModel.text_embeddings", "modeling_unimo.UnimoModel.encoder", "transformers.modeling_outputs.BaseModelOutputWithPooling", "torch.ones", "hasattr", "modeling_unimo.UnimoModel.text_pooler", "buffered_token_type_ids.expand", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.get_extended_attention_mask", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.get_head_mask"], ["batch_size", ",", "seq_length", "=", "input_shape", "\n", "device", "=", "input_ids", ".", "device", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "(", "(", "batch_size", ",", "seq_length", ")", ")", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"token_type_ids is None!\"", ")", "\n", "\n", "", "extended_attention_mask", ":", "torch", ".", "Tensor", "=", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "device", ")", "\n", "head_mask", "=", "get_head_mask", "(", "head_mask", ",", "self", ".", "text_config", ".", "num_hidden_layers", ")", "# [None]*12", "\n", "\n", "text_embedding_output", "=", "self", ".", "text_embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", ")", "\n", "\n", "# all encoder", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "vision_embeds", "=", "vision_embedding_output", ",", "\n", "text_embeds", "=", "text_embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "text_pooler", "(", "sequence_output", ")", "if", "self", ".", "text_pooler", "is", "not", "None", "else", "None", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPooling", "(", "\n", "last_hidden_state", "=", "sequence_output", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n", "\n", "", "def", "_init_text_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Initialize the weights\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "text_config", ".", "initializer_range", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "text_config", ".", "initializer_range", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n", "", "", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "text_embeddings", ".", "word_embeddings", "\n", "\n", "", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "text_embeddings", ".", "word_embeddings", "=", "value", "\n", "\n", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "get_input_embeddings", "(", ")", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel._init_text_weights": [[758, 773], ["isinstance", "module.weight.data.normal_", "isinstance", "module.bias.data.zero_", "module.weight.data.normal_", "isinstance", "module.weight.data[].zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_get_resized_embeddings", "(", "\n", "self", ",", "old_embeddings", ":", "nn", ".", "Embedding", ",", "new_num_tokens", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", "->", "nn", ".", "Embedding", ":", "\n", "        "]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.get_input_embeddings": [[774, 776], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.set_input_embeddings": [[777, 779], ["None"], "methods", ["None"], ["\n", "if", "new_num_tokens", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.resize_token_embeddings": [[780, 784], ["modeling_unimo.UnimoModel.get_input_embeddings", "modeling_unimo.UnimoModel._get_resized_embeddings", "modeling_unimo.UnimoModel.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.get_input_embeddings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel._get_resized_embeddings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.set_input_embeddings"], ["            ", "return", "old_embeddings", "\n", "", "else", ":", "\n", "            ", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "\n", "", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel._get_resized_embeddings": [[785, 835], ["torch.nn.Embedding().to", "modeling_unimo.UnimoModel._init_text_weights", "min", "old_embeddings.weight.size", "isinstance", "TypeError", "torch.nn.Embedding", "type"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel._init_text_weights"], ["            ", "return", "old_embeddings", "\n", "\n", "", "if", "not", "isinstance", "(", "old_embeddings", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Old embeddings are of type {type(old_embeddings)}, which is not an instance of {nn.Embedding}.\"", "\n", "f\"You should either use a different resize function or make sure that `old_embeddings` are an instance of {nn.Embedding}.\"", "\n", ")", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", ".", "to", "(", "\n", "self", ".", "device", ",", "dtype", "=", "old_embeddings", ".", "weight", ".", "dtype", "\n", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "_init_text_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy token embeddings from the previous weights", "\n", "\n", "# numbers of tokens to copy", "\n", "n", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "n", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "n", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.get_extended_attention_mask": [[21, 58], ["extended_attention_mask.to.to", "attention_mask.dim", "attention_mask.dim", "ValueError", "torch.device"], "function", ["None"], ["\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Wrong shape for input_ids (shape {input_shape}) or attention_mask (shape {attention_mask.shape})\"", "\n", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "torch", ".", "long", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "return", "extended_attention_mask", "\n", "\n", "\n", "", "def", "get_head_mask", "(", "\n", "head_mask", ":", "Optional", "[", "Tensor", "]", ",", "num_hidden_layers", ":", "int", ",", "is_attention_chunked", ":", "bool", "=", "False", "\n", ")", "->", "Tensor", ":", "\n", "        "]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.get_head_mask": [[60, 81], ["None"], "function", ["None"], ["\n", "head_mask", "=", "[", "None", "]", "*", "num_hidden_layers", "\n", "\n", "return", "head_mask", "\n", "\n", "\n", "# models", "\n", "\n", "", "class", "CLIPVisionEmbeddings", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.unimo_model.UnimoCRFModel.__init__": [[10, 24], ["torch.nn.Module.__init__", "print", "print", "modeling_unimo.UnimoModel", "torchcrf.CRF", "torch.nn.Linear", "torch.nn.Dropout", "len"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", ".", "modeling_unimo", "import", "UnimoModel", "\n", "\n", "class", "UnimoREModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "num_labels", ",", "tokenizer", ",", "args", ",", "vision_config", ",", "text_config", ",", "clip_model_dict", ",", "bert_model_dict", ")", ":", "\n", "        ", "super", "(", "UnimoREModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "print", "(", "vision_config", ")", "\n", "print", "(", "text_config", ")", "\n", "self", ".", "vision_config", "=", "vision_config", "\n", "self", ".", "text_config", "=", "text_config", "\n", "\n", "# for re", "\n", "vision_config", ".", "device", "=", "args", ".", "device", "\n", "self", ".", "model", "=", "UnimoModel", "(", "vision_config", ",", "text_config", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.unimo_model.UnimoCRFModel.forward": [[25, 57], ["input_ids.size", "unimo_model.UnimoCRFModel.model", "unimo_model.UnimoCRFModel.dropout", "unimo_model.UnimoCRFModel.fc", "unimo_model.UnimoCRFModel.crf.decode", "transformers.modeling_outputs.TokenClassifierOutput", "attention_mask.byte", "unimo_model.UnimoCRFModel.crf", "attention_mask.byte"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.decode"], ["\n", "# test load:", "\n", "vision_names", ",", "text_names", "=", "[", "]", ",", "[", "]", "\n", "model_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "for", "name", "in", "model_dict", ":", "\n", "            ", "if", "'vision'", "in", "name", ":", "\n", "                ", "clip_name", "=", "name", ".", "replace", "(", "'vision_'", ",", "''", ")", ".", "replace", "(", "'model.'", ",", "''", ")", "\n", "if", "clip_name", "in", "clip_model_dict", ":", "\n", "                    ", "vision_names", ".", "append", "(", "clip_name", ")", "\n", "model_dict", "[", "name", "]", "=", "clip_model_dict", "[", "clip_name", "]", "\n", "", "", "elif", "'text'", "in", "name", ":", "\n", "                ", "text_name", "=", "name", ".", "replace", "(", "'text_'", ",", "''", ")", ".", "replace", "(", "'model.'", ",", "''", ")", "\n", "if", "text_name", "in", "bert_model_dict", ":", "\n", "                    ", "text_names", ".", "append", "(", "text_name", ")", "\n", "model_dict", "[", "name", "]", "=", "bert_model_dict", "[", "text_name", "]", "\n", "", "", "", "assert", "len", "(", "vision_names", ")", "==", "len", "(", "clip_model_dict", ")", "and", "len", "(", "text_names", ")", "==", "len", "(", "bert_model_dict", ")", ",", "(", "len", "(", "vision_names", ")", ",", "len", "(", "text_names", ")", ",", "len", "(", "clip_model_dict", ")", ",", "len", "(", "bert_model_dict", ")", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "text_config", ".", "hidden_size", "*", "2", ",", "num_labels", ")", "\n", "self", ".", "head_start", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\"<s>\"", ")", "\n", "self", ".", "tail_start", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\"<o>\"", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoConfig.__init__": [[86, 88], ["transformers.configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["self", ".", "patch_size", "=", "config", ".", "patch_size", "\n", "\n", "self", ".", "class_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "embed_dim", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoPreTrainedModel.__init_weights": [[96, 98], ["None"], "methods", ["None"], ["self", ".", "position_embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "num_positions", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "register_buffer", "(", "\"position_ids\"", ",", "torch", ".", "arange", "(", "self", ".", "num_positions", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.__init__": [[838, 845], ["torch.nn.Module.__init__", "modeling_unimo.UnimoModel", "modeling_unimo.UnimoOnlyMLMHead", "modeling_unimo.UnimoForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.tie_weights"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.forward": [[846, 893], ["modeling_unimo.UnimoForMaskedLM.unimo", "modeling_unimo.UnimoForMaskedLM.cls", "transformers.modeling_outputs.MaskedLMOutput", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_unimo.UnimoForMaskedLM.view", "labels.view"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.get_output_embeddings": [[895, 897], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.set_output_embeddings": [[898, 900], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.tie_weights": [[901, 904], ["modeling_unimo.UnimoForMaskedLM.get_output_embeddings", "modeling_unimo.UnimoForMaskedLM._tie_or_clone_weights", "modeling_unimo.UnimoForMaskedLM.unimo.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM._tie_or_clone_weights", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoModel.get_input_embeddings"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM._tie_or_clone_weights": [[905, 924], ["torch.nn.Parameter", "getattr", "torch.nn.functional.pad", "hasattr", "hasattr", "input_embeddings.weight.clone"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoOnlyMLMHead.__init__": [[930, 933], ["torch.nn.Module.__init__", "modeling_unimo.UnimoLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoOnlyMLMHead.forward": [[934, 937], ["modeling_unimo.UnimoOnlyMLMHead.predictions"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoLMPredictionHead.__init__": [[940, 952], ["torch.nn.Module.__init__", "modeling_unimo.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoLMPredictionHead.forward": [[953, 957], ["modeling_unimo.UnimoLMPredictionHead.transform", "modeling_unimo.UnimoLMPredictionHead.decoder"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertPredictionHeadTransform.__init__": [[960, 968], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.BertPredictionHeadTransform.forward": [[969, 974], ["modeling_unimo.BertPredictionHeadTransform.dense", "modeling_unimo.BertPredictionHeadTransform.transform_act_fn", "modeling_unimo.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.resize_token_embeddings": [[925, 928], ["modeling_unimo.UnimoForMaskedLM.unimo.resize_token_embeddings", "modeling_unimo.UnimoForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.resize_token_embeddings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.tie_weights"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.model.UnimoKGC.add_to_argparse": [[5, 9], ["parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_to_argparse", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"--pretrain\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"\"", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.LabelSmoothSoftmaxCEV1.__init__": [[10, 16], ["torch.Module.__init__", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["\n", "max_len", "=", "int", "(", "max_len", ")", "if", "max_len", "else", "seq_len", ".", "max", "(", ")", ".", "long", "(", ")", "\n", "cast_seq", "=", "torch", ".", "arange", "(", "max_len", ")", ".", "expand", "(", "seq_len", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "to", "(", "seq_len", ")", "\n", "mask", "=", "cast_seq", ".", "lt", "(", "seq_len", ".", "unsqueeze", "(", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.LabelSmoothSoftmaxCEV1.forward": [[17, 42], ["utils.LabelSmoothSoftmaxCEV1.log_softmax", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "logits.size", "torch.empty_like().fill_().scatter_().detach.clone().detach", "torch.empty_like().fill_().scatter_().detach.clone().detach", "torch.empty_like().fill_().scatter_().detach", "torch.empty_like().fill_().scatter_().detach", "torch.empty_like().fill_().scatter_().detach", "torch.empty_like().fill_().scatter_().detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss.sum.sum.sum", "loss.sum.sum.sum", "torch.empty_like().fill_().scatter_().detach.clone", "torch.empty_like().fill_().scatter_().detach.clone", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_().detach.unsqueeze", "torch.empty_like().fill_().scatter_().detach.unsqueeze", "torch.empty_like().fill_", "torch.empty_like().fill_", "torch.empty_like().fill_", "torch.empty_like().fill_", "torch.empty_like", "torch.empty_like", "torch.empty_like", "torch.empty_like"], "methods", ["None"], ["return", "mask", "\n", "\n", "\n", "", "def", "set_seed", "(", "seed", "=", "2021", ")", ":", "\n", "    ", "\"\"\"sets random seed\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n", "", "def", "convert_preds_to_outputs", "(", "preds", ",", "raw_words", ",", "mapping", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"convet model predicitons to BIO outputs\n\n    Args:\n        preds ([torch.Tensor]): [prompt model predictions, (bsz x seq_len x labels)]\n        raw_words ([List]): [source raw words]\n        mapping ([dict]): [map entity labels to <<>>]\n        tokenizer : [BartTokenizer]\n\n    Returns:\n        [outputs (List)]: [each item length equal to raw_words, BIO format.]\n    \"\"\"", "\n", "id2label", "=", "list", "(", "mapping", ".", "keys", "(", ")", ")", "\n", "pred_eos_index", "=", "preds", ".", "flip", "(", "dims", "=", "[", "1", "]", ")", ".", "eq", "(", "1", ")", ".", "cumsum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.LabelSmoothing.__init__": [[48, 56], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["outputs", "=", "[", "]", "\n", "for", "i", ",", "pred_item", "in", "enumerate", "(", "preds", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "pred_item", "=", "pred_item", "[", ":", "pred_seq_len", "[", "i", "]", "]", "# single sentence prediction", "\n", "pairs", ",", "cur_pair", "=", "[", "]", ",", "[", "]", "\n", "if", "len", "(", "pred_item", ")", ":", "# this sentence prediciton= is not null", "\n", "            ", "for", "idx", "in", "pred_item", ":", "\n", "                ", "if", "idx", "<", "word_start_index", ":", "# is entity", "\n", "                    ", "if", "len", "(", "cur_pair", ")", ">", "0", ":", "\n", "# assert word[i] < word[i+1]", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.LabelSmoothing.forward": [[57, 65], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "nll_loss.squeeze.squeeze.squeeze", "loss.mean", "torch.nn.functional.log_softmax.gather", "torch.nn.functional.log_softmax.gather", "torch.nn.functional.log_softmax.mean", "torch.nn.functional.log_softmax.mean", "target.unsqueeze"], "methods", ["None"], ["                        ", "if", "all", "(", "[", "cur_pair", "[", "i", "]", "<", "cur_pair", "[", "i", "+", "1", "]", "for", "i", "in", "range", "(", "len", "(", "cur_pair", ")", "-", "1", ")", "]", ")", ":", "\n", "                            ", "pairs", ".", "append", "(", "tuple", "(", "cur_pair", "+", "[", "idx", "]", ")", ")", "# add valid words and current entity id", "\n", "", "", "cur_pair", "=", "[", "]", "# clear word pairs", "\n", "", "else", ":", "# is word", "\n", "                    ", "cur_pair", ".", "append", "(", "idx", ")", "# add word id to word pairs", "\n", "", "", "", "raw_words_item", "=", "raw_words", "[", "i", "]", "\n", "cum_lens", "=", "[", "1", "]", "\n", "start_idx", "=", "1", "\n", "for", "word", "in", "raw_words_item", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.cached_property.__get__": [[1020, 1032], ["getattr", "AttributeError", "utils.cached_property.fget", "setattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__post_init__": [[1084, 1123], ["dataclasses.fields", "len", "all", "getattr", "all", "utils.is_tensor", "iter", "getattr", "getattr", "setattr", "isinstance", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_tensor"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__delitem__": [[1124, 1126], ["Exception"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.setdefault": [[1127, 1129], ["Exception"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop": [[1130, 1132], ["Exception"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update": [[1133, 1135], ["Exception"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__getitem__": [[1136, 1142], ["isinstance", "utils.ModelOutput.to_tuple", "utils.ModelOutput.items"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.to_tuple"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__setattr__": [[1143, 1148], ["collections.OrderedDict.__setattr__", "super().__setitem__", "utils.ModelOutput.keys"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.Config.__setattr__", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__setitem__"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__setitem__": [[1149, 1154], ["super().__setitem__", "collections.OrderedDict.__setattr__"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.__setitem__", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.Config.__setattr__"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.to_tuple": [[1155, 1160], ["tuple", "utils.ModelOutput.keys"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.get_entity_spans_pre_processing": [[66, 77], ["None"], "function", ["None"], ["            ", "start_idx", "+=", "len", "(", "tokenizer", ".", "tokenize", "(", "word", ",", "add_prefix_space", "=", "True", ")", ")", "\n", "cum_lens", ".", "append", "(", "start_idx", ")", "\n", "", "cum_lens", ".", "append", "(", "start_idx", "+", "1", ")", "\n", "output", "=", "[", "'O'", "for", "_", "in", "range", "(", "len", "(", "raw_words_item", ")", ")", "]", "\n", "# pairs: List[(word id, ... , entity id), (...), ...]", "\n", "for", "pair", "in", "pairs", ":", "# (word id, ... , entity id)", "\n", "            ", "entity", "=", "pair", "[", "-", "1", "]", "\n", "words", "=", "[", "]", "\n", "for", "word", "in", "pair", "[", ":", "-", "1", "]", ":", "\n", "                ", "if", "word", "-", "word_start_index", "in", "cum_lens", ":", "\n", "                    ", "words", ".", "append", "(", "cum_lens", ".", "index", "(", "word", "-", "word_start_index", ")", ")", "\n", "", "", "if", "len", "(", "words", ")", "==", "0", ":", "continue", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.label_smoothed_nll_loss": [[80, 99], ["nll_loss.squeeze.mean", "smooth_loss.squeeze.mean", "target.unsqueeze.dim", "target.unsqueeze.unsqueeze", "lprobs.gather", "lprobs.sum", "target.unsqueeze.eq", "nll_loss.squeeze.masked_fill_", "smooth_loss.squeeze.masked_fill_", "nll_loss.squeeze.squeeze", "smooth_loss.squeeze.squeeze", "lprobs.size", "lprobs.dim"], "function", ["None"], ["output", "[", "start_idx", "]", "=", "f'B-{id2label[entity-2]}'", "\n", "for", "_", "in", "range", "(", "start_idx", "+", "1", ",", "end_idx", "+", "1", ")", ":", "\n", "                ", "output", "[", "_", "]", "=", "f'I-{id2label[entity-2]}'", "\n", "", "", "outputs", ".", "append", "(", "output", ")", "\n", "", "return", "outputs", "\n", "\n", "\n", "", "def", "write_predictions", "(", "path", ",", "texts", ",", "labels", ",", "imgids", "=", "None", ")", ":", "\n", "    ", "\"\"\"[write model predictions to path (conll format)]\n\n    Args:\n        path ([str]): [save path]\n        texts ([List]): [raw texts]\n        labels ([List]): [predict labels]\n    \"\"\"", "\n", "print", "(", "len", "(", "texts", ")", ",", "len", "(", "labels", ")", ")", "\n", "assert", "len", "(", "texts", ")", "==", "len", "(", "labels", ")", "\n", "with", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "# f.writelines(\"-DOCSTART-\tO\\n\\n\")", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "texts", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_torch_available": [[260, 262], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_tf_available": [[264, 266], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_torch_tpu_available": [[268, 270], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_datasets_available": [[272, 274], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_psutil_available": [[276, 278], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_py3nvml_available": [[280, 282], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_apex_available": [[284, 286], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_faiss_available": [[288, 290], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.add_start_docstrings": [[292, 298], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.add_start_docstrings_to_callable": [[300, 316], ["fn.__qualname__.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.add_end_docstrings": [[318, 324], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._get_indent": [[346, 350], ["re.search", "re.search.groups"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._convert_output_args_doc": [[352, 376], ["utils._get_indent", "output_args_doc.split", "blocks.append", "range", "len", "re.sub", "re.sub", "utils._get_indent", "len", "blocks.append"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._get_indent", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._get_indent"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._prepare_output_docstrings": [[378, 398], ["_convert_output_args_doc.split", "intro.format.format", "len", "utils._convert_output_args_doc", "output_type.__name__.startswith", "len", "re.search"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._convert_output_args_doc"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.add_code_sample_docstrings": [[637, 665], ["code_sample.format", "fn.__qualname__.split", "utils._prepare_output_docstrings", "ValueError"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._prepare_output_docstrings"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.replace_return_docstrings": [[667, 685], ["docstrings.split", "len", "utils._prepare_output_docstrings", "ValueError", "len", "re.search"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils._prepare_output_docstrings"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_remote_url": [[687, 690], ["urllib.parse.urlparse"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.hf_bucket_url": [[692, 720], ["PRESET_MIRROR_DICT.get"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.url_to_filename": [[722, 744], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "url.endswith", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.encode", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.encode"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.filename_to_url": [[746, 770], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "open", "json.load"], "function", ["None"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.cached_path": [[772, 862], ["isinstance", "isinstance", "utils.is_remote_url", "str", "str", "utils.get_from_cache", "os.path.exists", "os.path.split", "os.path.join", "output_file.replace", "os.path.isdir", "os.listdir", "filelock.FileLock", "shutil.rmtree", "os.makedirs", "zipfile.is_zipfile", "EnvironmentError", "ValueError", "zipfile.is_zipfile", "tarfile.is_tarfile", "tarfile.is_tarfile", "urllib.parse.urlparse", "zipfile.ZipFile", "zip_file.extractall", "zip_file.close", "tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "EnvironmentError"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_remote_url", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.get_from_cache"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.http_get": [[864, 895], ["utils.is_torch_available", "utils.is_tf_available", "isinstance", "requests.get", "requests.get.headers.get", "tqdm.auto.tqdm", "requests.get.iter_content", "tqdm.auto.tqdm.close", "isinstance", "sys.version.split", "int", "bool", "tqdm.auto.tqdm.update", "temp_file.write", "len", "transformers.utils.logging.get_verbosity", "user_agent.items"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_torch_available", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_tf_available", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.get_from_cache": [[897, 1009], ["isinstance", "os.makedirs", "utils.url_to_filename", "os.path.join", "str", "os.path.exists", "os.path.exists", "filelock.FileLock", "logger.info", "os.replace", "logger.info", "requests.head", "os.path.exists", "os.path.exists", "functools.partial", "functools.partial.", "logger.info", "utils.http_get", "open", "json.dump", "requests.head.headers.get", "len", "os.path.join", "fnmatch.filter", "ValueError", "open", "os.stat", "os.listdir", "file.endswith", "file.endswith"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.url_to_filename", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.http_get"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.torch_required": [[1034, 1044], ["functools.wraps", "utils.is_torch_available", "func", "ImportError"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_torch_available"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.tf_required": [[1046, 1056], ["functools.wraps", "utils.is_tf_available", "func", "ImportError"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_tf_available"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_tensor": [[1058, 1071], ["utils.is_torch_available", "utils.is_tf_available", "isinstance", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_torch_available", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.is_tf_available"], []], "home.repos.pwc.inspect_result.zjunlp_MKGformer.MNER.run.main": [[59, 141], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torchvision.transforms.Compose", "utils.utils.set_seed", "print", "os.path.join", "transformers.CLIPProcessor.from_pretrained", "transformers.CLIPProcessor.from_pretrained", "transformers.CLIPProcessor.from_pretrained", "models.modeling_clip.CLIPModel.from_pretrained", "data_process", "dataset_class", "torch.utils.data.DataLoader", "dataset_class", "torch.utils.data.DataLoader", "dataset_class", "torch.utils.data.DataLoader", "transformers.BertConfig.from_pretrained", "models.unimo_model.UnimoCRFModel", "modules.train.BertTrainer", "transformers.BertModel.from_pretrained", "clip_vit.state_dict", "BertModel.from_pretrained.state_dict", "modules.train.BertTrainer.train", "torch.cuda.empty_cache", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.exists", "os.makedirs", "transformers.CLIPConfig.from_pretrained", "enumerate", "str", "str"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.set_seed", "home.repos.pwc.inspect_result.zjunlp_MKGformer.modules.train.BertTrainer.train"], ["\n", "def", "set_seed", "(", "seed", "=", "2021", ")", ":", "\n", "    ", "\"\"\"set random seed\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "default", "=", "'bert'", ",", "type", "=", "str", ",", "help", "=", "\"The name of bert.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vit_name'", ",", "default", "=", "'vit'", ",", "type", "=", "str", ",", "help", "=", "\"The name of vit.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_name'", ",", "default", "=", "'twitter15'", ",", "type", "=", "str", ",", "help", "=", "\"The name of dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_name'", ",", "default", "=", "'bert-base'", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained language model name, bart-base or bart-large\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"Training epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "default", "=", "'cuda'", ",", "type", "=", "str", ",", "help", "=", "\"cuda or cpu\"", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "\"batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "2e-5", ",", "type", "=", "float", ",", "help", "=", "\"learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_ratio'", ",", "default", "=", "0.01", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_begin_epoch'", ",", "default", "=", "16", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"random seed, default is 1\"", ")", "\n", "parser", ".", "add_argument", "(", "'--load_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Load model from load_path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"save model at save_path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--write_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"do_test=True, predictions will be write in write_path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--notes'", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"input some remarks for making save path dir.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--do_train'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do_test'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do_predict'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--prompt_len'", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq'", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--aux_size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "help", "=", "\"aux size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rcnn_size'", ",", "default", "=", "64", ",", "type", "=", "int", ",", "help", "=", "\"rcnn size\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data_path", ",", "img_path", ",", "aux_path", "=", "DATA_PATH", "[", "args", ".", "dataset_name", "]", ",", "IMG_PATH", "[", "args", ".", "dataset_name", "]", ",", "AUX_PATH", "[", "args", ".", "dataset_name", "]", "\n", "data_process", ",", "dataset_class", "=", "MODEL_CLASS", "[", "args", ".", "model_name", "]", "\n", "re_path", "=", "'data/ours_rel2id.json'", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n", "set_seed", "(", "args", ".", "seed", ")", "# set seed, default is 1", "\n", "if", "args", ".", "save_path", "is", "not", "None", ":", "# make save_path dir", "\n", "        ", "args", ".", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "args", ".", "model_name", ",", "args", ".", "dataset_name", "+", "\"_\"", "+", "str", "(", "args", ".", "batch_size", ")", "+", "\"_\"", "+", "str", "(", "args", ".", "lr", ")", "+", "\"_\"", "+", "args", ".", "notes", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "", "", "print", "(", "args", ")", "\n", "logdir", "=", "\"logs/\"", "+", "args", ".", "model_name", "+", "\"_\"", "+", "args", ".", "dataset_name", "+", "\"_\"", "+", "str", "(", "args", ".", "batch_size", ")", "+", "\"_\"", "+", "str", "(", "args", ".", "lr", ")", "+", "args", ".", "notes", "\n", "# writer = SummaryWriter(logdir=logdir)", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "clip_vit", ",", "clip_processor", ",", "aux_processor", ",", "rcnn_processor", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "clip_processor", "=", "CLIPProcessor", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "aux_processor", "=", "CLIPProcessor", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "aux_processor", ".", "feature_extractor", ".", "size", ",", "aux_processor", ".", "feature_extractor", ".", "crop_size", "=", "args", ".", "aux_size", ",", "args", ".", "aux_size", "\n", "rcnn_processor", "=", "CLIPProcessor", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "rcnn_processor", ".", "feature_extractor", ".", "size", ",", "rcnn_processor", ".", "feature_extractor", ".", "crop_size", "=", "args", ".", "rcnn_size", ",", "args", ".", "rcnn_size", "\n", "clip_model", "=", "CLIPModel", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", "\n", "clip_vit", "=", "clip_model", ".", "vision_model", "\n", "\n", "processor", "=", "data_process", "(", "data_path", ",", "re_path", ",", "args", ".", "bert_name", ",", "clip_processor", "=", "clip_processor", ",", "aux_processor", "=", "aux_processor", ",", "rcnn_processor", "=", "rcnn_processor", ")", "\n", "train_dataset", "=", "dataset_class", "(", "processor", ",", "transform", ",", "img_path", ",", "aux_path", ",", "args", ".", "max_seq", ",", "aux_size", "=", "args", ".", "aux_size", ",", "rcnn_size", "=", "args", ".", "rcnn_size", ",", "mode", "=", "'train'", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "dev_dataset", "=", "dataset_class", "(", "processor", ",", "transform", ",", "img_path", ",", "aux_path", ",", "args", ".", "max_seq", ",", "aux_size", "=", "args", ".", "aux_size", ",", "rcnn_size", "=", "args", ".", "rcnn_size", ",", "mode", "=", "'dev'", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "test_dataset", "=", "dataset_class", "(", "processor", ",", "transform", ",", "img_path", ",", "aux_path", ",", "args", ".", "max_seq", ",", "aux_size", "=", "args", ".", "aux_size", ",", "rcnn_size", "=", "args", ".", "rcnn_size", ",", "mode", "=", "'test'", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "re_dict", "=", "processor", ".", "get_relation_dict", "(", ")", "\n", "num_labels", "=", "len", "(", "re_dict", ")", "\n", "tokenizer", "=", "processor", ".", "tokenizer", "\n", "\n", "# test", "\n", "vision_config", "=", "CLIPConfig", ".", "from_pretrained", "(", "args", ".", "vit_name", ")", ".", "vision_config", "\n", "text_config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "bert_name", ")", "\n", "bert", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_name", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunks": [[4, 47], ["enumerate", "chunks.append", "tags.items", "chunks.append", "len", "ner_evaluate.get_chunk_type", "chunks.append"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunk_type"], ["def", "get_chunks", "(", "seq", ",", "tags", ")", ":", "\n", "\t", "\"\"\"\n\ttags:dic{'per':1,....}\n\tArgs:\n\t\tseq: [4, 4, 0, 0, ...] sequence of labels\n\t\ttags: dict[\"O\"] = 4\n\tReturns:\n\t\tlist of (chunk_type, chunk_start, chunk_end)\n\n\tExample:\n\t\tseq = [4, 5, 0, 3]\n\t\ttags = {\"B-PER\": 4, \"I-PER\": 5, \"B-LOC\": 3}\n\t\tresult = [(\"PER\", 0, 2), (\"LOC\", 3, 4)]\n\t\"\"\"", "\n", "default", "=", "tags", "[", "'O'", "]", "\n", "idx_to_tag", "=", "{", "idx", ":", "tag", "for", "tag", ",", "idx", "in", "tags", ".", "items", "(", ")", "}", "\n", "chunks", "=", "[", "]", "\n", "chunk_type", ",", "chunk_start", "=", "None", ",", "None", "\n", "for", "i", ",", "tok", "in", "enumerate", "(", "seq", ")", ":", "\n", "#End of a chunk 1 ", "\n", "\t\t", "if", "tok", "==", "default", "and", "chunk_type", "is", "not", "None", ":", "\n", "# Add a chunk.", "\n", "\t\t\t", "chunk", "=", "(", "chunk_type", ",", "chunk_start", ",", "i", ")", "\n", "chunks", ".", "append", "(", "chunk", ")", "\n", "chunk_type", ",", "chunk_start", "=", "None", ",", "None", "\n", "\n", "# End of a chunk + start of a chunk!", "\n", "", "elif", "tok", "!=", "default", ":", "\n", "\t\t\t", "tok_chunk_class", ",", "tok_chunk_type", "=", "get_chunk_type", "(", "tok", ",", "idx_to_tag", ")", "\n", "if", "chunk_type", "is", "None", ":", "\n", "\t\t\t\t", "chunk_type", ",", "chunk_start", "=", "tok_chunk_type", ",", "i", "\n", "", "elif", "tok_chunk_type", "!=", "chunk_type", "or", "tok_chunk_class", "==", "\"B\"", ":", "\n", "\t\t\t\t", "chunk", "=", "(", "chunk_type", ",", "chunk_start", ",", "i", ")", "\n", "chunks", ".", "append", "(", "chunk", ")", "\n", "chunk_type", ",", "chunk_start", "=", "tok_chunk_type", ",", "i", "\n", "", "", "else", ":", "\n", "\t\t\t", "pass", "\n", "# end condition", "\n", "", "", "if", "chunk_type", "is", "not", "None", ":", "\n", "\t\t", "chunk", "=", "(", "chunk_type", ",", "chunk_start", ",", "len", "(", "seq", ")", ")", "\n", "chunks", ".", "append", "(", "chunk", ")", "\n", "\n", "", "return", "chunks", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunk_type": [[48, 60], ["tag_name.split", "tag_name.split"], "function", ["None"], ["", "def", "get_chunk_type", "(", "tok", ",", "idx_to_tag", ")", ":", "\n", "\t", "\"\"\"\n\tArgs:\n\t\ttok: id of token, such as 4\n\t\tidx_to_tag: dictionary {4: \"B-PER\", ...}\n\tReturns:\n\t\ttuple: \"B\", \"PER\"\n\t\"\"\"", "\n", "tag_name", "=", "idx_to_tag", "[", "tok", "]", "\n", "tag_class", "=", "tag_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "tag_type", "=", "tag_name", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "return", "tag_class", ",", "tag_type", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.evaluate": [[62, 108], ["zip", "numpy.mean", "set", "set", "len", "len", "len", "ner_evaluate.get_chunks", "ner_evaluate.get_chunks", "zip"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunks", "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunks"], ["", "def", "evaluate", "(", "labels_pred", ",", "labels", ",", "tags", ")", ":", "\n", "\n", "\t", "\"\"\"\n\twords,pred, right: is a sequence, is label index or word index.\n\tEvaluates performance on test set\n\tArgs:\n\t\tsess: tensorflow session\n\t\ttest: dataset that yields tuple of sentences, tags\n\t\ttags: {tag: index} dictionary\n\tReturns:\n\t\taccuracy\n\t\tf1 score\n\t\t...\n\t\"\"\"", "\n", "\n", "#file_write = open('./test_results.txt','w')", "\n", "\n", "\n", "index", "=", "0", "\n", "sents_length", "=", "[", "]", "\n", "\n", "accs", "=", "[", "]", "\n", "correct_preds", ",", "total_correct", ",", "total_preds", "=", "0.", ",", "0.", ",", "0.", "\n", "\n", "\n", "for", "lab", ",", "lab_pred", "in", "zip", "(", "labels", ",", "labels_pred", ")", ":", "\n", "\t\t", "lab", "=", "lab", "\n", "lab_pred", "=", "lab_pred", "\n", "accs", "+=", "[", "a", "==", "b", "for", "(", "a", ",", "b", ")", "in", "zip", "(", "lab", ",", "lab_pred", ")", "]", "\n", "lab_chunks", "=", "set", "(", "get_chunks", "(", "lab", ",", "tags", ")", ")", "\n", "lab_pred_chunks", "=", "set", "(", "get_chunks", "(", "lab_pred", ",", "tags", ")", ")", "\n", "correct_preds", "+=", "len", "(", "lab_chunks", "&", "lab_pred_chunks", ")", "\n", "total_preds", "+=", "len", "(", "lab_pred_chunks", ")", "\n", "total_correct", "+=", "len", "(", "lab_chunks", ")", "\n", "\n", "#for i in range(len(word_st)):", "\n", "#file_write.write('%s\\t%s\\t%s\\n'%(word_st[i],lab[i],lab_pred[i]))", "\n", "#file_write.write('\\n')", "\n", "\n", "", "p", "=", "correct_preds", "/", "total_preds", "if", "correct_preds", ">", "0", "else", "0", "\n", "r", "=", "correct_preds", "/", "total_correct", "if", "correct_preds", ">", "0", "else", "0", "\n", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "if", "correct_preds", ">", "0", "else", "0", "\n", "acc", "=", "np", ".", "mean", "(", "accs", ")", "\n", "\n", "#file_write.close()", "\n", "return", "acc", ",", "f1", ",", "p", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.evaluate_each_class": [[109, 145], ["zip", "ner_evaluate.get_chunks", "ner_evaluate.get_chunks", "range", "set", "range", "set", "set", "len", "len", "len", "len", "len", "lab_pre_class_type.append", "lab_class_type.append"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunks", "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.ner_evaluate.get_chunks"], ["", "def", "evaluate_each_class", "(", "labels_pred", ",", "labels", ",", "tags", ",", "class_type", ")", ":", "\n", "#class_type:PER or LOC or ORG", "\n", "\t\t", "index", "=", "0", "\n", "\n", "accs", "=", "[", "]", "\n", "correct_preds", ",", "total_correct", ",", "total_preds", "=", "0.", ",", "0.", ",", "0.", "\n", "correct_preds_cla_type", ",", "total_preds_cla_type", ",", "total_correct_cla_type", "=", "0.", ",", "0.", ",", "0.", "\n", "\n", "for", "lab", ",", "lab_pred", "in", "zip", "(", "labels", ",", "labels_pred", ")", ":", "\n", "\t\t\t\t", "lab_pre_class_type", "=", "[", "]", "\n", "lab_class_type", "=", "[", "]", "\n", "\n", "lab", "=", "lab", "\n", "lab_pred", "=", "lab_pred", "\n", "lab_chunks", "=", "get_chunks", "(", "lab", ",", "tags", ")", "\n", "lab_pred_chunks", "=", "get_chunks", "(", "lab_pred", ",", "tags", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "lab_pred_chunks", ")", ")", ":", "\n", "\t\t\t\t\t\t", "if", "lab_pred_chunks", "[", "i", "]", "[", "0", "]", "==", "class_type", ":", "\n", "\t\t\t\t\t\t\t\t", "lab_pre_class_type", ".", "append", "(", "lab_pred_chunks", "[", "i", "]", ")", "\n", "", "", "lab_pre_class_type_c", "=", "set", "(", "lab_pre_class_type", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "lab_chunks", ")", ")", ":", "\n", "\t\t\t\t\t\t", "if", "lab_chunks", "[", "i", "]", "[", "0", "]", "==", "class_type", ":", "\n", "\t\t\t\t\t\t\t\t", "lab_class_type", ".", "append", "(", "lab_chunks", "[", "i", "]", ")", "\n", "", "", "lab_class_type_c", "=", "set", "(", "lab_class_type", ")", "\n", "\n", "lab_chunksss", "=", "set", "(", "lab_chunks", ")", "\n", "correct_preds_cla_type", "+=", "len", "(", "lab_pre_class_type_c", "&", "lab_chunksss", ")", "\n", "total_preds_cla_type", "+=", "len", "(", "lab_pre_class_type_c", ")", "\n", "total_correct_cla_type", "+=", "len", "(", "lab_class_type_c", ")", "\n", "\n", "", "p", "=", "correct_preds_cla_type", "/", "total_preds_cla_type", "if", "correct_preds_cla_type", ">", "0", "else", "0", "\n", "r", "=", "correct_preds_cla_type", "/", "total_correct_cla_type", "if", "correct_preds_cla_type", ">", "0", "else", "0", "\n", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "if", "correct_preds_cla_type", ">", "0", "else", "0", "\n", "\n", "return", "f1", ",", "p", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.seq_to_mask": [[8, 18], ["torch.arange().expand().to", "torch.arange().expand().to.lt", "int", "seq_len.max().long", "seq_len.unsqueeze", "torch.arange().expand", "seq_len.max", "seq_len.size", "torch.arange"], "function", ["None"], ["def", "seq_to_mask", "(", "seq_len", ",", "max_len", ")", ":", "\n", "    ", "\"\"\"[get attention mask with sequence length]\n\n    Args:\n        seq_len ([torch.tensor]): [shape: bsz, each sequence length in a batch]\n    \"\"\"", "\n", "max_len", "=", "int", "(", "max_len", ")", "if", "max_len", "else", "seq_len", ".", "max", "(", ")", ".", "long", "(", ")", "\n", "cast_seq", "=", "torch", ".", "arange", "(", "max_len", ")", ".", "expand", "(", "seq_len", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "to", "(", "seq_len", ")", "\n", "mask", "=", "cast_seq", ".", "lt", "(", "seq_len", ".", "unsqueeze", "(", "1", ")", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.set_seed": [[20, 27], ["torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", "=", "2021", ")", ":", "\n", "    ", "\"\"\"sets random seed\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.convert_preds_to_outputs": [[29, 85], ["list", "preds.flip().eq().cumsum().long", "preds.flip().eq().cumsum().long.flip().eq().sum", "enumerate", "mapping.keys", "len", "preds.tolist", "len", "cum_lens.append", "outputs.append", "preds.flip().eq().cumsum", "preds.flip().eq().cumsum().long.flip().eq", "len", "cum_lens.append", "range", "tokenizer.tokenize", "range", "len", "preds.flip().eq", "preds.flip().eq().cumsum().long.flip", "cur_pair.append", "len", "words.append", "len", "all", "cum_lens.index", "preds.flip", "pairs.append", "tuple", "range", "len"], "function", ["None"], ["", "def", "convert_preds_to_outputs", "(", "preds", ",", "raw_words", ",", "mapping", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"convet model predicitons to BIO outputs\n\n    Args:\n        preds ([torch.Tensor]): [prompt model predictions, (bsz x seq_len x labels)]\n        raw_words ([List]): [source raw words]\n        mapping ([dict]): [map entity labels to <<>>]\n        tokenizer : [BartTokenizer]\n\n    Returns:\n        [outputs (List)]: [each item length equal to raw_words, BIO format.]\n    \"\"\"", "\n", "id2label", "=", "list", "(", "mapping", ".", "keys", "(", ")", ")", "\n", "pred_eos_index", "=", "preds", ".", "flip", "(", "dims", "=", "[", "1", "]", ")", ".", "eq", "(", "1", ")", ".", "cumsum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "preds", "=", "preds", "[", ":", ",", "1", ":", "]", "\n", "pred_seq_len", "=", "pred_eos_index", ".", "flip", "(", "dims", "=", "[", "1", "]", ")", ".", "eq", "(", "pred_eos_index", "[", ":", ",", "-", "1", ":", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "# bsz", "\n", "pred_seq_len", "=", "(", "pred_seq_len", "-", "2", ")", ".", "tolist", "(", ")", "\n", "\n", "word_start_index", "=", "len", "(", "mapping", ")", "+", "2", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "pred_item", "in", "enumerate", "(", "preds", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "pred_item", "=", "pred_item", "[", ":", "pred_seq_len", "[", "i", "]", "]", "# single sentence prediction", "\n", "pairs", ",", "cur_pair", "=", "[", "]", ",", "[", "]", "\n", "if", "len", "(", "pred_item", ")", ":", "# this sentence prediciton= is not null", "\n", "            ", "for", "idx", "in", "pred_item", ":", "\n", "                ", "if", "idx", "<", "word_start_index", ":", "# is entity", "\n", "                    ", "if", "len", "(", "cur_pair", ")", ">", "0", ":", "\n", "# assert word[i] < word[i+1]", "\n", "                        ", "if", "all", "(", "[", "cur_pair", "[", "i", "]", "<", "cur_pair", "[", "i", "+", "1", "]", "for", "i", "in", "range", "(", "len", "(", "cur_pair", ")", "-", "1", ")", "]", ")", ":", "\n", "                            ", "pairs", ".", "append", "(", "tuple", "(", "cur_pair", "+", "[", "idx", "]", ")", ")", "# add valid words and current entity id", "\n", "", "", "cur_pair", "=", "[", "]", "# clear word pairs", "\n", "", "else", ":", "# is word", "\n", "                    ", "cur_pair", ".", "append", "(", "idx", ")", "# add word id to word pairs", "\n", "", "", "", "raw_words_item", "=", "raw_words", "[", "i", "]", "\n", "cum_lens", "=", "[", "1", "]", "\n", "start_idx", "=", "1", "\n", "for", "word", "in", "raw_words_item", ":", "\n", "            ", "start_idx", "+=", "len", "(", "tokenizer", ".", "tokenize", "(", "word", ",", "add_prefix_space", "=", "True", ")", ")", "\n", "cum_lens", ".", "append", "(", "start_idx", ")", "\n", "", "cum_lens", ".", "append", "(", "start_idx", "+", "1", ")", "\n", "output", "=", "[", "'O'", "for", "_", "in", "range", "(", "len", "(", "raw_words_item", ")", ")", "]", "\n", "# pairs: List[(word id, ... , entity id), (...), ...]", "\n", "for", "pair", "in", "pairs", ":", "# (word id, ... , entity id)", "\n", "            ", "entity", "=", "pair", "[", "-", "1", "]", "\n", "words", "=", "[", "]", "\n", "for", "word", "in", "pair", "[", ":", "-", "1", "]", ":", "\n", "                ", "if", "word", "-", "word_start_index", "in", "cum_lens", ":", "\n", "                    ", "words", ".", "append", "(", "cum_lens", ".", "index", "(", "word", "-", "word_start_index", ")", ")", "\n", "", "", "if", "len", "(", "words", ")", "==", "0", ":", "continue", "\n", "start_idx", "=", "words", "[", "0", "]", "\n", "end_idx", "=", "words", "[", "-", "1", "]", "\n", "output", "[", "start_idx", "]", "=", "f'B-{id2label[entity-2]}'", "\n", "for", "_", "in", "range", "(", "start_idx", "+", "1", ",", "end_idx", "+", "1", ")", ":", "\n", "                ", "output", "[", "_", "]", "=", "f'I-{id2label[entity-2]}'", "\n", "", "", "outputs", ".", "append", "(", "output", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.write_predictions": [[87, 105], ["print", "len", "len", "len", "len", "open", "range", "len", "range", "f.writelines", "f.writelines", "len", "f.writelines", "[].upper"], "function", ["None"], ["", "def", "write_predictions", "(", "path", ",", "texts", ",", "labels", ",", "imgids", "=", "None", ")", ":", "\n", "    ", "\"\"\"[write model predictions to path (conll format)]\n\n    Args:\n        path ([str]): [save path]\n        texts ([List]): [raw texts]\n        labels ([List]): [predict labels]\n    \"\"\"", "\n", "print", "(", "len", "(", "texts", ")", ",", "len", "(", "labels", ")", ")", "\n", "assert", "len", "(", "texts", ")", "==", "len", "(", "labels", ")", "\n", "with", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "# f.writelines(\"-DOCSTART-\tO\\n\\n\")", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "texts", ")", ")", ":", "\n", "            ", "if", "imgids", "is", "not", "None", ":", "\n", "                ", "f", ".", "writelines", "(", "\"IMGID:{}\\n\"", ".", "format", "(", "imgids", "[", "i", "]", ")", ")", "\n", "", "for", "j", "in", "range", "(", "len", "(", "texts", "[", "i", "]", ")", ")", ":", "\n", "                ", "f", ".", "writelines", "(", "\"{}\\t{}\\n\"", ".", "format", "(", "texts", "[", "i", "]", "[", "j", "]", ",", "labels", "[", "i", "]", "[", "j", "]", ".", "upper", "(", ")", ")", ")", "\n", "", "f", ".", "writelines", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.write_bert_predictions": [[107, 119], ["open", "range", "len", "range", "f.writelines", "len", "f.writelines", "[].upper"], "function", ["None"], ["", "", "", "def", "write_bert_predictions", "(", "path", ",", "labels", ")", ":", "\n", "    ", "\"\"\"[write model predictions to path (conll format)]\n\n    Args:\n        path ([str]): [save path]\n        labels ([List]): [predict labels]\n    \"\"\"", "\n", "with", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "labels", "[", "i", "]", ")", ")", ":", "\n", "                ", "f", ".", "writelines", "(", "labels", "[", "i", "]", "[", "j", "]", ".", "upper", "(", ")", ")", "\n", "", "f", ".", "writelines", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.utils.utils.summary": [[121, 228], ["collections.OrderedDict", "model.apply", "model", "print", "print", "print", "print", "print", "print", "print", "print", "h.remove", "print", "len", "collections.OrderedDict", "list", "numpy.prod", "numpy.prod", "[].split", "input[].size", "isinstance", "hasattr", "hasattr", "torch.prod", "hasattr", "hasattr", "torch.prod", "isinstance", "isinstance", "hooks.append", "hooks.append", "str", "str", "list", "torch.LongTensor", "torch.LongTensor", "module.register_forward_pre_hook", "module.register_forward_hook", "isinstance", "output.size", "list", "list", "str().split", "module.weight.size", "module.bias.size", "str", "list", "list", "out.size", "out[].size"], "function", ["None"], ["", "", "", "def", "summary", "(", "model", ",", "*", "inputs", ",", "batch_size", "=", "-", "1", ",", "show_input", "=", "True", ")", ":", "\n", "    ", "'''\n    \u6253\u5370\u6a21\u578b\u7ed3\u6784\u4fe1\u606f\n    :param model:\n    :param inputs:\n    :param batch_size:\n    :param show_input:\n    :return:\n    Example:\n        >>> print(\"model summary info: \")\n        >>> for step,batch in enumerate(train_data):\n        >>>     summary(self.model,*batch,show_input=True)\n        >>>     break\n    '''", "\n", "\n", "def", "register_hook", "(", "module", ")", ":", "\n", "        ", "def", "hook", "(", "module", ",", "input", ",", "output", "=", "None", ")", ":", "\n", "            ", "class_name", "=", "str", "(", "module", ".", "__class__", ")", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"'\"", ")", "[", "0", "]", "\n", "module_idx", "=", "len", "(", "summary", ")", "\n", "m_key", "=", "f\"{class_name}-{module_idx + 1}\"", "\n", "summary", "[", "m_key", "]", "=", "OrderedDict", "(", ")", "\n", "summary", "[", "m_key", "]", "[", "\"input_shape\"", "]", "=", "list", "(", "input", "[", "0", "]", ".", "size", "(", ")", ")", "\n", "summary", "[", "m_key", "]", "[", "\"input_shape\"", "]", "[", "0", "]", "=", "batch_size", "\n", "\n", "if", "show_input", "is", "False", "and", "output", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "output", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "for", "out", "in", "output", ":", "\n", "                        ", "if", "isinstance", "(", "out", ",", "torch", ".", "Tensor", ")", ":", "\n", "                            ", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "=", "[", "\n", "[", "-", "1", "]", "+", "list", "(", "out", ".", "size", "(", ")", ")", "[", "1", ":", "]", "\n", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "=", "[", "\n", "[", "-", "1", "]", "+", "list", "(", "out", "[", "0", "]", ".", "size", "(", ")", ")", "[", "1", ":", "]", "\n", "]", "[", "0", "]", "\n", "", "", "", "else", ":", "\n", "                    ", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "=", "list", "(", "output", ".", "size", "(", ")", ")", "\n", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "[", "0", "]", "=", "batch_size", "\n", "\n", "", "", "params", "=", "0", "\n", "if", "hasattr", "(", "module", ",", "\"weight\"", ")", "and", "hasattr", "(", "module", ".", "weight", ",", "\"size\"", ")", ":", "\n", "                ", "params", "+=", "torch", ".", "prod", "(", "torch", ".", "LongTensor", "(", "list", "(", "module", ".", "weight", ".", "size", "(", ")", ")", ")", ")", "\n", "summary", "[", "m_key", "]", "[", "\"trainable\"", "]", "=", "module", ".", "weight", ".", "requires_grad", "\n", "", "if", "hasattr", "(", "module", ",", "\"bias\"", ")", "and", "hasattr", "(", "module", ".", "bias", ",", "\"size\"", ")", ":", "\n", "                ", "params", "+=", "torch", ".", "prod", "(", "torch", ".", "LongTensor", "(", "list", "(", "module", ".", "bias", ".", "size", "(", ")", ")", ")", ")", "\n", "", "summary", "[", "m_key", "]", "[", "\"nb_params\"", "]", "=", "params", "\n", "\n", "", "if", "(", "not", "isinstance", "(", "module", ",", "nn", ".", "Sequential", ")", "and", "not", "isinstance", "(", "module", ",", "nn", ".", "ModuleList", ")", "and", "not", "(", "module", "==", "model", ")", ")", ":", "\n", "            ", "if", "show_input", "is", "True", ":", "\n", "                ", "hooks", ".", "append", "(", "module", ".", "register_forward_pre_hook", "(", "hook", ")", ")", "\n", "", "else", ":", "\n", "                ", "hooks", ".", "append", "(", "module", ".", "register_forward_hook", "(", "hook", ")", ")", "\n", "\n", "# create properties", "\n", "", "", "", "summary", "=", "OrderedDict", "(", ")", "\n", "hooks", "=", "[", "]", "\n", "\n", "# register hook", "\n", "model", ".", "apply", "(", "register_hook", ")", "\n", "model", "(", "*", "inputs", ")", "\n", "\n", "# remove these hooks", "\n", "for", "h", "in", "hooks", ":", "\n", "        ", "h", ".", "remove", "(", ")", "\n", "\n", "", "print", "(", "\"-----------------------------------------------------------------------\"", ")", "\n", "if", "show_input", "is", "True", ":", "\n", "        ", "line_new", "=", "f\"{'Layer (type)':>25}  {'Input Shape':>25} {'Param #':>15}\"", "\n", "", "else", ":", "\n", "        ", "line_new", "=", "f\"{'Layer (type)':>25}  {'Output Shape':>25} {'Param #':>15}\"", "\n", "", "print", "(", "line_new", ")", "\n", "print", "(", "\"=======================================================================\"", ")", "\n", "\n", "total_params", "=", "0", "\n", "total_output", "=", "0", "\n", "trainable_params", "=", "0", "\n", "for", "layer", "in", "summary", ":", "\n", "# input_shape, output_shape, trainable, nb_params", "\n", "        ", "if", "show_input", "is", "True", ":", "\n", "            ", "line_new", "=", "\"{:>25}  {:>25} {:>15}\"", ".", "format", "(", "\n", "layer", ",", "\n", "str", "(", "summary", "[", "layer", "]", "[", "\"input_shape\"", "]", ")", ",", "\n", "\"{0:,}\"", ".", "format", "(", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "line_new", "=", "\"{:>25}  {:>25} {:>15}\"", ".", "format", "(", "\n", "layer", ",", "\n", "str", "(", "summary", "[", "layer", "]", "[", "\"output_shape\"", "]", ")", ",", "\n", "\"{0:,}\"", ".", "format", "(", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", ")", ",", "\n", ")", "\n", "\n", "", "total_params", "+=", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", "\n", "if", "show_input", "is", "True", ":", "\n", "            ", "total_output", "+=", "np", ".", "prod", "(", "summary", "[", "layer", "]", "[", "\"input_shape\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "total_output", "+=", "np", ".", "prod", "(", "summary", "[", "layer", "]", "[", "\"output_shape\"", "]", ")", "\n", "", "if", "\"trainable\"", "in", "summary", "[", "layer", "]", ":", "\n", "            ", "if", "summary", "[", "layer", "]", "[", "\"trainable\"", "]", "==", "True", ":", "\n", "                ", "trainable_params", "+=", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", "\n", "\n", "", "", "print", "(", "line_new", ")", "\n", "\n", "", "print", "(", "\"=======================================================================\"", ")", "\n", "print", "(", "f\"Total params: {total_params:0,}\"", ")", "\n", "print", "(", "f\"Trainable params: {trainable_params:0,}\"", ")", "\n", "print", "(", "f\"Non-trainable params: {(total_params - trainable_params):0,}\"", ")", "\n", "print", "(", "\"-----------------------------------------------------------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class": [[12, 18], ["module_and_class_name.rsplit", "importlib.import_module", "getattr"], "function", ["None"], ["def", "_import_class", "(", "module_and_class_name", ":", "str", ")", "->", "type", ":", "\n", "    ", "\"\"\"Import class from a module, e.g. 'text_recognizer.models.MLP'\"\"\"", "\n", "module_name", ",", "class_name", "=", "module_and_class_name", ".", "rsplit", "(", "\".\"", ",", "1", ")", "\n", "module", "=", "importlib", ".", "import_module", "(", "module_name", ")", "\n", "class_", "=", "getattr", "(", "module", ",", "class_name", ")", "\n", "return", "class_", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._setup_parser": [[20, 58], ["argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "main._import_class", "main._import_class", "main._import_class", "argparse.ArgumentParser.add_argument_group", "_import_class.add_to_argparse", "argparse.ArgumentParser.add_argument_group", "hasattr", "argparse.ArgumentParser.add_argument_group", "_import_class.add_to_argparse", "argparse.ArgumentParser.add_argument", "_import_class.add_to_argparse"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class", "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class", "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.add_to_argparse", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.add_to_argparse", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.add_to_argparse"], ["", "def", "_setup_parser", "(", ")", ":", "\n", "    ", "\"\"\"Set up Python's ArgumentParser with data, model, trainer, and other arguments.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ")", "\n", "\n", "# Add Trainer specific arguments, such as --max_epochs, --gpus, --precision", "\n", "trainer_parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "trainer_parser", ".", "_action_groups", "[", "1", "]", ".", "title", "=", "\"Trainer Args\"", "# pylint: disable=protected-access", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "parents", "=", "[", "trainer_parser", "]", ")", "\n", "\n", "# Basic arguments", "\n", "parser", ".", "add_argument", "(", "\"--wandb\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--litmodel_class\"", ",", "type", "=", "str", ",", "default", "=", "\"TransformerLitModel\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "7", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_class\"", ",", "type", "=", "str", ",", "default", "=", "\"KGC\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--chunk\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_class\"", ",", "type", "=", "str", ",", "default", "=", "\"RobertaUseLabelWord\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "# Get the data and model classes, so that we can add their specific arguments", "\n", "temp_args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "data_class", "=", "_import_class", "(", "f\"data.{temp_args.data_class}\"", ")", "\n", "model_class", "=", "_import_class", "(", "f\"models.{temp_args.model_class}\"", ")", "\n", "lit_model_class", "=", "_import_class", "(", "f\"lit_models.{temp_args.litmodel_class}\"", ")", "\n", "\n", "# Get data, model, and LitModel specific arguments", "\n", "data_group", "=", "parser", ".", "add_argument_group", "(", "\"Data Args\"", ")", "\n", "data_class", ".", "add_to_argparse", "(", "data_group", ")", "\n", "\n", "model_group", "=", "parser", ".", "add_argument_group", "(", "\"Model Args\"", ")", "\n", "if", "hasattr", "(", "model_class", ",", "\"add_to_argparse\"", ")", ":", "\n", "        ", "model_class", ".", "add_to_argparse", "(", "model_group", ")", "\n", "\n", "", "lit_model_group", "=", "parser", ".", "add_argument_group", "(", "\"LitModel Args\"", ")", "\n", "lit_model_class", ".", "add_to_argparse", "(", "lit_model_group", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--help\"", ",", "\"-h\"", ",", "action", "=", "\"help\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main.main": [[60, 145], ["main._setup_parser", "_setup_parser.parse_args", "print", "numpy.random.seed", "torch.manual_seed", "pytorch_lightning.seed_everything", "main._import_class", "main._import_class", "main._import_class", "transformers.BertConfig.from_pretrained", "transformers.BertModel.from_pretrained", "models.modeling_clip.CLIPModel.from_pretrained", "_import_class.", "clip_vit.state_dict", "BertModel.from_pretrained.state_dict", "main.main.load_state_dict"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._setup_parser", "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class", "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class", "home.repos.pwc.inspect_result.zjunlp_MKGformer.MKG.main._import_class"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "_setup_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "pl", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "data_class", "=", "_import_class", "(", "f\"data.{args.data_class}\"", ")", "# Dataset", "\n", "model_class", "=", "_import_class", "(", "f\"models.{args.model_class}\"", ")", "# Model", "\n", "litmodel_class", "=", "_import_class", "(", "f\"lit_models.{args.litmodel_class}\"", ")", "# Lit_model", "\n", "\n", "# load pretrained visual and textual configs, models", "\n", "vision_config", "=", "CLIPConfig", ".", "from_pretrained", "(", "'/home/lilei/package/clip-vit-base-patch32'", ")", ".", "vision_config", "\n", "text_config", "=", "BertConfig", ".", "from_pretrained", "(", "'/home/lilei/package/bert-base-uncased'", ")", "\n", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'/home/lilei/package/bert-base-uncased'", ")", "\n", "clip_model", "=", "CLIPModel", ".", "from_pretrained", "(", "'/home/lilei/package/clip-vit-base-patch32'", ")", "\n", "clip_vit", "=", "clip_model", ".", "vision_model", "\n", "\n", "vision_config", ".", "device", "=", "'cpu'", "\n", "model", "=", "model_class", "(", "vision_config", ",", "text_config", ")", "\n", "clip_model_dict", "=", "clip_vit", ".", "state_dict", "(", ")", "\n", "text_model_dict", "=", "bert", ".", "state_dict", "(", ")", "\n", "\n", "def", "load_state_dict", "(", ")", ":", "\n", "        ", "\"\"\"Load bert and vit pretrained weights\"\"\"", "\n", "vision_names", ",", "text_names", "=", "[", "]", ",", "[", "]", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "name", "in", "model_dict", ":", "\n", "            ", "if", "'vision'", "in", "name", ":", "\n", "                ", "clip_name", "=", "name", ".", "replace", "(", "'vision_'", ",", "''", ")", ".", "replace", "(", "'model.'", ",", "''", ")", ".", "replace", "(", "'unimo.'", ",", "''", ")", "\n", "if", "clip_name", "in", "clip_model_dict", ":", "\n", "                    ", "vision_names", ".", "append", "(", "clip_name", ")", "\n", "model_dict", "[", "name", "]", "=", "clip_model_dict", "[", "clip_name", "]", "\n", "", "", "elif", "'text'", "in", "name", ":", "\n", "                ", "text_name", "=", "name", ".", "replace", "(", "'text_'", ",", "''", ")", ".", "replace", "(", "'model.'", ",", "''", ")", ".", "replace", "(", "'unimo.'", ",", "''", ")", "\n", "if", "text_name", "in", "text_model_dict", ":", "\n", "                    ", "text_names", ".", "append", "(", "text_name", ")", "\n", "model_dict", "[", "name", "]", "=", "text_model_dict", "[", "text_name", "]", "\n", "", "", "", "assert", "len", "(", "vision_names", ")", "==", "len", "(", "clip_model_dict", ")", "and", "len", "(", "text_names", ")", "==", "len", "(", "text_model_dict", ")", ",", "(", "len", "(", "vision_names", ")", ",", "len", "(", "text_names", ")", ",", "len", "(", "clip_model_dict", ")", ",", "len", "(", "text_model_dict", ")", ")", "\n", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "print", "(", "'Load model state dict successful.'", ")", "\n", "", "load_state_dict", "(", ")", "\n", "\n", "data", "=", "data_class", "(", "args", ",", "model", ")", "\n", "tokenizer", "=", "data", ".", "tokenizer", "\n", "\n", "lit_model", "=", "litmodel_class", "(", "args", "=", "args", ",", "model", "=", "model", ",", "tokenizer", "=", "tokenizer", ",", "data_config", "=", "data", ".", "get_config", "(", ")", ")", "\n", "if", "args", ".", "checkpoint", ":", "\n", "        ", "lit_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "checkpoint", ",", "map_location", "=", "\"cpu\"", ")", "[", "\"state_dict\"", "]", ")", "\n", "\n", "", "logger", "=", "pl", ".", "loggers", ".", "TensorBoardLogger", "(", "\"training/logs\"", ")", "\n", "if", "args", ".", "wandb", ":", "\n", "        ", "logger", "=", "pl", ".", "loggers", ".", "WandbLogger", "(", "project", "=", "\"kgc_bert\"", ",", "name", "=", "args", ".", "data_dir", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ")", "\n", "logger", ".", "log_hyperparams", "(", "vars", "(", "args", ")", ")", "\n", "\n", "", "metric_name", "=", "\"Eval/hits10\"", "\n", "\n", "early_callback", "=", "pl", ".", "callbacks", ".", "EarlyStopping", "(", "monitor", "=", "\"Eval/mrr\"", ",", "mode", "=", "\"max\"", ",", "patience", "=", "5", ")", "\n", "model_checkpoint", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "monitor", "=", "metric_name", ",", "mode", "=", "\"max\"", ",", "\n", "filename", "=", "args", ".", "data_dir", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "+", "'/{epoch}-{Eval/hits10:.2f}-{Eval/hits1:.2f}'", "if", "not", "args", ".", "pretrain", "else", "args", ".", "data_dir", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "+", "'/{epoch}-{step}-{Eval/hits10:.2f}'", ",", "\n", "dirpath", "=", "\"output\"", ",", "\n", "save_weights_only", "=", "True", ",", "\n", ")", "\n", "callbacks", "=", "[", "early_callback", ",", "model_checkpoint", "]", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", ".", "from_argparse_args", "(", "args", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "logger", "=", "logger", ",", "\n", "default_root_dir", "=", "\"training/logs\"", ",", ")", "\n", "\n", "if", "\"EntityEmbedding\"", "not", "in", "lit_model", ".", "__class__", ".", "__name__", ":", "\n", "        ", "trainer", ".", "fit", "(", "lit_model", ",", "datamodule", "=", "data", ")", "\n", "path", "=", "model_checkpoint", ".", "best_model_path", "\n", "lit_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", "[", "\"state_dict\"", "]", ")", "\n", "\n", "", "result", "=", "trainer", ".", "test", "(", "lit_model", ",", "datamodule", "=", "data", ")", "\n", "print", "(", "result", ")", "\n", "\n", "# _saved_pretrain(lit_model, tokenizer, path)", "\n", "if", "\"EntityEmbedding\"", "not", "in", "lit_model", ".", "__class__", ".", "__name__", ":", "\n", "        ", "print", "(", "\"*path\"", "*", "30", ")", "\n", "print", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.Config.__getattr__": [[13, 15], ["base.Config.get"], "methods", ["None"], ["    ", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "get", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.Config.__setattr__": [[16, 18], ["None"], "methods", ["None"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "val", ")", ":", "\n", "        ", "self", "[", "name", "]", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.__init__": [[25, 33], ["pytorch_lightning.LightningModule.__init__", "base.BaseLitModel.args.get", "getattr", "base.BaseLitModel.args.get", "base.Config", "vars"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "args", ":", "argparse", ".", "Namespace", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "args", "=", "Config", "(", "vars", "(", "args", ")", ")", "if", "args", "is", "not", "None", "else", "{", "}", "\n", "\n", "optimizer", "=", "self", ".", "args", ".", "get", "(", "\"optimizer\"", ",", "OPTIMIZER", ")", "\n", "self", ".", "optimizer_class", "=", "getattr", "(", "torch", ".", "optim", ",", "optimizer", ")", "\n", "self", ".", "lr", "=", "self", ".", "args", ".", "get", "(", "\"lr\"", ",", "LR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.add_to_argparse": [[34, 40], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_to_argparse", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"--optimizer\"", ",", "type", "=", "str", ",", "default", "=", "OPTIMIZER", ",", "help", "=", "\"optimizer class from torch.optim\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "LR", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.configure_optimizers": [[41, 47], ["base.BaseLitModel.optimizer_class", "torch.optim.lr_scheduler.OneCycleLR", "base.BaseLitModel.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "optimizer", "=", "self", ".", "optimizer_class", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "if", "self", ".", "one_cycle_max_lr", "is", "None", ":", "\n", "            ", "return", "optimizer", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "OneCycleLR", "(", "optimizer", "=", "optimizer", ",", "max_lr", "=", "self", ".", "one_cycle_max_lr", ",", "total_steps", "=", "self", ".", "one_cycle_total_steps", ")", "\n", "return", "{", "\"optimizer\"", ":", "optimizer", ",", "\"lr_scheduler\"", ":", "scheduler", ",", "\"monitor\"", ":", "\"val_loss\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.forward": [[48, 50], ["base.BaseLitModel.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.training_step": [[51, 59], ["base.BaseLitModel.", "base.BaseLitModel.loss_fn", "base.BaseLitModel.log", "base.BaseLitModel.train_acc", "base.BaseLitModel.log"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "x", ",", "y", "=", "batch", "\n", "logits", "=", "self", "(", "x", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ",", "y", ")", "\n", "self", ".", "log", "(", "\"train_loss\"", ",", "loss", ")", "\n", "self", ".", "train_acc", "(", "logits", ",", "y", ")", "\n", "self", ".", "log", "(", "\"train_acc\"", ",", "self", ".", "train_acc", ",", "on_step", "=", "False", ",", "on_epoch", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.validation_step": [[60, 67], ["base.BaseLitModel.", "base.BaseLitModel.loss_fn", "base.BaseLitModel.log", "base.BaseLitModel.val_acc", "base.BaseLitModel.log"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "x", ",", "y", "=", "batch", "\n", "logits", "=", "self", "(", "x", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ",", "y", ")", "\n", "self", ".", "log", "(", "\"val_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "val_acc", "(", "logits", ",", "y", ")", "\n", "self", ".", "log", "(", "\"val_acc\"", ",", "self", ".", "val_acc", ",", "on_step", "=", "False", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.test_step": [[68, 73], ["base.BaseLitModel.", "base.BaseLitModel.test_acc", "base.BaseLitModel.log"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "x", ",", "y", "=", "batch", "\n", "logits", "=", "self", "(", "x", ")", "\n", "self", ".", "test_acc", "(", "logits", ",", "y", ")", "\n", "self", ".", "log", "(", "\"test_acc\"", ",", "self", ".", "test_acc", ",", "on_step", "=", "False", ",", "on_epoch", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.base.BaseLitModel.num_training_steps": [[74, 96], ["max", "isinstance", "isinstance", "max", "len", "int", "len", "base.BaseLitModel.trainer.datamodule.train_dataloader", "base.BaseLitModel.trainer.datamodule.train_dataloader"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.train_dataloader", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.train_dataloader"], ["", "@", "property", "\n", "def", "num_training_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Total training steps inferred from datamodule and devices.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "trainer", ".", "limit_train_batches", ",", "int", ")", "and", "self", ".", "trainer", ".", "limit_train_batches", "!=", "0", ":", "\n", "            ", "dataset_size", "=", "self", ".", "trainer", ".", "limit_train_batches", "\n", "", "elif", "isinstance", "(", "self", ".", "trainer", ".", "limit_train_batches", ",", "float", ")", ":", "\n", "# limit_train_batches is a percentage of batches", "\n", "            ", "dataset_size", "=", "len", "(", "self", ".", "trainer", ".", "datamodule", ".", "train_dataloader", "(", ")", ")", "\n", "dataset_size", "=", "int", "(", "dataset_size", "*", "self", ".", "trainer", ".", "limit_train_batches", ")", "\n", "", "else", ":", "\n", "            ", "dataset_size", "=", "len", "(", "self", ".", "trainer", ".", "datamodule", ".", "train_dataloader", "(", ")", ")", "\n", "\n", "", "num_devices", "=", "max", "(", "1", ",", "self", ".", "trainer", ".", "num_gpus", ",", "self", ".", "trainer", ".", "num_processes", ")", "\n", "if", "self", ".", "trainer", ".", "tpu_cores", ":", "\n", "            ", "num_devices", "=", "max", "(", "num_devices", ",", "self", ".", "trainer", ".", "tpu_cores", ")", "\n", "\n", "", "effective_batch_size", "=", "self", ".", "trainer", ".", "accumulate_grad_batches", "*", "num_devices", "\n", "max_estimated_steps", "=", "(", "dataset_size", "//", "effective_batch_size", ")", "*", "self", ".", "trainer", ".", "max_epochs", "\n", "\n", "if", "self", ".", "trainer", ".", "max_steps", "and", "self", ".", "trainer", ".", "max_steps", "<", "max_estimated_steps", ":", "\n", "            ", "return", "self", ".", "trainer", ".", "max_steps", "\n", "", "return", "max_estimated_steps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.__init__": [[29, 51], ["base.BaseLitModel.__init__", "transformer.TransformerLitModel.save_hyperparameters", "transformer.TransformerLitModel.__dict__.update", "transformer.TransformerLitModel.model.resize_token_embeddings", "functools.partial", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "len", "transformer.TransformerLitModel._freeze_attention", "utils.LabelSmoothSoftmaxCEV1", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.modeling_unimo.UnimoForMaskedLM.resize_token_embeddings", "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel._freeze_attention"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", ",", "tokenizer", "=", "None", ",", "data_config", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "args", ")", "\n", "self", ".", "save_hyperparameters", "(", "args", ")", "\n", "if", "args", ".", "bce", ":", "\n", "            ", "self", ".", "loss_fn", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "args", ".", "label_smoothing", "!=", "0.0", ":", "\n", "            ", "self", ".", "loss_fn", "=", "LabelSmoothSoftmaxCEV1", "(", "lb_smooth", "=", "args", ".", "label_smoothing", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "", "self", ".", "best_acc", "=", "0", "\n", "self", ".", "first", "=", "True", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "__dict__", ".", "update", "(", "data_config", ")", "\n", "\n", "# resize the word embedding layer", "\n", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "self", ".", "tokenizer", ")", ")", "\n", "self", ".", "decode", "=", "partial", "(", "decode", ",", "tokenizer", "=", "self", ".", "tokenizer", ")", "\n", "\n", "if", "args", ".", "pretrain", ":", "\n", "# when pretrain, only tune embedding layers", "\n", "            ", "self", ".", "_freeze_attention", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.forward": [[53, 55], ["transformer.TransformerLitModel.model"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.training_step": [[56, 75], ["batch.pop", "batch.pop", "transformer.TransformerLitModel.model", "transformer.TransformerLitModel.loss_fn", "transformer.TransformerLitModel.loss_fn", "print", "transformer.TransformerLitModel.decode", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.decode"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "bs", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "labels", "=", "batch", ".", "pop", "(", "\"labels\"", ")", "\n", "label", "=", "batch", ".", "pop", "(", "\"label\"", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "logits", "=", "self", ".", "model", "(", "**", "batch", ",", "return_dict", "=", "True", ")", ".", "logits", "\n", "\n", "_", ",", "mask_idx", "=", "(", "input_ids", "==", "self", ".", "tokenizer", ".", "mask_token_id", ")", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "mask_logits", "=", "logits", "[", "torch", ".", "arange", "(", "bs", ")", ",", "mask_idx", "]", "[", ":", ",", "self", ".", "entity_id_st", ":", "self", ".", "entity_id_ed", "]", "\n", "assert", "mask_idx", ".", "shape", "[", "0", "]", "==", "bs", ",", "\"only one mask in sequence!\"", "\n", "\n", "if", "self", ".", "args", ".", "bce", ":", "\n", "            ", "loss", "=", "self", ".", "loss_fn", "(", "mask_logits", ",", "labels", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "loss_fn", "(", "mask_logits", ",", "label", ")", "\n", "\n", "", "if", "batch_idx", "==", "0", ":", "\n", "            ", "print", "(", "'\\n'", ".", "join", "(", "self", ".", "decode", "(", "batch", "[", "'input_ids'", "]", "[", ":", "4", "]", ")", ")", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel._eval": [[76, 97], ["batch.pop", "batch.pop", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "dict", "outputs[].detach().cpu", "transformer.TransformerLitModel.model", "numpy.array", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "outputs[].detach", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop"], ["", "def", "_eval", "(", "self", ",", "batch", ",", "batch_idx", ",", ")", ":", "\n", "        ", "bsz", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "labels", "=", "batch", ".", "pop", "(", "\"labels\"", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "# single label", "\n", "label", "=", "batch", ".", "pop", "(", "'label'", ")", "# bsz", "\n", "logits", "=", "self", ".", "model", "(", "**", "batch", ",", "return_dict", "=", "True", ")", ".", "logits", "[", ":", ",", ":", ",", "self", ".", "entity_id_st", ":", "self", ".", "entity_id_ed", "]", "# bsz, len, entites", "\n", "\n", "_", ",", "mask_idx", "=", "(", "input_ids", "==", "self", ".", "tokenizer", ".", "mask_token_id", ")", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "# bsz", "\n", "logits", "=", "logits", "[", "torch", ".", "arange", "(", "bsz", ")", ",", "mask_idx", "]", "# bsz, entites", "\n", "# get the entity ranks", "\n", "# filter the entity", "\n", "assert", "labels", "[", "0", "]", "[", "label", "[", "0", "]", "]", ",", "\"correct ids must in filiter!\"", "\n", "labels", "[", "torch", ".", "arange", "(", "bsz", ")", ",", "label", "]", "=", "0", "\n", "assert", "logits", ".", "shape", "==", "labels", ".", "shape", "\n", "logits", "+=", "labels", "*", "-", "100", "# mask entity", "\n", "\n", "_", ",", "outputs", "=", "torch", ".", "sort", "(", "logits", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "# bsz, entities   index", "\n", "_", ",", "outputs", "=", "torch", ".", "sort", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "ranks", "=", "outputs", "[", "torch", ".", "arange", "(", "bsz", ")", ",", "label", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "+", "1", "\n", "return", "dict", "(", "ranks", "=", "np", ".", "array", "(", "ranks", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.validation_step": [[98, 101], ["transformer.TransformerLitModel._eval"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel._eval"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "result", "=", "self", ".", "_eval", "(", "batch", ",", "batch_idx", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.validation_epoch_end": [[102, 125], ["numpy.concatenate", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "numpy.concatenate.mean", "numpy.array", "list", "numpy.array", "numpy.arange", "list", "numpy.arange"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", "->", "None", ":", "\n", "        ", "ranks", "=", "np", ".", "concatenate", "(", "[", "_", "[", "'ranks'", "]", "for", "_", "in", "outputs", "]", ")", "\n", "total_ranks", "=", "ranks", ".", "shape", "[", "0", "]", "\n", "\n", "if", "not", "self", ".", "args", ".", "pretrain", ":", "\n", "            ", "l_ranks", "=", "ranks", "[", "np", ".", "array", "(", "list", "(", "np", ".", "arange", "(", "0", ",", "total_ranks", ",", "2", ")", ")", ")", "]", "\n", "r_ranks", "=", "ranks", "[", "np", ".", "array", "(", "list", "(", "np", ".", "arange", "(", "0", ",", "total_ranks", ",", "2", ")", ")", ")", "+", "1", "]", "\n", "self", ".", "log", "(", "\"Eval/lhits10\"", ",", "(", "l_ranks", "<=", "10", ")", ".", "mean", "(", ")", ")", "\n", "self", ".", "log", "(", "\"Eval/rhits10\"", ",", "(", "r_ranks", "<=", "10", ")", ".", "mean", "(", ")", ")", "\n", "\n", "", "hits20", "=", "(", "ranks", "<=", "20", ")", ".", "mean", "(", ")", "\n", "hits10", "=", "(", "ranks", "<=", "10", ")", ".", "mean", "(", ")", "\n", "hits3", "=", "(", "ranks", "<=", "3", ")", ".", "mean", "(", ")", "\n", "hits1", "=", "(", "ranks", "<=", "1", ")", ".", "mean", "(", ")", "\n", "\n", "self", ".", "log", "(", "\"Eval/hits10\"", ",", "hits10", ")", "\n", "self", ".", "log", "(", "\"Eval/hits20\"", ",", "hits20", ")", "\n", "self", ".", "log", "(", "\"Eval/hits3\"", ",", "hits3", ")", "\n", "self", ".", "log", "(", "\"Eval/hits1\"", ",", "hits1", ")", "\n", "self", ".", "log", "(", "\"Eval/mean_rank\"", ",", "ranks", ".", "mean", "(", ")", ")", "\n", "self", ".", "log", "(", "\"Eval/mrr\"", ",", "(", "1.", "/", "ranks", ")", ".", "mean", "(", ")", ")", "\n", "self", ".", "log", "(", "\"hits10\"", ",", "hits10", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"hits1\"", ",", "hits1", ",", "prog_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.test_step": [[127, 131], ["transformer.TransformerLitModel._eval"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel._eval"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "result", "=", "self", ".", "_eval", "(", "batch", ",", "batch_idx", ")", "\n", "# self.log(\"Test/ranks\", np.mean(ranks))", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.test_epoch_end": [[132, 147], ["numpy.concatenate", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "transformer.TransformerLitModel.log", "numpy.concatenate.mean"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", "->", "None", ":", "\n", "        ", "ranks", "=", "np", ".", "concatenate", "(", "[", "_", "[", "'ranks'", "]", "for", "_", "in", "outputs", "]", ")", "\n", "\n", "hits20", "=", "(", "ranks", "<=", "20", ")", ".", "mean", "(", ")", "\n", "hits10", "=", "(", "ranks", "<=", "10", ")", ".", "mean", "(", ")", "\n", "hits3", "=", "(", "ranks", "<=", "3", ")", ".", "mean", "(", ")", "\n", "hits1", "=", "(", "ranks", "<=", "1", ")", ".", "mean", "(", ")", "\n", "\n", "\n", "self", ".", "log", "(", "\"Test/hits10\"", ",", "hits10", ")", "\n", "self", ".", "log", "(", "\"Test/hits20\"", ",", "hits20", ")", "\n", "self", ".", "log", "(", "\"Test/hits3\"", ",", "hits3", ")", "\n", "self", ".", "log", "(", "\"Test/hits1\"", ",", "hits1", ")", "\n", "self", ".", "log", "(", "\"Test/mean_rank\"", ",", "ranks", ".", "mean", "(", ")", ")", "\n", "self", ".", "log", "(", "\"Test/mrr\"", ",", "(", "1.", "/", "ranks", ")", ".", "mean", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.configure_optimizers": [[148, 164], ["transformer.TransformerLitModel.optimizer_class", "transformers.optimization.get_linear_schedule_with_warmup", "transformer.TransformerLitModel.model.named_parameters", "transformer.TransformerLitModel.model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "no_decay_param", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "\n", "optimizer_group_parameters", "=", "[", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "and", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay_param", ")", "]", ",", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "and", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay_param", ")", "]", ",", "\"weight_decay\"", ":", "0", "}", "\n", "]", "\n", "\n", "optimizer", "=", "self", ".", "optimizer_class", "(", "optimizer_group_parameters", ",", "lr", "=", "self", ".", "lr", ",", "eps", "=", "1e-8", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "num_training_steps", "*", "self", ".", "args", ".", "warm_up_radio", ",", "num_training_steps", "=", "self", ".", "num_training_steps", ")", "\n", "return", "{", "\n", "\"optimizer\"", ":", "optimizer", ",", "\n", "\"lr_scheduler\"", ":", "{", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'interval'", ":", "'step'", ",", "# or 'epoch'", "\n", "'frequency'", ":", "1", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel._freeze_attention": [[167, 173], ["transformer.TransformerLitModel.model.named_parameters", "print"], "methods", ["None"], ["", "def", "_freeze_attention", "(", "self", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "\"word\"", "not", "in", "k", ":", "\n", "                ", "v", ".", "requires_grad", "=", "False", "\n", "", "else", ":", "\n", "                ", "print", "(", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel._freaze_word_embedding": [[174, 179], ["transformer.TransformerLitModel.model.named_parameters", "print"], "methods", ["None"], ["", "", "", "def", "_freaze_word_embedding", "(", "self", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "\"word\"", "in", "k", ":", "\n", "                ", "print", "(", "k", ")", "\n", "v", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.TransformerLitModel.add_to_argparse": [[180, 187], ["base.BaseLitModel.add_to_argparse", "base.BaseLitModel.add_to_argparse.add_argument", "base.BaseLitModel.add_to_argparse.add_argument"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.add_to_argparse"], ["", "", "", "@", "staticmethod", "\n", "def", "add_to_argparse", "(", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseLitModel", ".", "add_to_argparse", "(", "parser", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--bce\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"\"", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.lmap": [[10, 13], ["list", "map"], "function", ["None"], ["def", "lmap", "(", "f", ":", "Callable", ",", "x", ":", "Iterable", ")", "->", "List", ":", "\n", "    ", "\"\"\"list(map(f, x))\"\"\"", "\n", "return", "list", "(", "map", "(", "f", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.multilabel_categorical_crossentropy": [[14, 24], ["torch.zeros_like", "torch.zeros_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp"], "function", ["None"], ["", "def", "multilabel_categorical_crossentropy", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "y_pred", "=", "(", "1", "-", "2", "*", "y_true", ")", "*", "y_pred", "\n", "y_pred_neg", "=", "y_pred", "-", "y_true", "*", "1e12", "\n", "y_pred_pos", "=", "y_pred", "-", "(", "1", "-", "y_true", ")", "*", "1e12", "\n", "zeros", "=", "torch", ".", "zeros_like", "(", "y_pred", "[", "...", ",", ":", "1", "]", ")", "\n", "y_pred_neg", "=", "torch", ".", "cat", "(", "[", "y_pred_neg", ",", "zeros", "]", ",", "dim", "=", "-", "1", ")", "\n", "y_pred_pos", "=", "torch", ".", "cat", "(", "[", "y_pred_pos", ",", "zeros", "]", ",", "dim", "=", "-", "1", ")", "\n", "neg_loss", "=", "torch", ".", "logsumexp", "(", "y_pred_neg", ",", "dim", "=", "-", "1", ")", "\n", "pos_loss", "=", "torch", ".", "logsumexp", "(", "y_pred_pos", ",", "dim", "=", "-", "1", ")", "\n", "return", "(", "neg_loss", "+", "pos_loss", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.transformer.decode": [[25, 27], ["transformer.lmap", "tokenizer.batch_decode"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.lmap"], ["", "def", "decode", "(", "output_ids", ",", "tokenizer", ")", ":", "\n", "    ", "return", "lmap", "(", "str", ".", "strip", ",", "tokenizer", ".", "batch_decode", "(", "output_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.utils.LabelSmoothSoftmaxCEV1.__init__": [[35, 41], ["torch.Module.__init__", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["\n", "id2label", "=", "list", "(", "mapping", ".", "keys", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.utils.LabelSmoothSoftmaxCEV1.forward": [[42, 67], ["utils.LabelSmoothSoftmaxCEV1.log_softmax", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "logits.size", "torch.empty_like().fill_().scatter_().detach.clone().detach", "torch.empty_like().fill_().scatter_().detach.clone().detach", "torch.empty_like().fill_().scatter_().detach", "torch.empty_like().fill_().scatter_().detach", "torch.empty_like().fill_().scatter_().detach", "torch.empty_like().fill_().scatter_().detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss.sum.sum.sum", "loss.sum.sum.sum", "torch.empty_like().fill_().scatter_().detach.clone", "torch.empty_like().fill_().scatter_().detach.clone", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_", "torch.empty_like().fill_().scatter_().detach.unsqueeze", "torch.empty_like().fill_().scatter_().detach.unsqueeze", "torch.empty_like().fill_", "torch.empty_like().fill_", "torch.empty_like().fill_", "torch.empty_like().fill_", "torch.empty_like", "torch.empty_like", "torch.empty_like", "torch.empty_like"], "methods", ["None"], ["pred_eos_index", "=", "preds", ".", "flip", "(", "dims", "=", "[", "1", "]", ")", ".", "eq", "(", "1", ")", ".", "cumsum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "preds", "=", "preds", "[", ":", ",", "1", ":", "]", "\n", "pred_seq_len", "=", "pred_eos_index", ".", "flip", "(", "dims", "=", "[", "1", "]", ")", ".", "eq", "(", "pred_eos_index", "[", ":", ",", "-", "1", ":", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "# bsz", "\n", "pred_seq_len", "=", "(", "pred_seq_len", "-", "2", ")", ".", "tolist", "(", ")", "\n", "\n", "word_start_index", "=", "len", "(", "mapping", ")", "+", "2", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "pred_item", "in", "enumerate", "(", "preds", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "pred_item", "=", "pred_item", "[", ":", "pred_seq_len", "[", "i", "]", "]", "# single sentence prediction", "\n", "pairs", ",", "cur_pair", "=", "[", "]", ",", "[", "]", "\n", "if", "len", "(", "pred_item", ")", ":", "# this sentence prediciton= is not null", "\n", "            ", "for", "idx", "in", "pred_item", ":", "\n", "                ", "if", "idx", "<", "word_start_index", ":", "# is entity", "\n", "                    ", "if", "len", "(", "cur_pair", ")", ">", "0", ":", "\n", "# assert word[i] < word[i+1]", "\n", "                        ", "if", "all", "(", "[", "cur_pair", "[", "i", "]", "<", "cur_pair", "[", "i", "+", "1", "]", "for", "i", "in", "range", "(", "len", "(", "cur_pair", ")", "-", "1", ")", "]", ")", ":", "\n", "                            ", "pairs", ".", "append", "(", "tuple", "(", "cur_pair", "+", "[", "idx", "]", ")", ")", "# add valid words and current entity id", "\n", "", "", "cur_pair", "=", "[", "]", "# clear word pairs", "\n", "", "else", ":", "# is word", "\n", "                    ", "cur_pair", ".", "append", "(", "idx", ")", "# add word id to word pairs", "\n", "", "", "", "raw_words_item", "=", "raw_words", "[", "i", "]", "\n", "cum_lens", "=", "[", "1", "]", "\n", "start_idx", "=", "1", "\n", "for", "word", "in", "raw_words_item", ":", "\n", "            ", "start_idx", "+=", "len", "(", "tokenizer", ".", "tokenize", "(", "word", ",", "add_prefix_space", "=", "True", ")", ")", "\n", "cum_lens", ".", "append", "(", "start_idx", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.utils.rank_score": [[4, 24], ["len", "enumerate", "mrr.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["None"], ["from", "torch", "import", "nn", "\n", "from", "collections", "import", "OrderedDict", "\n", "\n", "\n", "def", "seq_to_mask", "(", "seq_len", ",", "max_len", ")", ":", "\n", "    ", "\"\"\"[get attention mask with sequence length]\n\n    Args:\n        seq_len ([torch.tensor]): [shape: bsz, each sequence length in a batch]\n    \"\"\"", "\n", "max_len", "=", "int", "(", "max_len", ")", "if", "max_len", "else", "seq_len", ".", "max", "(", ")", ".", "long", "(", ")", "\n", "cast_seq", "=", "torch", ".", "arange", "(", "max_len", ")", ".", "expand", "(", "seq_len", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "to", "(", "seq_len", ")", "\n", "mask", "=", "cast_seq", ".", "lt", "(", "seq_len", ".", "unsqueeze", "(", "1", ")", ")", "\n", "return", "mask", "\n", "\n", "\n", "", "def", "set_seed", "(", "seed", "=", "2021", ")", ":", "\n", "    ", "\"\"\"sets random seed\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.lit_models.utils.acc": [[25, 28], ["numpy.argmax"], "function", ["None"], ["np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.ExplicitEnum._missing_": [[34, 38], ["ValueError", "list", "cls._value2member_map_.keys"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_missing_", "(", "cls", ",", "value", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"{value} is not a valid {cls.__name__}, please select one of {list(cls._value2member_map_.keys())}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.DataCollatorForSeq2Seq.__call__": [[98, 187], ["features[].keys", "len", "data_module.DataCollatorForSeq2Seq.tokenizer.pad", "torch.tensor", "data_module.DataCollatorForSeq2Seq.update", "torch.stack", "torch.stack", "torch.stack", "feature.pop", "torch.no_grad", "torch.zeros", "enumerate", "range", "range", "range", "range", "aux_images.append", "rcnn_images.append", "features[].keys", "feature.pop", "features[].keys", "feature.pop", "feature.pop", "isinstance", "os.path.join", "len", "PIL.Image.open().convert", "[].squeeze", "pixel_images.append", "pixel_images.append", "min", "PIL.Image.open().convert", "[].squeeze", "aux_imgs.append", "min", "PIL.Image.open().convert", "[].squeeze", "rcnn_imgs.append", "aux_imgs.append", "rcnn_imgs.append", "torch.stack", "torch.stack", "entity[].replace", "ValueError", "os.path.join", "len", "random.seed", "random.sample", "torch.zeros", "len", "len", "len", "torch.zeros", "len", "torch.zeros", "os.listdir", "PIL.Image.open", "PIL.Image.open", "PIL.Image.open", "clip_processor", "aux_processor", "rcnn_processor"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop"], ["def", "__call__", "(", "self", ",", "features", ",", "return_tensors", "=", "None", ")", ":", "\n", "\n", "        ", "if", "return_tensors", "is", "None", ":", "\n", "            ", "return_tensors", "=", "self", ".", "return_tensors", "\n", "", "labels", "=", "[", "feature", ".", "pop", "(", "\"labels\"", ")", "for", "feature", "in", "features", "]", "if", "\"labels\"", "in", "features", "[", "0", "]", ".", "keys", "(", ")", "else", "None", "\n", "label", "=", "[", "feature", ".", "pop", "(", "\"label\"", ")", "for", "feature", "in", "features", "]", "\n", "features_keys", "=", "{", "}", "\n", "entities", "=", "[", "feature", ".", "pop", "(", "\"entity\"", ")", "for", "feature", "in", "features", "]", "if", "\"entity\"", "in", "features", "[", "0", "]", ".", "keys", "(", ")", "else", "None", "\n", "for", "k", "in", "features", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "# ignore the padding arguments", "\n", "            ", "if", "k", "in", "[", "\"input_ids\"", ",", "\"attention_mask\"", ",", "\"token_type_ids\"", "]", ":", "continue", "\n", "features_keys", "[", "k", "]", "=", "[", "feature", ".", "pop", "(", "k", ")", "for", "feature", "in", "features", "]", "\n", "\n", "# We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the", "\n", "# same length to return tensors.", "\n", "", "bsz", "=", "len", "(", "labels", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_labels", "=", "torch", ".", "zeros", "(", "bsz", ",", "self", ".", "num_labels", ")", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "int", ")", ":", "\n", "                    ", "new_labels", "[", "i", "]", "[", "l", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "for", "j", "in", "l", ":", "\n", "                        ", "new_labels", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "", "", "", "labels", "=", "new_labels", "\n", "\n", "", "features", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "features", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", ")", "\n", "features", "[", "'labels'", "]", "=", "labels", "\n", "features", "[", "'label'", "]", "=", "torch", ".", "tensor", "(", "label", ")", "\n", "features", ".", "update", "(", "features_keys", ")", "\n", "\n", "# region", "\n", "pixel_images", ",", "aux_images", ",", "rcnn_images", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "entity", "in", "entities", ":", "\n", "            ", "if", "self", ".", "task_name", "==", "'wn18'", ":", "\n", "                ", "en_file", "=", "'n'", "+", "entity", "# wn18", "\n", "", "elif", "self", ".", "task_name", "==", "'fb15k-237'", ":", "\n", "                ", "en_file", "=", "entity", "[", "1", ":", "]", ".", "replace", "(", "'/'", ",", "'.'", ")", "# m.01rng // n01443537", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"{self.task_name} is not a valid task name, please select one of [wn18, fb15k-237]\"", "\n", ")", "\n", "", "en_imgs", "=", "[", "]", "\n", "if", "en_file", "in", "self", ".", "entity_img_files", ":", "\n", "                ", "en_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "entity_img_path", ",", "en_file", ")", "\n", "en_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "en_file", ",", "file", ")", "for", "file", "in", "os", ".", "listdir", "(", "en_file", ")", "]", "\n", "if", "len", "(", "en_imgs", ")", ">", "7", ":", "# random select six imgs", "\n", "                    ", "random", ".", "seed", "(", "1", ")", "\n", "en_imgs", "=", "random", ".", "sample", "(", "en_imgs", ",", "k", "=", "7", ")", "\n", "", "", "en_full_imgs", "=", "en_imgs", "[", ":", "1", "]", "\n", "en_aux_imgs", "=", "en_imgs", "[", "1", ":", "4", "]", "\n", "en_rcnn_imgs", "=", "en_imgs", "[", "4", ":", "]", "\n", "\n", "if", "len", "(", "en_full_imgs", ")", ">", "0", ":", "\n", "                ", "full_img", "=", "Image", ".", "open", "(", "en_full_imgs", "[", "0", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "full_img", "=", "clip_processor", "(", "images", "=", "full_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "pixel_images", ".", "append", "(", "full_img", ")", "\n", "", "else", ":", "\n", "                ", "pixel_images", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "224", ",", "224", ")", ")", ")", "\n", "\n", "", "aux_imgs", ",", "rcnn_imgs", "=", "[", "]", ",", "[", "]", "\n", "# select 3 imgs", "\n", "for", "i", "in", "range", "(", "min", "(", "3", ",", "len", "(", "en_aux_imgs", ")", ")", ")", ":", "\n", "                ", "aux_img", "=", "Image", ".", "open", "(", "en_aux_imgs", "[", "i", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "aux_img", "=", "aux_processor", "(", "images", "=", "aux_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "aux_imgs", ".", "append", "(", "aux_img", ")", "\n", "", "for", "i", "in", "range", "(", "min", "(", "3", ",", "len", "(", "en_rcnn_imgs", ")", ")", ")", ":", "\n", "                ", "rcnn_img", "=", "Image", ".", "open", "(", "en_rcnn_imgs", "[", "i", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "rcnn_img", "=", "rcnn_processor", "(", "images", "=", "rcnn_img", ",", "return_tensors", "=", "'pt'", ")", "[", "'pixel_values'", "]", ".", "squeeze", "(", ")", "\n", "rcnn_imgs", ".", "append", "(", "rcnn_img", ")", "\n", "# padding", "\n", "", "for", "i", "in", "range", "(", "3", "-", "len", "(", "en_aux_imgs", ")", ")", ":", "\n", "                ", "aux_imgs", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "aux_size", ",", "aux_size", ")", ")", ")", "\n", "", "for", "i", "in", "range", "(", "3", "-", "len", "(", "en_rcnn_imgs", ")", ")", ":", "\n", "                ", "rcnn_imgs", ".", "append", "(", "torch", ".", "zeros", "(", "(", "3", ",", "rcnn_size", ",", "rcnn_size", ")", ")", ")", "\n", "", "aux_images", ".", "append", "(", "torch", ".", "stack", "(", "aux_imgs", ")", ")", "\n", "rcnn_images", ".", "append", "(", "torch", ".", "stack", "(", "rcnn_imgs", ")", ")", "\n", "\n", "", "features", "[", "'pixel_values'", "]", "=", "torch", ".", "stack", "(", "pixel_images", ")", "\n", "features", "[", "'aux_values'", "]", "=", "torch", ".", "stack", "(", "aux_images", ")", "\n", "features", "[", "'rcnn_values'", "]", "=", "torch", ".", "stack", "(", "rcnn_images", ")", "\n", "#endregion", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.__init__": [[190, 224], ["base_data_module.BaseDataModule.__init__", "transformers.AutoTokenizer.from_pretrained", "processor.KGProcessor", "data_module.KGC.processor.get_labels", "data_module.KGC.processor.get_entities", "print", "data_module.KGC.tokenizer.add_special_tokens", "os.listdir", "data_module.DataCollatorForSeq2Seq", "data_module.KGC.processor.get_relations", "len", "data_module.KGC.tokenizer.add_special_tokens", "data_module.KGC.tokenizer.get_added_vocab", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_labels", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_entities", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_relations"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "model", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_name_or_path", ",", "use_fast", "=", "False", ")", "\n", "self", ".", "processor", "=", "KGProcessor", "(", "self", ".", "tokenizer", ",", "args", ")", "\n", "self", ".", "label_list", "=", "self", ".", "processor", ".", "get_labels", "(", "args", ".", "data_dir", ")", "\n", "\n", "entity_list", "=", "self", ".", "processor", ".", "get_entities", "(", "args", ".", "data_dir", ")", "\n", "print", "(", "len", "(", "entity_list", ")", ")", "\n", "\n", "num_added_tokens", "=", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "entity_list", "}", ")", "\n", "\n", "entity_img_path", "=", "{", "'wn18'", ":", "'dataset/wn18-images/'", ",", "'fb15k-237'", ":", "'dataset/FB15k-images/'", "}", "[", "self", ".", "args", ".", "task_name", "]", "\n", "entity_img_files", "=", "listdir", "(", "entity_img_path", ")", "\n", "self", ".", "sampler", "=", "DataCollatorForSeq2Seq", "(", "self", ".", "tokenizer", ",", "\n", "model", "=", "model", ",", "\n", "label_pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", ",", "\n", "pad_to_multiple_of", "=", "8", "if", "self", ".", "args", ".", "precision", "==", "16", "else", "None", ",", "\n", "padding", "=", "\"longest\"", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_seq_length", ",", "\n", "num_labels", "=", "len", "(", "entity_list", ")", ",", "\n", "task_name", "=", "self", ".", "args", ".", "task_name", ",", "\n", "entity_img_path", "=", "entity_img_path", ",", "\n", "entity_img_files", "=", "entity_img_files", "\n", "\n", ")", "\n", "relations_tokens", "=", "self", ".", "processor", ".", "get_relations", "(", "args", ".", "data_dir", ")", "\n", "self", ".", "num_relations", "=", "len", "(", "relations_tokens", ")", "\n", "num_added_tokens", "=", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "relations_tokens", "}", ")", "\n", "\n", "vocab", "=", "self", ".", "tokenizer", ".", "get_added_vocab", "(", ")", "# dict: word: idx", "\n", "self", ".", "relation_id_st", "=", "vocab", "[", "relations_tokens", "[", "0", "]", "]", "\n", "self", ".", "relation_id_ed", "=", "vocab", "[", "relations_tokens", "[", "-", "1", "]", "]", "+", "1", "\n", "self", ".", "entity_id_st", "=", "vocab", "[", "entity_list", "[", "0", "]", "]", "\n", "self", ".", "entity_id_ed", "=", "vocab", "[", "entity_list", "[", "-", "1", "]", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.setup": [[226, 230], ["processor.get_dataset", "processor.get_dataset", "processor.get_dataset"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.get_dataset", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.get_dataset", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.get_dataset"], ["", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "data_train", "=", "get_dataset", "(", "self", ".", "args", ",", "self", ".", "processor", ",", "self", ".", "label_list", ",", "self", ".", "tokenizer", ",", "\"train\"", ")", "\n", "self", ".", "data_val", "=", "get_dataset", "(", "self", ".", "args", ",", "self", ".", "processor", ",", "self", ".", "label_list", ",", "self", ".", "tokenizer", ",", "\"dev\"", ")", "\n", "self", ".", "data_test", "=", "get_dataset", "(", "self", ".", "args", ",", "self", ".", "processor", ",", "self", ".", "label_list", ",", "self", ".", "tokenizer", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.prepare_data": [[231, 233], ["None"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.get_config": [[234, 241], ["data_module.KGC.__dict__.items", "d.update"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "d", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "if", "\"st\"", "in", "k", "or", "\"ed\"", "in", "k", ":", "\n", "                ", "d", ".", "update", "(", "{", "k", ":", "v", "}", ")", "\n", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.add_to_argparse": [[242, 252], ["base_data_module.BaseDataModule.add_to_argparse", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.add_to_argparse"], ["", "@", "staticmethod", "\n", "def", "add_to_argparse", "(", "parser", ")", ":", "\n", "        ", "BaseDataModule", ".", "add_to_argparse", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "type", "=", "str", ",", "default", "=", "\"roberta-base\"", ",", "help", "=", "\"the name or the path to the pretrained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"roberta-base\"", ",", "help", "=", "\"the name or the path to the pretrained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "\"Number of examples to operate on per forward step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warm_up_radio\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "\"Number of examples to operate on per forward step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.get_tokenizer": [[253, 255], ["None"], "methods", ["None"], ["", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.train_dataloader": [[256, 258], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "data_train", ",", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "False", ",", "collate_fn", "=", "self", ".", "sampler", ",", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "shuffle", "=", "self", ".", "args", ".", "pretrain", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.val_dataloader": [[259, 261], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "data_val", ",", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "False", ",", "collate_fn", "=", "self", ".", "sampler", ",", "batch_size", "=", "self", ".", "args", ".", "eval_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.data_module.KGC.test_dataloader": [[262, 264], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "data_test", ",", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "False", ",", "collate_fn", "=", "self", ".", "sampler", ",", "batch_size", "=", "self", ".", "args", ".", "eval_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.InputExample.__init__": [[251, 272], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "text_c", "=", "None", ",", "label", "=", "None", ",", "real_label", "=", "None", ",", "en", "=", "None", ",", "rel", "=", "None", ",", "entity", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            text_c: (Optional) string. The untokenized text of the third sequence.\n            Only must be specified for sequence triple tasks.\n            label: (Optional) string. list of entities\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "text_c", "=", "text_c", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "real_label", "=", "real_label", "\n", "self", ".", "en", "=", "en", "\n", "self", ".", "rel", "=", "rel", "# rel id", "\n", "self", ".", "entity", "=", "entity", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor.get_train_examples": [[290, 293], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor.get_dev_examples": [[294, 297], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor.get_labels": [[298, 301], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv": [[302, 313], ["open", "csv.reader", "lines.append", "list", "unicode"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.__init__": [[317, 323], ["set", "os.path.exists", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ")", ":", "\n", "        ", "self", ".", "labels", "=", "set", "(", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "entity_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"entity2textlong.txt\"", ")", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'entity2textlong.txt'", ")", ")", "else", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"entity2text.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_train_examples": [[324, 328], ["processor.KGProcessor._create_examples", "processor.KGProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor._create_examples", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ",", "data_dir", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_dev_examples": [[329, 333], ["processor.KGProcessor._create_examples", "processor.KGProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor._create_examples", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ",", "data_dir", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_test_examples": [[334, 338], ["processor.KGProcessor._create_examples", "processor.KGProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor._create_examples", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "chunk", "=", "\"\"", ")", ":", "\n", "      ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"test{chunk}.tsv\"", ")", ")", ",", "\"test\"", ",", "data_dir", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_relations": [[339, 349], ["list", "open", "f.readlines", "rel2token.values", "os.path.join", "relations.append", "enumerate", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "get_relations", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets all labels (relations) in the knowledge graph.\"\"\"", "\n", "# return list(self.labels)", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"relations.txt\"", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "relations", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "relations", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "[", "0", "]", ")", "\n", "", "", "rel2token", "=", "{", "ent", ":", "f\"[RELATION_{i}]\"", "for", "i", ",", "ent", "in", "enumerate", "(", "relations", ")", "}", "\n", "return", "list", "(", "rel2token", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_labels": [[350, 359], ["open", "f.readlines", "os.path.join", "relation.append", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets all labels (0, 1) for triples in the knowledge graph.\"\"\"", "\n", "relation", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"relation2text.txt\"", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "entities", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "relation", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "[", "-", "1", "]", ")", "\n", "", "", "return", "relation", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_entities": [[360, 370], ["list", "open", "f.readlines", "ent2token.values", "entities.append", "enumerate", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "get_entities", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets all entities in the knowledge graph.\"\"\"", "\n", "with", "open", "(", "self", ".", "entity_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "entities", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "entities", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", ")", "\n", "\n", "", "", "ent2token", "=", "{", "ent", ":", "f\"[ENTITY_{i}]\"", "for", "i", ",", "ent", "in", "enumerate", "(", "entities", ")", "}", "\n", "return", "list", "(", "ent2token", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_train_triples": [[371, 374], ["processor.KGProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv"], ["", "def", "get_train_triples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets training triples.\"\"\"", "\n", "return", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_dev_triples": [[375, 378], ["processor.KGProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv"], ["", "def", "get_dev_triples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets validation triples.\"\"\"", "\n", "return", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_test_triples": [[379, 382], ["processor.KGProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.DataProcessor._read_tsv"], ["", "def", "get_test_triples", "(", "self", ",", "data_dir", ",", "chunk", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Gets test triples.\"\"\"", "\n", "return", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"test{chunk}.tsv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor._create_examples": [[383, 497], ["list", "tqdm.tqdm.tqdm", "print", "collections.defaultdict", "collections.defaultdict", "max", "max", "print", "min", "processor.filter_init", "functools.partial", "list", "open", "f.readlines", "ent2text.keys", "open", "f.readlines", "open", "file.readlines", "tmp_lines.append", "collections.defaultdict.items", "collections.defaultdict.items", "ent2text.keys", "cpu_count", "tqdm.tqdm.tqdm", "line.strip().split", "temp[].replace().replace", "enumerate", "enumerate", "os.path.join", "line.strip().split", "os.path.join", "line.strip", "enumerate", "open", "file.readlines", "range", "tail_filter_entities[].append", "head_filter_entities[].append", "len", "len", "k.split", "lines.append", "k.split", "lines.append", "list", "lines.append", "map", "tmp_examples.append", "relation_names.keys", "os.path.join", "len", "train_lines[].strip().split", "collections.defaultdict.values", "collections.defaultdict.values", "rel2text.keys", "len", "line.strip", "temp[].replace", "line.strip", "train_lines[].strip"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.filter_init"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ",", "data_dir", ",", "args", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "# entity to text", "\n", "ent2text", "=", "{", "}", "\n", "ent2text_with_type", "=", "{", "}", "\n", "with", "open", "(", "self", ".", "entity_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ent_lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "ent_lines", ":", "\n", "                ", "temp", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "end", "=", "temp", "[", "1", "]", "#.find(',')", "\n", "if", "\"wiki\"", "in", "data_dir", ":", "\n", "                    ", "assert", "\"Q\"", "in", "temp", "[", "0", "]", "\n", "", "ent2text", "[", "temp", "[", "0", "]", "]", "=", "temp", "[", "1", "]", ".", "replace", "(", "\"\\\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\\\\"", ",", "\"\"", ")", "#[:end]", "\n", "\n", "", "", "entities", "=", "list", "(", "ent2text", ".", "keys", "(", ")", ")", "\n", "ent2token", "=", "{", "ent", ":", "f\"[ENTITY_{i}]\"", "for", "i", ",", "ent", "in", "enumerate", "(", "entities", ")", "}", "\n", "ent2id", "=", "{", "ent", ":", "i", "for", "i", ",", "ent", "in", "enumerate", "(", "entities", ")", "}", "\n", "\n", "rel2text", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"relation2text.txt\"", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "rel_lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "rel_lines", ":", "\n", "                ", "temp", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "rel2text", "[", "temp", "[", "0", "]", "]", "=", "temp", "[", "1", "]", "\n", "", "", "relation_names", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"relations.txt\"", ")", ",", "\"r\"", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ".", "readlines", "(", ")", ":", "\n", "                ", "t", "=", "line", ".", "strip", "(", ")", "\n", "relation_names", "[", "t", "]", "=", "rel2text", "[", "t", "]", "\n", "\n", "", "", "tmp_lines", "=", "[", "]", "\n", "not_in_text", "=", "0", "\n", "for", "line", "in", "tqdm", "(", "lines", ",", "desc", "=", "\"delete entities without text name.\"", ")", ":", "\n", "            ", "if", "(", "line", "[", "0", "]", "not", "in", "ent2text", ")", "or", "(", "line", "[", "2", "]", "not", "in", "ent2text", ")", "or", "(", "line", "[", "1", "]", "not", "in", "rel2text", ")", ":", "\n", "                ", "not_in_text", "+=", "1", "\n", "continue", "\n", "", "tmp_lines", ".", "append", "(", "line", ")", "\n", "", "lines", "=", "tmp_lines", "\n", "print", "(", "f\"total entity not in text : {not_in_text} \"", ")", "\n", "\n", "# rel id -> relation token id", "\n", "rel2id", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "enumerate", "(", "relation_names", ".", "keys", "(", ")", ")", "}", "\n", "\n", "examples", "=", "[", "]", "\n", "# head filter head entity", "\n", "head_filter_entities", "=", "defaultdict", "(", "list", ")", "\n", "tail_filter_entities", "=", "defaultdict", "(", "list", ")", "\n", "\n", "dataset_list", "=", "[", "\"train.tsv\"", ",", "\"dev.tsv\"", ",", "\"test.tsv\"", "]", "\n", "# in training, only use the train triples", "\n", "if", "set_type", "==", "\"train\"", "and", "not", "args", ".", "pretrain", ":", "dataset_list", "=", "dataset_list", "[", "0", ":", "1", "]", "\n", "for", "m", "in", "dataset_list", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "m", ")", ",", "'r'", ")", "as", "file", ":", "\n", "                ", "train_lines", "=", "file", ".", "readlines", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "train_lines", ")", ")", ":", "\n", "                    ", "train_lines", "[", "idx", "]", "=", "train_lines", "[", "idx", "]", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "", "", "for", "line", "in", "train_lines", ":", "\n", "                ", "tail_filter_entities", "[", "\"\\t\"", ".", "join", "(", "[", "line", "[", "0", "]", ",", "line", "[", "1", "]", "]", ")", "]", ".", "append", "(", "line", "[", "2", "]", ")", "\n", "head_filter_entities", "[", "\"\\t\"", ".", "join", "(", "[", "line", "[", "2", "]", ",", "line", "[", "1", "]", "]", ")", "]", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "\n", "\n", "\n", "", "", "max_head_entities", "=", "max", "(", "len", "(", "_", ")", "for", "_", "in", "head_filter_entities", ".", "values", "(", ")", ")", "\n", "max_tail_entities", "=", "max", "(", "len", "(", "_", ")", "for", "_", "in", "tail_filter_entities", ".", "values", "(", ")", ")", "\n", "\n", "\n", "# use bce loss, ignore the mlm", "\n", "if", "set_type", "==", "\"train\"", "and", "args", ".", "bce", ":", "\n", "            ", "lines", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "tail_filter_entities", ".", "items", "(", ")", ":", "\n", "                ", "h", ",", "r", "=", "k", ".", "split", "(", "'\\t'", ")", "\n", "t", "=", "v", "[", "0", "]", "\n", "lines", ".", "append", "(", "[", "h", ",", "r", ",", "t", "]", ")", "\n", "", "for", "k", ",", "v", "in", "head_filter_entities", ".", "items", "(", ")", ":", "\n", "                ", "t", ",", "r", "=", "k", ".", "split", "(", "'\\t'", ")", "\n", "h", "=", "v", "[", "0", "]", "\n", "lines", ".", "append", "(", "[", "h", ",", "r", ",", "t", "]", ")", "\n", "\n", "\n", "# for training , select each entity as for get mask embedding.", "\n", "", "", "if", "args", ".", "pretrain", ":", "\n", "            ", "rel", "=", "list", "(", "rel2text", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "lines", "=", "[", "]", "\n", "for", "k", "in", "ent2text", ".", "keys", "(", ")", ":", "\n", "                ", "lines", ".", "append", "(", "[", "k", ",", "rel", ",", "k", "]", ")", "\n", "\n", "", "", "print", "(", "f\"max number of filter entities : {max_head_entities} {max_tail_entities}\"", ")", "\n", "\n", "from", "os", "import", "cpu_count", "\n", "threads", "=", "min", "(", "1", ",", "cpu_count", "(", ")", ")", "\n", "filter_init", "(", "head_filter_entities", ",", "tail_filter_entities", ",", "ent2text", ",", "rel2text", ",", "ent2id", ",", "ent2token", ",", "rel2id", "\n", ")", "\n", "\n", "annotate_", "=", "partial", "(", "\n", "solve", ",", "\n", "pretrain", "=", "self", ".", "args", ".", "pretrain", "\n", ")", "\n", "examples", "=", "list", "(", "\n", "tqdm", "(", "\n", "map", "(", "annotate_", ",", "lines", ")", ",", "\n", "total", "=", "len", "(", "lines", ")", ",", "\n", "desc", "=", "\"convert text to examples\"", "\n", ")", "\n", ")", "\n", "\n", "tmp_examples", "=", "[", "]", "\n", "for", "e", "in", "examples", ":", "\n", "            ", "for", "ee", "in", "e", ":", "\n", "                ", "tmp_examples", ".", "append", "(", "ee", ")", "\n", "", "", "examples", "=", "tmp_examples", "\n", "# delete vars", "\n", "del", "head_filter_entities", ",", "tail_filter_entities", ",", "ent2text", ",", "rel2text", ",", "ent2id", ",", "ent2token", ",", "rel2id", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.Verbalizer.__init__": [[500, 507], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "if", "\"WN18RR\"", "in", "args", ".", "data_dir", ":", "\n", "            ", "self", ".", "mode", "=", "\"WN18RR\"", "\n", "", "elif", "\"FB15k\"", "in", "args", ".", "data_dir", ":", "\n", "            ", "self", ".", "mode", "=", "\"FB15k\"", "\n", "", "elif", "\"umls\"", "in", "args", ".", "data_dir", ":", "\n", "            ", "self", ".", "mode", "=", "\"umls\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.Verbalizer._convert": [[508, 513], ["None"], "methods", ["None"], ["", "", "def", "_convert", "(", "self", ",", "head", ",", "relation", ",", "tail", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "\"umls\"", ":", "\n", "            ", "return", "f\"The {relation} {head} is \"", "\n", "\n", "", "return", "f\"{head} {relation}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGCDataset.__init__": [[516, 518], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "features", ")", ":", "\n", "        ", "self", ".", "features", "=", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGCDataset.__getitem__": [[519, 521], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "features", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGCDataset.__len__": [[522, 524], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.__init__": [[527, 531], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "pretrain", "=", "args", ".", "pretrain", "\n", "self", ".", "max_seq_length", "=", "args", ".", "max_seq_length", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.initializer": [[532, 535], ["None"], "methods", ["None"], ["", "def", "initializer", "(", "self", ")", ":", "\n", "        ", "global", "bpe", "\n", "bpe", "=", "self", ".", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.encode": [[536, 540], ["bpe.encode", "list", "map"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.encode"], ["", "def", "encode", "(", "self", ",", "line", ")", ":", "\n", "        ", "global", "bpe", "\n", "ids", "=", "bpe", ".", "encode", "(", "line", ")", "\n", "return", "list", "(", "map", "(", "str", ",", "ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.decode": [[541, 544], ["bpe.decode"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "global", "bpe", "\n", "return", "bpe", ".", "decode", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.encode_lines": [[545, 556], ["line.strip.strip.strip", "enc_lines.append", "len", "json.dumps", "processor.MultiprocessingEncoder.convert_examples_to_features", "eval"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.convert_examples_to_features"], ["", "def", "encode_lines", "(", "self", ",", "lines", ")", ":", "\n", "        ", "\"\"\"\n        Encode a set of lines. All lines will be encoded together.\n        \"\"\"", "\n", "enc_lines", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                ", "return", "[", "\"EMPTY\"", ",", "None", "]", "\n", "", "enc_lines", ".", "append", "(", "json", ".", "dumps", "(", "self", ".", "convert_examples_to_features", "(", "example", "=", "eval", "(", "line", ")", ")", ")", ")", "\n", "", "return", "[", "\"PASS\"", ",", "enc_lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.decode_lines": [[557, 563], ["map", "dec_lines.append", "line.strip().split", "processor.MultiprocessingEncoder.decode", "line.strip"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.decode"], ["", "def", "decode_lines", "(", "self", ",", "lines", ")", ":", "\n", "        ", "dec_lines", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "tokens", "=", "map", "(", "int", ",", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "dec_lines", ".", "append", "(", "self", ".", "decode", "(", "tokens", ")", ")", "\n", "", "return", "[", "\"PASS\"", ",", "dec_lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.convert_examples_to_features": [[564, 613], ["dataclasses.asdict", "bpe", "bpe", "processor.InputFeatures", "bpe.sep_token.join", "bpe.sep_token.join"], "methods", ["None"], ["", "def", "convert_examples_to_features", "(", "self", ",", "example", ")", ":", "\n", "        ", "pretrain", "=", "self", ".", "pretrain", "\n", "max_seq_length", "=", "self", ".", "max_seq_length", "\n", "global", "bpe", "\n", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "text_a", "=", "example", "[", "'text_a'", "]", "\n", "text_b", "=", "example", "[", "'text_b'", "]", "\n", "text_c", "=", "example", "[", "'text_c'", "]", "\n", "\n", "if", "pretrain", ":", "\n", "# the des of xxx is [MASK] .", "\n", "# xxx is the description of [MASK].", "\n", "            ", "input_text", "=", "f\"The description of {text_a} is that {text_b} .\"", "\n", "inputs", "=", "bpe", "(", "\n", "input_text", ",", "\n", "truncation", "=", "\"longest_first\"", ",", "\n", "max_length", "=", "max_seq_length", ",", "\n", "padding", "=", "\"longest\"", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "text_a", "==", "\"[MASK]\"", ":", "\n", "                ", "input_text_a", "=", "bpe", ".", "sep_token", ".", "join", "(", "[", "text_a", ",", "text_b", "]", ")", "\n", "input_text_b", "=", "text_c", "\n", "", "else", ":", "\n", "                ", "input_text_a", "=", "text_a", "\n", "input_text_b", "=", "bpe", ".", "sep_token", ".", "join", "(", "[", "text_b", ",", "text_c", "]", ")", "\n", "\n", "", "inputs", "=", "bpe", "(", "\n", "input_text_a", ",", "\n", "input_text_b", ",", "\n", "truncation", "=", "\"longest_first\"", ",", "\n", "max_length", "=", "max_seq_length", ",", "\n", "padding", "=", "\"longest\"", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", ")", "\n", "", "assert", "bpe", ".", "mask_token_id", "in", "inputs", ".", "input_ids", ",", "\"mask token must in input\"", "\n", "\n", "features", "=", "asdict", "(", "InputFeatures", "(", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "inputs", "[", "'attention_mask'", "]", ",", "\n", "labels", "=", "example", "[", "'label'", "]", ",", "\n", "label", "=", "example", "[", "'real_label'", "]", ",", "\n", "en", "=", "example", "[", "'en'", "]", ",", "\n", "rel", "=", "example", "[", "'rel'", "]", ",", "\n", "entity", "=", "example", "[", "'entity'", "]", "\n", ")", "\n", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.lmap": [[22, 24], ["list", "map"], "function", ["None"], ["def", "lmap", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "list", "(", "map", "(", "a", ",", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.cache_results": [[26, 81], ["inspect.signature", "inspect.signature.parameters.items", "os.path.join", "RuntimeError", "kwargs.pop", "isinstance", "kwargs.pop", "isinstance", "kwargs.pop", "isinstance", "my_args.model_name_or_path.split", "os.path.exists", "func", "logger.info", "open", "pickle.load", "logger.info", "RuntimeError", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop"], ["", "def", "cache_results", "(", "_cache_fp", ",", "_refresh", "=", "False", ",", "_verbose", "=", "1", ")", ":", "\n", "    ", "def", "wrapper_", "(", "func", ")", ":", "\n", "        ", "signature", "=", "inspect", ".", "signature", "(", "func", ")", "\n", "for", "key", ",", "_", "in", "signature", ".", "parameters", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "(", "'_cache_fp'", ",", "'_refresh'", ",", "'_verbose'", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"The function decorated by cache_results cannot have keyword `{}`.\"", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "", "def", "wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "my_args", "=", "args", "[", "0", "]", "\n", "mode", "=", "args", "[", "-", "1", "]", "\n", "if", "'_cache_fp'", "in", "kwargs", ":", "\n", "                ", "cache_filepath", "=", "kwargs", ".", "pop", "(", "'_cache_fp'", ")", "\n", "assert", "isinstance", "(", "cache_filepath", ",", "str", ")", ",", "\"_cache_fp can only be str.\"", "\n", "", "else", ":", "\n", "                ", "cache_filepath", "=", "_cache_fp", "\n", "", "if", "'_refresh'", "in", "kwargs", ":", "\n", "                ", "refresh", "=", "kwargs", ".", "pop", "(", "'_refresh'", ")", "\n", "assert", "isinstance", "(", "refresh", ",", "bool", ")", ",", "\"_refresh can only be bool.\"", "\n", "", "else", ":", "\n", "                ", "refresh", "=", "_refresh", "\n", "", "if", "'_verbose'", "in", "kwargs", ":", "\n", "                ", "verbose", "=", "kwargs", ".", "pop", "(", "'_verbose'", ")", "\n", "assert", "isinstance", "(", "verbose", ",", "int", ")", ",", "\"_verbose can only be integer.\"", "\n", "", "else", ":", "\n", "                ", "verbose", "=", "_verbose", "\n", "", "refresh_flag", "=", "True", "\n", "\n", "model_name", "=", "my_args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "is_pretrain", "=", "my_args", ".", "pretrain", "\n", "cache_filepath", "=", "os", ".", "path", ".", "join", "(", "my_args", ".", "data_dir", ",", "f\"cached_{mode}_features{model_name}_pretrain{is_pretrain}.pkl\"", ")", "\n", "refresh", "=", "my_args", ".", "overwrite_cache", "\n", "\n", "if", "cache_filepath", "is", "not", "None", "and", "refresh", "is", "False", ":", "\n", "# load data", "\n", "                ", "if", "os", ".", "path", ".", "exists", "(", "cache_filepath", ")", ":", "\n", "                    ", "with", "open", "(", "cache_filepath", ",", "'rb'", ")", "as", "f", ":", "\n", "                        ", "results", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "if", "verbose", "==", "1", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Read cache from {}.\"", ".", "format", "(", "cache_filepath", ")", ")", "\n", "", "refresh_flag", "=", "False", "\n", "\n", "", "", "if", "refresh_flag", ":", "\n", "                ", "results", "=", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "cache_filepath", "is", "not", "None", ":", "\n", "                    ", "if", "results", "is", "None", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\"The return value is None. Delete the decorator.\"", ")", "\n", "", "with", "open", "(", "cache_filepath", ",", "'wb'", ")", "as", "f", ":", "\n", "                        ", "pickle", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "logger", ".", "info", "(", "\"Save cache to {}.\"", ".", "format", "(", "cache_filepath", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n", "", "return", "wrapper", "\n", "\n", "", "return", "wrapper_", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.solve": [[83, 109], ["examples.append", "examples.append", "examples.append", "processor.InputExample", "processor.InputExample", "processor.InputExample", "processor.lmap", "processor.lmap"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.lmap", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.lmap"], ["", "def", "solve", "(", "line", ",", "set_type", "=", "\"train\"", ",", "pretrain", "=", "1", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "\n", "head_ent_text", "=", "ent2text", "[", "line", "[", "0", "]", "]", "\n", "tail_ent_text", "=", "ent2text", "[", "line", "[", "2", "]", "]", "\n", "relation_text", "=", "rel2text", "[", "line", "[", "1", "]", "]", "\n", "\n", "i", "=", "0", "\n", "\n", "a", "=", "tail_filter_entities", "[", "\"\\t\"", ".", "join", "(", "[", "line", "[", "0", "]", ",", "line", "[", "1", "]", "]", ")", "]", "\n", "b", "=", "head_filter_entities", "[", "\"\\t\"", ".", "join", "(", "[", "line", "[", "2", "]", ",", "line", "[", "1", "]", "]", ")", "]", "\n", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "head_ent_text", "\n", "text_b", "=", "relation_text", "\n", "text_c", "=", "tail_ent_text", "\n", "\n", "if", "pretrain", ":", "\n", "        ", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "\"[MASK]\"", ",", "text_b", "=", "text_a", ",", "text_c", "=", "\"\"", ",", "label", "=", "ent2id", "[", "line", "[", "0", "]", "]", ",", "real_label", "=", "ent2id", "[", "line", "[", "0", "]", "]", ",", "en", "=", "0", ",", "rel", "=", "0", ",", "entity", "=", "line", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "\"[MASK]\"", ",", "text_b", "=", "text_b", "+", "\"[PAD]\"", ",", "text_c", "=", "\"[UNK]\"", "+", "\" \"", "+", "text_c", ",", "label", "=", "lmap", "(", "lambda", "x", ":", "ent2id", "[", "x", "]", ",", "b", ")", ",", "real_label", "=", "ent2id", "[", "line", "[", "0", "]", "]", ",", "en", "=", "ent2id", "[", "line", "[", "2", "]", "]", ",", "rel", "=", "rel2id", "[", "line", "[", "1", "]", "]", ",", "entity", "=", "line", "[", "0", "]", ")", ")", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "\"[UNK] \"", ",", "text_b", "=", "text_b", "+", "\"[PAD]\"", ",", "text_c", "=", "\"[MASK]\"", "+", "text_a", ",", "label", "=", "lmap", "(", "lambda", "x", ":", "ent2id", "[", "x", "]", ",", "a", ")", ",", "real_label", "=", "ent2id", "[", "line", "[", "2", "]", "]", ",", "en", "=", "ent2id", "[", "line", "[", "0", "]", "]", ",", "rel", "=", "rel2id", "[", "line", "[", "1", "]", "]", ",", "entity", "=", "line", "[", "2", "]", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.filter_init": [[111, 127], ["None"], "function", ["None"], ["", "def", "filter_init", "(", "head", ",", "tail", ",", "t1", ",", "t2", ",", "ent2id_", ",", "ent2token_", ",", "rel2id_", ")", ":", "\n", "    ", "global", "head_filter_entities", "\n", "global", "tail_filter_entities", "\n", "global", "ent2text", "\n", "global", "rel2text", "\n", "global", "ent2id", "\n", "global", "ent2token", "\n", "global", "rel2id", "\n", "\n", "head_filter_entities", "=", "head", "\n", "tail_filter_entities", "=", "tail", "\n", "ent2text", "=", "t1", "\n", "rel2text", "=", "t2", "\n", "ent2id", "=", "ent2id_", "\n", "ent2token", "=", "ent2token_", "\n", "rel2id", "=", "rel2id_", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.delete_init": [[129, 132], ["None"], "function", ["None"], ["", "def", "delete_init", "(", "ent2text_", ")", ":", "\n", "    ", "global", "ent2text", "\n", "ent2text", "=", "ent2text_", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.convert_examples_to_features_init": [[134, 137], ["None"], "function", ["None"], ["", "def", "convert_examples_to_features_init", "(", "tokenizer_for_convert", ")", ":", "\n", "    ", "global", "tokenizer", "\n", "tokenizer", "=", "tokenizer_for_convert", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.convert_examples_to_features": [[139, 170], ["tokenizer", "dataclasses.asdict", "tokenizer.sep_token.join", "processor.InputFeatures", "example.text_a.split", "example.text_b.split", "example.text_c.split", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "convert_examples_to_features", "(", "example", ",", "max_seq_length", ",", "mode", ",", "pretrain", "=", "1", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "text_a", "=", "\" \"", ".", "join", "(", "example", ".", "text_a", ".", "split", "(", ")", "[", ":", "128", "]", ")", "\n", "text_b", "=", "\" \"", ".", "join", "(", "example", ".", "text_b", ".", "split", "(", ")", "[", ":", "128", "]", ")", "\n", "text_c", "=", "\" \"", ".", "join", "(", "example", ".", "text_c", ".", "split", "(", ")", "[", ":", "128", "]", ")", "\n", "\n", "if", "pretrain", ":", "\n", "        ", "input_text_a", "=", "text_a", "\n", "input_text_b", "=", "text_b", "\n", "", "else", ":", "\n", "        ", "input_text_a", "=", "tokenizer", ".", "sep_token", ".", "join", "(", "[", "text_a", ",", "text_b", "]", ")", "\n", "input_text_b", "=", "text_c", "\n", "\n", "\n", "", "inputs", "=", "tokenizer", "(", "\n", "input_text_a", ",", "\n", "input_text_b", ",", "\n", "truncation", "=", "\"longest_first\"", ",", "\n", "max_length", "=", "max_seq_length", ",", "\n", "padding", "=", "\"longest\"", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", ")", "\n", "assert", "tokenizer", ".", "mask_token_id", "in", "inputs", ".", "input_ids", ",", "\"mask token must in input\"", "\n", "\n", "features", "=", "asdict", "(", "InputFeatures", "(", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "inputs", "[", "'attention_mask'", "]", ",", "\n", "labels", "=", "torch", ".", "tensor", "(", "example", ".", "label", ")", ",", "\n", "label", "=", "torch", ".", "tensor", "(", "example", ".", "real_label", ")", "\n", ")", "\n", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.get_dataset": [[172, 246], ["processor.cache_results", "transformers.models.auto.tokenization_auto.AutoTokenizer.from_pretrained", "len", "enumerate", "processor.KGCDataset", "processor.get_train_examples", "open", "os.path.join", "os.path.join", "contextlib.ExitStack", "processor.MultiprocessingEncoder", "multiprocessing.Pool", "processor.MultiprocessingEncoder.initializer", "multiprocessing.Pool.imap", "collections.Counter", "tqdm.tqdm", "collections.Counter.most_common", "processor.get_entities", "features[].pop", "features[].pop", "enumerate", "enumerate", "processor.get_dev_examples", "processor.get_test_examples", "os.path.join", "d.update", "file.write", "zip", "enumerate", "print", "stack.enter_context", "stack.enter_context", "len", "zip", "json.dumps", "open", "open", "KGCDataset.append", "len", "eval", "len"], "function", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.cache_results", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_train_examples", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.MultiprocessingEncoder.initializer", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_entities", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.pop", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_dev_examples", "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.processor.KGProcessor.get_test_examples", "home.repos.pwc.inspect_result.zjunlp_MKGformer.models.utils.ModelOutput.update"], ["", "@", "cache_results", "(", "_cache_fp", "=", "\"./dataset\"", ")", "\n", "def", "get_dataset", "(", "args", ",", "processor", ",", "label_list", ",", "tokenizer", ",", "mode", ")", ":", "\n", "\n", "    ", "assert", "mode", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ",", "\"mode must be in train dev test!\"", "\n", "\n", "# use training data to construct the entity embedding", "\n", "if", "args", ".", "faiss_init", "and", "mode", "==", "\"test\"", "and", "not", "args", ".", "pretrain", ":", "\n", "        ", "mode", "=", "\"train\"", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "\n", "", "if", "mode", "==", "\"train\"", ":", "\n", "        ", "train_examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"dev\"", ":", "\n", "        ", "train_examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "        ", "train_examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "f\"examples_{mode}.txt\"", ")", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "for", "line", "in", "train_examples", ":", "\n", "            ", "d", "=", "{", "}", "\n", "d", ".", "update", "(", "line", ".", "__dict__", ")", "\n", "file", ".", "write", "(", "json", ".", "dumps", "(", "d", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "features", "=", "[", "]", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "use_fast", "=", "False", ")", "\n", "file_inputs", "=", "[", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "f\"examples_{mode}.txt\"", ")", "]", "\n", "file_outputs", "=", "[", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "f\"features_{mode}.txt\"", ")", "]", "\n", "\n", "with", "contextlib", ".", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "inputs", "=", "[", "\n", "stack", ".", "enter_context", "(", "open", "(", "input", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "if", "input", "!=", "\"-\"", "else", "sys", ".", "stdin", "\n", "for", "input", "in", "file_inputs", "\n", "]", "\n", "outputs", "=", "[", "\n", "stack", ".", "enter_context", "(", "open", "(", "output", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "if", "output", "!=", "\"-\"", "else", "sys", ".", "stdout", "\n", "for", "output", "in", "file_outputs", "\n", "]", "\n", "\n", "encoder", "=", "MultiprocessingEncoder", "(", "tokenizer", ",", "args", ")", "\n", "pool", "=", "Pool", "(", "16", ",", "initializer", "=", "encoder", ".", "initializer", ")", "\n", "encoder", ".", "initializer", "(", ")", "\n", "encoded_lines", "=", "pool", ".", "imap", "(", "encoder", ".", "encode_lines", ",", "zip", "(", "*", "inputs", ")", ",", "1000", ")", "\n", "# encoded_lines = map(encoder.encode_lines, zip(*inputs))", "\n", "\n", "stats", "=", "Counter", "(", ")", "\n", "for", "i", ",", "(", "filt", ",", "enc_lines", ")", "in", "tqdm", "(", "enumerate", "(", "encoded_lines", ",", "start", "=", "1", ")", ",", "total", "=", "len", "(", "train_examples", ")", ")", ":", "\n", "            ", "if", "filt", "==", "\"PASS\"", ":", "\n", "                ", "for", "enc_line", ",", "output_h", "in", "zip", "(", "enc_lines", ",", "outputs", ")", ":", "\n", "                    ", "features", ".", "append", "(", "eval", "(", "enc_line", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "stats", "[", "\"num_filtered_\"", "+", "filt", "]", "+=", "1", "\n", "\n", "", "", "for", "k", ",", "v", "in", "stats", ".", "most_common", "(", ")", ":", "\n", "            ", "print", "(", "\"[{}] filtered {} lines\"", ".", "format", "(", "k", ",", "v", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "", "num_entities", "=", "len", "(", "processor", ".", "get_entities", "(", "args", ".", "data_dir", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "        ", "en", "=", "features", "[", "f_id", "]", ".", "pop", "(", "\"en\"", ")", "\n", "rel", "=", "features", "[", "f_id", "]", ".", "pop", "(", "\"rel\"", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "f", "[", "'input_ids'", "]", ")", ":", "\n", "            ", "if", "t", "==", "tokenizer", ".", "unk_token_id", ":", "\n", "                ", "features", "[", "f_id", "]", "[", "'input_ids'", "]", "[", "i", "]", "=", "en", "+", "len", "(", "tokenizer", ")", "\n", "break", "\n", "\n", "", "", "for", "i", ",", "t", "in", "enumerate", "(", "f", "[", "'input_ids'", "]", ")", ":", "\n", "            ", "if", "t", "==", "tokenizer", ".", "pad_token_id", ":", "\n", "                ", "features", "[", "f_id", "]", "[", "'input_ids'", "]", "[", "i", "]", "=", "rel", "+", "len", "(", "tokenizer", ")", "+", "num_entities", "\n", "break", "\n", "\n", "", "", "", "features", "=", "KGCDataset", "(", "features", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.Config.__getattr__": [[12, 14], ["base_data_module.Config.get"], "methods", ["None"], ["    ", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "get", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.Config.__setattr__": [[15, 17], ["None"], "methods", ["None"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "val", ")", ":", "\n", "        ", "self", "[", "name", "]", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__": [[29, 34], ["pytorch_lightning.LightningDataModule.__init__", "base_data_module.BaseDataModule.args.get", "base_data_module.BaseDataModule.args.get", "base_data_module.Config", "vars"], "methods", ["home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "args", ":", "argparse", ".", "Namespace", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "Config", "(", "vars", "(", "args", ")", ")", "if", "args", "is", "not", "None", "else", "{", "}", "\n", "self", ".", "batch_size", "=", "self", ".", "args", ".", "get", "(", "\"batch_size\"", ",", "BATCH_SIZE", ")", "\n", "self", ".", "num_workers", "=", "self", ".", "args", ".", "get", "(", "\"num_workers\"", ",", "NUM_WORKERS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.add_to_argparse": [[36, 48], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_to_argparse", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "BATCH_SIZE", ",", "help", "=", "\"Number of examples to operate on per forward step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Number of additional processes to load data.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"./dataset/NELL\"", ",", "help", "=", "\"Number of additional processes to load data.\"", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.prepare_data": [[49, 54], ["None"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Use this method to do things that might write to disk or that need to be done only from a single GPU in distributed settings (so don't set state `self.x = y`).\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.setup": [[55, 63], ["None"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Split into train, val, test, and set dims.\n        Should assign `torch Dataset` objects to self.data_train, self.data_val, and optionally self.data_test.\n        \"\"\"", "\n", "self", ".", "data_train", "=", "None", "\n", "self", ".", "data_val", "=", "None", "\n", "self", ".", "data_test", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.train_dataloader": [[64, 66], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "data_train", ",", "shuffle", "=", "True", ",", "batch_size", "=", "self", ".", "batch_size", ",", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.val_dataloader": [[67, 69], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "data_val", ",", "shuffle", "=", "False", ",", "batch_size", "=", "self", ".", "batch_size", ",", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zjunlp_MKGformer.data.base_data_module.BaseDataModule.test_dataloader": [[70, 72], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "data_test", ",", "shuffle", "=", "False", ",", "batch_size", "=", "self", ".", "batch_size", ",", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "", "", "", ""]]}