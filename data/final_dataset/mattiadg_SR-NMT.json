{"home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.translate.reportScore": [[55, 59], ["print", "math.exp"], "function", ["None"], ["def", "reportScore", "(", "name", ",", "scoreTotal", ",", "wordsTotal", ")", ":", "\n", "    ", "print", "(", "\"%s AVG SCORE: %.4f, %s PPL: %.4f\"", "%", "(", "\n", "name", ",", "scoreTotal", "/", "wordsTotal", ",", "\n", "name", ",", "math", ".", "exp", "(", "-", "scoreTotal", "/", "wordsTotal", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.translate.addone": [[61, 65], ["None"], "function", ["None"], ["", "def", "addone", "(", "f", ")", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "        ", "yield", "line", "\n", "", "yield", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.translate.main": [[67, 156], ["parser.parse_args", "onmt.Translator", "onmt.Translator", "codecs.open", "translate.addone", "translate.reportScore", "torch.cuda.set_device", "codecs.open", "onmt.Translator.initBeamAccum", "codecs.open", "onmt.Translator.translate", "sum", "sum", "range", "translate.reportScore", "tgtF.close", "json.dump", "line.split", "sum", "sum", "len", "codecs.open.write", "codecs.open.flush", "codecs.open", "len", "len", "len", "os.write", "os.write", "print", "print", "tgtF.readline().split", "len", "srcSent.lower.lower", "builtins.bytes", "builtins.bytes", "os.write", "print", "print", "range", "tgtSent.lower.lower", "builtins.bytes", "os.write", "tgtF.readline", "builtins.bytes"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.translate.addone", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.translate.reportScore", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.initBeamAccum", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.translate", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.translate.reportScore"], ["", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "", "translator", "=", "onmt", ".", "Translator", "(", "opt", ")", "\n", "\n", "\n", "outF", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w'", ",", "'utf-8'", ")", "\n", "\n", "predScoreTotal", ",", "predWordsTotal", ",", "goldScoreTotal", ",", "goldWordsTotal", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "srcBatch", ",", "tgtBatch", "=", "[", "]", ",", "[", "]", "\n", "\n", "count", "=", "0", "\n", "\n", "tgtF", "=", "codecs", ".", "open", "(", "opt", ".", "tgt", ",", "'r'", ",", "'utf-8'", ")", "if", "opt", ".", "tgt", "else", "None", "\n", "\n", "if", "opt", ".", "dump_beam", "!=", "\"\"", ":", "\n", "        ", "import", "json", "\n", "translator", ".", "initBeamAccum", "(", ")", "\n", "\n", "", "for", "line", "in", "addone", "(", "codecs", ".", "open", "(", "opt", ".", "src", ",", "'r'", ",", "'utf-8'", ")", ")", ":", "\n", "        ", "if", "line", "is", "not", "None", ":", "\n", "            ", "srcTokens", "=", "line", ".", "split", "(", ")", "\n", "srcBatch", "+=", "[", "srcTokens", "]", "\n", "if", "tgtF", ":", "\n", "                ", "tgtTokens", "=", "tgtF", ".", "readline", "(", ")", ".", "split", "(", ")", "if", "tgtF", "else", "None", "\n", "tgtBatch", "+=", "[", "tgtTokens", "]", "\n", "\n", "", "if", "len", "(", "srcBatch", ")", "<", "opt", ".", "batch_size", ":", "\n", "                ", "continue", "\n", "", "", "else", ":", "\n", "# at the end of file, check last batch", "\n", "            ", "if", "len", "(", "srcBatch", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "predBatch", ",", "predScore", ",", "goldScore", "=", "translator", ".", "translate", "(", "srcBatch", ",", "\n", "tgtBatch", ")", "\n", "predScoreTotal", "+=", "sum", "(", "score", "[", "0", "]", "for", "score", "in", "predScore", ")", "\n", "predWordsTotal", "+=", "sum", "(", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "predBatch", ")", "\n", "if", "tgtF", "is", "not", "None", ":", "\n", "            ", "goldScoreTotal", "+=", "sum", "(", "goldScore", ")", "\n", "goldWordsTotal", "+=", "sum", "(", "len", "(", "x", ")", "for", "x", "in", "tgtBatch", ")", "\n", "\n", "", "for", "b", "in", "range", "(", "len", "(", "predBatch", ")", ")", ":", "\n", "            ", "count", "+=", "1", "\n", "outF", ".", "write", "(", "\" \"", ".", "join", "(", "predBatch", "[", "b", "]", "[", "0", "]", ")", "+", "'\\n'", ")", "\n", "outF", ".", "flush", "(", ")", "\n", "\n", "if", "opt", ".", "verbose", ":", "\n", "                ", "srcSent", "=", "' '", ".", "join", "(", "srcBatch", "[", "b", "]", ")", "\n", "if", "translator", ".", "tgt_dict", ".", "lower", ":", "\n", "                    ", "srcSent", "=", "srcSent", ".", "lower", "(", ")", "\n", "", "os", ".", "write", "(", "1", ",", "bytes", "(", "'SENT %d: %s\\n'", "%", "(", "count", ",", "srcSent", ")", ",", "'UTF-8'", ")", ")", "\n", "os", ".", "write", "(", "1", ",", "bytes", "(", "'PRED %d: %s\\n'", "%", "\n", "(", "count", ",", "\" \"", ".", "join", "(", "predBatch", "[", "b", "]", "[", "0", "]", ")", ")", ",", "'UTF-8'", ")", ")", "\n", "print", "(", "\"PRED SCORE: %.4f\"", "%", "predScore", "[", "b", "]", "[", "0", "]", ")", "\n", "\n", "if", "tgtF", "is", "not", "None", ":", "\n", "                    ", "tgtSent", "=", "' '", ".", "join", "(", "tgtBatch", "[", "b", "]", ")", "\n", "if", "translator", ".", "tgt_dict", ".", "lower", ":", "\n", "                        ", "tgtSent", "=", "tgtSent", ".", "lower", "(", ")", "\n", "", "os", ".", "write", "(", "1", ",", "bytes", "(", "'GOLD %d: %s\\n'", "%", "\n", "(", "count", ",", "tgtSent", ")", ",", "'UTF-8'", ")", ")", "\n", "print", "(", "\"GOLD SCORE: %.4f\"", "%", "goldScore", "[", "b", "]", ")", "\n", "\n", "", "if", "opt", ".", "n_best", ">", "1", ":", "\n", "                    ", "print", "(", "'\\nBEST HYP:'", ")", "\n", "for", "n", "in", "range", "(", "opt", ".", "n_best", ")", ":", "\n", "                        ", "os", ".", "write", "(", "1", ",", "bytes", "(", "\"[%.4f] %s\\n\"", "%", "(", "predScore", "[", "b", "]", "[", "n", "]", ",", "\n", "\" \"", ".", "join", "(", "predBatch", "[", "b", "]", "[", "n", "]", ")", ")", ",", "\n", "'UTF-8'", ")", ")", "\n", "\n", "", "", "print", "(", "''", ")", "\n", "\n", "", "", "srcBatch", ",", "tgtBatch", "=", "[", "]", ",", "[", "]", "\n", "\n", "", "reportScore", "(", "'PRED'", ",", "predScoreTotal", ",", "predWordsTotal", ")", "\n", "if", "tgtF", ":", "\n", "        ", "reportScore", "(", "'GOLD'", ",", "goldScoreTotal", ",", "goldWordsTotal", ")", "\n", "\n", "", "if", "tgtF", ":", "\n", "        ", "tgtF", ".", "close", "(", ")", "\n", "\n", "", "if", "opt", ".", "dump_beam", ":", "\n", "        ", "json", ".", "dump", "(", "translator", ".", "beam_accum", ",", "\n", "codecs", ".", "open", "(", "opt", ".", "dump_beam", ",", "'w'", ",", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.NMTCriterion": [[179, 186], ["torch.ones", "torch.ones", "torch.NLLLoss", "nn.NLLLoss.cuda"], "function", ["None"], ["", "", "def", "NMTCriterion", "(", "vocabSize", ")", ":", "\n", "    ", "weight", "=", "torch", ".", "ones", "(", "vocabSize", ")", "\n", "weight", "[", "onmt", ".", "Constants", ".", "PAD", "]", "=", "0", "\n", "crit", "=", "nn", ".", "NLLLoss", "(", "weight", ",", "size_average", "=", "False", ")", "\n", "if", "opt", ".", "gpus", ":", "\n", "        ", "crit", ".", "cuda", "(", ")", "\n", "", "return", "crit", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.memoryEfficientLoss": [[188, 212], ["torch.autograd.Variable", "torch.autograd.Variable.size", "torch.split", "torch.split", "torch.split", "torch.split", "enumerate", "zip", "out_t.view.view", "generator", "crit", "pred_t.data.eq().masked_select().sum", "out_t.view.size", "targ_t.view", "generator.max", "crit.div().backward", "pred_t.data.eq().masked_select", "crit.div", "pred_t.data.eq", "targ_t.ne"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "memoryEfficientLoss", "(", "outputs", ",", "targets", ",", "generator", ",", "crit", ",", "eval", "=", "False", ")", ":", "\n", "# compute generations one piece at a time", "\n", "    ", "num_correct", ",", "loss", "=", "0", ",", "0", "\n", "outputs", "=", "Variable", "(", "outputs", ".", "data", ",", "requires_grad", "=", "(", "not", "eval", ")", ",", "volatile", "=", "eval", ")", "\n", "\n", "batch_size", "=", "outputs", ".", "size", "(", "1", ")", "\n", "outputs_split", "=", "torch", ".", "split", "(", "outputs", ",", "opt", ".", "max_generator_batches", ")", "\n", "targets_split", "=", "torch", ".", "split", "(", "targets", ",", "opt", ".", "max_generator_batches", ")", "\n", "for", "i", ",", "(", "out_t", ",", "targ_t", ")", "in", "enumerate", "(", "zip", "(", "outputs_split", ",", "targets_split", ")", ")", ":", "\n", "        ", "out_t", "=", "out_t", ".", "view", "(", "-", "1", ",", "out_t", ".", "size", "(", "2", ")", ")", "\n", "scores_t", "=", "generator", "(", "out_t", ")", "\n", "loss_t", "=", "crit", "(", "scores_t", ",", "targ_t", ".", "view", "(", "-", "1", ")", ")", "\n", "pred_t", "=", "scores_t", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "num_correct_t", "=", "pred_t", ".", "data", ".", "eq", "(", "targ_t", ".", "data", ")", ".", "masked_select", "(", "\n", "targ_t", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "data", ")", ".", "sum", "(", ")", "\n", "num_correct", "+=", "num_correct_t", "\n", "loss", "+=", "loss_t", ".", "data", "[", "0", "]", "\n", "if", "not", "eval", ":", "\n", "            ", "loss_t", ".", "div", "(", "batch_size", ")", ".", "backward", "(", ")", "\n", "\n", "", "", "grad_output", "=", "None", "if", "outputs", ".", "grad", "is", "None", "else", "outputs", ".", "grad", ".", "data", "\n", "return", "loss", ",", "grad_output", ",", "num_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.eval": [[214, 234], ["model.eval", "range", "model.train", "len", "model", "train.memoryEfficientLoss", "targets.data.ne().sum", "targets.data.ne"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.eval", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.memoryEfficientLoss"], ["", "def", "eval", "(", "model", ",", "criterion", ",", "data", ")", ":", "\n", "    ", "total_loss", "=", "0", "\n", "total_words", "=", "0", "\n", "total_num_correct", "=", "0", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "# exclude original indices", "\n", "        ", "batch", "=", "data", "[", "i", "]", "[", ":", "-", "1", "]", "\n", "outputs", "=", "model", "(", "batch", ")", "\n", "# exclude <s> from targets", "\n", "targets", "=", "batch", "[", "1", "]", "[", "1", ":", "]", "\n", "loss", ",", "_", ",", "num_correct", "=", "memoryEfficientLoss", "(", "\n", "outputs", ",", "targets", ",", "model", ".", "generator", ",", "criterion", ",", "eval", "=", "True", ")", "\n", "total_loss", "+=", "loss", "\n", "total_num_correct", "+=", "num_correct", "\n", "total_words", "+=", "targets", ".", "data", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "return", "total_loss", "/", "total_words", ",", "total_num_correct", "/", "total_words", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.trainModel": [[236, 344], ["print", "model.train", "train.NMTCriterion", "time.time", "[].size", "torch.randperm", "torch.randperm", "time.time", "range", "print", "train.trainModel.trainEpoch"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.NMTCriterion", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "trainModel", "(", "model", ",", "trainData", ",", "validData", ",", "dataset", ",", "optim", ",", "opt", ")", ":", "\n", "    ", "print", "(", "model", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# Define criterion of each GPU.", "\n", "criterion", "=", "NMTCriterion", "(", "dataset", "[", "'dicts'", "]", "[", "'tgt'", "]", ".", "size", "(", ")", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "def", "trainEpoch", "(", "epoch", ",", "iter", ")", ":", "\n", "\n", "        ", "if", "opt", ".", "extra_shuffle", "and", "epoch", ">", "opt", ".", "curriculum", ":", "\n", "            ", "trainData", ".", "shuffle", "(", ")", "\n", "\n", "# Shuffle mini batch order.", "\n", "", "batchOrder", "=", "torch", ".", "randperm", "(", "len", "(", "trainData", ")", ")", "\n", "\n", "total_loss", ",", "total_words", ",", "total_num_correct", "=", "0", ",", "0", ",", "0", "\n", "report_loss", ",", "report_tgt_words", "=", "0", ",", "0", "\n", "report_src_words", ",", "report_num_correct", "=", "0", ",", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "trainData", ")", ")", ":", "\n", "\n", "            ", "if", "iter", ">=", "opt", ".", "epochs", ":", "\n", "                ", "break", "\n", "", "iter", "+=", "1", "\n", "\n", "batchIdx", "=", "batchOrder", "[", "i", "]", "if", "epoch", ">", "opt", ".", "curriculum", "else", "i", "\n", "# Exclude original indices.", "\n", "batch", "=", "trainData", "[", "batchIdx", "]", "[", ":", "-", "1", "]", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", "(", "batch", ")", "\n", "# Exclude <s> from targets.", "\n", "targets", "=", "batch", "[", "1", "]", "[", "1", ":", "]", "\n", "loss", ",", "gradOutput", ",", "num_correct", "=", "memoryEfficientLoss", "(", "\n", "outputs", ",", "targets", ",", "model", ".", "generator", ",", "criterion", ")", "\n", "\n", "outputs", ".", "backward", "(", "gradOutput", ")", "\n", "\n", "# Update the parameters.", "\n", "optim", ".", "step", "(", ")", "\n", "\n", "num_words", "=", "targets", ".", "data", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", "\n", "report_loss", "+=", "loss", "\n", "report_num_correct", "+=", "num_correct", "\n", "report_tgt_words", "+=", "num_words", "\n", "report_src_words", "+=", "batch", "[", "0", "]", "[", "1", "]", ".", "data", ".", "sum", "(", ")", "\n", "total_loss", "+=", "loss", "\n", "total_num_correct", "+=", "num_correct", "\n", "total_words", "+=", "num_words", "\n", "if", "i", "%", "opt", ".", "log_interval", "==", "-", "1", "%", "opt", ".", "log_interval", ":", "\n", "                ", "print", "(", "(", "\"Epoch %2d, %5d/%5d; acc: %6.2f; ppl: %6.2f; \"", "+", "\n", "\"%3.0f src tok/s; %3.0f tgt tok/s; %6.0f s elapsed\"", ")", "%", "\n", "(", "epoch", ",", "i", "+", "1", ",", "len", "(", "trainData", ")", ",", "\n", "report_num_correct", "/", "report_tgt_words", "*", "100", ",", "\n", "math", ".", "exp", "(", "report_loss", "/", "report_tgt_words", ")", ",", "\n", "report_src_words", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ",", "\n", "report_tgt_words", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n", "report_loss", ",", "report_tgt_words", "=", "0", ",", "0", "\n", "report_src_words", ",", "report_num_correct", "=", "0", ",", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "if", "iter", "%", "opt", ".", "save_each", "==", "0", ":", "\n", "#  (2) evaluate on the validation set", "\n", "                ", "valid_loss", ",", "valid_acc", "=", "eval", "(", "model", ",", "criterion", ",", "validData", ")", "\n", "valid_ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", "\n", "print", "(", "'Validation perplexity: %g'", "%", "valid_ppl", ")", "\n", "print", "(", "'Validation accuracy: %g'", "%", "(", "valid_acc", "*", "100", ")", ")", "\n", "\n", "#  (3) update the learning rate", "\n", "if", "opt", ".", "use_learning_rate_decay", ":", "\n", "                    ", "optim", ".", "updateLearningRate", "(", "valid_ppl", ",", "iter", ")", "\n", "\n", "", "model_state_dict", "=", "(", "model", ".", "module", ".", "state_dict", "(", ")", "if", "len", "(", "opt", ".", "gpus", ")", ">", "1", "\n", "else", "model", ".", "state_dict", "(", ")", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "(", "model", ".", "generator", ".", "module", ".", "state_dict", "(", ")", "\n", "if", "len", "(", "opt", ".", "gpus", ")", ">", "1", "\n", "else", "model", ".", "generator", ".", "state_dict", "(", ")", ")", "\n", "#  (4) drop a checkpoint", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'dicts'", ":", "dataset", "[", "'dicts'", "]", ",", "\n", "'opt'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optim'", ":", "optim", ",", "\n", "'type'", ":", "opt", ".", "model_type", "\n", "}", "\n", "torch", ".", "save", "(", "checkpoint", ",", "\n", "'%s_acc_%.2f_ppl_%.2f_iter%d_e%d.pt'", "\n", "%", "(", "opt", ".", "save_model", ",", "100", "*", "valid_acc", ",", "valid_ppl", ",", "iter", ",", "epoch", ")", ")", "\n", "\n", "", "", "return", "total_loss", "/", "total_words", ",", "total_num_correct", "/", "total_words", ",", "iter", "\n", "\n", "", "epoch", ",", "iter", "=", "1", ",", "0", "\n", "while", "iter", "<", "opt", ".", "epochs", ":", "\n", "        ", "print", "(", "''", ")", "\n", "#  (1) train for one epoch on the training set", "\n", "train_loss", ",", "train_acc", ",", "iter", "=", "trainEpoch", "(", "epoch", ",", "iter", ")", "\n", "epoch", "+=", "1", "\n", "train_ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", "\n", "print", "(", "'Train perplexity: %g'", "%", "train_ppl", ")", "\n", "print", "(", "'Train accuracy: %g'", "%", "(", "train_acc", "*", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.main": [[346, 480], ["print", "torch.load", "torch.load", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "print", "print", "print", "torch.Sequential", "sum", "print", "train.trainModel", "print", "torch.load", "torch.load", "dicts.get", "print", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "torch.Linear", "torch.LogSoftmax", "print", "chk_model.generator.state_dict", "onmt.LanguageModel.LM.load_state_dict", "nn.DataParallel.load_state_dict", "print", "onmt.LanguageModel.LM.load_state_dict", "nn.DataParallel.load_state_dict", "len", "onmt.LanguageModel.LM.cuda", "nn.DataParallel.cuda", "onmt.LanguageModel.LM.cpu", "nn.DataParallel.cpu", "len", "torch.DataParallel", "torch.DataParallel", "onmt.LanguageModel.LM.parameters", "onmt.LanguageModel.LM.initialize_parameters", "onmt.LanguageModel.LM.load_pretrained_vectors", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim.set_parameters", "print", "onmt.Optim.optimizer.load_state_dict", "onmt.Optim.set_parameters", "print", "torch.load.get", "print", "NotImplementedError", "torch.load.get", "torch.load.get", "print", "len", "onmt.Decoders.getDecoder", "onmt.Decoders.getDecoder", "onmt.Decoders.getDecoder", "onmt.Decoders.getDecoder", "onmt.Decoders.getDecoder", "onmt.Decoders.getDecoder", "onmt.Encoders.getEncoder", "onmt.Encoders.getEncoder", "onmt.Encoders.getEncoder", "onmt.Encoders.getEncoder", "onmt.Encoders.getEncoder", "onmt.Encoders.getEncoder", "onmt.LanguageModel.LM", "onmt.LanguageModel.LM", "onmt.LanguageModel.LM", "onmt.LanguageModel.LM", "onmt.LanguageModel.LM", "onmt.LanguageModel.LM", "dicts[].size", "onmt.LanguageModel.LM.parameters", "checkpoint[].optimizer.state_dict", "onmt.LanguageModel.LM.parameters", "p.nelement", "torch.load.get", "print", "chk_model.state_dict().items", "len", "torch.nn.init.xavier_normal", "p.data.uniform_", "onmt.LanguageModel.LM.parameters", "torch.load.get", "dicts[].size", "dicts[].size", "dicts[].size", "p.data.size", "chk_model.state_dict"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.trainModel", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.ImageEncoder.ImageEncoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.set_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.set_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"Loading data from '%s'\"", "%", "opt", ".", "data", ")", "\n", "\n", "dataset", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "if", "opt", ".", "model_type", "==", "'nmt'", ":", "\n", "        ", "if", "dataset", ".", "get", "(", "\"type\"", ",", "\"text\"", ")", "not", "in", "[", "\"bitext\"", ",", "\"text\"", "]", ":", "\n", "            ", "print", "(", "\"WARNING: The provided dataset is not bilingual!\"", ")", "\n", "", "", "elif", "opt", ".", "model_type", "==", "'lm'", ":", "\n", "        ", "if", "dataset", ".", "get", "(", "\"type\"", ",", "\"text\"", ")", "!=", "'monotext'", ":", "\n", "            ", "print", "(", "\"WARNING: The provided dataset is not monolingual!\"", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Not valid model type %s'", "%", "opt", ".", "model_type", ")", "\n", "\n", "", "dict_checkpoint", "=", "(", "opt", ".", "train_from", "if", "opt", ".", "train_from", "\n", "else", "opt", ".", "train_from_state_dict", ")", "\n", "if", "dict_checkpoint", ":", "\n", "        ", "print", "(", "'Loading dicts from checkpoint at %s'", "%", "dict_checkpoint", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "dict_checkpoint", ")", "\n", "if", "opt", ".", "model_type", "==", "'nmt'", ":", "\n", "            ", "assert", "checkpoint", ".", "get", "(", "'type'", ",", "None", ")", "is", "None", "or", "checkpoint", "[", "'type'", "]", "==", "\"nmt\"", ",", "\"The loaded model is not neural machine translation!\"", "\n", "", "elif", "opt", ".", "model_type", "==", "'lm'", ":", "\n", "            ", "assert", "checkpoint", "[", "'type'", "]", "==", "\"lm\"", ",", "\"The loaded model is not a language model!\"", "\n", "", "dataset", "[", "'dicts'", "]", "=", "checkpoint", "[", "'dicts'", "]", "\n", "\n", "", "trainData", "=", "onmt", ".", "Dataset", "(", "dataset", "[", "'train'", "]", "[", "'src'", "]", ",", "\n", "dataset", "[", "'train'", "]", "[", "'tgt'", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "gpus", ",", "\n", "data_type", "=", "dataset", ".", "get", "(", "\"type\"", ",", "\"text\"", ")", ")", "\n", "validData", "=", "onmt", ".", "Dataset", "(", "dataset", "[", "'valid'", "]", "[", "'src'", "]", ",", "\n", "dataset", "[", "'valid'", "]", "[", "'tgt'", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "gpus", ",", "\n", "volatile", "=", "True", ",", "\n", "data_type", "=", "dataset", ".", "get", "(", "\"type\"", ",", "\"text\"", ")", ")", "\n", "\n", "dicts", "=", "dataset", "[", "'dicts'", "]", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "if", "dict_checkpoint", "else", "opt", "\n", "if", "dicts", ".", "get", "(", "'tgt'", ",", "None", ")", "is", "None", ":", "\n", "# Makes the code compatible with the language model", "\n", "        ", "dicts", "[", "'tgt'", "]", "=", "dicts", "[", "'src'", "]", "\n", "", "if", "opt", ".", "model_type", "==", "'nmt'", ":", "\n", "        ", "print", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "dicts", "[", "'src'", "]", ".", "size", "(", ")", ",", "dicts", "[", "'tgt'", "]", ".", "size", "(", ")", ")", ")", "\n", "", "elif", "opt", ".", "model_type", "==", "'lm'", ":", "\n", "        ", "print", "(", "' * vocabulary size = %d'", "%", "\n", "(", "dicts", "[", "'src'", "]", ".", "size", "(", ")", ")", ")", "\n", "", "print", "(", "' * number of training sentences. %d'", "%", "\n", "len", "(", "dataset", "[", "'train'", "]", "[", "'src'", "]", ")", ")", "\n", "print", "(", "' * maximum batch size. %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "print", "(", "'Building model...'", ")", "\n", "\n", "if", "opt", ".", "model_type", "==", "'nmt'", ":", "\n", "\n", "        ", "decoder", "=", "onmt", ".", "Decoders", ".", "getDecoder", "(", "model_opt", ".", "decoder_type", ")", "(", "model_opt", ",", "dicts", "[", "'tgt'", "]", ")", "\n", "encoder", "=", "onmt", ".", "Encoders", ".", "getEncoder", "(", "model_opt", ".", "encoder_type", ")", "(", "model_opt", ",", "dicts", "[", "'src'", "]", ")", "\n", "\n", "model", "=", "onmt", ".", "Models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "\n", "", "elif", "opt", ".", "model_type", "==", "'lm'", ":", "\n", "        ", "model", "=", "onmt", ".", "LanguageModel", ".", "LM", "(", "model_opt", ",", "dicts", "[", "'src'", "]", ")", "\n", "\n", "", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "dicts", "[", "'tgt'", "]", ".", "size", "(", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", ")", ")", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading model from checkpoint at %s'", "%", "opt", ".", "train_from", ")", "\n", "chk_model", "=", "checkpoint", "[", "'model'", "]", "\n", "generator_state_dict", "=", "chk_model", ".", "generator", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "chk_model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "model", ".", "load_state_dict", "(", "model_state_dict", ")", "\n", "generator", ".", "load_state_dict", "(", "generator_state_dict", ")", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "\n", "", "if", "opt", ".", "train_from_state_dict", ":", "\n", "        ", "print", "(", "'Loading model from state_dict at %s'", "\n", "%", "opt", ".", "train_from_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "model_opt", ".", "start_epoch", "=", "opt", ".", "start_epoch", "\n", "model_opt", ".", "epochs", "=", "opt", ".", "epochs", "\n", "\n", "", "if", "len", "(", "opt", ".", "gpus", ")", ">=", "1", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "generator", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "cpu", "(", ")", "\n", "generator", ".", "cpu", "(", ")", "\n", "\n", "", "if", "len", "(", "opt", ".", "gpus", ")", ">", "1", ":", "\n", "        ", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "opt", ".", "gpus", ",", "dim", "=", "1", ")", "\n", "generator", "=", "nn", ".", "DataParallel", "(", "generator", ",", "device_ids", "=", "opt", ".", "gpus", ",", "dim", "=", "0", ")", "\n", "model_opt", "[", "\"gpus\"", "]", "=", "opt", ".", "gpus", "\n", "\n", "", "model", ".", "generator", "=", "generator", "\n", "\n", "if", "not", "opt", ".", "train_from_state_dict", "and", "not", "opt", ".", "train_from", ":", "\n", "        ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "#p.data.uniform_(-opt.param_init, opt.param_init)", "\n", "            ", "if", "len", "(", "p", ".", "data", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "init", ".", "xavier_normal", "(", "p", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "opt", ".", "param_init", ",", "opt", ".", "param_init", ")", "\n", "", "", "model", ".", "initialize_parameters", "(", "opt", ".", "param_init", ")", "\n", "model", ".", "load_pretrained_vectors", "(", "opt", ")", "\n", "\n", "", "if", "(", "not", "opt", ".", "train_from_state_dict", "and", "not", "opt", ".", "train_from", ")", "or", "opt", ".", "change_optimizer", ":", "\n", "        ", "optim", "=", "onmt", ".", "Optim", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", "\n", ")", "\n", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "model_opt", ".", "learning_rate", "=", "opt", ".", "learning_rate", "\n", "model_opt", ".", "learning_rate_decay", "=", "opt", ".", "learning_rate_decay", "\n", "model_opt", ".", "save_each", "=", "opt", ".", "save_each", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint:'", ")", "\n", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "'optim'", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "", "nParams", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'* number of parameters: %d'", "%", "nParams", ")", "\n", "\n", "if", "opt", ".", "train_from", "or", "opt", ".", "train_from_state_dict", ":", "\n", "        ", "print", "(", "model_opt", ")", "\n", "\n", "", "model_opt", ".", "use_learning_rate_decay", "=", "opt", ".", "use_learning_rate_decay", "\n", "trainModel", "(", "model", ",", "trainData", ",", "validData", ",", "dataset", ",", "optim", ",", "model_opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.loadImageLibs": [[7, 12], ["None"], "function", ["None"], ["def", "loadImageLibs", "(", ")", ":", "\n", "    ", "\"Conditional import of torch image libs.\"", "\n", "global", "Image", ",", "transforms", "\n", "from", "PIL", "import", "Image", "\n", "from", "torchvision", "import", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeVocabulary": [[79, 95], ["onmt.Dict", "onmt.Dict", "vocab.prune.size", "vocab.prune.prune", "print", "open", "f.readlines", "sent.split", "vocab.prune.add", "vocab.prune.size"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.prune", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.add", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["def", "makeVocabulary", "(", "filename", ",", "size", ")", ":", "\n", "    ", "vocab", "=", "onmt", ".", "Dict", "(", "[", "onmt", ".", "Constants", ".", "PAD_WORD", ",", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "onmt", ".", "Constants", ".", "EOS_WORD", "]", ",", "\n", "lower", "=", "opt", ".", "lower", ")", "\n", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "sent", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "for", "word", "in", "sent", ".", "split", "(", ")", ":", "\n", "                ", "vocab", ".", "add", "(", "word", ")", "\n", "\n", "", "", "", "originalSize", "=", "vocab", ".", "size", "(", ")", "\n", "vocab", "=", "vocab", ".", "prune", "(", "size", ")", "\n", "print", "(", "'Created dictionary of size %d (pruned from %d)'", "%", "\n", "(", "vocab", ".", "size", "(", ")", ",", "originalSize", ")", ")", "\n", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.initVocabulary": [[97, 116], ["print", "print", "onmt.Dict", "onmt.Dict", "onmt.Dict.loadFile", "print", "print", "preprocess.makeVocabulary", "str", "onmt.Dict.size"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.loadFile", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeVocabulary", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "initVocabulary", "(", "name", ",", "dataFile", ",", "vocabFile", ",", "vocabSize", ")", ":", "\n", "\n", "    ", "vocab", "=", "None", "\n", "if", "vocabFile", "is", "not", "None", ":", "\n", "# If given, load existing word dictionary.", "\n", "        ", "print", "(", "'Reading '", "+", "name", "+", "' vocabulary from \\''", "+", "vocabFile", "+", "'\\'...'", ")", "\n", "vocab", "=", "onmt", ".", "Dict", "(", ")", "\n", "vocab", ".", "loadFile", "(", "vocabFile", ")", "\n", "print", "(", "'Loaded '", "+", "str", "(", "vocab", ".", "size", "(", ")", ")", "+", "' '", "+", "name", "+", "' words'", ")", "\n", "\n", "", "if", "vocab", "is", "None", ":", "\n", "# If a dictionary is still missing, generate it.", "\n", "        ", "print", "(", "'Building '", "+", "name", "+", "' vocabulary...'", ")", "\n", "genWordVocab", "=", "makeVocabulary", "(", "dataFile", ",", "vocabSize", ")", "\n", "\n", "vocab", "=", "genWordVocab", "\n", "\n", "", "print", "(", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.saveVocabulary": [[118, 121], ["print", "vocab.writeFile"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.writeFile"], ["", "def", "saveVocabulary", "(", "name", ",", "vocab", ",", "file", ")", ":", "\n", "    ", "print", "(", "'Saving '", "+", "name", "+", "' vocabulary to \\''", "+", "file", "+", "'\\'...'", ")", "\n", "vocab", ".", "writeFile", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeBilingualData": [[123, 206], ["print", "open", "open", "open.close", "open.close", "print", "torch.sort", "print", "open.readline", "open.readline", "sline.strip.strip", "tline.strip.strip", "sline.strip.split", "tline.strip.split", "print", "torch.randperm", "torch.Tensor", "print", "print", "print", "len", "len", "len", "tgtDicts.convertToIdx", "len", "len", "srcDicts.convertToIdx", "preprocess.loadImageLibs", "str", "transforms.ToTensor", "Image.open"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToIdx", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToIdx", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.loadImageLibs"], ["", "def", "makeBilingualData", "(", "srcFile", ",", "tgtFile", ",", "srcDicts", ",", "tgtDicts", ")", ":", "\n", "    ", "src", ",", "tgt", "=", "[", "]", ",", "[", "]", "\n", "sizes", "=", "[", "]", "\n", "count", ",", "ignored", "=", "0", ",", "0", "\n", "\n", "print", "(", "'Processing %s & %s ...'", "%", "(", "srcFile", ",", "tgtFile", ")", ")", "\n", "srcF", "=", "open", "(", "srcFile", ")", "\n", "tgtF", "=", "open", "(", "tgtFile", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "sline", "=", "srcF", ".", "readline", "(", ")", "\n", "tline", "=", "tgtF", ".", "readline", "(", ")", "\n", "\n", "# normal end of file", "\n", "if", "sline", "==", "\"\"", "and", "tline", "==", "\"\"", ":", "\n", "            ", "break", "\n", "\n", "# source or target does not have same number of lines", "\n", "", "if", "sline", "==", "\"\"", "or", "tline", "==", "\"\"", ":", "\n", "            ", "print", "(", "'WARNING: src and tgt do not have the same # of sentences'", ")", "\n", "break", "\n", "\n", "", "sline", "=", "sline", ".", "strip", "(", ")", "\n", "tline", "=", "tline", ".", "strip", "(", ")", "\n", "\n", "# source and/or target are empty", "\n", "if", "sline", "==", "\"\"", "or", "tline", "==", "\"\"", ":", "\n", "            ", "print", "(", "'WARNING: ignoring an empty line ('", "+", "str", "(", "count", "+", "1", ")", "+", "')'", ")", "\n", "continue", "\n", "\n", "", "srcWords", "=", "sline", ".", "split", "(", ")", "\n", "tgtWords", "=", "tline", ".", "split", "(", ")", "\n", "\n", "if", "len", "(", "srcWords", ")", "<=", "opt", ".", "src_seq_length", "and", "len", "(", "tgtWords", ")", "<=", "opt", ".", "tgt_seq_length", ":", "\n", "\n", "# Check truncation condition.", "\n", "            ", "if", "opt", ".", "src_seq_length_trunc", "!=", "0", ":", "\n", "                ", "srcWords", "=", "srcWords", "[", ":", "opt", ".", "src_seq_length_trunc", "]", "\n", "", "if", "opt", ".", "tgt_seq_length_trunc", "!=", "0", ":", "\n", "                ", "tgtWords", "=", "tgtWords", "[", ":", "opt", ".", "tgt_seq_length_trunc", "]", "\n", "\n", "", "if", "opt", ".", "src_type", "==", "\"bitext\"", ":", "\n", "                ", "src", "+=", "[", "srcDicts", ".", "convertToIdx", "(", "srcWords", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ")", "]", "\n", "", "elif", "opt", ".", "src_type", "==", "\"img\"", ":", "\n", "                ", "loadImageLibs", "(", ")", "\n", "src", "+=", "[", "transforms", ".", "ToTensor", "(", ")", "(", "\n", "Image", ".", "open", "(", "opt", ".", "src_img_dir", "+", "\"/\"", "+", "srcWords", "[", "0", "]", ")", ")", "]", "\n", "\n", "", "tgt", "+=", "[", "tgtDicts", ".", "convertToIdx", "(", "tgtWords", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "\n", "onmt", ".", "Constants", ".", "EOS_WORD", ")", "]", "\n", "sizes", "+=", "[", "len", "(", "srcWords", ")", "]", "\n", "", "else", ":", "\n", "            ", "ignored", "+=", "1", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "if", "count", "%", "opt", ".", "report_every", "==", "0", ":", "\n", "            ", "print", "(", "'... %d sentences prepared'", "%", "count", ")", "\n", "\n", "", "", "srcF", ".", "close", "(", ")", "\n", "tgtF", ".", "close", "(", ")", "\n", "\n", "if", "opt", ".", "shuffle", "==", "1", ":", "\n", "        ", "print", "(", "'... shuffling sentences'", ")", "\n", "perm", "=", "torch", ".", "randperm", "(", "len", "(", "src", ")", ")", "\n", "src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "tgt", "=", "[", "tgt", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "sizes", "=", "[", "sizes", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "\n", "", "print", "(", "'... sorting sentences by size'", ")", "\n", "_", ",", "perm", "=", "torch", ".", "sort", "(", "torch", ".", "Tensor", "(", "sizes", ")", ")", "\n", "src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "tgt", "=", "[", "tgt", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "\n", "print", "(", "(", "'Prepared %d sentences '", "+", "\n", "'(%d ignored due to length == 0 or src len > %d or tgt len > %d)'", ")", "%", "\n", "(", "len", "(", "src", ")", ",", "ignored", ",", "opt", ".", "src_seq_length", ",", "opt", ".", "tgt_seq_length", ")", ")", "\n", "\n", "return", "src", ",", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeMonolingualData": [[208, 260], ["print", "print", "torch.sort", "print", "open", "print", "torch.randperm", "torch.Tensor", "sline.strip.strip", "sline.strip.split", "len", "print", "len", "print", "len", "srcDicts.convertToIdx", "len", "str"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToIdx"], ["", "def", "makeMonolingualData", "(", "srcFile", ",", "srcDicts", ")", ":", "\n", "    ", "src", "=", "[", "]", "\n", "sizes", "=", "[", "]", "\n", "count", ",", "ignored", "=", "0", ",", "0", "\n", "\n", "print", "(", "'Processing %s ...'", "%", "(", "srcFile", ")", ")", "\n", "\n", "with", "open", "(", "srcFile", ")", "as", "srcF", ":", "\n", "        ", "for", "sline", "in", "srcF", ":", "\n", "            ", "sline", "=", "sline", ".", "strip", "(", ")", "\n", "\n", "# source and/or target are empty", "\n", "if", "sline", "==", "\"\"", ":", "\n", "                ", "print", "(", "'WARNING: ignoring an empty line ('", "+", "str", "(", "count", "+", "1", ")", "+", "')'", ")", "\n", "continue", "\n", "\n", "", "srcWords", "=", "sline", ".", "split", "(", ")", "\n", "\n", "if", "len", "(", "srcWords", ")", "<=", "opt", ".", "src_seq_length", ":", "\n", "\n", "# Check truncation condition.LGRU_model_1layers_acc_54.83_ppl_12.43_e1.pt", "\n", "                ", "if", "opt", ".", "src_seq_length_trunc", "!=", "0", ":", "\n", "                    ", "srcWords", "=", "srcWords", "[", ":", "opt", ".", "src_seq_length_trunc", "]", "\n", "\n", "", "src", "+=", "[", "srcDicts", ".", "convertToIdx", "(", "srcWords", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "\n", "onmt", ".", "Constants", ".", "EOS_WORD", ")", "]", "\n", "sizes", "+=", "[", "len", "(", "srcWords", ")", "]", "\n", "", "else", ":", "\n", "                ", "ignored", "+=", "1", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "if", "count", "%", "opt", ".", "report_every", "==", "0", ":", "\n", "                ", "print", "(", "'... %d sentences prepared'", "%", "count", ")", "\n", "\n", "", "", "", "if", "opt", ".", "shuffle", "==", "1", ":", "\n", "        ", "print", "(", "'... shuffling sentences'", ")", "\n", "perm", "=", "torch", ".", "randperm", "(", "len", "(", "src", ")", ")", "\n", "src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "sizes", "=", "[", "sizes", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "\n", "", "print", "(", "'... sorting sentences by size'", ")", "\n", "_", ",", "perm", "=", "torch", ".", "sort", "(", "torch", ".", "Tensor", "(", "sizes", ")", ")", "\n", "src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "\n", "print", "(", "(", "'Prepared %d sentences '", "+", "\n", "'(%d ignored due to length == 0 or src len > %d)'", ")", "%", "\n", "(", "len", "(", "src", ")", ",", "ignored", ",", "opt", ".", "src_seq_length", ")", ")", "\n", "\n", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.main": [[262, 326], ["onmt.Dict", "onmt.Dict", "print", "print", "torch.save", "preprocess.initVocabulary", "preprocess.initVocabulary", "preprocess.makeBilingualData", "print", "preprocess.makeBilingualData", "preprocess.saveVocabulary", "preprocess.saveVocabulary", "preprocess.initVocabulary", "preprocess.makeMonolingualData", "print", "preprocess.makeMonolingualData", "preprocess.initVocabulary"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeBilingualData", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeBilingualData", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.saveVocabulary", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.saveVocabulary", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeMonolingualData", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.makeMonolingualData", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.preprocess.initVocabulary"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "if", "opt", ".", "src_type", "in", "[", "'bitext'", ",", "'img'", "]", ":", "\n", "        ", "assert", "None", "not", "in", "[", "opt", ".", "train_src", ",", "opt", ".", "train_tgt", ",", "\n", "opt", ".", "valid_src", ",", "opt", ".", "valid_tgt", "]", ",", "\"With source type %s the following parameters are\"", "\"required: -train_src, -train_tgt, \"", "\"-valid_src, -valid_tgt\"", "%", "(", "opt", ".", "src_type", ")", "\n", "\n", "", "elif", "opt", ".", "src_type", "==", "'monotext'", ":", "\n", "        ", "assert", "None", "not", "in", "[", "opt", ".", "train", ",", "opt", ".", "valid", "]", ",", "\"With source type monotext the following \"", "\"parameters are required: -train, -valid\"", "\n", "\n", "", "dicts", "=", "{", "}", "\n", "dicts", "[", "'src'", "]", "=", "onmt", ".", "Dict", "(", ")", "\n", "if", "opt", ".", "src_type", "==", "'bitext'", ":", "\n", "        ", "dicts", "[", "'src'", "]", "=", "initVocabulary", "(", "'source'", ",", "opt", ".", "train_src", ",", "opt", ".", "src_vocab", ",", "\n", "opt", ".", "src_vocab_size", ")", "\n", "dicts", "[", "'tgt'", "]", "=", "initVocabulary", "(", "'target'", ",", "opt", ".", "train_tgt", ",", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ")", "\n", "\n", "", "elif", "opt", ".", "src_type", "==", "'monotext'", ":", "\n", "        ", "dicts", "[", "'src'", "]", "=", "initVocabulary", "(", "'source'", ",", "opt", ".", "train", ",", "opt", ".", "src_vocab", ",", "\n", "opt", ".", "src_vocab_size", ")", "\n", "\n", "", "elif", "opt", ".", "src_type", "==", "'img'", ":", "\n", "        ", "dicts", "[", "'tgt'", "]", "=", "initVocabulary", "(", "'target'", ",", "opt", ".", "train_tgt", ",", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ")", "\n", "\n", "", "print", "(", "'Preparing training ...'", ")", "\n", "train", "=", "{", "}", "\n", "valid", "=", "{", "}", "\n", "\n", "if", "opt", ".", "src_type", "in", "[", "'bitext'", ",", "'img'", "]", ":", "\n", "        ", "train", "[", "'src'", "]", ",", "train", "[", "'tgt'", "]", "=", "makeBilingualData", "(", "opt", ".", "train_src", ",", "\n", "opt", ".", "train_tgt", ",", "\n", "dicts", "[", "'src'", "]", ",", "\n", "dicts", "[", "'tgt'", "]", ")", "\n", "\n", "print", "(", "'Preparing validation ...'", ")", "\n", "valid", "[", "'src'", "]", ",", "valid", "[", "'tgt'", "]", "=", "makeBilingualData", "(", "opt", ".", "valid_src", ",", "\n", "opt", ".", "valid_tgt", ",", "\n", "dicts", "[", "'src'", "]", ",", "\n", "dicts", "[", "'tgt'", "]", ")", "\n", "\n", "", "elif", "opt", ".", "src_type", "==", "'monotext'", ":", "\n", "        ", "train", "[", "'src'", "]", "=", "makeMonolingualData", "(", "opt", ".", "train", ",", "dicts", "[", "'src'", "]", ")", "\n", "train", "[", "'tgt'", "]", "=", "train", "[", "'src'", "]", "# Keeps compatibility with bilingual code", "\n", "print", "(", "'Preparing validation ...'", ")", "\n", "valid", "[", "'src'", "]", "=", "makeMonolingualData", "(", "opt", ".", "valid", ",", "dicts", "[", "'src'", "]", ")", "\n", "valid", "[", "'tgt'", "]", "=", "valid", "[", "'src'", "]", "\n", "\n", "", "if", "opt", ".", "src_vocab", "is", "None", ":", "\n", "        ", "saveVocabulary", "(", "'source'", ",", "dicts", "[", "'src'", "]", ",", "opt", ".", "save_data", "+", "'.src.dict'", ")", "\n", "", "if", "opt", ".", "src_type", "in", "[", "'bitext'", ",", "'img'", "]", "and", "opt", ".", "tgt_vocab", "is", "None", ":", "\n", "        ", "saveVocabulary", "(", "'target'", ",", "dicts", "[", "'tgt'", "]", ",", "opt", ".", "save_data", "+", "'.tgt.dict'", ")", "\n", "\n", "", "print", "(", "'Saving data to \\''", "+", "opt", ".", "save_data", "+", "'.train.pt\\'...'", ")", "\n", "save_data", "=", "{", "'dicts'", ":", "dicts", ",", "\n", "'type'", ":", "opt", ".", "src_type", ",", "\n", "'train'", ":", "train", ",", "\n", "'valid'", ":", "valid", "}", "\n", "torch", ".", "save", "(", "save_data", ",", "opt", ".", "save_data", "+", "'.train.pt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.test.test_simple.test_load": [[4, 7], ["None"], "function", ["None"], ["def", "test_load", "(", ")", ":", "\n", "    ", "onmt", "\n", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.Encoder.__init__": [[24, 47], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "dicts.size", "Encoders.Encoder.__init__.getunittype"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "\n", "        ", "def", "getunittype", "(", "rnn_type", ")", ":", "\n", "            ", "if", "rnn_type", "in", "[", "'LSTM'", ",", "'GRU'", "]", ":", "\n", "                ", "return", "getattr", "(", "nn", ",", "rnn_type", ")", "\n", "", "elif", "rnn_type", "==", "'SRU'", ":", "\n", "                ", "return", "ParallelMyRNN", "\n", "\n", "", "", "self", ".", "layers", "=", "opt", ".", "layers_enc", "\n", "self", ".", "num_directions", "=", "2", "if", "opt", ".", "brnn", "else", "1", "\n", "assert", "opt", ".", "rnn_size", "%", "self", ".", "num_directions", "==", "0", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "//", "self", ".", "num_directions", "\n", "\n", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "\n", "rnn_type", "=", "opt", ".", "rnn_encoder_type", "if", "opt", ".", "rnn_encoder_type", "else", "opt", ".", "rnn_type", "\n", "self", ".", "rnn", "=", "getunittype", "(", "rnn_type", ")", "(", "\n", "opt", ".", "word_vec_size", ",", "self", ".", "hidden_size", ",", "\n", "num_layers", "=", "opt", ".", "layers_enc", ",", "dropout", "=", "opt", ".", "dropout", ",", "\n", "bidirectional", "=", "opt", ".", "brnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.Encoder.load_pretrained_vectors": [[48, 52], ["torch.load", "torch.load", "torch.load", "torch.load", "Encoders.Encoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "pre_word_vecs_enc", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_enc", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.Encoder.initialize_parameters": [[53, 56], ["hasattr", "Encoders.Encoder.rnn.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "rnn", ",", "'initialize_parameters'", ")", ":", "\n", "            ", "self", ".", "rnn", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.Encoder.forward": [[57, 70], ["isinstance", "Encoders.Encoder.rnn", "isinstance", "input[].data.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Encoders.Encoder.word_lut", "Encoders.Encoder.word_lut", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "input[].data.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", "=", "None", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "# Lengths data is wrapped inside a Variable.", "\n", "            ", "lengths", "=", "input", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "emb", "=", "pack", "(", "self", ".", "word_lut", "(", "input", "[", "0", "]", ")", ",", "lengths", ")", "\n", "", "else", ":", "\n", "            ", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "emb", ",", "hidden", ")", "\n", "if", "isinstance", "(", "outputs", ",", "PackedSequence", ")", ":", "\n", "            ", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "", "return", "hidden_t", ",", "outputs", ",", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.StackedSGU.__init__": [[73, 81], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "range", "Encoders.StackedSGU.sgus.append", "modules.SRU_units.BiSRU"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "input_size", ",", "hidden_size", ",", "layer_norm", ",", "dropout", ")", ":", "\n", "        ", "self", ".", "layers", "=", "layers", "\n", "super", "(", "StackedSGU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sgus", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "sgus", ".", "append", "(", "BiSRU", "(", "input_size", ",", "hidden_size", ",", "layer_norm", ",", "dropout", ")", ")", "\n", "input_size", "=", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.StackedSGU.initialize_parameters": [[82, 85], ["sgu.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "for", "sgu", "in", "self", ".", "sgus", ":", "\n", "            ", "sgu", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.StackedSGU.forward": [[86, 93], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "\n", "        ", "hiddens", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "layers", ")", ":", "\n", "            ", "input", "=", "self", ".", "sgus", "[", "i", "]", "(", "input", ")", "\n", "hiddens", "+=", "[", "input", "[", "-", "1", "]", "]", "\n", "", "return", "input", ",", "torch", ".", "stack", "(", "hiddens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.SGUEncoder.__init__": [[96, 110], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "Encoders.StackedSGU", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers_enc", "\n", "self", ".", "num_directions", "=", "2", "if", "opt", ".", "brnn", "else", "1", "\n", "assert", "opt", ".", "rnn_size", "%", "self", ".", "num_directions", "==", "0", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "//", "self", ".", "num_directions", "\n", "\n", "super", "(", "SGUEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "self", ".", "sgu", "=", "StackedSGU", "(", "self", ".", "layers", ",", "opt", ".", "word_vec_size", ",", "\n", "self", ".", "hidden_size", "*", "self", ".", "num_directions", ",", "opt", ".", "layer_norm", ",", "\n", "opt", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.SGUEncoder.load_pretrained_vectors": [[112, 116], ["torch.load", "torch.load", "torch.load", "torch.load", "Encoders.SGUEncoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "pre_word_vecs_enc", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_enc", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.SGUEncoder.initialize_parameters": [[117, 119], ["Encoders.SGUEncoder.sgu.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "self", ".", "sgu", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.SGUEncoder.forward": [[120, 131], ["isinstance", "Encoders.SGUEncoder.sgu", "input[].data.view().tolist", "Encoders.SGUEncoder.word_lut", "Encoders.SGUEncoder.word_lut", "input[].data.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", "=", "None", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "# Lengths data is wrapped inside a Variable.", "\n", "            ", "lengths", "=", "input", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "emb", "=", "self", ".", "word_lut", "(", "input", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "", "outputs", ",", "hidden_t", "=", "self", ".", "sgu", "(", "emb", ")", "\n", "\n", "return", "hidden_t", ",", "outputs", ",", "emb", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder": [[14, 20], ["NotImplementedError"], "function", ["None"], ["def", "getEncoder", "(", "encoder_type", ")", ":", "\n", "    ", "encoders", "=", "{", "'RNN'", ":", "Encoder", ",", "\n", "'SR'", ":", "SGUEncoder", "}", "\n", "if", "encoder_type", "not", "in", "encoders", ":", "\n", "        ", "raise", "NotImplementedError", "(", "encoder_type", ")", "\n", "", "return", "encoders", "[", "encoder_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.__init__": [[8, 12], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.make_init_decoder_output": [[13, 17], ["context.size", "torch.autograd.Variable", "context.data.new().zero_", "context.data.new"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "make_init_decoder_output", "(", "self", ",", "context", ")", ":", "\n", "        ", "batch_size", "=", "context", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "self", ".", "decoder", ".", "hidden_size", ")", "\n", "return", "Variable", "(", "context", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.load_pretrained_vectors": [[18, 21], ["Models.NMTModel.encoder.load_pretrained_vectors", "Models.NMTModel.decoder.load_pretrained_vectors"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.ImageEncoder.ImageEncoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.ImageEncoder.ImageEncoder.load_pretrained_vectors"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_pretrained_vectors", "(", "opt", ")", "\n", "self", ".", "decoder", ".", "load_pretrained_vectors", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.initialize_parameters": [[22, 25], ["Models.NMTModel.encoder.initialize_parameters", "Models.NMTModel.decoder.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "initialize_parameters", "(", "param_init", ")", "\n", "self", ".", "decoder", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.brnn_merge_concat": [[26, 35], ["h.view().transpose().contiguous().view", "h.size", "h.view().transpose().contiguous", "h.size", "h.size", "h.view().transpose", "h.view", "h.size", "h.size", "h.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "brnn_merge_concat", "(", "self", ",", "h", ")", ":", "\n", "#  the encoder hidden is  (layers*directions) x batch x dim", "\n", "#  we need to convert it to layers x batch x (directions*dim)", "\n", "        ", "if", "self", ".", "encoder", ".", "num_directions", "==", "2", ":", "\n", "            ", "return", "h", ".", "view", "(", "h", ".", "size", "(", "0", ")", "//", "2", ",", "2", ",", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "h", ".", "size", "(", "0", ")", "//", "2", ",", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", "*", "2", ")", "\n", "", "else", ":", "\n", "            ", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.forward": [[36, 57], ["Models.NMTModel.encoder", "Models.NMTModel.make_init_decoder_output", "isinstance", "Models.NMTModel.decoder", "isinstance", "torch.autograd.Variable", "tuple", "Models.NMTModel.brnn_merge_concat", "enc_hidden.repeat.repeat.data.new().zero_", "enc_hidden.repeat.repeat.size", "enc_hidden.repeat.repeat.repeat", "Models.NMTModel.brnn_merge_concat", "enc_hidden.repeat.repeat.data.new", "range", "len", "enc_hidden.repeat.repeat.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.make_init_decoder_output", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.brnn_merge_concat", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.brnn_merge_concat", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "src", "=", "input", "[", "0", "]", "\n", "tgt", "=", "input", "[", "1", "]", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "enc_hidden", ",", "context", ",", "emb", "=", "self", ".", "encoder", "(", "src", ")", "\n", "init_output", "=", "self", ".", "make_init_decoder_output", "(", "context", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "encoder", ",", "Encoder", ")", ":", "\n", "            ", "if", "isinstance", "(", "enc_hidden", ",", "tuple", ")", ":", "\n", "                ", "enc_hidden", "=", "tuple", "(", "self", ".", "brnn_merge_concat", "(", "enc_hidden", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "enc_hidden", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "enc_hidden", "=", "self", ".", "brnn_merge_concat", "(", "enc_hidden", ")", "\n", "if", "enc_hidden", ".", "size", "(", "0", ")", "<", "self", ".", "decoder", ".", "layers", ":", "\n", "                    ", "enc_hidden", "=", "enc_hidden", ".", "repeat", "(", "self", ".", "decoder", ".", "layers", ",", "1", ",", "1", ")", "\n", "", "", "", "else", ":", "\n", "            ", "enc_hidden", "=", "Variable", "(", "enc_hidden", ".", "data", ".", "new", "(", "*", "enc_hidden", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "#self.decoder.mask_attention(src[0])", "\n", "", "out", ",", "dec_hidden", ",", "_attn", "=", "self", ".", "decoder", "(", "tgt", ",", "enc_hidden", ",", "\n", "context", ",", "init_output", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.__init__": [[23, 67], ["torch.load", "torch.load", "torch.load", "torch.load", "print", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "onmt.Models.NMTModel", "torch.Sequential", "torch.Sequential", "onmt.Models.NMTModel.load_state_dict", "onmt.Models.NMTModel.load_state_dict", "onmt.Models.NMTModel.load_state_dict", "torch.Sequential.load_state_dict", "Translator.Translator.model.eval", "Encoders.getEncoder", "Decoders.getDecoder", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "onmt.Models.NMTModel.cuda", "onmt.Models.NMTModel.cuda", "onmt.Models.NMTModel.cuda", "torch.Sequential.cuda", "onmt.Models.NMTModel.cpu", "onmt.Models.NMTModel.cpu", "onmt.Models.NMTModel.cpu", "torch.Sequential.cpu", "Translator.Translator.tgt_dict.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.None.train.eval", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Encoders.getEncoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "opt", ".", "cuda", "else", "torch", "\n", "self", ".", "beam_accum", "=", "None", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "src_dict", "=", "checkpoint", "[", "'dicts'", "]", "[", "'src'", "]", "\n", "self", ".", "tgt_dict", "=", "checkpoint", "[", "'dicts'", "]", "[", "'tgt'", "]", "\n", "self", ".", "_type", "=", "\"text\"", "#model_opt.encoder_type \\", "\n", "#if \"encoder_type\" in model_opt else \"text\"", "\n", "\n", "#if self._type == \"text\":", "\n", "#    encoder = Encoder(model_opt, self.src_dict)", "\n", "#elif self._type == \"img\":", "\n", "#    loadImageLibs()", "\n", "#    encoder = onmt.modules.ImageEncoder(model_opt)", "\n", "print", "(", "\"Translator layer_norm:\"", ",", "model_opt", ".", "layer_norm", ")", "\n", "\n", "encoder", "=", "getEncoder", "(", "model_opt", ".", "encoder_type", ")", "(", "model_opt", ",", "self", ".", "src_dict", ")", "\n", "decoder", "=", "getDecoder", "(", "model_opt", ".", "decoder_type", ")", "(", "model_opt", ",", "self", ".", "tgt_dict", ")", "\n", "model", "=", "onmt", ".", "Models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "\n", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "self", ".", "tgt_dict", ".", "size", "(", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", ")", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "\n", "if", "opt", ".", "cuda", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "generator", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "cpu", "(", ")", "\n", "generator", ".", "cpu", "(", ")", "\n", "\n", "", "model", ".", "generator", "=", "generator", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.initBeamAccum": [[68, 74], ["None"], "methods", ["None"], ["", "def", "initBeamAccum", "(", "self", ")", ":", "\n", "        ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator._getBatchSize": [[75, 80], ["batch.size", "batch.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "_getBatchSize", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "self", ".", "_type", "==", "\"text\"", ":", "\n", "            ", "return", "batch", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "batch", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.buildData": [[81, 102], ["onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "Translator.Translator.src_dict.convertToIdx", "Translator.Translator.tgt_dict.convertToIdx", "transforms.ToTensor", "Image.open"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToIdx", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToIdx"], ["", "", "def", "buildData", "(", "self", ",", "srcBatch", ",", "goldBatch", ")", ":", "\n", "# This needs to be the same as preprocess.py.", "\n", "        ", "if", "self", ".", "_type", "==", "\"text\"", ":", "\n", "            ", "srcData", "=", "[", "self", ".", "src_dict", ".", "convertToIdx", "(", "b", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ")", "\n", "for", "b", "in", "srcBatch", "]", "\n", "", "elif", "self", ".", "_type", "==", "\"img\"", ":", "\n", "            ", "srcData", "=", "[", "transforms", ".", "ToTensor", "(", ")", "(", "\n", "Image", ".", "open", "(", "self", ".", "opt", ".", "src_img_dir", "+", "\"/\"", "+", "b", "[", "0", "]", ")", ")", "\n", "for", "b", "in", "srcBatch", "]", "\n", "\n", "", "tgtData", "=", "None", "\n", "if", "goldBatch", ":", "\n", "            ", "tgtData", "=", "[", "self", ".", "tgt_dict", ".", "convertToIdx", "(", "b", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "\n", "onmt", ".", "Constants", ".", "EOS_WORD", ")", "for", "b", "in", "goldBatch", "]", "\n", "\n", "", "return", "onmt", ".", "Dataset", "(", "srcData", ",", "tgtData", ",", "self", ".", "opt", ".", "batch_size", ",", "\n", "self", ".", "opt", ".", "cuda", ",", "volatile", "=", "True", ",", "\n", "data_type", "=", "self", ".", "_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.buildTargetTokens": [[103, 112], ["Translator.Translator.tgt_dict.convertToLabels", "range", "len", "attn[].max"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToLabels"], ["", "def", "buildTargetTokens", "(", "self", ",", "pred", ",", "src", ",", "attn", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "tgt_dict", ".", "convertToLabels", "(", "pred", ",", "onmt", ".", "Constants", ".", "EOS", ")", "\n", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "# EOS", "\n", "if", "self", ".", "opt", ".", "replace_unk", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "onmt", ".", "Constants", ".", "UNK_WORD", ":", "\n", "                    ", "_", ",", "maxIndex", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src", "[", "maxIndex", "[", "0", "]", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.translateBatch": [[113, 325], ["Translator.Translator.model.encoder", "Translator.Translator._getBatchSize", "updateActive.size", "isinstance", "updateActive.data.new().zero_", "torch.autograd.Variable", "torch.autograd.Variable", "isinstance", "isinstance", "Translator.Translator.model.make_init_decoder_output", "list", "range", "range", "hasattr", "isinstance", "torch.autograd.Variable", "torch.autograd.Variable", "isinstance", "srcBatch.data.eq().t", "Translator.Translator.translateBatch.mask"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator._getBatchSize", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Models.NMTModel.make_init_decoder_output"], ["", "def", "translateBatch", "(", "self", ",", "srcBatch", ",", "tgtBatch", ")", ":", "\n", "# Batch size is in different location depending on data.", "\n", "\n", "        ", "beamSize", "=", "self", ".", "opt", ".", "beam_size", "\n", "\n", "#  (1) run the encoder on the src", "\n", "encStates", ",", "context", ",", "emb", "=", "self", ".", "model", ".", "encoder", "(", "srcBatch", ")", "\n", "\n", "# Drop the lengths needed for encoder.", "\n", "srcBatch", "=", "srcBatch", "[", "0", "]", "\n", "batchSize", "=", "self", ".", "_getBatchSize", "(", "srcBatch", ")", "\n", "\n", "rnnSize", "=", "context", ".", "size", "(", "2", ")", "\n", "decoder", "=", "self", ".", "model", ".", "decoder", "\n", "attentionLayer", "=", "decoder", ".", "attn", "if", "hasattr", "(", "decoder", ",", "'attn'", ")", "else", "None", "\n", "\n", "if", "isinstance", "(", "self", ".", "model", ".", "encoder", ",", "Encoder", ")", ":", "\n", "            ", "if", "isinstance", "(", "encStates", ",", "tuple", ")", ":", "\n", "                ", "encStates", "=", "tuple", "(", "self", ".", "model", ".", "brnn_merge_concat", "(", "encStates", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "encStates", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "encStates", "=", "self", ".", "model", ".", "brnn_merge_concat", "(", "encStates", ")", "\n", "if", "encStates", ".", "size", "(", "0", ")", "<", "decoder", ".", "layers", ":", "\n", "                    ", "encStates", "=", "encStates", ".", "repeat", "(", "decoder", ".", "layers", ",", "1", ",", "1", ")", "\n", "", "", "", "else", ":", "\n", "            ", "encStates", "=", "Variable", "(", "encStates", ".", "data", ".", "new", "(", "*", "encStates", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "#    encStates = encStates.unsqueeze(0).repeat(decoder.layers, 1, 1)", "\n", "\n", "\n", "", "useMasking", "=", "not", "isinstance", "(", "decoder", ",", "SGUDecoder", ")", "#self._type.endswith(\"text\")", "\n", "\n", "#  This mask is applied to the attention model inside the decoder", "\n", "#  so that the attention ignores source padding", "\n", "padMask", "=", "None", "\n", "if", "useMasking", ":", "\n", "            ", "padMask", "=", "srcBatch", ".", "data", ".", "eq", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", "\n", "\n", "", "def", "mask", "(", "padMask", ")", ":", "\n", "            ", "if", "useMasking", ":", "\n", "                ", "attentionLayer", ".", "applyMask", "(", "padMask", ")", "\n", "\n", "#  (2) if a target is specified, compute the 'goldScore'", "\n", "#  (i.e. log likelihood) of the target under the model", "\n", "", "", "goldScores", "=", "context", ".", "data", ".", "new", "(", "batchSize", ")", ".", "zero_", "(", ")", "\n", "\n", "if", "tgtBatch", "is", "not", "None", ":", "\n", "\n", "            ", "decStates", "=", "encStates", "\n", "\n", "mask", "(", "padMask", ")", "\n", "initOutput", "=", "self", ".", "model", ".", "make_init_decoder_output", "(", "context", ")", "\n", "\n", "decOut", ",", "decStates", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "tgtBatch", "[", ":", "-", "1", "]", ",", "decStates", ",", "context", ",", "initOutput", ")", "\n", "for", "dec_t", ",", "tgt_t", "in", "zip", "(", "decOut", ",", "tgtBatch", "[", "1", ":", "]", ".", "data", ")", ":", "\n", "                ", "gen_t", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_t", ")", "\n", "tgt_t", "=", "tgt_t", ".", "unsqueeze", "(", "1", ")", "\n", "scores", "=", "gen_t", ".", "data", ".", "gather", "(", "1", ",", "tgt_t", ")", "\n", "scores", ".", "masked_fill_", "(", "tgt_t", ".", "eq", "(", "onmt", ".", "Constants", ".", "PAD", ")", ",", "0", ")", "\n", "goldScores", "+=", "scores", "\n", "\n", "#  (3) run the decoder to generate sentences, using beam search", "\n", "\n", "# Expand tensors for each beam.", "\n", "", "", "context", "=", "Variable", "(", "context", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", "\n", "if", "isinstance", "(", "emb", ",", "PackedSequence", ")", ":", "\n", "            ", "emb", "=", "Variable", "(", "unpack", "(", "emb", ")", "[", "0", "]", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "emb", "=", "Variable", "(", "emb", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "encStates", ",", "tuple", ")", ":", "\n", "            ", "decStates", "=", "tuple", "(", "Variable", "(", "encStates", "[", "i", "]", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "encStates", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "decStates", "=", "Variable", "(", "encStates", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", "\n", "\n", "", "beam", "=", "[", "onmt", ".", "Beam", "(", "beamSize", ",", "self", ".", "opt", ".", "cuda", ")", "for", "_", "in", "range", "(", "batchSize", ")", "]", "\n", "\n", "decOut", "=", "self", ".", "model", ".", "make_init_decoder_output", "(", "context", ")", "\n", "\n", "if", "useMasking", ":", "\n", "            ", "padMask", "=", "srcBatch", ".", "data", ".", "eq", "(", "\n", "onmt", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "beamSize", ",", "1", ",", "1", ")", "\n", "\n", "", "batchIdx", "=", "list", "(", "range", "(", "batchSize", ")", ")", "\n", "remainingSents", "=", "batchSize", "\n", "\n", "activs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "opt", ".", "max_sent_length", ")", ":", "\n", "            ", "mask", "(", "padMask", ")", "\n", "# Prepare decoder input.", "\n", "input", "=", "torch", ".", "stack", "(", "[", "b", ".", "getCurrentState", "(", ")", "for", "b", "in", "beam", "\n", "if", "not", "b", ".", "done", "]", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "#if self.model.decoder.log:", "\n", "#    decOut, decStates, attn, activ = self.model.decoder(", "\n", "#        Variable(input, volatile=True), decStates, context, decOut, emb)", "\n", "#    activs.append(activ)", "\n", "#else:", "\n", "decOut", ",", "decStates", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "Variable", "(", "input", ",", "volatile", "=", "True", ")", ",", "decStates", ",", "context", ",", "decOut", ")", "\n", "\n", "# decOut: 1 x (beam*batch) x numWords", "\n", "decOut", "=", "decOut", ".", "squeeze", "(", "0", ")", "\n", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "decOut", ")", "\n", "\n", "# batch x beam x numWords", "\n", "wordLk", "=", "out", ".", "view", "(", "beamSize", ",", "remainingSents", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "attn", "=", "attn", ".", "view", "(", "beamSize", ",", "remainingSents", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "active", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batchSize", ")", ":", "\n", "                ", "if", "beam", "[", "b", "]", ".", "done", ":", "\n", "                    ", "continue", "\n", "\n", "", "idx", "=", "batchIdx", "[", "b", "]", "\n", "if", "not", "beam", "[", "b", "]", ".", "advance", "(", "wordLk", ".", "data", "[", "idx", "]", ",", "attn", ".", "data", "[", "idx", "]", ")", ":", "\n", "                    ", "active", "+=", "[", "b", "]", "\n", "#print(decStates)", "\n", "", "if", "not", "isinstance", "(", "decStates", ",", "tuple", ")", ":", "\n", "                    ", "decStates", "=", "tuple", "(", "decStates", ".", "unsqueeze", "(", "0", ")", ")", "\n", "#print(decStates)", "\n", "", "for", "decState", "in", "decStates", ":", "# iterate over h, c", "\n", "# layers x beam*sent x dim", "\n", "                    ", "sentStates", "=", "decState", ".", "view", "(", "-", "1", ",", "beamSize", ",", "\n", "remainingSents", ",", "\n", "decState", ".", "size", "(", "2", ")", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "sentStates", ".", "data", ".", "copy_", "(", "\n", "sentStates", ".", "data", ".", "index_select", "(", "\n", "1", ",", "beam", "[", "b", "]", ".", "getCurrentOrigin", "(", ")", ")", ")", "\n", "\n", "", "", "if", "not", "active", ":", "\n", "                ", "break", "\n", "\n", "# in this section, the sentences that are still active are", "\n", "# compacted so that the decoder is not run on completed sentences", "\n", "", "activeIdx", "=", "self", ".", "tt", ".", "LongTensor", "(", "[", "batchIdx", "[", "k", "]", "for", "k", "in", "active", "]", ")", "\n", "batchIdx", "=", "{", "beam", ":", "idx", "for", "idx", ",", "beam", "in", "enumerate", "(", "active", ")", "}", "\n", "\n", "def", "updateActive", "(", "t", ",", "lastSize", "=", "rnnSize", ")", ":", "\n", "# select only the remaining active sentences", "\n", "                ", "view", "=", "t", ".", "data", ".", "view", "(", "-", "1", ",", "remainingSents", ",", "lastSize", ")", "\n", "newSize", "=", "list", "(", "t", ".", "size", "(", ")", ")", "\n", "newSize", "[", "-", "2", "]", "=", "newSize", "[", "-", "2", "]", "*", "len", "(", "activeIdx", ")", "//", "remainingSents", "\n", "return", "Variable", "(", "view", ".", "index_select", "(", "1", ",", "activeIdx", ")", "\n", ".", "view", "(", "*", "newSize", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "", "decStates", "=", "tuple", "(", "updateActive", "(", "decStates", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "decStates", ")", ")", ")", "\n", "\n", "if", "len", "(", "decStates", ")", "==", "1", ":", "\n", "# The GRU needs only one matrix as hidden state", "\n", "                ", "decStates", "=", "decStates", "[", "0", "]", "\n", "\n", "", "decOut", "=", "updateActive", "(", "decOut", ")", "\n", "context", "=", "updateActive", "(", "context", ")", "\n", "emb", "=", "updateActive", "(", "emb", ",", "emb", ".", "size", "(", "2", ")", ")", "\n", "\n", "if", "useMasking", ":", "\n", "                ", "padMask", "=", "padMask", ".", "index_select", "(", "1", ",", "activeIdx", ")", "\n", "\n", "", "remainingSents", "=", "len", "(", "active", ")", "\n", "\n", "#  (4) package everything up", "\n", "", "allHyp", ",", "allScores", ",", "allAttn", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "n_best", "=", "self", ".", "opt", ".", "n_best", "\n", "\n", "if", "activs", ":", "\n", "            ", "new_activs", "=", "torch", ".", "zeros", "(", "(", "2", ",", "activs", "[", "0", "]", ".", "size", "(", "1", ")", ",", "len", "(", "activs", ")", ")", ")", "\n", "for", "i", ",", "activ", "in", "enumerate", "(", "activs", ")", ":", "\n", "                ", "new_activs", "[", ":", ",", ":", "activ", ".", "size", "(", "1", ")", ",", "i", "]", "=", "activ", ".", "data", "\n", "", "activs", "=", "new_activs", "\n", "sys", ".", "stderr", ".", "write", "(", "\"r=\\n\"", ")", "\n", "for", "i", "in", "range", "(", "activs", ".", "size", "(", "1", ")", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "activs", ".", "size", "(", "2", ")", ")", ":", "\n", "                    ", "sys", ".", "stderr", ".", "write", "(", "str", "(", "activs", "[", "0", "]", "[", "i", "]", "[", "j", "]", ")", "+", "\" \"", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "\"\\n\"", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "\"z=\\n\"", ")", "\n", "for", "i", "in", "range", "(", "activs", ".", "size", "(", "1", ")", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "activs", ".", "size", "(", "2", ")", ")", ":", "\n", "                    ", "sys", ".", "stderr", ".", "write", "(", "str", "(", "activs", "[", "1", "]", "[", "i", "]", "[", "j", "]", ")", "+", "\" \"", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "for", "b", "in", "range", "(", "batchSize", ")", ":", "\n", "            ", "scores", ",", "ks", "=", "beam", "[", "b", "]", ".", "sortBest", "(", ")", "\n", "\n", "allScores", "+=", "[", "scores", "[", ":", "n_best", "]", "]", "\n", "hyps", ",", "attn", "=", "zip", "(", "*", "[", "beam", "[", "b", "]", ".", "getHyp", "(", "k", ")", "for", "k", "in", "ks", "[", ":", "n_best", "]", "]", ")", "\n", "allHyp", "+=", "[", "hyps", "]", "\n", "if", "useMasking", ":", "\n", "                ", "valid_attn", "=", "srcBatch", ".", "data", "[", ":", ",", "b", "]", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "attn", "=", "[", "a", ".", "index_select", "(", "1", ",", "valid_attn", ")", "for", "a", "in", "attn", "]", "\n", "", "allAttn", "+=", "[", "attn", "]", "\n", "\n", "if", "self", ".", "beam_accum", ":", "\n", "                ", "self", ".", "beam_accum", "[", "\"beam_parent_ids\"", "]", ".", "append", "(", "\n", "[", "t", ".", "tolist", "(", ")", "\n", "for", "t", "in", "beam", "[", "b", "]", ".", "prevKs", "]", ")", "\n", "self", ".", "beam_accum", "[", "\"scores\"", "]", ".", "append", "(", "[", "\n", "[", "\"%4f\"", "%", "s", "for", "s", "in", "t", ".", "tolist", "(", ")", "]", "\n", "for", "t", "in", "beam", "[", "b", "]", ".", "allScores", "]", "[", "1", ":", "]", ")", "\n", "self", ".", "beam_accum", "[", "\"predicted_ids\"", "]", ".", "append", "(", "\n", "[", "[", "self", ".", "tgt_dict", ".", "getLabel", "(", "id", ")", "\n", "for", "id", "in", "t", ".", "tolist", "(", ")", "]", "\n", "for", "t", "in", "beam", "[", "b", "]", ".", "nextYs", "]", "[", "1", ":", "]", ")", "\n", "\n", "", "", "return", "allHyp", ",", "allScores", ",", "allAttn", ",", "goldScores", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.translate": [[326, 347], ["Translator.Translator.buildData", "Translator.Translator._getBatchSize", "Translator.Translator.translateBatch", "range", "list", "predBatch.append", "zip", "Translator.Translator.buildTargetTokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.buildData", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator._getBatchSize", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.translateBatch", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.Translator.buildTargetTokens"], ["", "def", "translate", "(", "self", ",", "srcBatch", ",", "goldBatch", ")", ":", "\n", "#  (1) convert words to indexes", "\n", "        ", "dataset", "=", "self", ".", "buildData", "(", "srcBatch", ",", "goldBatch", ")", "\n", "src", ",", "tgt", ",", "indices", "=", "dataset", "[", "0", "]", "\n", "batchSize", "=", "self", ".", "_getBatchSize", "(", "src", "[", "0", "]", ")", "\n", "\n", "#  (2) translate", "\n", "pred", ",", "predScore", ",", "attn", ",", "goldScore", "=", "self", ".", "translateBatch", "(", "src", ",", "tgt", ")", "\n", "pred", ",", "predScore", ",", "attn", ",", "goldScore", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "pred", ",", "predScore", ",", "attn", ",", "goldScore", ",", "indices", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "[", ":", "-", "1", "]", "\n", "\n", "#  (3) convert indexes to words", "\n", "predBatch", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batchSize", ")", ":", "\n", "            ", "predBatch", ".", "append", "(", "\n", "[", "self", ".", "buildTargetTokens", "(", "pred", "[", "b", "]", "[", "n", "]", ",", "srcBatch", "[", "b", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "opt", ".", "n_best", ")", "]", "\n", ")", "\n", "\n", "", "return", "predBatch", ",", "predScore", ",", "goldScore", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Translator.loadImageLibs": [[15, 20], ["None"], "function", ["None"], ["def", "loadImageLibs", "(", ")", ":", "\n", "    ", "\"Conditional import of torch image libs.\"", "\n", "global", "Image", ",", "transforms", "\n", "from", "PIL", "import", "Image", "\n", "from", "torchvision", "import", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.set_parameters": [[7, 20], ["list", "torch.SGD", "torch.Adagrad", "torch.Adadelta", "torch.Adam", "RuntimeError"], "methods", ["None"], ["    ", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "list", "(", "params", ")", "# careful: params may be a generator", "\n", "\n", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-5", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.__init__": [[21, 30], ["None"], "methods", ["None"], ["", "", "def", "__init__", "(", "self", ",", "method", ",", "lr", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_at", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_at", "=", "start_decay_at", "\n", "self", ".", "start_decay", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.step": [[31, 36], ["Optim.Optim.optimizer.step", "torch.nn.utils.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Compute gradients norm.\"", "\n", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Optim.Optim.updateLearningRate": [[38, 55], ["print"], "methods", ["None"], ["", "def", "updateLearningRate", "(", "self", ",", "ppl", ",", "iter", ")", ":", "\n", "        ", "\"\"\"\n        Decay learning rate if val perf does not improve\n        or we hit the start_decay_at limit.\n        \"\"\"", "\n", "\n", "if", "self", ".", "start_decay_at", "is", "not", "None", "and", "iter", ">=", "self", ".", "start_decay_at", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "self", ".", "last_ppl", "is", "not", "None", "and", "ppl", ">", "self", ".", "last_ppl", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "\n", "", "if", "self", ".", "start_decay", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "lr", "*", "self", ".", "lr_decay", "\n", "print", "(", "\"Decaying learning rate to %g\"", "%", "self", ".", "lr", ")", "\n", "\n", "", "self", ".", "last_ppl", "=", "ppl", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter._format_usage": [[18, 22], ["super()._format_usage"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter._format_usage"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "usage_text", "=", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "_format_usage", "(", "\n", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", "\n", "return", "'\\n```\\n%s\\n```\\n\\n'", "%", "usage_text", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter.format_help": [[23, 26], ["super().format_help"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "self", ".", "_root_section", ".", "heading", "=", "'# %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter.start_section": [[27, 29], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'## **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpFormatter._format_action": [[30, 42], ["Markdown.MarkdownHelpFormatter._format_action_invocation", "lines.append", "lines.extend", "lines.append", "lines.append", "Markdown.MarkdownHelpFormatter._expand_help", "lines.extend", "lines.append", "Markdown.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "action_header", "=", "self", ".", "_format_action_invocation", "(", "action", ")", "\n", "lines", ".", "append", "(", "'### **%s** '", "%", "action_header", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'```'", ")", "\n", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "lines", ".", "append", "(", "'```'", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpAction.__init__": [[45, 54], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.MarkdownHelpAction.__call__": [[55, 59], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Markdown.add_md_help_argument": [[61, 64], ["parser.add_argument"], "function", ["None"], ["", "", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.__init__": [[5, 19], ["type", "Dict.Dict.loadFile", "Dict.Dict.addSpecials"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.loadFile", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.addSpecials"], ["    ", "def", "__init__", "(", "self", ",", "data", "=", "None", ",", "lower", "=", "False", ")", ":", "\n", "        ", "self", ".", "idxToLabel", "=", "{", "}", "\n", "self", ".", "labelToIdx", "=", "{", "}", "\n", "self", ".", "frequencies", "=", "{", "}", "\n", "self", ".", "lower", "=", "lower", "\n", "\n", "# Special entries will not be pruned.", "\n", "self", ".", "special", "=", "[", "]", "\n", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "if", "type", "(", "data", ")", "==", "str", ":", "\n", "                ", "self", ".", "loadFile", "(", "data", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "addSpecials", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size": [[20, 22], ["len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idxToLabel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.loadFile": [[23, 30], ["open", "line.split", "int", "Dict.Dict.add"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.add"], ["", "def", "loadFile", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"Load entries from a file.\"", "\n", "for", "line", "in", "open", "(", "filename", ")", ":", "\n", "            ", "fields", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "fields", "[", "0", "]", "\n", "idx", "=", "int", "(", "fields", "[", "1", "]", ")", "\n", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.writeFile": [[31, 39], ["file.close", "open", "range", "Dict.Dict.size", "file.write"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "", "def", "writeFile", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"Write entries to a file.\"", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "file", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "size", "(", ")", ")", ":", "\n", "                ", "label", "=", "self", ".", "idxToLabel", "[", "i", "]", "\n", "file", ".", "write", "(", "'%s %d\\n'", "%", "(", "label", ",", "i", ")", ")", "\n", "\n", "", "", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.lookup": [[40, 46], ["key.lower"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "key", ",", "default", "=", "None", ")", ":", "\n", "        ", "key", "=", "key", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "key", "\n", "try", ":", "\n", "            ", "return", "self", ".", "labelToIdx", "[", "key", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.getLabel": [[47, 52], ["None"], "methods", ["None"], ["", "", "def", "getLabel", "(", "self", ",", "idx", ",", "default", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "idxToLabel", "[", "idx", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.addSpecial": [[53, 57], ["Dict.Dict.add"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.add"], ["", "", "def", "addSpecial", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"Mark this `label` and `idx` as special (i.e. will not be pruned).\"", "\n", "idx", "=", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "self", ".", "special", "+=", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.addSpecials": [[58, 62], ["Dict.Dict.addSpecial"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.addSpecial"], ["", "def", "addSpecials", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"Mark all labels in `labels` as specials (i.e. will not be pruned).\"", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "self", ".", "addSpecial", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.add": [[63, 83], ["label.lower", "len"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"Add `label` in the dictionary. Use `idx` as its index if given.\"", "\n", "label", "=", "label", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "label", "\n", "if", "idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "idxToLabel", "[", "idx", "]", "=", "label", "\n", "self", ".", "labelToIdx", "[", "label", "]", "=", "idx", "\n", "", "else", ":", "\n", "            ", "if", "label", "in", "self", ".", "labelToIdx", ":", "\n", "                ", "idx", "=", "self", ".", "labelToIdx", "[", "label", "]", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "idxToLabel", ")", "\n", "self", ".", "idxToLabel", "[", "idx", "]", "=", "label", "\n", "self", ".", "labelToIdx", "[", "label", "]", "=", "idx", "\n", "\n", "", "", "if", "idx", "not", "in", "self", ".", "frequencies", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "+=", "1", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.prune": [[84, 105], ["torch.Tensor", "torch.sort", "Dict.Dict", "Dict.Dict.size", "Dict.addSpecial", "Dict.add", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.addSpecial", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.add"], ["", "def", "prune", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"Return a new dictionary with the `size` most frequent entries.\"", "\n", "if", "size", ">=", "self", ".", "size", "(", ")", ":", "\n", "            ", "return", "self", "\n", "\n", "# Only keep the `size` most frequent entries.", "\n", "", "freq", "=", "torch", ".", "Tensor", "(", "\n", "[", "self", ".", "frequencies", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "frequencies", ")", ")", "]", ")", "\n", "_", ",", "idx", "=", "torch", ".", "sort", "(", "freq", ",", "0", ",", "True", ")", "\n", "\n", "newDict", "=", "Dict", "(", ")", "\n", "newDict", ".", "lower", "=", "self", ".", "lower", "\n", "\n", "# Add special entries in all cases.", "\n", "for", "i", "in", "self", ".", "special", ":", "\n", "            ", "newDict", ".", "addSpecial", "(", "self", ".", "idxToLabel", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "idx", "[", ":", "size", "]", ":", "\n", "            ", "newDict", ".", "add", "(", "self", ".", "idxToLabel", "[", "i", "]", ")", "\n", "\n", "", "return", "newDict", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToIdx": [[106, 123], ["Dict.Dict.lookup", "torch.LongTensor", "Dict.Dict.lookup", "Dict.Dict.lookup", "Dict.Dict.lookup"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.lookup", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.lookup", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.lookup", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.lookup"], ["", "def", "convertToIdx", "(", "self", ",", "labels", ",", "unkWord", ",", "bosWord", "=", "None", ",", "eosWord", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Convert `labels` to indices. Use `unkWord` if not found.\n        Optionally insert `bosWord` at the beginning and `eosWord` at the .\n        \"\"\"", "\n", "vec", "=", "[", "]", "\n", "\n", "if", "bosWord", "is", "not", "None", ":", "\n", "            ", "vec", "+=", "[", "self", ".", "lookup", "(", "bosWord", ")", "]", "\n", "\n", "", "unk", "=", "self", ".", "lookup", "(", "unkWord", ")", "\n", "vec", "+=", "[", "self", ".", "lookup", "(", "label", ",", "default", "=", "unk", ")", "for", "label", "in", "labels", "]", "\n", "\n", "if", "eosWord", "is", "not", "None", ":", "\n", "            ", "vec", "+=", "[", "self", ".", "lookup", "(", "eosWord", ")", "]", "\n", "\n", "", "return", "torch", ".", "LongTensor", "(", "vec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.convertToLabels": [[124, 138], ["Dict.Dict.getLabel"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.getLabel"], ["", "def", "convertToLabels", "(", "self", ",", "idx", ",", "stop", ")", ":", "\n", "        ", "\"\"\"\n        Convert `idx` to labels.\n        If index `stop` is reached, convert it and return.\n        \"\"\"", "\n", "\n", "labels", "=", "[", "]", "\n", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "labels", "+=", "[", "self", ".", "getLabel", "(", "i", ")", "]", "\n", "if", "i", "==", "stop", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset.__init__": [[11, 25], ["math.ceil", "len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "srcData", ",", "tgtData", ",", "batchSize", ",", "cuda", ",", "\n", "volatile", "=", "False", ",", "data_type", "=", "\"text\"", ")", ":", "\n", "        ", "self", ".", "src", "=", "srcData", "\n", "self", ".", "_type", "=", "data_type", "\n", "if", "tgtData", ":", "\n", "            ", "self", ".", "tgt", "=", "tgtData", "\n", "assert", "(", "len", "(", "self", ".", "src", ")", "==", "len", "(", "self", ".", "tgt", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tgt", "=", "None", "\n", "", "self", ".", "cuda", "=", "cuda", "\n", "\n", "self", ".", "batchSize", "=", "batchSize", "\n", "self", ".", "numBatches", "=", "math", ".", "ceil", "(", "len", "(", "self", ".", "src", ")", "/", "batchSize", ")", "\n", "self", ".", "volatile", "=", "volatile", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset._batchify": [[26, 55], ["max", "data[].new().fill_", "range", "x.size", "len", "data[].size", "out[].narrow().copy_", "max", "max", "data[].new().fill_", "range", "data[].new", "x.size", "x.size", "len", "data[].size", "data[].size", "out[].narrow().narrow().copy_", "len", "out[].narrow", "data[].new", "len", "out[].narrow().narrow", "out[].narrow"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "_batchify", "(", "self", ",", "data", ",", "align_right", "=", "False", ",", "\n", "include_lengths", "=", "False", ",", "dtype", "=", "\"text\"", ")", ":", "\n", "        ", "if", "dtype", "in", "[", "\"text\"", ",", "\"bitext\"", ",", "\"monotext\"", "]", ":", "\n", "            ", "lengths", "=", "[", "x", ".", "size", "(", "0", ")", "for", "x", "in", "data", "]", "\n", "max_length", "=", "max", "(", "lengths", ")", "\n", "out", "=", "data", "[", "0", "]", ".", "new", "(", "len", "(", "data", ")", ",", "max_length", ")", ".", "fill_", "(", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                ", "data_length", "=", "data", "[", "i", "]", ".", "size", "(", "0", ")", "\n", "offset", "=", "max_length", "-", "data_length", "if", "align_right", "else", "0", "\n", "out", "[", "i", "]", ".", "narrow", "(", "0", ",", "offset", ",", "data_length", ")", ".", "copy_", "(", "data", "[", "i", "]", ")", "\n", "", "if", "include_lengths", ":", "\n", "                ", "return", "out", ",", "lengths", "\n", "", "else", ":", "\n", "                ", "return", "out", "\n", "", "", "elif", "dtype", "==", "\"img\"", ":", "\n", "            ", "heights", "=", "[", "x", ".", "size", "(", "1", ")", "for", "x", "in", "data", "]", "\n", "max_height", "=", "max", "(", "heights", ")", "\n", "widths", "=", "[", "x", ".", "size", "(", "2", ")", "for", "x", "in", "data", "]", "\n", "max_width", "=", "max", "(", "widths", ")", "\n", "\n", "out", "=", "data", "[", "0", "]", ".", "new", "(", "len", "(", "data", ")", ",", "3", ",", "max_height", ",", "max_width", ")", ".", "fill_", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                ", "data_height", "=", "data", "[", "i", "]", ".", "size", "(", "1", ")", "\n", "data_width", "=", "data", "[", "i", "]", ".", "size", "(", "2", ")", "\n", "height_offset", "=", "max_height", "-", "data_height", "if", "align_right", "else", "0", "\n", "width_offset", "=", "max_width", "-", "data_width", "if", "align_right", "else", "0", "\n", "out", "[", "i", "]", ".", "narrow", "(", "1", ",", "height_offset", ",", "data_height", ")", ".", "narrow", "(", "2", ",", "width_offset", ",", "data_width", ")", ".", "copy_", "(", "data", "[", "i", "]", ")", "\n", "", "return", "out", ",", "widths", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset.__getitem__": [[56, 95], ["Dataset.Dataset._batchify", "range", "zip", "torch.LongTensor().view", "torch.autograd.Variable", "Dataset.Dataset._batchify", "len", "zip", "zip", "zip", "zip", "torch.stack", "torch.autograd.Variable", "Dataset.Dataset.__getitem__.wrap"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset._batchify", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset._batchify"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "assert", "index", "<", "self", ".", "numBatches", ",", "\"%d > %d\"", "%", "(", "index", ",", "self", ".", "numBatches", ")", "\n", "srcBatch", ",", "lengths", "=", "self", ".", "_batchify", "(", "\n", "self", ".", "src", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ",", "\n", "align_right", "=", "False", ",", "include_lengths", "=", "True", ",", "dtype", "=", "self", ".", "_type", ")", "\n", "\n", "if", "self", ".", "tgt", ":", "\n", "            ", "tgtBatch", "=", "self", ".", "_batchify", "(", "\n", "self", ".", "tgt", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ",", "\n", "dtype", "=", "\"text\"", ")", "\n", "", "else", ":", "\n", "            ", "tgtBatch", "=", "None", "\n", "\n", "# within batch sorting by decreasing length for variable length rnns", "\n", "", "indices", "=", "range", "(", "len", "(", "srcBatch", ")", ")", "\n", "batch", "=", "(", "zip", "(", "indices", ",", "srcBatch", ")", "if", "tgtBatch", "is", "None", "\n", "else", "zip", "(", "indices", ",", "srcBatch", ",", "tgtBatch", ")", ")", "\n", "batch", ",", "lengths", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "batch", ",", "lengths", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ")", "\n", "if", "tgtBatch", "is", "None", ":", "\n", "            ", "indices", ",", "srcBatch", "=", "zip", "(", "*", "batch", ")", "\n", "", "else", ":", "\n", "            ", "indices", ",", "srcBatch", ",", "tgtBatch", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "", "def", "wrap", "(", "b", ",", "dtype", "=", "\"text\"", ")", ":", "\n", "            ", "if", "b", "is", "None", ":", "\n", "                ", "return", "b", "\n", "", "b", "=", "torch", ".", "stack", "(", "b", ",", "0", ")", "\n", "if", "dtype", "in", "[", "\"text\"", ",", "\"bitext\"", ",", "\"monotext\"", "]", ":", "\n", "                ", "b", "=", "b", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "", "if", "self", ".", "cuda", ":", "\n", "                ", "b", "=", "b", ".", "cuda", "(", ")", "\n", "", "b", "=", "Variable", "(", "b", ",", "volatile", "=", "self", ".", "volatile", ")", "\n", "return", "b", "\n", "\n", "# wrap lengths in a Variable to properly split it in DataParallel", "\n", "", "lengths", "=", "torch", ".", "LongTensor", "(", "lengths", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "lengths", "=", "Variable", "(", "lengths", ",", "volatile", "=", "self", ".", "volatile", ")", "\n", "return", "(", "wrap", "(", "srcBatch", ",", "self", ".", "_type", ")", ",", "lengths", ")", ",", "wrap", "(", "tgtBatch", ",", "\"text\"", ")", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset.__len__": [[96, 98], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "numBatches", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dataset.Dataset.shuffle": [[99, 102], ["list", "zip", "zip", "torch.randperm", "len"], "methods", ["None"], ["", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "data", "=", "list", "(", "zip", "(", "self", ".", "src", ",", "self", ".", "tgt", ")", ")", "\n", "self", ".", "src", ",", "self", ".", "tgt", "=", "zip", "(", "*", "[", "data", "[", "i", "]", "for", "i", "in", "torch", ".", "randperm", "(", "len", "(", "data", ")", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedLSTM.__init__": [[43, 52], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "Decoders.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedLSTM.forward": [[53, 68], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "Decoders.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedGRU.__init__": [[72, 81], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "Decoders.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedGRU.forward": [[82, 94], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "Decoders.StackedGRU.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input", ",", "hidden", "[", "i", "]", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "\n", "return", "input", ",", "h_1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedSGU.__init__": [[98, 107], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "range", "Decoders.StackedSGU.layers.append", "modules.SRU_units.AttSRU"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "layer_norm", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedSGU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "AttSRU", "(", "input_size", ",", "\n", "rnn_size", ",", "rnn_size", ",", "layer_norm", ",", "dropout", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedSGU.initialize_parameters": [[108, 111], ["layer.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "layer", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedSGU.forward": [[112, 121], ["enumerate", "layer", "Decoders.StackedSGU.dropout", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "dec_state", ",", "hidden", ",", "enc_out", ")", ":", "\n", "        ", "input", "=", "dec_state", "\n", "first_input", "=", "dec_state", "\n", "hiddens", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "input", ",", "new_hidden", ",", "attn_state", "=", "layer", "(", "input", ",", "hidden", "[", "i", "]", ",", "enc_out", ")", "\n", "hiddens", "+=", "[", "new_hidden", "]", "\n", "\n", "", "return", "self", ".", "dropout", "(", "input", ")", ",", "torch", ".", "stack", "(", "hiddens", ")", ",", "attn_state", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedRNNDecoder.__init__": [[125, 162], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "getattr", "dicts.size", "modules.Attention.getAttention", "hasattr", "modules.Normalization.LayerNorm", "Decoders.getStackedLayer", "Decoders.getStackedLayer"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.getAttention", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getStackedLayer", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getStackedLayer"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers_dec", "\n", "self", ".", "input_feed", "=", "opt", ".", "input_feed", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "\n", "\n", "input_size", "=", "opt", ".", "word_vec_size", "\n", "if", "self", ".", "input_feed", ":", "\n", "            ", "input_size", "+=", "opt", ".", "rnn_size", "\n", "\n", "", "super", "(", "StackedRNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "\n", "rnn_type", "=", "opt", ".", "rnn_decoder_type", "if", "opt", ".", "rnn_decoder_type", "else", "opt", ".", "rnn_type", "\n", "if", "rnn_type", "in", "[", "'LSTM'", ",", "'GRU'", "]", ":", "\n", "            ", "self", ".", "rnn", "=", "getStackedLayer", "(", "rnn_type", ")", "(", "opt", ".", "layers_dec", ",", "input_size", ",", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "rnn", "=", "getStackedLayer", "(", "rnn_type", ")", "(", "opt", ".", "layers_dec", ",", "input_size", ",", "opt", ".", "rnn_size", ",", "opt", ".", "activ", ",", "\n", "opt", ".", "layer_norm", ",", "opt", ".", "dropout", ")", "\n", "\n", "", "self", ".", "attn", "=", "getAttention", "(", "opt", ".", "attn_type", ")", "(", "opt", ".", "rnn_size", ",", "opt", ".", "activ", ")", "\n", "\n", "self", ".", "linear_ctx", "=", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "2", "*", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "opt", ".", "dropout", ")", "\n", "self", ".", "log", "=", "self", ".", "rnn", ".", "log", "if", "hasattr", "(", "self", ".", "rnn", ",", "'log'", ")", "else", "False", "\n", "\n", "self", ".", "layer_norm", "=", "opt", ".", "layer_norm", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "self", ".", "ctx_ln", "=", "LayerNorm", "(", "opt", ".", "rnn_size", ")", "\n", "\n", "", "self", ".", "activ", "=", "getattr", "(", "F", ",", "opt", ".", "activ", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedRNNDecoder.load_pretrained_vectors": [[163, 167], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "Decoders.StackedRNNDecoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "pre_word_vecs_dec", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_dec", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedRNNDecoder.initialize_parameters": [[168, 170], ["None"], "methods", ["None"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedRNNDecoder.forward": [[171, 224], ["Decoders.StackedRNNDecoder.word_lut", "context.transpose.transpose.transpose", "Decoders.StackedRNNDecoder.split", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "emb_t.squeeze", "Decoders.StackedRNNDecoder.linear_ctx", "Decoders.StackedRNNDecoder.attn", "Decoders.StackedRNNDecoder.linear_out", "Decoders.StackedRNNDecoder.activ", "Decoders.StackedRNNDecoder.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Decoders.StackedRNNDecoder.rnn", "Decoders.StackedRNNDecoder.rnn", "Decoders.StackedRNNDecoder.dropout", "Decoders.StackedRNNDecoder.ctx_ln", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "context", ",", "init_output", ")", ":", "\n", "        ", "\"\"\"\n        input: targetL x batch\n        hidden: batch x hidden_dim\n        context: sourceL x batch x hidden_dim\n        init_output: batch x hidden_dim\n        \"\"\"", "\n", "# targetL x batch x hidden_dim", "\n", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "\n", "# batch x sourceL x hidden_dim", "\n", "context", "=", "context", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# n.b. you can increase performance if you compute W_ih * x for all", "\n", "# iterations in parallel, but that's only possible if", "\n", "# self.input_feed=False", "\n", "outputs", "=", "[", "]", "\n", "output", "=", "init_output", "\n", "\n", "for", "emb_t", "in", "emb", ".", "split", "(", "1", ")", ":", "\n", "# batch x word_dim", "\n", "            ", "emb_inp", "=", "emb_t", ".", "squeeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "input_feed", "==", "1", ":", "\n", "# batch x (word_dim+hidden_dim)", "\n", "                ", "emb_inp_feed", "=", "torch", ".", "cat", "(", "[", "emb_inp", ",", "output", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "emb_inp_feed", "=", "emb_inp", "\n", "\n", "# batch x hidden_dim, layers x batch x hidden_dim", "\n", "", "if", "self", ".", "log", ":", "\n", "                ", "rnn_output", ",", "hidden", ",", "activ", "=", "self", ".", "rnn", "(", "emb_inp_feed", ",", "hidden", ")", "\n", "", "else", ":", "\n", "                ", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb_inp_feed", ",", "hidden", ")", "\n", "\n", "", "values", "=", "context", "\n", "pctx", "=", "self", ".", "linear_ctx", "(", "self", ".", "dropout", "(", "context", ")", ")", "\n", "if", "self", ".", "layer_norm", ":", "\n", "                ", "pctx", "=", "self", ".", "ctx_ln", "(", "pctx", ")", "\n", "", "weightedContext", ",", "attn", "=", "self", ".", "attn", "(", "rnn_output", ",", "pctx", ",", "values", ")", "\n", "\n", "contextCombined", "=", "self", ".", "linear_out", "(", "torch", ".", "cat", "(", "[", "rnn_output", ",", "weightedContext", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "output", "=", "self", ".", "activ", "(", "contextCombined", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "outputs", "+=", "[", "output", "]", "\n", "\n", "", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "\n", "if", "self", ".", "log", ":", "\n", "            ", "return", "outputs", ",", "hidden", ",", "attn", ",", "activ", "\n", "\n", "", "return", "outputs", ",", "hidden", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.SGUDecoder.__init__": [[228, 244], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "Decoders.StackedSGU", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers_dec", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "\n", "\n", "input_size", "=", "opt", ".", "word_vec_size", "\n", "\n", "super", "(", "SGUDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "\n", "self", ".", "stacked", "=", "StackedSGU", "(", "opt", ".", "layers_dec", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "layer_norm", ",", "\n", "opt", ".", "dropout", ")", "\n", "\n", "self", ".", "log", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.SGUDecoder.load_pretrained_vectors": [[245, 249], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "Decoders.SGUDecoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "pre_word_vecs_dec", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_dec", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.SGUDecoder.initialize_parameters": [[250, 252], ["Decoders.SGUDecoder.stacked.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "self", ".", "stacked", ".", "initialize_parameters", "(", "param_init", ")", "\n", "#self.attn.initialize_parameters(param_init)", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.SGUDecoder.forward": [[254, 279], ["input.size", "context.transpose.transpose.size", "Decoders.SGUDecoder.word_lut", "context.transpose.transpose.transpose", "Decoders.SGUDecoder.stacked", "len", "hidden.unsqueeze.unsqueeze.unsqueeze", "hidden.unsqueeze.unsqueeze.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "context", ",", "init_output", ")", ":", "\n", "        ", "\"\"\"\n        input: targetL x batch\n        hidden: num_layers x batch x hidden_dim\n        context: sourceL x batch x hidden_dim\n        init_output: batch x hidden_dim\n        \"\"\"", "\n", "batch_size", "=", "input", ".", "size", "(", "1", ")", "\n", "hidden_dim", "=", "context", ".", "size", "(", "2", ")", "\n", "\n", "#targetL x batch x hidden_dim", "\n", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "\n", "# batch x sourceL x hidden_dim", "\n", "context", "=", "context", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "len", "(", "hidden", ".", "size", "(", ")", ")", "<", "3", ":", "\n", "            ", "hidden", "=", "hidden", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# (targetL x batch) x sourceL x hidden_dim", "\n", "#values = context.repeat(emb.size(0), 1, 1)", "\n", "", "rnn_outputs", "=", "emb", "#.view(-1, hidden_dim)", "\n", "\n", "outputs", ",", "hidden", ",", "attn", "=", "self", ".", "stacked", "(", "rnn_outputs", ",", "hidden", ",", "context", ")", "\n", "\n", "return", "outputs", ",", "hidden", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedSRU.__init__": [[282, 291], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "Decoders.StackedSRU.layers.append", "onmt.modules.SRU"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "    ", "super", "(", "StackedSRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "      ", "self", ".", "layers", ".", "append", "(", "SRU", "(", "input_size", ",", "rnn_size", ",", "dropout", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedSRU.initialize_parameters": [[292, 295], ["layer.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "    ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "      ", "layer", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.StackedSRU.forward": [[296, 312], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "    ", "\"\"\"\n\n    :param input: batch x hi\n    :param hidden:\n    :return:\n    \"\"\"", "\n", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "      ", "h_1_i", ",", "h", "=", "layer", "(", "input", ",", "hidden", "[", "i", "]", ")", "\n", "input", "=", "h_1_i", "\n", "h_1", "+=", "[", "h", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "\n", "return", "input", ",", "h_1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.ParallelRNNDecoder.__init__": [[315, 336], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "Decoders.StackedSRU", "MLPAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["  ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "    ", "from", ".", "modules", ".", "Attention", "import", "MLPAttention", "\n", "\n", "self", ".", "layers", "=", "opt", ".", "layers_dec", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "\n", "\n", "input_size", "=", "opt", ".", "word_vec_size", "\n", "\n", "super", "(", "ParallelRNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "\n", "self", ".", "rnn", "=", "StackedSRU", "(", "self", ".", "layers", ",", "input_size", ",", "self", ".", "hidden_size", ",", "opt", ".", "dropout", ")", "\n", "\n", "self", ".", "attn", "=", "MLPAttention", "(", "opt", ".", "rnn_size", ",", "opt", ".", "activ", ")", "# getAttention(opt.attn_type)(opt.rnn_size, opt.activ)", "\n", "\n", "self", ".", "linear_ctx", "=", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "2", "*", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "opt", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.ParallelRNNDecoder.load_pretrained_vectors": [[337, 341], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "Decoders.ParallelRNNDecoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "pre_word_vecs_dec", "is", "not", "None", ":", "\n", "      ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_dec", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.ParallelRNNDecoder.initialize_parameters": [[342, 344], ["None"], "methods", ["None"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.ParallelRNNDecoder.forward": [[345, 372], ["Decoders.ParallelRNNDecoder.word_lut", "context.transpose.transpose.transpose", "Decoders.ParallelRNNDecoder.rnn", "Decoders.ParallelRNNDecoder.linear_ctx", "Decoders.ParallelRNNDecoder.attn", "Decoders.ParallelRNNDecoder.linear_out", "torch.tanh", "torch.tanh", "torch.tanh", "Decoders.ParallelRNNDecoder.dropout", "Decoders.ParallelRNNDecoder.dropout", "Decoders.ParallelRNNDecoder.dropout", "Decoders.ParallelRNNDecoder.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "context", ",", "init_output", ")", ":", "\n", "    ", "\"\"\"\n    input: targetL x batch\n    hidden: batch x hidden_dim\n    context: sourceL x batch x hidden_dim\n    init_output: batch x hidden_dim\n    \"\"\"", "\n", "# targetL x batch x hidden_dim", "\n", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "\n", "# batch x sourceL x hidden_dim", "\n", "context", "=", "context", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# batch x hidden_dim, layers x batch x hidden_dim", "\n", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "hidden", ")", "\n", "\n", "values", "=", "context", "\n", "pctx", "=", "self", ".", "linear_ctx", "(", "self", ".", "dropout", "(", "context", ")", ")", "\n", "\n", "weightedContext", ",", "attn", "=", "self", ".", "attn", "(", "self", ".", "dropout", "(", "rnn_output", ")", ",", "pctx", ",", "values", ")", "\n", "\n", "contextCombined", "=", "self", ".", "linear_out", "(", "self", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "rnn_output", ",", "weightedContext", "]", ",", "dim", "=", "-", "1", ")", ")", ")", "\n", "\n", "output", "=", "F", ".", "tanh", "(", "contextCombined", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "\n", "return", "output", ",", "hidden", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getDecoder": [[15, 24], ["NotImplementedError"], "function", ["None"], ["def", "getDecoder", "(", "decoderType", ")", ":", "\n", "    ", "decoders", "=", "{", "'StackedRNN'", ":", "StackedRNNDecoder", ",", "\n", "'SR'", ":", "SGUDecoder", ",", "\n", "'ParallelRNN'", ":", "ParallelRNNDecoder", "}", "\n", "\n", "if", "decoderType", "not", "in", "decoders", ":", "\n", "        ", "raise", "NotImplementedError", "(", "decoderType", ")", "\n", "\n", "", "return", "decoders", "[", "decoderType", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getStackedLayer": [[26, 33], ["None"], "function", ["None"], ["", "def", "getStackedLayer", "(", "rnn_type", ")", ":", "\n", "    ", "if", "rnn_type", "==", "\"LSTM\"", ":", "\n", "        ", "return", "StackedLSTM", "\n", "", "elif", "rnn_type", "==", "\"GRU\"", ":", "\n", "        ", "return", "StackedGRU", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Decoders.getRNN": [[34, 40], ["None"], "function", ["None"], ["", "", "def", "getRNN", "(", "rnn_type", ")", ":", "\n", "    ", "rnns", "=", "{", "'LSTM'", ":", "nn", ".", "LSTM", ",", "\n", "'GRU'", ":", "nn", ".", "GRU", "\n", "}", "\n", "\n", "return", "rnns", "[", "rnn_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.__init__": [[21, 41], ["Beam.Beam.tt.FloatTensor().zero_", "Beam.Beam.tt.LongTensor().fill_", "Beam.Beam.tt.FloatTensor", "Beam.Beam.tt.LongTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "cuda", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "done", "=", "False", "\n", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "allScores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prevKs", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "nextYs", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", ".", "fill_", "(", "onmt", ".", "Constants", ".", "PAD", ")", "]", "\n", "self", ".", "nextYs", "[", "0", "]", "[", "0", "]", "=", "onmt", ".", "Constants", ".", "BOS", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.getCurrentState": [[42, 45], ["None"], "methods", ["None"], ["", "def", "getCurrentState", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "nextYs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.getCurrentOrigin": [[46, 49], ["None"], "methods", ["None"], ["", "def", "getCurrentOrigin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prevKs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.advance": [[50, 89], ["wordLk.size", "beamLk.view", "beamLk.view.topk", "Beam.Beam.allScores.append", "Beam.Beam.prevKs.append", "Beam.Beam.nextYs.append", "Beam.Beam.attn.append", "len", "attnOut.index_select", "Beam.Beam.allScores.append", "Beam.Beam.scores.unsqueeze().expand_as", "Beam.Beam.scores.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "advance", "(", "self", ",", "wordLk", ",", "attnOut", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attnOut`: Compute and update the beam search.\n\n        Parameters:\n\n        * `wordLk`- probs of advancing from the last step (K x words)\n        * `attnOut`- attention at the last step\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "numWords", "=", "wordLk", ".", "size", "(", "1", ")", "\n", "\n", "# Sum the previous scores.", "\n", "if", "len", "(", "self", ".", "prevKs", ")", ">", "0", ":", "\n", "            ", "beamLk", "=", "wordLk", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "wordLk", ")", "\n", "", "else", ":", "\n", "            ", "beamLk", "=", "wordLk", "[", "0", "]", "\n", "\n", "", "flatBeamLk", "=", "beamLk", ".", "view", "(", "-", "1", ")", "\n", "\n", "bestScores", ",", "bestScoresId", "=", "flatBeamLk", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "True", ",", "True", ")", "\n", "self", ".", "allScores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "bestScores", "\n", "\n", "# bestScoresId is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prevK", "=", "bestScoresId", "/", "numWords", "\n", "self", ".", "prevKs", ".", "append", "(", "prevK", ")", "\n", "self", ".", "nextYs", ".", "append", "(", "bestScoresId", "-", "prevK", "*", "numWords", ")", "\n", "self", ".", "attn", ".", "append", "(", "attnOut", ".", "index_select", "(", "0", ",", "prevK", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS.", "\n", "if", "self", ".", "nextYs", "[", "-", "1", "]", "[", "0", "]", "==", "onmt", ".", "Constants", ".", "EOS", ":", "\n", "            ", "self", ".", "done", "=", "True", "\n", "self", ".", "allScores", ".", "append", "(", "self", ".", "scores", ")", "\n", "\n", "", "return", "self", ".", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.sortBest": [[90, 92], ["torch.sort"], "methods", ["None"], ["", "def", "sortBest", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "sort", "(", "self", ".", "scores", ",", "0", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.getBest": [[93, 97], ["Beam.Beam.sortBest"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.sortBest"], ["", "def", "getBest", "(", "self", ")", ":", "\n", "        ", "\"Get the score of the best in the beam.\"", "\n", "scores", ",", "ids", "=", "self", ".", "sortBest", "(", ")", "\n", "return", "scores", "[", "1", "]", ",", "ids", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Beam.Beam.getHyp": [[98, 119], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "getHyp", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Walk back to construct the full hypothesis.\n\n        Parameters.\n\n             * `k` - the position in the beam to construct.\n\n         Returns.\n\n            1. The hypothesis\n            2. The attention at each time step.\n        \"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "# print(len(self.prevKs), len(self.nextYs), len(self.attn))", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prevKs", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "nextYs", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prevKs", "[", "j", "]", "[", "k", "]", "\n", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.ContextGate.__init__": [[28, 37], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.ContextGate.forward": [[38, 47], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "Gate.ContextGate.sig", "Gate.ContextGate.source_proj", "Gate.ContextGate.target_proj", "Gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.SourceContextGate.__init__": [[52, 58], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.SourceContextGate.forward": [[59, 63], ["Gate.SourceContextGate.context_gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "target", "+", "z", "*", "source", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.TargetContextGate.__init__": [[68, 74], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.TargetContextGate.forward": [[75, 78], ["Gate.TargetContextGate.context_gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "z", "*", "target", "+", "source", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.BothContextGate.__init__": [[83, 89], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.BothContextGate.forward": [[90, 93], ["Gate.BothContextGate.context_gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Gate.ContextGateFactory": [[12, 23], ["None"], "function", ["None"], ["def", "ContextGateFactory", "(", "type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "type", ")", "\n", "return", "gate_types", "[", "type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.AttSRU.__init__": [[18, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "DotAttention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "Normalization.LayerNorm", "Normalization.LayerNorm", "Normalization.LayerNorm", "Normalization.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "attention_size", ",", "output_size", ",", "layer_norm", ",", "dropout", ")", ":", "\n", "        ", "from", ".", "Attention", "import", "DotAttention", "\n", "super", "(", "AttSRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "3", "*", "output_size", ",", "bias", "=", "(", "not", "layer_norm", ")", ")", "\n", "self", ".", "linear_hidden", "=", "nn", ".", "Linear", "(", "output_size", ",", "output_size", ",", "bias", "=", "(", "not", "layer_norm", ")", ")", "\n", "self", ".", "linear_ctx", "=", "nn", ".", "Linear", "(", "output_size", ",", "output_size", ",", "bias", "=", "(", "not", "layer_norm", ")", ")", "\n", "self", ".", "linear_enc", "=", "nn", ".", "Linear", "(", "output_size", ",", "output_size", ",", "bias", "=", "(", "not", "layer_norm", ")", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "attn", "=", "DotAttention", "(", "attention_size", ",", "layer_norm", "=", "True", ")", "\n", "self", ".", "layer_norm", "=", "layer_norm", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "self", ".", "preact_ln", "=", "LayerNorm", "(", "3", "*", "output_size", ")", "\n", "self", ".", "enc_ln", "=", "LayerNorm", "(", "output_size", ")", "\n", "\n", "self", ".", "trans_h_ln", "=", "LayerNorm", "(", "output_size", ")", "\n", "self", ".", "trans_c_ln", "=", "LayerNorm", "(", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.AttSRU.initialize_parameters": [[36, 41], ["SRU_units.AttSRU.preact_ln.initialize_parameters", "SRU_units.AttSRU.trans_h_ln.initialize_parameters", "SRU_units.AttSRU.trans_c_ln.initialize_parameters", "SRU_units.AttSRU.enc_ln.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "self", ".", "preact_ln", ".", "initialize_parameters", "(", "param_init", ")", "\n", "self", ".", "trans_h_ln", ".", "initialize_parameters", "(", "param_init", ")", "\n", "self", ".", "trans_c_ln", ".", "initialize_parameters", "(", "param_init", ")", "\n", "self", ".", "enc_ln", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.AttSRU.forward": [[42, 88], ["SRU_units.AttSRU.linear_in", "SRU_units.AttSRU.linear_enc", "SRU_units.AttSRU.split", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "SRU_units.AttSRU.attn", "SRU_units.AttSRU.linear_hidden", "SRU_units.AttSRU.linear_ctx", "torch.tanh", "torch.tanh", "torch.tanh", "out.view.view.view", "SRU_units.AttSRU.dropout", "SRU_units.AttSRU.dropout", "SRU_units.AttSRU.preact_ln", "SRU_units.AttSRU.enc_ln", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "prev_layer.size", "SRU_units.AttSRU.dropout", "numpy.sqrt", "SRU_units.AttSRU.dropout", "SRU_units.AttSRU.dropout", "SRU_units.AttSRU.trans_h_ln", "SRU_units.AttSRU.trans_c_ln", "prev_layer.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "prev_layer", ",", "hidden", ",", "enc_output", ")", ":", "\n", "        ", "\"\"\"\n        :param prev_layer: targetL x batch x output_size\n        :param hidden: batch x output_size\n        :param enc_output: (targetL x batch) x sourceL x output_size\n        :return:\n        \"\"\"", "\n", "\n", "# targetL x batch x output_size", "\n", "preact", "=", "self", ".", "linear_in", "(", "self", ".", "dropout", "(", "prev_layer", ")", ")", "\n", "pctx", "=", "self", ".", "linear_enc", "(", "self", ".", "dropout", "(", "enc_output", ")", ")", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "preact", "=", "self", ".", "preact_ln", "(", "preact", ")", "\n", "pctx", "=", "self", ".", "enc_ln", "(", "pctx", ")", "\n", "#z = self.z_ln(z)", "\n", "#prev_layer_t = self.prev_layer_ln(prev_layer_t)", "\n", "#h_gate = self.h_gate_ln(h_gate)", "\n", "", "z", ",", "h_gate", ",", "prev_layer_t", "=", "preact", ".", "split", "(", "self", ".", "output_size", ",", "dim", "=", "-", "1", ")", "\n", "z", ",", "h_gate", "=", "F", ".", "sigmoid", "(", "z", ")", ",", "F", ".", "sigmoid", "(", "h_gate", ")", "\n", "\n", "ss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "prev_layer", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "s", "=", "(", "1.", "-", "z", "[", "i", "]", ")", "*", "hidden", "+", "z", "[", "i", "]", "*", "prev_layer_t", "[", "i", "]", "\n", "# targetL x batch x output_size", "\n", "ss", "+=", "[", "s", "]", "\n", "# batch x output_size", "\n", "hidden", "=", "s", "\n", "\n", "# (targetL x batch) x output_size", "\n", "", "ss", "=", "torch", ".", "stack", "(", "ss", ")", "\n", "attn_out", ",", "attn", "=", "self", ".", "attn", "(", "self", ".", "dropout", "(", "ss", ")", ",", "pctx", ",", "pctx", ")", "\n", "attn_out", "=", "attn_out", "/", "np", ".", "sqrt", "(", "self", ".", "output_size", ")", "\n", "\n", "trans_h", "=", "self", ".", "linear_hidden", "(", "self", ".", "dropout", "(", "ss", ")", ")", "\n", "trans_c", "=", "self", ".", "linear_ctx", "(", "self", ".", "dropout", "(", "attn_out", ")", ")", "\n", "if", "self", ".", "layer_norm", ":", "\n", "#out = self.post_ln(out)", "\n", "            ", "trans_h", "=", "self", ".", "trans_h_ln", "(", "trans_h", ")", "\n", "trans_c", "=", "self", ".", "trans_c_ln", "(", "trans_c", ")", "\n", "#trans_h, trans_c = F.tanh(trans_h), F.tanh(trans_c)", "\n", "", "out", "=", "trans_h", "+", "trans_c", "\n", "out", "=", "F", ".", "tanh", "(", "out", ")", "\n", "out", "=", "out", ".", "view", "(", "prev_layer", ".", "size", "(", ")", ")", "\n", "out", "=", "(", "1.", "-", "h_gate", ")", "*", "out", "+", "h_gate", "*", "prev_layer", "\n", "\n", "return", "out", ",", "hidden", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.BiSRU.__init__": [[91, 99], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "Normalization.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "layer_norm", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "BiSRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "3", "*", "output_size", ",", "bias", "=", "(", "not", "layer_norm", ")", ")", "\n", "self", ".", "layer_norm", "=", "layer_norm", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "self", ".", "preact_ln", "=", "LayerNorm", "(", "3", "*", "output_size", ")", "\n", "#self.x_f_ln = LayerNorm(output_size // 2)", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.BiSRU.initialize_parameters": [[105, 107], ["SRU_units.BiSRU.preact_ln.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "self", ".", "preact_ln", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.BiSRU.forward": [[108, 142], ["SRU_units.BiSRU.input_linear", "pre_act[].split", "torch.sigmoid().split", "torch.sigmoid().split", "torch.sigmoid().split", "x.split", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "SRU_units.BiSRU.dropout", "SRU_units.BiSRU.preact_ln", "h_f_pre.data.new().zero_", "h_f_pre.data.new().zero_", "input.size", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "h_f_pre.data.new", "h_f_pre.data.new", "gf[].size", "gf[].size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "pre_act", "=", "self", ".", "input_linear", "(", "self", ".", "dropout", "(", "input", ")", ")", "\n", "#h_gate = pre_act[:, :, 2*self.output_size:]", "\n", "#gf, gb, x_f, x_b = pre_act[:, :, :2*self.output_size].split(self.output_size // 2, dim=-1)", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "pre_act", "=", "self", ".", "preact_ln", "(", "pre_act", ")", "\n", "#x_f = self.x_f_ln(x_f)", "\n", "#x_b = self.x_b_ln(x_b)", "\n", "#gf = self.f_g_ln(gf)", "\n", "#gb = self.b_g_ln(gb)", "\n", "#h_gate = self.highway_ln(h_gate)", "\n", "", "h_gate", "=", "pre_act", "[", ":", ",", ":", ",", "2", "*", "self", ".", "output_size", ":", "]", "\n", "g", ",", "x", "=", "pre_act", "[", ":", ",", ":", ",", ":", "2", "*", "self", ".", "output_size", "]", ".", "split", "(", "self", ".", "output_size", ",", "dim", "=", "-", "1", ")", "\n", "gf", ",", "gb", "=", "F", ".", "sigmoid", "(", "g", ")", ".", "split", "(", "self", ".", "output_size", "//", "2", ",", "dim", "=", "-", "1", ")", "\n", "x_f", ",", "x_b", "=", "x", ".", "split", "(", "self", ".", "output_size", "//", "2", ",", "dim", "=", "-", "1", ")", "\n", "h_gate", "=", "F", ".", "sigmoid", "(", "h_gate", ")", "\n", "h_f_pre", "=", "gf", "*", "x_f", "\n", "h_b_pre", "=", "gb", "*", "x_b", "\n", "\n", "h_i_f", "=", "Variable", "(", "h_f_pre", ".", "data", ".", "new", "(", "gf", "[", "0", "]", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "h_i_b", "=", "Variable", "(", "h_f_pre", ".", "data", ".", "new", "(", "gf", "[", "0", "]", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "h_f", ",", "h_b", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "h_i_f", "=", "(", "1.", "-", "gf", "[", "i", "]", ")", "*", "h_i_f", "+", "h_f_pre", "[", "i", "]", "\n", "h_i_b", "=", "(", "1.", "-", "gb", "[", "-", "(", "i", "+", "1", ")", "]", ")", "*", "h_i_b", "+", "h_b_pre", "[", "-", "(", "i", "+", "1", ")", "]", "\n", "h_f", "+=", "[", "h_i_f", "]", "\n", "h_b", "+=", "[", "h_i_b", "]", "\n", "\n", "", "h", "=", "torch", ".", "cat", "(", "[", "torch", ".", "stack", "(", "h_f", ")", ",", "torch", ".", "stack", "(", "h_b", "[", ":", ":", "-", "1", "]", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output", "=", "(", "1.", "-", "h_gate", ")", "*", "h", "+", "input", "*", "h_gate", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.SRU.__init__": [[145, 153], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", ")", ":", "\n", "    ", "super", "(", "SRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "3", "*", "output_size", ")", "\n", "if", "input_size", "!=", "output_size", ":", "\n", "      ", "self", ".", "reduce", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ")", "\n", "", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.SRU.initialize_parameters": [[154, 156], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.SRU_units.SRU.forward": [[157, 186], ["SRU_units.SRU.linear_in", "torch.sigmoid().split", "torch.sigmoid().split", "torch.sigmoid().split", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "SRU_units.SRU.dropout", "SRU_units.SRU.size", "SRU_units.SRU.reduce", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "SRU_units.SRU.dropout"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "prev_layer", ",", "hidden", ")", ":", "\n", "    ", "\"\"\"\n    :param prev_layer: targetL x batch x output_size\n    :param hidden: batch x output_size\n    :return:\n    \"\"\"", "\n", "\n", "# targetL x batch x output_size", "\n", "preact", "=", "self", ".", "linear_in", "(", "self", ".", "dropout", "(", "prev_layer", ")", ")", "\n", "\n", "prev_layer_t", "=", "preact", "[", ":", ",", ":", ",", ":", "self", ".", "output_size", "]", "\n", "z", ",", "h_gate", "=", "F", ".", "sigmoid", "(", "preact", "[", ":", ",", ":", ",", "self", ".", "output_size", ":", "]", ")", ".", "split", "(", "self", ".", "output_size", ",", "dim", "=", "-", "1", ")", "\n", "\n", "ss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "prev_layer", ".", "size", "(", "0", ")", ")", ":", "\n", "      ", "s", "=", "(", "1", "-", "z", "[", "i", "]", ")", "*", "hidden", "+", "z", "[", "i", "]", "*", "prev_layer_t", "[", "i", "]", "\n", "# targetL x batch x output_size", "\n", "ss", "+=", "[", "s", "]", "\n", "# batch x output_size", "\n", "hidden", "=", "s", "\n", "\n", "# (targetL x batch) x output_size", "\n", "", "out", "=", "torch", ".", "stack", "(", "ss", ")", "\n", "if", "self", ".", "input_size", "!=", "self", ".", "output_size", ":", "\n", "      ", "prev_layer", "=", "self", ".", "reduce", "(", "self", ".", "dropout", "(", "prev_layer", ")", ")", "\n", "\n", "", "out", "=", "(", "1.", "-", "h_gate", ")", "*", "out", "+", "h_gate", "*", "prev_layer", "\n", "\n", "return", "out", ",", "hidden", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.ImageEncoder.ImageEncoder.__init__": [[9, 38], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "opt", ".", "layers", "\n", "self", ".", "num_directions", "=", "2", "if", "opt", ".", "brnn", "else", "1", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer5", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer6", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "batch_norm3", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "input_size", "=", "512", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "input_size", ",", "opt", ".", "rnn_size", ",", "\n", "num_layers", "=", "opt", ".", "layers", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "bidirectional", "=", "opt", ".", "brnn", ")", "\n", "self", ".", "pos_lut", "=", "nn", ".", "Embedding", "(", "1000", ",", "input_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.ImageEncoder.ImageEncoder.load_pretrained_vectors": [[39, 41], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.ImageEncoder.ImageEncoder.forward": [[42, 97], ["torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ImageEncoder.ImageEncoder.layer1", "ImageEncoder.ImageEncoder.layer2", "ImageEncoder.ImageEncoder.batch_norm1", "ImageEncoder.ImageEncoder.layer4", "ImageEncoder.ImageEncoder.batch_norm2", "ImageEncoder.ImageEncoder.batch_norm3", "torch.relu.size", "input[].transpose().transpose", "ImageEncoder.ImageEncoder.pos_lut", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ImageEncoder.ImageEncoder.rnn", "all_outputs.append", "ImageEncoder.ImageEncoder.layer3", "ImageEncoder.ImageEncoder.layer5", "ImageEncoder.ImageEncoder.layer6", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input[].transpose", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "ImageEncoder.ImageEncoder.view", "ImageEncoder.ImageEncoder.size", "ImageEncoder.ImageEncoder.size", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "input", "=", "input", "[", "0", "]", "\n", "batchSize", "=", "input", ".", "size", "(", "0", ")", "\n", "# (batch_size, 64, imgH, imgW)", "\n", "# layer 1", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "layer1", "(", "input", "[", ":", ",", ":", ",", ":", ",", ":", "]", "-", "0.5", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 64, imgH/2, imgW/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 128, imgH/2, imgW/2)", "\n", "# layer 2", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "layer2", "(", "input", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 128, imgH/2/2, imgW/2/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "#  (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer 3", "\n", "# batch norm 1", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "batch_norm1", "(", "self", ".", "layer3", "(", "input", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer4", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "layer4", "(", "input", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2/2, imgW/2/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "1", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2)", "\n", "# layer 5", "\n", "# batch norm 2", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "batch_norm2", "(", "self", ".", "layer5", "(", "input", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "2", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "batch_norm3", "(", "self", ".", "layer6", "(", "input", ")", ")", ",", "True", ")", "\n", "\n", "# # (batch_size, 512, H, W)", "\n", "# # (batch_size, H, W, 512)", "\n", "all_outputs", "=", "[", "]", "\n", "for", "row", "in", "range", "(", "input", ".", "size", "(", "2", ")", ")", ":", "\n", "            ", "inp", "=", "input", "[", ":", ",", ":", ",", "row", ",", ":", "]", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "pos_emb", "=", "self", ".", "pos_lut", "(", "\n", "Variable", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "batchSize", ")", ".", "fill_", "(", "row", ")", ")", ")", "\n", "with_pos", "=", "torch", ".", "cat", "(", "\n", "(", "pos_emb", ".", "view", "(", "1", ",", "pos_emb", ".", "size", "(", "0", ")", ",", "pos_emb", ".", "size", "(", "1", ")", ")", ",", "inp", ")", ",", "0", ")", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "with_pos", ")", "\n", "all_outputs", ".", "append", "(", "outputs", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "all_outputs", ",", "0", ")", "\n", "\n", "return", "hidden_t", ",", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.DotAttention.__init__": [[41, 51], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "Normalization.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "enc_dim", "=", "None", ",", "layer_norm", "=", "False", ",", "activ", "=", "'tanh'", ")", ":", "\n", "        ", "super", "(", "DotAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask", "=", "None", "\n", "if", "not", "enc_dim", ":", "\n", "            ", "enc_dim", "=", "dim", "\n", "", "out_dim", "=", "dim", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "out_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "layer_norm", "=", "layer_norm", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "self", ".", "ln_in", "=", "LayerNorm", "(", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.DotAttention.applyMask": [[52, 54], ["None"], "methods", ["None"], ["", "", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.DotAttention.initialize_parameters": [[55, 57], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.DotAttention.forward": [[58, 75], ["context.transpose.transpose.size", "Attention.DotAttention.ln_in", "context.transpose.transpose.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.view", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "Attention.DotAttention.linear_in", "torch.softmax.data.masked_fill_", "torch.softmax.view", "input.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "float"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "values", ")", ":", "\n", "        ", "\"\"\"\n        input: targetL x batch x dim\n        context: batch x sourceL x dim\n        \"\"\"", "\n", "batch", ",", "sourceL", ",", "dim", "=", "context", ".", "size", "(", ")", "\n", "targetT", "=", "self", ".", "ln_in", "(", "self", ".", "linear_in", "(", "input", ".", "transpose", "(", "0", ",", "1", ")", ")", ")", "# batch x targetL x dim", "\n", "context", "=", "context", ".", "transpose", "(", "1", ",", "2", ")", "# batch x dim x sourceL", "\n", "# Get attention", "\n", "attn", "=", "torch", ".", "bmm", "(", "targetT", ",", "context", ")", "# batch x targetL x sourceL", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "attn", "=", "F", ".", "softmax", "(", "attn", ".", "view", "(", "-", "1", ",", "sourceL", ")", ")", "# (batch x targetL) x sourceL", "\n", "attn3", "=", "attn", ".", "view", "(", "batch", ",", "-", "1", ",", "sourceL", ")", "# batch x targetL x sourceL", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "attn3", ",", "values", ")", ".", "transpose", "(", "0", ",", "1", ")", "# targetL x batch x dim", "\n", "\n", "return", "weightedContext", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttention.__init__": [[78, 90], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "getattr", "Normalization.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "layer_norm", "=", "False", ",", "activ", "=", "'tanh'", ")", ":", "\n", "        ", "super", "(", "MLPAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "self", ".", "dim", ",", "1", ")", "\n", "self", ".", "combine_hid", "=", "nn", ".", "Linear", "(", "self", ".", "dim", ",", "self", ".", "dim", ")", "\n", "#self.combine_ctx = nn.Linear(self.dim, self.dim)", "\n", "self", ".", "mask", "=", "None", "\n", "self", ".", "activ", "=", "getattr", "(", "F", ",", "activ", ")", "\n", "self", ".", "layer_norm", "=", "layer_norm", "\n", "if", "layer_norm", ":", "\n", "#self.ctx_ln = LayerNorm(dim)", "\n", "            ", "self", ".", "hidden_ln", "=", "LayerNorm", "(", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttention.applyMask": [[91, 93], ["None"], "methods", ["None"], ["", "", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttention.initialize_parameters": [[94, 96], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttention.forward": [[98, 150], ["Attention.MLPAttention.size", "Attention.MLPAttention.size", "context.repeat.repeat.size", "Attention.MLPAttention.size", "Attention.MLPAttention.combine_hid", "context.repeat.repeat.repeat", "Attention.MLPAttention.transpose().repeat().contiguous().view", "Attention.MLPAttention.activ", "Attention.MLPAttention.v", "torch.softmax.contiguous().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.contiguous().view", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "Attention.MLPAttention.hidden_ln", "torch.softmax.data.masked_fill_", "Attention.MLPAttention.transpose().repeat().contiguous", "torch.softmax.contiguous", "torch.softmax.contiguous", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "float", "Attention.MLPAttention.transpose().repeat", "Attention.MLPAttention.transpose"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "values", ")", ":", "\n", "        ", "\"\"\"\n        input: targetL x batch x dim\n        context: batch x sourceL x dim\n        values: batch x sourceL x dim\n\n        Output:\n\n        output: batch x hidden_size\n        w: batch x sourceL\n        \"\"\"", "\n", "targetL", "=", "input", ".", "size", "(", "0", ")", "\n", "output_size", "=", "input", ".", "size", "(", "2", ")", "\n", "sourceL", "=", "context", ".", "size", "(", "1", ")", "\n", "batch_size", "=", "input", ".", "size", "(", "1", ")", "\n", "\n", "# targetL x batch x dim", "\n", "input", "=", "self", ".", "combine_hid", "(", "input", ")", "\n", "# (targetL x batch) x dim", "\n", "#context = self.combine_ctx(context)", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "input", "=", "self", ".", "hidden_ln", "(", "input", ")", "\n", "#context = self.ctx_ln(context)", "\n", "\n", "# batch x (sourceL x targetL) x dim", "\n", "", "context", "=", "context", ".", "repeat", "(", "1", ",", "targetL", ",", "1", ")", "\n", "\n", "# batch x targetL x dim -> batch x (targetL x sourceL) x dim", "\n", "input", "=", "input", ".", "transpose", "(", "0", ",", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "sourceL", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "output_size", ")", "\n", "#context = context.view(batch_size, -1, output_size)", "\n", "# batch x (targetL x sourceL) x dim", "\n", "combined", "=", "self", ".", "activ", "(", "input", "+", "context", ")", "\n", "\n", "# batch x (targetL x sourceL) x 1", "\n", "attn", "=", "self", ".", "v", "(", "combined", ")", "\n", "\n", "# (batch_size x targetL) x sourceL", "\n", "attn", "=", "attn", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "targetL", ",", "sourceL", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# (batch_size x targetL) x sourceL", "\n", "", "attn", "=", "F", ".", "softmax", "(", "attn", ")", "\n", "\n", "# batch_size x targetL x sourceL", "\n", "attn3", "=", "attn", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "targetL", ",", "sourceL", ")", "\n", "\n", "# batch x targetL x dim -> targetL x batch x dim", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "attn3", ",", "values", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "weightedContext", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttentionGRU.__init__": [[152, 164], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "getattr", "Normalization.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["     ", "def", "__init__", "(", "self", ",", "dim", ",", "layer_norm", "=", "False", ",", "activ", "=", "'tanh'", ")", ":", "\n", "         ", "super", "(", "MLPAttentionGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "self", ".", "dim", ",", "1", ")", "\n", "self", ".", "combine_hid", "=", "nn", ".", "Linear", "(", "self", ".", "dim", ",", "self", ".", "dim", ")", "\n", "# self.combine_ctx = nn.Linear(self.dim, self.dim)", "\n", "self", ".", "mask", "=", "None", "\n", "self", ".", "activ", "=", "getattr", "(", "F", ",", "activ", ")", "\n", "self", ".", "layer_norm", "=", "layer_norm", "\n", "if", "layer_norm", ":", "\n", "# self.ctx_ln = LayerNorm(dim)", "\n", "             ", "self", ".", "hidden_ln", "=", "LayerNorm", "(", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttentionGRU.applyMask": [[165, 167], ["None"], "methods", ["None"], ["", "", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "         ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttentionGRU.initialize_parameters": [[168, 170], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "         ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.MLPAttentionGRU.forward": [[171, 215], ["context.size", "Attention.MLPAttentionGRU.size", "Attention.MLPAttentionGRU.combine_hid", "Attention.MLPAttentionGRU.unsqueeze().expand_as", "Attention.MLPAttentionGRU.activ", "Attention.MLPAttentionGRU.v", "torch.softmax.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.unsqueeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "Attention.MLPAttentionGRU.hidden_ln", "torch.softmax.data.masked_fill_", "Attention.MLPAttentionGRU.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "float"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "values", ")", ":", "\n", "         ", "\"\"\"\n         input: batch x dim\n         context: batch x sourceL x dim\n         values: batch x sourceL x dim\n\n         Output:\n\n         output: batch x hidden_size\n         w: batch x sourceL\n         \"\"\"", "\n", "sourceL", "=", "context", ".", "size", "(", "1", ")", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "\n", "# batch x dim", "\n", "input", "=", "self", ".", "combine_hid", "(", "input", ")", "\n", "\n", "if", "self", ".", "layer_norm", ":", "\n", "             ", "input", "=", "self", ".", "hidden_ln", "(", "input", ")", "\n", "\n", "# batch x sourceL x dim", "\n", "", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "context", ")", "\n", "# batch x sourceL x dim", "\n", "combined", "=", "self", ".", "activ", "(", "input", "+", "context", ")", "\n", "\n", "# batch x sourceL x 1", "\n", "attn", "=", "self", ".", "v", "(", "combined", ")", "\n", "\n", "# batch_size x sourceL", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", ",", "sourceL", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "             ", "attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# batch_size x sourceL", "\n", "", "attn", "=", "F", ".", "softmax", "(", "attn", ")", "\n", "\n", "# batch_size x 1 x sourceL", "\n", "attn3", "=", "attn", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# batch x dim", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "attn3", ",", "values", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "weightedContext", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.SelfAttention.__init__": [[219, 226], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "k_size", ",", "q_size", ",", "v_size", ",", "out_size", ")", ":", "\n", "        ", "super", "(", "SelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linearK", "=", "nn", ".", "Linear", "(", "v_size", ",", "out_size", ")", "\n", "self", ".", "linearQ", "=", "nn", ".", "Linear", "(", "q_size", ",", "out_size", ")", "\n", "self", ".", "linearV", "=", "nn", ".", "Linear", "(", "v_size", ",", "out_size", ")", "\n", "self", ".", "dim", "=", "out_size", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.SelfAttention.applyMask": [[227, 229], ["None"], "methods", ["None"], ["", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.SelfAttention.forward": [[230, 250], ["Attention.SelfAttention.linearK", "Attention.SelfAttention.linearQ", "Attention.SelfAttention.linearV", "dot_prod.sum", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.unsqueeze", "Attention.SelfAttention.bmm", "torch.softmax.data.masked_fill_", "Attention.SelfAttention.transpose", "numpy.sqrt", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "values", ")", ":", "\n", "        ", "\"\"\"\n        input: batch x targetL x dim\n        context: batch x sourceL x dim\n        values: batch x sourceL x dim\n        \"\"\"", "\n", "K", "=", "self", ".", "linearK", "(", "input", ")", "# batch x targetL x out_size", "\n", "Q", "=", "self", ".", "linearQ", "(", "context", ")", "# batch x sourceL x out_size", "\n", "V", "=", "self", ".", "linearV", "(", "values", ")", "# batch x sourceL x out_size", "\n", "\n", "dot_prod", "=", "K", ".", "bmm", "(", "Q", ".", "transpose", "(", "1", ",", "2", ")", ")", "*", "(", "1", "/", "np", ".", "sqrt", "(", "self", ".", "dim", ")", ")", "# batch x targetL x sourceL", "\n", "\n", "attn", "=", "dot_prod", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "# batch x sourceL", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "attn", "=", "F", ".", "softmax", "(", "attn", ")", "# batch x sourceL", "\n", "attn3", "=", "attn", ".", "unsqueeze", "(", "2", ")", "# batch x sourceL x 1", "\n", "weightedContext", "=", "V", "*", "attn3", "# batch x sourceL x out_size", "\n", "\n", "return", "weightedContext", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Attention.getAttention": [[29, 38], ["NotImplementedError"], "function", ["None"], ["def", "getAttention", "(", "attention_type", ")", ":", "\n", "    ", "attns", "=", "{", "'dot'", ":", "DotAttention", ",", "\n", "'mlp'", ":", "MLPAttentionGRU", ",", "\n", "}", "\n", "\n", "if", "attention_type", "not", "in", "attns", ":", "\n", "        ", "raise", "NotImplementedError", "(", "attention_type", ")", "\n", "\n", "", "return", "attns", "[", "attention_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Normalization.LayerNorm.__init__": [[6, 11], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Normalization.LayerNorm.forward": [[12, 16], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "(", "self", ".", "gamma", "/", "(", "std", "+", "self", ".", "eps", ")", ")", "*", "(", "x", "-", "mean", ")", "+", "self", ".", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Normalization.LayerNorm.initialize_parameters": [[17, 20], ["Normalization.LayerNorm.gamma.data.fill_", "Normalization.LayerNorm.beta.data.fill_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "        ", "self", ".", "gamma", ".", "data", ".", "fill_", "(", "1.", ")", "\n", "self", ".", "beta", ".", "data", ".", "fill_", "(", "0.", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__": [[13, 32], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "range", "torch.ModuleList", "torch.ModuleList", "Units.ParallelMyRNN.rnns[].append", "range", "Units.ParallelMyRNN.unit"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", ")", ":", "\n", "    ", "super", "(", "ParallelMyRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "unit", "=", "SRU", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "rnn_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "self", ".", "rnn_size", "*", "self", ".", "num_directions", "\n", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", ")", "for", "_", "in", "range", "(", "self", ".", "num_directions", ")", "]", ")", "\n", "\n", "# for layer in range(num_layers):", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "      ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "self", ".", "hidden_size", "\n", "for", "direction", "in", "range", "(", "self", ".", "num_directions", ")", ":", "\n", "        ", "self", ".", "rnns", "[", "direction", "]", ".", "append", "(", "self", ".", "unit", "(", "layer_input_size", ",", "self", ".", "rnn_size", ",", "self", ".", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.reset_parameters": [[33, 37], ["Units.ParallelMyRNN.parameters", "math.sqrt", "weight.data.uniform_"], "methods", ["None"], ["", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "    ", "stdv", "=", "1.0", "/", "math", ".", "sqrt", "(", "self", ".", "rnn_size", ")", "\n", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "      ", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters": [[38, 42], ["range", "layer.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.initialize_parameters"], ["", "", "def", "initialize_parameters", "(", "self", ",", "param_init", ")", ":", "\n", "    ", "for", "direction", "in", "range", "(", "self", ".", "num_directions", ")", ":", "\n", "      ", "for", "layer", "in", "self", ".", "rnns", "[", "direction", "]", ":", "\n", "        ", "layer", ".", "initialize_parameters", "(", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.reverse_tensor": [[43, 49], ["torch.autograd.Variable", "torch.autograd.Variable", "x.index_select", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "idx.cuda.cuda.cuda", "range", "x.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "", "", "def", "reverse_tensor", "(", "self", ",", "x", ",", "dim", ")", ":", "\n", "    ", "idx", "=", "[", "i", "for", "i", "in", "range", "(", "x", ".", "size", "(", "dim", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", "]", "\n", "idx", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "idx", ")", ")", "\n", "if", "x", ".", "is_cuda", ":", "\n", "      ", "idx", "=", "idx", ".", "cuda", "(", ")", "\n", "", "return", "x", ".", "index_select", "(", "dim", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.forward": [[50, 102], ["isinstance", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "hidden.cuda.cuda.cuda", "Units.ParallelMyRNN.Dropout", "unit", "Units.ParallelMyRNN.Dropout", "Units.ParallelMyRNN.Dropout", "unit_forward", "Units.ParallelMyRNN.compute_backwards", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gru_out.append", "gru_out.append", "gru_out.append", "output_forward[].unsqueeze", "output_backward[].unsqueeze", "input.data.new", "input.size"], "methods", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.compute_backwards", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", "=", "None", ")", ":", "\n", "\n", "    ", "is_packed", "=", "isinstance", "(", "input", ",", "PackedSequence", ")", "\n", "if", "is_packed", ":", "\n", "      ", "input", ",", "batch_sizes", "=", "unpack", "(", "input", ")", "\n", "max_batch_size", "=", "batch_sizes", "[", "0", "]", "\n", "\n", "", "if", "hidden", "is", "None", ":", "\n", "# (num_layers x num_directions) x batch_size x rnn_size", "\n", "      ", "hidden", "=", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "\n", "self", ".", "num_directions", ",", "\n", "input", ".", "size", "(", "1", ")", ",", "\n", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "if", "input", ".", "is_cuda", ":", "\n", "        ", "hidden", "=", "hidden", ".", "cuda", "(", ")", "\n", "\n", "", "", "gru_out", "=", "[", "]", "\n", "_input", "=", "input", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "      ", "if", "not", "self", ".", "bidirectional", ":", "\n", "        ", "prev_layer", "=", "self", ".", "Dropout", "(", "_input", ")", "\n", "h", "=", "hidden", "[", "i", "]", "# batch_size x rnn_size", "\n", "unit", "=", "self", ".", "rnns", "[", "0", "]", "[", "i", "]", "# Computation unit", "\n", "\n", "layer_out", ",", "hid_uni", "=", "unit", "(", "prev_layer", ",", "h", ")", "# src_len x batch x hidden_size", "\n", "\n", "", "else", ":", "\n", "        ", "input_forward", "=", "self", ".", "Dropout", "(", "_input", ")", "\n", "input_backward", "=", "self", ".", "Dropout", "(", "_input", ")", "\n", "h_forward", "=", "hidden", "[", "i", "*", "self", ".", "num_directions", "]", "# batch_size x rnn_size", "\n", "h_backward", "=", "hidden", "[", "i", "*", "self", ".", "num_directions", "+", "1", "]", "# batch_size x rnn_size", "\n", "unit_forward", "=", "self", ".", "rnns", "[", "0", "]", "[", "i", "]", "# Computation unit", "\n", "unit_backward", "=", "self", ".", "rnns", "[", "1", "]", "[", "i", "]", "# Computation unit", "\n", "\n", "output_forward", ",", "h_forward", "=", "unit_forward", "(", "input_forward", ",", "h_forward", ")", "\n", "output_backward", ",", "h_backward", "=", "self", ".", "compute_backwards", "(", "unit_backward", ",", "input_backward", ",", "h_backward", ")", "\n", "\n", "layer_out", "=", "torch", ".", "cat", "(", "[", "output_forward", ",", "output_backward", "]", ",", "dim", "=", "2", ")", "# src_len x batch x hidden_size", "\n", "\n", "", "_input", "=", "layer_out", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "        ", "gru_out", ".", "append", "(", "output_forward", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "gru_out", ".", "append", "(", "output_backward", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", ")", "# num_directions x [batch x rnn_size]", "\n", "", "else", ":", "\n", "        ", "gru_out", ".", "append", "(", "layer_out", ")", "\n", "\n", "", "", "hidden", "=", "torch", ".", "cat", "(", "gru_out", ",", "dim", "=", "0", ")", "# (num_layers x num_directions) x batch x rnn_size", "\n", "\n", "output", "=", "_input", "\n", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.__repr__": [[103, 113], ["s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "    ", "s", "=", "'{name}({input_size}, {rnn_size}'", "\n", "if", "self", ".", "num_layers", "!=", "1", ":", "\n", "      ", "s", "+=", "', num_layers={num_layers}'", "\n", "", "if", "self", ".", "dropout", "!=", "0", ":", "\n", "      ", "s", "+=", "', dropout={dropout}'", "\n", "", "if", "self", ".", "bidirectional", "is", "not", "False", ":", "\n", "      ", "s", "+=", "', bidirectional={bidirectional}'", "\n", "", "s", "+=", "')'", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.modules.Units.ParallelMyRNN.compute_backwards": [[114, 120], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "unit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input.split", "torch.cat.split", "torch.cat.split"], "methods", ["None"], ["", "def", "compute_backwards", "(", "self", ",", "unit", ",", "input", ",", "hidden", ")", ":", "\n", "    ", "h", "=", "hidden", "\n", "steps", "=", "torch", ".", "cat", "(", "input", ".", "split", "(", "1", ",", "dim", "=", "0", ")", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "0", ")", "\n", "out", ",", "hidden", "=", "unit", "(", "steps", ",", "h", ")", "\n", "out", "=", "torch", ".", "cat", "(", "out", ".", "split", "(", "1", ",", "dim", "=", "0", ")", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "0", ")", "\n", "return", "out", ",", "hidden", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.tools.extract_embeddings.write_embeddings": [[19, 26], ["open", "range", "len", "dict.idxToLabel[].encode", "range", "file.write", "len"], "function", ["None"], ["def", "write_embeddings", "(", "filename", ",", "dict", ",", "embeddings", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "embeddings", ")", ")", ":", "\n", "            ", "str", "=", "dict", ".", "idxToLabel", "[", "i", "]", ".", "encode", "(", "\"utf-8\"", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "embeddings", "[", "0", "]", ")", ")", ":", "\n", "                ", "str", "=", "str", "+", "\" %5f\"", "%", "(", "embeddings", "[", "i", "]", "[", "j", "]", ")", "\n", "", "file", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattiadg_SR-NMT.tools.extract_embeddings.main": [[28, 54], ["parser.parse_args", "torch.load", "onmt.Models.Encoder", "onmt.Models.Encoder", "onmt.Models.Decoder", "onmt.Models.Decoder", "onmt.Models.Encoder.word_lut.weight.data.tolist", "onmt.Models.Decoder.word_lut.weight.data.tolist", "print", "extract_embeddings.write_embeddings", "print", "extract_embeddings.write_embeddings", "print", "print", "torch.cuda.set_device"], "function", ["home.repos.pwc.inspect_result.mattiadg_SR-NMT.tools.extract_embeddings.write_embeddings", "home.repos.pwc.inspect_result.mattiadg_SR-NMT.tools.extract_embeddings.write_embeddings"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "src_dict", "=", "checkpoint", "[", "'dicts'", "]", "[", "'src'", "]", "\n", "tgt_dict", "=", "checkpoint", "[", "'dicts'", "]", "[", "'tgt'", "]", "\n", "\n", "encoder", "=", "onmt", ".", "Models", ".", "Encoder", "(", "model_opt", ",", "src_dict", ")", "\n", "decoder", "=", "onmt", ".", "Models", ".", "Decoder", "(", "model_opt", ",", "tgt_dict", ")", "\n", "encoder_embeddings", "=", "encoder", ".", "word_lut", ".", "weight", ".", "data", ".", "tolist", "(", ")", "\n", "decoder_embeddings", "=", "decoder", ".", "word_lut", ".", "weight", ".", "data", ".", "tolist", "(", ")", "\n", "\n", "print", "(", "\"Writing source embeddings\"", ")", "\n", "write_embeddings", "(", "opt", ".", "output_dir", "+", "\"/src_embeddings.txt\"", ",", "src_dict", ",", "\n", "encoder_embeddings", ")", "\n", "\n", "print", "(", "\"Writing target embeddings\"", ")", "\n", "write_embeddings", "(", "opt", ".", "output_dir", "+", "\"/tgt_embeddings.txt\"", ",", "tgt_dict", ",", "\n", "decoder_embeddings", ")", "\n", "\n", "print", "(", "'... done.'", ")", "\n", "print", "(", "'Converting model...'", ")", "\n", "\n"]]}