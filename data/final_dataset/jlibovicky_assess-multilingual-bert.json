{"home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment_embeddings.load_data": [[18, 41], ["print", "utils.load_word_embeddings", "print", "utils.word_embeddings_for_file", "print", "print", "utils.load_word_embeddings", "print", "utils.word_embeddings_for_file", "print", "print", "word_alignment.center", "word_alignment.center"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center"], ["def", "load_data", "(", "\n", "src", ",", "tgt", ",", "src_emb", ",", "tgt_emb", ",", "src_lng", ",", "tgt_lng", ",", "center_lng", ")", ":", "\n", "    ", "print", "(", "f\"Loading src: {src} ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "src_embeddings", "=", "load_word_embeddings", "(", "src_emb", ")", "\n", "print", "(", "\" embeddings ... \"", ",", "end", "=", "\"\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "src_repr", "=", "word_embeddings_for_file", "(", "\n", "src", ",", "src_embeddings", ",", "src_lng", ",", "mean_pool", "=", "False", ",", "\n", "skip_tokenization", "=", "True", ")", "\n", "print", "(", "\"Done\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "print", "(", "f\"Loading tgt: {tgt} ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "tgt_embeddings", "=", "load_word_embeddings", "(", "tgt_emb", ")", "\n", "print", "(", "\" embeddings ... \"", ",", "end", "=", "\"\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "tgt_repr", "=", "word_embeddings_for_file", "(", "\n", "tgt", ",", "tgt_embeddings", ",", "tgt_lng", ",", "mean_pool", "=", "False", ",", "\n", "skip_tokenization", "=", "True", ")", "\n", "print", "(", "\"Done\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "if", "center_lng", ":", "\n", "        ", "print", "(", "\"Centering data.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "src_repr", ",", "tgt_repr", "=", "center", "(", "src_repr", ")", ",", "center", "(", "tgt_repr", ")", "\n", "\n", "", "return", "src_repr", ",", "tgt_repr", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment_embeddings.main": [[43, 94], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "print", "word_alignment_embeddings.load_data", "zip", "word_alignment.align", "enumerate", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.load_data", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.align"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"tgt\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"tgt_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"tgt_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, center representations first.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reordering-penalty\"", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Penalty for long-distance alignment added to cost.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, print the actual alignment.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-projection\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Location to save the word projection.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "\n", "proj", "=", "None", "\n", "\n", "print", "(", "\"Loading test data.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "src_repr", ",", "tgt_repr", "=", "load_data", "(", "\n", "args", ".", "src", ",", "args", ".", "tgt", ",", "args", ".", "src_emb", ",", "args", ".", "tgt_emb", ",", "\n", "args", ".", "src_lng", ",", "args", ".", "tgt_lng", ",", "args", ".", "center_lng", ")", "\n", "\n", "for", "(", "src_mat", ",", "src_tok", ")", ",", "(", "tgt_mat", ",", "tgt_tok", ")", "in", "zip", "(", "src_repr", ",", "tgt_repr", ")", ":", "\n", "        ", "alignment", "=", "align", "(", "src_mat", ",", "tgt_mat", ",", "args", ".", "reordering_penalty", ",", "proj", ")", "\n", "\n", "if", "args", ".", "verbose", ":", "\n", "            ", "for", "i", ",", "token", "in", "enumerate", "(", "src_tok", ")", ":", "\n", "                ", "aligned_indices", "=", "[", "tix", "for", "six", ",", "tix", "in", "alignment", "if", "six", "==", "i", "]", "\n", "aligned_formatted", "=", "[", "\n", "f\"{tgt_tok[j]} ({j})\"", "for", "j", "in", "aligned_indices", "]", "\n", "print", "(", "f\"{i:2d}: {token} -- {', '.join(aligned_formatted)}\"", ")", "\n", "", "print", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\" \"", ".", "join", "(", "\n", "f\"{src_id}-{tgt_id}\"", "for", "src_id", ",", "tgt_id", "in", "alignment", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.eval_cluster_vs_families.compute_homogenity": [[19, 26], ["max", "homogenities.append", "sum", "len", "sum", "len"], "function", ["None"], ["def", "compute_homogenity", "(", "classes1", ",", "classes2", ")", ":", "\n", "    ", "homogenities", "=", "[", "]", "\n", "for", "group", "in", "classes1", ":", "\n", "        ", "max_in_second", "=", "max", "(", "\n", "sum", "(", "x", "in", "group2", "for", "x", "in", "group", ")", "for", "group2", "in", "classes2", ")", "\n", "homogenities", ".", "append", "(", "max_in_second", "/", "len", "(", "group", ")", ")", "\n", "", "return", "sum", "(", "homogenities", ")", "/", "len", "(", "homogenities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.eval_cluster_vs_families.score": [[28, 42], ["numpy.array", "scipy.optimize.linear_sum_assignment", "numpy.mean", "np.array.append", "len", "group1.intersection", "row.append", "row.append", "len", "len"], "function", ["None"], ["", "def", "score", "(", "classes1", ",", "classes2", ")", ":", "\n", "    ", "mutual_scores", "=", "[", "]", "\n", "for", "group1", "in", "classes1", ":", "\n", "        ", "row", "=", "[", "]", "\n", "for", "group2", "in", "classes2", ":", "\n", "            ", "in_both", "=", "len", "(", "group1", ".", "intersection", "(", "group2", ")", ")", "\n", "if", "in_both", "==", "0", ":", "\n", "                ", "row", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "row", ".", "append", "(", "2", "*", "in_both", "/", "(", "len", "(", "group1", ")", "+", "len", "(", "group2", ")", ")", ")", "\n", "", "", "mutual_scores", ".", "append", "(", "row", ")", "\n", "", "mutual_scores", "=", "np", ".", "array", "(", "mutual_scores", ")", "\n", "mapping", "=", "linear_sum_assignment", "(", "1", "-", "mutual_scores", ")", "\n", "return", "np", ".", "mean", "(", "mutual_scores", "[", "mapping", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.eval_cluster_vs_families.main": [[44, 80], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "numpy.load", "collections.defaultdict", "LNG_INFO.items", "scipy.linkage", "scipy.fcluster", "eval_cluster_vs_families.compute_homogenity", "eval_cluster_vs_families.compute_homogenity", "print", "print", "print", "families_dict[].append", "set", "set", "len", "set", "argparse.FileType", "collections.defaultdict.values", "enumerate", "[].tolist", "range", "len", "len", "numpy.where"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.eval_cluster_vs_families.compute_homogenity", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.eval_cluster_vs_families.compute_homogenity"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"centroids\"", ",", "type", "=", "argparse", ".", "FileType", "(", "'rb'", ")", ",", "\n", "help", "=", "\".npz file with saved centroids.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "np_file", "=", "np", ".", "load", "(", "args", ".", "centroids", ")", "\n", "languages", "=", "np_file", "[", "\"languages\"", "]", "\n", "centroids", "=", "np_file", "[", "\"centroids\"", "]", "\n", "\n", "families_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "lng", ",", "info", "in", "LNG_INFO", ".", "items", "(", ")", ":", "\n", "        ", "families_dict", "[", "info", "[", "\"genus\"", "]", "]", ".", "append", "(", "lng", ")", "\n", "", "families", "=", "[", "\n", "set", "(", "family", ")", "for", "family", "in", "families_dict", ".", "values", "(", ")", "if", "len", "(", "family", ")", ">", "2", "]", "\n", "\n", "interesting_languages", "=", "[", "lng", "for", "family", "in", "families", "for", "lng", "in", "family", "]", "\n", "lng2idx", "=", "{", "lng", ":", "i", "for", "i", ",", "lng", "in", "enumerate", "(", "interesting_languages", ")", "}", "\n", "centroids", "=", "centroids", "[", "[", "l", "in", "interesting_languages", "for", "l", "in", "languages", "]", "]", "\n", "family_idx", "=", "[", "set", "(", "lng2idx", "[", "lng", "]", "for", "lng", "in", "family", ")", "for", "family", "in", "families", "]", "\n", "\n", "tree", "=", "hac", ".", "linkage", "(", "centroids", ",", "method", "=", "'single'", ",", "metric", "=", "'cosine'", ")", "\n", "clustered", "=", "hac", ".", "fcluster", "(", "tree", ",", "len", "(", "families", ")", ",", "criterion", "=", "'maxclust'", ")", "\n", "\n", "clusters", "=", "[", "\n", "set", "(", "np", ".", "where", "(", "clustered", "==", "i", ")", "[", "0", "]", ".", "tolist", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "families", ")", "+", "1", ")", "]", "\n", "\n", "homogenity", "=", "compute_homogenity", "(", "clusters", ",", "family_idx", ")", "\n", "completeness", "=", "compute_homogenity", "(", "family_idx", ",", "clusters", ")", "\n", "v_measure", "=", "2", "*", "homogenity", "*", "completeness", "/", "(", "homogenity", "+", "completeness", ")", "\n", "\n", "print", "(", "f\"Homogenity:   {100 * homogenity:.2f}\"", ")", "\n", "print", "(", "f\"Completeness: {100 * completeness:.2f}\"", ")", "\n", "print", "(", "f\"V-Measure:    {100 * v_measure:.2f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_confusion_matrix.main": [[13, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "sklearn.metrics.confusion_matrix", "matplotlib.subplots", "ax1.imshow", "fig.colorbar", "ax1.set_ylim", "ax1.set_xticks", "ax1.set_yticks", "ax1.set_xticklabels", "ax1.set_yticklabels", "ax1.set_xticks", "ax1.set_yticks", "ax1.yaxis.grid", "ax1.xaxis.grid", "ax2.imshow", "fig.colorbar", "ax2.set_ylim", "ax2.set_xticks", "ax2.set_yticks", "ax2.set_xticklabels", "ax2.set_yticklabels", "ax2.set_xticks", "ax2.set_yticks", "ax2.yaxis.grid", "ax2.xaxis.grid", "matplotlib.tight_layout", "matplotlib.savefig", "line.strip", "numpy.ma.array", "numpy.arange", "numpy.arange", "numpy.ma.array", "numpy.arange", "numpy.arange", "argparse.FileType", "argparse.FileType", "argparse.FileType", "enumerate", "len", "len", "numpy.arange", "numpy.arange", "len", "len", "numpy.arange", "numpy.arange", "line.strip", "line.strip", "numpy.eye", "len", "len", "len", "len", "numpy.eye"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"languages\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "help", "=", "\"List of languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_data\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "help", "=", "\"Tab-separated test data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"predictions\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "help", "=", "\"Predictions made by the model.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "languages", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "args", ".", "languages", "]", "\n", "lng2idx", "=", "{", "lng", ":", "i", "for", "i", ",", "lng", "in", "enumerate", "(", "languages", ")", "}", "\n", "\n", "true_labels", "=", "[", "\n", "lng2idx", "[", "line", ".", "strip", "(", ")", "]", "for", "line", "in", "args", ".", "test_data", "]", "\n", "predicted_labels", "=", "[", "\n", "lng2idx", "[", "line", ".", "strip", "(", ")", "]", "for", "line", "in", "args", ".", "predictions", "]", "\n", "\n", "matrix", "=", "confusion_matrix", "(", "true_labels", ",", "predicted_labels", ")", "\n", "\n", "fig", ",", "(", "ax1", ",", "ax2", ")", "=", "plt", ".", "subplots", "(", "1", ",", "2", ",", "figsize", "=", "(", "20", ",", "10", ")", ")", "\n", "\n", "#im = ax.matshow(matrix)", "\n", "im1", "=", "ax1", ".", "imshow", "(", "np", ".", "ma", ".", "array", "(", "matrix", ",", "mask", "=", "np", ".", "eye", "(", "matrix", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "fig", ".", "colorbar", "(", "im1", ",", "ax", "=", "ax1", ",", "orientation", "=", "\"horizontal\"", ",", "fraction", "=", "0.046", ",", "pad", "=", "0.04", ")", "\n", "ax1", ".", "set_ylim", "(", "-", "0.5", ",", "matrix", ".", "shape", "[", "1", "]", "-", "0.5", ")", "\n", "\n", "ax1", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", ",", "minor", "=", "False", ")", "\n", "ax1", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", ",", "minor", "=", "False", ")", "\n", "ax1", ".", "set_xticklabels", "(", "languages", ")", "\n", "ax1", ".", "set_yticklabels", "(", "languages", ")", "\n", "\n", "ax1", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", "+", "0.5", ",", "minor", "=", "True", ")", "\n", "ax1", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", "+", "0.5", ",", "minor", "=", "True", ")", "\n", "ax1", ".", "yaxis", ".", "grid", "(", "True", ",", "which", "=", "'minor'", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "1", ")", "\n", "ax1", ".", "xaxis", ".", "grid", "(", "True", ",", "which", "=", "'minor'", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "1", ")", "\n", "\n", "im2", "=", "ax2", ".", "imshow", "(", "np", ".", "ma", ".", "array", "(", "matrix", ",", "mask", "=", "1", "-", "np", ".", "eye", "(", "matrix", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "fig", ".", "colorbar", "(", "im2", ",", "ax", "=", "ax2", ",", "orientation", "=", "\"horizontal\"", ",", "fraction", "=", "0.046", ",", "pad", "=", "0.04", ")", "\n", "ax2", ".", "set_ylim", "(", "-", "0.5", ",", "matrix", ".", "shape", "[", "1", "]", "-", "0.5", ")", "\n", "\n", "ax2", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", ",", "minor", "=", "False", ")", "\n", "ax2", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", ",", "minor", "=", "False", ")", "\n", "ax2", ".", "set_xticklabels", "(", "languages", ")", "\n", "ax2", ".", "set_yticklabels", "(", "languages", ")", "\n", "\n", "ax2", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", "+", "0.5", ",", "minor", "=", "True", ")", "\n", "ax2", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "languages", ")", ")", "+", "0.5", ",", "minor", "=", "True", ")", "\n", "ax2", ".", "yaxis", ".", "grid", "(", "True", ",", "which", "=", "'minor'", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "1", ")", "\n", "ax2", ".", "xaxis", ".", "grid", "(", "True", ",", "which", "=", "'minor'", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "1", ")", "\n", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "f\"confusion_matrix.pdf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.mwec.matching": [[26, 30], ["scipy.optimize.linear_sum_assignment", "list", "zip"], "function", ["None"], ["def", "matching", "(", "cost_matrix", ")", ":", "\n", "    ", "\"\"\"Minumum cost maximum matching in a bipartite graph.\"\"\"", "\n", "matching_x", ",", "matching_y", "=", "linear_sum_assignment", "(", "cost_matrix", ")", "\n", "return", "list", "(", "zip", "(", "matching_x", ",", "matching_y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.mwec.edge_cover": [[32, 63], ["numpy.full", "range", "range", "scipy.optimize.linear_sum_assignment", "zip", "min", "min", "edge_cover_pairs.append", "numpy.argmin", "edge_cover_pairs.append", "numpy.argmin", "edge_cover_pairs.append"], "function", ["None"], ["", "def", "edge_cover", "(", "cost_matrix", ",", "infinity", "=", "1e12", ")", ":", "\n", "    ", "\"\"\"Minimum weighted edge cover in a bipartite graph.\"\"\"", "\n", "if", "cost_matrix", ".", "shape", "==", "(", "0", ",", "0", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "x_dim", ",", "y_dim", "=", "cost_matrix", ".", "shape", "\n", "\n", "new_matrix", "=", "np", ".", "full", "(", "[", "x_dim", "+", "y_dim", ",", "x_dim", "+", "y_dim", "]", ",", "infinity", ")", "\n", "new_matrix", "[", ":", "x_dim", ",", ":", "y_dim", "]", "=", "cost_matrix", "\n", "new_matrix", "[", "x_dim", ":", ",", "y_dim", ":", "]", "=", "cost_matrix", ".", "T", "\n", "\n", "for", "i", "in", "range", "(", "x_dim", ")", ":", "\n", "        ", "new_matrix", "[", "i", "]", "[", "y_dim", "+", "i", "]", "=", "2", "*", "min", "(", "cost_matrix", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "y_dim", ")", ":", "\n", "        ", "new_matrix", "[", "x_dim", "+", "i", "]", "[", "i", "]", "=", "2", "*", "min", "(", "cost_matrix", "[", ":", ",", "i", "]", ")", "\n", "\n", "", "matching_x", ",", "matching_y", "=", "linear_sum_assignment", "(", "new_matrix", ")", "\n", "\n", "edge_cover_pairs", "=", "[", "]", "\n", "for", "pair", "in", "zip", "(", "matching_x", ",", "matching_y", ")", ":", "\n", "        ", "if", "pair", "[", "0", "]", "<", "x_dim", "and", "pair", "[", "1", "]", "<", "y_dim", ":", "\n", "            ", "edge_cover_pairs", ".", "append", "(", "pair", ")", "\n", "", "elif", "pair", "[", "0", "]", "==", "pair", "[", "1", "]", "-", "y_dim", ":", "\n", "            ", "target", "=", "np", ".", "argmin", "(", "cost_matrix", "[", "pair", "[", "0", "]", "]", ")", "\n", "edge_cover_pairs", ".", "append", "(", "(", "pair", "[", "0", "]", ",", "target", ")", ")", "\n", "", "elif", "pair", "[", "0", "]", "-", "x_dim", "==", "pair", "[", "1", "]", ":", "\n", "            ", "source", "=", "np", ".", "argmin", "(", "cost_matrix", "[", ":", ",", "pair", "[", "1", "]", "]", ")", "\n", "edge_cover_pairs", ".", "append", "(", "(", "source", ",", "pair", "[", "1", "]", ")", ")", "\n", "\n", "", "", "return", "edge_cover_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.load_char_vocab": [[22, 34], ["open", "line.strip().split", "int", "len", "chars.append", "line.strip"], "function", ["None"], ["def", "load_char_vocab", "(", "path", ",", "freq_limit", "=", "5", ")", ":", "\n", "    ", "chars", "=", "[", "]", "\n", "char2idx", "=", "{", "}", "\n", "with", "open", "(", "path", ")", "as", "f_vocab", ":", "\n", "        ", "for", "line", "in", "f_vocab", ":", "\n", "            ", "word", ",", "freq_str", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "freq", "=", "int", "(", "freq_str", ")", "\n", "if", "freq", ">=", "freq_limit", ":", "\n", "                ", "char2idx", "[", "word", "]", "=", "len", "(", "chars", ")", "\n", "chars", ".", "append", "(", "word", ")", "\n", "\n", "", "", "", "return", "chars", ",", "char2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.sentence2vec": [[36, 42], ["numpy.zeros", "len"], "function", ["None"], ["", "def", "sentence2vec", "(", "sent", ",", "char2idx", ")", ":", "\n", "    ", "vector", "=", "np", ".", "zeros", "(", "len", "(", "char2idx", ")", ")", "\n", "for", "char", "in", "sent", ":", "\n", "        ", "if", "char", "in", "char2idx", ":", "\n", "            ", "vector", "[", "char2idx", "[", "char", "]", "]", "+=", "1", "\n", "", "", "return", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.load_data_as_tensors": [[44, 59], ["open", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "sentences.append", "lngs.append", "numpy.array", "numpy.array", "line.strip().split", "lng_id_char_unigrams.sentence2vec", "line.strip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.sentence2vec"], ["", "def", "load_data_as_tensors", "(", "path", ",", "char2idx", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "lngs", "=", "[", "]", "\n", "\n", "with", "open", "(", "path", ")", "as", "f_data", ":", "\n", "        ", "for", "line", "in", "f_data", ":", "\n", "            ", "try", ":", "\n", "                ", "sentence", ",", "lng", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "continue", "\n", "\n", "", "sentences", ".", "append", "(", "sentence2vec", "(", "sentence", ",", "char2idx", ")", ")", "\n", "lngs", ".", "append", "(", "LNG2IDX", "[", "lng", "]", ")", "\n", "\n", "", "", "return", "torch", ".", "tensor", "(", "np", ".", "array", "(", "sentences", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "torch", ".", "tensor", "(", "np", ".", "array", "(", "lngs", ")", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.main": [[61, 180], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "torch.device", "torch.device", "lng_id_char_unigrams.load_char_vocab", "print", "lng_id_char_unigrams.load_data_as_tensors", "print", "lng_id_char_unigrams.load_data_as_tensors", "print", "lng_id_char_unigrams.load_data_as_tensors", "print", "nn.Sequential.to", "torch.CrossEntropyLoss", "torch.Adam", "enumerate", "nn.Sequential.eval", "lng_id_char_unigrams.main.evaluate"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.load_char_vocab", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.load_data_as_tensors", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.load_data_as_tensors", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lng_id_char_unigrams.load_data_as_tensors"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"char_vocabulary\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to character vocabulary.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"val_data\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences with language for validation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_data\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences with language for testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--hidden\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Size of the hidden classification layer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test-output\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Output for example classification.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "chars", ",", "char2idx", "=", "load_char_vocab", "(", "args", ".", "char_vocabulary", ")", "\n", "print", "(", "\"Vocabulary loaded.\"", ")", "\n", "\n", "train_data", ",", "train_lng", "=", "load_data_as_tensors", "(", "args", ".", "train_data", ",", "char2idx", ")", "\n", "print", "(", "\"Train data loaded.\"", ")", "\n", "val_data", ",", "val_lng", "=", "load_data_as_tensors", "(", "args", ".", "val_data", ",", "char2idx", ")", "\n", "val_data", ",", "val_lng", "=", "val_data", ".", "to", "(", "device", ")", ",", "val_lng", ".", "to", "(", "device", ")", "\n", "print", "(", "\"Val data loaded.\"", ")", "\n", "test_data", ",", "test_lng", "=", "load_data_as_tensors", "(", "args", ".", "test_data", ",", "char2idx", ")", "\n", "test_data", ",", "test_lng", "=", "test_data", ".", "to", "(", "device", ")", ",", "test_lng", ".", "to", "(", "device", ")", "\n", "print", "(", "\"Test data loaded.\"", ")", "\n", "\n", "if", "args", ".", "hidden", "is", "None", ":", "\n", "        ", "classifier", "=", "nn", ".", "Linear", "(", "len", "(", "chars", ")", ",", "len", "(", "LANGUAGES", ")", ")", "\n", "", "else", ":", "\n", "        ", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "len", "(", "chars", ")", ",", "args", ".", "hidden", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden", ",", "len", "(", "LANGUAGES", ")", ")", ")", "\n", "", "classifier", "=", "classifier", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "classifier", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "\n", "def", "evaluate", "(", "data", ",", "tgt", ")", ":", "\n", "        ", "classifier", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "prediction", "=", "classifier", "(", "data", ")", "\n", "\n", "loss", "=", "criterion", "(", "prediction", ",", "tgt", ")", "\n", "\n", "predicted_lng", "=", "prediction", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "accuracy", "=", "torch", ".", "mean", "(", "(", "predicted_lng", "==", "tgt", ")", ".", "float", "(", ")", ")", "\n", "\n", "", "return", "loss", ",", "accuracy", ",", "predicted_lng", "\n", "\n", "", "best_accuracy", "=", "0.0", "\n", "no_improvement", "=", "0", "\n", "lr_decreased", "=", "0", "\n", "lr", "=", "1e-3", "\n", "\n", "for", "i", ",", "(", "sentences", ",", "lng", ")", "in", "enumerate", "(", "zip", "(", "train_data", ".", "split", "(", "32", ")", ",", "train_lng", ".", "split", "(", "32", ")", ")", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "classifier", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "sentences", ",", "lng", "=", "sentences", ".", "to", "(", "device", ")", ",", "lng", ".", "to", "(", "device", ")", "\n", "prediction", "=", "classifier", "(", "sentences", ")", "\n", "\n", "loss", "=", "criterion", "(", "prediction", ",", "lng", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "i", "%", "10", "==", "9", ":", "\n", "                ", "print", "(", "f\"loss: {loss.cpu().detach().numpy().tolist():5g}\"", ")", "\n", "\n", "", "if", "i", "%", "100", "==", "99", ":", "\n", "                ", "print", "(", ")", "\n", "val_loss", ",", "accuracy", ",", "_", "=", "evaluate", "(", "val_data", ",", "val_lng", ")", "\n", "\n", "print", "(", "\"Validation: \"", "\n", "f\"loss: {val_loss:5g}, \"", "\n", "f\"accuracy: {accuracy:5g}\"", ")", "\n", "\n", "if", "accuracy", ">", "best_accuracy", ":", "\n", "                    ", "best_accuracy", "=", "accuracy", "\n", "no_improvement", "=", "0", "\n", "", "else", ":", "\n", "                    ", "no_improvement", "+=", "1", "\n", "\n", "", "if", "no_improvement", ">=", "5", ":", "\n", "                    ", "if", "lr_decreased", ">=", "5", ":", "\n", "                        ", "print", "(", "\"Learning rate decreased five times, ending.\"", ")", "\n", "break", "\n", "\n", "", "lr", "/=", "2", "\n", "print", "(", "f\"Decreasing learning rate to {lr}.\"", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "lr_decreased", "+=", "1", "\n", "no_improvement", "=", "0", "\n", "\n", "", "print", "(", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "break", "\n", "\n", "", "", "classifier", ".", "eval", "(", ")", "\n", "test_loss", ",", "test_accuracy", ",", "test_outputs", "=", "evaluate", "(", "test_data", ",", "test_lng", ")", "\n", "print", "(", ")", "\n", "print", "(", "\"Testing:\"", ")", "\n", "print", "(", "f\"test loss: {test_loss:5g}, \"", "\n", "f\"test accuracy: {test_accuracy:5g}\"", ")", "\n", "\n", "if", "args", ".", "test_output", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "args", ".", "test_output", ",", "'w'", ")", "as", "f_out", ":", "\n", "            ", "for", "lng_prediction", "in", "test_outputs", ":", "\n", "                ", "print", "(", "LANGUAGES", "[", "lng_prediction", "]", ",", "file", "=", "f_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.att_entropies_per_lng.text_data_generator": [[17, 27], ["open", "line.strip", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["def", "text_data_generator", "(", "path", ",", "tokenizer", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "sentence", "=", "line", ".", "strip", "(", ")", "\n", "\n", "# 512 is the maximum input size of BERT", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "sentence", ")", "\n", "tokenized", "=", "[", "\"[CLS]\"", "]", "+", "tokens", "[", ":", "510", "]", "+", "[", "\"[SEP]\"", "]", "\n", "token_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized", ")", "\n", "yield", "torch", ".", "tensor", "(", "token_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.att_entropies_per_lng.main": [[29, 89], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "pytorch_pretrained_bert.BertTokenizer.from_pretrained", "pytorch_pretrained_bert.BertModel.from_pretrained().to", "BertModel.from_pretrained().to.eval", "zip", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "pytorch_pretrained_bert.BertModel.from_pretrained", "print", "att_entropies_per_lng.text_data_generator", "languages.append", "entropies.append", "input_file.split", "BertModel.from_pretrained().to.", "numpy.zeros", "att_matrices.squeeze", "sentence_tensor.unsqueeze", "entropy.cpu().numpy", "len", "torch.mean", "torch.mean", "torch.mean", "entropy.cpu", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "\n", "choices", "=", "[", "\"bert-base-uncased\"", ",", "\"bert-large-uncased\"", ",", "\"bert-base-cased\"", ",", "\n", "\"bert-base-multilingual-cased\"", ",", "\"bert-base-multilingual-uncased\"", ",", "\"bert-base-chinese\"", "]", ",", "\n", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"language_data\"", ",", "nargs", "=", "\"+\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Files with data, name of the file is language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--limit\"", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "\n", "args", ".", "bert_model", ",", "\n", "output_attentions", "=", "True", ",", "\n", "keep_multihead_output", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "languages", "=", "[", "]", "\n", "entropies", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "input_file", "in", "args", ".", "language_data", ":", "\n", "            ", "lng_code", "=", "input_file", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "print", "(", "f\"Working on {lng_code}\"", ")", "\n", "\n", "entropies_sums", "=", "None", "\n", "sentence_count", "=", "0", "\n", "\n", "for", "sentence_tensor", "in", "text_data_generator", "(", "input_file", ",", "tokenizer", ")", ":", "\n", "                ", "sentence_count", "+=", "1", "\n", "layer_attentions", "=", "model", "(", "sentence_tensor", ".", "unsqueeze", "(", "0", ")", ")", "[", "0", "]", "\n", "head_count", "=", "layer_attentions", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "\n", "if", "entropies_sums", "is", "None", ":", "\n", "                    ", "entropies_sums", "=", "np", ".", "zeros", "(", "\n", "len", "(", "layer_attentions", ")", "*", "head_count", ")", "\n", "\n", "", "head_id", "=", "0", "\n", "for", "att_matrices", "in", "layer_attentions", ":", "\n", "                    ", "for", "matrix", "in", "att_matrices", ".", "squeeze", "(", "0", ")", ":", "\n", "                        ", "entropy", "=", "-", "torch", ".", "mean", "(", "(", "matrix", "*", "torch", ".", "log", "(", "matrix", "+", "1e-9", ")", ")", ".", "sum", "(", "1", ")", ")", "\n", "entropies_sums", "[", "head_id", "]", "+=", "entropy", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "head_id", "+=", "1", "\n", "\n", "", "", "if", "sentence_count", ">=", "args", ".", "limit", ":", "\n", "                    ", "break", "\n", "\n", "", "", "languages", ".", "append", "(", "lng_code", ")", "\n", "entropies", ".", "append", "(", "entropies_sums", "/", "sentence_count", ")", "\n", "\n", "", "", "for", "lng", ",", "entropy", "in", "zip", "(", "languages", ",", "entropies", ")", ":", "\n", "        ", "formatted_ent", "=", "\"\\t\"", ".", "join", "(", "[", "f\"{e:.5f}\"", "for", "e", "in", "entropy", "]", ")", "\n", "print", "(", "f\"{lng}\\t{formatted_ent}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_regression_embeddings.main": [[20, 106], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "utils.load_word_embeddings", "utils.load_word_embeddings", "print", "sklearn.neural_network.MLPRegressor", "sklearn.neural_network.MLPRegressor.fit", "print", "sklearn.neural_network.MLPRegressor.predict", "print", "exit", "utils.word_embeddings_for_file", "utils.word_embeddings_for_file", "open", "numpy.array", "utils.word_embeddings_for_file", "utils.word_embeddings_for_file", "print", "numpy.concatenate", "numpy.concatenate", "float", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_src\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sentences in source language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_mt\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Machine-translated sentences for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_hter\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Machine-translated sentences for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language for testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_mt\"", ",", "type", "=", "str", ",", "help", "=", "\"Machine-translated sentences for testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--exclude-src\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Exclude source representatiion from the classifier.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--exclude-mt\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Exclude target representatiion from the classifier.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vecotr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "exclude_src", "and", "args", ".", "exclude_mt", ":", "\n", "        ", "print", "(", "\"You cannot exclude both source and MT!\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "\n", "src_embeddings", "=", "load_word_embeddings", "(", "args", ".", "src_emb", ")", "\n", "mt_embeddings", "=", "load_word_embeddings", "(", "args", ".", "mt_emb", ")", "\n", "\n", "if", "not", "args", ".", "exclude_src", ":", "\n", "        ", "train_src_repr", "=", "word_embeddings_for_file", "(", "\n", "args", ".", "train_src", ",", "src_embeddings", ",", "args", ".", "src_lng", ")", "\n", "", "if", "not", "args", ".", "exclude_mt", ":", "\n", "        ", "train_mt_repr", "=", "word_embeddings_for_file", "(", "\n", "args", ".", "train_src", ",", "mt_embeddings", ",", "args", ".", "mt_lng", ")", "\n", "\n", "", "if", "args", ".", "exclude_src", ":", "\n", "        ", "train_inputs", "=", "train_mt_repr", "\n", "", "elif", "args", ".", "exclude_mt", ":", "\n", "        ", "train_inputs", "=", "train_src_repr", "\n", "", "else", ":", "\n", "        ", "train_inputs", "=", "np", ".", "concatenate", "(", "(", "train_src_repr", ",", "train_mt_repr", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "train_hter", ")", "as", "f_tgt", ":", "\n", "        ", "train_targets", "=", "np", ".", "array", "(", "[", "float", "(", "line", ".", "rstrip", "(", ")", ")", "for", "line", "in", "f_tgt", "]", ")", "\n", "\n", "", "print", "(", "\"Training regression ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "regressor", "=", "MLPRegressor", "(", "(", "256", ")", ",", "early_stopping", "=", "True", ")", "\n", "regressor", ".", "fit", "(", "train_inputs", ",", "train_targets", ")", "\n", "print", "(", "\"Done.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "if", "not", "args", ".", "exclude_src", ":", "\n", "        ", "test_src_repr", "=", "word_embeddings_for_file", "(", "\n", "args", ".", "test_src", ",", "src_embeddings", ",", "args", ".", "src_lng", ")", "\n", "", "if", "not", "args", ".", "exclude_mt", ":", "\n", "        ", "test_mt_repr", "=", "word_embeddings_for_file", "(", "\n", "args", ".", "test_src", ",", "mt_embeddings", ",", "args", ".", "mt_lng", ")", "\n", "\n", "", "if", "args", ".", "exclude_src", ":", "\n", "        ", "test_inputs", "=", "test_mt_repr", "\n", "", "elif", "args", ".", "exclude_mt", ":", "\n", "        ", "test_inputs", "=", "test_src_repr", "\n", "", "else", ":", "\n", "        ", "test_inputs", "=", "np", ".", "concatenate", "(", "(", "test_src_repr", ",", "test_mt_repr", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "predictions", "=", "regressor", ".", "predict", "(", "test_inputs", ")", "\n", "\n", "for", "num", "in", "predictions", ":", "\n", "        ", "print", "(", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.save_centroids.main": [[20, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "print", "numpy.savez", "utils.load_bert", "open", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "line.strip().split", "os.path.join", "utils.text_data_generator", "utils.batch_generator", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "line.strip", "range", "utils.get_repr_from_layer().cpu().numpy", "language_names.append", "numpy.concatenate().mean", "centroids.append", "numpy.any", "representations.append", "utils.get_repr_from_layer().cpu", "numpy.isnan", "numpy.concatenate", "utils.get_repr_from_layer", "txt.to"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_repr_from_layer"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"language_list\"", ",", "type", "=", "str", ",", "help", "=", "\"TSV file with available languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "type", "=", "str", ",", "help", "=", "\"Directory with txt files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"target\"", ",", "type", "=", "str", ",", "help", "=", "\"npz file with saved centroids.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vecotr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-count\"", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "language_names", "=", "[", "]", "\n", "centroids", "=", "[", "]", "\n", "\n", "with", "open", "(", "args", ".", "language_list", ")", "as", "lng_f", ":", "\n", "        ", "for", "line", "in", "lng_f", ":", "\n", "            ", "name", ",", "code", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "f\"{code}.txt\"", ")", "\n", "\n", "data", "=", "text_data_generator", "(", "data_file", ",", "tokenizer", ")", "\n", "batches", "=", "batch_generator", "(", "data", ",", "args", ".", "batch_size", ",", "tokenizer", ")", "\n", "print", "(", "f\"Data iterator initialized: {data_file}\"", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "representations", "=", "[", "]", "\n", "for", "_", ",", "txt", "in", "zip", "(", "range", "(", "args", ".", "batch_count", ")", ",", "batches", ")", ":", "\n", "                    ", "batch_repr", "=", "get_repr_from_layer", "(", "\n", "model", ",", "txt", ".", "to", "(", "device", ")", ",", "args", ".", "layer", ",", "\n", "tokenizer", ".", "pad_token_id", ",", "\n", "mean_pool", "=", "args", ".", "mean_pool", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "not", "np", ".", "any", "(", "np", ".", "isnan", "(", "batch_repr", ")", ")", ":", "\n", "                        ", "representations", ".", "append", "(", "batch_repr", ")", "\n", "\n", "", "", "if", "representations", ":", "\n", "                    ", "language_names", ".", "append", "(", "name", ")", "\n", "centroid", "=", "np", ".", "concatenate", "(", "representations", ",", "axis", "=", "0", ")", ".", "mean", "(", "0", ")", "\n", "centroids", ".", "append", "(", "centroid", ")", "\n", "\n", "", "", "", "", "print", "(", "\"Centroids computed.\"", ")", "\n", "\n", "np", ".", "savez", "(", "args", ".", "target", ",", "languages", "=", "language_names", ",", "centroids", "=", "centroids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.learn_lng_projection.repr_for_text_file": [[22, 31], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "utils.get_repr_from_layer", "utils.batch_generator", "torch.cat", "torch.cat", "torch.cat", "utils.text_data_generator"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_repr_from_layer", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator"], ["def", "repr_for_text_file", "(", "text_file", ",", "model", ",", "tokenizer", ",", "layer", ",", "mean_pool", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "vectors", "=", "[", "\n", "get_repr_from_layer", "(", "\n", "model", ",", "sentence_tensor", ",", "layer", ",", "tokenizer", ".", "pad_token_id", ",", "\n", "mean_pool", "=", "mean_pool", ")", "\n", "for", "sentence_tensor", "in", "batch_generator", "(", "\n", "text_data_generator", "(", "text_file", ",", "tokenizer", ")", ",", "64", ",", "tokenizer", ")", "]", "\n", "return", "torch", ".", "cat", "(", "vectors", ",", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.learn_lng_projection.main": [[33, 73], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "print", "learn_lng_projection.repr_for_text_file", "print", "learn_lng_projection.repr_for_text_file", "print", "print", "sklearn.linear_model.LinearRegression", "sklearn.linear_model.LinearRegression.fit", "print", "joblib.dump", "utils.load_bert", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.learn_lng_projection.repr_for_text_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.learn_lng_projection.repr_for_text_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data_lng1\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data_lng2\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"save_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the saved model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vector.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "print", "(", "f\"Loading representation for {args.data_lng1}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "lng1_repr", "=", "repr_for_text_file", "(", "\n", "args", ".", "data_lng1", ",", "model", ",", "tokenizer", ",", "args", ".", "layer", ",", "args", ".", "mean_pool", ")", "\n", "print", "(", "f\"Loading representation for {args.data_lng2}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "lng2_repr", "=", "repr_for_text_file", "(", "\n", "args", ".", "data_lng2", ",", "model", ",", "tokenizer", ",", "args", ".", "layer", ",", "args", ".", "mean_pool", ")", "\n", "print", "(", "\"BERT representations loaded.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "print", "(", "\"Fitting the projection.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "model", "=", "LinearRegression", "(", ")", "\n", "model", ".", "fit", "(", "lng1_repr", ",", "lng2_repr", ")", "\n", "print", "(", "\"Done, saving model.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "joblib", ".", "dump", "(", "model", ",", "args", ".", "save_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.call_bert_and_collapse_tokens": [[25, 51], ["open", "torch.no_grad", "torch.no_grad", "torch.no_grad", "line.strip().split", "[].numpy", "tokenizer.tokenize", "vectors_squeezed.append", "line.strip", "len", "token_spans.append", "bert_tokens.extend", "numpy.mean", "numpy.stack", "len", "utils.vectors_for_sentence"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.vectors_for_sentence"], ["def", "call_bert_and_collapse_tokens", "(", "filename", ",", "model", ",", "tokenizer", ",", "layer", ")", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "f_data", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "line", "in", "f_data", ":", "\n", "                ", "original_tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "token_spans", "=", "[", "]", "\n", "bert_tokens", "=", "[", "]", "\n", "for", "token", "in", "original_tokens", ":", "\n", "                    ", "bert_split", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "if", "len", "(", "bert_split", ")", ">=", "1", ":", "\n", "                        ", "token_spans", ".", "append", "(", "len", "(", "bert_split", ")", ")", "\n", "bert_tokens", ".", "extend", "(", "bert_split", ")", "\n", "\n", "", "", "vectors", "=", "vectors_for_sentence", "(", "\n", "tokenizer", ",", "model", ",", "bert_tokens", ",", "layer", ",", "\n", "skip_tokenization", "=", "True", ")", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "vectors_squeezed", "=", "[", "]", "\n", "\n", "offset", "=", "0", "\n", "for", "span", "in", "token_spans", ":", "\n", "                    ", "vectors_squeezed", ".", "append", "(", "\n", "np", ".", "mean", "(", "vectors", "[", "offset", ":", "offset", "+", "span", "]", ",", "axis", "=", "0", ")", ")", "\n", "offset", "+=", "span", "\n", "\n", "", "yield", "np", ".", "stack", "(", "vectors_squeezed", ")", ",", "original_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.apply_sklearn_proj": [[53, 58], ["print", "joblib.load", "joblib.load.predict"], "function", ["None"], ["", "", "", "", "def", "apply_sklearn_proj", "(", "representations", ",", "model_path", ")", ":", "\n", "    ", "print", "(", "\"Projecting representations.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "model", "=", "joblib", ".", "load", "(", "model_path", ")", "\n", "for", "vectors", ",", "tokens", "in", "representations", ":", "\n", "        ", "yield", "model", ".", "predict", "(", "vectors", ")", ",", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.reordering_penalty": [[60, 68], ["numpy.zeros", "max", "range", "range", "abs"], "function", ["None"], ["", "", "def", "reordering_penalty", "(", "src_size", ",", "tgt_size", ")", ":", "\n", "    ", "\"\"\"Penalty for reordering 0-1 based on relative token distance.\"\"\"", "\n", "penalty_matrix", "=", "np", ".", "zeros", "(", "(", "src_size", ",", "tgt_size", ")", ")", "\n", "max_size", "=", "max", "(", "src_size", ",", "tgt_size", ")", "\n", "for", "i", "in", "range", "(", "src_size", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "tgt_size", ")", ":", "\n", "            ", "penalty_matrix", "[", "i", ",", "j", "]", "=", "abs", "(", "i", "-", "j", ")", "/", "max_size", "\n", "", "", "return", "penalty_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.align": [[70, 84], ["mwec.edge_cover", "proj.predict", "numpy.expand_dims", "word_alignment.reordering_penalty", "numpy.dot", "numpy.expand_dims", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.mwec.edge_cover", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.reordering_penalty"], ["", "def", "align", "(", "src_mat", ",", "tgt_mat", ",", "penalty", ",", "proj", "=", "None", ")", ":", "\n", "    ", "if", "proj", "is", "not", "None", ":", "\n", "        ", "src_mat", "=", "proj", ".", "predict", "(", "src_mat", ")", "\n", "\n", "# Cosine in (-1, 1) and MWEC requires positive weights => 2 -", "\n", "", "distance", "=", "2", "-", "(", "\n", "np", ".", "dot", "(", "src_mat", ",", "tgt_mat", ".", "T", ")", "\n", "/", "np", ".", "expand_dims", "(", "np", ".", "linalg", ".", "norm", "(", "src_mat", ",", "axis", "=", "1", ")", ",", "1", ")", "\n", "/", "np", ".", "expand_dims", "(", "np", ".", "linalg", ".", "norm", "(", "tgt_mat", ",", "axis", "=", "1", ")", ",", "0", ")", ")", "\n", "\n", "if", "penalty", ">", "0", ":", "\n", "        ", "distance", "+=", "(", "\n", "penalty", "*", "reordering_penalty", "(", "*", "distance", ".", "shape", ")", ")", "\n", "", "return", "edge_cover", "(", "distance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.center": [[86, 91], ["numpy.mean", "numpy.concatenate"], "function", ["None"], ["", "def", "center", "(", "representations", ")", ":", "\n", "    ", "vec_center", "=", "np", ".", "mean", "(", "\n", "np", ".", "concatenate", "(", "\n", "[", "mat", "for", "mat", ",", "txt", "in", "representations", "]", ")", ",", "0", ",", "keepdims", "=", "True", ")", "\n", "return", "[", "(", "mat", "-", "vec_center", ",", "txt", ")", "for", "mat", ",", "txt", "in", "representations", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.em_step": [[93, 110], ["print", "zip", "print", "sklearn.neural_network.MLPRegressor", "print", "sklearn.neural_network.MLPRegressor.fit", "print", "word_alignment.align", "src_vectors.append", "tgt_vectors.append"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.align"], ["", "def", "em_step", "(", "src_repr", ",", "tgt_repr", ",", "penalty", ",", "orig_proj", ")", ":", "\n", "    ", "src_vectors", "=", "[", "]", "\n", "tgt_vectors", "=", "[", "]", "\n", "\n", "print", "(", "\"Computing alignment ... \"", ",", "end", "=", "\"\"", ",", "file", "=", "sys", ".", "stderr", ",", "flush", "=", "True", ")", "\n", "for", "(", "src_mat", ",", "_", ")", ",", "(", "tgt_mat", ",", "_", ")", "in", "zip", "(", "src_repr", ",", "tgt_repr", ")", ":", "\n", "        ", "for", "i", ",", "j", "in", "align", "(", "src_mat", ",", "tgt_mat", ",", "penalty", ",", "orig_proj", ")", ":", "\n", "            ", "src_vectors", ".", "append", "(", "src_mat", "[", "i", "]", ")", "\n", "tgt_vectors", ".", "append", "(", "tgt_mat", "[", "j", "]", ")", "\n", "", "", "print", "(", "\"Done\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "new_proj", "=", "MLPRegressor", "(", "(", "768", ")", ",", "early_stopping", "=", "True", ")", "#LinearRegression()", "\n", "print", "(", "\"Fitting regression ... \"", ",", "end", "=", "\"\"", ",", "file", "=", "sys", ".", "stderr", ",", "flush", "=", "True", ")", "\n", "new_proj", ".", "fit", "(", "src_vectors", ",", "tgt_vectors", ")", "\n", "print", "(", "\"Done\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "return", "new_proj", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.load_data": [[112, 133], ["print", "list", "print", "print", "list", "print", "word_alignment.call_bert_and_collapse_tokens", "word_alignment.call_bert_and_collapse_tokens", "print", "list", "list", "word_alignment.center", "word_alignment.center", "word_alignment.apply_sklearn_proj", "word_alignment.apply_sklearn_proj"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.call_bert_and_collapse_tokens", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.call_bert_and_collapse_tokens", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj"], ["", "def", "load_data", "(", "\n", "src", ",", "tgt", ",", "model", ",", "tokenizer", ",", "layer", ",", "center_lng", ",", "src_proj", ",", "tgt_proj", ")", ":", "\n", "    ", "print", "(", "f\"Loading src: {src} ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "src_repr", "=", "list", "(", "call_bert_and_collapse_tokens", "(", "\n", "src", ",", "model", ",", "tokenizer", ",", "layer", ")", ")", "\n", "print", "(", "\"Done\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "print", "(", "f\"Loading tgt: {tgt} ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "tgt_repr", "=", "list", "(", "call_bert_and_collapse_tokens", "(", "\n", "tgt", ",", "model", ",", "tokenizer", ",", "layer", ")", ")", "\n", "print", "(", "\"Done\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "if", "center_lng", ":", "\n", "        ", "print", "(", "\"Centering data.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "src_repr", ",", "tgt_repr", "=", "center", "(", "src_repr", ")", ",", "center", "(", "tgt_repr", ")", "\n", "", "if", "src_proj", "is", "not", "None", ":", "\n", "        ", "src_repr", "=", "list", "(", "apply_sklearn_proj", "(", "src_repr", ",", "src_proj", ")", ")", "\n", "", "if", "tgt_proj", "is", "not", "None", ":", "\n", "        ", "tgt_repr", "=", "list", "(", "apply_sklearn_proj", "(", "tgt_repr", ",", "tgt_proj", ")", ")", "\n", "\n", "", "return", "src_repr", ",", "tgt_repr", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.main": [[135, 224], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "print", "word_alignment.load_data", "zip", "print", "exit", "utils.load_bert", "print", "word_alignment.load_data", "range", "word_alignment.align", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "print", "exit", "print", "word_alignment.em_step", "print", "joblib.dump", "enumerate", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.load_data", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.load_data", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.align", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.word_alignment.em_step"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"tgt\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, center representations first.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tgt-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reordering-penalty\"", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Penalty for long-distance alignment added to cost.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, print the actual alignment.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--iterations\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Number of EM iterations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train-data\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Training data for EM training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-projection\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Location to save the word projection.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "center_lng", "and", "(", "\n", "args", ".", "src_proj", "is", "not", "None", "and", "args", ".", "tgt_proj", "is", "not", "None", ")", ":", "\n", "        ", "print", "(", "\"You can either project or center \"", "\n", "\"the representations, not both.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "proj", "=", "None", "\n", "if", "args", ".", "iterations", ">", "0", ":", "\n", "        ", "if", "args", ".", "train_data", "is", "None", ":", "\n", "            ", "print", "(", "\"You need to specify train data for EM training.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "print", "(", "\"Loading training data.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "train_src_repr", ",", "train_tgt_repr", "=", "load_data", "(", "\n", "args", ".", "train_data", "[", "0", "]", ",", "args", ".", "train_data", "[", "1", "]", ",", "\n", "model", ",", "tokenizer", ",", "args", ".", "layer", ",", "\n", "args", ".", "center_lng", ",", "args", ".", "src_proj", ",", "args", ".", "tgt_proj", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "args", ".", "iterations", ")", ":", "\n", "            ", "print", "(", "f\"Iteration {iteration + 1}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "proj", "=", "em_step", "(", "\n", "train_src_repr", ",", "train_tgt_repr", ",", "args", ".", "reordering_penalty", ",", "proj", ")", "\n", "print", "(", "\"Done.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "if", "args", ".", "save_projection", ":", "\n", "            ", "joblib", ".", "dump", "(", "proj", ",", "args", ".", "save_projection", ")", "\n", "\n", "", "", "print", "(", "\"Loading test data.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "src_repr", ",", "tgt_repr", "=", "load_data", "(", "\n", "args", ".", "src", ",", "args", ".", "tgt", ",", "model", ",", "tokenizer", ",", "args", ".", "layer", ",", "\n", "args", ".", "center_lng", ",", "args", ".", "src_proj", ",", "args", ".", "tgt_proj", ")", "\n", "\n", "for", "(", "src_mat", ",", "src_tok", ")", ",", "(", "tgt_mat", ",", "tgt_tok", ")", "in", "zip", "(", "src_repr", ",", "tgt_repr", ")", ":", "\n", "        ", "alignment", "=", "align", "(", "src_mat", ",", "tgt_mat", ",", "args", ".", "reordering_penalty", ",", "proj", ")", "\n", "\n", "if", "args", ".", "verbose", ":", "\n", "            ", "for", "i", ",", "token", "in", "enumerate", "(", "src_tok", ")", ":", "\n", "                ", "aligned_indices", "=", "[", "tix", "for", "six", ",", "tix", "in", "alignment", "if", "six", "==", "i", "]", "\n", "aligned_formatted", "=", "[", "\n", "f\"{tgt_tok[j]} ({j})\"", "for", "j", "in", "aligned_indices", "]", "\n", "print", "(", "f\"{i:2d}: {token} -- {', '.join(aligned_formatted)}\"", ")", "\n", "", "print", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\" \"", ".", "join", "(", "\n", "f\"{src_id}-{tgt_id}\"", "for", "src_id", ",", "tgt_id", "in", "alignment", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.learn_lng_projection_embeddings.main": [[19, 70], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "utils.load_word_embeddings", "print", "utils.load_word_embeddings", "print", "numpy.stack", "print", "numpy.stack", "print", "print", "sklearn.linear_model.LinearRegression", "sklearn.linear_model.LinearRegression.fit", "print", "joblib.dump", "utils.word_embeddings_for_file", "utils.word_embeddings_for_file", "qe_by_cosine.apply_sklearn_proj", "qe_by_cosine.apply_sklearn_proj"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data_lng1\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data_lng2\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"lng1_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"lng2_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"lng1\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"lng2\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"save_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the saved model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mt-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "print", "(", "f\"Loading {args.lng1} embeddings.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "lng1_embeddings", "=", "load_word_embeddings", "(", "args", ".", "lng1_emb", ")", "\n", "print", "(", "f\"Loading {args.lng2} embeddings.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "lng2_embeddings", "=", "load_word_embeddings", "(", "args", ".", "lng2_emb", ")", "\n", "\n", "print", "(", "f\"Loading representation for {args.data_lng1}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "lng1_repr", "=", "np", ".", "stack", "(", "\n", "word_embeddings_for_file", "(", "args", ".", "data_lng1", ",", "lng1_embeddings", ",", "args", ".", "lng1", ")", ")", "\n", "print", "(", "f\"Loading representation for {args.data_lng2}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "lng2_repr", "=", "np", ".", "stack", "(", "\n", "word_embeddings_for_file", "(", "args", ".", "data_lng2", ",", "lng2_embeddings", ",", "args", ".", "lng2", ")", ")", "\n", "print", "(", "\"Representations loaded.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "if", "args", ".", "src_proj", "is", "not", "None", ":", "\n", "        ", "src_repr", "=", "apply_sklearn_proj", "(", "src_repr", ",", "args", ".", "src_proj", ")", "\n", "", "if", "args", ".", "mt_proj", "is", "not", "None", ":", "\n", "        ", "mt_repr", "=", "apply_sklearn_proj", "(", "mt_repr", ",", "args", ".", "mt_proj", ")", "\n", "\n", "", "print", "(", "\"Fitting the projection.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "model", "=", "LinearRegression", "(", ")", "\n", "model", ".", "fit", "(", "lng1_repr", ",", "lng2_repr", ")", "\n", "print", "(", "\"Done, saving model.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "joblib", ".", "dump", "(", "model", ",", "args", ".", "save_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.eval_word_alignment.main": [[9, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "zip", "print", "print", "print", "set", "set", "len", "recalls.append", "precisions.append", "len", "len", "len", "len", "len", "len", "len", "argparse.FileType", "argparse.FileType", "gt_line.strip().split", "pred_line.strip().split", "set.intersection", "precisions.append", "recalls.append", "f_scores.append", "len", "f_scores.append", "f_scores.append", "sum", "sum", "sum", "len", "gt_line.strip", "pred_line.strip"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"ground_truth\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "help", "=", "\"Ground truth alignment.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"prediction\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "help", "=", "\"Predicted alignment.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "precisions", "=", "[", "]", "\n", "recalls", "=", "[", "]", "\n", "f_scores", "=", "[", "]", "\n", "\n", "for", "gt_line", ",", "pred_line", "in", "zip", "(", "args", ".", "ground_truth", ",", "args", ".", "prediction", ")", ":", "\n", "        ", "gt_set", "=", "set", "(", "gt_line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "prediction_set", "=", "set", "(", "pred_line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "in_both_size", "=", "len", "(", "gt_set", ".", "intersection", "(", "prediction_set", ")", ")", "\n", "\n", "if", "in_both_size", "==", "0", ":", "\n", "            ", "precisions", ".", "append", "(", "0.", ")", "\n", "recalls", ".", "append", "(", "0.", ")", "\n", "f_scores", ".", "append", "(", "0.", ")", "\n", "\n", "", "recall", "=", "in_both_size", "/", "len", "(", "gt_set", ")", "\n", "recalls", ".", "append", "(", "recall", ")", "\n", "if", "prediction_set", ":", "\n", "            ", "precision", "=", "in_both_size", "/", "len", "(", "prediction_set", ")", "\n", "", "else", ":", "\n", "            ", "precision", "=", "1.", "\n", "", "precisions", ".", "append", "(", "precision", ")", "\n", "\n", "if", "recall", "+", "precision", ">", "0", ":", "\n", "            ", "f_scores", ".", "append", "(", "2", "*", "recall", "*", "precision", "/", "(", "recall", "+", "precision", ")", ")", "\n", "", "else", ":", "\n", "            ", "f_scores", ".", "append", "(", "0.", ")", "\n", "\n", "", "", "assert", "len", "(", "precisions", ")", "==", "len", "(", "recalls", ")", "\n", "assert", "len", "(", "precisions", ")", "==", "len", "(", "f_scores", ")", "\n", "\n", "mean_precision", "=", "100", "*", "sum", "(", "precisions", ")", "/", "len", "(", "precisions", ")", "\n", "mean_recall", "=", "100", "*", "sum", "(", "recalls", ")", "/", "len", "(", "recalls", ")", "\n", "mean_f_score", "=", "100", "*", "sum", "(", "f_scores", ")", "/", "len", "(", "f_scores", ")", "\n", "\n", "print", "(", "f\"Precision: {mean_precision:.2f}\"", ")", "\n", "print", "(", "f\"Recall:    {mean_recall:.2f}\"", ")", "\n", "print", "(", "f\"F-Score:   {mean_f_score:.2f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.visualize_centroids.main": [[31, 142], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "numpy.load", "sklearn.manifold.TSNE", "sklearn.manifold.TSNE.fit_transform", "matplotlib.pyplot.figure", "matplotlib.pyplot.subplot", "matplotlib.pyplot.title", "zip", "FAMILY_COLORS.items", "matplotlib.pyplot.subplot", "scipy.linkage", "enumerate", "scipy.dendrogram", "matplotlib.pyplot.gca", "plt.gca.get_ymajorticklabels", "matplotlib.pyplot.show", "matplotlib.pyplot.savefig", "matplotlib.pyplot.scatter", "matplotlib.pyplot.annotate", "set", "matplotlib.pyplot.annotate", "family_nodes.get", "visualize_centroids.main.get_family_for_index"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"centroids\"", ",", "type", "=", "argparse", ".", "FileType", "(", "'rb'", ")", ",", "\n", "help", "=", "\".npz file with saved centroids.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"output_img\"", ",", "type", "=", "argparse", ".", "FileType", "(", "'wb'", ")", ",", "\n", "help", "=", "\"Plot with tSNE output.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "np_file", "=", "np", ".", "load", "(", "args", ".", "centroids", ")", "\n", "languages", "=", "np_file", "[", "\"languages\"", "]", "\n", "centroids", "=", "np_file", "[", "\"centroids\"", "]", "\n", "\n", "tsne", "=", "TSNE", "(", "n_components", "=", "2", ",", "random_state", "=", "0", ")", "\n", "centroids_2d", "=", "tsne", ".", "fit_transform", "(", "centroids", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "32", ",", "16", ")", ")", "\n", "plt", ".", "subplot", "(", "121", ")", "\n", "\n", "plt", ".", "title", "(", "f\"tSNE of '{args.centroids.name}'\"", ")", "\n", "for", "name", ",", "point", "in", "zip", "(", "languages", ",", "centroids_2d", ")", ":", "\n", "        ", "plt", ".", "scatter", "(", "point", "[", "0", "]", ",", "point", "[", "1", "]", ",", "s", "=", "0", ")", "\n", "\n", "color", "=", "\"#ffffff\"", "\n", "if", "\"genus\"", "in", "LNG_INFO", "[", "name", "]", ":", "\n", "            ", "family", "=", "LNG_INFO", "[", "name", "]", "[", "\"genus\"", "]", "\n", "if", "family", "in", "FAMILY_COLORS", ":", "\n", "                ", "color", "=", "FAMILY_COLORS", "[", "family", "]", "\n", "\n", "", "", "plt", ".", "annotate", "(", "\n", "name", ",", "xy", "=", "point", ",", "\n", "xytext", "=", "(", "5", ",", "2", ")", ",", "\n", "textcoords", "=", "'offset points'", ",", "\n", "ha", "=", "'center'", ",", "\n", "va", "=", "'center'", ",", "\n", "bbox", "=", "{", "\"boxstyle\"", ":", "\"square,pad=0.3\"", ",", "\n", "\"fc\"", ":", "f\"{color}aa\"", "}", ")", "\n", "\n", "", "for", "family", ",", "color", "in", "FAMILY_COLORS", ".", "items", "(", ")", ":", "\n", "        ", "family_languages", "=", "set", "(", "\n", "lng", "[", "\"name\"", "]", "for", "lng", "in", "LNG_INFO", ".", "values", "(", ")", "\n", "if", "\"genus\"", "in", "lng", "and", "lng", "[", "\"genus\"", "]", "==", "family", ")", "\n", "\n", "lng_points", "=", "[", "\n", "point", "for", "name", ",", "point", "in", "zip", "(", "languages", ",", "centroids_2d", ")", "\n", "if", "name", "in", "family_languages", "]", "\n", "avg_point", "=", "(", "\n", "np", ".", "median", "(", "lng_points", ",", "axis", "=", "0", ")", "+", "\n", "np", ".", "mean", "(", "lng_points", ",", "axis", "=", "0", ")", ")", "/", "2", "\n", "\n", "plt", ".", "annotate", "(", "\n", "family", ",", "xy", "=", "avg_point", ",", "\n", "xytext", "=", "(", "5", ",", "2", ")", ",", "\n", "textcoords", "=", "'offset points'", ",", "\n", "ha", "=", "'center'", ",", "va", "=", "'center'", ",", "\n", "color", "=", "\"white\"", ",", "weight", "=", "'bold'", ",", "size", "=", "18", ",", "\n", "backgroundcolor", "=", "color", ")", "\n", "\n", "", "plt", ".", "subplot", "(", "122", ")", "\n", "\n", "clustering", "=", "hac", ".", "linkage", "(", "centroids", ",", "method", "=", "'complete'", ",", "metric", "=", "'cosine'", ")", "\n", "link_colors", "=", "[", "\"#aaaaaa\"", "]", "*", "(", "2", "*", "len", "(", "centroids", ")", "-", "1", ")", "\n", "family_nodes", "=", "{", "}", "\n", "\n", "def", "get_family_for_index", "(", "index", ")", ":", "\n", "        ", "if", "index", "<", "len", "(", "languages", ")", ":", "\n", "            ", "return", "LNG_INFO", "[", "languages", "[", "index", "]", "]", "[", "\"genus\"", "]", "\n", "", "return", "family_nodes", ".", "get", "(", "index", ")", "\n", "\n", "", "for", "i", ",", "(", "item1", ",", "item2", ",", "_", ",", "_", ")", "in", "enumerate", "(", "clustering", ")", ":", "\n", "        ", "new_id", "=", "len", "(", "languages", ")", "+", "i", "\n", "item1", ",", "item2", "=", "int", "(", "item1", ")", ",", "int", "(", "item2", ")", "\n", "\n", "family1", "=", "get_family_for_index", "(", "int", "(", "item1", ")", ")", "\n", "family2", "=", "get_family_for_index", "(", "int", "(", "item2", ")", ")", "\n", "\n", "if", "family1", "is", "None", "or", "family2", "is", "None", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "family1", "==", "family2", ":", "\n", "            ", "family_nodes", "[", "new_id", "]", "=", "family1", "\n", "if", "family1", "in", "FAMILY_COLORS", ":", "\n", "                ", "link_colors", "[", "new_id", "]", "=", "FAMILY_COLORS", "[", "family1", "]", "\n", "", "else", ":", "\n", "                ", "link_colors", "[", "new_id", "]", "=", "\"black\"", "\n", "\n", "", "", "", "hac", ".", "dendrogram", "(", "\n", "clustering", ",", "labels", "=", "languages", ",", "orientation", "=", "'left'", ",", "\n", "leaf_font_size", "=", "10", ",", "show_leaf_counts", "=", "True", ",", "\n", "link_color_func", "=", "lambda", "k", ":", "link_colors", "[", "k", "]", ")", "\n", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "xlbls", "=", "ax", ".", "get_ymajorticklabels", "(", ")", "\n", "for", "lbl", "in", "xlbls", ":", "\n", "        ", "lng_name", "=", "lbl", ".", "get_text", "(", ")", "\n", "if", "\"genus\"", "in", "LNG_INFO", "[", "lng_name", "]", ":", "\n", "            ", "family", "=", "LNG_INFO", "[", "lng_name", "]", "[", "\"genus\"", "]", "\n", "if", "family", "in", "FAMILY_COLORS", ":", "\n", "                ", "color", "=", "FAMILY_COLORS", "[", "family", "]", "\n", "lbl", ".", "set_bbox", "(", "{", "\n", "\"boxstyle\"", ":", "\"square,pad=0.\"", ",", "\n", "\"fc\"", ":", "f\"{color}aa\"", ",", "\n", "\"ec\"", ":", "\"none\"", "}", ")", "\n", "#lbl.set_backgroundcolor(color)", "\n", "#lbl.set_color(label_colors[lbl.get_text()])", "\n", "\n", "\n", "\n", "", "", "", "plt", ".", "show", "(", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "output_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval_embeddings.main": [[24, 122], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "print", "exit", "print", "exit", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "all", "print", "len", "len", "ValueError", "zip", "print", "utils.load_word_embeddings", "print", "utils.word_embeddings_for_file", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "representations.append", "print", "print", "print", "zip", "print", "print", "projections.append", "projections.append", "numpy.stack", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "print", "print", "zip", "print", "joblib.load", "torch.from_numpy.mean", "proj.predict", "distance_fn", "sentence_retrieval.recall_at_k_from_distances", "print", "torch.from_numpy.numpy", "recalls_to_avg.append", "numpy.mean", "sentence_retrieval.recall_at_k_from_distances.numpy", "sentence_retrieval.recall_at_k_from_distances.numpy"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval.recall_at_k_from_distances"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embeddings\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Files with word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--languages\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Language codes used for tokenizers.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--distance\"", ",", "choices", "=", "[", "\"cosine\"", ",", "\"euklid\"", "]", ",", "default", "=", "\"cosine\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Center languages to be around coordinate origin.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--projections\"", ",", "default", "=", "None", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"List of sklearn projections for particular languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "center_lng", "and", "args", ".", "projections", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"You cannot do projections and centering at once.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "(", "args", ".", "projections", "is", "not", "None", "and", "\n", "len", "(", "args", ".", "projections", ")", "!=", "len", "(", "args", ".", "data", ")", ")", ":", "\n", "        ", "print", "(", "\"You must have a projection for each data file.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "projections", "=", "None", "\n", "if", "args", ".", "projections", "is", "not", "None", ":", "\n", "        ", "projections", "=", "[", "]", "\n", "for", "proj_str", "in", "args", ".", "projections", ":", "\n", "            ", "if", "proj_str", "==", "\"None\"", ":", "\n", "                ", "projections", ".", "append", "(", "None", ")", "\n", "", "else", ":", "\n", "                ", "projections", ".", "append", "(", "joblib", ".", "load", "(", "proj_str", ")", ")", "\n", "\n", "", "", "", "distance_fn", "=", "None", "\n", "if", "args", ".", "distance", "==", "\"cosine\"", ":", "\n", "        ", "distance_fn", "=", "cosine_distances", "\n", "", "elif", "args", ".", "distance", "==", "\"euklid\"", ":", "\n", "        ", "distance_fn", "=", "euklid_distances", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown distance function.\"", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "\n", "representations", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "(", "text_file", ",", "embeddings_file", ",", "lng", ")", "in", "enumerate", "(", "\n", "zip", "(", "args", ".", "data", ",", "args", ".", "embeddings", ",", "args", ".", "languages", ")", ")", ":", "\n", "            ", "print", "(", "f\"Loading embeddings {embeddings_file}\"", ")", "\n", "word_embeddings", "=", "load_word_embeddings", "(", "embeddings_file", ")", "\n", "print", "(", "f\"Processing {text_file}\"", ")", "\n", "embedded_sentences", "=", "word_embeddings_for_file", "(", "\n", "text_file", ",", "word_embeddings", ",", "lng", ")", "\n", "\n", "lng_repr", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "embedded_sentences", ")", ")", "\n", "if", "args", ".", "center_lng", ":", "\n", "                ", "lng_repr", "=", "lng_repr", "-", "lng_repr", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "if", "projections", "is", "not", "None", "and", "projections", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "proj", "=", "projections", "[", "i", "]", "\n", "lng_repr", "=", "torch", ".", "from_numpy", "(", "proj", ".", "predict", "(", "lng_repr", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "representations", ".", "append", "(", "lng_repr", ")", "\n", "\n", "", "data_len", "=", "representations", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "assert", "all", "(", "r", ".", "shape", "[", "0", "]", "==", "data_len", "for", "r", "in", "representations", ")", "\n", "print", "(", ")", "\n", "for", "k", "in", "[", "1", ",", "5", ",", "10", ",", "20", ",", "50", ",", "100", "]", ":", "\n", "            ", "print", "(", "f\"Recall at {k}, random baseline {k / data_len:.5f}\"", ")", "\n", "print", "(", "\"--\"", ",", "end", "=", "\"\\t\"", ")", "\n", "for", "lng", "in", "args", ".", "data", ":", "\n", "                ", "print", "(", "lng", "[", "-", "6", ":", "-", "4", "]", ",", "end", "=", "\"\\t\"", ")", "\n", "", "print", "(", ")", "\n", "\n", "recalls_to_avg", "=", "[", "]", "\n", "\n", "for", "lng1", ",", "repr1", "in", "zip", "(", "args", ".", "data", ",", "representations", ")", ":", "\n", "                ", "print", "(", "lng1", "[", "-", "6", ":", "-", "4", "]", ",", "end", "=", "\"\\t\"", ")", "\n", "for", "lng2", ",", "repr2", "in", "zip", "(", "args", ".", "data", ",", "representations", ")", ":", "\n", "\n", "                    ", "distances", "=", "distance_fn", "(", "repr1", ",", "repr2", ")", "\n", "\n", "recall", "=", "recall_at_k_from_distances", "(", "distances", ",", "k", ")", "\n", "print", "(", "f\"{recall.numpy():.5f}\"", ",", "end", "=", "\"\\t\"", ")", "\n", "\n", "if", "lng1", "!=", "lng2", ":", "\n", "                        ", "recalls_to_avg", ".", "append", "(", "recall", ".", "numpy", "(", ")", ")", "\n", "", "", "print", "(", ")", "\n", "", "print", "(", "f\"On average: {np.mean(recalls_to_avg):.5f}\"", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center": [[18, 20], ["lng_repr.mean"], "function", ["None"], ["def", "center", "(", "lng_repr", ")", ":", "\n", "    ", "return", "lng_repr", "-", "lng_repr", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.main": [[22, 86], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "utils.load_word_embeddings", "utils.load_word_embeddings", "torch.from_numpy", "torch.from_numpy", "cosine.cpu().detach().numpy", "print", "exit", "numpy.stack", "numpy.stack", "qe_by_cosine_embeddings.center", "qe_by_cosine_embeddings.center", "qe_by_cosine.apply_sklearn_proj", "qe_by_cosine.apply_sklearn_proj", "print", "utils.word_embeddings_for_file", "utils.word_embeddings_for_file", "cosine.cpu().detach", "cosine.cpu"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine_embeddings.center", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt_emb\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Source language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Target language code.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vecotr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, center representations first.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mt-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "center_lng", "and", "(", "\n", "args", ".", "src_proj", "is", "not", "None", "and", "args", ".", "src_proj", "is", "not", "None", ")", ":", "\n", "        ", "print", "(", "\"You can either project or center \"", "\n", "\"the representations, not both.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "\n", "src_embeddings", "=", "load_word_embeddings", "(", "args", ".", "src_emb", ")", "\n", "mt_embeddings", "=", "load_word_embeddings", "(", "args", ".", "mt_emb", ")", "\n", "\n", "src_repr", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "\n", "word_embeddings_for_file", "(", "args", ".", "src", ",", "src_embeddings", ",", "args", ".", "src_lng", ")", ")", ")", "\n", "mt_repr", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "\n", "word_embeddings_for_file", "(", "args", ".", "mt", ",", "mt_embeddings", ",", "args", ".", "mt_lng", ")", ")", ")", "\n", "\n", "if", "args", ".", "center_lng", ":", "\n", "        ", "src_repr", "=", "center", "(", "src_repr", ")", "\n", "mt_repr", "=", "center", "(", "mt_repr", ")", "\n", "\n", "", "if", "args", ".", "src_proj", "is", "not", "None", ":", "\n", "        ", "src_repr", "=", "apply_sklearn_proj", "(", "src_repr", ",", "args", ".", "src_proj", ")", "\n", "", "if", "args", ".", "mt_proj", "is", "not", "None", ":", "\n", "        ", "mt_repr", "=", "apply_sklearn_proj", "(", "mt_repr", ",", "args", ".", "mt_proj", ")", "\n", "\n", "\n", "", "src_norm", "=", "(", "src_repr", "*", "src_repr", ")", ".", "sum", "(", "1", ")", ".", "sqrt", "(", ")", "\n", "mt_norm", "=", "(", "mt_repr", "*", "mt_repr", ")", ".", "sum", "(", "1", ")", ".", "sqrt", "(", ")", "\n", "\n", "cosine", "=", "(", "src_repr", "*", "mt_repr", ")", ".", "sum", "(", "1", ")", "/", "src_norm", "/", "mt_norm", "\n", "\n", "for", "num", "in", "cosine", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ":", "\n", "        ", "print", "(", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.binarize_embeddings.main": [[15, 23], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.load_word_embeddings", "joblib.dump"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"vec_file\"", ",", "type", "=", "str", ",", "help", "=", "\"File with embeddings\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "embeddings", "=", "load_word_embeddings", "(", "args", ".", "vec_file", ")", "\n", "\n", "joblib", ".", "dump", "(", "embeddings", ",", "args", ".", "vec_file", "+", "\".bin\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_bertscore.apply_sklearn_proj": [[21, 25], ["print", "joblib.load", "joblib.load.predict"], "function", ["None"], ["def", "apply_sklearn_proj", "(", "representations", ",", "model_path", ")", ":", "\n", "    ", "print", "(", "\"Projecting representations.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "model", "=", "joblib", ".", "load", "(", "model_path", ")", "\n", "return", "[", "model", ".", "predict", "(", "rep", ")", "for", "rep", "in", "representations", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_bertscore.main": [[27, 104], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "print", "print", "zip", "print", "exit", "utils.load_bert", "open", "open", "numpy.mean", "numpy.mean", "qe_by_bertscore.apply_sklearn_proj", "qe_by_bertscore.apply_sklearn_proj", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims", "similarity.max().sum", "similarity.max().sum", "[].numpy", "[].numpy", "numpy.dot", "numpy.expand_dims", "numpy.linalg.norm", "numpy.linalg.norm", "similarity.max", "similarity.max", "utils.vectors_for_sentence", "utils.vectors_for_sentence", "line.rstrip", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.vectors_for_sentence", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.vectors_for_sentence"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt\"", ",", "type", "=", "str", ",", "help", "=", "\"Machine-translated sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, center representations first.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mt-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "center_lng", "and", "(", "\n", "args", ".", "src_proj", "is", "not", "None", "and", "args", ".", "src_proj", "is", "not", "None", ")", ":", "\n", "        ", "print", "(", "\"You can either project or center \"", "\n", "\"the representations, not both.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "print", "(", "f\"Loading src: {args.src}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "with", "open", "(", "args", ".", "src", ")", "as", "f_src", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "src_repr", "=", "[", "\n", "vectors_for_sentence", "(", "\n", "tokenizer", ",", "model", ",", "line", ".", "rstrip", "(", ")", ",", "args", ".", "layer", ")", "[", "0", "]", ".", "numpy", "(", ")", "\n", "for", "line", "in", "f_src", "]", "\n", "\n", "", "", "print", "(", "f\"Loading mt: {args.mt}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "with", "open", "(", "args", ".", "mt", ")", "as", "f_mt", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "mt_repr", "=", "[", "\n", "vectors_for_sentence", "(", "\n", "tokenizer", ",", "model", ",", "line", ".", "rstrip", "(", ")", ",", "args", ".", "layer", ")", "[", "0", "]", ".", "numpy", "(", ")", "\n", "for", "line", "in", "f_mt", "]", "\n", "\n", "", "", "if", "args", ".", "center_lng", ":", "\n", "        ", "src_center", "=", "np", ".", "mean", "(", "np", ".", "concatenate", "(", "src_repr", ")", ",", "0", ")", "\n", "mt_center", "=", "np", ".", "mean", "(", "np", ".", "concatenate", "(", "mt_repr", ")", ",", "0", ")", "\n", "\n", "src_repr", "=", "[", "r", "-", "src_center", "for", "r", "in", "src_repr", "]", "\n", "mt_repr", "=", "[", "r", "-", "mt_center", "for", "r", "in", "mt_repr", "]", "\n", "\n", "", "if", "args", ".", "src_proj", "is", "not", "None", ":", "\n", "        ", "src_repr", "=", "apply_sklearn_proj", "(", "src_repr", ",", "args", ".", "src_proj", ")", "\n", "", "if", "args", ".", "mt_proj", "is", "not", "None", ":", "\n", "        ", "mt_repr", "=", "apply_sklearn_proj", "(", "mt_repr", ",", "args", ".", "mt_proj", ")", "\n", "\n", "", "for", "src", ",", "mt", "in", "zip", "(", "src_repr", ",", "mt_repr", ")", ":", "\n", "        ", "similarity", "=", "(", "\n", "np", ".", "dot", "(", "src", ",", "mt", ".", "T", ")", "\n", "/", "np", ".", "expand_dims", "(", "np", ".", "linalg", ".", "norm", "(", "src", ",", "axis", "=", "1", ")", ",", "1", ")", "\n", "/", "np", ".", "expand_dims", "(", "np", ".", "linalg", ".", "norm", "(", "mt", ",", "axis", "=", "1", ")", ",", "0", ")", ")", "\n", "\n", "recall", "=", "similarity", ".", "max", "(", "1", ")", ".", "sum", "(", ")", "/", "similarity", ".", "shape", "[", "0", "]", "\n", "precision", "=", "similarity", ".", "max", "(", "0", ")", ".", "sum", "(", ")", "/", "similarity", ".", "shape", "[", "1", "]", "\n", "\n", "if", "recall", "+", "precision", ">", "0", ":", "\n", "            ", "f_score", "=", "2", "*", "recall", "*", "precision", "/", "(", "recall", "+", "precision", ")", "\n", "", "else", ":", "\n", "            ", "f_score", "=", "0", "\n", "\n", "", "print", "(", "f_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id_embeddings.load_dataset": [[10, 27], ["open", "open", "zip", "numpy.stack", "numpy.array", "lng.strip.strip", "utils.mean_word_embedding", "representations.append", "targets.append", "sentence.strip", "tuple"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.mean_word_embedding"], ["def", "load_dataset", "(", "txt_file", ",", "lng_file", ",", "all_embeddings", ",", "lng2idx", ")", ":", "\n", "    ", "representations", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "with", "open", "(", "txt_file", ")", "as", "f_txt", ",", "open", "(", "lng_file", ")", "as", "f_lng", ":", "\n", "        ", "for", "sentence", ",", "lng", "in", "zip", "(", "f_txt", ",", "f_lng", ")", ":", "\n", "            ", "lng", "=", "lng", ".", "strip", "(", ")", "\n", "vector", "=", "mean_word_embedding", "(", "\n", "all_embeddings", "[", "lng", "]", ",", "sentence", ".", "strip", "(", ")", ",", "lng", ")", "\n", "\n", "if", "vector", ".", "shape", "==", "tuple", "(", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "representations", ".", "append", "(", "vector", ")", "\n", "targets", ".", "append", "(", "lng2idx", "[", "lng", "]", ")", "\n", "\n", "", "", "return", "np", ".", "stack", "(", "representations", ")", ",", "np", ".", "array", "(", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id_embeddings.main": [[29, 93], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "print", "lang_id_embeddings.load_dataset", "print", "lang_id_embeddings.load_dataset", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.predict", "numpy.mean", "print", "open", "utils.load_word_embeddings", "numpy.stack", "line.strip", "enumerate", "numpy.mean", "range", "len"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id_embeddings.load_dataset", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id_embeddings.load_dataset", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"embeddings_prefix\"", ",", "type", "=", "str", ",", "help", "=", "\"Directory with word embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"languages\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"File with a list of languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Training sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data_lng\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Language codes for training sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"val_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Validation sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"val_data_lng\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Language codes for validation sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Test sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_data_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Language codes for test sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-model\"", ",", "type", "=", "str", ",", "help", "=", "\"Path where to save the best model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-centroids\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to save language centroids.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test-output\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Output for example classification.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Center languages to be around coordinate origin.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "languages", ")", "as", "f_lang", ":", "\n", "        ", "languages", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f_lang", "]", "\n", "", "lng2idx", "=", "{", "lng", ":", "i", "for", "i", ",", "lng", "in", "enumerate", "(", "languages", ")", "}", "\n", "\n", "print", "(", "\"Loading embeddings.\"", ")", "\n", "all_embeddings", "=", "{", "\n", "lng", ":", "load_word_embeddings", "(", "f\"{args.embeddings_prefix}/{lng}.vec\"", ")", "\n", "for", "lng", "in", "languages", "}", "\n", "\n", "print", "(", "\"Loading training data.\"", ")", "\n", "train_repr", ",", "train_tgt", "=", "load_dataset", "(", "\n", "args", ".", "train_data_txt", ",", "args", ".", "train_data_lng", ",", "all_embeddings", ",", "lng2idx", ")", "\n", "print", "(", "\"Loading test data.\"", ")", "\n", "test_repr", ",", "test_tgt", "=", "load_dataset", "(", "\n", "args", ".", "test_data_txt", ",", "args", ".", "test_data_lng", ",", "all_embeddings", ",", "lng2idx", ")", "\n", "\n", "if", "args", ".", "center_lng", ":", "\n", "        ", "centroids", "=", "np", ".", "stack", "(", "[", "\n", "np", ".", "mean", "(", "train_repr", "[", "train_tgt", "==", "i", "]", ",", "axis", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "all_embeddings", ")", ")", "]", ")", "\n", "train_repr", "=", "train_repr", "-", "centroids", "[", "train_tgt", "]", "\n", "test_repr", "=", "test_repr", "-", "centroids", "[", "test_tgt", "]", "\n", "\n", "", "model", "=", "LogisticRegression", "(", ")", "\n", "model", ".", "fit", "(", "train_repr", ",", "train_tgt", ")", "\n", "\n", "test_prediction", "=", "model", ".", "predict", "(", "test_repr", ")", "\n", "\n", "accuracy", "=", "np", ".", "mean", "(", "test_prediction", "==", "test_tgt", ")", "\n", "print", "(", "accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_regression.main": [[24, 110], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "print", "sklearn.neural_network.MLPRegressor", "sklearn.neural_network.MLPRegressor.fit", "print", "sklearn.neural_network.MLPRegressor.predict", "print", "exit", "utils.load_bert", "qe_by_cosine.repr_for_txt_file().numpy", "qe_by_cosine.repr_for_txt_file().numpy", "open", "numpy.array", "qe_by_cosine.repr_for_txt_file().numpy", "qe_by_cosine.repr_for_txt_file().numpy", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "numpy.concatenate", "numpy.concatenate", "qe_by_cosine.repr_for_txt_file", "qe_by_cosine.repr_for_txt_file", "float", "qe_by_cosine.repr_for_txt_file", "qe_by_cosine.repr_for_txt_file", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_src\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sentences in source language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_mt\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Machine-translated sentences for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_hter\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Machine-translated sentences for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language for testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_mt\"", ",", "type", "=", "str", ",", "help", "=", "\"Machine-translated sentences for testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--exclude-src\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Exclude source representatiion from the classifier.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--exclude-mt\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Exclude target representatiion from the classifier.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vecotr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "exclude_src", "and", "args", ".", "exclude_mt", ":", "\n", "        ", "print", "(", "\"You cannot exclude both source and MT!\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "if", "not", "args", ".", "exclude_src", ":", "\n", "        ", "train_src_repr", "=", "repr_for_txt_file", "(", "\n", "args", ".", "train_src", ",", "tokenizer", ",", "model", ",", "device", ",", "args", ".", "layer", ",", "\n", "center_lng", "=", "False", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", ".", "numpy", "(", ")", "\n", "", "if", "not", "args", ".", "exclude_mt", ":", "\n", "        ", "train_mt_repr", "=", "repr_for_txt_file", "(", "\n", "args", ".", "train_mt", ",", "tokenizer", ",", "model", ",", "device", ",", "args", ".", "layer", ",", "\n", "center_lng", "=", "False", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", ".", "numpy", "(", ")", "\n", "", "if", "args", ".", "exclude_src", ":", "\n", "        ", "train_inputs", "=", "train_mt_repr", "\n", "", "elif", "args", ".", "exclude_mt", ":", "\n", "        ", "train_inputs", "=", "train_src_repr", "\n", "", "else", ":", "\n", "        ", "train_inputs", "=", "np", ".", "concatenate", "(", "(", "train_src_repr", ",", "train_mt_repr", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "train_hter", ")", "as", "f_tgt", ":", "\n", "        ", "train_targets", "=", "np", ".", "array", "(", "[", "float", "(", "line", ".", "rstrip", "(", ")", ")", "for", "line", "in", "f_tgt", "]", ")", "\n", "\n", "", "print", "(", "\"Training regression ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "regressor", "=", "MLPRegressor", "(", "(", "256", ")", ",", "early_stopping", "=", "True", ")", "\n", "regressor", ".", "fit", "(", "train_inputs", ",", "train_targets", ")", "\n", "print", "(", "\"Done.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "if", "not", "args", ".", "exclude_src", ":", "\n", "        ", "test_src_repr", "=", "repr_for_txt_file", "(", "\n", "args", ".", "test_src", ",", "tokenizer", ",", "model", ",", "device", ",", "args", ".", "layer", ",", "\n", "center_lng", "=", "False", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", ".", "numpy", "(", ")", "\n", "", "if", "not", "args", ".", "exclude_mt", ":", "\n", "        ", "test_mt_repr", "=", "repr_for_txt_file", "(", "\n", "args", ".", "test_mt", ",", "tokenizer", ",", "model", ",", "device", ",", "args", ".", "layer", ",", "\n", "center_lng", "=", "False", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", ".", "numpy", "(", ")", "\n", "\n", "", "if", "args", ".", "exclude_src", ":", "\n", "        ", "test_inputs", "=", "test_mt_repr", "\n", "", "elif", "args", ".", "exclude_mt", ":", "\n", "        ", "test_inputs", "=", "test_src_repr", "\n", "", "else", ":", "\n", "        ", "test_inputs", "=", "np", ".", "concatenate", "(", "(", "test_src_repr", ",", "test_mt_repr", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "predictions", "=", "regressor", ".", "predict", "(", "test_inputs", ")", "\n", "\n", "for", "num", "in", "predictions", ":", "\n", "        ", "print", "(", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file": [[22, 40], ["print", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat", "torch.cat", "torch.cat", "utils.get_repr_from_layer().cpu", "utils.batch_generator", "torch.cat.mean", "utils.get_repr_from_layer", "utils.text_data_generator", "sentence_tensor.to"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_repr_from_layer", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator"], ["def", "repr_for_txt_file", "(", "\n", "filename", ",", "tokenizer", ",", "model", ",", "device", ",", "layer", ",", "\n", "center_lng", "=", "True", ",", "mean_pool", "=", "True", ")", ":", "\n", "    ", "print", "(", "f\"Processing {filename} ... \"", ",", "file", "=", "sys", ".", "stderr", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "vectors", "=", "[", "\n", "get_repr_from_layer", "(", "\n", "model", ",", "sentence_tensor", ".", "to", "(", "device", ")", ",", "layer", ",", "\n", "tokenizer", ".", "pad_token_id", ",", "\n", "mean_pool", "=", "mean_pool", ")", ".", "cpu", "(", ")", "\n", "for", "sentence_tensor", "in", "batch_generator", "(", "\n", "text_data_generator", "(", "filename", ",", "tokenizer", ")", ",", "32", ",", "tokenizer", ")", "]", "\n", "\n", "lng_repr", "=", "torch", ".", "cat", "(", "vectors", ",", "dim", "=", "0", ")", "\n", "if", "center_lng", ":", "\n", "            ", "lng_repr", "=", "lng_repr", "-", "lng_repr", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "", "", "print", "(", "\"Done.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "lng_repr", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj": [[42, 46], ["print", "joblib.load", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "joblib.load.predict", "representations.numpy"], "function", ["None"], ["", "def", "apply_sklearn_proj", "(", "representations", ",", "model_path", ")", ":", "\n", "    ", "print", "(", "\"Projecting representations.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "model", "=", "joblib", ".", "load", "(", "model_path", ")", "\n", "return", "torch", ".", "from_numpy", "(", "model", ".", "predict", "(", "representations", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.main": [[48, 106], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "qe_by_cosine.repr_for_txt_file", "qe_by_cosine.repr_for_txt_file", "cosine.cpu().detach().numpy", "print", "exit", "utils.load_bert", "qe_by_cosine.apply_sklearn_proj", "qe_by_cosine.apply_sklearn_proj", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "cosine.cpu().detach", "cosine.cpu"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.repr_for_txt_file", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.qe_by_cosine.apply_sklearn_proj"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"src\"", ",", "type", "=", "str", ",", "help", "=", "\"Sentences in source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"mt\"", ",", "type", "=", "str", ",", "help", "=", "\"Machine-translated sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vecotr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, center representations first.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the source language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mt-proj\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Sklearn projection of the target language.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "center_lng", "and", "(", "\n", "args", ".", "src_proj", "is", "not", "None", "and", "args", ".", "src_proj", "is", "not", "None", ")", ":", "\n", "        ", "print", "(", "\"You can either project or center \"", "\n", "\"the representations, not both.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "src_repr", "=", "repr_for_txt_file", "(", "\n", "args", ".", "src", ",", "tokenizer", ",", "model", ",", "device", ",", "args", ".", "layer", ",", "\n", "center_lng", "=", "args", ".", "center_lng", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", "\n", "mt_repr", "=", "repr_for_txt_file", "(", "\n", "args", ".", "mt", ",", "tokenizer", ",", "model", ",", "device", ",", "args", ".", "layer", ",", "\n", "center_lng", "=", "args", ".", "center_lng", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", "\n", "\n", "if", "args", ".", "src_proj", "is", "not", "None", ":", "\n", "        ", "src_repr", "=", "apply_sklearn_proj", "(", "src_repr", ",", "args", ".", "src_proj", ")", "\n", "", "if", "args", ".", "mt_proj", "is", "not", "None", ":", "\n", "        ", "mt_repr", "=", "apply_sklearn_proj", "(", "mt_repr", ",", "args", ".", "mt_proj", ")", "\n", "\n", "", "src_norm", "=", "(", "src_repr", "*", "src_repr", ")", ".", "sum", "(", "1", ")", ".", "sqrt", "(", ")", "\n", "mt_norm", "=", "(", "mt_repr", "*", "mt_repr", ")", ".", "sum", "(", "1", ")", ".", "sqrt", "(", ")", "\n", "\n", "cosine", "=", "(", "src_repr", "*", "mt_repr", ")", ".", "sum", "(", "1", ")", "/", "src_norm", "/", "mt_norm", "\n", "\n", "for", "num", "in", "cosine", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ":", "\n", "        ", "print", "(", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.lng_data_generator": [[20, 27], ["range", "open", "line.strip", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["def", "lng_data_generator", "(", "path", ",", "lng2idx", ",", "epochs", "=", "1", ")", ":", "\n", "    ", "for", "_", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f_lang", ":", "\n", "            ", "for", "line", "in", "f_lang", ":", "\n", "                ", "lng", "=", "line", ".", "strip", "(", ")", "\n", "lng_id", "=", "lng2idx", "[", "lng", "]", "\n", "yield", "torch", ".", "tensor", "(", "lng_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.get_centroids": [[29, 43], ["torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "text_repr[].mean", "torch.cat", "torch.cat", "torch.cat", "utils.get_repr_from_layer", "len", "torch.cat.size", "d.to"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_repr_from_layer"], ["", "", "", "", "def", "get_centroids", "(", "\n", "device", ",", "model", ",", "data", ",", "languages", ",", "labels", ",", "layer", ",", "tokenizer", ",", "mean_pool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get language centeroids based on labels.\"\"\"", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ")", ".", "to", "(", "device", ")", "\n", "text_repr", "=", "torch", ".", "cat", "(", "[", "\n", "get_repr_from_layer", "(", "model", ",", "d", ".", "to", "(", "device", ")", ",", "layer", ",", "\n", "tokenizer", ".", "pad_token_id", ",", "mean_pool", "=", "mean_pool", ")", "\n", "for", "d", "in", "data", "]", ")", "\n", "centroids", "=", "torch", ".", "zeros", "(", "(", "len", "(", "languages", ")", ",", "text_repr", ".", "size", "(", "1", ")", ")", ")", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "languages", ")", ":", "\n", "        ", "centroids", "[", "i", "]", "=", "text_repr", "[", "labels", "==", "i", "]", ".", "mean", "(", "0", ")", "\n", "\n", "", "return", "centroids", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.load_and_batch_data": [[45, 54], ["utils.batch_generator", "utils.batch_generator", "zip", "utils.text_data_generator", "lang_id.lng_data_generator"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.lng_data_generator"], ["", "def", "load_and_batch_data", "(", "txt", ",", "lng", ",", "tokenizer", ",", "lng2idx", ",", "batch_size", "=", "32", ",", "epochs", "=", "1", ")", ":", "\n", "    ", "text_batches", "=", "batch_generator", "(", "\n", "text_data_generator", "(", "\n", "txt", ",", "tokenizer", ",", "epochs", "=", "epochs", ",", "max_len", "=", "110", ")", ",", "\n", "size", "=", "batch_size", ",", "tokenizer", "=", "tokenizer", ",", "padding", "=", "True", ")", "\n", "lng_batches", "=", "batch_generator", "(", "\n", "lng_data_generator", "(", "lng", ",", "lng2idx", ",", "epochs", "=", "epochs", ")", ",", "\n", "size", "=", "batch_size", ",", "tokenizer", "=", "None", ",", "padding", "=", "False", ")", "\n", "return", "zip", "(", "text_batches", ",", "lng_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.main": [[56, 317], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "utils.load_bert", "hasattr", "hasattr", "lang_id.load_and_batch_data", "print", "print", "list", "print", "print", "list", "print", "print", "range", "print", "print", "print", "print", "print", "print", "numpy.argmax", "print", "open", "print", "exit", "print", "exit", "print", "get_centroids.to", "lang_id.load_and_batch_data", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lang_id.load_and_batch_data", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "print", "nn.Sequential.to", "torch.CrossEntropyLoss", "torch.Adam", "enumerate", "model.eval", "lang_id.main.evaluate"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.load_and_batch_data", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.load_and_batch_data", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.load_and_batch_data"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"languages\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"File with a list of languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Training sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data_lng\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Language codes for training sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"val_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Validation sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"val_data_lng\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Language codes for validation sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Test sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"test_data_lng\"", ",", "type", "=", "str", ",", "help", "=", "\"Language codes for test sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--hidden\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Size of the hidden classification layer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-model\"", ",", "type", "=", "str", ",", "help", "=", "\"Path where to save the best model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-centroids\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to save language centroids.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test-output\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Output for example classification.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--skip-tokenization\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Only split on spaces, skip wordpieces.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vecotr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Center languages to be around coordinate origin.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "languages", ")", "as", "f_lang", ":", "\n", "        ", "languages", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f_lang", "]", "\n", "", "lng2idx", "=", "{", "lng", ":", "i", "for", "i", ",", "lng", "in", "enumerate", "(", "languages", ")", "}", "\n", "\n", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", ",", "model_dim", ",", "_", "=", "load_bert", "(", "\n", "args", ".", "bert_model", ",", "device", ")", "\n", "\n", "if", "args", ".", "layer", "<", "-", "1", ":", "\n", "        ", "print", "(", "\"Layer index cannot be negative.\"", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "num_layers", "=", "None", "\n", "if", "hasattr", "(", "model", ".", "config", ",", "\"num_hidden_layers\"", ")", ":", "\n", "        ", "num_layers", "=", "model", ".", "config", ".", "num_hidden_layers", "\n", "", "if", "hasattr", "(", "model", ".", "config", ",", "\"n_layers\"", ")", ":", "\n", "        ", "num_layers", "=", "model", ".", "config", ".", "n_layers", "\n", "", "if", "args", ".", "layer", ">=", "num_layers", ":", "\n", "        ", "print", "(", "f\"Model only has {num_layers} layers, {args.layer} is too much.\"", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "train_batches", "=", "load_and_batch_data", "(", "\n", "args", ".", "train_data_txt", ",", "args", ".", "train_data_lng", ",", "tokenizer", ",", "\n", "lng2idx", ",", "batch_size", "=", "32", ",", "epochs", "=", "1000", ")", "\n", "print", "(", "\"Train data iterator initialized.\"", ")", "\n", "\n", "centroids", "=", "None", "\n", "if", "args", ".", "center_lng", ":", "\n", "        ", "print", "(", "\"Estimating language centroids.\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "texts", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "for", "_", ",", "(", "txt", ",", "lab", ")", "in", "zip", "(", "range", "(", "100", ")", ",", "train_batches", ")", ":", "\n", "                ", "texts", ".", "append", "(", "txt", ")", "\n", "labels", ".", "append", "(", "lab", ")", "\n", "", "centroids", "=", "get_centroids", "(", "\n", "device", ",", "model", ",", "texts", ",", "languages", ",", "labels", ",", "\n", "args", ".", "layer", ",", "tokenizer", ",", "mean_pool", "=", "args", ".", "mean_pool", ")", "\n", "", "centroids", "=", "centroids", ".", "to", "(", "device", ")", "\n", "\n", "if", "args", ".", "save_centroids", ":", "\n", "            ", "torch", ".", "save", "(", "centroids", ".", "cpu", "(", ")", ",", "args", ".", "save_centroids", ")", "\n", "\n", "", "", "print", "(", "\"Loading validation data.\"", ")", "\n", "val_batches_raw", "=", "list", "(", "load_and_batch_data", "(", "\n", "args", ".", "val_data_txt", ",", "args", ".", "val_data_lng", ",", "tokenizer", ",", "\n", "lng2idx", ",", "batch_size", "=", "32", ",", "epochs", "=", "1", ")", ")", "\n", "print", "(", "\"Validation data loaded in memory, pre-computing BERT.\"", ")", "\n", "val_batches", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "tokens", ",", "lng", "in", "val_batches_raw", ":", "\n", "            ", "bert_features", "=", "get_repr_from_layer", "(", "\n", "model", ",", "tokens", ".", "to", "(", "device", ")", ",", "args", ".", "layer", ",", "\n", "tokenizer", ".", "pad_token_id", ",", "args", ".", "mean_pool", ")", ".", "cpu", "(", ")", "\n", "val_batches", ".", "append", "(", "(", "bert_features", ",", "lng", ")", ")", "\n", "\n", "", "", "print", "(", "\"Loading test data.\"", ")", "\n", "test_batches_raw", "=", "list", "(", "load_and_batch_data", "(", "\n", "args", ".", "test_data_txt", ",", "args", ".", "test_data_lng", ",", "tokenizer", ",", "\n", "lng2idx", ",", "batch_size", "=", "32", ",", "epochs", "=", "1", ")", ")", "\n", "print", "(", "\"Test data loaded in memory, pre-computing BERT.\"", ")", "\n", "test_batches", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "tokens", ",", "lng", "in", "test_batches_raw", ":", "\n", "            ", "bert_features", "=", "get_repr_from_layer", "(", "\n", "model", ",", "tokens", ".", "to", "(", "device", ")", ",", "args", ".", "layer", ",", "\n", "tokenizer", ".", "pad_token_id", ",", "args", ".", "mean_pool", ")", ".", "cpu", "(", ")", "\n", "test_batches", ".", "append", "(", "(", "bert_features", ",", "lng", ")", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "test_accuracies", "=", "[", "]", "\n", "all_test_outputs", "=", "[", "]", "\n", "trained_models", "=", "[", "]", "\n", "\n", "for", "exp_no", "in", "range", "(", "5", ")", ":", "\n", "        ", "print", "(", "f\"Starting experiment no {exp_no + 1}\"", ")", "\n", "print", "(", "f\"------------------------------------\"", ")", "\n", "if", "args", ".", "hidden", "is", "None", ":", "\n", "            ", "classifier", "=", "nn", ".", "Linear", "(", "model_dim", ",", "len", "(", "languages", ")", ")", "\n", "", "else", ":", "\n", "            ", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_dim", ",", "args", ".", "hidden", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden", ",", "len", "(", "languages", ")", ")", ")", "\n", "", "classifier", "=", "classifier", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "classifier", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "\n", "def", "evaluate", "(", "data_batches", ")", ":", "\n", "            ", "classifier", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "running_val_loss", "=", "0.", "\n", "running_val_acc", "=", "0.", "\n", "val_count", "=", "0", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "bert_features", ",", "lng", "in", "data_batches", ":", "\n", "                    ", "bert_features", ",", "lng", "=", "(", "\n", "bert_features", ".", "to", "(", "device", ")", ",", "lng", ".", "to", "(", "device", ")", ")", "\n", "batch_size", "=", "bert_features", ".", "size", "(", "0", ")", "\n", "\n", "if", "centroids", "is", "not", "None", ":", "\n", "                        ", "bert_features", "=", "bert_features", "-", "centroids", "[", "lng", "]", "\n", "", "prediction", "=", "classifier", "(", "bert_features", ")", "\n", "batch_loss", "=", "criterion", "(", "prediction", ",", "lng", ")", "\n", "\n", "predicted_lng", "=", "prediction", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "batch_accuracy", "=", "torch", ".", "sum", "(", "(", "predicted_lng", "==", "lng", ")", ".", "float", "(", ")", ")", "\n", "\n", "running_val_loss", "+=", "(", "\n", "batch_size", "*", "batch_loss", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "running_val_acc", "+=", "batch_accuracy", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "val_count", "+=", "batch_size", "\n", "\n", "outputs", ".", "extend", "(", "predicted_lng", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "val_loss", "=", "running_val_loss", "/", "val_count", "\n", "accuracy", "=", "running_val_acc", "/", "val_count", "\n", "\n", "", "return", "val_loss", ",", "accuracy", ",", "outputs", "\n", "\n", "", "best_accuracy", "=", "0.0", "\n", "no_improvement", "=", "0", "\n", "learning_rate_decreased", "=", "0", "\n", "learning_rate", "=", "1e-3", "\n", "\n", "for", "i", ",", "(", "sentences", ",", "lng", ")", "in", "enumerate", "(", "train_batches", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "classifier", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "sentences", ",", "lng", "=", "sentences", ".", "to", "(", "device", ")", ",", "lng", ".", "to", "(", "device", ")", "\n", "bert_features", "=", "get_repr_from_layer", "(", "\n", "model", ",", "sentences", ",", "args", ".", "layer", ",", "tokenizer", ".", "pad_token_id", ",", "\n", "mean_pool", "=", "args", ".", "mean_pool", ")", "\n", "\n", "if", "centroids", "is", "not", "None", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "bert_features", "=", "bert_features", "-", "centroids", "[", "lng", "]", "\n", "\n", "", "", "prediction", "=", "classifier", "(", "bert_features", ")", "\n", "\n", "loss", "=", "criterion", "(", "prediction", ",", "lng", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "i", "%", "10", "==", "9", ":", "\n", "                    ", "print", "(", "f\"loss: {loss.cpu().detach().numpy().tolist():5g}\"", ")", "\n", "\n", "", "if", "i", "%", "50", "==", "49", ":", "\n", "                    ", "print", "(", ")", "\n", "val_loss", ",", "accuracy", ",", "_", "=", "evaluate", "(", "val_batches", ")", "\n", "\n", "print", "(", "\"Validation: \"", "\n", "f\"loss: {val_loss:5g}, \"", "\n", "f\"accuracy: {accuracy:5g}\"", ")", "\n", "\n", "if", "accuracy", ">", "best_accuracy", ":", "\n", "                        ", "best_accuracy", "=", "accuracy", "\n", "no_improvement", "=", "0", "\n", "", "else", ":", "\n", "                        ", "no_improvement", "+=", "1", "\n", "\n", "", "if", "no_improvement", ">=", "5", ":", "\n", "                        ", "if", "learning_rate_decreased", ">=", "5", ":", "\n", "                            ", "print", "(", "\n", "\"Learning rate decreased five times, ending.\"", ")", "\n", "break", "\n", "\n", "", "learning_rate", "/=", "2", "\n", "print", "(", "f\"Decreasing learning rate to {learning_rate}.\"", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                            ", "param_group", "[", "'lr'", "]", "=", "learning_rate", "\n", "", "learning_rate_decreased", "+=", "1", "\n", "no_improvement", "=", "0", "\n", "\n", "", "print", "(", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "break", "\n", "\n", "", "", "model", ".", "eval", "(", ")", "\n", "test_loss", ",", "test_accuracy", ",", "test_outputs", "=", "evaluate", "(", "test_batches", ")", "\n", "print", "(", ")", "\n", "print", "(", "\"Testing:\"", ")", "\n", "print", "(", "f\"test loss: {test_loss:5g}, \"", "\n", "f\"test accuracy: {test_accuracy:5g}\"", ")", "\n", "\n", "test_accuracies", ".", "append", "(", "test_accuracy", ")", "\n", "\n", "this_test_outputs", "=", "[", "]", "\n", "for", "lng_prediction", "in", "test_outputs", ":", "\n", "            ", "this_test_outputs", ".", "append", "(", "languages", "[", "lng_prediction", "]", ")", "\n", "", "all_test_outputs", ".", "append", "(", "this_test_outputs", ")", "\n", "trained_models", ".", "append", "(", "classifier", ".", "cpu", "(", ")", ")", "\n", "\n", "", "print", "(", ")", "\n", "print", "(", "\"===============================================\"", ")", "\n", "print", "(", "\"All experiments done.\"", ")", "\n", "print", "(", "\"===============================================\"", ")", "\n", "print", "(", "f\"Mean test accuracy {np.mean(test_accuracies)}\"", ")", "\n", "print", "(", "f\"Mean test stdev    {np.std(test_accuracies)}\"", ")", "\n", "\n", "best_exp_id", "=", "np", ".", "argmax", "(", "test_accuracies", ")", "\n", "\n", "print", "(", "f\"Best test accuracy {max(test_accuracies)}\"", ")", "\n", "\n", "if", "args", ".", "save_model", ":", "\n", "        ", "torch", ".", "save", "(", "trained_models", "[", "best_exp_id", "]", ",", "args", ".", "save_model", ")", "\n", "\n", "", "if", "args", ".", "test_output", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "args", ".", "test_output", ",", "'w'", ")", "as", "f_out", ":", "\n", "            ", "for", "prediction", "in", "all_test_outputs", "[", "best_exp_id", "]", ":", "\n", "                ", "print", "(", "prediction", ",", "file", "=", "f_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval.cosine_distances": [[22, 27], ["torch.matmul", "torch.matmul", "torch.matmul", "mat2.t"], "function", ["None"], ["def", "cosine_distances", "(", "mat1", ",", "mat2", ")", ":", "\n", "    ", "mat1_norms", "=", "(", "mat1", "*", "mat1", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "\n", "mat2_norms", "=", "(", "mat2", "*", "mat2", ")", ".", "sum", "(", "1", ")", ".", "sqrt", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "1", "-", "torch", ".", "matmul", "(", "mat1", ",", "mat2", ".", "t", "(", ")", ")", "/", "mat1_norms", "/", "mat2_norms", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval.euklid_distances": [[29, 35], ["mat1.unsqueeze().repeat", "mat2.unsqueeze().repeat", "mat1.unsqueeze", "mat2.unsqueeze"], "function", ["None"], ["", "def", "euklid_distances", "(", "mat1", ",", "mat2", ")", ":", "\n", "    ", "data_len", "=", "mat1", ".", "shape", "[", "0", "]", "\n", "differences", "=", "(", "\n", "mat1", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "data_len", ",", "1", ")", "-", "\n", "mat2", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "data_len", ",", "1", ",", "1", ")", ")", "\n", "return", "(", "differences", "**", "2", ")", ".", "sum", "(", "2", ")", ".", "sqrt", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval.recall_at_k_from_distances": [[37, 49], ["distances.topk", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "presence.mean", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "recall_at_k_from_distances", "(", "distances", ",", "k", ")", ":", "\n", "    ", "\"\"\"Computes recall at k using distance matrix.\n\n    Because the data is parallel, we always want to retrieve i-th\n    number from i-th row.\n    \"\"\"", "\n", "\n", "_", ",", "top_indices", "=", "distances", ".", "topk", "(", "k", ",", "dim", "=", "1", ",", "largest", "=", "False", ")", "\n", "targets", "=", "torch", ".", "arange", "(", "distances", ".", "shape", "[", "0", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "presence", "=", "(", "top_indices", "==", "targets", ")", ".", "sum", "(", "1", ")", ".", "float", "(", ")", "\n", "return", "presence", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval.main": [[51, 192], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "print", "exit", "print", "exit", "print", "exit", "utils.load_bert", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "all", "print", "len", "len", "ValueError", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "print", "torch.cat", "torch.cat", "torch.cat", "representations.append", "print", "range", "print", "print", "print", "zip", "print", "print", "projections.append", "projections.append", "utils.get_repr_from_layer", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "print", "zip", "print", "print", "zip", "print", "joblib.load", "utils.batch_generator", "torch.from_numpy.mean", "sklearn.linear_model.LinearRegression.predict", "zip", "distance_fn", "sentence_retrieval.recall_at_k_from_distances", "print", "utils.text_data_generator", "torch.from_numpy.numpy", "distance_fn", "sklearn.linear_model.LinearRegression", "sklearn.linear_model.LinearRegression.fit", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "recalls_to_avg.append", "numpy.mean", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.numpy", "retrieved.numpy", "sklearn.linear_model.LinearRegression.predict", "recall_at_k_from_distances.numpy", "sklearn.linear_model.LinearRegression.predict", "torch.from_numpy.numpy", "recall_at_k_from_distances.numpy", "torch.from_numpy.numpy", "distance_fn.min"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_repr_from_layer", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.sentence_retrieval.recall_at_k_from_distances", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"layer\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Layer from of layer from which the representation is taken.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Sentences with language for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--distance\"", ",", "choices", "=", "[", "\"cosine\"", ",", "\"euklid\"", "]", ",", "default", "=", "\"cosine\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--skip-tokenization\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Only split on spaces, skip wordpieces.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mean-pool\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, use mean-pooling instead of [CLS] vector.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--center-lng\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Center languages to be around coordinate origin.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--projections\"", ",", "default", "=", "None", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"List of sklearn projections for particular languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--em-iterations\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Iterations of projection self-learning.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "center_lng", "and", "args", ".", "projections", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"You cannot do projections and centering at once.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "(", "args", ".", "projections", "is", "not", "None", "and", "\n", "len", "(", "args", ".", "projections", ")", "!=", "len", "(", "args", ".", "data", ")", ")", ":", "\n", "        ", "print", "(", "\"You must have a projection for each data file.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "(", "args", ".", "projections", "is", "not", "None", "and", "\n", "args", ".", "em_iterations", "is", "not", "None", ")", ":", "\n", "        ", "print", "(", "\"You either have pre-trained projections or self-train them.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "projections", "=", "None", "\n", "if", "args", ".", "projections", "is", "not", "None", ":", "\n", "        ", "projections", "=", "[", "]", "\n", "for", "proj_str", "in", "args", ".", "projections", ":", "\n", "            ", "if", "proj_str", "==", "\"None\"", ":", "\n", "                ", "projections", ".", "append", "(", "None", ")", "\n", "", "else", ":", "\n", "                ", "projections", ".", "append", "(", "joblib", ".", "load", "(", "proj_str", ")", ")", "\n", "\n", "", "", "", "distance_fn", "=", "None", "\n", "if", "args", ".", "distance", "==", "\"cosine\"", ":", "\n", "        ", "distance_fn", "=", "cosine_distances", "\n", "", "elif", "args", ".", "distance", "==", "\"euklid\"", ":", "\n", "        ", "distance_fn", "=", "euklid_distances", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown distance function.\"", ")", "\n", "\n", "\n", "", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "tokenizer", ",", "model", "=", "load_bert", "(", "args", ".", "bert_model", ",", "device", ")", "[", ":", "2", "]", "\n", "\n", "representations", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "text_file", "in", "enumerate", "(", "args", ".", "data", ")", ":", "\n", "            ", "print", "(", "f\"Processing {text_file}\"", ")", "\n", "vectors", "=", "[", "\n", "get_repr_from_layer", "(", "\n", "model", ",", "sentence_tensor", ",", "args", ".", "layer", ",", "\n", "tokenizer", ".", "pad_token_id", ",", "\n", "mean_pool", "=", "args", ".", "mean_pool", ")", "\n", "for", "sentence_tensor", "in", "batch_generator", "(", "\n", "text_data_generator", "(", "text_file", ",", "tokenizer", ")", ",", "64", ",", "tokenizer", ")", "]", "\n", "\n", "lng_repr", "=", "torch", ".", "cat", "(", "vectors", ",", "dim", "=", "0", ")", "\n", "if", "args", ".", "center_lng", ":", "\n", "                ", "lng_repr", "=", "lng_repr", "-", "lng_repr", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "if", "projections", "is", "not", "None", "and", "projections", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "proj", "=", "projections", "[", "i", "]", "\n", "lng_repr", "=", "torch", ".", "from_numpy", "(", "proj", ".", "predict", "(", "lng_repr", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "representations", ".", "append", "(", "lng_repr", ")", "\n", "\n", "", "mutual_projections", "=", "None", "\n", "if", "args", ".", "em_iterations", "is", "not", "None", ":", "\n", "            ", "print", "(", "f\"EM training ...\"", ")", "\n", "new_mutual_projections", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "args", ".", "em_iterations", ")", ":", "\n", "                ", "print", "(", "f\" ... iteration {i + 1}\"", ")", "\n", "for", "lng1", ",", "repr1", "in", "zip", "(", "args", ".", "data", ",", "representations", ")", ":", "\n", "                    ", "for", "lng2", ",", "repr2", "in", "zip", "(", "args", ".", "data", ",", "representations", ")", ":", "\n", "                        ", "if", "mutual_projections", "is", "not", "None", ":", "\n", "                            ", "proj", "=", "mutual_projections", "[", "(", "lng1", ",", "lng2", ")", "]", "\n", "repr1", "=", "torch", ".", "from_numpy", "(", "\n", "proj", ".", "predict", "(", "repr1", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "distances", "=", "distance_fn", "(", "repr1", ",", "repr2", ")", "\n", "retrieved", "=", "repr2", "[", "distances", ".", "min", "(", "dim", "=", "1", ")", "[", "1", "]", "]", "\n", "proj", "=", "LinearRegression", "(", ")", "\n", "proj", ".", "fit", "(", "repr1", ".", "numpy", "(", ")", ",", "retrieved", ".", "numpy", "(", ")", ")", "\n", "new_mutual_projections", "[", "(", "lng1", ",", "lng2", ")", "]", "=", "proj", "\n", "", "", "mutual_projections", "=", "new_mutual_projections", "\n", "\n", "", "", "data_len", "=", "representations", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "assert", "all", "(", "r", ".", "shape", "[", "0", "]", "==", "data_len", "for", "r", "in", "representations", ")", "\n", "print", "(", ")", "\n", "for", "k", "in", "[", "1", ",", "5", ",", "10", ",", "20", ",", "50", ",", "100", "]", ":", "\n", "            ", "print", "(", "f\"Recall at {k}, random baseline {k / data_len:.5f}\"", ")", "\n", "print", "(", "\"--\"", ",", "end", "=", "\"\\t\"", ")", "\n", "for", "lng", "in", "args", ".", "data", ":", "\n", "                ", "print", "(", "lng", "[", "-", "6", ":", "-", "4", "]", ",", "end", "=", "\"\\t\"", ")", "\n", "", "print", "(", ")", "\n", "\n", "recalls_to_avg", "=", "[", "]", "\n", "\n", "for", "lng1", ",", "repr1", "in", "zip", "(", "args", ".", "data", ",", "representations", ")", ":", "\n", "                ", "print", "(", "lng1", "[", "-", "6", ":", "-", "4", "]", ",", "end", "=", "\"\\t\"", ")", "\n", "for", "lng2", ",", "repr2", "in", "zip", "(", "args", ".", "data", ",", "representations", ")", ":", "\n", "\n", "                    ", "if", "mutual_projections", "is", "not", "None", ":", "\n", "                        ", "proj", "=", "mutual_projections", "[", "(", "lng1", ",", "lng2", ")", "]", "\n", "repr1", "=", "torch", ".", "from_numpy", "(", "proj", ".", "predict", "(", "repr1", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "distances", "=", "distance_fn", "(", "repr1", ",", "repr2", ")", "\n", "\n", "recall", "=", "recall_at_k_from_distances", "(", "distances", ",", "k", ")", "\n", "print", "(", "f\"{recall.numpy():.5f}\"", ",", "end", "=", "\"\\t\"", ")", "\n", "\n", "if", "lng1", "!=", "lng2", ":", "\n", "                        ", "recalls_to_avg", ".", "append", "(", "recall", ".", "numpy", "(", ")", ")", "\n", "", "", "print", "(", ")", "\n", "", "print", "(", "f\"On average: {np.mean(recalls_to_avg):.5f}\"", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.text_data_generator": [[10, 16], ["range", "open", "line.strip", "tokenizer.encode"], "function", ["None"], ["def", "text_data_generator", "(", "path", ",", "tokenizer", ",", "epochs", "=", "1", ",", "max_len", "=", "510", ")", ":", "\n", "    ", "for", "_", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f_txt", ":", "\n", "            ", "for", "line", "in", "f_txt", ":", "\n", "                ", "sentence", "=", "line", ".", "strip", "(", ")", "\n", "yield", "tokenizer", ".", "encode", "(", "sentence", ",", "max_length", "=", "max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.batch_generator": [[18, 36], ["items.append", "len", "utils.pad_sentences", "torch.stack", "utils.pad_sentences", "torch.stack"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.pad_sentences", "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.pad_sentences"], ["", "", "", "", "def", "batch_generator", "(", "generator", ",", "size", ",", "tokenizer", ",", "padding", "=", "True", ")", ":", "\n", "    ", "\"\"\"Take data generator and return batches of given size.\"\"\"", "\n", "items", "=", "[", "]", "\n", "\n", "for", "item", "in", "generator", ":", "\n", "        ", "items", ".", "append", "(", "item", ")", "\n", "\n", "if", "len", "(", "items", ")", ">=", "size", ":", "\n", "            ", "if", "padding", ":", "\n", "                ", "yield", "pad_sentences", "(", "items", ",", "tokenizer", ")", "\n", "", "else", ":", "\n", "                ", "yield", "torch", ".", "stack", "(", "items", ")", "\n", "", "items", "=", "[", "]", "\n", "", "", "if", "items", ":", "\n", "        ", "if", "padding", ":", "\n", "            ", "yield", "pad_sentences", "(", "items", ",", "tokenizer", ")", "\n", "", "else", ":", "\n", "            ", "yield", "torch", ".", "stack", "(", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.pad_sentences": [[38, 46], ["max", "enumerate", "torch.zeros", "enumerate", "len", "len"], "function", ["None"], ["", "", "", "def", "pad_sentences", "(", "sentences", ",", "tokenizer", ")", ":", "\n", "    ", "max_len", "=", "max", "(", "len", "(", "ex", ")", "for", "ex", "in", "sentences", ")", "\n", "padded_batch", "=", "torch", ".", "zeros", "(", "\n", "len", "(", "sentences", ")", ",", "max_len", ",", "dtype", "=", "torch", ".", "int64", ")", "+", "tokenizer", ".", "pad_token_id", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "for", "j", ",", "idx", "in", "enumerate", "(", "ex", ")", ":", "\n", "            ", "padded_batch", "[", "i", ",", "j", "]", "=", "idx", "\n", "", "", "return", "padded_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_repr_from_layer": [[48, 75], ["ValueError", "mask.unsqueeze.unsqueeze", "mask.unsqueeze.unsqueeze", "mask.unsqueeze.long().sum", "model", "len", "mask.unsqueeze.sum", "model", "mask.unsqueeze.sum", "ValueError", "mask.unsqueeze.long"], "function", ["None"], ["", "def", "get_repr_from_layer", "(", "model", ",", "data", ",", "layer", ",", "pad_index", ",", "mean_pool", "=", "False", ")", ":", "\n", "    ", "mask", "=", "(", "data", "!=", "pad_index", ")", ".", "float", "(", ")", "\n", "if", "layer", ">=", "0", ":", "\n", "        ", "layer_output", "=", "model", "(", "data", ",", "attention_mask", "=", "mask", ")", "[", "-", "1", "]", "[", "layer", "]", "\n", "if", "mean_pool", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", "\n", "lengths", "=", "mask", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "\n", "# Mask out [CLS] and [SEP] symbols as well.", "\n", "# mask[:, lengths - 1] = 0", "\n", "# mask[:, 0] = 0", "\n", "return", "(", "layer_output", "*", "mask", ")", ".", "sum", "(", "1", ")", "/", "mask", ".", "sum", "(", "1", ")", "\n", "\n", "# Otherwise just take [CLS]", "\n", "", "return", "layer_output", "[", ":", ",", "0", "]", "\n", "\n", "", "if", "layer", "==", "-", "1", ":", "\n", "        ", "model_output", "=", "model", "(", "data", ",", "attention_mask", "=", "mask", ")", "[", "0", "]", "\n", "if", "len", "(", "model_output", ")", "==", "3", ":", "\n", "            ", "if", "mean_pool", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Cannot mean-pool the default vector.\"", ")", "\n", "", "return", "model_output", "[", "1", "]", "\n", "", "assert", "mean_pool", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", "\n", "return", "(", "model_output", "[", "0", "]", "*", "mask", ")", ".", "sum", "(", "1", ")", "/", "mask", ".", "sum", "(", "1", ")", "\n", "\n", "", "raise", "ValueError", "(", "f\"Invalid layer {layer}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.vectors_for_sentence": [[77, 91], ["torch.tensor().unsqueeze", "tokenizer.tokenize", "torch.tensor", "model", "layer_output.squeeze", "tokenizer.convert_tokens_to_ids"], "function", ["None"], ["", "def", "vectors_for_sentence", "(", "\n", "tokenizer", ",", "model", ",", "sentence", ",", "layer", ",", "skip_tokenization", "=", "False", ")", ":", "\n", "    ", "if", "skip_tokenization", ":", "\n", "        ", "tokens", "=", "sentence", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "tokenizer", ".", "tokenize", "(", "sentence", ")", "\n", "\n", "", "tokenized", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "tokens", "[", ":", "510", "]", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "token_ids", "=", "torch", ".", "tensor", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "layer_output", "=", "model", "(", "token_ids", ")", "[", "-", "1", "]", "[", "layer", "]", "\n", "\n", "return", "layer_output", ".", "squeeze", "(", "0", ")", "[", "1", ":", "-", "1", "]", ",", "tokenized", "[", "1", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_bert": [[99, 120], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModel.from_pretrained().to", "AutoModel.from_pretrained().to.eval", "hasattr", "hasattr", "AutoModel.from_pretrained().to.embeddings.word_embeddings.weight.size", "ValueError", "os.path.isdir", "bert_spec.endswith", "transformers.AutoModel.from_pretrained"], "function", ["None"], ["def", "load_bert", "(", "bert_spec", ",", "device", ")", ":", "\n", "    ", "\"\"\"Load pretrained BERT, either standard or from a file.\"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "bert_spec", ")", "and", "bert_spec", "not", "in", "PRETRAINED_BERTS", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"{bert_spec} is not a directory neither a pretrained BERT id.\"", "\n", "f\"Available: {' '.join(PRETRAINED_BERTS)}\"", ")", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "bert_spec", ",", "do_lower_case", "=", "bert_spec", ".", "endswith", "(", "\"-uncased\"", ")", ")", "\n", "model", "=", "AutoModel", ".", "from_pretrained", "(", "bert_spec", ",", "output_hidden_states", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "model_dim", "=", "None", "\n", "if", "hasattr", "(", "model", ".", "config", ",", "'dim'", ")", ":", "\n", "        ", "model_dim", "=", "model", ".", "config", ".", "dim", "\n", "", "if", "hasattr", "(", "model", ".", "config", ",", "'hidden_size'", ")", ":", "\n", "        ", "model_dim", "=", "model", ".", "config", ".", "hidden_size", "\n", "", "vocab_size", "=", "model", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "size", "(", "0", ")", "\n", "\n", "return", "tokenizer", ",", "model", ",", "model_dim", ",", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_lng_database": [[122, 147], ["open", "line.strip().split", "line.strip", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_lng_database", "(", ")", ":", "\n", "    ", "lng_info", "=", "{", "}", "\n", "with", "open", "(", "\"bert_languages_complete.tsv\"", ")", "as", "f_lng", ":", "\n", "        ", "for", "line", "in", "f_lng", ":", "\n", "            ", "fields", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "record", "=", "{", "\n", "\"name\"", ":", "fields", "[", "0", "]", ",", "\n", "\"iso\"", ":", "fields", "[", "2", "]", "}", "\n", "\n", "if", "len", "(", "fields", ")", ">", "3", "and", "fields", "[", "3", "]", ":", "\n", "                ", "record", "[", "\"genus\"", "]", "=", "fields", "[", "3", "]", "\n", "", "if", "len", "(", "fields", ")", ">", "4", "and", "fields", "[", "4", "]", ":", "\n", "                ", "record", "[", "\"family\"", "]", "=", "fields", "[", "4", "]", "\n", "", "if", "len", "(", "fields", ")", ">", "5", "and", "fields", "[", "5", "]", ":", "\n", "                ", "record", "[", "\"svo\"", "]", "=", "fields", "[", "5", "]", "\n", "", "if", "len", "(", "fields", ")", ">", "6", "and", "fields", "[", "6", "]", ":", "\n", "                ", "record", "[", "\"sv\"", "]", "=", "fields", "[", "6", "]", "\n", "", "if", "len", "(", "fields", ")", ">", "7", "and", "fields", "[", "7", "]", ":", "\n", "                ", "record", "[", "\"vo\"", "]", "=", "fields", "[", "7", "]", "\n", "", "if", "len", "(", "fields", ")", ">", "8", "and", "fields", "[", "8", "]", ":", "\n", "                ", "record", "[", "\"adj-noun\"", "]", "=", "fields", "[", "8", "]", "\n", "\n", "", "lng_info", "[", "fields", "[", "0", "]", "]", "=", "record", "\n", "", "", "return", "lng_info", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.load_word_embeddings": [[149, 165], ["os.path.exists", "joblib.load", "open", "f_vec.readline().strip().split", "int", "int", "line.strip().split", "numpy.fromstring", "f_vec.readline().strip", "line.strip", "f_vec.readline"], "function", ["None"], ["", "def", "load_word_embeddings", "(", "path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "path", "+", "\".bin\"", ")", ":", "\n", "        ", "return", "joblib", ".", "load", "(", "path", "+", "\".bin\"", ")", "\n", "\n", "", "embeddings_dic", "=", "{", "}", "\n", "with", "open", "(", "path", ")", "as", "f_vec", ":", "\n", "        ", "count_str", ",", "dim_str", "=", "f_vec", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "dim", "=", "int", "(", "count_str", ")", ",", "int", "(", "dim_str", ")", "\n", "\n", "for", "line", "in", "f_vec", ":", "\n", "            ", "word", ",", "vec_str", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "maxsplit", "=", "1", ")", "\n", "vector", "=", "np", ".", "fromstring", "(", "vec_str", ",", "sep", "=", "\" \"", ",", "dtype", "=", "np", ".", "float", ")", "\n", "if", "vector", ".", "shape", "==", "(", "dim", ",", ")", ":", "\n", "                ", "embeddings_dic", "[", "word", "]", "=", "vector", "\n", "\n", "", "", "", "return", "embeddings_dic", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_tokenizer": [[170, 174], ["sacremoses.MosesTokenizer"], "function", ["None"], ["def", "get_tokenizer", "(", "lng", ")", ":", "\n", "    ", "if", "lng", "not", "in", "TOKENIZERS", ":", "\n", "        ", "TOKENIZERS", "[", "lng", "]", "=", "MosesTokenizer", "(", "lng", ")", "\n", "", "return", "TOKENIZERS", "[", "lng", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.mean_word_embedding": [[176, 187], ["sentence.split", "get_tokenizer().tokenize", "embeddings.get", "numpy.mean", "numpy.stack", "tok.lower", "utils.get_tokenizer"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.get_tokenizer"], ["", "def", "mean_word_embedding", "(", "embeddings", ",", "sentence", ",", "lng", ",", "mean_pool", "=", "True", ",", "\n", "skip_tokenization", "=", "False", ")", ":", "\n", "    ", "unk", "=", "embeddings", "[", "\"</s>\"", "]", "\n", "if", "skip_tokenization", ":", "\n", "        ", "tokens", "=", "sentence", ".", "split", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "get_tokenizer", "(", "lng", ")", ".", "tokenize", "(", "sentence", ")", "\n", "", "embedded_tokens", "=", "[", "embeddings", ".", "get", "(", "tok", ".", "lower", "(", ")", ",", "unk", ")", "for", "tok", "in", "tokens", "]", "\n", "if", "mean_pool", ":", "\n", "        ", "return", "np", ".", "mean", "(", "embedded_tokens", ",", "axis", "=", "0", ")", "\n", "", "return", "np", ".", "stack", "(", "embedded_tokens", ")", ",", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.word_embeddings_for_file": [[189, 199], ["open", "embedded_sentences.append", "utils.mean_word_embedding", "line.strip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.utils.mean_word_embedding"], ["", "def", "word_embeddings_for_file", "(", "path", ",", "embeddings", ",", "lng", ",", "mean_pool", "=", "True", ",", "\n", "skip_tokenization", "=", "False", ")", ":", "\n", "    ", "embedded_sentences", "=", "[", "]", "\n", "with", "open", "(", "path", ")", "as", "f_txt", ":", "\n", "        ", "for", "line", "in", "f_txt", ":", "\n", "            ", "embedded_sentences", ".", "append", "(", "\n", "mean_word_embedding", "(", "embeddings", ",", "line", ".", "strip", "(", ")", ",", "lng", ",", "\n", "mean_pool", "=", "mean_pool", ",", "\n", "skip_tokenization", "=", "skip_tokenization", ")", ")", "\n", "", "", "return", "embedded_sentences", "\n", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.fine_mbert.main": [[27, 205], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.device", "torch.device", "torch.device", "pytorch_transformers.BertTokenizer.from_pretrained", "pytorch_transformers.BertForMaskedLM.from_pretrained().to", "lang_id.load_and_batch_data", "print", "torch.CrossEntropyLoss", "torch.Adam", "enumerate", "open", "torch.Sequential().to", "fine_mbert.main.get_classifier"], "function", ["home.repos.pwc.inspect_result.jlibovicky_assess-multilingual-bert.None.lang_id.load_and_batch_data"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"bert_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Variant of pre-trained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"languages\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"File with a list of languages.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data_txt\"", ",", "type", "=", "str", ",", "help", "=", "\"Training sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"train_data_lng\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Language codes for training sentences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--hidden\"", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Size of the hidden classification layer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-threads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-model\"", ",", "type", "=", "str", ",", "help", "=", "\"Path where to save the best model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "parser", ".", "add_argument", "(", "\"--update-every-batch\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tighten-centroids\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Make centroids of the first an the second half closer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bert-lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-7", ",", "\n", "help", "=", "\"Learning rate for finetuning BERT.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "args", ".", "num_threads", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "with", "open", "(", "args", ".", "languages", ")", "as", "f_lang", ":", "\n", "        ", "languages", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f_lang", "]", "\n", "", "lng2idx", "=", "{", "lng", ":", "i", "for", "i", ",", "lng", "in", "enumerate", "(", "languages", ")", "}", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "bert_model", ",", "do_lower_case", "=", "args", ".", "bert_model", ".", "endswith", "(", "\"-uncased\"", ")", ")", "\n", "model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "\n", "args", ".", "bert_model", ",", "output_hidden_states", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "\n", "model_dim", "=", "model", ".", "bert", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "dense", ".", "out_features", "\n", "\n", "train_batches", "=", "load_and_batch_data", "(", "\n", "args", ".", "train_data_txt", ",", "args", ".", "train_data_lng", ",", "tokenizer", ",", "\n", "lng2idx", ",", "batch_size", "=", "args", ".", "batch_size", ",", "epochs", "=", "args", ".", "epochs", ")", "\n", "print", "(", "\"Train data iterator initialized.\"", ")", "\n", "\n", "def", "get_classifier", "(", ")", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "\n", "RevGrad", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "model_dim", ",", "args", ".", "hidden", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden", ",", "len", "(", "languages", ")", ")", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "cls_classifiers", "=", "[", "get_classifier", "(", ")", "for", "_", "in", "range", "(", "12", ")", "]", "\n", "state_classifiers", "=", "[", "get_classifier", "(", ")", "for", "_", "in", "range", "(", "12", ")", "]", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "[", "{", "\"params\"", ":", "model", ".", "parameters", "(", ")", ",", "\"lr\"", ":", "1e-6", "}", "]", "+", "[", "\n", "{", "\"params\"", ":", "cls", ".", "parameters", "(", ")", "}", "for", "cls", "\n", "in", "cls_classifiers", "+", "state_classifiers", "]", ",", "\n", "lr", "=", "1e-4", ")", "\n", "\n", "cosine", "=", "None", "\n", "if", "args", ".", "tighten_centroids", ":", "\n", "        ", "cosine", "=", "torch", ".", "nn", ".", "CosineSimilarity", "(", ")", "\n", "\n", "", "for", "i", ",", "(", "sentences", ",", "lng", ")", "in", "enumerate", "(", "train_batches", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "for", "cls", "in", "cls_classifiers", "+", "state_classifiers", ":", "\n", "                ", "cls", ".", "train", "(", ")", "\n", "\n", "", "sentences", ",", "lng", "=", "sentences", ".", "to", "(", "device", ")", ",", "lng", ".", "to", "(", "device", ")", "\n", "\n", "# Len mask not to include padded tokens", "\n", "len_mask", "=", "(", "sentences", "!=", "0", ")", ".", "float", "(", ")", "\n", "\n", "# This is the mask that says where we do the BERT magic, i.e., (1)", "\n", "# these are the tokens where we want to predict what word actually", "\n", "# should on the input and (2) these are the tokens we want to mess", "\n", "# up the input .. but be careful, we don't want to predict the", "\n", "# padding.", "\n", "randomized_mask", "=", "(", "\n", "torch", ".", "zeros_like", "(", "len_mask", ")", ".", "uniform_", "(", ")", "*", "len_mask", ")", ">", "0.85", "\n", "\n", "# This the prediction targe. Predict the real word on the", "\n", "# randomized places, -1 elswhere", "\n", "lm_target", "=", "torch", ".", "where", "(", "\n", "randomized_mask", ",", "sentences", ",", "-", "torch", ".", "ones_like", "(", "len_mask", ")", ".", "long", "(", ")", ")", "\n", "\n", "# Create an \"alternative input\":", "\n", "#  * 80% [MASK];", "\n", "#  * 10% random words;", "\n", "#  * 10% original words.", "\n", "alternative_input", "=", "(", "\n", "torch", ".", "ones_like", "(", "sentences", ")", "*", "tokenizer", ".", "mask_token_id", ")", "\n", "random_values", "=", "torch", ".", "zeros_like", "(", "len_mask", ")", ".", "uniform_", "(", ")", "\n", "\n", "alternative_input", "=", "torch", ".", "where", "(", "\n", "random_values", "<", "0.1", ",", "# with 10% probability", "\n", "torch", ".", "zeros_like", "(", "sentences", ")", ".", "random_", "(", "0", ",", "len", "(", "tokenizer", ".", "vocab", ")", ")", ",", "\n", "alternative_input", ")", "# otherwise [MASK]", "\n", "\n", "alternative_input", "=", "torch", ".", "where", "(", "\n", "random_values", ">", "0.9", ",", "# with 10% probability", "\n", "sentences", ",", "# put the original token", "\n", "alternative_input", ")", "# otherwise keep the alternative", "\n", "\n", "bert_input", "=", "torch", ".", "where", "(", "\n", "randomized_mask", ",", "alternative_input", ",", "sentences", ")", "\n", "\n", "bert_loss", ",", "_", ",", "hidden_states", "=", "model", "(", "\n", "bert_input", ",", "attention_mask", "=", "len_mask", ",", "\n", "masked_lm_labels", "=", "lm_target", ")", "\n", "\n", "cls_repr", "=", "[", "states", "[", ":", ",", "0", "]", "for", "states", "in", "hidden_states", "[", "1", ":", "]", "]", "\n", "state_repr", "=", "[", "\n", "(", "states", "[", ":", ",", "1", ":", "]", "*", "len_mask", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "2", ")", ")", ".", "sum", "(", "1", ")", "\n", "/", "(", "len_mask", ".", "sum", "(", "1", ")", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "for", "states", "in", "hidden_states", "[", "1", ":", "]", "]", "\n", "\n", "cls_losses", "=", "[", "\n", "criterion", "(", "cls", "(", "rep", ")", ",", "lng", ")", "for", "cls", ",", "rep", "\n", "in", "zip", "(", "cls_classifiers", ",", "cls_repr", ")", "]", "\n", "mean_losses", "=", "[", "\n", "criterion", "(", "cls", "(", "rep", ")", ",", "lng", ")", "for", "cls", ",", "rep", "\n", "in", "zip", "(", "state_classifiers", ",", "state_repr", ")", "]", "\n", "\n", "loss", "=", "sum", "(", "cls_losses", ")", "+", "sum", "(", "mean_losses", ")", "+", "100", "*", "bert_loss", "\n", "\n", "if", "args", ".", "tighten_centroids", ":", "\n", "                ", "cls_half_1", "=", "torch", ".", "stack", "(", "[", "\n", "mat", "[", ":", "args", ".", "batch_size", "//", "2", "]", ".", "mean", "(", "0", ")", "for", "mat", "in", "cls_repr", "]", ")", "\n", "cls_half_2", "=", "torch", ".", "stack", "(", "[", "\n", "mat", "[", "args", ".", "batch_size", "//", "2", ":", "]", ".", "mean", "(", "0", ")", "for", "mat", "in", "cls_repr", "]", ")", "\n", "\n", "state_half_1", "=", "torch", ".", "stack", "(", "[", "\n", "mat", "[", ":", "args", ".", "batch_size", "//", "2", "]", ".", "mean", "(", "0", ")", "for", "mat", "in", "state_repr", "]", ")", "\n", "state_half_2", "=", "torch", ".", "stack", "(", "[", "\n", "mat", "[", "args", ".", "batch_size", "//", "2", ":", "]", ".", "mean", "(", "0", ")", "for", "mat", "in", "state_repr", "]", ")", "\n", "\n", "structure_loss", "=", "(", "1", "-", "cosine", "(", "\n", "torch", ".", "cat", "(", "[", "cls_half_1", ",", "state_half_1", "]", ")", ",", "\n", "torch", ".", "cat", "(", "[", "cls_half_2", ",", "state_half_2", "]", ")", ")", ")", ".", "sum", "(", ")", "\n", "loss", "+=", "structure_loss", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "if", "i", "%", "args", ".", "update_every_batch", "==", "args", ".", "update_every_batch", "-", "1", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "lngid_loss", "=", "(", "sum", "(", "cls_losses", ")", "+", "sum", "(", "mean_losses", ")", ")", "/", "24", "\n", "\n", "def", "loss_to_pyfloat", "(", "loss", ")", ":", "\n", "                    ", "return", "loss", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "", "log_string", "=", "(", "\n", "f'{time.strftime(\"%Y-%m-%d %H:%M:%S\")}, {i + 1} steps:   '", "\n", "f\"BERT loss: {loss_to_pyfloat(bert_loss):5g}  \"", "\n", "f\"lngid loss: {loss_to_pyfloat(lngid_loss):5g}\"", ")", "\n", "if", "args", ".", "tighten_centroids", ":", "\n", "                    ", "log_string", "+=", "(", "\n", "f\"  centroid loss: {loss_to_pyfloat(structure_loss):5g}\"", ")", "\n", "", "print", "(", "log_string", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", "\"Training interrupted by user\"", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "save_model", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save_model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "save_pretrained", "(", "args", ".", "save_model", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "save_model", ")", "\n", "\n"]]}