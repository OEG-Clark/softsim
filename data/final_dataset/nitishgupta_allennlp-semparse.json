{"home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.reformat_text2sql_data.process_dataset": [[14, 37], ["collections.defaultdict", "collections.defaultdict.items", "split.isdigit", "splits[].append", "example.pop", "example.copy", "splits[].append"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "process_dataset", "(", "data", ":", "JsonDict", ",", "split_type", ":", "str", ")", "->", "Iterable", "[", "Tuple", "[", "str", ",", "JsonDict", "]", "]", ":", "\n", "\n", "    ", "splits", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "example", "in", "data", ":", "\n", "        ", "if", "split_type", "==", "\"query_split\"", ":", "\n", "            ", "example_split", "=", "example", "[", "\"query-split\"", "]", "\n", "splits", "[", "example_split", "]", ".", "append", "(", "example", ")", "\n", "\n", "", "else", ":", "\n", "            ", "sentences", "=", "example", ".", "pop", "(", "\"sentences\"", ")", "\n", "\n", "for", "sentence", "in", "sentences", ":", "\n", "                ", "new_example", "=", "example", ".", "copy", "(", ")", "\n", "new_example", "[", "\"sentences\"", "]", "=", "[", "sentence", "]", "\n", "split", "=", "sentence", "[", "\"question-split\"", "]", "\n", "splits", "[", "split", "]", ".", "append", "(", "new_example", ")", "\n", "\n", "", "", "", "for", "split", ",", "examples", "in", "splits", ".", "items", "(", ")", ":", "\n", "        ", "if", "split", ".", "isdigit", "(", ")", ":", "\n", "            ", "yield", "(", "\"split_\"", "+", "split", "+", "\".json\"", ",", "examples", ")", "\n", "", "else", ":", "\n", "            ", "yield", "(", "split", "+", "\".json\"", ",", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.reformat_text2sql_data.main": [[39, 95], ["glob.glob", "os.path.join", "print", "json.load", "os.path.basename", "open", "isinstance", "os.path.join", "reformat_text2sql_data.process_dataset", "os.path.join", "os.makedirs", "json.dump", "open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.reformat_text2sql_data.process_dataset"], ["", "", "", "def", "main", "(", "output_directory", ":", "int", ",", "data", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Processes the text2sql data into the following directory structure:\n\n    ``dataset/{query_split, question_split}/{train,dev,test}.json``\n\n    for datasets which have train, dev and test splits, or:\n\n    ``dataset/{query_split, question_split}/{split_{split_id}}.json``\n\n    for datasets which use cross validation.\n\n    The JSON format is identical to the original datasets, apart from they\n    are split into separate files with respect to the split_type. This means that\n    for the question split, all of the sql data is duplicated for each sentence\n    which is bucketed together as having the same semantics.\n\n    As an example, the following blob would be put \"as-is\" into the query split\n    dataset, and split into two datasets with identical blobs for the question split,\n    differing only in the \"sentence\" key, where blob1 would end up in the train split\n    and blob2 would be in the dev split, with the rest of the json duplicated in each.\n    {\n        \"comments\": [],\n        \"old-name\": \"\",\n        \"query-split\": \"train\",\n        \"sentences\": [{blob1, \"question-split\": \"train\"}, {blob2, \"question-split\": \"dev\"}],\n        \"sql\": [],\n        \"variables\": []\n    },\n\n    Parameters\n    ----------\n    output_directory : str, required.\n        The output directory.\n    data: str, default = None\n        The path to the data director of https://github.com/jkkummerfeld/text2sql-data.\n    \"\"\"", "\n", "json_files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "data", ",", "\"*.json\"", ")", ")", "\n", "\n", "for", "dataset", "in", "json_files", ":", "\n", "        ", "dataset_name", "=", "os", ".", "path", ".", "basename", "(", "dataset", ")", "[", ":", "-", "5", "]", "\n", "print", "(", "\n", "f\"Processing dataset: {dataset} into query and question \"", "\n", "f\"splits at output path: {output_directory + '/' + dataset_name}\"", "\n", ")", "\n", "full_dataset", "=", "json", ".", "load", "(", "open", "(", "dataset", ")", ")", "\n", "if", "not", "isinstance", "(", "full_dataset", ",", "list", ")", ":", "\n", "            ", "full_dataset", "=", "[", "full_dataset", "]", "\n", "\n", "", "for", "split_type", "in", "[", "\"query_split\"", ",", "\"question_split\"", "]", ":", "\n", "            ", "dataset_out", "=", "os", ".", "path", ".", "join", "(", "output_directory", ",", "dataset_name", ",", "split_type", ")", "\n", "\n", "for", "split", ",", "split_dataset", "in", "process_dataset", "(", "full_dataset", ",", "split_type", ")", ":", "\n", "                ", "dataset_out", "=", "os", ".", "path", ".", "join", "(", "output_directory", ",", "dataset_name", ",", "split_type", ")", "\n", "os", ".", "makedirs", "(", "dataset_out", ",", "exist_ok", "=", "True", ")", "\n", "json", ".", "dump", "(", "split_dataset", ",", "open", "(", "os", ".", "path", ".", "join", "(", "dataset_out", ",", "split", ")", ",", "\"w\"", ")", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.examine_sql_coverage.parse_dataset": [[20, 97], ["allennlp.semparse.contexts.sql_context_utils.format_grammar_string", "parsimonious.grammar.Grammar", "json.load", "enumerate", "open", "allennlp.data.dataset_readers.dataset_utils.text2sql_utils.process_sql_data", "allennlp.semparse.contexts.sql_context_utils.SqlVisitor", "any", "enumerate", "enumerate", "allennlp.semparse.contexts.sql_context_utils.SqlVisitor.parse", "print", "sql_to_use.append", "sql_to_use.append", "print", "print", "print", "print", "print", "sqlparse.format", "print"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_grammar_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "parse_dataset", "(", "filename", ":", "str", ",", "filter_by", ":", "str", "=", "None", ",", "verbose", ":", "bool", "=", "False", ")", ":", "\n", "\n", "    ", "grammar_string", "=", "format_grammar_string", "(", "GRAMMAR_DICTIONARY", ")", "\n", "grammar", "=", "Grammar", "(", "grammar_string", ")", "\n", "\n", "filter_by", "=", "filter_by", "or", "\"13754332dvmklfdsaf-3543543\"", "\n", "data", "=", "json", ".", "load", "(", "open", "(", "filename", ")", ")", "\n", "num_queries", "=", "0", "\n", "num_parsed", "=", "0", "\n", "filtered_errors", "=", "0", "\n", "\n", "non_basic_as_aliases", "=", "0", "\n", "as_count", "=", "0", "\n", "queries_with_weird_as", "=", "0", "\n", "\n", "for", "i", ",", "sql_data", "in", "enumerate", "(", "process_sql_data", "(", "data", ")", ")", ":", "\n", "        ", "sql_visitor", "=", "SqlVisitor", "(", "grammar", ")", "\n", "\n", "if", "any", "(", "[", "x", "[", ":", "7", "]", "==", "\"DERIVED\"", "]", "for", "x", "in", "sql_data", ".", "sql", ")", ":", "\n", "# NOTE: DATA hack alert - the geography dataset doesn't alias derived tables consistently,", "\n", "# so we fix the data a bit here instead of completely re-working the grammar.", "\n", "            ", "sql_to_use", "=", "[", "]", "\n", "for", "j", ",", "token", "in", "enumerate", "(", "sql_data", ".", "sql", ")", ":", "\n", "                ", "if", "token", "[", ":", "7", "]", "==", "\"DERIVED\"", "and", "sql_data", ".", "sql", "[", "j", "-", "1", "]", "==", "\")\"", ":", "\n", "                    ", "sql_to_use", ".", "append", "(", "\"AS\"", ")", "\n", "", "sql_to_use", ".", "append", "(", "token", ")", "\n", "\n", "", "previous_token", "=", "None", "\n", "query_has_weird_as", "=", "False", "\n", "for", "j", ",", "token", "in", "enumerate", "(", "sql_to_use", "[", ":", "-", "1", "]", ")", ":", "\n", "\n", "                ", "if", "token", "==", "\"AS\"", "and", "previous_token", "is", "not", "None", ":", "\n", "\n", "                    ", "table_name", "=", "sql_to_use", "[", "j", "+", "1", "]", "[", ":", "-", "6", "]", "\n", "if", "table_name", "!=", "previous_token", ":", "\n", "                        ", "non_basic_as_aliases", "+=", "1", "\n", "query_has_weird_as", "=", "True", "\n", "", "as_count", "+=", "1", "\n", "", "previous_token", "=", "token", "\n", "\n", "", "if", "query_has_weird_as", ":", "\n", "                ", "queries_with_weird_as", "+=", "1", "\n", "\n", "", "sql_string", "=", "\" \"", ".", "join", "(", "sql_to_use", ")", "\n", "", "else", ":", "\n", "            ", "sql_string", "=", "\" \"", ".", "join", "(", "sql_data", ".", "sql", ")", "\n", "", "num_queries", "+=", "1", "\n", "try", ":", "\n", "            ", "sql_visitor", ".", "parse", "(", "sql_string", ")", "\n", "num_parsed", "+=", "1", "\n", "", "except", "Exception", "as", "e", ":", "\n", "\n", "            ", "if", "filter_by", "in", "sql_string", ":", "\n", "                ", "filtered_errors", "+=", "1", "\n", "\n", "", "if", "verbose", "and", "filter_by", "not", "in", "sql_string", ":", "\n", "                ", "print", "(", ")", "\n", "print", "(", "e", ")", "\n", "print", "(", "\" \"", ".", "join", "(", "sql_data", ".", "text", ")", ")", "\n", "print", "(", "sql_data", ".", "sql", ")", "\n", "try", ":", "\n", "                    ", "import", "sqlparse", "\n", "\n", "print", "(", "sqlparse", ".", "format", "(", "sql_string", ",", "reindent", "=", "True", ")", ")", "\n", "", "except", "Exception", ":", "\n", "                    ", "print", "(", "sql_string", ")", "\n", "\n", "", "", "", "if", "(", "i", "+", "1", ")", "%", "500", "==", "0", ":", "\n", "            ", "print", "(", "f\"\\tProcessed {i + 1} queries.\"", ")", "\n", "\n", "", "", "return", "(", "\n", "num_parsed", ",", "\n", "num_queries", ",", "\n", "filtered_errors", ",", "\n", "non_basic_as_aliases", ",", "\n", "as_count", ",", "\n", "queries_with_weird_as", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.examine_sql_coverage.main": [[100, 153], ["directory_dict.items", "print", "print", "print", "print", "os.walk", "print", "os.path.join", "examine_sql_coverage.parse_dataset", "print"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.examine_sql_coverage.parse_dataset"], ["", "def", "main", "(", "\n", "data_directory", ":", "int", ",", "dataset", ":", "str", "=", "None", ",", "filter_by", ":", "str", "=", "None", ",", "verbose", ":", "bool", "=", "False", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Parameters\n    ----------\n    data_directory : str, required.\n        The path to the data directory of https://github.com/jkkummerfeld/text2sql-data\n        which has been preprocessed using scripts/reformat_text2sql_data.py.\n    dataset : str, optional.\n        The dataset to parse. By default all are parsed.\n    filter_by : str, optional\n        Compute statistics about a particular error and only print errors which don't contain this string.\n    verbose : bool, optional.\n        Whether to print information about incorrectly parsed SQL.\n    \"\"\"", "\n", "directory_dict", "=", "{", "path", ":", "files", "for", "path", ",", "names", ",", "files", "in", "os", ".", "walk", "(", "data_directory", ")", "if", "files", "}", "\n", "\n", "for", "directory", ",", "data_files", "in", "directory_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "\"query_split\"", "in", "directory", "or", "(", "dataset", "is", "not", "None", "and", "dataset", "not", "in", "directory", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "print", "(", "f\"Parsing dataset at {directory}\"", ")", "\n", "parsed", "=", "0", "\n", "total_non_aliases", "=", "0", "\n", "total_as_count", "=", "0", "\n", "total_queries_with_weird_as", "=", "0", "\n", "total_filtered_errors", "=", "0", "\n", "total", "=", "0", "\n", "for", "json_file", "in", "data_files", ":", "\n", "            ", "print", "(", "f\"\\tParsing split at {json_file}\"", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "json_file", ")", "\n", "stats", "=", "parse_dataset", "(", "file_path", ",", "filter_by", ",", "verbose", ")", "\n", "\n", "parsed", "+=", "stats", "[", "0", "]", "\n", "total", "+=", "stats", "[", "1", "]", "\n", "total_filtered_errors", "+=", "stats", "[", "2", "]", "\n", "total_non_aliases", "+=", "stats", "[", "3", "]", "\n", "total_as_count", "+=", "stats", "[", "4", "]", "\n", "total_queries_with_weird_as", "+=", "stats", "[", "5", "]", "\n", "\n", "", "print", "(", "f\"\\tParsed {parsed} out of {total} queries, coverage {parsed/total}\"", ")", "\n", "print", "(", "\n", "f\"\\tFound {total_non_aliases} out of {total_as_count} non simple AS aliases. \"", "\n", "f\"percentage: {total_non_aliases/total_as_count}\"", "\n", ")", "\n", "print", "(", "\n", "f\"\\tFound {total_queries_with_weird_as} out of {total} queries with > 1 weird AS. \"", "\n", "f\"percentage: {total_queries_with_weird_as/total}\"", "\n", ")", "\n", "if", "filter_by", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "f\"\\tOf {total - parsed} errors, {total_filtered_errors / (total - parsed + 1e-13)} \"", "\n", "f\"contain {filter_by}\"", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.parse_args": [[7, 12], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"version_type\"", ",", "choices", "=", "[", "\"stable\"", ",", "\"latest\"", ",", "\"current\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--minimal\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.post_process": [[14, 18], ["version.startswith"], "function", ["None"], ["", "def", "post_process", "(", "version", ":", "str", ",", "minimal", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "version", ".", "startswith", "(", "\"v\"", ")", ":", "\n", "        ", "return", "version", "if", "not", "minimal", "else", "version", "[", "1", ":", "]", "\n", "", "return", "version", "if", "minimal", "else", "f\"v{version}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.get_current_version": [[20, 25], ["open", "exec", "version_file.read"], "function", ["None"], ["", "def", "get_current_version", "(", ")", "->", "str", ":", "\n", "    ", "VERSION", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "with", "open", "(", "\"allennlp_semparse/version.py\"", ",", "\"r\"", ")", "as", "version_file", ":", "\n", "        ", "exec", "(", "version_file", ".", "read", "(", ")", ",", "VERSION", ")", "\n", "", "return", "VERSION", "[", "\"VERSION\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.get_latest_version": [[27, 34], ["requests.get", "requests.get.json"], "function", ["None"], ["", "def", "get_latest_version", "(", ")", "->", "str", ":", "\n", "# Import this here so this requirements isn't mandatory when we just want to", "\n", "# call `get_current_version`.", "\n", "    ", "import", "requests", "\n", "\n", "resp", "=", "requests", ".", "get", "(", "\"https://api.github.com/repos/allenai/allennlp-semparse/tags\"", ")", "\n", "return", "resp", ".", "json", "(", ")", "[", "0", "]", "[", "\"name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.get_stable_version": [[36, 41], ["requests.get", "requests.get.json"], "function", ["None"], ["", "def", "get_stable_version", "(", ")", "->", "str", ":", "\n", "    ", "import", "requests", "\n", "\n", "resp", "=", "requests", ".", "get", "(", "\"https://api.github.com/repos/allenai/allennlp-semparse/releases/latest\"", ")", "\n", "return", "resp", ".", "json", "(", ")", "[", "\"tag_name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.main": [[43, 53], ["get_version.parse_args", "print", "get_version.post_process", "print", "get_version.get_stable_version", "get_version.post_process", "print", "get_version.get_latest_version", "get_version.post_process", "get_version.get_current_version"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.parse_args", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.post_process", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.get_stable_version", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.post_process", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.get_latest_version", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.post_process", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.get_current_version"], ["", "def", "main", "(", ")", "->", "None", ":", "\n", "    ", "opts", "=", "parse_args", "(", ")", "\n", "if", "opts", ".", "version_type", "==", "\"stable\"", ":", "\n", "        ", "print", "(", "post_process", "(", "get_stable_version", "(", ")", ",", "opts", ".", "minimal", ")", ")", "\n", "", "elif", "opts", ".", "version_type", "==", "\"latest\"", ":", "\n", "        ", "print", "(", "post_process", "(", "get_latest_version", "(", ")", ",", "opts", ".", "minimal", ")", ")", "\n", "", "elif", "opts", ".", "version_type", "==", "\"current\"", ":", "\n", "        ", "print", "(", "post_process", "(", "get_current_version", "(", ")", ",", "opts", ".", "minimal", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.search_for_logical_forms.search": [[23, 81], ["print", "logging.getLogger", "logging.getLogger.setLevel", "allennlp.data.tokenizers.WordTokenizer", "os.makedirs", "open", "instance_data[].replace", "allennlp.data.tokenizers.WordTokenizer.tokenize", "allennlp.semparse.contexts.TableQuestionContext.read_from_file", "allennlp.semparse.domain_languages.WikiTablesLanguage", "allennlp.semparse.ActionSpaceWalker", "open.close", "os.path.exists", "utterance.startswith", "utterance.endswith", "allennlp.semparse.domain_languages.WikiTablesLanguage.get_agenda", "allennlp.semparse.ActionSpaceWalker.get_logical_forms_with_agenda", "allennlp.semparse.ActionSpaceWalker.get_all_logical_forms", "allennlp.semparse.domain_languages.WikiTablesLanguage.evaluate_logical_form", "len", "correct_logical_forms.append", "gzip.open", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_all_logical_forms", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "search", "(", "\n", "tables_directory", ":", "str", ",", "\n", "data", ":", "JsonDict", ",", "\n", "output_path", ":", "str", ",", "\n", "max_path_length", ":", "int", ",", "\n", "max_num_logical_forms", ":", "int", ",", "\n", "use_agenda", ":", "bool", ",", "\n", "output_separate_files", ":", "bool", ",", "\n", "conservative_agenda", ":", "bool", ",", "\n", ")", "->", "None", ":", "\n", "    ", "print", "(", "f\"Starting search with {len(data)} instances\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "language_logger", "=", "logging", ".", "getLogger", "(", "\"allennlp.semparse.domain_languages.wikitables_language\"", ")", "\n", "language_logger", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "tokenizer", "=", "WordTokenizer", "(", ")", "\n", "if", "output_separate_files", "and", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "", "if", "not", "output_separate_files", ":", "\n", "        ", "output_file_pointer", "=", "open", "(", "output_path", ",", "\"w\"", ")", "\n", "", "for", "instance_data", "in", "data", ":", "\n", "        ", "utterance", "=", "instance_data", "[", "\"question\"", "]", "\n", "question_id", "=", "instance_data", "[", "\"id\"", "]", "\n", "if", "utterance", ".", "startswith", "(", "'\"'", ")", "and", "utterance", ".", "endswith", "(", "'\"'", ")", ":", "\n", "            ", "utterance", "=", "utterance", "[", "1", ":", "-", "1", "]", "\n", "# For example: csv/200-csv/47.csv -> tagged/200-tagged/47.tagged", "\n", "", "table_file", "=", "instance_data", "[", "\"table_filename\"", "]", ".", "replace", "(", "\"csv\"", ",", "\"tagged\"", ")", "\n", "target_list", "=", "instance_data", "[", "\"target_values\"", "]", "\n", "tokenized_question", "=", "tokenizer", ".", "tokenize", "(", "utterance", ")", "\n", "table_file", "=", "f\"{tables_directory}/{table_file}\"", "\n", "context", "=", "TableQuestionContext", ".", "read_from_file", "(", "table_file", ",", "tokenized_question", ")", "\n", "world", "=", "WikiTablesLanguage", "(", "context", ")", "\n", "walker", "=", "ActionSpaceWalker", "(", "world", ",", "max_path_length", "=", "max_path_length", ")", "\n", "correct_logical_forms", "=", "[", "]", "\n", "if", "use_agenda", ":", "\n", "            ", "agenda", "=", "world", ".", "get_agenda", "(", "conservative", "=", "conservative_agenda", ")", "\n", "allow_partial_match", "=", "not", "conservative_agenda", "\n", "all_logical_forms", "=", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "agenda", "=", "agenda", ",", "max_num_logical_forms", "=", "10000", ",", "allow_partial_match", "=", "allow_partial_match", "\n", ")", "\n", "", "else", ":", "\n", "            ", "all_logical_forms", "=", "walker", ".", "get_all_logical_forms", "(", "max_num_logical_forms", "=", "10000", ")", "\n", "", "for", "logical_form", "in", "all_logical_forms", ":", "\n", "            ", "if", "world", ".", "evaluate_logical_form", "(", "logical_form", ",", "target_list", ")", ":", "\n", "                ", "correct_logical_forms", ".", "append", "(", "logical_form", ")", "\n", "", "", "if", "output_separate_files", "and", "correct_logical_forms", ":", "\n", "            ", "with", "gzip", ".", "open", "(", "f\"{output_path}/{question_id}.gz\"", ",", "\"wt\"", ")", "as", "output_file_pointer", ":", "\n", "                ", "for", "logical_form", "in", "correct_logical_forms", ":", "\n", "                    ", "print", "(", "logical_form", ",", "file", "=", "output_file_pointer", ")", "\n", "", "", "", "elif", "not", "output_separate_files", ":", "\n", "            ", "print", "(", "f\"{question_id} {utterance}\"", ",", "file", "=", "output_file_pointer", ")", "\n", "if", "use_agenda", ":", "\n", "                ", "print", "(", "f\"Agenda: {agenda}\"", ",", "file", "=", "output_file_pointer", ")", "\n", "", "if", "not", "correct_logical_forms", ":", "\n", "                ", "print", "(", "\"NO LOGICAL FORMS FOUND!\"", ",", "file", "=", "output_file_pointer", ")", "\n", "", "for", "logical_form", "in", "correct_logical_forms", "[", ":", "max_num_logical_forms", "]", ":", "\n", "                ", "print", "(", "logical_form", ",", "file", "=", "output_file_pointer", ")", "\n", "", "print", "(", "file", "=", "output_file_pointer", ")", "\n", "", "", "if", "not", "output_separate_files", ":", "\n", "        ", "output_file_pointer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.preprocess_data.main": [[15, 25], ["os.makedirs", "allennlp.commands.train.datasets_from_params", "allennlp.commands.train.datasets_from_params.items", "open", "iter", "outfile.write", "preprocess_data.to_json_line"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.preprocess_data.to_json_line"], ["def", "main", "(", "params", ":", "Params", ",", "outdir", ":", "str", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "outdir", ",", "exist_ok", "=", "True", ")", "\n", "params", "[", "\"dataset_reader\"", "]", "[", "\"include_table_metadata\"", "]", "=", "True", "\n", "if", "\"validation_dataset_reader\"", "in", "params", ":", "\n", "        ", "params", "[", "\"validation_dataset_reader\"", "]", "[", "\"include_table_metadata\"", "]", "=", "True", "\n", "", "all_datasets", "=", "datasets_from_params", "(", "params", ")", "\n", "for", "name", ",", "dataset", "in", "all_datasets", ".", "items", "(", ")", ":", "\n", "        ", "with", "open", "(", "outdir", "+", "name", "+", "\".jsonl\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "for", "instance", "in", "iter", "(", "dataset", ")", ":", "\n", "                ", "outfile", ".", "write", "(", "to_json_line", "(", "instance", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.preprocess_data.to_json_line": [[27, 55], ["json.dumps", "entity_texts.append", "enumerate", "targets.append", "targets[].append"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "", "", "def", "to_json_line", "(", "instance", ":", "Instance", ")", ":", "\n", "    ", "json_obj", "=", "{", "}", "\n", "question_tokens", "=", "instance", ".", "fields", "[", "\"question\"", "]", ".", "tokens", "\n", "json_obj", "[", "\"question_tokens\"", "]", "=", "[", "\n", "{", "\"text\"", ":", "token", ".", "text", ",", "\"lemma\"", ":", "token", ".", "lemma_", "}", "for", "token", "in", "question_tokens", "\n", "]", "\n", "json_obj", "[", "\"table_lines\"", "]", "=", "instance", ".", "fields", "[", "\"table_metadata\"", "]", ".", "metadata", "\n", "\n", "action_map", "=", "{", "i", ":", "action", ".", "rule", "for", "i", ",", "action", "in", "enumerate", "(", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", ")", "}", "\n", "\n", "if", "\"target_action_sequences\"", "in", "instance", ".", "fields", ":", "\n", "        ", "targets", "=", "[", "]", "\n", "for", "target_sequence", "in", "instance", ".", "fields", "[", "\"target_action_sequences\"", "]", ".", "field_list", ":", "\n", "            ", "targets", ".", "append", "(", "[", "]", ")", "\n", "for", "target_index_field", "in", "target_sequence", ".", "field_list", ":", "\n", "                ", "targets", "[", "-", "1", "]", ".", "append", "(", "action_map", "[", "target_index_field", ".", "sequence_index", "]", ")", "\n", "\n", "", "", "json_obj", "[", "\"target_action_sequences\"", "]", "=", "targets", "\n", "\n", "", "json_obj", "[", "\"example_lisp_string\"", "]", "=", "instance", ".", "fields", "[", "\"example_lisp_string\"", "]", ".", "metadata", "\n", "\n", "entity_texts", "=", "[", "]", "\n", "for", "entity_text", "in", "instance", ".", "fields", "[", "\"table\"", "]", ".", "entity_texts", ":", "\n", "        ", "tokens", "=", "[", "{", "\"text\"", ":", "token", ".", "text", ",", "\"lemma\"", ":", "token", ".", "lemma_", "}", "for", "token", "in", "entity_text", "]", "\n", "entity_texts", ".", "append", "(", "tokens", ")", "\n", "", "json_obj", "[", "\"entity_texts\"", "]", "=", "entity_texts", "\n", "json_obj", "[", "\"linking_features\"", "]", "=", "instance", ".", "fields", "[", "\"table\"", "]", ".", "linking_features", "\n", "return", "json", ".", "dumps", "(", "json_obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.generate_data_from_erm_model.make_data": [[18, 60], ["allennlp.data.dataset_readers.WikiTablesDatasetReader", "allennlp.data.dataset_readers.WikiTablesDatasetReader.read", "allennlp.models.archival.load_archive", "zip", "open", "input_file.readlines", "model.forward_on_instance", "allennlp.data.dataset_readers.semantic_parsing.wikitables.util.parse_example_line", "len", "print", "gzip.open", "gzip.open.close", "world.evaluate_logical_form", "os.path.exists", "os.makedirs", "os.path.join", "gzip.open.write", "correct_logical_forms.append", "len"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.parse_example_line", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "make_data", "(", "\n", "input_examples_file", ":", "str", ",", "\n", "tables_directory", ":", "str", ",", "\n", "archived_model_file", ":", "str", ",", "\n", "output_dir", ":", "str", ",", "\n", "num_logical_forms", ":", "int", ",", "\n", ")", "->", "None", ":", "\n", "    ", "reader", "=", "WikiTablesDatasetReader", "(", "\n", "tables_directory", "=", "tables_directory", ",", "keep_if_no_logical_forms", "=", "True", ",", "output_agendas", "=", "True", "\n", ")", "\n", "dataset", "=", "reader", ".", "read", "(", "input_examples_file", ")", "\n", "input_lines", "=", "[", "]", "\n", "with", "open", "(", "input_examples_file", ")", "as", "input_file", ":", "\n", "        ", "input_lines", "=", "input_file", ".", "readlines", "(", ")", "\n", "", "archive", "=", "load_archive", "(", "archived_model_file", ")", "\n", "model", "=", "archive", ".", "model", "\n", "model", ".", "training", "=", "False", "\n", "model", ".", "_decoder_trainer", ".", "_max_num_decoded_sequences", "=", "100", "\n", "for", "instance", ",", "example_line", "in", "zip", "(", "dataset", ",", "input_lines", ")", ":", "\n", "        ", "outputs", "=", "model", ".", "forward_on_instance", "(", "instance", ")", "\n", "world", "=", "instance", ".", "fields", "[", "\"world\"", "]", ".", "metadata", "\n", "parsed_info", "=", "util", ".", "parse_example_line", "(", "example_line", ")", "\n", "example_id", "=", "parsed_info", "[", "\"id\"", "]", "\n", "target_list", "=", "parsed_info", "[", "\"target_values\"", "]", "\n", "logical_forms", "=", "outputs", "[", "\"logical_form\"", "]", "\n", "correct_logical_forms", "=", "[", "]", "\n", "for", "logical_form", "in", "logical_forms", ":", "\n", "            ", "if", "world", ".", "evaluate_logical_form", "(", "logical_form", ",", "target_list", ")", ":", "\n", "                ", "correct_logical_forms", ".", "append", "(", "logical_form", ")", "\n", "if", "len", "(", "correct_logical_forms", ")", ">=", "num_logical_forms", ":", "\n", "                    ", "break", "\n", "", "", "", "num_found", "=", "len", "(", "correct_logical_forms", ")", "\n", "print", "(", "f\"{num_found} found for {example_id}\"", ")", "\n", "if", "num_found", "==", "0", ":", "\n", "            ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "output_file", "=", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{example_id}.gz\"", ")", ",", "\"wb\"", ")", "\n", "for", "logical_form", "in", "correct_logical_forms", ":", "\n", "            ", "logical_form_line", "=", "(", "logical_form", "+", "\"\\n\"", ")", ".", "encode", "(", "\"utf-8\"", ")", "\n", "output_file", ".", "write", "(", "logical_form_line", ")", "\n", "", "output_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser.__init__": [[74, 152], ["allennlp.models.model.Model.__init__", "allennlp.modules.TimeDistributed", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "vocab.get_vocab_size", "allennlp.modules.Embedding", "allennlp.modules.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "allennlp.common.checks.check_dimensions_match", "question_embedder.get_output_dim", "allennlp.modules.Embedding", "allennlp.modules.Embedding", "torch.nn.Linear", "torch.nn.Dropout", "allennlp.modules.Embedding", "torch.FloatTensor", "torch.FloatTensor", "entity_encoder.get_output_dim", "question_embedder.get_output_dim", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "encoder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "question_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "entity_encoder", ":", "Seq2VecEncoder", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "use_neighbor_similarity_for_linking", ":", "bool", "=", "False", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "num_linking_features", ":", "int", "=", "10", ",", "\n", "rule_namespace", ":", "str", "=", "\"rule_labels\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "_question_embedder", "=", "question_embedder", "\n", "self", ".", "_encoder", "=", "encoder", "\n", "self", ".", "_entity_encoder", "=", "TimeDistributed", "(", "entity_encoder", ")", "\n", "self", ".", "_max_decoding_steps", "=", "max_decoding_steps", "\n", "self", ".", "_add_action_bias", "=", "add_action_bias", "\n", "self", ".", "_use_neighbor_similarity_for_linking", "=", "use_neighbor_similarity_for_linking", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dropout", "=", "lambda", "x", ":", "x", "\n", "", "self", ".", "_rule_namespace", "=", "rule_namespace", "\n", "self", ".", "_denotation_accuracy", "=", "Average", "(", ")", "\n", "self", ".", "_action_sequence_accuracy", "=", "Average", "(", ")", "\n", "self", ".", "_has_logical_form", "=", "Average", "(", ")", "\n", "\n", "self", ".", "_action_padding_index", "=", "-", "1", "# the padding value used by IndexField", "\n", "num_actions", "=", "vocab", ".", "get_vocab_size", "(", "self", ".", "_rule_namespace", ")", "\n", "if", "self", ".", "_add_action_bias", ":", "\n", "            ", "self", ".", "_action_biases", "=", "Embedding", "(", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "1", ")", "\n", "", "self", ".", "_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "action_embedding_dim", "\n", ")", "\n", "self", ".", "_output_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "action_embedding_dim", "\n", ")", "\n", "\n", "# This is what we pass as input in the first step of decoding, when we don't have a", "\n", "# previous action, or a previous question attention.", "\n", "self", ".", "_first_action_embedding", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "action_embedding_dim", ")", ")", "\n", "self", ".", "_first_attended_question", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "encoder", ".", "get_output_dim", "(", ")", ")", "\n", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_action_embedding", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_attended_question", ")", "\n", "\n", "check_dimensions_match", "(", "\n", "entity_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "question_embedder", ".", "get_output_dim", "(", ")", ",", "\n", "\"entity word average embedding dim\"", ",", "\n", "\"question embedding dim\"", ",", "\n", ")", "\n", "\n", "self", ".", "_num_entity_types", "=", "5", "# TODO(mattg): get this in a more principled way somehow?", "\n", "self", ".", "_embedding_dim", "=", "question_embedder", ".", "get_output_dim", "(", ")", "\n", "self", ".", "_entity_type_encoder_embedding", "=", "Embedding", "(", "\n", "num_embeddings", "=", "self", ".", "_num_entity_types", ",", "embedding_dim", "=", "self", ".", "_embedding_dim", "\n", ")", "\n", "self", ".", "_entity_type_decoder_embedding", "=", "Embedding", "(", "\n", "num_embeddings", "=", "self", ".", "_num_entity_types", ",", "embedding_dim", "=", "action_embedding_dim", "\n", ")", "\n", "self", ".", "_neighbor_params", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "_embedding_dim", ",", "self", ".", "_embedding_dim", ")", "\n", "\n", "if", "num_linking_features", ">", "0", ":", "\n", "            ", "self", ".", "_linking_params", "=", "torch", ".", "nn", ".", "Linear", "(", "num_linking_features", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_linking_params", "=", "None", "\n", "\n", "", "if", "self", ".", "_use_neighbor_similarity_for_linking", ":", "\n", "            ", "self", ".", "_question_entity_params", "=", "torch", ".", "nn", ".", "Linear", "(", "1", ",", "1", ")", "\n", "self", ".", "_question_neighbor_params", "=", "torch", ".", "nn", ".", "Linear", "(", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_question_entity_params", "=", "None", "\n", "self", ".", "_question_neighbor_params", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_initial_rnn_and_grammar_state": [[153, 329], ["wikitables_semantic_parser.WikiTablesSemanticParser._question_embedder", "allennlp.nn.util.get_text_field_mask", "wikitables_semantic_parser.WikiTablesSemanticParser._question_embedder", "allennlp.nn.util.get_text_field_mask", "wikitables_semantic_parser.WikiTablesSemanticParser.size", "wikitables_semantic_parser.WikiTablesSemanticParser.size", "wikitables_semantic_parser.WikiTablesSemanticParser._entity_encoder", "wikitables_semantic_parser.WikiTablesSemanticParser._get_type_vector", "wikitables_semantic_parser.WikiTablesSemanticParser._entity_type_encoder_embedding", "wikitables_semantic_parser.WikiTablesSemanticParser._get_neighbor_indices", "torch.bmm", "question_entity_similarity.view.view.view", "torch.max", "wikitables_semantic_parser.WikiTablesSemanticParser._get_linking_probabilities", "allennlp.nn.util.weighted_sum", "torch.cat", "wikitables_semantic_parser.WikiTablesSemanticParser._dropout", "allennlp.nn.util.get_final_encoder_states", "wikitables_semantic_parser.WikiTablesSemanticParser.new_zeros", "range", "allennlp.nn.util.batched_index_select", "allennlp.nn.util.get_text_field_mask().float", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed.", "wikitables_semantic_parser.WikiTablesSemanticParser._neighbor_params", "torch.tanh", "torch.tanh", "wikitables_semantic_parser.WikiTablesSemanticParser.view", "torch.transpose", "allennlp.nn.util.batched_index_select", "torch.max", "wikitables_semantic_parser.WikiTablesSemanticParser._question_entity_params().squeeze", "wikitables_semantic_parser.WikiTablesSemanticParser._question_neighbor_params().squeeze", "wikitables_semantic_parser.WikiTablesSemanticParser._linking_params().squeeze", "linking_scores.transpose", "wikitables_semantic_parser.WikiTablesSemanticParser._encoder", "wikitables_semantic_parser.WikiTablesSemanticParser._encoder.is_bidirectional", "wikitables_semantic_parser.WikiTablesSemanticParser._encoder.get_output_dim", "initial_rnn_state.append", "wikitables_semantic_parser.WikiTablesSemanticParser._create_grammar_state", "torch.abs", "allennlp.modules.seq2vec_encoders.BagOfEmbeddingsEncoder", "allennlp.modules.TimeDistributed.float", "torch.abs", "range", "range", "allennlp_semparse.state_machines.states.RnnStatelet", "range", "allennlp.nn.util.get_text_field_mask", "wikitables_semantic_parser.WikiTablesSemanticParser._question_entity_params", "wikitables_semantic_parser.WikiTablesSemanticParser._question_neighbor_params", "wikitables_semantic_parser.WikiTablesSemanticParser._linking_params", "question_entity_similarity_max_score.unsqueeze", "question_neighbor_similarity_max_score.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_type_vector", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_neighbor_indices", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_linking_probabilities", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._create_grammar_state"], ["", "", "def", "_get_initial_rnn_and_grammar_state", "(", "\n", "self", ",", "\n", "question", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "table", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "world", ":", "List", "[", "WikiTablesLanguage", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRuleArray", "]", "]", ",", "\n", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "RnnStatelet", "]", ",", "List", "[", "GrammarStatelet", "]", "]", ":", "\n", "        ", "\"\"\"\n        Encodes the question and table, computes a linking between the two, and constructs an\n        initial RnnStatelet and GrammarStatelet for each batch instance to pass to the\n        decoder.\n\n        We take ``outputs`` as a parameter here and `modify` it, adding things that we want to\n        visualize in a demo.\n        \"\"\"", "\n", "table_text", "=", "table", "[", "\"text\"", "]", "\n", "# (batch_size, question_length, embedding_dim)", "\n", "embedded_question", "=", "self", ".", "_question_embedder", "(", "question", ")", "\n", "question_mask", "=", "util", ".", "get_text_field_mask", "(", "question", ")", "\n", "# (batch_size, num_entities, num_entity_tokens, embedding_dim)", "\n", "embedded_table", "=", "self", ".", "_question_embedder", "(", "table_text", ",", "num_wrapping_dims", "=", "1", ")", "\n", "table_mask", "=", "util", ".", "get_text_field_mask", "(", "table_text", ",", "num_wrapping_dims", "=", "1", ")", "\n", "\n", "batch_size", ",", "num_entities", ",", "num_entity_tokens", ",", "_", "=", "embedded_table", ".", "size", "(", ")", "\n", "num_question_tokens", "=", "embedded_question", ".", "size", "(", "1", ")", "\n", "\n", "# (batch_size, num_entities, embedding_dim)", "\n", "encoded_table", "=", "self", ".", "_entity_encoder", "(", "embedded_table", ",", "table_mask", ")", "\n", "\n", "# entity_types: tensor with shape (batch_size, num_entities), where each entry is the", "\n", "# entity's type id.", "\n", "# entity_type_dict: Dict[int, int], mapping flattened_entity_index -> type_index", "\n", "# These encode the same information, but for efficiency reasons later it's nice", "\n", "# to have one version as a tensor and one that's accessible on the cpu.", "\n", "entity_types", ",", "entity_type_dict", "=", "self", ".", "_get_type_vector", "(", "world", ",", "num_entities", ",", "encoded_table", ")", "\n", "\n", "entity_type_embeddings", "=", "self", ".", "_entity_type_encoder_embedding", "(", "entity_types", ")", "\n", "\n", "# (batch_size, num_entities, num_neighbors) or None", "\n", "neighbor_indices", "=", "self", ".", "_get_neighbor_indices", "(", "world", ",", "num_entities", ",", "encoded_table", ")", "\n", "\n", "if", "neighbor_indices", "is", "not", "None", ":", "\n", "# Neighbor_indices is padded with -1 since 0 is a potential neighbor index.", "\n", "# Thus, the absolute value needs to be taken in the index_select, and 1 needs to", "\n", "# be added for the mask since that method expects 0 for padding.", "\n", "# (batch_size, num_entities, num_neighbors, embedding_dim)", "\n", "            ", "embedded_neighbors", "=", "util", ".", "batched_index_select", "(", "\n", "encoded_table", ",", "torch", ".", "abs", "(", "neighbor_indices", ")", "\n", ")", "\n", "\n", "neighbor_mask", "=", "util", ".", "get_text_field_mask", "(", "\n", "{", "\"ignored\"", ":", "{", "\"ignored\"", ":", "neighbor_indices", "+", "1", "}", "}", ",", "num_wrapping_dims", "=", "1", "\n", ")", ".", "float", "(", ")", "\n", "\n", "# Encoder initialized to easily obtain a masked average.", "\n", "neighbor_encoder", "=", "TimeDistributed", "(", "\n", "BagOfEmbeddingsEncoder", "(", "self", ".", "_embedding_dim", ",", "averaged", "=", "True", ")", "\n", ")", "\n", "# (batch_size, num_entities, embedding_dim)", "\n", "embedded_neighbors", "=", "neighbor_encoder", "(", "embedded_neighbors", ",", "neighbor_mask", ")", "\n", "projected_neighbor_embeddings", "=", "self", ".", "_neighbor_params", "(", "embedded_neighbors", ".", "float", "(", ")", ")", "\n", "\n", "# (batch_size, num_entities, embedding_dim)", "\n", "entity_embeddings", "=", "torch", ".", "tanh", "(", "entity_type_embeddings", "+", "projected_neighbor_embeddings", ")", "\n", "", "else", ":", "\n", "# (batch_size, num_entities, embedding_dim)", "\n", "            ", "entity_embeddings", "=", "torch", ".", "tanh", "(", "entity_type_embeddings", ")", "\n", "\n", "# Compute entity and question word similarity.  We tried using cosine distance here, but", "\n", "# because this similarity is the main mechanism that the model can use to push apart logit", "\n", "# scores for certain actions (like \"n -> 1\" and \"n -> -1\"), this needs to have a larger", "\n", "# output range than [-1, 1].", "\n", "", "question_entity_similarity", "=", "torch", ".", "bmm", "(", "\n", "embedded_table", ".", "view", "(", "batch_size", ",", "num_entities", "*", "num_entity_tokens", ",", "self", ".", "_embedding_dim", ")", ",", "\n", "torch", ".", "transpose", "(", "embedded_question", ",", "1", ",", "2", ")", ",", "\n", ")", "\n", "\n", "question_entity_similarity", "=", "question_entity_similarity", ".", "view", "(", "\n", "batch_size", ",", "num_entities", ",", "num_entity_tokens", ",", "num_question_tokens", "\n", ")", "\n", "\n", "# (batch_size, num_entities, num_question_tokens)", "\n", "question_entity_similarity_max_score", ",", "_", "=", "torch", ".", "max", "(", "question_entity_similarity", ",", "2", ")", "\n", "\n", "# (batch_size, num_entities, num_question_tokens, num_features)", "\n", "linking_features", "=", "table", "[", "\"linking\"", "]", "\n", "\n", "linking_scores", "=", "question_entity_similarity_max_score", "\n", "\n", "if", "self", ".", "_use_neighbor_similarity_for_linking", ":", "\n", "# The linking score is computed as a linear projection of two terms. The first is the", "\n", "# maximum similarity score over the entity's words and the question token. The second", "\n", "# is the maximum similarity over the words in the entity's neighbors and the question", "\n", "# token.", "\n", "#", "\n", "# The second term, projected_question_neighbor_similarity, is useful when a column", "\n", "# needs to be selected. For example, the question token might have no similarity with", "\n", "# the column name, but is similar with the cells in the column.", "\n", "#", "\n", "# Note that projected_question_neighbor_similarity is intended to capture the same", "\n", "# information as the related_column feature.", "\n", "#", "\n", "# Also note that this block needs to be _before_ the `linking_params` block, because", "\n", "# we're overwriting `linking_scores`, not adding to it.", "\n", "\n", "# (batch_size, num_entities, num_neighbors, num_question_tokens)", "\n", "            ", "question_neighbor_similarity", "=", "util", ".", "batched_index_select", "(", "\n", "question_entity_similarity_max_score", ",", "torch", ".", "abs", "(", "neighbor_indices", ")", "\n", ")", "\n", "# (batch_size, num_entities, num_question_tokens)", "\n", "question_neighbor_similarity_max_score", ",", "_", "=", "torch", ".", "max", "(", "question_neighbor_similarity", ",", "2", ")", "\n", "projected_question_entity_similarity", "=", "self", ".", "_question_entity_params", "(", "\n", "question_entity_similarity_max_score", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "projected_question_neighbor_similarity", "=", "self", ".", "_question_neighbor_params", "(", "\n", "question_neighbor_similarity_max_score", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "linking_scores", "=", "(", "\n", "projected_question_entity_similarity", "+", "projected_question_neighbor_similarity", "\n", ")", "\n", "\n", "", "feature_scores", "=", "None", "\n", "if", "self", ".", "_linking_params", "is", "not", "None", ":", "\n", "            ", "feature_scores", "=", "self", ".", "_linking_params", "(", "linking_features", ")", ".", "squeeze", "(", "3", ")", "\n", "linking_scores", "=", "linking_scores", "+", "feature_scores", "\n", "\n", "# (batch_size, num_question_tokens, num_entities)", "\n", "", "linking_probabilities", "=", "self", ".", "_get_linking_probabilities", "(", "\n", "world", ",", "linking_scores", ".", "transpose", "(", "1", ",", "2", ")", ",", "question_mask", ",", "entity_type_dict", "\n", ")", "\n", "\n", "# (batch_size, num_question_tokens, embedding_dim)", "\n", "link_embedding", "=", "util", ".", "weighted_sum", "(", "entity_embeddings", ",", "linking_probabilities", ")", "\n", "encoder_input", "=", "torch", ".", "cat", "(", "[", "link_embedding", ",", "embedded_question", "]", ",", "2", ")", "\n", "\n", "# (batch_size, question_length, encoder_output_dim)", "\n", "encoder_outputs", "=", "self", ".", "_dropout", "(", "self", ".", "_encoder", "(", "encoder_input", ",", "question_mask", ")", ")", "\n", "\n", "# This will be our initial hidden state and memory cell for the decoder LSTM.", "\n", "final_encoder_output", "=", "util", ".", "get_final_encoder_states", "(", "\n", "encoder_outputs", ",", "question_mask", ",", "self", ".", "_encoder", ".", "is_bidirectional", "(", ")", "\n", ")", "\n", "memory_cell", "=", "encoder_outputs", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ")", "\n", "\n", "# To make grouping states together in the decoder easier, we convert the batch dimension in", "\n", "# all of our tensors into an outer list.  For instance, the encoder outputs have shape", "\n", "# `(batch_size, question_length, encoder_output_dim)`.  We need to convert this into a list", "\n", "# of `batch_size` tensors, each of shape `(question_length, encoder_output_dim)`.  Then we", "\n", "# won't have to do any index selects, or anything, we'll just do some `torch.cat()`s.", "\n", "encoder_output_list", "=", "[", "encoder_outputs", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "question_mask_list", "=", "[", "question_mask", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_rnn_state", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "initial_rnn_state", ".", "append", "(", "\n", "RnnStatelet", "(", "\n", "final_encoder_output", "[", "i", "]", ",", "\n", "memory_cell", "[", "i", "]", ",", "\n", "self", ".", "_first_action_embedding", ",", "\n", "self", ".", "_first_attended_question", ",", "\n", "encoder_output_list", ",", "\n", "question_mask_list", ",", "\n", ")", "\n", ")", "\n", "", "initial_grammar_state", "=", "[", "\n", "self", ".", "_create_grammar_state", "(", "world", "[", "i", "]", ",", "actions", "[", "i", "]", ",", "linking_scores", "[", "i", "]", ",", "entity_types", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "if", "not", "self", ".", "training", ":", "\n", "# We add a few things to the outputs that will be returned from `forward` at evaluation", "\n", "# time, for visualization in a demo.", "\n", "            ", "outputs", "[", "\"linking_scores\"", "]", "=", "linking_scores", "\n", "if", "feature_scores", "is", "not", "None", ":", "\n", "                ", "outputs", "[", "\"feature_scores\"", "]", "=", "feature_scores", "\n", "", "outputs", "[", "\"similarity_scores\"", "]", "=", "question_entity_similarity_max_score", "\n", "", "return", "initial_rnn_state", ",", "initial_grammar_state", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_neighbor_indices": [[330, 382], ["tensor.new_tensor", "allennlp.common.util.pad_sequence_to_length", "batch_neighbors.append", "allennlp.common.util.pad_sequence_to_length", "allennlp.common.util.pad_sequence_to_length.append", "len", "len", "enumerate"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_get_neighbor_indices", "(", "\n", "worlds", ":", "List", "[", "WikiTablesLanguage", "]", ",", "num_entities", ":", "int", ",", "tensor", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "\"\"\"\n        This method returns the indices of each entity's neighbors. A tensor\n        is accepted as a parameter for copying purposes.\n\n        Parameters\n        ----------\n        worlds : ``List[WikiTablesLanguage]``\n        num_entities : ``int``\n        tensor : ``torch.Tensor``\n            Used for copying the constructed list onto the right device.\n\n        Returns\n        -------\n        A ``torch.LongTensor`` with shape ``(batch_size, num_entities, num_neighbors)``. It is padded\n        with -1 instead of 0, since 0 is a valid neighbor index. If all the entities in the batch\n        have no neighbors, None will be returned.\n        \"\"\"", "\n", "\n", "num_neighbors", "=", "0", "\n", "for", "world", "in", "worlds", ":", "\n", "            ", "for", "entity", "in", "world", ".", "table_graph", ".", "entities", ":", "\n", "                ", "if", "len", "(", "world", ".", "table_graph", ".", "neighbors", "[", "entity", "]", ")", ">", "num_neighbors", ":", "\n", "                    ", "num_neighbors", "=", "len", "(", "world", ".", "table_graph", ".", "neighbors", "[", "entity", "]", ")", "\n", "\n", "", "", "", "batch_neighbors", "=", "[", "]", "\n", "no_entities_have_neighbors", "=", "True", "\n", "for", "world", "in", "worlds", ":", "\n", "# Each batch instance has its own world, which has a corresponding table.", "\n", "            ", "entities", "=", "world", ".", "table_graph", ".", "entities", "\n", "entity2index", "=", "{", "entity", ":", "i", "for", "i", ",", "entity", "in", "enumerate", "(", "entities", ")", "}", "\n", "entity2neighbors", "=", "world", ".", "table_graph", ".", "neighbors", "\n", "neighbor_indexes", "=", "[", "]", "\n", "for", "entity", "in", "entities", ":", "\n", "                ", "entity_neighbors", "=", "[", "entity2index", "[", "n", "]", "for", "n", "in", "entity2neighbors", "[", "entity", "]", "]", "\n", "if", "entity_neighbors", ":", "\n", "                    ", "no_entities_have_neighbors", "=", "False", "\n", "# Pad with -1 instead of 0, since 0 represents a neighbor index.", "\n", "", "padded", "=", "pad_sequence_to_length", "(", "entity_neighbors", ",", "num_neighbors", ",", "lambda", ":", "-", "1", ")", "\n", "neighbor_indexes", ".", "append", "(", "padded", ")", "\n", "", "neighbor_indexes", "=", "pad_sequence_to_length", "(", "\n", "neighbor_indexes", ",", "num_entities", ",", "lambda", ":", "[", "-", "1", "]", "*", "num_neighbors", "\n", ")", "\n", "batch_neighbors", ".", "append", "(", "neighbor_indexes", ")", "\n", "# It is possible that none of the entities has any neighbors, since our definition of the", "\n", "# knowledge graph allows it when no entities or numbers were extracted from the question.", "\n", "", "if", "no_entities_have_neighbors", ":", "\n", "            ", "return", "None", "\n", "", "return", "tensor", ".", "new_tensor", "(", "batch_neighbors", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_type_vector": [[383, 433], ["enumerate", "enumerate", "allennlp.common.util.pad_sequence_to_length", "batch_types.append", "tensor.new_tensor", "entity.startswith", "types.append", "entity.startswith", "entity.startswith", "entity.startswith"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_get_type_vector", "(", "\n", "worlds", ":", "List", "[", "WikiTablesLanguage", "]", ",", "num_entities", ":", "int", ",", "tensor", ":", "torch", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "LongTensor", ",", "Dict", "[", "int", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Produces a tensor with shape ``(batch_size, num_entities)`` that encodes each entity's\n        type. In addition, a map from a flattened entity index to type is returned to combine\n        entity type operations into one method.\n\n        Parameters\n        ----------\n        worlds : ``List[WikiTablesLanguage]``\n        num_entities : ``int``\n        tensor : ``torch.Tensor``\n            Used for copying the constructed list onto the right device.\n\n        Returns\n        -------\n        A ``torch.LongTensor`` with shape ``(batch_size, num_entities)``.\n        entity_types : ``Dict[int, int]``\n            This is a mapping from ((batch_index * num_entities) + entity_index) to entity type id.\n        \"\"\"", "\n", "entity_types", "=", "{", "}", "\n", "batch_types", "=", "[", "]", "\n", "for", "batch_index", ",", "world", "in", "enumerate", "(", "worlds", ")", ":", "\n", "            ", "types", "=", "[", "]", "\n", "for", "entity_index", ",", "entity", "in", "enumerate", "(", "world", ".", "table_graph", ".", "entities", ")", ":", "\n", "# We need numbers to be first, then date columns, then number columns, strings, and", "\n", "# string columns, in that order, because our entities are going to be sorted.  We do", "\n", "# a split by type and then a merge later, and it relies on this sorting.", "\n", "                ", "if", "entity", ".", "startswith", "(", "\"date_column:\"", ")", ":", "\n", "                    ", "entity_type", "=", "1", "\n", "", "elif", "entity", ".", "startswith", "(", "\"number_column:\"", ")", ":", "\n", "                    ", "entity_type", "=", "2", "\n", "", "elif", "entity", ".", "startswith", "(", "\"string:\"", ")", ":", "\n", "                    ", "entity_type", "=", "3", "\n", "", "elif", "entity", ".", "startswith", "(", "\"string_column:\"", ")", ":", "\n", "                    ", "entity_type", "=", "4", "\n", "", "else", ":", "\n", "                    ", "entity_type", "=", "0", "\n", "", "types", ".", "append", "(", "entity_type", ")", "\n", "\n", "# For easier lookups later, we're actually using a _flattened_ version", "\n", "# of (batch_index, entity_index) for the key, because this is how the", "\n", "# linking scores are stored.", "\n", "flattened_entity_index", "=", "batch_index", "*", "num_entities", "+", "entity_index", "\n", "entity_types", "[", "flattened_entity_index", "]", "=", "entity_type", "\n", "", "padded", "=", "pad_sequence_to_length", "(", "types", ",", "num_entities", ",", "lambda", ":", "0", ")", "\n", "batch_types", ".", "append", "(", "padded", ")", "\n", "", "return", "tensor", ".", "new_tensor", "(", "batch_types", ",", "dtype", "=", "torch", ".", "long", ")", ",", "entity_types", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_linking_probabilities": [[434, 518], ["linking_scores.size", "enumerate", "torch.stack", "range", "torch.cat", "torch.stack.append", "question_mask.unsqueeze().float", "enumerate", "linking_scores.new_tensor", "linking_scores[].index_select", "torch.nn.functional.softmax", "all_probabilities.append", "linking_scores.new_zeros", "all_probabilities.append", "len", "len", "question_mask.unsqueeze", "entity_indices.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_linking_probabilities", "(", "\n", "self", ",", "\n", "worlds", ":", "List", "[", "WikiTablesLanguage", "]", ",", "\n", "linking_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "question_mask", ":", "torch", ".", "LongTensor", ",", "\n", "entity_type_dict", ":", "Dict", "[", "int", ",", "int", "]", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"\n        Produces the probability of an entity given a question word and type. The logic below\n        separates the entities by type since the softmax normalization term sums over entities\n        of a single type.\n\n        Parameters\n        ----------\n        worlds : ``List[WikiTablesLanguage]``\n        linking_scores : ``torch.FloatTensor``\n            Has shape (batch_size, num_question_tokens, num_entities).\n        question_mask: ``torch.LongTensor``\n            Has shape (batch_size, num_question_tokens).\n        entity_type_dict : ``Dict[int, int]``\n            This is a mapping from ((batch_index * num_entities) + entity_index) to entity type id.\n\n        Returns\n        -------\n        batch_probabilities : ``torch.FloatTensor``\n            Has shape ``(batch_size, num_question_tokens, num_entities)``.\n            Contains all the probabilities for an entity given a question word.\n        \"\"\"", "\n", "_", ",", "num_question_tokens", ",", "num_entities", "=", "linking_scores", ".", "size", "(", ")", "\n", "batch_probabilities", "=", "[", "]", "\n", "\n", "for", "batch_index", ",", "world", "in", "enumerate", "(", "worlds", ")", ":", "\n", "            ", "all_probabilities", "=", "[", "]", "\n", "num_entities_in_instance", "=", "0", "\n", "\n", "# NOTE: The way that we're doing this here relies on the fact that entities are", "\n", "# implicitly sorted by their types when we sort them by name, and that numbers come", "\n", "# before \"date_column:\", followed by \"number_column:\", \"string:\", and \"string_column:\".", "\n", "# This is not a great assumption, and could easily break later, but it should work for now.", "\n", "for", "type_index", "in", "range", "(", "self", ".", "_num_entity_types", ")", ":", "\n", "# This index of 0 is for the null entity for each type, representing the case where a", "\n", "# word doesn't link to any entity.", "\n", "                ", "entity_indices", "=", "[", "0", "]", "\n", "entities", "=", "world", ".", "table_graph", ".", "entities", "\n", "for", "entity_index", ",", "_", "in", "enumerate", "(", "entities", ")", ":", "\n", "                    ", "if", "entity_type_dict", "[", "batch_index", "*", "num_entities", "+", "entity_index", "]", "==", "type_index", ":", "\n", "                        ", "entity_indices", ".", "append", "(", "entity_index", ")", "\n", "\n", "", "", "if", "len", "(", "entity_indices", ")", "==", "1", ":", "\n", "# No entities of this type; move along...", "\n", "                    ", "continue", "\n", "\n", "# We're subtracting one here because of the null entity we added above.", "\n", "", "num_entities_in_instance", "+=", "len", "(", "entity_indices", ")", "-", "1", "\n", "\n", "# We separate the scores by type, since normalization is done per type.  There's an", "\n", "# extra \"null\" entity per type, also, so we have `num_entities_per_type + 1`.  We're", "\n", "# selecting from a (num_question_tokens, num_entities) linking tensor on _dimension 1_,", "\n", "# so we get back something of shape (num_question_tokens,) for each index we're", "\n", "# selecting.  All of the selected indices together then make a tensor of shape", "\n", "# (num_question_tokens, num_entities_per_type + 1).", "\n", "indices", "=", "linking_scores", ".", "new_tensor", "(", "entity_indices", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "entity_scores", "=", "linking_scores", "[", "batch_index", "]", ".", "index_select", "(", "1", ",", "indices", ")", "\n", "\n", "# We used index 0 for the null entity, so this will actually have some values in it.", "\n", "# But we want the null entity's score to be 0, so we set that here.", "\n", "entity_scores", "[", ":", ",", "0", "]", "=", "0", "\n", "\n", "# No need for a mask here, as this is done per batch instance, with no padding.", "\n", "type_probabilities", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "entity_scores", ",", "dim", "=", "1", ")", "\n", "all_probabilities", ".", "append", "(", "type_probabilities", "[", ":", ",", "1", ":", "]", ")", "\n", "\n", "# We need to add padding here if we don't have the right number of entities.", "\n", "", "if", "num_entities_in_instance", "!=", "num_entities", ":", "\n", "                ", "zeros", "=", "linking_scores", ".", "new_zeros", "(", "\n", "num_question_tokens", ",", "num_entities", "-", "num_entities_in_instance", "\n", ")", "\n", "all_probabilities", ".", "append", "(", "zeros", ")", "\n", "\n", "# (num_question_tokens, num_entities)", "\n", "", "probabilities", "=", "torch", ".", "cat", "(", "all_probabilities", ",", "dim", "=", "1", ")", "\n", "batch_probabilities", ".", "append", "(", "probabilities", ")", "\n", "", "batch_probabilities", "=", "torch", ".", "stack", "(", "batch_probabilities", ",", "dim", "=", "0", ")", "\n", "return", "batch_probabilities", "*", "question_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._action_history_match": [[519, 529], ["targets.new_tensor", "torch.max().item", "len", "targets.size", "torch.max", "len", "torch.min", "targets_trimmed.eq"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_action_history_match", "(", "predicted", ":", "List", "[", "int", "]", ",", "targets", ":", "torch", ".", "LongTensor", ")", "->", "int", ":", "\n", "# TODO(mattg): this could probably be moved into a FullSequenceMatch metric, or something.", "\n", "# Check if target is big enough to cover prediction (including start/end symbols)", "\n", "        ", "if", "len", "(", "predicted", ")", ">", "targets", ".", "size", "(", "1", ")", ":", "\n", "            ", "return", "0", "\n", "", "predicted_tensor", "=", "targets", ".", "new_tensor", "(", "predicted", ")", "\n", "targets_trimmed", "=", "targets", "[", ":", ",", ":", "len", "(", "predicted", ")", "]", "\n", "# Return 1 if the predicted sequence is anywhere in the list of targets.", "\n", "return", "torch", ".", "max", "(", "torch", ".", "min", "(", "targets_trimmed", ".", "eq", "(", "predicted_tensor", ")", ",", "dim", "=", "1", ")", "[", "0", "]", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser.get_metrics": [[530, 556], ["wikitables_semantic_parser.WikiTablesSemanticParser._action_sequence_accuracy.get_metric", "wikitables_semantic_parser.WikiTablesSemanticParser._denotation_accuracy.get_metric", "wikitables_semantic_parser.WikiTablesSemanticParser._has_logical_form.get_metric"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        We track three metrics here:\n\n            1. lf_retrieval_acc, which is the percentage of the time that our best output action\n            sequence is in the set of action sequences provided by offline search.  This is an\n            easy-to-compute lower bound on denotation accuracy for the set of examples where we\n            actually have offline output.  We only score lf_retrieval_acc on that subset.\n\n            2. denotation_acc, which is the percentage of examples where we get the correct\n            denotation.  This is the typical \"accuracy\" metric, and it is what you should usually\n            report in an experimental result.  You need to be careful, though, that you're\n            computing this on the full data, and not just the subset that has DPD output (make sure\n            you pass \"keep_if_no_dpd=True\" to the dataset reader, which we do for validation data,\n            but not training data).\n\n            3. lf_percent, which is the percentage of time that decoding actually produces a\n            finished logical form.  We might not produce a valid logical form if the decoder gets\n            into a repetitive loop, or we're trying to produce a super long logical form and run\n            out of time steps, or something.\n        \"\"\"", "\n", "return", "{", "\n", "\"lf_retrieval_acc\"", ":", "self", ".", "_action_sequence_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"denotation_acc\"", ":", "self", ".", "_denotation_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"lf_percent\"", ":", "self", ".", "_has_logical_form", ".", "get_metric", "(", "reset", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._create_grammar_state": [[558, 658], ["enumerate", "enumerate", "world.get_nonterminal_productions", "world.get_nonterminal_productions.items", "allennlp_semparse.state_machines.states.GrammarStatelet", "zip", "torch.cat", "wikitables_semantic_parser.WikiTablesSemanticParser._action_embedder", "wikitables_semantic_parser.WikiTablesSemanticParser._output_action_embedder", "zip", "wikitables_semantic_parser.WikiTablesSemanticParser._entity_type_decoder_embedding", "global_actions.append", "linked_actions.append", "wikitables_semantic_parser.WikiTablesSemanticParser._action_biases", "torch.cat", "list", "list", "rule.split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_create_grammar_state", "(", "\n", "self", ",", "\n", "world", ":", "WikiTablesLanguage", ",", "\n", "possible_actions", ":", "List", "[", "ProductionRuleArray", "]", ",", "\n", "linking_scores", ":", "torch", ".", "Tensor", ",", "\n", "entity_types", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "GrammarStatelet", ":", "\n", "        ", "\"\"\"\n        This method creates the GrammarStatelet object that's used for decoding.  Part of\n        creating that is creating the `valid_actions` dictionary, which contains embedded\n        representations of all of the valid actions.  So, we create that here as well.\n\n        The way we represent the valid expansions is a little complicated: we use a\n        dictionary of `action types`, where the key is the action type (like \"global\", \"linked\", or\n        whatever your model is expecting), and the value is a tuple representing all actions of\n        that type.  The tuple is (input tensor, output tensor, action id).  The input tensor has\n        the representation that is used when `selecting` actions, for all actions of this type.\n        The output tensor has the representation that is used when feeding the action to the next\n        step of the decoder (this could just be the same as the input tensor).  The action ids are\n        a list of indices into the main action list for each batch instance.\n\n        The inputs to this method are for a `single instance in the batch`; none of the tensors we\n        create here are batched.  We grab the global action ids from the input\n        ``ProductionRuleArrays``, and we use those to embed the valid actions for every\n        non-terminal type.  We use the input ``linking_scores`` for non-global actions.\n\n        Parameters\n        ----------\n        world : ``WikiTablesLanguage``\n            From the input to ``forward`` for a single batch instance.\n        possible_actions : ``List[ProductionRuleArray]``\n            From the input to ``forward`` for a single batch instance.\n        linking_scores : ``torch.Tensor``\n            Assumed to have shape ``(num_entities, num_question_tokens)`` (i.e., there is no batch\n            dimension).\n        entity_types : ``torch.Tensor``\n            Assumed to have shape ``(num_entities,)`` (i.e., there is no batch dimension).\n        \"\"\"", "\n", "# TODO(mattg): Move the \"valid_actions\" construction to another method.", "\n", "action_map", "=", "{", "}", "\n", "for", "action_index", ",", "action", "in", "enumerate", "(", "possible_actions", ")", ":", "\n", "            ", "action_string", "=", "action", "[", "0", "]", "\n", "action_map", "[", "action_string", "]", "=", "action_index", "\n", "", "entity_map", "=", "{", "}", "\n", "for", "entity_index", ",", "entity", "in", "enumerate", "(", "world", ".", "table_graph", ".", "entities", ")", ":", "\n", "            ", "entity_map", "[", "entity", "]", "=", "entity_index", "\n", "\n", "", "valid_actions", "=", "world", ".", "get_nonterminal_productions", "(", ")", "\n", "translated_valid_actions", ":", "Dict", "[", "\n", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", "\n", "]", "=", "{", "}", "\n", "for", "key", ",", "action_strings", "in", "valid_actions", ".", "items", "(", ")", ":", "\n", "            ", "translated_valid_actions", "[", "key", "]", "=", "{", "}", "\n", "# `key` here is a non-terminal from the grammar, and `action_strings` are all the valid", "\n", "# productions of that non-terminal.  We'll first split those productions by global vs.", "\n", "# linked action.", "\n", "action_indices", "=", "[", "action_map", "[", "action_string", "]", "for", "action_string", "in", "action_strings", "]", "\n", "production_rule_arrays", "=", "[", "(", "possible_actions", "[", "index", "]", ",", "index", ")", "for", "index", "in", "action_indices", "]", "\n", "global_actions", "=", "[", "]", "\n", "linked_actions", "=", "[", "]", "\n", "for", "production_rule_array", ",", "action_index", "in", "production_rule_arrays", ":", "\n", "                ", "if", "production_rule_array", "[", "1", "]", ":", "\n", "                    ", "global_actions", ".", "append", "(", "(", "production_rule_array", "[", "2", "]", ",", "action_index", ")", ")", "\n", "", "else", ":", "\n", "                    ", "linked_actions", ".", "append", "(", "(", "production_rule_array", "[", "0", "]", ",", "action_index", ")", ")", "\n", "\n", "# Then we get the embedded representations of the global actions if any.", "\n", "", "", "if", "global_actions", ":", "\n", "                ", "global_action_tensors", ",", "global_action_ids", "=", "zip", "(", "*", "global_actions", ")", "\n", "global_action_tensor", "=", "torch", ".", "cat", "(", "global_action_tensors", ",", "dim", "=", "0", ")", "\n", "global_input_embeddings", "=", "self", ".", "_action_embedder", "(", "global_action_tensor", ")", "\n", "if", "self", ".", "_add_action_bias", ":", "\n", "                    ", "global_action_biases", "=", "self", ".", "_action_biases", "(", "global_action_tensor", ")", "\n", "global_input_embeddings", "=", "torch", ".", "cat", "(", "\n", "[", "global_input_embeddings", ",", "global_action_biases", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "", "global_output_embeddings", "=", "self", ".", "_output_action_embedder", "(", "global_action_tensor", ")", "\n", "translated_valid_actions", "[", "key", "]", "[", "\"global\"", "]", "=", "(", "\n", "global_input_embeddings", ",", "\n", "global_output_embeddings", ",", "\n", "list", "(", "global_action_ids", ")", ",", "\n", ")", "\n", "\n", "# Then the representations of the linked actions.", "\n", "", "if", "linked_actions", ":", "\n", "                ", "linked_rules", ",", "linked_action_ids", "=", "zip", "(", "*", "linked_actions", ")", "\n", "entities", "=", "[", "rule", ".", "split", "(", "\" -> \"", ")", "[", "1", "]", "for", "rule", "in", "linked_rules", "]", "\n", "entity_ids", "=", "[", "entity_map", "[", "entity", "]", "for", "entity", "in", "entities", "]", "\n", "# (num_linked_actions, num_question_tokens)", "\n", "entity_linking_scores", "=", "linking_scores", "[", "entity_ids", "]", "\n", "# (num_linked_actions,)", "\n", "entity_type_tensor", "=", "entity_types", "[", "entity_ids", "]", "\n", "# (num_linked_actions, entity_type_embedding_dim)", "\n", "entity_type_embeddings", "=", "self", ".", "_entity_type_decoder_embedding", "(", "entity_type_tensor", ")", "\n", "translated_valid_actions", "[", "key", "]", "[", "\"linked\"", "]", "=", "(", "\n", "entity_linking_scores", ",", "\n", "entity_type_embeddings", ",", "\n", "list", "(", "linked_action_ids", ")", ",", "\n", ")", "\n", "", "", "return", "GrammarStatelet", "(", "[", "START_SYMBOL", "]", ",", "translated_valid_actions", ",", "world", ".", "is_nonterminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._compute_validation_outputs": [[659, 741], ["len", "enumerate", "range", "enumerate", "outputs[].append", "outputs[].append", "outputs[].append", "wikitables_semantic_parser.WikiTablesSemanticParser._has_logical_form", "wikitables_semantic_parser.WikiTablesSemanticParser._denotation_accuracy", "[].append", "outputs[].append", "wikitables_semantic_parser.WikiTablesSemanticParser._denotation_accuracy", "range", "world[].action_sequence_to_logical_form", "world[].evaluate_logical_form", "len", "world[].execute", "outputs[].append", "outputs[].append", "wikitables_semantic_parser.WikiTablesSemanticParser._has_logical_form", "wikitables_semantic_parser.WikiTablesSemanticParser._has_logical_form", "wikitables_semantic_parser.WikiTablesSemanticParser._denotation_accuracy"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_compute_validation_outputs", "(", "\n", "self", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRuleArray", "]", "]", ",", "\n", "best_final_states", ":", "Mapping", "[", "int", ",", "Sequence", "[", "GrammarBasedState", "]", "]", ",", "\n", "world", ":", "List", "[", "WikiTablesLanguage", "]", ",", "\n", "target_list", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Does common things for validation time: computing logical form accuracy (which is expensive\n        and unnecessary during training), adding visualization info to the output dictionary, etc.\n\n        This doesn't return anything; instead it `modifies` the given ``outputs`` dictionary, and\n        calls metrics on ``self``.\n        \"\"\"", "\n", "batch_size", "=", "len", "(", "actions", ")", "\n", "action_mapping", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_actions", "in", "enumerate", "(", "actions", ")", ":", "\n", "            ", "for", "action_index", ",", "action", "in", "enumerate", "(", "batch_actions", ")", ":", "\n", "                ", "action_mapping", "[", "(", "batch_index", ",", "action_index", ")", "]", "=", "action", "[", "0", "]", "\n", "", "", "outputs", "[", "\"action_mapping\"", "]", "=", "action_mapping", "\n", "outputs", "[", "\"best_action_sequence\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"debug_info\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"entities\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"logical_form\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"answer\"", "]", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# Decoding may not have terminated with any completed logical forms, if `num_steps`", "\n", "# isn't long enough (or if the model is not trained enough and gets into an", "\n", "# infinite action loop).", "\n", "            ", "outputs", "[", "\"logical_form\"", "]", ".", "append", "(", "[", "]", ")", "\n", "if", "i", "in", "best_final_states", ":", "\n", "                ", "all_action_indices", "=", "[", "\n", "best_final_states", "[", "i", "]", "[", "j", "]", ".", "action_history", "[", "0", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "best_final_states", "[", "i", "]", ")", ")", "\n", "]", "\n", "found_denotation", "=", "False", "\n", "for", "action_indices", "in", "all_action_indices", ":", "\n", "                    ", "action_strings", "=", "[", "\n", "action_mapping", "[", "(", "i", ",", "action_index", ")", "]", "for", "action_index", "in", "action_indices", "\n", "]", "\n", "has_logical_form", "=", "False", "\n", "try", ":", "\n", "                        ", "logical_form", "=", "world", "[", "i", "]", ".", "action_sequence_to_logical_form", "(", "action_strings", ")", "\n", "has_logical_form", "=", "True", "\n", "", "except", "ParsingError", ":", "\n", "                        ", "logical_form", "=", "\"Error producing logical form\"", "\n", "", "if", "target_list", "is", "not", "None", ":", "\n", "                        ", "denotation_correct", "=", "world", "[", "i", "]", ".", "evaluate_logical_form", "(", "\n", "logical_form", ",", "target_list", "[", "i", "]", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "denotation_correct", "=", "False", "\n", "", "if", "not", "found_denotation", ":", "\n", "                        ", "try", ":", "\n", "                            ", "denotation", "=", "world", "[", "i", "]", ".", "execute", "(", "logical_form", ")", "\n", "if", "denotation", ":", "\n", "                                ", "outputs", "[", "\"answer\"", "]", ".", "append", "(", "denotation", ")", "\n", "found_denotation", "=", "True", "\n", "", "", "except", "ExecutionError", ":", "\n", "                            ", "pass", "\n", "", "if", "found_denotation", ":", "\n", "                            ", "if", "has_logical_form", ":", "\n", "                                ", "self", ".", "_has_logical_form", "(", "1.0", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "_has_logical_form", "(", "0.0", ")", "\n", "", "if", "target_list", ":", "\n", "                                ", "self", ".", "_denotation_accuracy", "(", "1.0", "if", "denotation_correct", "else", "0.0", ")", "\n", "", "outputs", "[", "\"best_action_sequence\"", "]", ".", "append", "(", "action_strings", ")", "\n", "", "", "outputs", "[", "\"logical_form\"", "]", "[", "-", "1", "]", ".", "append", "(", "logical_form", ")", "\n", "", "if", "not", "found_denotation", ":", "\n", "                    ", "outputs", "[", "\"answer\"", "]", ".", "append", "(", "None", ")", "\n", "self", ".", "_denotation_accuracy", "(", "0.0", ")", "\n", "", "outputs", "[", "\"debug_info\"", "]", ".", "append", "(", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "debug_info", "[", "0", "]", ")", "# type: ignore", "\n", "outputs", "[", "\"entities\"", "]", ".", "append", "(", "world", "[", "i", "]", ".", "table_graph", ".", "entities", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_has_logical_form", "(", "0.0", ")", "\n", "self", ".", "_denotation_accuracy", "(", "0.0", ")", "\n", "\n", "", "", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "outputs", "[", "\"question_tokens\"", "]", "=", "[", "x", "[", "\"question_tokens\"", "]", "for", "x", "in", "metadata", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser.make_output_human_readable": [[742, 780], ["enumerate", "zip", "zip", "batch_action_info.append", "zip", "actions.sort", "zip", "action_debug_info.get", "instance_action_info.append", "actions.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "@", "overrides", "\n", "def", "make_output_human_readable", "(", "\n", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        This method overrides ``Model.decode``, which gets called after ``Model.forward``, at test\n        time, to finalize predictions.  This is (confusingly) a separate notion from the \"decoder\"\n        in \"encoder/decoder\", where that decoder logic lives in the ``TransitionFunction``.\n\n        This method trims the output predictions to the first end symbol, replaces indices with\n        corresponding tokens, and adds a field called ``predicted_tokens`` to the ``output_dict``.\n        \"\"\"", "\n", "action_mapping", "=", "output_dict", "[", "\"action_mapping\"", "]", "\n", "best_actions", "=", "output_dict", "[", "\"best_action_sequence\"", "]", "\n", "debug_infos", "=", "output_dict", "[", "\"debug_info\"", "]", "\n", "batch_action_info", "=", "[", "]", "\n", "for", "batch_index", ",", "(", "predicted_actions", ",", "debug_info", ")", "in", "enumerate", "(", "\n", "zip", "(", "best_actions", ",", "debug_infos", ")", "\n", ")", ":", "\n", "            ", "instance_action_info", "=", "[", "]", "\n", "for", "predicted_action", ",", "action_debug_info", "in", "zip", "(", "predicted_actions", ",", "debug_info", ")", ":", "\n", "                ", "action_info", "=", "{", "}", "\n", "action_info", "[", "\"predicted_action\"", "]", "=", "predicted_action", "\n", "considered_actions", "=", "action_debug_info", "[", "\"considered_actions\"", "]", "\n", "probabilities", "=", "action_debug_info", "[", "\"probabilities\"", "]", "\n", "actions", "=", "[", "]", "\n", "for", "action", ",", "probability", "in", "zip", "(", "considered_actions", ",", "probabilities", ")", ":", "\n", "                    ", "if", "action", "!=", "-", "1", ":", "\n", "                        ", "actions", ".", "append", "(", "(", "action_mapping", "[", "(", "batch_index", ",", "action", ")", "]", ",", "probability", ")", ")", "\n", "", "", "actions", ".", "sort", "(", ")", "\n", "considered_actions", ",", "probabilities", "=", "zip", "(", "*", "actions", ")", "\n", "action_info", "[", "\"considered_actions\"", "]", "=", "considered_actions", "\n", "action_info", "[", "\"action_probabilities\"", "]", "=", "probabilities", "\n", "action_info", "[", "\"question_attention\"", "]", "=", "action_debug_info", ".", "get", "(", "\"question_attention\"", ",", "[", "]", ")", "\n", "instance_action_info", ".", "append", "(", "action_info", ")", "\n", "", "batch_action_info", ".", "append", "(", "instance_action_info", ")", "\n", "", "output_dict", "[", "\"predicted_actions\"", "]", "=", "batch_action_info", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser.__init__": [[94, 164], ["allennlp_semparse.models.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser.__init__", "allennlp_semparse.state_machines.trainers.ExpectedRiskMinimization", "allennlp_semparse.state_machines.transition_functions.LinkingCoverageTransitionFunction", "allennlp.training.metrics.Average", "allennlp_semparse.state_machines.BeamSearch", "os.path.isfile", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._encoder.get_output_dim", "allennlp.models.archival.load_archive", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._initialize_weights_from_archive", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._initialize_weights_from_archive"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "question_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "entity_encoder", ":", "Seq2VecEncoder", ",", "\n", "attention", ":", "Attention", ",", "\n", "decoder_beam_size", ":", "int", ",", "\n", "decoder_num_finished_states", ":", "int", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "mixture_feedforward", ":", "FeedForward", "=", "None", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "normalize_beam_score_by_length", ":", "bool", "=", "False", ",", "\n", "checklist_cost_weight", ":", "float", "=", "0.6", ",", "\n", "use_neighbor_similarity_for_linking", ":", "bool", "=", "False", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "num_linking_features", ":", "int", "=", "10", ",", "\n", "rule_namespace", ":", "str", "=", "\"rule_labels\"", ",", "\n", "mml_model_file", ":", "str", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "use_similarity", "=", "use_neighbor_similarity_for_linking", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "vocab", "=", "vocab", ",", "\n", "question_embedder", "=", "question_embedder", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "encoder", "=", "encoder", ",", "\n", "entity_encoder", "=", "entity_encoder", ",", "\n", "max_decoding_steps", "=", "max_decoding_steps", ",", "\n", "add_action_bias", "=", "add_action_bias", ",", "\n", "use_neighbor_similarity_for_linking", "=", "use_similarity", ",", "\n", "dropout", "=", "dropout", ",", "\n", "num_linking_features", "=", "num_linking_features", ",", "\n", "rule_namespace", "=", "rule_namespace", ",", "\n", ")", "\n", "# Not sure why mypy needs a type annotation for this!", "\n", "self", ".", "_decoder_trainer", ":", "ExpectedRiskMinimization", "=", "ExpectedRiskMinimization", "(", "\n", "beam_size", "=", "decoder_beam_size", ",", "\n", "normalize_by_length", "=", "normalize_beam_score_by_length", ",", "\n", "max_decoding_steps", "=", "self", ".", "_max_decoding_steps", ",", "\n", "max_num_finished_states", "=", "decoder_num_finished_states", ",", "\n", ")", "\n", "self", ".", "_decoder_step", "=", "LinkingCoverageTransitionFunction", "(", "\n", "encoder_output_dim", "=", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "attention", ",", "\n", "add_action_bias", "=", "self", ".", "_add_action_bias", ",", "\n", "mixture_feedforward", "=", "mixture_feedforward", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "_checklist_cost_weight", "=", "checklist_cost_weight", "\n", "self", ".", "_agenda_coverage", "=", "Average", "(", ")", "\n", "# We don't need a separate beam search since the trainer does that already. But we're defining one just to", "\n", "# be able to use interactive beam search (a functionality that's only implemented in the ``BeamSearch``", "\n", "# class) in the demo. We'll use this only at test time.", "\n", "self", ".", "_beam_search", ":", "BeamSearch", "=", "BeamSearch", "(", "beam_size", "=", "decoder_beam_size", ")", "\n", "# TODO (pradeep): Checking whether file exists here to avoid raising an error when we've", "\n", "# copied a trained ERM model from a different machine and the original MML model that was", "\n", "# used to initialize it does not exist on the current machine. This may not be the best", "\n", "# solution for the problem.", "\n", "if", "mml_model_file", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "mml_model_file", ")", ":", "\n", "                ", "archive", "=", "load_archive", "(", "mml_model_file", ")", "\n", "self", ".", "_initialize_weights_from_archive", "(", "archive", ")", "\n", "", "else", ":", "\n", "# A model file is passed, but it does not exist. This is expected to happen when", "\n", "# you're using a trained ERM model to decode. But it may also happen if the path to", "\n", "# the file is really just incorrect. So throwing a warning.", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"MML model file for initializing weights is passed, but does not exist.\"", "\n", "\" This is fine if you're just decoding.\"", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._initialize_weights_from_archive": [[167, 202], ["logger.info", "dict", "dict", "dict.items", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser.named_parameters", "archive.model.named_parameters", "RuntimeError", "logger.info", "model_parameters[].data.copy_", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._get_vocab_index_mapping", "model_parameters[].data.clone", "logger.info", "len", "model_parameters[].data.clone.size"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_vocab_index_mapping"], ["", "", "", "def", "_initialize_weights_from_archive", "(", "self", ",", "archive", ":", "Archive", ")", "->", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Initializing weights from MML model.\"", ")", "\n", "model_parameters", "=", "dict", "(", "self", ".", "named_parameters", "(", ")", ")", "\n", "archived_parameters", "=", "dict", "(", "archive", ".", "model", ".", "named_parameters", "(", ")", ")", "\n", "question_embedder_weight", "=", "\"_question_embedder.token_embedder_tokens.weight\"", "\n", "if", "(", "\n", "question_embedder_weight", "not", "in", "archived_parameters", "\n", "or", "question_embedder_weight", "not", "in", "model_parameters", "\n", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"When initializing model weights from an MML model, we need \"", "\n", "\"the question embedder to be a TokenEmbedder using namespace called \"", "\n", "\"tokens.\"", "\n", ")", "\n", "", "for", "name", ",", "weights", "in", "archived_parameters", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "in", "model_parameters", ":", "\n", "                ", "if", "name", "==", "question_embedder_weight", ":", "\n", "# The shapes of embedding weights will most likely differ between the two models", "\n", "# because the vocabularies will most likely be different. We will get a mapping", "\n", "# of indices from this model's token indices to the archived model's and copy", "\n", "# the tensor accordingly.", "\n", "                    ", "vocab_index_mapping", "=", "self", ".", "_get_vocab_index_mapping", "(", "archive", ".", "model", ".", "vocab", ")", "\n", "archived_embedding_weights", "=", "weights", ".", "data", "\n", "new_weights", "=", "model_parameters", "[", "name", "]", ".", "data", ".", "clone", "(", ")", "\n", "for", "index", ",", "archived_index", "in", "vocab_index_mapping", ":", "\n", "                        ", "new_weights", "[", "index", "]", "=", "archived_embedding_weights", "[", "archived_index", "]", "\n", "", "logger", ".", "info", "(", "\n", "\"Copied embeddings of %d out of %d tokens\"", ",", "\n", "len", "(", "vocab_index_mapping", ")", ",", "\n", "new_weights", ".", "size", "(", ")", "[", "0", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "new_weights", "=", "weights", ".", "data", "\n", "", "logger", ".", "info", "(", "\"Copying parameter %s\"", ",", "name", ")", "\n", "model_parameters", "[", "name", "]", ".", "data", ".", "copy_", "(", "new_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._get_vocab_index_mapping": [[203, 218], ["range", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser.vocab.get_vocab_size", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser.vocab.get_token_from_index", "archived_vocab.get_token_index", "archived_vocab.get_token_from_index", "vocab_index_mapping.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "", "def", "_get_vocab_index_mapping", "(", "self", ",", "archived_vocab", ":", "Vocabulary", ")", "->", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ":", "\n", "        ", "vocab_index_mapping", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "\"tokens\"", ")", ")", ":", "\n", "            ", "token", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "index", "=", "index", ",", "namespace", "=", "\"tokens\"", ")", "\n", "archived_token_index", "=", "archived_vocab", ".", "get_token_index", "(", "token", ",", "namespace", "=", "\"tokens\"", ")", "\n", "# Checking if we got the UNK token index, because we don't want all new token", "\n", "# representations initialized to UNK token's representation. We do that by checking if", "\n", "# the two tokens are the same. They will not be if the token at the archived index is", "\n", "# UNK.", "\n", "if", "(", "\n", "archived_vocab", ".", "get_token_from_index", "(", "archived_token_index", ",", "namespace", "=", "\"tokens\"", ")", "\n", "==", "token", "\n", ")", ":", "\n", "                ", "vocab_index_mapping", ".", "append", "(", "(", "index", ",", "archived_token_index", ")", ")", "\n", "", "", "return", "vocab_index_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser.forward": [[219, 350], ["max", "zip", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._get_initial_rnn_and_grammar_state", "len", "rnn_state[].hidden_state.new_zeros", "allennlp_semparse.state_machines.states.CoverageState", "set", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._get_checklist_info", "checklist_target.new_zeros", "checklist_states.append", "logger.warning", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._decoder_trainer.decode", "outputs.update", "len", "enumerate", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._beam_search.search", "range", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._compute_validation_outputs", "instance_world.terminal_productions.values", "len", "checklist_target.size", "allennlp_semparse.state_machines.states.ChecklistStatelet", "range", "list", "functools.partial", "enumerate", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._agenda_coverage", "range", "range", "actions_[].cpu", "range", "int", "agenda_actions.append", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_initial_rnn_and_grammar_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_checklist_info", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._compute_validation_outputs", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum"], ["", "@", "overrides", "\n", "def", "forward", "(", "\n", "self", ",", "# type: ignore", "\n", "question", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "table", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "world", ":", "List", "[", "WikiTablesLanguage", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "agenda", ":", "torch", ".", "LongTensor", ",", "\n", "target_values", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        question : Dict[str, torch.LongTensor]\n           The output of ``TextField.as_array()`` applied on the question ``TextField``. This will\n           be passed through a ``TextFieldEmbedder`` and then through an encoder.\n        table : ``Dict[str, torch.LongTensor]``\n            The output of ``KnowledgeGraphField.as_array()`` applied on the table\n            ``KnowledgeGraphField``.  This output is similar to a ``TextField`` output, where each\n            entity in the table is treated as a \"token\", and we will use a ``TextFieldEmbedder`` to\n            get embeddings for each entity.\n        world : ``List[WikiTablesLanguage]``\n            We use a ``MetadataField`` to get the ``WikiTablesLanguage`` object for each input instance.\n            Because of how ``MetadataField`` works, this gets passed to us as a ``List[WikiTablesLanguage]``,\n        actions : ``List[List[ProductionRule]]``\n            A list of all possible actions for each ``world`` in the batch, indexed into a\n            ``ProductionRule`` using a ``ProductionRuleField``.  We will embed all of these\n            and use the embeddings to determine which action to take at each timestep in the\n            decoder.\n        agenda : ``torch.LongTensor``\n            Agenda vectors that the checklist vectors will be compared against to compute the checklist\n            cost.\n        target_values : ``List[List[str]]``, optional (default = None)\n            For each instance, a list of target values taken from the example lisp string. We pass\n            this list to the evaluator along with logical forms to compute denotation accuracy.\n        metadata : ``List[Dict[str, Any]]``, optional (default = None)\n            Metadata containing the original tokenized question within a 'question_tokens' field.\n        \"\"\"", "\n", "# Each instance's agenda is of size (agenda_size, 1)", "\n", "agenda_list", "=", "[", "a", "for", "a", "in", "agenda", "]", "\n", "checklist_states", "=", "[", "]", "\n", "all_terminal_productions", "=", "[", "\n", "set", "(", "instance_world", ".", "terminal_productions", ".", "values", "(", ")", ")", "for", "instance_world", "in", "world", "\n", "]", "\n", "max_num_terminals", "=", "max", "(", "[", "len", "(", "terminals", ")", "for", "terminals", "in", "all_terminal_productions", "]", ")", "\n", "for", "instance_actions", ",", "instance_agenda", ",", "terminal_productions", "in", "zip", "(", "\n", "actions", ",", "agenda_list", ",", "all_terminal_productions", "\n", ")", ":", "\n", "            ", "checklist_info", "=", "self", ".", "_get_checklist_info", "(", "\n", "instance_agenda", ",", "instance_actions", ",", "terminal_productions", ",", "max_num_terminals", "\n", ")", "\n", "checklist_target", ",", "terminal_actions", ",", "checklist_mask", "=", "checklist_info", "\n", "initial_checklist", "=", "checklist_target", ".", "new_zeros", "(", "checklist_target", ".", "size", "(", ")", ")", "\n", "checklist_states", ".", "append", "(", "\n", "ChecklistStatelet", "(", "\n", "terminal_actions", "=", "terminal_actions", ",", "\n", "checklist_target", "=", "checklist_target", ",", "\n", "checklist_mask", "=", "checklist_mask", ",", "\n", "checklist", "=", "initial_checklist", ",", "\n", ")", "\n", ")", "\n", "", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "rnn_state", ",", "grammar_state", "=", "self", ".", "_get_initial_rnn_and_grammar_state", "(", "\n", "question", ",", "table", ",", "world", ",", "actions", ",", "outputs", "\n", ")", "\n", "\n", "batch_size", "=", "len", "(", "rnn_state", ")", "\n", "initial_score", "=", "rnn_state", "[", "0", "]", ".", "hidden_state", ".", "new_zeros", "(", "batch_size", ")", "\n", "initial_score_list", "=", "[", "initial_score", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_state", "=", "CoverageState", "(", "\n", "batch_indices", "=", "list", "(", "range", "(", "batch_size", ")", ")", ",", "# type: ignore", "\n", "action_history", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "\n", "score", "=", "initial_score_list", ",", "\n", "rnn_state", "=", "rnn_state", ",", "\n", "grammar_state", "=", "grammar_state", ",", "\n", "checklist_state", "=", "checklist_states", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "extras", "=", "target_values", ",", "\n", "debug_info", "=", "None", ",", "\n", ")", "\n", "\n", "if", "target_values", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"TARGET VALUES: {target_values}\"", ")", "\n", "trainer_outputs", "=", "self", ".", "_decoder_trainer", ".", "decode", "(", "# type: ignore", "\n", "initial_state", ",", "self", ".", "_decoder_step", ",", "partial", "(", "self", ".", "_get_state_cost", ",", "world", ")", "\n", ")", "\n", "outputs", ".", "update", "(", "trainer_outputs", ")", "\n", "", "else", ":", "\n", "            ", "initial_state", ".", "debug_info", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "batch_size", "=", "len", "(", "actions", ")", "\n", "agenda_indices", "=", "[", "actions_", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "data", "for", "actions_", "in", "agenda", "]", "\n", "action_mapping", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_actions", "in", "enumerate", "(", "actions", ")", ":", "\n", "                ", "for", "action_index", ",", "action", "in", "enumerate", "(", "batch_actions", ")", ":", "\n", "                    ", "action_mapping", "[", "(", "batch_index", ",", "action_index", ")", "]", "=", "action", "[", "0", "]", "\n", "", "", "best_final_states", "=", "self", ".", "_beam_search", ".", "search", "(", "\n", "self", ".", "_max_decoding_steps", ",", "\n", "initial_state", ",", "\n", "self", ".", "_decoder_step", ",", "\n", "keep_final_unfinished_states", "=", "False", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "in_agenda_ratio", "=", "0.0", "\n", "# Decoding may not have terminated with any completed logical forms, if `num_steps`", "\n", "# isn't long enough (or if the model is not trained enough and gets into an", "\n", "# infinite action loop).", "\n", "if", "i", "in", "best_final_states", ":", "\n", "                    ", "action_sequence", "=", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "\n", "action_strings", "=", "[", "\n", "action_mapping", "[", "(", "i", ",", "action_index", ")", "]", "for", "action_index", "in", "action_sequence", "\n", "]", "\n", "instance_possible_actions", "=", "actions", "[", "i", "]", "\n", "agenda_actions", "=", "[", "]", "\n", "for", "rule_id", "in", "agenda_indices", "[", "i", "]", ":", "\n", "                        ", "rule_id", "=", "int", "(", "rule_id", ")", "\n", "if", "rule_id", "==", "-", "1", ":", "\n", "                            ", "continue", "\n", "", "action_string", "=", "instance_possible_actions", "[", "rule_id", "]", "[", "0", "]", "\n", "agenda_actions", ".", "append", "(", "action_string", ")", "\n", "", "actions_in_agenda", "=", "[", "action", "in", "action_strings", "for", "action", "in", "agenda_actions", "]", "\n", "if", "actions_in_agenda", ":", "\n", "# Note: This means that when there are no actions on agenda, agenda coverage", "\n", "# will be 0, not 1.", "\n", "                        ", "in_agenda_ratio", "=", "sum", "(", "actions_in_agenda", ")", "/", "len", "(", "actions_in_agenda", ")", "\n", "", "", "self", ".", "_agenda_coverage", "(", "in_agenda_ratio", ")", "\n", "\n", "", "self", ".", "_compute_validation_outputs", "(", "\n", "actions", ",", "best_final_states", ",", "world", ",", "target_values", ",", "metadata", ",", "outputs", "\n", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._get_checklist_info": [[351, 400], ["enumerate", "agenda.new_tensor", "agenda.new_tensor", "int", "len", "target_checklist_list.append", "terminal_indices.append", "agenda.squeeze().detach().cpu().numpy", "terminal_indices.append", "target_checklist_list.append", "target_checklist_list.append", "agenda.squeeze().detach().cpu", "agenda.squeeze().detach", "agenda.squeeze"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_get_checklist_info", "(", "\n", "agenda", ":", "torch", ".", "LongTensor", ",", "\n", "all_actions", ":", "List", "[", "ProductionRule", "]", ",", "\n", "terminal_productions", ":", "Set", "[", "str", "]", ",", "\n", "max_num_terminals", ":", "int", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Takes an agenda, a list of all actions, a set of terminal productions in the corresponding\n        world, and a length to pad the checklist vectors to, and returns a target checklist against\n        which the checklist at each state will be compared to compute a loss, indices of\n        ``terminal_actions``, and a ``checklist_mask`` that indicates which of the terminal actions\n        are relevant for checklist loss computation.\n\n        Parameters\n        ----------\n        ``agenda`` : ``torch.LongTensor``\n            Agenda of one instance of size ``(agenda_size, 1)``.\n        ``all_actions`` : ``List[ProductionRule]``\n            All actions for one instance.\n        ``terminal_productions`` : ``Set[str]``\n            String representations of terminal productions in the corresponding world.\n        ``max_num_terminals`` : ``int``\n            Length to which the checklist vectors will be padded till. This is the max number of\n            terminal productions in all the worlds in the batch.\n        \"\"\"", "\n", "terminal_indices", "=", "[", "]", "\n", "target_checklist_list", "=", "[", "]", "\n", "agenda_indices_set", "=", "{", "int", "(", "x", ")", "for", "x", "in", "agenda", ".", "squeeze", "(", "0", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "}", "\n", "# We want to return checklist target and terminal actions that are column vectors to make", "\n", "# computing softmax over the difference between checklist and target easier.", "\n", "for", "index", ",", "action", "in", "enumerate", "(", "all_actions", ")", ":", "\n", "# Each action is a ProductionRule, a tuple where the first item is the production", "\n", "# rule string.", "\n", "            ", "if", "action", "[", "0", "]", "in", "terminal_productions", ":", "\n", "                ", "terminal_indices", ".", "append", "(", "[", "index", "]", ")", "\n", "if", "index", "in", "agenda_indices_set", ":", "\n", "                    ", "target_checklist_list", ".", "append", "(", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "target_checklist_list", ".", "append", "(", "[", "0", "]", ")", "\n", "", "", "", "while", "len", "(", "target_checklist_list", ")", "<", "max_num_terminals", ":", "\n", "            ", "target_checklist_list", ".", "append", "(", "[", "0", "]", ")", "\n", "terminal_indices", ".", "append", "(", "[", "-", "1", "]", ")", "\n", "# (max_num_terminals, 1)", "\n", "", "terminal_actions", "=", "agenda", ".", "new_tensor", "(", "terminal_indices", ")", "\n", "# (max_num_terminals, 1)", "\n", "target_checklist", "=", "agenda", ".", "new_tensor", "(", "target_checklist_list", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "checklist_mask", "=", "(", "target_checklist", "!=", "0", ")", ".", "float", "(", ")", "\n", "return", "target_checklist", ",", "terminal_actions", ",", "checklist_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._get_state_cost": [[401, 433], ["torch.clamp", "torch.sum", "torch.sum", "logging.getLogger", "logging.getLogger.setLevel", "world.evaluate_action_sequence", "state.is_finished", "RuntimeError", "state.checklist_state[].get_balance", "state.checklist_state[].checklist_target.float"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.get_balance"], ["", "def", "_get_state_cost", "(", "\n", "self", ",", "worlds", ":", "List", "[", "WikiTablesLanguage", "]", ",", "state", ":", "CoverageState", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "not", "state", ".", "is_finished", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"_get_state_cost() is not defined for unfinished states!\"", ")", "\n", "", "world", "=", "worlds", "[", "state", ".", "batch_indices", "[", "0", "]", "]", "\n", "\n", "# Our checklist cost is a sum of squared error from where we want to be, making sure we", "\n", "# take into account the mask. We clamp the lower limit of the balance at 0 to avoid", "\n", "# penalizing agenda actions produced multiple times.", "\n", "checklist_balance", "=", "torch", ".", "clamp", "(", "state", ".", "checklist_state", "[", "0", "]", ".", "get_balance", "(", ")", ",", "min", "=", "0.0", ")", "\n", "checklist_cost", "=", "torch", ".", "sum", "(", "(", "checklist_balance", ")", "**", "2", ")", "\n", "\n", "# This is the number of items on the agenda that we want to see in the decoded sequence.", "\n", "# We use this as the denotation cost if the path is incorrect.", "\n", "denotation_cost", "=", "torch", ".", "sum", "(", "state", ".", "checklist_state", "[", "0", "]", ".", "checklist_target", ".", "float", "(", ")", ")", "\n", "checklist_cost", "=", "self", ".", "_checklist_cost_weight", "*", "checklist_cost", "\n", "action_history", "=", "state", ".", "action_history", "[", "0", "]", "\n", "batch_index", "=", "state", ".", "batch_indices", "[", "0", "]", "\n", "action_strings", "=", "[", "state", ".", "possible_actions", "[", "batch_index", "]", "[", "i", "]", "[", "0", "]", "for", "i", "in", "action_history", "]", "\n", "target_values", "=", "state", ".", "extras", "[", "batch_index", "]", "\n", "evaluation", "=", "False", "\n", "executor_logger", "=", "logging", ".", "getLogger", "(", "\n", "\"allennlp_semparse.domain_languages.wikitables_language\"", "\n", ")", "\n", "executor_logger", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "evaluation", "=", "world", ".", "evaluate_action_sequence", "(", "action_strings", ",", "target_values", ")", "\n", "if", "evaluation", ":", "\n", "            ", "cost", "=", "checklist_cost", "\n", "", "else", ":", "\n", "            ", "cost", "=", "checklist_cost", "+", "(", "1", "-", "self", ".", "_checklist_cost_weight", ")", "*", "denotation_cost", "\n", "", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser.WikiTablesErmSemanticParser.get_metrics": [[434, 443], ["super().get_metrics", "wikitables_erm_semantic_parser.WikiTablesErmSemanticParser._agenda_coverage.get_metric"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.get_metrics"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        The base class returns a dict with dpd accuracy, denotation accuracy, and logical form\n        percentage metrics. We add the agenda coverage metric here.\n        \"\"\"", "\n", "metrics", "=", "super", "(", ")", ".", "get_metrics", "(", "reset", ")", "\n", "metrics", "[", "\"agenda_coverage\"", "]", "=", "self", ".", "_agenda_coverage", ".", "get_metric", "(", "reset", ")", "\n", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser.__init__": [[88, 129], ["allennlp_semparse.models.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser.__init__", "allennlp_semparse.state_machines.trainers.MaximumMarginalLikelihood", "allennlp_semparse.state_machines.transition_functions.LinkingTransitionFunction", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._encoder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "question_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "entity_encoder", ":", "Seq2VecEncoder", ",", "\n", "decoder_beam_search", ":", "BeamSearch", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "attention", ":", "Attention", ",", "\n", "mixture_feedforward", ":", "FeedForward", "=", "None", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "training_beam_size", ":", "int", "=", "None", ",", "\n", "use_neighbor_similarity_for_linking", ":", "bool", "=", "False", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "num_linking_features", ":", "int", "=", "10", ",", "\n", "rule_namespace", ":", "str", "=", "\"rule_labels\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "use_similarity", "=", "use_neighbor_similarity_for_linking", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "vocab", "=", "vocab", ",", "\n", "question_embedder", "=", "question_embedder", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "encoder", "=", "encoder", ",", "\n", "entity_encoder", "=", "entity_encoder", ",", "\n", "max_decoding_steps", "=", "max_decoding_steps", ",", "\n", "add_action_bias", "=", "add_action_bias", ",", "\n", "use_neighbor_similarity_for_linking", "=", "use_similarity", ",", "\n", "dropout", "=", "dropout", ",", "\n", "num_linking_features", "=", "num_linking_features", ",", "\n", "rule_namespace", "=", "rule_namespace", ",", "\n", ")", "\n", "self", ".", "_beam_search", "=", "decoder_beam_search", "\n", "self", ".", "_decoder_trainer", "=", "MaximumMarginalLikelihood", "(", "training_beam_size", ")", "\n", "self", ".", "_decoder_step", "=", "LinkingTransitionFunction", "(", "\n", "encoder_output_dim", "=", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "attention", ",", "\n", "add_action_bias", "=", "self", ".", "_add_action_bias", ",", "\n", "mixture_feedforward", "=", "mixture_feedforward", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser.forward": [[131, 236], ["wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._get_initial_rnn_and_grammar_state", "len", "rnn_state[].hidden_state.new_zeros", "allennlp_semparse.state_machines.states.GrammarBasedState", "target_action_sequences.squeeze.squeeze.squeeze", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._decoder_trainer.decode", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._beam_search.search", "range", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._compute_validation_outputs", "range", "list", "range", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._decoder_trainer.decode", "range", "range", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._action_history_match", "wikitables_mml_semantic_parser.WikiTablesMmlSemanticParser._action_sequence_accuracy"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_initial_rnn_and_grammar_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._compute_validation_outputs", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._action_history_match"], ["", "@", "overrides", "\n", "def", "forward", "(", "\n", "self", ",", "# type: ignore", "\n", "question", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "table", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "world", ":", "List", "[", "WikiTablesLanguage", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRuleArray", "]", "]", ",", "\n", "target_values", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "target_action_sequences", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        In this method we encode the table entities, link them to words in the question, then\n        encode the question. Then we set up the initial state for the decoder, and pass that\n        state off to either a DecoderTrainer, if we're training, or a BeamSearch for inference,\n        if we're not.\n\n        Parameters\n        ----------\n        question : Dict[str, torch.LongTensor]\n           The output of ``TextField.as_array()`` applied on the question ``TextField``. This will\n           be passed through a ``TextFieldEmbedder`` and then through an encoder.\n        table : ``Dict[str, torch.LongTensor]``\n            The output of ``KnowledgeGraphField.as_array()`` applied on the table\n            ``KnowledgeGraphField``.  This output is similar to a ``TextField`` output, where each\n            entity in the table is treated as a \"token\", and we will use a ``TextFieldEmbedder`` to\n            get embeddings for each entity.\n        world : ``List[WikiTablesLanguage]``\n            We use a ``MetadataField`` to get the ``WikiTablesLanguage`` object for each input instance.\n            Because of how ``MetadataField`` works, this gets passed to us as a ``List[WikiTablesLanguage]``,\n        actions : ``List[List[ProductionRuleArray]]``\n            A list of all possible actions for each ``world`` in the batch, indexed into a\n            ``ProductionRuleArray`` using a ``ProductionRuleField``.  We will embed all of these\n            and use the embeddings to determine which action to take at each timestep in the\n            decoder.\n        target_values : ``List[List[str]]``, optional (default = None)\n            For each instance, a list of target values taken from the example lisp string. We pass\n            this list to the evaluator along with logical forms to compute denotation accuracy.\n        target_action_sequences : torch.Tensor, optional (default = None)\n           A list of possibly valid action sequences, where each action is an index into the list\n           of possible actions.  This tensor has shape ``(batch_size, num_action_sequences,\n           sequence_length)``.\n        metadata : ``List[Dict[str, Any]]``, optional (default = None)\n            Metadata containing the original tokenized question within a 'question_tokens' field.\n        \"\"\"", "\n", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "rnn_state", ",", "grammar_state", "=", "self", ".", "_get_initial_rnn_and_grammar_state", "(", "\n", "question", ",", "table", ",", "world", ",", "actions", ",", "outputs", "\n", ")", "\n", "batch_size", "=", "len", "(", "rnn_state", ")", "\n", "initial_score", "=", "rnn_state", "[", "0", "]", ".", "hidden_state", ".", "new_zeros", "(", "batch_size", ")", "\n", "initial_score_list", "=", "[", "initial_score", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_state", "=", "GrammarBasedState", "(", "\n", "batch_indices", "=", "list", "(", "range", "(", "batch_size", ")", ")", ",", "# type: ignore", "\n", "action_history", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "\n", "score", "=", "initial_score_list", ",", "\n", "rnn_state", "=", "rnn_state", ",", "\n", "grammar_state", "=", "grammar_state", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "extras", "=", "target_values", ",", "\n", "debug_info", "=", "None", ",", "\n", ")", "\n", "\n", "if", "target_action_sequences", "is", "not", "None", ":", "\n", "# Remove the trailing dimension (from ListField[ListField[IndexField]]).", "\n", "            ", "target_action_sequences", "=", "target_action_sequences", ".", "squeeze", "(", "-", "1", ")", "\n", "target_mask", "=", "target_action_sequences", "!=", "self", ".", "_action_padding_index", "\n", "", "else", ":", "\n", "            ", "target_mask", "=", "None", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_decoder_trainer", ".", "decode", "(", "\n", "initial_state", ",", "self", ".", "_decoder_step", ",", "(", "target_action_sequences", ",", "target_mask", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "target_action_sequences", "is", "not", "None", ":", "\n", "                ", "outputs", "[", "\"loss\"", "]", "=", "self", ".", "_decoder_trainer", ".", "decode", "(", "\n", "initial_state", ",", "self", ".", "_decoder_step", ",", "(", "target_action_sequences", ",", "target_mask", ")", "\n", ")", "[", "\"loss\"", "]", "\n", "", "num_steps", "=", "self", ".", "_max_decoding_steps", "\n", "# This tells the state to start keeping track of debug info, which we'll pass along in", "\n", "# our output dictionary.", "\n", "initial_state", ".", "debug_info", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "best_final_states", "=", "self", ".", "_beam_search", ".", "search", "(", "\n", "num_steps", ",", "initial_state", ",", "self", ".", "_decoder_step", ",", "keep_final_unfinished_states", "=", "False", "\n", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# Decoding may not have terminated with any completed logical forms, if `num_steps`", "\n", "# isn't long enough (or if the model is not trained enough and gets into an", "\n", "# infinite action loop).", "\n", "                ", "if", "i", "in", "best_final_states", ":", "\n", "                    ", "best_action_indices", "=", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "\n", "if", "target_action_sequences", "is", "not", "None", ":", "\n", "# Use a Tensor, not a Variable, to avoid a memory leak.", "\n", "                        ", "targets", "=", "target_action_sequences", "[", "i", "]", ".", "data", "\n", "sequence_in_targets", "=", "0", "\n", "sequence_in_targets", "=", "self", ".", "_action_history_match", "(", "\n", "best_action_indices", ",", "targets", "\n", ")", "\n", "self", ".", "_action_sequence_accuracy", "(", "sequence_in_targets", ")", "\n", "\n", "", "", "", "self", ".", "_compute_validation_outputs", "(", "\n", "actions", ",", "best_final_states", ",", "world", ",", "target_values", ",", "metadata", ",", "outputs", "\n", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.Value.match": [[95, 105], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "match", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"Return True if the value matches the other value.\n\n        Args:\n            other (Value)\n        Returns:\n            a boolean\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.Value.normalized": [[106, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "normalized", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.StringValue.__init__": [[112, 115], ["wikitables_evaluator.normalize", "hash"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.normalize"], ["    ", "def", "__init__", "(", "self", ",", "content", ")", ":", "\n", "        ", "self", ".", "_normalized", "=", "normalize", "(", "content", ")", "\n", "self", ".", "_hash", "=", "hash", "(", "self", ".", "_normalized", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.StringValue.__eq__": [[116, 118], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "isinstance", "(", "other", ",", "StringValue", ")", "and", "self", ".", "normalized", "==", "other", ".", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.StringValue.__hash__": [[119, 121], ["None"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_hash", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.StringValue.__str__": [[122, 124], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"S\"", "+", "str", "(", "[", "self", ".", "normalized", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.StringValue.match": [[127, 130], ["isinstance"], "methods", ["None"], ["def", "match", "(", "self", ",", "other", ")", ":", "\n", "        ", "assert", "isinstance", "(", "other", ",", "Value", ")", "\n", "return", "self", ".", "normalized", "==", "other", ".", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.__init__": [[133, 144], ["isinstance", "hash", "abs", "int", "float", "str", "wikitables_evaluator.normalize", "round"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.normalize"], ["    ", "def", "__init__", "(", "self", ",", "amount", ",", "original_string", "=", "None", ")", ":", "\n", "        ", "assert", "isinstance", "(", "amount", ",", "(", "int", ",", "float", ")", ")", "\n", "if", "abs", "(", "amount", "-", "round", "(", "amount", ")", ")", "<", "1e-6", ":", "\n", "            ", "self", ".", "_amount", "=", "int", "(", "amount", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_amount", "=", "float", "(", "amount", ")", "\n", "", "if", "not", "original_string", ":", "\n", "            ", "self", ".", "_normalized", "=", "str", "(", "self", ".", "_amount", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_normalized", "=", "normalize", "(", "original_string", ")", "\n", "", "self", ".", "_hash", "=", "hash", "(", "self", ".", "_amount", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.amount": [[145, 148], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "amount", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_amount", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.__eq__": [[149, 151], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "isinstance", "(", "other", ",", "NumberValue", ")", "and", "self", ".", "amount", "==", "other", ".", "amount", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.__hash__": [[152, 154], ["None"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_hash", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.__str__": [[155, 157], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\"N(%f)\"", "%", "self", ".", "amount", ")", "+", "str", "(", "[", "self", ".", "normalized", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.match": [[160, 167], ["isinstance", "isinstance", "abs"], "methods", ["None"], ["def", "match", "(", "self", ",", "other", ")", ":", "\n", "        ", "assert", "isinstance", "(", "other", ",", "Value", ")", "\n", "if", "self", ".", "normalized", "==", "other", ".", "normalized", ":", "\n", "            ", "return", "True", "\n", "", "if", "isinstance", "(", "other", ",", "NumberValue", ")", ":", "\n", "            ", "return", "abs", "(", "self", ".", "amount", "-", "other", ".", "amount", ")", "<", "1e-6", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.NumberValue.parse": [[168, 184], ["int", "float", "math.isnan", "math.isinf"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "parse", "(", "text", ")", ":", "\n", "        ", "\"\"\"Try to parse into a number.\n\n        Return:\n            the number (int or float) if successful; otherwise None.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "return", "int", "(", "text", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "try", ":", "\n", "                ", "amount", "=", "float", "(", "text", ")", "\n", "assert", "not", "isnan", "(", "amount", ")", "and", "not", "isinf", "(", "amount", ")", "\n", "return", "amount", "\n", "", "except", "(", "ValueError", ",", "AssertionError", ")", ":", "\n", "                ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.__init__": [[187, 205], ["isinstance", "hash", "isinstance", "isinstance", "wikitables_evaluator.normalize"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.normalize"], ["    ", "def", "__init__", "(", "self", ",", "year", ",", "month", ",", "day", ",", "original_string", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"", "\n", "assert", "isinstance", "(", "year", ",", "int", ")", "\n", "assert", "isinstance", "(", "month", ",", "int", ")", "and", "(", "month", "==", "-", "1", "or", "1", "<=", "month", "<=", "12", ")", "\n", "assert", "isinstance", "(", "day", ",", "int", ")", "and", "(", "day", "==", "-", "1", "or", "1", "<=", "day", "<=", "31", ")", "\n", "assert", "not", "year", "==", "month", "==", "day", "==", "-", "1", "\n", "self", ".", "_year", "=", "year", "\n", "self", ".", "_month", "=", "month", "\n", "self", ".", "_day", "=", "day", "\n", "if", "not", "original_string", ":", "\n", "            ", "self", ".", "_normalized", "=", "\"{}-{}-{}\"", ".", "format", "(", "\n", "year", "if", "year", "!=", "-", "1", "else", "\"xx\"", ",", "\n", "month", "if", "month", "!=", "-", "1", "else", "\"xx\"", ",", "\n", "day", "if", "day", "!=", "\"-1\"", "else", "\"xx\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_normalized", "=", "normalize", "(", "original_string", ")", "\n", "", "self", ".", "_hash", "=", "hash", "(", "(", "self", ".", "_year", ",", "self", ".", "_month", ",", "self", ".", "_day", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.ymd": [[206, 209], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "ymd", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "_year", ",", "self", ".", "_month", ",", "self", ".", "_day", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.__eq__": [[210, 212], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "isinstance", "(", "other", ",", "DateValue", ")", "and", "self", ".", "ymd", "==", "other", ".", "ymd", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.__hash__": [[213, 215], ["None"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_hash", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.__str__": [[216, 218], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\"D(%d,%d,%d)\"", "%", "(", "self", ".", "_year", ",", "self", ".", "_month", ",", "self", ".", "_day", ")", ")", "+", "str", "(", "[", "self", ".", "_normalized", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.match": [[221, 228], ["isinstance", "isinstance"], "methods", ["None"], ["def", "match", "(", "self", ",", "other", ")", ":", "\n", "        ", "assert", "isinstance", "(", "other", ",", "Value", ")", "\n", "if", "self", ".", "normalized", "==", "other", ".", "normalized", ":", "\n", "            ", "return", "True", "\n", "", "if", "isinstance", "(", "other", ",", "DateValue", ")", ":", "\n", "            ", "return", "self", ".", "ymd", "==", "other", ".", "ymd", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse": [[229, 248], ["text.lower().split", "len", "int", "int", "int", "text.lower"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "parse", "(", "text", ")", ":", "\n", "        ", "\"\"\"Try to parse into a date.\n\n        Return:\n            tuple (year, month, date) if successful; otherwise None.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "ymd", "=", "text", ".", "lower", "(", ")", ".", "split", "(", "\"-\"", ")", "\n", "assert", "len", "(", "ymd", ")", "==", "3", "\n", "year", "=", "-", "1", "if", "ymd", "[", "0", "]", "in", "(", "\"xx\"", ",", "\"xxxx\"", ")", "else", "int", "(", "ymd", "[", "0", "]", ")", "\n", "month", "=", "-", "1", "if", "ymd", "[", "1", "]", "==", "\"xx\"", "else", "int", "(", "ymd", "[", "1", "]", ")", "\n", "day", "=", "-", "1", "if", "ymd", "[", "2", "]", "==", "\"xx\"", "else", "int", "(", "ymd", "[", "2", "]", ")", "\n", "assert", "not", "year", "==", "month", "==", "day", "==", "-", "1", "\n", "assert", "month", "==", "-", "1", "or", "1", "<=", "month", "<=", "12", "\n", "assert", "day", "==", "-", "1", "or", "1", "<=", "day", "<=", "31", "\n", "return", "(", "year", ",", "month", ",", "day", ")", "\n", "", "except", "(", "ValueError", ",", "AssertionError", ")", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.normalize": [[61, 84], ["re.sub", "re.sub", "re.sub", "re.sub().lower().strip", "re.sub", "re.sub", "re.sub", "re.sub.strip", "re.sub.strip", "re.sub.strip", "re.sub().lower", "unicodedata.normalize", "unicodedata.category", "re.sub"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.normalize"], ["def", "normalize", "(", "x", ")", ":", "\n", "# Remove diacritics", "\n", "    ", "x", "=", "\"\"", ".", "join", "(", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "\"NFKD\"", ",", "x", ")", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "\"Mn\"", ")", "\n", "# Normalize quotes and dashes", "\n", "x", "=", "re", ".", "sub", "(", "r\"[\u2018\u2019\u00b4`]\"", ",", "\"'\"", ",", "x", ")", "\n", "x", "=", "re", ".", "sub", "(", "r\"[\u201c\u201d]\"", ",", "'\"'", ",", "x", ")", "\n", "x", "=", "re", ".", "sub", "(", "r\"[\u2010\u2011\u2012\u2013\u2014\u2212]\"", ",", "\"-\"", ",", "x", ")", "\n", "while", "True", ":", "\n", "        ", "old_x", "=", "x", "\n", "# Remove citations", "\n", "x", "=", "re", ".", "sub", "(", "r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[\u2022\u2666\u2020\u2021*#+])*$\"", ",", "\"\"", ",", "x", ".", "strip", "(", ")", ")", "\n", "# Remove details in parenthesis", "\n", "x", "=", "re", ".", "sub", "(", "r\"(?<!^)( \\([^)]*\\))*$\"", ",", "\"\"", ",", "x", ".", "strip", "(", ")", ")", "\n", "# Remove outermost quotation mark", "\n", "x", "=", "re", ".", "sub", "(", "r'^\"([^\"]*)\"$'", ",", "r\"\\1\"", ",", "x", ".", "strip", "(", ")", ")", "\n", "if", "x", "==", "old_x", ":", "\n", "            ", "break", "\n", "# Remove final '.'", "\n", "", "", "if", "x", "and", "x", "[", "-", "1", "]", "==", "\".\"", ":", "\n", "        ", "x", "=", "x", "[", ":", "-", "1", "]", "\n", "# Collapse whitespaces and convert to lower case", "\n", "", "x", "=", "re", ".", "sub", "(", "r\"\\s+\"", ",", "\" \"", ",", "x", ",", "flags", "=", "re", ".", "U", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value": [[253, 280], ["isinstance", "wikitables_evaluator.NumberValue.parse", "wikitables_evaluator.DateValue.parse", "wikitables_evaluator.StringValue", "wikitables_evaluator.NumberValue", "wikitables_evaluator.NumberValue", "wikitables_evaluator.DateValue"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse"], ["", "", "", "def", "to_value", "(", "original_string", ",", "corenlp_value", "=", "None", ")", ":", "\n", "    ", "\"\"\"Convert the string to Value object.\n\n    Args:\n        original_string (basestring): Original string\n        corenlp_value (basestring): Optional value returned from CoreNLP\n    Returns:\n        Value\n    \"\"\"", "\n", "if", "isinstance", "(", "original_string", ",", "Value", ")", ":", "\n", "# Already a Value", "\n", "        ", "return", "original_string", "\n", "", "if", "not", "corenlp_value", ":", "\n", "        ", "corenlp_value", "=", "original_string", "\n", "# Number?", "\n", "", "amount", "=", "NumberValue", ".", "parse", "(", "corenlp_value", ")", "\n", "if", "amount", "is", "not", "None", ":", "\n", "        ", "return", "NumberValue", "(", "amount", ",", "original_string", ")", "\n", "# Date?", "\n", "", "ymd", "=", "DateValue", ".", "parse", "(", "corenlp_value", ")", "\n", "if", "ymd", "is", "not", "None", ":", "\n", "        ", "if", "ymd", "[", "1", "]", "==", "ymd", "[", "2", "]", "==", "-", "1", ":", "\n", "            ", "return", "NumberValue", "(", "ymd", "[", "0", "]", ",", "original_string", ")", "\n", "", "else", ":", "\n", "            ", "return", "DateValue", "(", "ymd", "[", "0", "]", ",", "ymd", "[", "1", "]", ",", "ymd", "[", "2", "]", ",", "original_string", ")", "\n", "# String.", "\n", "", "", "return", "StringValue", "(", "original_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value_list": [[282, 298], ["isinstance", "isinstance", "list", "list", "len", "len", "set", "set", "wikitables_evaluator.to_value", "wikitables_evaluator.to_value", "zip"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value"], ["", "def", "to_value_list", "(", "original_strings", ",", "corenlp_values", "=", "None", ")", ":", "\n", "    ", "\"\"\"Convert a list of strings to a list of Values\n\n    Args:\n        original_strings (list[basestring])\n        corenlp_values (list[basestring or None])\n    Returns:\n        list[Value]\n    \"\"\"", "\n", "assert", "isinstance", "(", "original_strings", ",", "(", "list", ",", "tuple", ",", "set", ")", ")", "\n", "if", "corenlp_values", "is", "not", "None", ":", "\n", "        ", "assert", "isinstance", "(", "corenlp_values", ",", "(", "list", ",", "tuple", ",", "set", ")", ")", "\n", "assert", "len", "(", "original_strings", ")", "==", "len", "(", "corenlp_values", ")", "\n", "return", "list", "(", "set", "(", "to_value", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "zip", "(", "original_strings", ",", "corenlp_values", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "list", "(", "set", "(", "to_value", "(", "x", ")", "for", "x", "in", "original_strings", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.check_denotation": [[303, 320], ["len", "len", "any", "target.match"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.match"], ["", "", "def", "check_denotation", "(", "target_values", ",", "predicted_values", ")", ":", "\n", "    ", "\"\"\"Return True if the predicted denotation is correct.\n\n    Args:\n        target_values (list[Value])\n        predicted_values (list[Value])\n    Returns:\n        bool\n    \"\"\"", "\n", "# Check size", "\n", "if", "len", "(", "target_values", ")", "!=", "len", "(", "predicted_values", ")", ":", "\n", "        ", "return", "False", "\n", "# Check items", "\n", "", "for", "target", "in", "target_values", ":", "\n", "        ", "if", "not", "any", "(", "target", ".", "match", "(", "pred", ")", "for", "pred", "in", "predicted_values", ")", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.tsv_unescape": [[325, 342], ["x.replace().replace().replace", "x.replace().replace", "x.replace"], "function", ["None"], ["", "def", "tsv_unescape", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Unescape strings in the TSV file.\n    Escaped characters include:\n    - newline (0x10) -> backslash + n\n    - vertical bar (0x7C) -> backslash + p\n    - backslash (0x5C) -> backslash + backslash\n\n    Parameters\n    ----------\n    x : ``str``\n\n    Returns\n    -------\n    ``str``\n    \"\"\"", "\n", "return", "x", ".", "replace", "(", "r\"\\n\"", ",", "\"\\n\"", ")", ".", "replace", "(", "r\"\\p\"", ",", "\"|\"", ")", ".", "replace", "(", "\"\\\\\\\\\"", ",", "\"\\\\\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.tsv_unescape_list": [[344, 354], ["wikitables_evaluator.tsv_unescape", "x.split"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.tsv_unescape"], ["", "def", "tsv_unescape_list", "(", "x", ")", ":", "\n", "    ", "\"\"\"Unescape a list in the TSV file.\n    List items are joined with vertical bars (0x5C)\n\n    Args:\n        x (str or unicode)\n    Returns:\n        a list of unicodes\n    \"\"\"", "\n", "return", "[", "tsv_unescape", "(", "y", ")", "for", "y", "in", "x", ".", "split", "(", "\"|\"", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.main": [[356, 405], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.listdir", "print", "print", "print", "print", "print", "os.path.join", "print", "len", "codecs.open", "round", "os.path.join", "codecs.open", "fin.readline().rstrip().split", "line.rstrip().split.rstrip().split", "dict", "wikitables_evaluator.tsv_unescape_list", "wikitables_evaluator.tsv_unescape_list", "wikitables_evaluator.to_value_list", "print", "wikitables_evaluator.to_value_list", "wikitables_evaluator.check_denotation", "print", "fin.readline().rstrip", "zip", "line.rstrip().split.rstrip", "line.rstrip().split.rstrip().split", "fin.readline", "line.rstrip().split.rstrip"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.scripts.get_version.parse_args", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.tsv_unescape_list", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.tsv_unescape_list", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value_list", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value_list", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.check_denotation"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-t\"", ",", "\n", "\"--tagged-dataset-path\"", ",", "\n", "default", "=", "os", ".", "path", ".", "join", "(", "\".\"", ",", "\"tagged\"", ",", "\"data\"", ")", ",", "\n", "help", "=", "\"Directory containing CoreNLP-tagged dataset TSV file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"prediction_path\"", ",", "\n", "help", "=", "\"Path to the prediction file. Each line contains \"", "\n", "\"ex_id <tab> item1 <tab> item2 <tab> ...\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# ID string --> list[Value]", "\n", "target_values_map", "=", "{", "}", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "args", ".", "tagged_dataset_path", ")", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "tagged_dataset_path", ",", "filename", ")", "\n", "print", "(", "\"Reading dataset from\"", ",", "filename", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "with", "codecs_open", "(", "filename", ",", "\"r\"", ",", "\"utf8\"", ")", "as", "fin", ":", "\n", "            ", "header", "=", "fin", ".", "readline", "(", ")", ".", "rstrip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "for", "line", "in", "fin", ":", "\n", "                ", "stuff", "=", "dict", "(", "zip", "(", "header", ",", "line", ".", "rstrip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", ")", ")", "\n", "ex_id", "=", "stuff", "[", "\"id\"", "]", "\n", "original_strings", "=", "tsv_unescape_list", "(", "stuff", "[", "\"targetValue\"", "]", ")", "\n", "canon_strings", "=", "tsv_unescape_list", "(", "stuff", "[", "\"targetCanon\"", "]", ")", "\n", "target_values_map", "[", "ex_id", "]", "=", "to_value_list", "(", "original_strings", ",", "canon_strings", ")", "\n", "", "", "", "print", "(", "\"Read\"", ",", "len", "(", "target_values_map", ")", ",", "\"examples\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "print", "(", "\"Reading predictions from\"", ",", "args", ".", "prediction_path", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "num_examples", ",", "num_correct", "=", "0", ",", "0", "\n", "with", "codecs_open", "(", "args", ".", "prediction_path", ",", "\"r\"", ",", "\"utf8\"", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "ex_id", "=", "line", "[", "0", "]", "\n", "if", "ex_id", "not", "in", "target_values_map", ":", "\n", "                ", "print", "(", "'WARNING: Example ID \"%s\" not found'", "%", "ex_id", ")", "\n", "", "else", ":", "\n", "                ", "target_values", "=", "target_values_map", "[", "ex_id", "]", "\n", "predicted_values", "=", "to_value_list", "(", "line", "[", "1", ":", "]", ")", "\n", "correct", "=", "check_denotation", "(", "target_values", ",", "predicted_values", ")", "\n", "print", "(", "u\"%s\\t%s\\t%s\\t%s\"", "%", "(", "ex_id", ",", "correct", ",", "target_values", ",", "predicted_values", ")", ")", "\n", "num_examples", "+=", "1", "\n", "if", "correct", ":", "\n", "                    ", "num_correct", "+=", "1", "\n", "", "", "", "", "print", "(", "\"Examples:\"", ",", "num_examples", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "\"Correct:\"", ",", "num_correct", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "\"Accuracy:\"", ",", "round", "(", "(", "num_correct", "+", "1e-9", ")", "/", "(", "num_examples", "+", "1e-9", ")", ",", "4", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.__init__": [[185, 208], ["set", "column_name_type_mapping.values", "collections.defaultdict", "dict", "table_question_context.TableQuestionContext.column_types.update", "table_row.items", "string_column_mapping[].append", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["def", "__init__", "(", "\n", "self", ",", "\n", "table_data", ":", "List", "[", "Dict", "[", "str", ",", "CellValueType", "]", "]", ",", "\n", "column_name_type_mapping", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", ",", "\n", "column_names", ":", "Set", "[", "str", "]", ",", "\n", "question_tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "table_data", "=", "table_data", "\n", "self", ".", "column_types", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "self", ".", "column_names", "=", "column_names", "\n", "for", "types", "in", "column_name_type_mapping", ".", "values", "(", ")", ":", "\n", "            ", "self", ".", "column_types", ".", "update", "(", "types", ")", "\n", "", "self", ".", "question_tokens", "=", "question_tokens", "\n", "# Mapping from strings to the columns they are under.", "\n", "string_column_mapping", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "table_row", "in", "table_data", ":", "\n", "            ", "for", "column_name", ",", "cell_value", "in", "table_row", ".", "items", "(", ")", ":", "\n", "                ", "if", "\"string_column:\"", "in", "column_name", "and", "cell_value", "is", "not", "None", ":", "\n", "                    ", "string_column_mapping", "[", "str", "(", "cell_value", ")", "]", ".", "append", "(", "column_name", ")", "\n", "# We want the object to raise KeyError when checking if a specific string is a cell in the", "\n", "# table.", "\n", "", "", "", "self", ".", "_string_column_mapping", "=", "dict", "(", "string_column_mapping", ")", "\n", "self", ".", "_table_knowledge_graph", ":", "KnowledgeGraph", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.__eq__": [[209, 213], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "TableQuestionContext", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "table_data", "==", "other", ".", "table_data", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_knowledge_graph": [[214, 264], ["set", "collections.defaultdict", "table_question_context.TableQuestionContext.get_entities_from_question", "neighbors.items", "allennlp_semparse.common.knowledge_graph.KnowledgeGraph", "entities.add", "[].replace", "entities.add", "entity.replace().replace", "entities.add", "neighbors[].extend", "list", "entities.add", "dict", "number_columns.append", "date_columns.append", "neighbors[].append", "neighbors[].append", "neighbors[].append", "set", "neighbors[].append", "entity.replace", "typed_column_name.split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_table_knowledge_graph", "(", "self", ")", "->", "KnowledgeGraph", ":", "\n", "        ", "if", "self", ".", "_table_knowledge_graph", "is", "None", ":", "\n", "            ", "entities", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "neighbors", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "entity_text", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "# Add all column names to entities. We'll define their neighbors to be empty lists for", "\n", "# now, and later add number and string entities as needed.", "\n", "number_columns", "=", "[", "]", "\n", "date_columns", "=", "[", "]", "\n", "for", "typed_column_name", "in", "self", ".", "column_names", ":", "\n", "                ", "if", "\"number_column:\"", "in", "typed_column_name", "or", "\"num2_column\"", "in", "typed_column_name", ":", "\n", "                    ", "number_columns", ".", "append", "(", "typed_column_name", ")", "\n", "\n", "", "if", "\"date_column:\"", "in", "typed_column_name", ":", "\n", "                    ", "date_columns", ".", "append", "(", "typed_column_name", ")", "\n", "\n", "# Add column names to entities, with no neighbors yet.", "\n", "", "entities", ".", "add", "(", "typed_column_name", ")", "\n", "neighbors", "[", "typed_column_name", "]", "=", "[", "]", "\n", "entity_text", "[", "typed_column_name", "]", "=", "typed_column_name", ".", "split", "(", "\":\"", ",", "1", ")", "[", "-", "1", "]", ".", "replace", "(", "\n", "\"_\"", ",", "\" \"", "\n", ")", "\n", "\n", "", "string_entities", ",", "numbers", "=", "self", ".", "get_entities_from_question", "(", ")", "\n", "for", "entity", ",", "column_names", "in", "string_entities", ":", "\n", "                ", "entities", ".", "add", "(", "entity", ")", "\n", "for", "column_name", "in", "column_names", ":", "\n", "                    ", "neighbors", "[", "entity", "]", ".", "append", "(", "column_name", ")", "\n", "neighbors", "[", "column_name", "]", ".", "append", "(", "entity", ")", "\n", "", "entity_text", "[", "entity", "]", "=", "entity", ".", "replace", "(", "\"string:\"", ",", "\"\"", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "\n", "# For all numbers (except -1), we add all number and date columns as their neighbors.", "\n", "", "for", "number", ",", "_", "in", "numbers", ":", "\n", "                ", "entities", ".", "add", "(", "number", ")", "\n", "neighbors", "[", "number", "]", ".", "extend", "(", "number_columns", "+", "date_columns", ")", "\n", "for", "column_name", "in", "number_columns", "+", "date_columns", ":", "\n", "                    ", "neighbors", "[", "column_name", "]", ".", "append", "(", "number", ")", "\n", "", "entity_text", "[", "number", "]", "=", "number", "\n", "", "for", "entity", ",", "entity_neighbors", "in", "neighbors", ".", "items", "(", ")", ":", "\n", "                ", "neighbors", "[", "entity", "]", "=", "list", "(", "set", "(", "entity_neighbors", ")", ")", "\n", "\n", "# Add \"-1\" as an entity only if we have date columns in the table because we will need", "\n", "# it as a wild-card in dates. The neighbors are the date columns.", "\n", "", "if", "\"-1\"", "not", "in", "neighbors", "and", "date_columns", ":", "\n", "                ", "entities", ".", "add", "(", "\"-1\"", ")", "\n", "neighbors", "[", "\"-1\"", "]", "=", "date_columns", "\n", "entity_text", "[", "\"-1\"", "]", "=", "\"-1\"", "\n", "for", "date_column", "in", "date_columns", ":", "\n", "                    ", "neighbors", "[", "date_column", "]", ".", "append", "(", "\"-1\"", ")", "\n", "", "", "self", ".", "_table_knowledge_graph", "=", "KnowledgeGraph", "(", "entities", ",", "dict", "(", "neighbors", ")", ",", "entity_text", ")", "\n", "", "return", "self", ".", "_table_knowledge_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_data_from_tagged_lines": [[265, 313], ["collections.defaultdict", "int", "column_name_sempre.replace", "int", "int", "dict", "table_data.append", "zip", "column_name_type_mapping[].add", "column_name_type_mapping[].add", "column_name_type_mapping[].add", "column_name_type_mapping[].add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "@", "classmethod", "\n", "def", "get_table_data_from_tagged_lines", "(", "\n", "cls", ",", "lines", ":", "List", "[", "List", "[", "str", "]", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "]", ",", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "]", ":", "\n", "        ", "column_index_to_name", "=", "{", "}", "\n", "header", "=", "lines", "[", "0", "]", "# the first line is the header (\"row\\tcol\\t...\")", "\n", "index", "=", "1", "\n", "table_data", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "]", "=", "[", "]", "\n", "while", "lines", "[", "index", "]", "[", "0", "]", "==", "\"-1\"", ":", "\n", "# column names start with fb:row.row.", "\n", "            ", "current_line", "=", "lines", "[", "index", "]", "\n", "column_name_sempre", "=", "current_line", "[", "2", "]", "\n", "column_index", "=", "int", "(", "current_line", "[", "1", "]", ")", "\n", "column_name", "=", "column_name_sempre", ".", "replace", "(", "\"fb:row.row.\"", ",", "\"\"", ")", "\n", "column_index_to_name", "[", "column_index", "]", "=", "column_name", "\n", "index", "+=", "1", "\n", "", "column_name_type_mapping", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "last_row_index", "=", "-", "1", "\n", "for", "current_line", "in", "lines", "[", "1", ":", "]", ":", "\n", "            ", "row_index", "=", "int", "(", "current_line", "[", "0", "]", ")", "\n", "if", "row_index", "==", "-", "1", ":", "\n", "                ", "continue", "# header row", "\n", "", "column_index", "=", "int", "(", "current_line", "[", "1", "]", ")", "\n", "if", "row_index", "!=", "last_row_index", ":", "\n", "                ", "table_data", ".", "append", "(", "{", "}", ")", "\n", "", "node_info", "=", "dict", "(", "zip", "(", "header", ",", "current_line", ")", ")", "\n", "cell_data", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "column_name", "=", "column_index_to_name", "[", "column_index", "]", "\n", "if", "node_info", "[", "\"date\"", "]", ":", "\n", "                ", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"date\"", ")", "\n", "cell_data", "[", "\"date\"", "]", "=", "node_info", "[", "\"date\"", "]", "\n", "\n", "", "if", "node_info", "[", "\"number\"", "]", ":", "\n", "                ", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"number\"", ")", "\n", "cell_data", "[", "\"number\"", "]", "=", "node_info", "[", "\"number\"", "]", "\n", "\n", "", "if", "node_info", "[", "\"num2\"", "]", ":", "\n", "                ", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"num2\"", ")", "\n", "cell_data", "[", "\"num2\"", "]", "=", "node_info", "[", "\"num2\"", "]", "\n", "\n", "", "if", "node_info", "[", "\"content\"", "]", "!=", "\"\u2014\"", ":", "\n", "                ", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"string\"", ")", "\n", "cell_data", "[", "\"string\"", "]", "=", "node_info", "[", "\"content\"", "]", "\n", "\n", "", "table_data", "[", "-", "1", "]", "[", "column_name", "]", "=", "cell_data", "\n", "last_row_index", "=", "row_index", "\n", "\n", "", "return", "table_data", ",", "column_name_type_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_data_from_untagged_lines": [[314, 375], ["enumerate", "collections.defaultdict", "cls.normalize_string", "table_data.append", "enumerate", "column_name_type_mapping[].add", "str", "float", "column_name_type_mapping[].add", "cell_value.split", "allennlp_semparse.common.Date.make_date", "column_name_type_mapping[].add", "len", "float", "float", "column_name_type_mapping[].add", "column_name_type_mapping[].add", "cell_value.split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.normalize_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.make_date", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "@", "classmethod", "\n", "def", "get_table_data_from_untagged_lines", "(", "\n", "cls", ",", "lines", ":", "List", "[", "List", "[", "str", "]", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "]", ",", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        This method will be called only when we do not have tagged information from CoreNLP. That is, when we are\n        running the parser on data outside the WikiTableQuestions dataset. We try to do the same processing that\n        CoreNLP does for WTQ, but what we do here may not be as effective.\n        \"\"\"", "\n", "table_data", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "]", "=", "[", "]", "\n", "column_index_to_name", "=", "{", "}", "\n", "column_names", "=", "lines", "[", "0", "]", "\n", "for", "column_index", ",", "column_name", "in", "enumerate", "(", "column_names", ")", ":", "\n", "            ", "normalized_name", "=", "cls", ".", "normalize_string", "(", "column_name", ")", "\n", "column_index_to_name", "[", "column_index", "]", "=", "normalized_name", "\n", "\n", "", "column_name_type_mapping", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "for", "row", "in", "lines", "[", "1", ":", "]", ":", "\n", "            ", "table_data", ".", "append", "(", "{", "}", ")", "\n", "for", "column_index", ",", "cell_value", "in", "enumerate", "(", "row", ")", ":", "\n", "                ", "column_name", "=", "column_index_to_name", "[", "column_index", "]", "\n", "cell_data", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "\n", "# Interpret the content as a date.", "\n", "try", ":", "\n", "                    ", "potential_date_string", "=", "str", "(", "Date", ".", "make_date", "(", "cell_value", ")", ")", "\n", "if", "potential_date_string", "!=", "\"-1\"", ":", "\n", "# This means the string is a really a date.", "\n", "                        ", "cell_data", "[", "\"date\"", "]", "=", "cell_value", "\n", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"date\"", ")", "\n", "", "", "except", "ValueError", ":", "\n", "                    ", "pass", "\n", "\n", "# Interpret the content as a number.", "\n", "", "try", ":", "\n", "                    ", "float", "(", "cell_value", ")", "\n", "cell_data", "[", "\"number\"", "]", "=", "cell_value", "\n", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"number\"", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "pass", "\n", "\n", "# Interpret the content as a range or a score to get number and num2 out.", "\n", "", "if", "\"-\"", "in", "cell_value", "and", "len", "(", "cell_value", ".", "split", "(", "\"-\"", ")", ")", "==", "2", ":", "\n", "# This could be a number range or a score", "\n", "                    ", "cell_parts", "=", "cell_value", ".", "split", "(", "\"-\"", ")", "\n", "try", ":", "\n", "                        ", "float", "(", "cell_parts", "[", "0", "]", ")", "\n", "float", "(", "cell_parts", "[", "1", "]", ")", "\n", "cell_data", "[", "\"number\"", "]", "=", "cell_parts", "[", "0", "]", "\n", "cell_data", "[", "\"num2\"", "]", "=", "cell_parts", "[", "1", "]", "\n", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"number\"", ")", "\n", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"num2\"", ")", "\n", "", "except", "ValueError", ":", "\n", "                        ", "pass", "\n", "\n", "# Interpret the content as a string.", "\n", "", "", "cell_data", "[", "\"string\"", "]", "=", "cell_value", "\n", "column_name_type_mapping", "[", "column_name", "]", ".", "add", "(", "\"string\"", ")", "\n", "table_data", "[", "-", "1", "]", "[", "column_name", "]", "=", "cell_data", "\n", "\n", "", "", "return", "table_data", ",", "column_name_type_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_lines": [[376, 430], ["set", "cls", "isinstance", "cls.get_table_data_from_tagged_lines", "cls.get_table_data_from_untagged_lines", "table_data_with_column_types.append", "table_row.items", "line.split", "all_column_names.add", "cell_data.get", "float", "allennlp_semparse.common.Date.make_date", "cls.normalize_string"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_data_from_tagged_lines", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_data_from_untagged_lines", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.make_date", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.normalize_string"], ["", "@", "classmethod", "\n", "def", "read_from_lines", "(", "cls", ",", "lines", ":", "List", ",", "question_tokens", ":", "List", "[", "Token", "]", ")", "->", "\"TableQuestionContext\"", ":", "\n", "\n", "        ", "header", "=", "lines", "[", "0", "]", "\n", "if", "isinstance", "(", "header", ",", "list", ")", "and", "header", "[", ":", "6", "]", "==", "[", "\n", "\"row\"", ",", "\n", "\"col\"", ",", "\n", "\"id\"", ",", "\n", "\"content\"", ",", "\n", "\"tokens\"", ",", "\n", "\"lemmaTokens\"", ",", "\n", "]", ":", "\n", "# These lines are from the tagged table file from the official dataset.", "\n", "            ", "table_data", ",", "column_name_type_mapping", "=", "cls", ".", "get_table_data_from_tagged_lines", "(", "lines", ")", "\n", "", "else", ":", "\n", "# We assume that the lines are just the table data, with rows being newline separated, and columns", "\n", "# being tab-separated.", "\n", "            ", "rows", "=", "[", "line", ".", "split", "(", "\"\\t\"", ")", "for", "line", "in", "lines", "]", "# type: ignore", "\n", "table_data", ",", "column_name_type_mapping", "=", "cls", ".", "get_table_data_from_untagged_lines", "(", "rows", ")", "\n", "# Each row is a mapping from column names to cell data. Cell data is a dict, where keys are", "\n", "# \"string\", \"number\", \"num2\" and \"date\", and the values are the corresponding values", "\n", "# extracted by CoreNLP.", "\n", "# Table data with each column split into different ones, depending on the types they have.", "\n", "", "table_data_with_column_types", ":", "List", "[", "Dict", "[", "str", ",", "CellValueType", "]", "]", "=", "[", "]", "\n", "all_column_names", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "for", "table_row", "in", "table_data", ":", "\n", "            ", "table_data_with_column_types", ".", "append", "(", "{", "}", ")", "\n", "for", "column_name", ",", "cell_data", "in", "table_row", ".", "items", "(", ")", ":", "\n", "                ", "for", "column_type", "in", "column_name_type_mapping", "[", "column_name", "]", ":", "\n", "                    ", "typed_column_name", "=", "f\"{column_type}_column:{column_name}\"", "\n", "all_column_names", ".", "add", "(", "typed_column_name", ")", "\n", "cell_value_string", "=", "cell_data", ".", "get", "(", "column_type", ",", "None", ")", "\n", "if", "column_type", "in", "[", "\"number\"", ",", "\"num2\"", "]", ":", "\n", "                        ", "try", ":", "\n", "                            ", "cell_number", "=", "float", "(", "cell_value_string", ")", "\n", "", "except", "(", "ValueError", ",", "TypeError", ")", ":", "\n", "                            ", "cell_number", "=", "None", "\n", "", "table_data_with_column_types", "[", "-", "1", "]", "[", "typed_column_name", "]", "=", "cell_number", "\n", "", "elif", "column_type", "==", "\"date\"", ":", "\n", "                        ", "cell_date", "=", "None", "\n", "if", "cell_value_string", "is", "not", "None", ":", "\n", "                            ", "cell_date", "=", "Date", ".", "make_date", "(", "cell_value_string", ")", "\n", "", "table_data_with_column_types", "[", "-", "1", "]", "[", "typed_column_name", "]", "=", "cell_date", "\n", "", "else", ":", "\n", "                        ", "if", "cell_value_string", "is", "None", ":", "\n", "                            ", "normalized_string", "=", "None", "\n", "", "else", ":", "\n", "                            ", "normalized_string", "=", "cls", ".", "normalize_string", "(", "cell_value_string", ")", "\n", "", "table_data_with_column_types", "[", "-", "1", "]", "[", "typed_column_name", "]", "=", "normalized_string", "\n", "", "", "", "", "return", "cls", "(", "\n", "table_data_with_column_types", ",", "\n", "column_name_type_mapping", ",", "\n", "all_column_names", ",", "\n", "question_tokens", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file": [[432, 438], ["open", "csv.reader", "cls.read_from_lines"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_lines"], ["", "@", "classmethod", "\n", "def", "read_from_file", "(", "cls", ",", "filename", ":", "str", ",", "question_tokens", ":", "List", "[", "Token", "]", ")", "->", "\"TableQuestionContext\"", ":", "\n", "        ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "file_pointer", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "file_pointer", ",", "delimiter", "=", "\"\\t\"", ",", "quoting", "=", "csv", ".", "QUOTE_NONE", ")", "\n", "lines", "=", "[", "line", "for", "line", "in", "reader", "]", "\n", "return", "cls", ".", "read_from_lines", "(", "lines", ",", "question_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question": [[439, 471], ["enumerate", "table_question_context.TableQuestionContext._get_numbers_from_tokens", "table_question_context.TableQuestionContext._expand_entities", "table_question_context.TableQuestionContext.normalize_string", "table_question_context.TableQuestionContext._string_in_table", "[].replace", "entity_data.append", "expanded_entities.append", "token_columns[].split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._get_numbers_from_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._expand_entities", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.normalize_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._string_in_table", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "def", "get_entities_from_question", "(", "self", ")", "->", "Tuple", "[", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", "]", ":", "\n", "        ", "entity_data", "=", "[", "]", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "self", ".", "question_tokens", ")", ":", "\n", "            ", "token_text", "=", "token", ".", "text", "\n", "if", "token_text", "in", "STOP_WORDS", ":", "\n", "                ", "continue", "\n", "", "normalized_token_text", "=", "self", ".", "normalize_string", "(", "token_text", ")", "\n", "if", "not", "normalized_token_text", ":", "\n", "                ", "continue", "\n", "", "token_columns", "=", "self", ".", "_string_in_table", "(", "normalized_token_text", ")", "\n", "if", "token_columns", ":", "\n", "# We need to keep track of the type of column this string occurs in. It is unlikely it occurs in", "\n", "# columns of multiple types. So we just keep track of the first column type. Hence, the", "\n", "# ``token_columns[0]``.", "\n", "                ", "token_type", "=", "token_columns", "[", "0", "]", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "replace", "(", "\"_column\"", ",", "\"\"", ")", "\n", "entity_data", ".", "append", "(", "\n", "{", "\n", "\"value\"", ":", "normalized_token_text", ",", "\n", "\"token_start\"", ":", "i", ",", "\n", "\"token_end\"", ":", "i", "+", "1", ",", "\n", "\"token_type\"", ":", "token_type", ",", "\n", "\"token_in_columns\"", ":", "token_columns", ",", "\n", "}", "\n", ")", "\n", "\n", "", "", "extracted_numbers", "=", "self", ".", "_get_numbers_from_tokens", "(", "self", ".", "question_tokens", ")", "\n", "# filter out number entities to avoid repetition", "\n", "expanded_entities", "=", "[", "]", "\n", "for", "entity", "in", "self", ".", "_expand_entities", "(", "self", ".", "question_tokens", ",", "entity_data", ")", ":", "\n", "            ", "if", "entity", "[", "\"token_type\"", "]", "==", "\"string\"", ":", "\n", "                ", "expanded_entities", ".", "append", "(", "(", "f\"string:{entity['value']}\"", ",", "entity", "[", "\"token_in_columns\"", "]", ")", ")", "\n", "", "", "return", "expanded_entities", ",", "extracted_numbers", "# TODO(shikhar) Handle conjunctions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._get_numbers_from_tokens": [[472, 532], ["enumerate", "token.text.replace().lower", "float", "tokens[].text.lower", "float", "numbers.append", "token.text.replace", "len", "len", "numbers.append", "enumerate", "str", "int"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "@", "staticmethod", "\n", "def", "_get_numbers_from_tokens", "(", "tokens", ":", "List", "[", "Token", "]", ")", "->", "List", "[", "Tuple", "[", "str", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Finds numbers in the input tokens and returns them as strings.  We do some simple heuristic\n        number recognition, finding ordinals and cardinals expressed as text (\"one\", \"first\",\n        etc.), as well as numerals (\"7th\", \"3rd\"), months (mapping \"july\" to 7), and units\n        (\"1ghz\").\n\n        We also handle year ranges expressed as decade or centuries (\"1800s\" or \"1950s\"), adding\n        the endpoints of the range as possible numbers to generate.\n\n        We return a list of tuples, where each tuple is the (number_string, token_index) for a\n        number found in the input tokens.\n        \"\"\"", "\n", "numbers", "=", "[", "]", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "token_text", "=", "token", ".", "text", "\n", "text", "=", "token", ".", "text", ".", "replace", "(", "\",\"", ",", "\"\"", ")", ".", "lower", "(", ")", "\n", "number", "=", "float", "(", "NUMBER_WORDS", "[", "text", "]", ")", "if", "text", "in", "NUMBER_WORDS", "else", "None", "\n", "\n", "magnitude", "=", "1", "\n", "if", "i", "<", "len", "(", "tokens", ")", "-", "1", ":", "\n", "                ", "next_token", "=", "tokens", "[", "i", "+", "1", "]", ".", "text", ".", "lower", "(", ")", "\n", "if", "next_token", "in", "ORDER_OF_MAGNITUDE_WORDS", ":", "\n", "                    ", "magnitude", "=", "ORDER_OF_MAGNITUDE_WORDS", "[", "next_token", "]", "\n", "token_text", "+=", "\" \"", "+", "tokens", "[", "i", "+", "1", "]", ".", "text", "\n", "\n", "", "", "is_range", "=", "False", "\n", "if", "len", "(", "text", ")", ">", "1", "and", "text", "[", "-", "1", "]", "==", "\"s\"", "and", "text", "[", "-", "2", "]", "==", "\"0\"", ":", "\n", "                ", "is_range", "=", "True", "\n", "text", "=", "text", "[", ":", "-", "1", "]", "\n", "\n", "# We strip out any non-digit characters, to capture things like '7th', or '1ghz'.  The", "\n", "# way we're doing this could lead to false positives for something like '1e2', but", "\n", "# we'll take that risk.  It shouldn't be a big deal.", "\n", "", "text", "=", "\"\"", ".", "join", "(", "text", "[", "i", "]", "for", "i", ",", "char", "in", "enumerate", "(", "text", ")", "if", "char", "in", "NUMBER_CHARACTERS", ")", "\n", "\n", "try", ":", "\n", "# We'll use a check for float(text) to find numbers, because text.isdigit() doesn't", "\n", "# catch things like \"-3\" or \"0.07\".", "\n", "                ", "number", "=", "float", "(", "text", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "pass", "\n", "\n", "", "if", "number", "is", "not", "None", ":", "\n", "                ", "number", "=", "number", "*", "magnitude", "\n", "if", "\".\"", "in", "text", ":", "\n", "                    ", "number_string", "=", "\"%.3f\"", "%", "number", "\n", "", "else", ":", "\n", "                    ", "number_string", "=", "\"%d\"", "%", "number", "\n", "", "numbers", ".", "append", "(", "(", "number_string", ",", "i", ")", ")", "\n", "if", "is_range", ":", "\n", "# TODO(mattg): both numbers in the range will have the same text, and so the", "\n", "# linking score won't have any way to differentiate them...  We should figure", "\n", "# out a better way to handle this.", "\n", "                    ", "num_zeros", "=", "1", "\n", "while", "text", "[", "-", "(", "num_zeros", "+", "1", ")", "]", "==", "\"0\"", ":", "\n", "                        ", "num_zeros", "+=", "1", "\n", "", "numbers", ".", "append", "(", "(", "str", "(", "int", "(", "number", "+", "10", "**", "num_zeros", ")", ")", ",", "i", ")", ")", "\n", "", "", "", "return", "numbers", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._string_in_table": [[533, 549], ["list", "table_question_context.TableQuestionContext._string_column_mapping.items", "set", "list.extend"], "methods", ["None"], ["", "def", "_string_in_table", "(", "self", ",", "candidate", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Checks if the string occurs in the table, and if it does, returns the names of the columns\n        under which it occurs. If it does not, returns an empty list.\n        \"\"\"", "\n", "candidate_column_names", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "# First check if the entire candidate occurs as a cell.", "\n", "if", "candidate", "in", "self", ".", "_string_column_mapping", ":", "\n", "            ", "candidate_column_names", "=", "self", ".", "_string_column_mapping", "[", "candidate", "]", "\n", "# If not, check if it is a substring pf any cell value.", "\n", "", "if", "not", "candidate_column_names", ":", "\n", "            ", "for", "cell_value", ",", "column_names", "in", "self", ".", "_string_column_mapping", ".", "items", "(", ")", ":", "\n", "                ", "if", "candidate", "in", "cell_value", ":", "\n", "                    ", "candidate_column_names", ".", "extend", "(", "column_names", ")", "\n", "", "", "", "candidate_column_names", "=", "list", "(", "set", "(", "candidate_column_names", ")", ")", "\n", "return", "candidate_column_names", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._process_conjunction": [[550, 552], ["None"], "methods", ["None"], ["", "def", "_process_conjunction", "(", "self", ",", "entity_data", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._expand_entities": [[553, 593], ["new_entities.append", "len", "table_question_context.TableQuestionContext.normalize_string", "table_question_context.TableQuestionContext._string_in_table", "list", "[].replace", "set().intersection", "set", "candidate_columns[].split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.normalize_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext._string_in_table"], ["", "def", "_expand_entities", "(", "self", ",", "question", ",", "entity_data", ")", ":", "\n", "        ", "new_entities", "=", "[", "]", "\n", "for", "entity", "in", "entity_data", ":", "\n", "# to ensure the same strings are not used over and over", "\n", "            ", "if", "new_entities", "and", "entity", "[", "\"token_end\"", "]", "<=", "new_entities", "[", "-", "1", "]", "[", "\"token_end\"", "]", ":", "\n", "                ", "continue", "\n", "", "current_start", "=", "entity", "[", "\"token_start\"", "]", "\n", "current_end", "=", "entity", "[", "\"token_end\"", "]", "\n", "current_token", "=", "entity", "[", "\"value\"", "]", "\n", "current_token_type", "=", "entity", "[", "\"token_type\"", "]", "\n", "current_token_columns", "=", "entity", "[", "\"token_in_columns\"", "]", "\n", "\n", "while", "current_end", "<", "len", "(", "question", ")", ":", "\n", "                ", "next_token", "=", "question", "[", "current_end", "]", ".", "text", "\n", "next_token_normalized", "=", "self", ".", "normalize_string", "(", "next_token", ")", "\n", "if", "next_token_normalized", "==", "\"\"", ":", "\n", "                    ", "current_end", "+=", "1", "\n", "continue", "\n", "", "candidate", "=", "\"%s_%s\"", "%", "(", "current_token", ",", "next_token_normalized", ")", "\n", "candidate_columns", "=", "self", ".", "_string_in_table", "(", "candidate", ")", "\n", "candidate_columns", "=", "list", "(", "set", "(", "candidate_columns", ")", ".", "intersection", "(", "current_token_columns", ")", ")", "\n", "if", "not", "candidate_columns", ":", "\n", "                    ", "break", "\n", "", "candidate_type", "=", "candidate_columns", "[", "0", "]", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "replace", "(", "\"_column\"", ",", "\"\"", ")", "\n", "if", "candidate_type", "!=", "current_token_type", ":", "\n", "                    ", "break", "\n", "", "current_end", "+=", "1", "\n", "current_token", "=", "candidate", "\n", "current_token_columns", "=", "candidate_columns", "\n", "\n", "", "new_entities", ".", "append", "(", "\n", "{", "\n", "\"token_start\"", ":", "current_start", ",", "\n", "\"token_end\"", ":", "current_end", ",", "\n", "\"value\"", ":", "current_token", ",", "\n", "\"token_type\"", ":", "current_token_type", ",", "\n", "\"token_in_columns\"", ":", "current_token_columns", ",", "\n", "}", "\n", ")", "\n", "", "return", "new_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.normalize_string": [[594, 633], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub().strip", "re.sub().strip", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub", "unidecode.unidecode.unidecode", "re.sub.lower", "re.sub", "re.sub"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "normalize_string", "(", "string", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        These are the transformation rules used to normalize cell in column names in Sempre.  See\n        ``edu.stanford.nlp.sempre.tables.StringNormalizationUtils.characterNormalize`` and\n        ``edu.stanford.nlp.sempre.tables.TableTypeSystem.canonicalizeName``.  We reproduce those\n        rules here to normalize and canonicalize cells and columns in the same way so that we can\n        match them against constants in logical forms appropriately.\n        \"\"\"", "\n", "# Normalization rules from Sempre", "\n", "# \\u201A -> ,", "\n", "string", "=", "re", ".", "sub", "(", "\"\u201a\"", ",", "\",\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\u201e\"", ",", "\",,\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"[\u00b7\u30fb]\"", ",", "\".\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\u2026\"", ",", "\"...\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\u02c6\"", ",", "\"^\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\u02dc\"", ",", "\"~\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\u2039\"", ",", "\"<\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\u203a\"", ",", "\">\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"[\u2018\u2019\u00b4`]\"", ",", "\"'\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"[\u201c\u201d\u00ab\u00bb]\"", ",", "'\"'", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"[\u2022\u2020\u2021\u00b2\u00b3]\"", ",", "\"\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"[\u2010\u2011\u2013\u2014\u2212]\"", ",", "\"-\"", ",", "string", ")", "\n", "# Oddly, some unicode characters get converted to _ instead of being stripped.  Not really", "\n", "# sure how sempre decides what to do with these...  TODO(mattg): can we just get rid of the", "\n", "# need for this function somehow?  It's causing a whole lot of headaches.", "\n", "string", "=", "re", ".", "sub", "(", "\"[\u00f0\u00f8\u2032\u2033\u20ac\u2044\u00aa\u03a3]\"", ",", "\"_\"", ",", "string", ")", "\n", "# This is such a mess.  There isn't just a block of unicode that we can strip out, because", "\n", "# sometimes sempre just strips diacritics...  We'll try stripping out a few separate", "\n", "# blocks, skipping the ones that sempre skips...", "\n", "string", "=", "re", ".", "sub", "(", "\"[\\\\u0180-\\\\u0210]\"", ",", "\"\"", ",", "string", ")", ".", "strip", "(", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"[\\\\u0220-\\\\uFFFF]\"", ",", "\"\"", ",", "string", ")", ".", "strip", "(", ")", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\n\"", ",", "\"_\"", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\\\\s+\"", ",", "\" \"", ",", "string", ")", "\n", "# Canonicalization rules from Sempre.", "\n", "string", "=", "re", ".", "sub", "(", "\"[^\\\\w]\"", ",", "\"_\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"_+\"", ",", "\"_\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"_$\"", ",", "\"\"", ",", "string", ")", "\n", "return", "unidecode", "(", "string", ".", "lower", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser_test.TestWikiTablesVariableFreeErm.setup_method": [[7, 12], ["super().setup_method", "wikitables_erm_semantic_parser_test.TestWikiTablesVariableFreeErm.set_up_model"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "config_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"wikitables\"", "/", "\"experiment-erm.json\"", "\n", "data_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"sample_data.examples\"", "\n", "self", ".", "set_up_model", "(", "config_path", ",", "data_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_erm_semantic_parser_test.TestWikiTablesVariableFreeErm.test_model_can_train_save_and_load": [[13, 21], ["wikitables_erm_semantic_parser_test.TestWikiTablesVariableFreeErm.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "@", "flaky", "\n", "def", "test_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "# We have very few embedded actions on our agenda, and so it's rare that this parameter", "\n", "# actually gets used.  We know this parameter works from our NLVR ERM test, so it's easier", "\n", "# to just ignore it here than to try to finagle the test to make it so this has a non-zero", "\n", "# gradient.", "\n", "        ", "ignore", "=", "{", "\"_decoder_step._checklist_multiplier\"", "}", "\n", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ",", "gradients_to_ignore", "=", "ignore", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.setup_method": [[11, 17], ["super().setup_method", "print", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.set_up_model"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "print", "(", "self", ".", "FIXTURES_ROOT", ")", "\n", "config_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"wikitables\"", "/", "\"experiment.json\"", "\n", "data_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"sample_data.examples\"", "\n", "self", ".", "set_up_model", "(", "config_path", ",", "data_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.test_model_can_train_save_and_load": [[18, 21], ["wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "@", "flaky", "\n", "def", "test_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.test_make_output_human_readable": [[22, 28], ["wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.dataset.as_tensor_dict", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.model", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.model.make_output_human_readable", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.dataset.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.make_output_human_readable", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths"], ["", "def", "test_make_output_human_readable", "(", "self", ")", ":", "\n", "        ", "model_batch", "=", "self", ".", "dataset", ".", "as_tensor_dict", "(", "self", ".", "dataset", ".", "get_padding_lengths", "(", ")", ")", "\n", "self", ".", "model", ".", "training", "=", "False", "\n", "forward_output", "=", "self", ".", "model", "(", "**", "model_batch", ")", "\n", "decode_output", "=", "self", ".", "model", ".", "make_output_human_readable", "(", "forward_output", ")", "\n", "assert", "\"predicted_actions\"", "in", "decode_output", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.test_get_neighbor_indices": [[29, 42], ["wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds", "torch.LongTensor", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.model._get_neighbor_indices", "numpy.testing.assert_almost_equal", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.data.numpy"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_neighbor_indices"], ["", "def", "test_get_neighbor_indices", "(", "self", ")", ":", "\n", "        ", "worlds", ",", "num_entities", "=", "self", ".", "get_fake_worlds", "(", ")", "\n", "tensor", "=", "torch", ".", "LongTensor", "(", "[", "]", ")", "\n", "\n", "neighbor_indices", "=", "self", ".", "model", ".", "_get_neighbor_indices", "(", "worlds", ",", "num_entities", ",", "tensor", ")", "\n", "\n", "# Checks for the correct shape meaning dimension 2 has size num_neighbors,", "\n", "# padding of -1 is used, and correct neighbor indices.", "\n", "assert_almost_equal", "(", "\n", "neighbor_indices", ".", "data", ".", "numpy", "(", ")", ",", "\n", "[", "\n", "[", "[", "-", "1", ",", "-", "1", "]", ",", "[", "4", ",", "-", "1", "]", ",", "[", "4", ",", "-", "1", "]", ",", "[", "5", ",", "-", "1", "]", ",", "[", "1", ",", "2", "]", ",", "[", "3", ",", "-", "1", "]", "]", ",", "\n", "[", "[", "-", "1", ",", "-", "1", "]", ",", "[", "2", ",", "-", "1", "]", ",", "[", "1", ",", "-", "1", "]", ",", "[", "-", "1", ",", "-", "1", "]", ",", "[", "-", "1", ",", "-", "1", "]", ",", "[", "-", "1", ",", "-", "1", "]", "]", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.test_get_type_vector": [[45, 51], ["wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds", "torch.LongTensor", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.model._get_type_vector", "numpy.testing.assert_almost_equal", "type_vector.data.numpy"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_type_vector"], ["", "def", "test_get_type_vector", "(", "self", ")", ":", "\n", "        ", "worlds", ",", "num_entities", "=", "self", ".", "get_fake_worlds", "(", ")", "\n", "tensor", "=", "torch", ".", "LongTensor", "(", "[", "]", ")", "\n", "type_vector", ",", "_", "=", "self", ".", "model", ".", "_get_type_vector", "(", "worlds", ",", "num_entities", ",", "tensor", ")", "\n", "# Verify that the appropriate types are present and padding used for non existent entities.", "\n", "assert_almost_equal", "(", "type_vector", ".", "data", ".", "numpy", "(", ")", ",", "[", "[", "0", ",", "0", ",", "0", ",", "3", ",", "1", ",", "4", "]", ",", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.test_get_linking_probabilities": [[52, 86], ["wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds", "torch.FloatTensor", "torch.LongTensor", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.model._get_type_vector", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.model._get_linking_probabilities", "numpy.testing.assert_almost_equal", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.detach().cpu().numpy", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.detach().cpu", "wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.detach"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_type_vector", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_semantic_parser.WikiTablesSemanticParser._get_linking_probabilities"], ["", "def", "test_get_linking_probabilities", "(", "self", ")", ":", "\n", "        ", "worlds", ",", "num_entities", "=", "self", ".", "get_fake_worlds", "(", ")", "\n", "# (batch_size, num_question_tokens, num_entities)", "\n", "linking_scores", "=", "[", "\n", "[", "[", "-", "2", ",", "1", ",", "0", ",", "-", "3", ",", "2", ",", "-", "2", "]", ",", "[", "4", ",", "-", "1", ",", "5", ",", "-", "3", ",", "4", ",", "3", "]", "]", ",", "\n", "[", "[", "0", ",", "1", ",", "8", ",", "10", ",", "10", ",", "4", "]", ",", "[", "3", ",", "2", ",", "-", "1", ",", "-", "2", ",", "1", ",", "-", "6", "]", "]", ",", "\n", "]", "\n", "linking_scores", "=", "torch", ".", "FloatTensor", "(", "linking_scores", ")", "\n", "question_mask", "=", "torch", ".", "LongTensor", "(", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "0", "]", "]", ")", "\n", "_", ",", "entity_type_dict", "=", "self", ".", "model", ".", "_get_type_vector", "(", "worlds", ",", "num_entities", ",", "linking_scores", ")", "\n", "\n", "# (batch_size, num_question_tokens, num_entities)", "\n", "entity_probability", "=", "self", ".", "model", ".", "_get_linking_probabilities", "(", "\n", "worlds", ",", "linking_scores", ",", "question_mask", ",", "entity_type_dict", "\n", ")", "\n", "\n", "# The following properties in entity_probability are tested for by true_probability:", "\n", "# (1) It has all 0.0 probabilities when there is no question token, as seen for the", "\n", "#     second word in the second batch.", "\n", "# (2) It has 0.0 probabilities when an entity is masked, as seen in the last three entities", "\n", "#     for the second batch instance.", "\n", "# (3) The probabilities for entities of the same type with the same question token should", "\n", "#     sum to at most 1, but not necessarily 1, because some probability mass goes to the", "\n", "#     null entity.  We have four entity types here, so each row should sum to at most 4,", "\n", "#     and that number will approach 4 as the unnormalized linking scores for each entity", "\n", "#     get higher.", "\n", "true_probability", "=", "[", "\n", "[", "\n", "[", "0.02788338", ",", "0.56005275", ",", "0.2060319", ",", "0.880797", ",", "0.04742587", ",", "0.11920291", "]", ",", "\n", "[", "0.26714143", ",", "0.00179998", ",", "0.7261657", ",", "0.98201376", ",", "0.04742587", ",", "0.95257413", "]", ",", "\n", "]", ",", "\n", "[", "[", "0.21194156", ",", "0.57611686", ",", "0.99966466", ",", "0.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "]", ",", "\n", "]", "\n", "assert_almost_equal", "(", "entity_probability", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "true_probability", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_mml_semantic_parser_test.TestWikiTablesMmlSemanticParser.get_fake_worlds": [[87, 113], ["collections.namedtuple", "collections.namedtuple", "max", "collections.namedtuple.", "collections.namedtuple.", "zip", "len"], "methods", ["None"], ["", "def", "get_fake_worlds", "(", "self", ")", ":", "\n", "# Generate a toy WikitablesWorld.", "\n", "        ", "FakeTable", "=", "namedtuple", "(", "\"FakeTable\"", ",", "[", "\"entities\"", ",", "\"neighbors\"", "]", ")", "\n", "FakeWorld", "=", "namedtuple", "(", "\"FakeWorld\"", ",", "[", "\"table_graph\"", "]", ")", "\n", "entities", "=", "[", "\n", "[", "\"-1\"", ",", "\"2010\"", ",", "\"2012\"", ",", "\"string:bmw\"", ",", "\"date_column:year\"", ",", "\"string_column:make\"", "]", ",", "\n", "[", "\"-1\"", ",", "\"2012\"", ",", "\"date_column:year\"", "]", ",", "\n", "]", "\n", "neighbors", "=", "[", "\n", "{", "\n", "\"2010\"", ":", "[", "\"date_column:year\"", "]", ",", "\n", "\"2012\"", ":", "[", "\"date_column:year\"", "]", ",", "\n", "\"string:bmw\"", ":", "[", "\"string_column:make\"", "]", ",", "\n", "\"date_column:year\"", ":", "[", "\"2010\"", ",", "\"2012\"", "]", ",", "\n", "\"string_column:make\"", ":", "[", "\"string:bmw\"", "]", ",", "\n", "\"-1\"", ":", "[", "]", ",", "\n", "}", ",", "\n", "{", "\"2012\"", ":", "[", "\"date_column:year\"", "]", ",", "\"date_column:year\"", ":", "[", "\"2012\"", "]", ",", "\"-1\"", ":", "[", "]", "}", ",", "\n", "]", "\n", "\n", "worlds", "=", "[", "\n", "FakeWorld", "(", "FakeTable", "(", "entity_list", ",", "entity2neighbors", ")", ")", "\n", "for", "entity_list", ",", "entity2neighbors", "in", "zip", "(", "entities", ",", "neighbors", ")", "\n", "]", "\n", "num_entities", "=", "max", "(", "[", "len", "(", "entity_list", ")", "for", "entity_list", "in", "entities", "]", ")", "\n", "return", "worlds", ",", "num_entities", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.setup_method": [[9, 12], ["super().setup_method", "allennlp.data.tokenizers.SpacyTokenizer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "tokenizer", "=", "SpacyTokenizer", "(", "pos_tags", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_table_data": [[13, 48], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "test_table_data", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"what was the attendance when usl a league played?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/wikitables/sample_table.tagged\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "assert", "table_question_context", ".", "table_data", "==", "[", "\n", "{", "\n", "\"date_column:year\"", ":", "Date", "(", "2001", ",", "-", "1", ",", "-", "1", ")", ",", "\n", "\"number_column:year\"", ":", "2001.0", ",", "\n", "\"string_column:year\"", ":", "\"2001\"", ",", "\n", "\"number_column:division\"", ":", "2.0", ",", "\n", "\"string_column:division\"", ":", "\"2\"", ",", "\n", "\"string_column:league\"", ":", "\"usl_a_league\"", ",", "\n", "\"string_column:regular_season\"", ":", "\"4th_western\"", ",", "\n", "\"number_column:regular_season\"", ":", "4.0", ",", "\n", "\"string_column:playoffs\"", ":", "\"quarterfinals\"", ",", "\n", "\"string_column:open_cup\"", ":", "\"did_not_qualify\"", ",", "\n", "\"number_column:open_cup\"", ":", "None", ",", "\n", "\"number_column:avg_attendance\"", ":", "7169.0", ",", "\n", "\"string_column:avg_attendance\"", ":", "\"7_169\"", ",", "\n", "}", ",", "\n", "{", "\n", "\"date_column:year\"", ":", "Date", "(", "2005", ",", "-", "1", ",", "-", "1", ")", ",", "\n", "\"number_column:year\"", ":", "2005.0", ",", "\n", "\"string_column:year\"", ":", "\"2005\"", ",", "\n", "\"number_column:division\"", ":", "2.0", ",", "\n", "\"string_column:division\"", ":", "\"2\"", ",", "\n", "\"string_column:league\"", ":", "\"usl_first_division\"", ",", "\n", "\"string_column:regular_season\"", ":", "\"5th\"", ",", "\n", "\"number_column:regular_season\"", ":", "5.0", ",", "\n", "\"string_column:playoffs\"", ":", "\"quarterfinals\"", ",", "\n", "\"string_column:open_cup\"", ":", "\"4th_round\"", ",", "\n", "\"number_column:open_cup\"", ":", "4.0", ",", "\n", "\"number_column:avg_attendance\"", ":", "6028.0", ",", "\n", "\"string_column:avg_attendance\"", ":", "\"6_028\"", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_table_data_from_untagged_file": [[51, 99], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_lines", "line.strip", "open().readlines", "open"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_lines"], ["", "def", "test_table_data_from_untagged_file", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"what was the attendance when usl a league played?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/wikitables/sample_table.tsv\"", "\n", "table_lines", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "test_file", ")", ".", "readlines", "(", ")", "]", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_lines", "(", "table_lines", ",", "question_tokens", ")", "\n", "# The content in the table represented by the untagged file we are reading here is the same as the one we", "\n", "# had in the tagged file above, except that we have a \"Score\" column instead of \"Avg. Attendance\" column,", "\n", "# which is changed to test the num2 extraction logic. I've shown the values not being extracted here as", "\n", "# well and commented them out.", "\n", "assert", "table_question_context", ".", "table_data", "==", "[", "\n", "{", "\n", "\"number_column:year\"", ":", "2001.0", ",", "\n", "# The value extraction logic we have for untagged lines does", "\n", "# not extract this value as a date.", "\n", "# 'date_column:year': Date(2001, -1, -1),", "\n", "\"string_column:year\"", ":", "\"2001\"", ",", "\n", "\"number_column:division\"", ":", "2.0", ",", "\n", "\"string_column:division\"", ":", "\"2\"", ",", "\n", "\"string_column:league\"", ":", "\"usl_a_league\"", ",", "\n", "\"string_column:regular_season\"", ":", "\"4th_western\"", ",", "\n", "# We only check for strings that are entirely numbers. So 4.0", "\n", "# will not be extracted.", "\n", "# 'number_column:regular_season': 4.0,", "\n", "\"string_column:playoffs\"", ":", "\"quarterfinals\"", ",", "\n", "\"string_column:open_cup\"", ":", "\"did_not_qualify\"", ",", "\n", "# 'number_column:open_cup': None,", "\n", "\"number_column:score\"", ":", "20.0", ",", "\n", "\"num2_column:score\"", ":", "30.0", ",", "\n", "\"string_column:score\"", ":", "\"20_30\"", ",", "\n", "}", ",", "\n", "{", "\n", "\"number_column:year\"", ":", "2005.0", ",", "\n", "# 'date_column:year': Date(2005, -1, -1),", "\n", "\"string_column:year\"", ":", "\"2005\"", ",", "\n", "\"number_column:division\"", ":", "2.0", ",", "\n", "\"string_column:division\"", ":", "\"2\"", ",", "\n", "\"string_column:league\"", ":", "\"usl_first_division\"", ",", "\n", "\"string_column:regular_season\"", ":", "\"5th\"", ",", "\n", "# Same here as in the \"division\" column for the first row.", "\n", "# 5.0 will not be extracted from \"5th\".", "\n", "# 'number_column:regular_season': 5.0,", "\n", "\"string_column:playoffs\"", ":", "\"quarterfinals\"", ",", "\n", "\"string_column:open_cup\"", ":", "\"4th_round\"", ",", "\n", "# 'number_column:open_cup': 4.0,", "\n", "\"number_column:score\"", ":", "50.0", ",", "\n", "\"num2_column:score\"", ":", "40.0", ",", "\n", "\"string_column:score\"", ":", "\"50_40\"", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_number_extraction": [[102, 110], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_number_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"\"\"how many players on the 191617 illinois fighting illini men's basketball team\n                      had more than 100 points scored?\"\"\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-7.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "_", ",", "number_entities", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "assert", "number_entities", "==", "[", "(", "\"191617\"", ",", "5", ")", ",", "(", "\"100\"", ",", "16", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_date_extraction": [[111, 118], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_date_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"how many laps did matt kenset complete on february 26, 2006.\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-8.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "_", ",", "number_entities", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "assert", "number_entities", "==", "[", "(", "\"2\"", ",", "8", ")", ",", "(", "\"26\"", ",", "9", ")", ",", "(", "\"2006\"", ",", "11", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_date_extraction_2": [[119, 127], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_date_extraction_2", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"\"\"how many different players scored for the san jose earthquakes during their\n                      1979 home opener against the timbers?\"\"\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-6.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "_", ",", "number_entities", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "assert", "number_entities", "==", "[", "(", "\"1979\"", ",", "12", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_multiword_entity_extraction": [[128, 137], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_multiword_entity_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"was the positioning better the year of the france venue or the year of the south korea venue?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-3.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "entities", ",", "_", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "assert", "entities", "==", "[", "\n", "(", "\"string:france\"", ",", "[", "\"string_column:venue\"", "]", ")", ",", "\n", "(", "\"string:south_korea\"", ",", "[", "\"string_column:venue\"", "]", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_rank_number_extraction": [[139, 146], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_rank_number_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"what was the first tamil-language film in 1943?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-1.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "_", ",", "numbers", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "assert", "numbers", "==", "[", "(", "\"1\"", ",", "3", ")", ",", "(", "\"1943\"", ",", "9", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_null_extraction": [[147, 156], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_null_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"on what date did the eagles score the least points?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-2.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "entities", ",", "numbers", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "# \"Eagles\" does not appear in the table.", "\n", "assert", "entities", "==", "[", "]", "\n", "assert", "numbers", "==", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_numerical_column_type_extraction": [[157, 168], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "test_numerical_column_type_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"\"\"how many players on the 191617 illinois fighting illini men's basketball team\n                      had more than 100 points scored?\"\"\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-7.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "column_names", "=", "table_question_context", ".", "column_names", "\n", "assert", "\"number_column:games_played\"", "in", "column_names", "\n", "assert", "\"number_column:field_goals\"", "in", "column_names", "\n", "assert", "\"number_column:free_throws\"", "in", "column_names", "\n", "assert", "\"number_column:points\"", "in", "column_names", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_date_column_type_extraction_1": [[169, 176], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "test_date_column_type_extraction_1", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"how many were elected?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-5.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "column_names", "=", "table_question_context", ".", "column_names", "\n", "assert", "\"date_column:first_elected\"", "in", "column_names", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_date_column_type_extraction_2": [[177, 185], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "test_date_column_type_extraction_2", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"how many were elected?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-9.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "column_names", "=", "table_question_context", ".", "column_names", "\n", "assert", "\"date_column:date_of_appointment\"", "in", "column_names", "\n", "assert", "\"date_column:date_of_election\"", "in", "column_names", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_string_column_types_extraction": [[186, 196], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "test_string_column_types_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"how many were elected?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-10.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "column_names", "=", "table_question_context", ".", "column_names", "\n", "assert", "\"string_column:birthplace\"", "in", "column_names", "\n", "assert", "\"string_column:advocate\"", "in", "column_names", "\n", "assert", "\"string_column:notability\"", "in", "column_names", "\n", "assert", "\"string_column:name\"", "in", "column_names", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_number_and_entity_extraction": [[197, 208], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_entities_from_question"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question"], ["", "def", "test_number_and_entity_extraction", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"other than m1 how many notations have 1 in them?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-11.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "string_entities", ",", "number_entities", "=", "table_question_context", ".", "get_entities_from_question", "(", ")", "\n", "assert", "string_entities", "==", "[", "\n", "(", "\"string:m1\"", ",", "[", "\"string_column:notation\"", "]", ")", ",", "\n", "(", "\"string:1\"", ",", "[", "\"string_column:position\"", "]", ")", ",", "\n", "]", "\n", "assert", "number_entities", "==", "[", "(", "\"1\"", ",", "2", ")", ",", "(", "\"1\"", ",", "7", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_get_knowledge_graph": [[209, 258], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_table_knowledge_graph", "sorted", "set", "neighbors.items", "set", "set", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_knowledge_graph"], ["", "def", "test_get_knowledge_graph", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"other than m1 how many notations have 1 in them?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/corenlp_processed_tables/TEST-11.table\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "knowledge_graph", "=", "table_question_context", ".", "get_table_knowledge_graph", "(", ")", "\n", "entities", "=", "knowledge_graph", ".", "entities", "\n", "# -1 is not in entities because there are no date columns in the table.", "\n", "assert", "sorted", "(", "entities", ")", "==", "[", "\n", "\"1\"", ",", "\n", "\"number_column:notation\"", ",", "\n", "\"number_column:position\"", ",", "\n", "\"string:1\"", ",", "\n", "\"string:m1\"", ",", "\n", "\"string_column:mnemonic\"", ",", "\n", "\"string_column:notation\"", ",", "\n", "\"string_column:position\"", ",", "\n", "\"string_column:short_name\"", ",", "\n", "\"string_column:swara\"", ",", "\n", "]", "\n", "neighbors", "=", "knowledge_graph", ".", "neighbors", "\n", "# Each number extracted from the question will have all number and date columns as", "\n", "# neighbors. Each string entity extracted from the question will only have the corresponding", "\n", "# column as the neighbor.", "\n", "neighbors_with_sets", "=", "{", "key", ":", "set", "(", "value", ")", "for", "key", ",", "value", "in", "neighbors", ".", "items", "(", ")", "}", "\n", "assert", "neighbors_with_sets", "==", "{", "\n", "\"1\"", ":", "{", "\"number_column:position\"", ",", "\"number_column:notation\"", "}", ",", "\n", "\"string_column:mnemonic\"", ":", "set", "(", ")", ",", "\n", "\"string_column:short_name\"", ":", "set", "(", ")", ",", "\n", "\"string_column:swara\"", ":", "set", "(", ")", ",", "\n", "\"number_column:position\"", ":", "{", "\"1\"", "}", ",", "\n", "\"number_column:notation\"", ":", "{", "\"1\"", "}", ",", "\n", "\"string:m1\"", ":", "{", "\"string_column:notation\"", "}", ",", "\n", "\"string:1\"", ":", "{", "\"string_column:position\"", "}", ",", "\n", "\"string_column:notation\"", ":", "{", "\"string:m1\"", "}", ",", "\n", "\"string_column:position\"", ":", "{", "\"string:1\"", "}", ",", "\n", "}", "\n", "entity_text", "=", "knowledge_graph", ".", "entity_text", "\n", "assert", "entity_text", "==", "{", "\n", "\"1\"", ":", "\"1\"", ",", "\n", "\"string:m1\"", ":", "\"m1\"", ",", "\n", "\"string:1\"", ":", "\"1\"", ",", "\n", "\"string_column:notation\"", ":", "\"notation\"", ",", "\n", "\"number_column:notation\"", ":", "\"notation\"", ",", "\n", "\"string_column:mnemonic\"", ":", "\"mnemonic\"", ",", "\n", "\"string_column:short_name\"", ":", "\"short name\"", ",", "\n", "\"string_column:swara\"", ":", "\"swara\"", ",", "\n", "\"number_column:position\"", ":", "\"position\"", ",", "\n", "\"string_column:position\"", ":", "\"position\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context_test.TestTableQuestionContext.test_knowledge_graph_has_correct_neighbors": [[260, 308], ["table_question_context_test.TestTableQuestionContext.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file.get_table_knowledge_graph", "set", "set", "set", "neighbors.keys"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_knowledge_graph"], ["", "def", "test_knowledge_graph_has_correct_neighbors", "(", "self", ")", ":", "\n", "        ", "question", "=", "\"when was the attendance greater than 5000?\"", "\n", "question_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question", ")", "\n", "test_file", "=", "f\"{self.FIXTURES_ROOT}/data/wikitables/sample_table.tagged\"", "\n", "table_question_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "test_file", ",", "question_tokens", ")", "\n", "knowledge_graph", "=", "table_question_context", ".", "get_table_knowledge_graph", "(", ")", "\n", "neighbors", "=", "knowledge_graph", ".", "neighbors", "\n", "# '5000' is neighbors with number and date columns. '-1' is in entities because there is a", "\n", "# date column, which is its only neighbor.", "\n", "assert", "set", "(", "neighbors", ".", "keys", "(", ")", ")", "==", "{", "\n", "\"date_column:year\"", ",", "\n", "\"number_column:year\"", ",", "\n", "\"string_column:year\"", ",", "\n", "\"number_column:division\"", ",", "\n", "\"string_column:division\"", ",", "\n", "\"string_column:league\"", ",", "\n", "\"string_column:regular_season\"", ",", "\n", "\"number_column:regular_season\"", ",", "\n", "\"string_column:playoffs\"", ",", "\n", "\"string_column:open_cup\"", ",", "\n", "\"number_column:open_cup\"", ",", "\n", "\"number_column:avg_attendance\"", ",", "\n", "\"string_column:avg_attendance\"", ",", "\n", "\"5000\"", ",", "\n", "\"-1\"", ",", "\n", "}", "\n", "assert", "set", "(", "neighbors", "[", "\"date_column:year\"", "]", ")", "==", "{", "\"5000\"", ",", "\"-1\"", "}", "\n", "assert", "neighbors", "[", "\"number_column:year\"", "]", "==", "[", "\"5000\"", "]", "\n", "assert", "neighbors", "[", "\"string_column:year\"", "]", "==", "[", "]", "\n", "assert", "neighbors", "[", "\"number_column:division\"", "]", "==", "[", "\"5000\"", "]", "\n", "assert", "neighbors", "[", "\"string_column:division\"", "]", "==", "[", "]", "\n", "assert", "neighbors", "[", "\"string_column:league\"", "]", "==", "[", "]", "\n", "assert", "neighbors", "[", "\"string_column:regular_season\"", "]", "==", "[", "]", "\n", "assert", "neighbors", "[", "\"number_column:regular_season\"", "]", "==", "[", "\"5000\"", "]", "\n", "assert", "neighbors", "[", "\"string_column:playoffs\"", "]", "==", "[", "]", "\n", "assert", "neighbors", "[", "\"string_column:open_cup\"", "]", "==", "[", "]", "\n", "assert", "neighbors", "[", "\"number_column:open_cup\"", "]", "==", "[", "\"5000\"", "]", "\n", "assert", "neighbors", "[", "\"number_column:avg_attendance\"", "]", "==", "[", "\"5000\"", "]", "\n", "assert", "neighbors", "[", "\"string_column:avg_attendance\"", "]", "==", "[", "]", "\n", "assert", "set", "(", "neighbors", "[", "\"5000\"", "]", ")", "==", "{", "\n", "\"date_column:year\"", ",", "\n", "\"number_column:year\"", ",", "\n", "\"number_column:division\"", ",", "\n", "\"number_column:avg_attendance\"", ",", "\n", "\"number_column:regular_season\"", ",", "\n", "\"number_column:open_cup\"", ",", "\n", "}", "\n", "assert", "neighbors", "[", "\"-1\"", "]", "==", "[", "\"date_column:year\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.get_nlvr_logical_forms.read_json_line": [[18, 30], ["json.loads", "label_str.lower", "data[].lower"], "function", ["None"], ["def", "read_json_line", "(", "line", ":", "str", ")", "->", "Tuple", "[", "str", ",", "str", ",", "List", "[", "JsonDict", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "instance_id", "=", "data", "[", "\"identifier\"", "]", "\n", "sentence", "=", "data", "[", "\"sentence\"", "]", "\n", "if", "\"worlds\"", "in", "data", ":", "\n", "        ", "structured_reps", "=", "data", "[", "\"worlds\"", "]", "\n", "label_strings", "=", "[", "label_str", ".", "lower", "(", ")", "for", "label_str", "in", "data", "[", "\"labels\"", "]", "]", "\n", "", "else", ":", "\n", "# We're reading ungrouped data.", "\n", "        ", "structured_reps", "=", "[", "data", "[", "\"structured_rep\"", "]", "]", "\n", "label_strings", "=", "[", "data", "[", "\"label\"", "]", ".", "lower", "(", ")", "]", "\n", "", "return", "instance_id", ",", "sentence", ",", "structured_reps", ",", "label_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.get_nlvr_logical_forms.process_data": [[32, 118], ["allennlp.semparse.ActionSpaceWalker", "open", "allennlp.semparse.domain_languages.NlvrLanguage", "get_nlvr_logical_forms.read_json_line", "open", "outfile.close", "worlds.append", "allennlp.semparse.ActionSpaceWalker.get_all_logical_forms", "worlds[].get_agenda_for_sentence", "allennlp.semparse.ActionSpaceWalker.get_logical_forms_with_agenda", "all", "processed_data.append", "processed_data.append", "json.dump", "outfile.write", "allennlp.semparse.domain_languages.nlvr_language.Box", "allennlp.semparse.domain_languages.NlvrLanguage", "worlds[].logical_form_to_action_sequence", "worlds[].logical_form_to_action_sequence", "enumerate", "len", "correct_logical_forms.append", "len", "incorrect_logical_forms.append", "len", "len", "world.execute", "zip"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.get_nlvr_logical_forms.read_json_line", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_all_logical_forms", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "process_data", "(", "\n", "input_file", ":", "str", ",", "\n", "output_file", ":", "str", ",", "\n", "max_path_length", ":", "int", ",", "\n", "max_num_logical_forms", ":", "int", ",", "\n", "ignore_agenda", ":", "bool", ",", "\n", "write_sequences", ":", "bool", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Reads an NLVR dataset and returns a JSON representation containing sentences, labels, correct and\n    incorrect logical forms. The output will contain at most `max_num_logical_forms` logical forms\n    each in both correct and incorrect lists. The output format is:\n        ``[{\"id\": str, \"label\": str, \"sentence\": str, \"correct\": List[str], \"incorrect\": List[str]}]``\n    \"\"\"", "\n", "processed_data", ":", "JsonDict", "=", "[", "]", "\n", "# We can instantiate the ``ActionSpaceWalker`` with any world because the action space is the", "\n", "# same for all the ``NlvrLanguage`` objects. It is just the execution that differs.", "\n", "walker", "=", "ActionSpaceWalker", "(", "NlvrLanguage", "(", "{", "}", ")", ",", "max_path_length", "=", "max_path_length", ")", "\n", "for", "line", "in", "open", "(", "input_file", ")", ":", "\n", "        ", "instance_id", ",", "sentence", ",", "structured_reps", ",", "label_strings", "=", "read_json_line", "(", "line", ")", "\n", "worlds", "=", "[", "]", "\n", "for", "structured_representation", "in", "structured_reps", ":", "\n", "            ", "boxes", "=", "{", "\n", "Box", "(", "object_list", ",", "box_id", ")", "\n", "for", "box_id", ",", "object_list", "in", "enumerate", "(", "structured_representation", ")", "\n", "}", "\n", "worlds", ".", "append", "(", "NlvrLanguage", "(", "boxes", ")", ")", "\n", "", "labels", "=", "[", "label_string", "==", "\"true\"", "for", "label_string", "in", "label_strings", "]", "\n", "correct_logical_forms", "=", "[", "]", "\n", "incorrect_logical_forms", "=", "[", "]", "\n", "if", "ignore_agenda", ":", "\n", "# Get 1000 shortest logical forms.", "\n", "            ", "logical_forms", "=", "walker", ".", "get_all_logical_forms", "(", "max_num_logical_forms", "=", "1000", ")", "\n", "", "else", ":", "\n", "# TODO (pradeep): Assuming all worlds give the same agenda.", "\n", "            ", "sentence_agenda", "=", "worlds", "[", "0", "]", ".", "get_agenda_for_sentence", "(", "sentence", ")", "\n", "logical_forms", "=", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "sentence_agenda", ",", "max_num_logical_forms", "*", "10", "\n", ")", "\n", "", "for", "logical_form", "in", "logical_forms", ":", "\n", "            ", "if", "all", "(", "[", "world", ".", "execute", "(", "logical_form", ")", "==", "label", "for", "world", ",", "label", "in", "zip", "(", "worlds", ",", "labels", ")", "]", ")", ":", "\n", "                ", "if", "len", "(", "correct_logical_forms", ")", "<=", "max_num_logical_forms", ":", "\n", "                    ", "correct_logical_forms", ".", "append", "(", "logical_form", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "len", "(", "incorrect_logical_forms", ")", "<=", "max_num_logical_forms", ":", "\n", "                    ", "incorrect_logical_forms", ".", "append", "(", "logical_form", ")", "\n", "", "", "if", "(", "\n", "len", "(", "correct_logical_forms", ")", ">=", "max_num_logical_forms", "\n", "and", "len", "(", "incorrect_logical_forms", ")", ">=", "max_num_logical_forms", "\n", ")", ":", "\n", "                ", "break", "\n", "", "", "if", "write_sequences", ":", "\n", "            ", "correct_sequences", "=", "[", "\n", "worlds", "[", "0", "]", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "for", "logical_form", "in", "correct_logical_forms", "\n", "]", "\n", "incorrect_sequences", "=", "[", "\n", "worlds", "[", "0", "]", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "for", "logical_form", "in", "incorrect_logical_forms", "\n", "]", "\n", "processed_data", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "instance_id", ",", "\n", "\"sentence\"", ":", "sentence", ",", "\n", "\"correct_sequences\"", ":", "correct_sequences", ",", "\n", "\"incorrect_sequences\"", ":", "incorrect_sequences", ",", "\n", "\"worlds\"", ":", "structured_reps", ",", "\n", "\"labels\"", ":", "label_strings", ",", "\n", "}", "\n", ")", "\n", "", "else", ":", "\n", "            ", "processed_data", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "instance_id", ",", "\n", "\"sentence\"", ":", "sentence", ",", "\n", "\"correct_logical_forms\"", ":", "correct_logical_forms", ",", "\n", "\"incorrect_logical_forms\"", ":", "incorrect_logical_forms", ",", "\n", "\"worlds\"", ":", "structured_reps", ",", "\n", "\"labels\"", ":", "label_strings", ",", "\n", "}", "\n", ")", "\n", "", "", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "for", "instance_processed_data", "in", "processed_data", ":", "\n", "            ", "json", ".", "dump", "(", "instance_processed_data", ",", "outfile", ")", "\n", "outfile", ".", "write", "(", "\"\\n\"", ")", "\n", "", "outfile", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.group_nlvr_worlds.group_dataset": [[14, 31], ["collections.defaultdict", "open", "json.loads", "[].append", "[].append", "open", "collections.defaultdict.values", "data[].split", "json.dump", "output.write"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "group_dataset", "(", "input_file", ":", "str", ",", "output_file", ":", "str", ")", "->", "None", ":", "\n", "    ", "instance_groups", "=", "defaultdict", "(", "lambda", ":", "{", "\"worlds\"", ":", "[", "]", ",", "\"labels\"", ":", "[", "]", "}", ")", "\n", "for", "line", "in", "open", "(", "input_file", ")", ":", "\n", "        ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "# \"identifier\" in the original dataset looks something like 4055-3, where 4055 is common", "\n", "# across all four instances with the same sentence, but different worlds, and the suffix", "\n", "# differentiates among the four instances.", "\n", "identifier", "=", "data", "[", "\"identifier\"", "]", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "instance_groups", "[", "identifier", "]", "[", "\"identifier\"", "]", "=", "identifier", "\n", "instance_groups", "[", "identifier", "]", "[", "\"sentence\"", "]", "=", "data", "[", "\"sentence\"", "]", "\n", "instance_groups", "[", "identifier", "]", "[", "\"worlds\"", "]", ".", "append", "(", "data", "[", "\"structured_rep\"", "]", ")", "\n", "instance_groups", "[", "identifier", "]", "[", "\"labels\"", "]", ".", "append", "(", "data", "[", "\"label\"", "]", ")", "\n", "\n", "", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "output", ":", "\n", "        ", "for", "instance_group", "in", "instance_groups", ".", "values", "(", ")", ":", "\n", "            ", "json", ".", "dump", "(", "instance_group", ",", "output", ")", "\n", "output", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.generate_data_from_erm_model.make_data": [[19, 71], ["allennlp.data.dataset_readers.NlvrDatasetReader", "sys.stderr.write", "allennlp.models.archival.load_archive", "isinstance", "type", "RuntimeError", "open", "open", "outfile.close", "json.loads", "allennlp.data.dataset_readers.NlvrDatasetReader.text_to_instance", "model.forward_on_instance", "zip", "json.dump", "outfile.write", "allennlp.semparse.worlds.NlvrWorld", "all", "world.execute", "correct_sequences.append", "label.lower", "str().lower", "zip", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["input_examples_file", ":", "str", ",", "\n", "tables_directory", ":", "str", ",", "\n", "archived_model_file", ":", "str", ",", "\n", "output_dir", ":", "str", ",", "\n", "num_logical_forms", ":", "int", ",", "\n", ")", "->", "None", ":", "\n", "    ", "reader", "=", "WikiTablesDatasetReader", "(", "\n", "tables_directory", "=", "tables_directory", ",", "keep_if_no_logical_forms", "=", "True", ",", "output_agendas", "=", "True", "\n", ")", "\n", "dataset", "=", "reader", ".", "read", "(", "input_examples_file", ")", "\n", "input_lines", "=", "[", "]", "\n", "with", "open", "(", "input_examples_file", ")", "as", "input_file", ":", "\n", "        ", "input_lines", "=", "input_file", ".", "readlines", "(", ")", "\n", "", "archive", "=", "load_archive", "(", "archived_model_file", ")", "\n", "model", "=", "archive", ".", "model", "\n", "model", ".", "training", "=", "False", "\n", "model", ".", "_decoder_trainer", ".", "_max_num_decoded_sequences", "=", "100", "\n", "for", "instance", ",", "example_line", "in", "zip", "(", "dataset", ",", "input_lines", ")", ":", "\n", "        ", "outputs", "=", "model", ".", "forward_on_instance", "(", "instance", ")", "\n", "world", "=", "instance", ".", "fields", "[", "\"world\"", "]", ".", "metadata", "\n", "parsed_info", "=", "util", ".", "parse_example_line", "(", "example_line", ")", "\n", "example_id", "=", "parsed_info", "[", "\"id\"", "]", "\n", "target_list", "=", "parsed_info", "[", "\"target_values\"", "]", "\n", "logical_forms", "=", "outputs", "[", "\"logical_form\"", "]", "\n", "correct_logical_forms", "=", "[", "]", "\n", "for", "logical_form", "in", "logical_forms", ":", "\n", "            ", "if", "world", ".", "evaluate_logical_form", "(", "logical_form", ",", "target_list", ")", ":", "\n", "                ", "correct_logical_forms", ".", "append", "(", "logical_form", ")", "\n", "if", "len", "(", "correct_logical_forms", ")", ">=", "num_logical_forms", ":", "\n", "                    ", "break", "\n", "", "", "", "num_found", "=", "len", "(", "correct_logical_forms", ")", "\n", "print", "(", "f\"{num_found} found for {example_id}\"", ")", "\n", "if", "num_found", "==", "0", ":", "\n", "            ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "output_file", "=", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{example_id}.gz\"", ")", ",", "\"wb\"", ")", "\n", "for", "logical_form", "in", "correct_logical_forms", ":", "\n", "            ", "logical_form_line", "=", "(", "logical_form", "+", "\"\\n\"", ")", ".", "encode", "(", "\"utf-8\"", ")", "\n", "output_file", ".", "write", "(", "logical_form_line", ")", "\n", "", "output_file", ".", "close", "(", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "argparser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argparser", ".", "add_argument", "(", "\"input\"", ",", "type", "=", "str", ",", "help", "=", "\"Input file\"", ")", "\n", "argparser", ".", "add_argument", "(", "\"tables_directory\"", ",", "type", "=", "str", ",", "help", "=", "\"Tables directory\"", ")", "\n", "argparser", ".", "add_argument", "(", "\"archived_model\"", ",", "type", "=", "str", ",", "help", "=", "\"Archived model.tar.gz\"", ")", "\n", "argparser", ".", "add_argument", "(", "\n", "\"--output-dir\"", ",", "type", "=", "str", ",", "dest", "=", "\"output_dir\"", ",", "help", "=", "\"Output directory\"", ",", "default", "=", "\"erm_output\"", "\n", ")", "\n", "argparser", ".", "add_argument", "(", "\n", "\"--num-logical-forms\"", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser.__init__": [[80, 146], ["allennlp_semparse.models.nlvr.nlvr_semantic_parser.NlvrSemanticParser.__init__", "allennlp.training.metrics.Average", "allennlp_semparse.state_machines.trainers.ExpectedRiskMinimization", "set", "allennlp_semparse.state_machines.transition_functions.CoverageTransitionFunction", "allennlp_semparse.domain_languages.NlvrLanguage().terminal_productions.values", "os.path.isfile", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._encoder.get_output_dim", "allennlp.models.archival.load_archive", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._initialize_weights_from_archive", "logger.warning", "allennlp.nn.Activation.by_name", "allennlp_semparse.domain_languages.NlvrLanguage", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._initialize_weights_from_archive"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "sentence_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "attention", ":", "Attention", ",", "\n", "beam_size", ":", "int", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "max_num_finished_states", ":", "int", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "normalize_beam_score_by_length", ":", "bool", "=", "False", ",", "\n", "checklist_cost_weight", ":", "float", "=", "0.6", ",", "\n", "dynamic_cost_weight", ":", "Dict", "[", "str", ",", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "\n", "penalize_non_agenda_actions", ":", "bool", "=", "False", ",", "\n", "initial_mml_model_file", ":", "str", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "NlvrCoverageSemanticParser", ",", "self", ")", ".", "__init__", "(", "\n", "vocab", "=", "vocab", ",", "\n", "sentence_embedder", "=", "sentence_embedder", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "encoder", "=", "encoder", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "_agenda_coverage", "=", "Average", "(", ")", "\n", "self", ".", "_decoder_trainer", ":", "DecoderTrainer", "[", "\n", "Callable", "[", "[", "CoverageState", "]", ",", "torch", ".", "Tensor", "]", "\n", "]", "=", "ExpectedRiskMinimization", "(", "\n", "beam_size", "=", "beam_size", ",", "\n", "normalize_by_length", "=", "normalize_beam_score_by_length", ",", "\n", "max_decoding_steps", "=", "max_decoding_steps", ",", "\n", "max_num_finished_states", "=", "max_num_finished_states", ",", "\n", ")", "\n", "\n", "# Instantiating an empty NlvrLanguage just to get the number of terminals.", "\n", "self", ".", "_terminal_productions", "=", "set", "(", "NlvrLanguage", "(", "set", "(", ")", ")", ".", "terminal_productions", ".", "values", "(", ")", ")", "\n", "self", ".", "_decoder_step", "=", "CoverageTransitionFunction", "(", "\n", "encoder_output_dim", "=", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "attention", ",", "\n", "activation", "=", "Activation", ".", "by_name", "(", "\"tanh\"", ")", "(", ")", ",", "\n", "add_action_bias", "=", "False", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "_checklist_cost_weight", "=", "checklist_cost_weight", "\n", "self", ".", "_dynamic_cost_wait_epochs", "=", "None", "\n", "self", ".", "_dynamic_cost_rate", "=", "None", "\n", "if", "dynamic_cost_weight", ":", "\n", "            ", "self", ".", "_dynamic_cost_wait_epochs", "=", "dynamic_cost_weight", "[", "\"wait_num_epochs\"", "]", "\n", "self", ".", "_dynamic_cost_rate", "=", "dynamic_cost_weight", "[", "\"rate\"", "]", "\n", "", "self", ".", "_penalize_non_agenda_actions", "=", "penalize_non_agenda_actions", "\n", "self", ".", "_last_epoch_in_forward", ":", "int", "=", "None", "\n", "# TODO (pradeep): Checking whether file exists here to avoid raising an error when we've", "\n", "# copied a trained ERM model from a different machine and the original MML model that was", "\n", "# used to initialize it does not exist on the current machine. This may not be the best", "\n", "# solution for the problem.", "\n", "if", "initial_mml_model_file", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "initial_mml_model_file", ")", ":", "\n", "                ", "archive", "=", "load_archive", "(", "initial_mml_model_file", ")", "\n", "self", ".", "_initialize_weights_from_archive", "(", "archive", ")", "\n", "", "else", ":", "\n", "# A model file is passed, but it does not exist. This is expected to happen when", "\n", "# you're using a trained ERM model to decode. But it may also happen if the path to", "\n", "# the file is really just incorrect. So throwing a warning.", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"MML model file for initializing weights is passed, but does not exist.\"", "\n", "\" This is fine if you're just decoding.\"", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._initialize_weights_from_archive": [[149, 184], ["logger.info", "dict", "dict", "dict.items", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser.named_parameters", "archive.model.named_parameters", "RuntimeError", "logger.info", "model_parameters[].data.copy_", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_vocab_index_mapping", "model_parameters[].data.clone", "logger.info", "len", "model_parameters[].data.clone.size"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_vocab_index_mapping"], ["", "", "", "def", "_initialize_weights_from_archive", "(", "self", ",", "archive", ":", "Archive", ")", "->", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Initializing weights from MML model.\"", ")", "\n", "model_parameters", "=", "dict", "(", "self", ".", "named_parameters", "(", ")", ")", "\n", "archived_parameters", "=", "dict", "(", "archive", ".", "model", ".", "named_parameters", "(", ")", ")", "\n", "sentence_embedder_weight", "=", "\"_sentence_embedder.token_embedder_tokens.weight\"", "\n", "if", "(", "\n", "sentence_embedder_weight", "not", "in", "archived_parameters", "\n", "or", "sentence_embedder_weight", "not", "in", "model_parameters", "\n", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"When initializing model weights from an MML model, we need \"", "\n", "\"the sentence embedder to be a TokenEmbedder using namespace called \"", "\n", "\"tokens.\"", "\n", ")", "\n", "", "for", "name", ",", "weights", "in", "archived_parameters", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "in", "model_parameters", ":", "\n", "                ", "if", "name", "==", "\"_sentence_embedder.token_embedder_tokens.weight\"", ":", "\n", "# The shapes of embedding weights will most likely differ between the two models", "\n", "# because the vocabularies will most likely be different. We will get a mapping", "\n", "# of indices from this model's token indices to the archived model's and copy", "\n", "# the tensor accordingly.", "\n", "                    ", "vocab_index_mapping", "=", "self", ".", "_get_vocab_index_mapping", "(", "archive", ".", "model", ".", "vocab", ")", "\n", "archived_embedding_weights", "=", "weights", ".", "data", "\n", "new_weights", "=", "model_parameters", "[", "name", "]", ".", "data", ".", "clone", "(", ")", "\n", "for", "index", ",", "archived_index", "in", "vocab_index_mapping", ":", "\n", "                        ", "new_weights", "[", "index", "]", "=", "archived_embedding_weights", "[", "archived_index", "]", "\n", "", "logger", ".", "info", "(", "\n", "\"Copied embeddings of %d out of %d tokens\"", ",", "\n", "len", "(", "vocab_index_mapping", ")", ",", "\n", "new_weights", ".", "size", "(", ")", "[", "0", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "new_weights", "=", "weights", ".", "data", "\n", "", "logger", ".", "info", "(", "\"Copying parameter %s\"", ",", "name", ")", "\n", "model_parameters", "[", "name", "]", ".", "data", ".", "copy_", "(", "new_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_vocab_index_mapping": [[185, 200], ["range", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser.vocab.get_vocab_size", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser.vocab.get_token_from_index", "archived_vocab.get_token_index", "archived_vocab.get_token_from_index", "vocab_index_mapping.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "", "def", "_get_vocab_index_mapping", "(", "self", ",", "archived_vocab", ":", "Vocabulary", ")", "->", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ":", "\n", "        ", "vocab_index_mapping", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "\"tokens\"", ")", ")", ":", "\n", "            ", "token", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "index", "=", "index", ",", "namespace", "=", "\"tokens\"", ")", "\n", "archived_token_index", "=", "archived_vocab", ".", "get_token_index", "(", "token", ",", "namespace", "=", "\"tokens\"", ")", "\n", "# Checking if we got the UNK token index, because we don't want all new token", "\n", "# representations initialized to UNK token's representation. We do that by checking if", "\n", "# the two tokens are the same. They will not be if the token at the archived index is", "\n", "# UNK.", "\n", "if", "(", "\n", "archived_vocab", ".", "get_token_from_index", "(", "archived_token_index", ",", "namespace", "=", "\"tokens\"", ")", "\n", "==", "token", "\n", ")", ":", "\n", "                ", "vocab_index_mapping", ".", "append", "(", "(", "index", ",", "archived_token_index", ")", ")", "\n", "", "", "return", "vocab_index_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser.forward": [[201, 300], ["len", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_initial_rnn_state", "zip", "allennlp_semparse.state_machines.states.CoverageState", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._decoder_trainer.decode", "best_final_states.items", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_action_strings", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_denotations", "logger.warning", "agenda.new_zeros", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._create_grammar_state", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_label_strings", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_checklist_info", "checklist_target.new_zeros", "initial_checklist_states.append", "functools.partial", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._update_metrics", "range", "enumerate", "range", "range", "range", "checklist_target.size", "allennlp_semparse.state_machines.states.ChecklistStatelet", "list", "agenda_[].cpu", "outputs[].append", "enumerate", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_initial_rnn_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_action_strings", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_denotations", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._create_grammar_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_label_strings", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_checklist_info", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser.NlvrDirectSemanticParser._update_metrics", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "forward", "(", "\n", "self", ",", "# type: ignore", "\n", "sentence", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "agenda", ":", "torch", ".", "LongTensor", ",", "\n", "identifier", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "labels", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Decoder logic for producing type constrained target sequences that maximize coverage of\n        their respective agendas, and minimize a denotation based loss.\n        \"\"\"", "\n", "if", "self", ".", "_dynamic_cost_rate", "is", "not", "None", ":", "\n", "# This could be added back pretty easily with an EpochCallback passed to the Trainer (it", "\n", "# just has to set the epoch number on the model, which could then be queried in here).", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Dynamic cost rate functionality was removed in AllenNLP 1.0. If you want this, \"", "\n", "\"use version 0.9.  We will just use the static checklist cost weight.\"", "\n", ")", "\n", "", "batch_size", "=", "len", "(", "worlds", ")", "\n", "\n", "initial_rnn_state", "=", "self", ".", "_get_initial_rnn_state", "(", "sentence", ")", "\n", "initial_score_list", "=", "[", "agenda", ".", "new_zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "# TODO (pradeep): Assuming all worlds give the same set of valid actions.", "\n", "initial_grammar_state", "=", "[", "\n", "self", ".", "_create_grammar_state", "(", "worlds", "[", "i", "]", "[", "0", "]", ",", "actions", "[", "i", "]", ")", "for", "i", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "label_strings", "=", "self", ".", "_get_label_strings", "(", "labels", ")", "if", "labels", "is", "not", "None", "else", "None", "\n", "# Each instance's agenda is of size (agenda_size, 1)", "\n", "# TODO(mattg): It looks like the agenda is only ever used on the CPU.  In that case, it's a", "\n", "# waste to copy it to the GPU and then back, and this should probably be a MetadataField.", "\n", "agenda_list", "=", "[", "agenda", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_checklist_states", "=", "[", "]", "\n", "for", "instance_actions", ",", "instance_agenda", "in", "zip", "(", "actions", ",", "agenda_list", ")", ":", "\n", "            ", "checklist_info", "=", "self", ".", "_get_checklist_info", "(", "instance_agenda", ",", "instance_actions", ")", "\n", "checklist_target", ",", "terminal_actions", ",", "checklist_mask", "=", "checklist_info", "\n", "\n", "initial_checklist", "=", "checklist_target", ".", "new_zeros", "(", "checklist_target", ".", "size", "(", ")", ")", "\n", "initial_checklist_states", ".", "append", "(", "\n", "ChecklistStatelet", "(", "\n", "terminal_actions", "=", "terminal_actions", ",", "\n", "checklist_target", "=", "checklist_target", ",", "\n", "checklist_mask", "=", "checklist_mask", ",", "\n", "checklist", "=", "initial_checklist", ",", "\n", ")", "\n", ")", "\n", "", "initial_state", "=", "CoverageState", "(", "\n", "batch_indices", "=", "list", "(", "range", "(", "batch_size", ")", ")", ",", "\n", "action_history", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "\n", "score", "=", "initial_score_list", ",", "\n", "rnn_state", "=", "initial_rnn_state", ",", "\n", "grammar_state", "=", "initial_grammar_state", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "extras", "=", "label_strings", ",", "\n", "checklist_state", "=", "initial_checklist_states", ",", "\n", ")", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "initial_state", ".", "debug_info", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "", "agenda_data", "=", "[", "agenda_", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "data", "for", "agenda_", "in", "agenda_list", "]", "\n", "outputs", "=", "self", ".", "_decoder_trainer", ".", "decode", "(", "# type: ignore", "\n", "initial_state", ",", "self", ".", "_decoder_step", ",", "partial", "(", "self", ".", "_get_state_cost", ",", "worlds", ")", "\n", ")", "\n", "if", "identifier", "is", "not", "None", ":", "\n", "            ", "outputs", "[", "\"identifier\"", "]", "=", "identifier", "\n", "", "best_final_states", "=", "outputs", "[", "\"best_final_states\"", "]", "\n", "best_action_sequences", "=", "{", "}", "\n", "for", "batch_index", ",", "states", "in", "best_final_states", ".", "items", "(", ")", ":", "\n", "            ", "best_action_sequences", "[", "batch_index", "]", "=", "[", "state", ".", "action_history", "[", "0", "]", "for", "state", "in", "states", "]", "\n", "", "batch_action_strings", "=", "self", ".", "_get_action_strings", "(", "actions", ",", "best_action_sequences", ")", "\n", "batch_denotations", "=", "self", ".", "_get_denotations", "(", "batch_action_strings", ",", "worlds", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# We're either training or validating.", "\n", "            ", "self", ".", "_update_metrics", "(", "\n", "action_strings", "=", "batch_action_strings", ",", "\n", "worlds", "=", "worlds", ",", "\n", "label_strings", "=", "label_strings", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "agenda_data", "=", "agenda_data", ",", "\n", ")", "\n", "", "else", ":", "\n", "# We're testing.", "\n", "            ", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "outputs", "[", "\"sentence_tokens\"", "]", "=", "[", "x", "[", "\"sentence_tokens\"", "]", "for", "x", "in", "metadata", "]", "\n", "", "outputs", "[", "\"debug_info\"", "]", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "outputs", "[", "\"debug_info\"", "]", ".", "append", "(", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "debug_info", "[", "0", "]", ")", "# type: ignore", "\n", "", "outputs", "[", "\"best_action_strings\"", "]", "=", "batch_action_strings", "\n", "outputs", "[", "\"denotations\"", "]", "=", "batch_denotations", "\n", "action_mapping", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_actions", "in", "enumerate", "(", "actions", ")", ":", "\n", "                ", "for", "action_index", ",", "action", "in", "enumerate", "(", "batch_actions", ")", ":", "\n", "                    ", "action_mapping", "[", "(", "batch_index", ",", "action_index", ")", "]", "=", "action", "[", "0", "]", "\n", "", "", "outputs", "[", "\"action_mapping\"", "]", "=", "action_mapping", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_checklist_info": [[301, 343], ["enumerate", "agenda.new_tensor", "agenda.new_tensor", "int", "torch.ones_like", "agenda.squeeze().detach().cpu().numpy", "terminal_indices.append", "target_checklist_list.append", "target_checklist_list.append", "agenda.squeeze().detach().cpu", "agenda.squeeze().detach", "agenda.squeeze"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_checklist_info", "(", "\n", "self", ",", "agenda", ":", "torch", ".", "LongTensor", ",", "all_actions", ":", "List", "[", "ProductionRule", "]", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Takes an agenda and a list of all actions and returns a target checklist against which the\n        checklist at each state will be compared to compute a loss, indices of ``terminal_actions``,\n        and a ``checklist_mask`` that indicates which of the terminal actions are relevant for\n        checklist loss computation. If ``self.penalize_non_agenda_actions`` is set to``True``,\n        ``checklist_mask`` will be all 1s (i.e., all terminal actions are relevant). If it is set to\n        ``False``, indices of all terminals that are not in the agenda will be masked.\n\n        Parameters\n        ----------\n        ``agenda`` : ``torch.LongTensor``\n            Agenda of one instance of size ``(agenda_size, 1)``.\n        ``all_actions`` : ``List[ProductionRule]``\n            All actions for one instance.\n        \"\"\"", "\n", "terminal_indices", "=", "[", "]", "\n", "target_checklist_list", "=", "[", "]", "\n", "agenda_indices_set", "=", "{", "int", "(", "x", ")", "for", "x", "in", "agenda", ".", "squeeze", "(", "0", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "}", "\n", "for", "index", ",", "action", "in", "enumerate", "(", "all_actions", ")", ":", "\n", "# Each action is a ProductionRule, a tuple where the first item is the production", "\n", "# rule string.", "\n", "            ", "if", "action", "[", "0", "]", "in", "self", ".", "_terminal_productions", ":", "\n", "                ", "terminal_indices", ".", "append", "(", "[", "index", "]", ")", "\n", "if", "index", "in", "agenda_indices_set", ":", "\n", "                    ", "target_checklist_list", ".", "append", "(", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "target_checklist_list", ".", "append", "(", "[", "0", "]", ")", "\n", "# We want to return checklist target and terminal actions that are column vectors to make", "\n", "# computing softmax over the difference between checklist and target easier.", "\n", "# (num_terminals, 1)", "\n", "", "", "", "terminal_actions", "=", "agenda", ".", "new_tensor", "(", "terminal_indices", ")", "\n", "# (num_terminals, 1)", "\n", "target_checklist", "=", "agenda", ".", "new_tensor", "(", "target_checklist_list", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "self", ".", "_penalize_non_agenda_actions", ":", "\n", "# All terminal actions are relevant", "\n", "            ", "checklist_mask", "=", "torch", ".", "ones_like", "(", "target_checklist", ")", "\n", "", "else", ":", "\n", "            ", "checklist_mask", "=", "(", "target_checklist", "!=", "0", ")", ".", "float", "(", ")", "\n", "", "return", "target_checklist", ",", "terminal_actions", ",", "checklist_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._update_metrics": [[344, 384], ["len", "range", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._consistency", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._agenda_coverage", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._check_denotation", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._denotation_accuracy", "sum", "len", "all", "action_string.split", "right_side.isdigit", "terminal_agenda_actions.append", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._check_denotation", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_update_metrics", "(", "\n", "self", ",", "\n", "action_strings", ":", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", ",", "\n", "worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", ",", "\n", "label_strings", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "possible_actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "agenda_data", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", ")", "->", "None", ":", "\n", "# TODO(pradeep): Move this to the base class.", "\n", "# TODO(pradeep): action_strings contains k-best lists. This method only uses the top decoded", "\n", "# sequence currently. Maybe define top-k metrics?", "\n", "        ", "batch_size", "=", "len", "(", "worlds", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# Using only the top decoded sequence per instance.", "\n", "            ", "instance_action_strings", "=", "action_strings", "[", "i", "]", "[", "0", "]", "if", "action_strings", "[", "i", "]", "else", "[", "]", "\n", "sequence_is_correct", "=", "[", "False", "]", "\n", "in_agenda_ratio", "=", "0.0", "\n", "instance_possible_actions", "=", "possible_actions", "[", "i", "]", "\n", "if", "instance_action_strings", ":", "\n", "                ", "terminal_agenda_actions", "=", "[", "]", "\n", "for", "rule_id", "in", "agenda_data", "[", "i", "]", ":", "\n", "                    ", "if", "rule_id", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "action_string", "=", "instance_possible_actions", "[", "rule_id", "]", "[", "0", "]", "\n", "right_side", "=", "action_string", ".", "split", "(", "\" -> \"", ")", "[", "1", "]", "\n", "if", "right_side", ".", "isdigit", "(", ")", "or", "(", "\"[\"", "not", "in", "right_side", "and", "len", "(", "right_side", ")", ">", "1", ")", ":", "\n", "                        ", "terminal_agenda_actions", ".", "append", "(", "action_string", ")", "\n", "", "", "actions_in_agenda", "=", "[", "\n", "action", "in", "instance_action_strings", "for", "action", "in", "terminal_agenda_actions", "\n", "]", "\n", "in_agenda_ratio", "=", "sum", "(", "actions_in_agenda", ")", "/", "len", "(", "actions_in_agenda", ")", "\n", "instance_label_strings", "=", "label_strings", "[", "i", "]", "\n", "instance_worlds", "=", "worlds", "[", "i", "]", "\n", "sequence_is_correct", "=", "self", ".", "_check_denotation", "(", "\n", "instance_action_strings", ",", "instance_label_strings", ",", "instance_worlds", "\n", ")", "\n", "", "for", "correct_in_world", "in", "sequence_is_correct", ":", "\n", "                ", "self", ".", "_denotation_accuracy", "(", "1", "if", "correct_in_world", "else", "0", ")", "\n", "", "self", ".", "_consistency", "(", "1", "if", "all", "(", "sequence_is_correct", ")", "else", "0", ")", "\n", "self", ".", "_agenda_coverage", "(", "in_agenda_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser.get_metrics": [[385, 391], ["nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._denotation_accuracy.get_metric", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._consistency.get_metric", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._agenda_coverage.get_metric"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "return", "{", "\n", "\"denotation_accuracy\"", ":", "self", ".", "_denotation_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"consistency\"", ":", "self", ".", "_consistency", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"agenda_coverage\"", ":", "self", ".", "_agenda_coverage", ".", "get_metric", "(", "reset", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_cost": [[393, 427], ["state.checklist_state[].get_balance", "torch.sum", "torch.sum", "state.is_finished", "RuntimeError", "state.checklist_state[].checklist_target.float", "all", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._check_state_denotations"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.get_balance", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._check_state_denotations"], ["", "def", "_get_state_cost", "(", "\n", "self", ",", "batch_worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", ",", "state", ":", "CoverageState", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Return the cost of a finished state. Since it is a finished state, the group size will be\n        1, and hence we'll return just one cost.\n\n        The ``batch_worlds`` parameter here is because we need the world to check the denotation\n        accuracy of the action sequence in the finished state.  Instead of adding a field to the\n        ``State`` object just for this method, we take the ``World`` as a parameter here.\n        \"\"\"", "\n", "if", "not", "state", ".", "is_finished", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"_get_state_cost() is not defined for unfinished states!\"", ")", "\n", "", "instance_worlds", "=", "batch_worlds", "[", "state", ".", "batch_indices", "[", "0", "]", "]", "\n", "# Our checklist cost is a sum of squared error from where we want to be, making sure we", "\n", "# take into account the mask.", "\n", "checklist_balance", "=", "state", ".", "checklist_state", "[", "0", "]", ".", "get_balance", "(", ")", "\n", "checklist_cost", "=", "torch", ".", "sum", "(", "(", "checklist_balance", ")", "**", "2", ")", "\n", "\n", "# This is the number of items on the agenda that we want to see in the decoded sequence.", "\n", "# We use this as the denotation cost if the path is incorrect.", "\n", "# Note: If we are penalizing the model for producing non-agenda actions, this is not the", "\n", "# upper limit on the checklist cost. That would be the number of terminal actions.", "\n", "denotation_cost", "=", "torch", ".", "sum", "(", "state", ".", "checklist_state", "[", "0", "]", ".", "checklist_target", ".", "float", "(", ")", ")", "\n", "checklist_cost", "=", "self", ".", "_checklist_cost_weight", "*", "checklist_cost", "\n", "# TODO (pradeep): The denotation based cost below is strict. May be define a cost based on", "\n", "# how many worlds the logical form is correct in?", "\n", "# extras being None happens when we are testing. We do not care about the cost", "\n", "# then.  TODO (pradeep): Make this cleaner.", "\n", "if", "state", ".", "extras", "is", "None", "or", "all", "(", "self", ".", "_check_state_denotations", "(", "state", ",", "instance_worlds", ")", ")", ":", "\n", "            ", "cost", "=", "checklist_cost", "\n", "", "else", ":", "\n", "            ", "cost", "=", "checklist_cost", "+", "(", "1", "-", "self", ".", "_checklist_cost_weight", ")", "*", "denotation_cost", "\n", "", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_info": [[428, 467], ["state.is_finished", "float", "zip", "agenda_sequences.append", "all_agenda_indices.append", "len", "float", "score.detach().cpu().numpy", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_action_string", "int", "int", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_cost().detach().cpu().numpy", "action.detach().cpu().numpy", "is_wanted.detach().cpu().numpy", "agenda_indices.append", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_action_string", "score.detach().cpu", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_cost().detach().cpu", "action.detach().cpu", "is_wanted.detach().cpu", "score.detach", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_cost().detach", "action.detach", "is_wanted.detach", "nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_cost"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_state_cost"], ["", "def", "_get_state_info", "(", "\n", "self", ",", "state", ":", "CoverageState", ",", "batch_worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "]", ":", "\n", "        ", "\"\"\"\n        This method is here for debugging purposes, in case you want to look at the what the model\n        is learning. It may be inefficient to call it while training the model on real data.\n        \"\"\"", "\n", "if", "len", "(", "state", ".", "batch_indices", ")", "==", "1", "and", "state", ".", "is_finished", "(", ")", ":", "\n", "            ", "costs", "=", "[", "float", "(", "self", ".", "_get_state_cost", "(", "batch_worlds", ",", "state", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "costs", "=", "[", "]", "\n", "", "model_scores", "=", "[", "float", "(", "score", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "for", "score", "in", "state", ".", "score", "]", "\n", "all_actions", "=", "state", ".", "possible_actions", "[", "0", "]", "\n", "action_sequences", "=", "[", "\n", "[", "self", ".", "_get_action_string", "(", "all_actions", "[", "action", "]", ")", "for", "action", "in", "history", "]", "\n", "for", "history", "in", "state", ".", "action_history", "\n", "]", "\n", "agenda_sequences", "=", "[", "]", "\n", "all_agenda_indices", "=", "[", "]", "\n", "for", "checklist_state", "in", "state", ".", "checklist_state", ":", "\n", "            ", "agenda_indices", "=", "[", "]", "\n", "for", "action", ",", "is_wanted", "in", "zip", "(", "\n", "checklist_state", ".", "terminal_actions", ",", "checklist_state", ".", "checklist_target", "\n", ")", ":", "\n", "                ", "action_int", "=", "int", "(", "action", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "is_wanted_int", "=", "int", "(", "is_wanted", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "is_wanted_int", "!=", "0", ":", "\n", "                    ", "agenda_indices", ".", "append", "(", "action_int", ")", "\n", "", "", "agenda_sequences", ".", "append", "(", "\n", "[", "self", ".", "_get_action_string", "(", "all_actions", "[", "action", "]", ")", "for", "action", "in", "agenda_indices", "]", "\n", ")", "\n", "all_agenda_indices", ".", "append", "(", "agenda_indices", ")", "\n", "", "return", "{", "\n", "\"agenda\"", ":", "agenda_sequences", ",", "\n", "\"agenda_indices\"", ":", "all_agenda_indices", ",", "\n", "\"history\"", ":", "action_sequences", ",", "\n", "\"history_indices\"", ":", "state", ".", "action_history", ",", "\n", "\"costs\"", ":", "costs", ",", "\n", "\"scores\"", ":", "model_scores", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser.__init__": [[48, 78], ["allennlp.models.model.Model.__init__", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.modules.Embedding", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.Dropout", "torch.FloatTensor", "vocab.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "sentence_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "rule_namespace", ":", "str", "=", "\"rule_labels\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "NlvrSemanticParser", ",", "self", ")", ".", "__init__", "(", "vocab", "=", "vocab", ")", "\n", "\n", "self", ".", "_sentence_embedder", "=", "sentence_embedder", "\n", "self", ".", "_denotation_accuracy", "=", "Average", "(", ")", "\n", "self", ".", "_consistency", "=", "Average", "(", ")", "\n", "self", ".", "_encoder", "=", "encoder", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dropout", "=", "lambda", "x", ":", "x", "\n", "", "self", ".", "_rule_namespace", "=", "rule_namespace", "\n", "\n", "self", ".", "_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "vocab", ".", "get_vocab_size", "(", "self", ".", "_rule_namespace", ")", ",", "\n", "embedding_dim", "=", "action_embedding_dim", ",", "\n", ")", "\n", "\n", "# This is what we pass as input in the first step of decoding, when we don't have a", "\n", "# previous action.", "\n", "self", ".", "_first_action_embedding", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "action_embedding_dim", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_action_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser.forward": [[79, 83], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ")", ":", "# type: ignore", "\n", "# Sub-classes should define their own logic here.", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_initial_rnn_state": [[84, 116], ["nlvr_semantic_parser.NlvrSemanticParser._sentence_embedder", "allennlp.nn.util.get_text_field_mask", "nlvr_semantic_parser.NlvrSemanticParser.size", "nlvr_semantic_parser.NlvrSemanticParser._dropout", "allennlp.nn.util.get_final_encoder_states", "nlvr_semantic_parser.NlvrSemanticParser.new_zeros", "nlvr_semantic_parser.NlvrSemanticParser._decoder_step.attend_on_question", "range", "nlvr_semantic_parser.NlvrSemanticParser._encoder", "nlvr_semantic_parser.NlvrSemanticParser._encoder.is_bidirectional", "nlvr_semantic_parser.NlvrSemanticParser._encoder.get_output_dim", "initial_rnn_state.append", "range", "range", "allennlp_semparse.state_machines.states.RnnStatelet"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.attend_on_question", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_initial_rnn_state", "(", "self", ",", "sentence", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ")", ":", "\n", "        ", "embedded_input", "=", "self", ".", "_sentence_embedder", "(", "sentence", ")", "\n", "# (batch_size, sentence_length)", "\n", "sentence_mask", "=", "util", ".", "get_text_field_mask", "(", "sentence", ")", "\n", "\n", "batch_size", "=", "embedded_input", ".", "size", "(", "0", ")", "\n", "\n", "# (batch_size, sentence_length, encoder_output_dim)", "\n", "encoder_outputs", "=", "self", ".", "_dropout", "(", "self", ".", "_encoder", "(", "embedded_input", ",", "sentence_mask", ")", ")", "\n", "\n", "final_encoder_output", "=", "util", ".", "get_final_encoder_states", "(", "\n", "encoder_outputs", ",", "sentence_mask", ",", "self", ".", "_encoder", ".", "is_bidirectional", "(", ")", "\n", ")", "\n", "memory_cell", "=", "encoder_outputs", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ")", "\n", "attended_sentence", ",", "_", "=", "self", ".", "_decoder_step", ".", "attend_on_question", "(", "\n", "final_encoder_output", ",", "encoder_outputs", ",", "sentence_mask", "\n", ")", "\n", "encoder_outputs_list", "=", "[", "encoder_outputs", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "sentence_mask_list", "=", "[", "sentence_mask", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_rnn_state", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "initial_rnn_state", ".", "append", "(", "\n", "RnnStatelet", "(", "\n", "final_encoder_output", "[", "i", "]", ",", "\n", "memory_cell", "[", "i", "]", ",", "\n", "self", ".", "_first_action_embedding", ",", "\n", "attended_sentence", "[", "i", "]", ",", "\n", "encoder_outputs_list", ",", "\n", "sentence_mask_list", ",", "\n", ")", "\n", ")", "\n", "", "return", "initial_rnn_state", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_label_strings": [[117, 130], ["labels.detach().cpu", "label_strings.append", "labels.detach", "int", "label_strings[].append", "nlvr_semantic_parser.NlvrSemanticParser.vocab.get_token_from_index"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_label_strings", "(", "self", ",", "labels", ")", ":", "\n", "# TODO (pradeep): Use an unindexed field for labels?", "\n", "        ", "labels_data", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "label_strings", ":", "List", "[", "List", "[", "str", "]", "]", "=", "[", "]", "\n", "for", "instance_labels_data", "in", "labels_data", ":", "\n", "            ", "label_strings", ".", "append", "(", "[", "]", ")", "\n", "for", "label", "in", "instance_labels_data", ":", "\n", "                ", "label_int", "=", "int", "(", "label", ")", "\n", "if", "label_int", "==", "-", "1", ":", "\n", "# Padding, because not all instances have the same number of labels.", "\n", "                    ", "continue", "\n", "", "label_strings", "[", "-", "1", "]", ".", "append", "(", "self", ".", "vocab", ".", "get_token_from_index", "(", "label_int", ",", "\"denotations\"", ")", ")", "\n", "", "", "return", "label_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_action_strings": [[131, 155], ["len", "range", "all_action_strings.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "classmethod", "\n", "def", "_get_action_strings", "(", "\n", "cls", ",", "\n", "possible_actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "action_indices", ":", "Dict", "[", "int", ",", "List", "[", "List", "[", "int", "]", "]", "]", ",", "\n", ")", "->", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Takes a list of possible actions and indices of decoded actions into those possible actions\n        for a batch and returns sequences of action strings. We assume ``action_indices`` is a dict\n        mapping batch indices to k-best decoded sequence lists.\n        \"\"\"", "\n", "all_action_strings", ":", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", "=", "[", "]", "\n", "batch_size", "=", "len", "(", "possible_actions", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "batch_actions", "=", "possible_actions", "[", "i", "]", "\n", "batch_best_sequences", "=", "action_indices", "[", "i", "]", "if", "i", "in", "action_indices", "else", "[", "]", "\n", "# This will append an empty list to ``all_action_strings`` if ``batch_best_sequences``", "\n", "# is empty.", "\n", "action_strings", "=", "[", "\n", "[", "batch_actions", "[", "rule_id", "]", "[", "0", "]", "for", "rule_id", "in", "sequence", "]", "\n", "for", "sequence", "in", "batch_best_sequences", "\n", "]", "\n", "all_action_strings", ".", "append", "(", "action_strings", ")", "\n", "", "return", "all_action_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_denotations": [[156, 178], ["zip", "all_denotations.append", "instance_worlds[].action_sequence_to_logical_form", "denotations.append", "instance_denotations.append", "str", "world.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "@", "staticmethod", "\n", "def", "_get_denotations", "(", "\n", "action_strings", ":", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", ",", "worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", "\n", ")", "->", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", ":", "\n", "        ", "all_denotations", ":", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", "=", "[", "]", "\n", "for", "instance_worlds", ",", "instance_action_sequences", "in", "zip", "(", "worlds", ",", "action_strings", ")", ":", "\n", "            ", "denotations", ":", "List", "[", "List", "[", "str", "]", "]", "=", "[", "]", "\n", "for", "instance_action_strings", "in", "instance_action_sequences", ":", "\n", "                ", "if", "not", "instance_action_strings", ":", "\n", "                    ", "continue", "\n", "", "logical_form", "=", "instance_worlds", "[", "0", "]", ".", "action_sequence_to_logical_form", "(", "\n", "instance_action_strings", "\n", ")", "\n", "instance_denotations", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "for", "world", "in", "instance_worlds", ":", "\n", "# Some of the worlds can be None for instances that come with less than 4 worlds", "\n", "# because of padding.", "\n", "                    ", "if", "world", "is", "not", "None", ":", "\n", "                        ", "instance_denotations", ".", "append", "(", "str", "(", "world", ".", "execute", "(", "logical_form", ")", ")", ")", "\n", "", "", "denotations", ".", "append", "(", "instance_denotations", ")", "\n", "", "all_denotations", ".", "append", "(", "denotations", ")", "\n", "", "return", "all_denotations", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._check_denotation": [[179, 189], ["zip", "world.action_sequence_to_logical_form", "world.execute", "is_correct.append", "str().lower", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "@", "staticmethod", "\n", "def", "_check_denotation", "(", "\n", "action_sequence", ":", "List", "[", "str", "]", ",", "labels", ":", "List", "[", "str", "]", ",", "worlds", ":", "List", "[", "NlvrLanguage", "]", "\n", ")", "->", "List", "[", "bool", "]", ":", "\n", "        ", "is_correct", "=", "[", "]", "\n", "for", "world", ",", "label", "in", "zip", "(", "worlds", ",", "labels", ")", ":", "\n", "            ", "logical_form", "=", "world", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "\n", "denotation", "=", "world", ".", "execute", "(", "logical_form", ")", "\n", "is_correct", ".", "append", "(", "str", "(", "denotation", ")", ".", "lower", "(", ")", "==", "label", ")", "\n", "", "return", "is_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._create_grammar_state": [[190, 218], ["world.get_nonterminal_productions", "enumerate", "world.get_nonterminal_productions.items", "allennlp_semparse.state_machines.states.GrammarStatelet", "zip", "torch.cat", "nlvr_semantic_parser.NlvrSemanticParser._action_embedder", "list"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions"], ["", "def", "_create_grammar_state", "(", "\n", "self", ",", "world", ":", "NlvrLanguage", ",", "possible_actions", ":", "List", "[", "ProductionRule", "]", "\n", ")", "->", "GrammarStatelet", ":", "\n", "        ", "valid_actions", "=", "world", ".", "get_nonterminal_productions", "(", ")", "\n", "action_mapping", "=", "{", "}", "\n", "for", "i", ",", "action", "in", "enumerate", "(", "possible_actions", ")", ":", "\n", "            ", "action_mapping", "[", "action", "[", "0", "]", "]", "=", "i", "\n", "", "translated_valid_actions", ":", "Dict", "[", "\n", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", "\n", "]", "=", "{", "}", "\n", "for", "key", ",", "action_strings", "in", "valid_actions", ".", "items", "(", ")", ":", "\n", "            ", "translated_valid_actions", "[", "key", "]", "=", "{", "}", "\n", "# `key` here is a non-terminal from the grammar, and `action_strings` are all the valid", "\n", "# productions of that non-terminal.", "\n", "action_indices", "=", "[", "action_mapping", "[", "action_string", "]", "for", "action_string", "in", "action_strings", "]", "\n", "# All actions in NLVR are global actions.", "\n", "global_actions", "=", "[", "(", "possible_actions", "[", "index", "]", "[", "2", "]", ",", "index", ")", "for", "index", "in", "action_indices", "]", "\n", "\n", "# Then we get the embedded representations of the global actions.", "\n", "global_action_tensors", ",", "global_action_ids", "=", "zip", "(", "*", "global_actions", ")", "\n", "global_action_tensor", "=", "torch", ".", "cat", "(", "global_action_tensors", ",", "dim", "=", "0", ")", "\n", "global_input_embeddings", "=", "self", ".", "_action_embedder", "(", "global_action_tensor", ")", "\n", "translated_valid_actions", "[", "key", "]", "[", "\"global\"", "]", "=", "(", "\n", "global_input_embeddings", ",", "\n", "global_input_embeddings", ",", "\n", "list", "(", "global_action_ids", ")", ",", "\n", ")", "\n", "", "return", "GrammarStatelet", "(", "[", "START_SYMBOL", "]", ",", "translated_valid_actions", ",", "world", ".", "is_nonterminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser.make_output_human_readable": [[219, 270], ["allennlp_semparse.domain_languages.NlvrLanguage", "enumerate", "set", "logical_forms.append", "zip", "zip", "batch_action_info.append", "zip", "actions.sort", "zip", "action_debug_info.get", "instance_action_info.append", "instance_logical_forms.append", "instance_logical_forms.append", "allennlp_semparse.domain_languages.NlvrLanguage.action_sequence_to_logical_form", "actions.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "make_output_human_readable", "(", "\n", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        This method overrides ``Model.decode``, which gets called after ``Model.forward``, at test\n        time, to finalize predictions. We only transform the action string sequences into logical\n        forms here.\n        \"\"\"", "\n", "best_action_strings", "=", "output_dict", "[", "\"best_action_strings\"", "]", "\n", "# Instantiating an empty world for getting logical forms.", "\n", "world", "=", "NlvrLanguage", "(", "set", "(", ")", ")", "\n", "logical_forms", "=", "[", "]", "\n", "for", "instance_action_sequences", "in", "best_action_strings", ":", "\n", "            ", "instance_logical_forms", "=", "[", "]", "\n", "for", "action_strings", "in", "instance_action_sequences", ":", "\n", "                ", "if", "action_strings", ":", "\n", "                    ", "instance_logical_forms", ".", "append", "(", "\n", "world", ".", "action_sequence_to_logical_form", "(", "action_strings", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "instance_logical_forms", ".", "append", "(", "\"\"", ")", "\n", "", "", "logical_forms", ".", "append", "(", "instance_logical_forms", ")", "\n", "\n", "", "action_mapping", "=", "output_dict", "[", "\"action_mapping\"", "]", "\n", "best_actions", "=", "output_dict", "[", "\"best_action_strings\"", "]", "\n", "debug_infos", "=", "output_dict", "[", "\"debug_info\"", "]", "\n", "batch_action_info", "=", "[", "]", "\n", "for", "batch_index", ",", "(", "predicted_actions", ",", "debug_info", ")", "in", "enumerate", "(", "\n", "zip", "(", "best_actions", ",", "debug_infos", ")", "\n", ")", ":", "\n", "            ", "instance_action_info", "=", "[", "]", "\n", "for", "predicted_action", ",", "action_debug_info", "in", "zip", "(", "predicted_actions", "[", "0", "]", ",", "debug_info", ")", ":", "\n", "                ", "action_info", "=", "{", "}", "\n", "action_info", "[", "\"predicted_action\"", "]", "=", "predicted_action", "\n", "considered_actions", "=", "action_debug_info", "[", "\"considered_actions\"", "]", "\n", "probabilities", "=", "action_debug_info", "[", "\"probabilities\"", "]", "\n", "actions", "=", "[", "]", "\n", "for", "action", ",", "probability", "in", "zip", "(", "considered_actions", ",", "probabilities", ")", ":", "\n", "                    ", "if", "action", "!=", "-", "1", ":", "\n", "                        ", "actions", ".", "append", "(", "(", "action_mapping", "[", "(", "batch_index", ",", "action", ")", "]", ",", "probability", ")", ")", "\n", "", "", "actions", ".", "sort", "(", ")", "\n", "considered_actions", ",", "probabilities", "=", "zip", "(", "*", "actions", ")", "\n", "action_info", "[", "\"considered_actions\"", "]", "=", "considered_actions", "\n", "action_info", "[", "\"action_probabilities\"", "]", "=", "probabilities", "\n", "action_info", "[", "\"question_attention\"", "]", "=", "action_debug_info", ".", "get", "(", "\"question_attention\"", ",", "[", "]", ")", "\n", "instance_action_info", ".", "append", "(", "action_info", ")", "\n", "", "batch_action_info", ".", "append", "(", "instance_action_info", ")", "\n", "", "output_dict", "[", "\"predicted_actions\"", "]", "=", "batch_action_info", "\n", "output_dict", "[", "\"logical_form\"", "]", "=", "logical_forms", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._check_state_denotations": [[271, 286], ["state.is_finished", "nlvr_semantic_parser.NlvrSemanticParser._check_denotation"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._check_denotation"], ["", "def", "_check_state_denotations", "(", "\n", "self", ",", "state", ":", "GrammarBasedState", ",", "worlds", ":", "List", "[", "NlvrLanguage", "]", "\n", ")", "->", "List", "[", "bool", "]", ":", "\n", "        ", "\"\"\"\n        Returns whether action history in the state evaluates to the correct denotations over all\n        worlds. Only defined when the state is finished.\n        \"\"\"", "\n", "assert", "state", ".", "is_finished", "(", ")", ",", "\"Cannot compute denotations for unfinished states!\"", "\n", "# Since this is a finished state, its group size must be 1.", "\n", "batch_index", "=", "state", ".", "batch_indices", "[", "0", "]", "\n", "instance_label_strings", "=", "state", ".", "extras", "[", "batch_index", "]", "\n", "history", "=", "state", ".", "action_history", "[", "0", "]", "\n", "all_actions", "=", "state", ".", "possible_actions", "[", "0", "]", "\n", "action_sequence", "=", "[", "all_actions", "[", "action", "]", "[", "0", "]", "for", "action", "in", "history", "]", "\n", "return", "self", ".", "_check_denotation", "(", "action_sequence", ",", "instance_label_strings", ",", "worlds", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser.NlvrDirectSemanticParser.__init__": [[54, 84], ["allennlp_semparse.models.nlvr.nlvr_semantic_parser.NlvrSemanticParser.__init__", "allennlp_semparse.state_machines.trainers.MaximumMarginalLikelihood", "allennlp_semparse.state_machines.transition_functions.BasicTransitionFunction", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._encoder.get_output_dim", "allennlp.nn.Activation.by_name"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "sentence_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "attention", ":", "Attention", ",", "\n", "decoder_beam_search", ":", "BeamSearch", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "NlvrDirectSemanticParser", ",", "self", ")", ".", "__init__", "(", "\n", "vocab", "=", "vocab", ",", "\n", "sentence_embedder", "=", "sentence_embedder", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "encoder", "=", "encoder", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "_decoder_trainer", "=", "MaximumMarginalLikelihood", "(", ")", "\n", "self", ".", "_decoder_step", "=", "BasicTransitionFunction", "(", "\n", "encoder_output_dim", "=", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "attention", ",", "\n", "activation", "=", "Activation", ".", "by_name", "(", "\"tanh\"", ")", "(", ")", ",", "\n", "add_action_bias", "=", "False", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "_decoder_beam_search", "=", "decoder_beam_search", "\n", "self", ".", "_max_decoding_steps", "=", "max_decoding_steps", "\n", "self", ".", "_action_padding_index", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser.NlvrDirectSemanticParser.forward": [[85, 173], ["len", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._get_initial_rnn_state", "allennlp.nn.util.get_token_ids_from_text_field_tensors", "allennlp_semparse.state_machines.states.GrammarBasedState", "allennlp.nn.util.get_token_ids_from_text_field_tensors.new_zeros", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._get_label_strings", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._create_grammar_state", "target_action_sequences.squeeze.squeeze.squeeze", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._decoder_trainer.decode", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._decoder_beam_search.search", "range", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._get_action_strings", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._get_denotations", "range", "range", "list", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._update_metrics", "range", "enumerate", "range", "range", "outputs[].append", "enumerate", "range"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_initial_rnn_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_label_strings", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._create_grammar_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_action_strings", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._get_denotations", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser.NlvrDirectSemanticParser._update_metrics", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "forward", "(", "\n", "self", ",", "# type: ignore", "\n", "sentence", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "identifier", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "target_action_sequences", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "labels", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Decoder logic for producing type constrained target sequences, trained to maximize marginal\n        likelihod over a set of approximate logical forms.\n        \"\"\"", "\n", "batch_size", "=", "len", "(", "worlds", ")", "\n", "\n", "initial_rnn_state", "=", "self", ".", "_get_initial_rnn_state", "(", "sentence", ")", "\n", "token_ids", "=", "util", ".", "get_token_ids_from_text_field_tensors", "(", "sentence", ")", "\n", "initial_score_list", "=", "[", "token_ids", ".", "new_zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "label_strings", "=", "self", ".", "_get_label_strings", "(", "labels", ")", "if", "labels", "is", "not", "None", "else", "None", "\n", "# TODO (pradeep): Assuming all worlds give the same set of valid actions.", "\n", "initial_grammar_state", "=", "[", "\n", "self", ".", "_create_grammar_state", "(", "worlds", "[", "i", "]", "[", "0", "]", ",", "actions", "[", "i", "]", ")", "for", "i", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "initial_state", "=", "GrammarBasedState", "(", "\n", "batch_indices", "=", "list", "(", "range", "(", "batch_size", ")", ")", ",", "\n", "action_history", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "\n", "score", "=", "initial_score_list", ",", "\n", "rnn_state", "=", "initial_rnn_state", ",", "\n", "grammar_state", "=", "initial_grammar_state", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "extras", "=", "label_strings", ",", "\n", ")", "\n", "\n", "if", "target_action_sequences", "is", "not", "None", ":", "\n", "# Remove the trailing dimension (from ListField[ListField[IndexField]]).", "\n", "            ", "target_action_sequences", "=", "target_action_sequences", ".", "squeeze", "(", "-", "1", ")", "\n", "target_mask", "=", "target_action_sequences", "!=", "self", ".", "_action_padding_index", "\n", "", "else", ":", "\n", "            ", "target_mask", "=", "None", "\n", "\n", "", "outputs", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "=", "{", "}", "\n", "if", "identifier", "is", "not", "None", ":", "\n", "            ", "outputs", "[", "\"identifier\"", "]", "=", "identifier", "\n", "", "if", "target_action_sequences", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "self", ".", "_decoder_trainer", ".", "decode", "(", "\n", "initial_state", ",", "self", ".", "_decoder_step", ",", "(", "target_action_sequences", ",", "target_mask", ")", "\n", ")", "\n", "", "if", "not", "self", ".", "training", ":", "\n", "            ", "initial_state", ".", "debug_info", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "best_final_states", "=", "self", ".", "_decoder_beam_search", ".", "search", "(", "\n", "self", ".", "_max_decoding_steps", ",", "\n", "initial_state", ",", "\n", "self", ".", "_decoder_step", ",", "\n", "keep_final_unfinished_states", "=", "False", ",", "\n", ")", "\n", "best_action_sequences", ":", "Dict", "[", "int", ",", "List", "[", "List", "[", "int", "]", "]", "]", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# Decoding may not have terminated with any completed logical forms, if `num_steps`", "\n", "# isn't long enough (or if the model is not trained enough and gets into an", "\n", "# infinite action loop).", "\n", "                ", "if", "i", "in", "best_final_states", ":", "\n", "                    ", "best_action_indices", "=", "[", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "]", "\n", "best_action_sequences", "[", "i", "]", "=", "best_action_indices", "\n", "", "", "batch_action_strings", "=", "self", ".", "_get_action_strings", "(", "actions", ",", "best_action_sequences", ")", "\n", "batch_denotations", "=", "self", ".", "_get_denotations", "(", "batch_action_strings", ",", "worlds", ")", "\n", "if", "target_action_sequences", "is", "not", "None", ":", "\n", "                ", "self", ".", "_update_metrics", "(", "\n", "action_strings", "=", "batch_action_strings", ",", "worlds", "=", "worlds", ",", "label_strings", "=", "label_strings", "\n", ")", "\n", "", "else", ":", "\n", "                ", "if", "metadata", "is", "not", "None", ":", "\n", "                    ", "outputs", "[", "\"sentence_tokens\"", "]", "=", "[", "x", "[", "\"sentence_tokens\"", "]", "for", "x", "in", "metadata", "]", "\n", "", "outputs", "[", "\"debug_info\"", "]", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "outputs", "[", "\"debug_info\"", "]", ".", "append", "(", "\n", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "debug_info", "[", "0", "]", "\n", ")", "# type: ignore", "\n", "", "outputs", "[", "\"best_action_strings\"", "]", "=", "batch_action_strings", "\n", "outputs", "[", "\"denotations\"", "]", "=", "batch_denotations", "\n", "action_mapping", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_actions", "in", "enumerate", "(", "actions", ")", ":", "\n", "                    ", "for", "action_index", ",", "action", "in", "enumerate", "(", "batch_actions", ")", ":", "\n", "                        ", "action_mapping", "[", "(", "batch_index", ",", "action_index", ")", "]", "=", "action", "[", "0", "]", "\n", "", "", "outputs", "[", "\"action_mapping\"", "]", "=", "action_mapping", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser.NlvrDirectSemanticParser._update_metrics": [[174, 196], ["len", "range", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._consistency", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._check_denotation", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._denotation_accuracy", "all"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_semantic_parser.NlvrSemanticParser._check_denotation"], ["", "def", "_update_metrics", "(", "\n", "self", ",", "\n", "action_strings", ":", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", ",", "\n", "worlds", ":", "List", "[", "List", "[", "NlvrLanguage", "]", "]", ",", "\n", "label_strings", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", ")", "->", "None", ":", "\n", "# TODO(pradeep): Move this to the base class.", "\n", "# TODO(pradeep): Using only the best decoded sequence. Define metrics for top-k sequences?", "\n", "        ", "batch_size", "=", "len", "(", "worlds", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "instance_action_strings", "=", "action_strings", "[", "i", "]", "\n", "sequence_is_correct", "=", "[", "False", "]", "\n", "if", "instance_action_strings", ":", "\n", "                ", "instance_label_strings", "=", "label_strings", "[", "i", "]", "\n", "instance_worlds", "=", "worlds", "[", "i", "]", "\n", "# Taking only the best sequence.", "\n", "sequence_is_correct", "=", "self", ".", "_check_denotation", "(", "\n", "instance_action_strings", "[", "0", "]", ",", "instance_label_strings", ",", "instance_worlds", "\n", ")", "\n", "", "for", "correct_in_world", "in", "sequence_is_correct", ":", "\n", "                ", "self", ".", "_denotation_accuracy", "(", "1", "if", "correct_in_world", "else", "0", ")", "\n", "", "self", ".", "_consistency", "(", "1", "if", "all", "(", "sequence_is_correct", ")", "else", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser.NlvrDirectSemanticParser.get_metrics": [[197, 202], ["nlvr_direct_semantic_parser.NlvrDirectSemanticParser._denotation_accuracy.get_metric", "nlvr_direct_semantic_parser.NlvrDirectSemanticParser._consistency.get_metric"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "return", "{", "\n", "\"denotation_accuracy\"", ":", "self", ".", "_denotation_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"consistency\"", ":", "self", ".", "_consistency", ".", "get_metric", "(", "reset", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.setup_method": [[13, 18], ["super().setup_method", "nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.set_up_model"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "set_up_model", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"experiment.json\"", ",", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_grouped_data.jsonl\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_model_can_train_save_and_load": [[20, 22], ["nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "def", "test_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_ungrouped_model_can_train_save_and_load": [[23, 26], ["nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "def", "test_ungrouped_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"ungrouped_experiment.json\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_mml_initialized_model_can_train_save_and_load": [[28, 31], ["nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "def", "test_mml_initialized_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"mml_init_experiment.json\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_get_checklist_info": [[33, 50], ["torch.Tensor", "nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.model._get_checklist_info", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "target_checklist.data.numpy", "terminal_actions.data.numpy", "checklist_mask.data.numpy"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_checklist_info"], ["", "def", "test_get_checklist_info", "(", "self", ")", ":", "\n", "# Creating a fake all_actions field where actions 0, 2 and 4 are terminal productions.", "\n", "        ", "all_actions", "=", "[", "\n", "(", "\"<Set[Object]:Set[Object]> -> top\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"fake_action\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"Color -> color_black\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"fake_action2\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"int -> 6\"", ",", "True", ",", "None", ")", ",", "\n", "]", "\n", "# Of the actions above, those at indices 0 and 4 are on the agenda, and there are padding", "\n", "# indices at the end.", "\n", "test_agenda", "=", "torch", ".", "Tensor", "(", "[", "[", "0", "]", ",", "[", "4", "]", ",", "[", "-", "1", "]", ",", "[", "-", "1", "]", "]", ")", "\n", "checklist_info", "=", "self", ".", "model", ".", "_get_checklist_info", "(", "test_agenda", ",", "all_actions", ")", "\n", "target_checklist", ",", "terminal_actions", ",", "checklist_mask", "=", "checklist_info", "\n", "assert_almost_equal", "(", "target_checklist", ".", "data", ".", "numpy", "(", ")", ",", "[", "[", "1", "]", ",", "[", "0", "]", ",", "[", "1", "]", "]", ")", "\n", "assert_almost_equal", "(", "terminal_actions", ".", "data", ".", "numpy", "(", ")", ",", "[", "[", "0", "]", ",", "[", "2", "]", ",", "[", "4", "]", "]", ")", "\n", "assert_almost_equal", "(", "checklist_mask", ".", "data", ".", "numpy", "(", ")", ",", "[", "[", "1", "]", ",", "[", "1", "]", ",", "[", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_initialize_weights_from_archive": [[51, 74], ["nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.model.named_parameters", "allennlp.models.archival.load_archive", "allennlp.models.archival.load_archive.model.named_parameters", "nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.model._initialize_weights_from_archive", "dict", "parameter.data.clone().numpy", "nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.model.named_parameters", "archived_parameter.data.numpy", "changed_model_parameters[].data.numpy", "numpy.testing.assert_almost_equal", "pytest.raises", "numpy.testing.assert_almost_equal", "parameter.data.clone"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._initialize_weights_from_archive"], ["", "def", "test_initialize_weights_from_archive", "(", "self", ")", ":", "\n", "        ", "original_model_parameters", "=", "self", ".", "model", ".", "named_parameters", "(", ")", "\n", "original_model_weights", "=", "{", "\n", "name", ":", "parameter", ".", "data", ".", "clone", "(", ")", ".", "numpy", "(", ")", "for", "name", ",", "parameter", "in", "original_model_parameters", "\n", "}", "\n", "mml_model_archive_file", "=", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_direct_semantic_parser\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", ")", "\n", "archive", "=", "load_archive", "(", "mml_model_archive_file", ")", "\n", "archived_model_parameters", "=", "archive", ".", "model", ".", "named_parameters", "(", ")", "\n", "self", ".", "model", ".", "_initialize_weights_from_archive", "(", "archive", ")", "\n", "changed_model_parameters", "=", "dict", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ")", "\n", "for", "name", ",", "archived_parameter", "in", "archived_model_parameters", ":", "\n", "            ", "archived_weight", "=", "archived_parameter", ".", "data", ".", "numpy", "(", ")", "\n", "original_weight", "=", "original_model_weights", "[", "name", "]", "\n", "changed_weight", "=", "changed_model_parameters", "[", "name", "]", ".", "data", ".", "numpy", "(", ")", "\n", "# We want to make sure that the weights in the original model have indeed been changed", "\n", "# after a call to ``_initialize_weights_from_archive``.", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ",", "match", "=", "\"Arrays are not almost equal\"", ")", ":", "\n", "                ", "assert_almost_equal", "(", "original_weight", ",", "changed_weight", ")", "\n", "# This also includes the sentence token embedder. Those weights will be the same", "\n", "# because the two models have the same vocabulary.", "\n", "", "assert_almost_equal", "(", "archived_weight", ",", "changed_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_get_vocab_index_mapping": [[75, 97], ["allennlp.models.archival.load_archive", "nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.model._get_vocab_index_mapping", "allennlp.data.Vocabulary", "nlvr_coverage_semantic_parser_test.TestNlvrCoverageSemanticParser.test_get_vocab_index_mapping.copy_token_at_index"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_coverage_semantic_parser.NlvrCoverageSemanticParser._get_vocab_index_mapping"], ["", "", "def", "test_get_vocab_index_mapping", "(", "self", ")", ":", "\n", "        ", "mml_model_archive_file", "=", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_direct_semantic_parser\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", ")", "\n", "archive", "=", "load_archive", "(", "mml_model_archive_file", ")", "\n", "mapping", "=", "self", ".", "model", ".", "_get_vocab_index_mapping", "(", "archive", ".", "model", ".", "vocab", ")", "\n", "expected_mapping", "=", "[", "(", "i", ",", "i", ")", "for", "i", "in", "range", "(", "16", ")", "]", "\n", "assert", "mapping", "==", "expected_mapping", "\n", "\n", "new_vocab", "=", "Vocabulary", "(", ")", "\n", "\n", "def", "copy_token_at_index", "(", "i", ")", ":", "\n", "            ", "token", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "i", ",", "\"tokens\"", ")", "\n", "new_vocab", ".", "add_token_to_namespace", "(", "token", ",", "\"tokens\"", ")", "\n", "\n", "", "copy_token_at_index", "(", "5", ")", "\n", "copy_token_at_index", "(", "7", ")", "\n", "copy_token_at_index", "(", "10", ")", "\n", "mapping", "=", "self", ".", "model", ".", "_get_vocab_index_mapping", "(", "new_vocab", ")", "\n", "# Mapping of indices from model vocabulary to new vocabulary. 0 and 1 are padding and unk", "\n", "# tokens.", "\n", "assert", "mapping", "==", "[", "(", "0", ",", "0", ")", ",", "(", "1", ",", "1", ")", ",", "(", "5", ",", "2", ")", ",", "(", "7", ",", "3", ")", ",", "(", "10", ",", "4", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser_test.TestNlvrDirectSemanticParser.setup_method": [[5, 10], ["super().setup_method", "nlvr_direct_semantic_parser_test.TestNlvrDirectSemanticParser.set_up_model"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "set_up_model", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_direct_semantic_parser\"", "/", "\"experiment.json\"", ",", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_processed_data.jsonl\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.nlvr.nlvr_direct_semantic_parser_test.TestNlvrDirectSemanticParser.test_model_can_train_save_and_load": [[12, 14], ["nlvr_direct_semantic_parser_test.TestNlvrDirectSemanticParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "def", "test_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor._json_to_instance": [[17, 32], ["json_dict[].split", "wikitables_parser.WikiTablesParserPredictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Expects JSON that looks like ``{\"question\": \"...\", \"table\": \"...\"}``.\n        \"\"\"", "\n", "question_text", "=", "json_dict", "[", "\"question\"", "]", "\n", "table_rows", "=", "json_dict", "[", "\"table\"", "]", ".", "split", "(", "\"\\n\"", ")", "\n", "\n", "# We are directly passing the raw table rows here. The code in ``TableQuestionContext`` will do some", "\n", "# minimal processing to extract dates and numbers from the cells.", "\n", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "question_text", ",", "# type: ignore", "\n", "table_rows", ",", "\n", ")", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json": [[33, 93], ["wikitables_parser.WikiTablesParserPredictor._json_to_instance", "inputs.get", "torch.tensor", "original_beam_search.constrained_to", "wikitables_parser.WikiTablesParserPredictor.predict_instance", "enumerate", "original_beam_search.constrained_to.beam_snapshots.items", "next", "zip", "wikitables_parser.WikiTablesParserPredictor._model.parameters"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser.NlvrParserPredictor._json_to_instance", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.beam_search.BeamSearch.constrained_to", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.next"], ["", "@", "overrides", "\n", "def", "predict_json", "(", "self", ",", "inputs", ":", "JsonDict", ")", "->", "JsonDict", ":", "\n", "        ", "\"\"\"\n        We need to override this because of the interactive beam search aspects.\n        \"\"\"", "\n", "instance", "=", "self", ".", "_json_to_instance", "(", "inputs", ")", "\n", "\n", "# Get the rules out of the instance", "\n", "index_to_rule", "=", "[", "\n", "production_rule_field", ".", "rule", "\n", "for", "production_rule_field", "in", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", "\n", "]", "\n", "rule_to_index", "=", "{", "rule", ":", "i", "for", "i", ",", "rule", "in", "enumerate", "(", "index_to_rule", ")", "}", "\n", "\n", "# A sequence of strings to force, then convert them to ints", "\n", "initial_tokens", "=", "inputs", ".", "get", "(", "\"initial_sequence\"", ",", "[", "]", ")", "\n", "\n", "# Want to get initial_sequence on the same device as the model.", "\n", "initial_sequence", "=", "torch", ".", "tensor", "(", "\n", "[", "rule_to_index", "[", "token", "]", "for", "token", "in", "initial_tokens", "]", ",", "\n", "device", "=", "next", "(", "self", ".", "_model", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "\n", "# Replace beam search with one that forces the initial sequence", "\n", "original_beam_search", "=", "self", ".", "_model", ".", "_beam_search", "\n", "interactive_beam_search", "=", "original_beam_search", ".", "constrained_to", "(", "initial_sequence", ")", "\n", "self", ".", "_model", ".", "_beam_search", "=", "interactive_beam_search", "\n", "\n", "# Now get results", "\n", "results", "=", "self", ".", "predict_instance", "(", "instance", ")", "\n", "\n", "# And add in the choices. Need to convert from idxs to rules.", "\n", "results", "[", "\"choices\"", "]", "=", "[", "\n", "[", "\n", "(", "probability", ",", "action", ")", "\n", "for", "probability", ",", "action", "in", "zip", "(", "pa", "[", "\"action_probabilities\"", "]", ",", "pa", "[", "\"considered_actions\"", "]", ")", "\n", "]", "\n", "for", "pa", "in", "results", "[", "\"predicted_actions\"", "]", "\n", "]", "\n", "\n", "results", "[", "\"beam_snapshots\"", "]", "=", "{", "\n", "# For each batch_index, we get a list of beam snapshots", "\n", "batch_index", ":", "[", "\n", "# Each beam_snapshots consists of a list of timesteps,", "\n", "# each of which is a list of pairs (score, sequence).", "\n", "# The sequence is the *indices* of the rules, which we", "\n", "# want to convert to the string representations.", "\n", "[", "\n", "(", "score", ",", "[", "index_to_rule", "[", "idx", "]", "for", "idx", "in", "sequence", "]", ")", "\n", "for", "score", ",", "sequence", "in", "timestep_snapshot", "\n", "]", "\n", "for", "timestep_snapshot", "in", "beam_snapshots", "\n", "]", "\n", "for", "batch_index", ",", "beam_snapshots", "in", "interactive_beam_search", ".", "beam_snapshots", ".", "items", "(", ")", "\n", "}", "\n", "\n", "# Restore original beam search", "\n", "self", ".", "_model", ".", "_beam_search", "=", "original_beam_search", "\n", "\n", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.atis_parser.AtisParserPredictor._json_to_instance": [[14, 21], ["atis_parser.AtisParserPredictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Expects JSON that looks like ``{\"utterance\": \"...\"}``.\n        \"\"\"", "\n", "utterance", "=", "json_dict", "[", "\"utterance\"", "]", "\n", "return", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "[", "utterance", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser.NlvrParserPredictor._json_to_instance": [[12, 32], ["nlvr_parser.NlvrParserPredictor._dataset_reader.text_to_instance", "isinstance", "isinstance", "json.loads", "json.loads"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["    ", "@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "sentence", "=", "json_dict", "[", "\"sentence\"", "]", "\n", "if", "\"worlds\"", "in", "json_dict", ":", "\n", "# This is grouped data", "\n", "            ", "worlds", "=", "json_dict", "[", "\"worlds\"", "]", "\n", "if", "isinstance", "(", "worlds", ",", "str", ")", ":", "\n", "                ", "worlds", "=", "json", ".", "loads", "(", "worlds", ")", "\n", "", "", "else", ":", "\n", "            ", "structured_rep", "=", "json_dict", "[", "\"structured_rep\"", "]", "\n", "if", "isinstance", "(", "structured_rep", ",", "str", ")", ":", "\n", "                ", "structured_rep", "=", "json", ".", "loads", "(", "structured_rep", ")", "\n", "", "worlds", "=", "[", "structured_rep", "]", "\n", "", "identifier", "=", "json_dict", "[", "\"identifier\"", "]", "if", "\"identifier\"", "in", "json_dict", "else", "None", "\n", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "sentence", "=", "sentence", ",", "# type: ignore", "\n", "structured_representations", "=", "worlds", ",", "\n", "identifier", "=", "identifier", ",", "\n", ")", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser.NlvrParserPredictor.dump_line": [[33, 42], ["json.dumps"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "dump_line", "(", "self", ",", "outputs", ":", "JsonDict", ")", "->", "str", ":", "\n", "        ", "if", "\"identifier\"", "in", "outputs", ":", "\n", "# Returning CSV lines for official evaluation", "\n", "            ", "identifier", "=", "outputs", "[", "\"identifier\"", "]", "\n", "denotation", "=", "outputs", "[", "\"denotations\"", "]", "[", "0", "]", "[", "0", "]", "\n", "return", "f\"{identifier},{denotation}\\n\"", "\n", "", "else", ":", "\n", "            ", "return", "json", ".", "dumps", "(", "outputs", ")", "+", "\"\\n\"", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.atis_parser_test.TestAtisParserPredictor.test_atis_parser_uses_named_inputs": [[9, 27], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "Predictor.from_archive.predict_json.get", "all", "Predictor.from_archive.predict_json.get", "len", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["    ", "@", "flaky", "\n", "def", "test_atis_parser_uses_named_inputs", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "{", "\"utterance\"", ":", "\"show me the flights to seattle\"", "}", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"atis\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"atis-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_json", "(", "inputs", ")", "\n", "action_sequence", "=", "result", ".", "get", "(", "\"best_action_sequence\"", ")", "\n", "if", "action_sequence", ":", "\n", "# An untrained model will likely get into a loop, and not produce at finished states.", "\n", "# When the model gets into a loop it will not produce any valid SQL, so we don't get", "\n", "# any actions. This basically just tests if the model runs.", "\n", "            ", "assert", "len", "(", "action_sequence", ")", ">", "1", "\n", "assert", "all", "(", "[", "isinstance", "(", "action", ",", "str", ")", "for", "action", "in", "action_sequence", "]", ")", "\n", "predicted_sql_query", "=", "result", ".", "get", "(", "\"predicted_sql_query\"", ")", "\n", "assert", "predicted_sql_query", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.atis_parser_test.TestAtisParserPredictor.test_atis_parser_predicted_sql_present": [[28, 39], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "Predictor.from_archive.predict_json.get"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "", "@", "flaky", "\n", "def", "test_atis_parser_predicted_sql_present", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "{", "\"utterance\"", ":", "\"show me flights to seattle\"", "}", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"atis\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"atis-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_json", "(", "inputs", ")", "\n", "predicted_sql_query", "=", "result", ".", "get", "(", "\"predicted_sql_query\"", ")", "\n", "assert", "predicted_sql_query", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.atis_parser_test.TestAtisParserPredictor.test_atis_parser_batch_predicted_sql_present": [[40, 51], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_batch_json", "result[].get"], "methods", ["None"], ["", "@", "flaky", "\n", "def", "test_atis_parser_batch_predicted_sql_present", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "[", "{", "\"utterance\"", ":", "\"show me flights to seattle\"", "}", "]", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"atis\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"atis-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_batch_json", "(", "inputs", ")", "\n", "predicted_sql_query", "=", "result", "[", "0", "]", ".", "get", "(", "\"predicted_sql_query\"", ")", "\n", "assert", "predicted_sql_query", "is", "not", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser_test.TestWikiTablesParserPredictor.test_uses_named_inputs": [[9, 30], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "Predictor.from_archive.predict_json.get", "all", "Predictor.from_archive.predict_json.get", "len", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["    ", "def", "test_uses_named_inputs", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "{", "\"question\"", ":", "\"names\"", ",", "\"table\"", ":", "\"name\\tdate\\nmatt\\t2017\\npradeep\\t2018\"", "}", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"wikitables\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"wikitables-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_json", "(", "inputs", ")", "\n", "\n", "action_sequence", "=", "result", ".", "get", "(", "\"best_action_sequence\"", ")", "\n", "if", "action_sequence", ":", "\n", "# We don't currently disallow endless loops in the decoder, and an untrained seq2seq", "\n", "# model will easily get itself into a loop.  An endless loop isn't a finished logical", "\n", "# form, so decoding doesn't return any finished states, which means no actions.  So,", "\n", "# sadly, we don't have a great test here.  This is just testing that the predictor", "\n", "# runs, basically.", "\n", "            ", "assert", "len", "(", "action_sequence", ")", ">", "1", "\n", "assert", "all", "(", "[", "isinstance", "(", "action", ",", "str", ")", "for", "action", "in", "action_sequence", "]", ")", "\n", "\n", "logical_form", "=", "result", ".", "get", "(", "\"logical_form\"", ")", "\n", "assert", "logical_form", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser_test.TestWikiTablesParserPredictor.test_answer_present": [[31, 44], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "Predictor.from_archive.predict_json.get"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "", "def", "test_answer_present", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "{", "\n", "\"question\"", ":", "\"Who is 18 years old?\"", ",", "\n", "\"table\"", ":", "\"Name\\tAge\\nShallan\\t16\\nKaladin\\t18\"", ",", "\n", "}", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"wikitables\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"wikitables-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_json", "(", "inputs", ")", "\n", "answer", "=", "result", ".", "get", "(", "\"answer\"", ")", "\n", "assert", "answer", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser_test.TestWikiTablesParserPredictor.test_interactive_beam_search": [[45, 90], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "allennlp.predictors.Predictor.from_archive.predict_json", "zip", "enumerate", "any", "len", "zip", "all", "any", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "def", "test_interactive_beam_search", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "{", "\n", "\"question\"", ":", "\"Who is 18 years old?\"", ",", "\n", "\"table\"", ":", "\"Name\\tAge\\nShallan\\t16\\nKaladin\\t18\"", ",", "\n", "}", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"wikitables\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"wikitables-parser\"", ")", "\n", "\n", "# This is not the start of the best sequence, but it will be once we force it.", "\n", "initial_tokens", "=", "[", "\n", "\"@start@ -> Number\"", ",", "\n", "\"Number -> [<List[Row],NumberColumn:Number>, List[Row], NumberColumn]\"", ",", "\n", "]", "\n", "\n", "# First let's try an unforced one. Its initial tokens should not be ours.", "\n", "result", "=", "predictor", ".", "predict_json", "(", "inputs", ")", "\n", "best_action_sequence", "=", "result", "[", "\"best_action_sequence\"", "]", "\n", "assert", "best_action_sequence", "\n", "assert", "best_action_sequence", "[", ":", "2", "]", "!=", "initial_tokens", "\n", "\n", "# Now let's try forcing it down the path of `initial_sequence`", "\n", "inputs", "[", "\"initial_sequence\"", "]", "=", "initial_tokens", "\n", "result", "=", "predictor", ".", "predict_json", "(", "inputs", ")", "\n", "best_action_sequence", "=", "result", "[", "\"best_action_sequence\"", "]", "\n", "assert", "best_action_sequence", "[", ":", "2", "]", "==", "initial_tokens", "\n", "\n", "# Should get choices back from beam search", "\n", "beam_search_choices", "=", "result", "[", "\"choices\"", "]", "\n", "\n", "# Make sure that our forced choices appear as beam_search_choices.", "\n", "for", "choices", ",", "initial_token", "in", "zip", "(", "beam_search_choices", ",", "initial_tokens", ")", ":", "\n", "            ", "assert", "any", "(", "token", "==", "initial_token", "for", "_", ",", "token", "in", "choices", ")", "\n", "\n", "# Should get back beams too", "\n", "", "beam_snapshots", "=", "result", "[", "\"beam_snapshots\"", "]", "\n", "assert", "len", "(", "beam_snapshots", ")", "==", "1", "\n", "assert", "0", "in", "beam_snapshots", "\n", "beams", "=", "beam_snapshots", "[", "0", "]", "\n", "\n", "for", "idx", ",", "(", "beam", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "beams", ",", "best_action_sequence", ")", ")", ":", "\n", "# First beam should have 1-element sequences, etc...", "\n", "            ", "assert", "all", "(", "len", "(", "sequence", ")", "==", "idx", "+", "1", "for", "_", ",", "sequence", "in", "beam", ")", "\n", "assert", "any", "(", "sequence", "[", "-", "1", "]", "==", "action", "for", "_", ",", "sequence", "in", "beam", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser_test.TestWikiTablesParserPredictor.test_answer_present_with_batch_predict": [[91, 103], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_batch_json", "result[].get"], "methods", ["None"], ["", "", "def", "test_answer_present_with_batch_predict", "(", "self", ")", ":", "\n", "        ", "inputs", "=", "[", "\n", "{", "\"question\"", ":", "\"Who is 18 years old?\"", ",", "\"table\"", ":", "\"Name\\tAge\\nShallan\\t16\\nKaladin\\t18\"", "}", "\n", "]", "\n", "\n", "archive_path", "=", "self", ".", "FIXTURES_ROOT", "/", "\"wikitables\"", "/", "\"serialization\"", "/", "\"model.tar.gz\"", "\n", "archive", "=", "load_archive", "(", "archive_path", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"wikitables-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_batch_json", "(", "inputs", ")", "\n", "answer", "=", "result", "[", "0", "]", ".", "get", "(", "\"answer\"", ")", "\n", "assert", "answer", "is", "not", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser_test.TestNlvrParserPredictor.setup_method": [[10, 35], ["super().setup_method"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "inputs", "=", "{", "\n", "\"worlds\"", ":", "[", "\n", "[", "\n", "[", "\n", "{", "\n", "\"y_loc\"", ":", "80", ",", "\n", "\"type\"", ":", "\"triangle\"", ",", "\n", "\"color\"", ":", "\"#0099ff\"", ",", "\n", "\"x_loc\"", ":", "80", ",", "\n", "\"size\"", ":", "20", ",", "\n", "}", "\n", "]", ",", "\n", "[", "{", "\"y_loc\"", ":", "80", ",", "\"type\"", ":", "\"square\"", ",", "\"color\"", ":", "\"Yellow\"", ",", "\"x_loc\"", ":", "13", ",", "\"size\"", ":", "20", "}", "]", ",", "\n", "[", "{", "\"y_loc\"", ":", "67", ",", "\"type\"", ":", "\"triangle\"", ",", "\"color\"", ":", "\"Yellow\"", ",", "\"x_loc\"", ":", "35", ",", "\"size\"", ":", "10", "}", "]", ",", "\n", "]", ",", "\n", "[", "\n", "[", "{", "\"y_loc\"", ":", "8", ",", "\"type\"", ":", "\"square\"", ",", "\"color\"", ":", "\"Yellow\"", ",", "\"x_loc\"", ":", "57", ",", "\"size\"", ":", "30", "}", "]", ",", "\n", "[", "{", "\"y_loc\"", ":", "43", ",", "\"type\"", ":", "\"square\"", ",", "\"color\"", ":", "\"#0099ff\"", ",", "\"x_loc\"", ":", "70", ",", "\"size\"", ":", "30", "}", "]", ",", "\n", "[", "{", "\"y_loc\"", ":", "59", ",", "\"type\"", ":", "\"square\"", ",", "\"color\"", ":", "\"Yellow\"", ",", "\"x_loc\"", ":", "47", ",", "\"size\"", ":", "10", "}", "]", ",", "\n", "]", ",", "\n", "]", ",", "\n", "\"identifier\"", ":", "\"fake_id\"", ",", "\n", "\"sentence\"", ":", "\"Each grey box contains atleast one yellow object touching the edge\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser_test.TestNlvrParserPredictor.test_predictor_with_coverage_parser": [[37, 48], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "def", "test_predictor_with_coverage_parser", "(", "self", ")", ":", "\n", "        ", "archive_dir", "=", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"serialization\"", "\n", "archive", "=", "load_archive", "(", "os", ".", "path", ".", "join", "(", "archive_dir", ",", "\"model.tar.gz\"", ")", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"nlvr-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_json", "(", "self", ".", "inputs", ")", "\n", "assert", "\"logical_form\"", "in", "result", "\n", "assert", "\"denotations\"", "in", "result", "\n", "# result['denotations'] is a list corresponding to k-best logical forms, where k is 1 by", "\n", "# default.", "\n", "assert", "len", "(", "result", "[", "\"denotations\"", "]", "[", "0", "]", ")", "==", "2", "# Because there are two worlds in the input.", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser_test.TestNlvrParserPredictor.test_predictor_with_direct_parser": [[49, 60], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "def", "test_predictor_with_direct_parser", "(", "self", ")", ":", "\n", "        ", "archive_dir", "=", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_direct_semantic_parser\"", "/", "\"serialization\"", "\n", "archive", "=", "load_archive", "(", "os", ".", "path", ".", "join", "(", "archive_dir", ",", "\"model.tar.gz\"", ")", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"nlvr-parser\"", ")", "\n", "\n", "result", "=", "predictor", ".", "predict_json", "(", "self", ".", "inputs", ")", "\n", "assert", "\"logical_form\"", "in", "result", "\n", "assert", "\"denotations\"", "in", "result", "\n", "# result['denotations'] is a list corresponding to k-best logical forms, where k is 1 by", "\n", "# default.", "\n", "assert", "len", "(", "result", "[", "\"denotations\"", "]", "[", "0", "]", ")", "==", "2", "# Because there are two worlds in the input.", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser_test.TestNlvrParserPredictor.test_predictor_with_string_input": [[61, 73], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "json.dumps", "allennlp.predictors.Predictor.from_archive.predict_json", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "def", "test_predictor_with_string_input", "(", "self", ")", ":", "\n", "        ", "archive_dir", "=", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"serialization\"", "\n", "archive", "=", "load_archive", "(", "os", ".", "path", ".", "join", "(", "archive_dir", ",", "\"model.tar.gz\"", ")", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"nlvr-parser\"", ")", "\n", "\n", "self", ".", "inputs", "[", "\"worlds\"", "]", "=", "json", ".", "dumps", "(", "self", ".", "inputs", "[", "\"worlds\"", "]", ")", "\n", "result", "=", "predictor", ".", "predict_json", "(", "self", ".", "inputs", ")", "\n", "assert", "\"logical_form\"", "in", "result", "\n", "assert", "\"denotations\"", "in", "result", "\n", "# result['denotations'] is a list corresponding to k-best logical forms, where k is 1 by", "\n", "# default.", "\n", "assert", "len", "(", "result", "[", "\"denotations\"", "]", "[", "0", "]", ")", "==", "2", "# Because there are two worlds in the input.", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser_test.TestNlvrParserPredictor.test_predictor_with_single_world": [[74, 87], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "allennlp.predictors.Predictor.from_archive.predict_json", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "def", "test_predictor_with_single_world", "(", "self", ")", ":", "\n", "        ", "archive_dir", "=", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"serialization\"", "\n", "archive", "=", "load_archive", "(", "os", ".", "path", ".", "join", "(", "archive_dir", ",", "\"model.tar.gz\"", ")", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"nlvr-parser\"", ")", "\n", "\n", "self", ".", "inputs", "[", "\"structured_rep\"", "]", "=", "self", ".", "inputs", "[", "\"worlds\"", "]", "[", "0", "]", "\n", "del", "self", ".", "inputs", "[", "\"worlds\"", "]", "\n", "result", "=", "predictor", ".", "predict_json", "(", "self", ".", "inputs", ")", "\n", "assert", "\"logical_form\"", "in", "result", "\n", "assert", "\"denotations\"", "in", "result", "\n", "# result['denotations'] is a list corresponding to k-best logical forms, where k is 1 by", "\n", "# default.", "\n", "assert", "len", "(", "result", "[", "\"denotations\"", "]", "[", "0", "]", ")", "==", "1", "# Because there is one world in the input.", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.nlvr_parser_test.TestNlvrParserPredictor.test_predictor_with_single_world_and_string_input": [[88, 101], ["allennlp.models.archival.load_archive", "allennlp.predictors.Predictor.from_archive", "json.dumps", "allennlp.predictors.Predictor.from_archive.predict_json", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.predictors.wikitables_parser.WikiTablesParserPredictor.predict_json"], ["", "def", "test_predictor_with_single_world_and_string_input", "(", "self", ")", ":", "\n", "        ", "archive_dir", "=", "self", ".", "FIXTURES_ROOT", "/", "\"nlvr_coverage_semantic_parser\"", "/", "\"serialization\"", "\n", "archive", "=", "load_archive", "(", "os", ".", "path", ".", "join", "(", "archive_dir", ",", "\"model.tar.gz\"", ")", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "\"nlvr-parser\"", ")", "\n", "\n", "self", ".", "inputs", "[", "\"structured_rep\"", "]", "=", "json", ".", "dumps", "(", "self", ".", "inputs", "[", "\"worlds\"", "]", "[", "0", "]", ")", "\n", "del", "self", ".", "inputs", "[", "\"worlds\"", "]", "\n", "result", "=", "predictor", ".", "predict_json", "(", "self", ".", "inputs", ")", "\n", "assert", "\"logical_form\"", "in", "result", "\n", "assert", "\"denotations\"", "in", "result", "\n", "# result['denotations'] is a list corresponding to k-best logical forms, where k is 1 by", "\n", "# default.", "\n", "assert", "len", "(", "result", "[", "\"denotations\"", "]", "[", "0", "]", ")", "==", "1", "# Because there is one world in the input.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.pm_map_match_to_query_value": [[19, 30], ["len", "match.startswith", "match.startswith", "match.rstrip", "int", "int", "match.rstrip", "int", "match.rstrip", "int", "match.rstrip", "match.rstrip"], "function", ["None"], ["def", "pm_map_match_to_query_value", "(", "match", ":", "str", ")", ":", "\n", "    ", "if", "len", "(", "match", ".", "rstrip", "(", "\"pm\"", ")", ")", "<", "3", ":", "# This will match something like ``5pm``.", "\n", "        ", "if", "match", ".", "startswith", "(", "\"12\"", ")", ":", "\n", "            ", "return", "[", "int", "(", "match", ".", "rstrip", "(", "\"pm\"", ")", ")", "*", "HOUR_TO_TWENTY_FOUR", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "int", "(", "match", ".", "rstrip", "(", "\"pm\"", ")", ")", "*", "HOUR_TO_TWENTY_FOUR", "+", "TWELVE_TO_TWENTY_FOUR", "]", "\n", "", "", "else", ":", "# This will match something like ``530pm``.", "\n", "        ", "if", "match", ".", "startswith", "(", "\"12\"", ")", ":", "\n", "            ", "return", "[", "int", "(", "match", ".", "rstrip", "(", "\"pm\"", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "int", "(", "match", ".", "rstrip", "(", "\"pm\"", ")", ")", "+", "TWELVE_TO_TWENTY_FOUR", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.am_map_match_to_query_value": [[32, 37], ["len", "match.rstrip", "int", "int", "match.rstrip", "match.rstrip"], "function", ["None"], ["", "", "", "def", "am_map_match_to_query_value", "(", "match", ":", "str", ")", ":", "\n", "    ", "if", "len", "(", "match", ".", "rstrip", "(", "\"am\"", ")", ")", "<", "3", ":", "\n", "        ", "return", "[", "int", "(", "match", ".", "rstrip", "(", "\"am\"", ")", ")", "*", "HOUR_TO_TWENTY_FOUR", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "int", "(", "match", ".", "rstrip", "(", "\"am\"", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_times_from_utterance": [[39, 89], ["atis_tables._time_regex_match", "atis_tables._time_regex_match", "atis_tables._time_regex_match", "atis_tables._time_regex_match", "collections.defaultdict", "linking_dict.items", "atis_tables.digit_to_query_time", "times_linking_dict[].extend", "match.rstrip", "int", "match.rstrip"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables._time_regex_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables._time_regex_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables._time_regex_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables._time_regex_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.digit_to_query_time"], ["", "", "def", "get_times_from_utterance", "(", "\n", "utterance", ":", "str", ",", "\n", "char_offset_to_token_index", ":", "Dict", "[", "int", ",", "int", "]", ",", "\n", "indices_of_approximate_words", ":", "Set", "[", "int", "]", ",", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Given an utterance, we get the numbers that correspond to times and convert them to\n    values that may appear in the query. For example: convert ``7pm`` to ``1900``.\n    \"\"\"", "\n", "\n", "pm_linking_dict", "=", "_time_regex_match", "(", "\n", "r\"\\d+pm\"", ",", "\n", "utterance", ",", "\n", "char_offset_to_token_index", ",", "\n", "pm_map_match_to_query_value", ",", "\n", "indices_of_approximate_words", ",", "\n", ")", "\n", "\n", "am_linking_dict", "=", "_time_regex_match", "(", "\n", "r\"\\d+am\"", ",", "\n", "utterance", ",", "\n", "char_offset_to_token_index", ",", "\n", "am_map_match_to_query_value", ",", "\n", "indices_of_approximate_words", ",", "\n", ")", "\n", "\n", "oclock_linking_dict", "=", "_time_regex_match", "(", "\n", "r\"\\d+ o'clock\"", ",", "\n", "utterance", ",", "\n", "char_offset_to_token_index", ",", "\n", "lambda", "match", ":", "digit_to_query_time", "(", "match", ".", "rstrip", "(", "\" o'clock\"", ")", ")", ",", "\n", "indices_of_approximate_words", ",", "\n", ")", "\n", "\n", "hours_linking_dict", "=", "_time_regex_match", "(", "\n", "r\"\\d+ hours\"", ",", "\n", "utterance", ",", "\n", "char_offset_to_token_index", ",", "\n", "lambda", "match", ":", "[", "int", "(", "match", ".", "rstrip", "(", "\" hours\"", ")", ")", "]", ",", "\n", "indices_of_approximate_words", ",", "\n", ")", "\n", "\n", "times_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "linking_dicts", "=", "[", "pm_linking_dict", ",", "am_linking_dict", ",", "oclock_linking_dict", ",", "hours_linking_dict", "]", "\n", "\n", "for", "linking_dict", "in", "linking_dicts", ":", "\n", "        ", "for", "key", ",", "value", "in", "linking_dict", ".", "items", "(", ")", ":", "\n", "            ", "times_linking_dict", "[", "key", "]", ".", "extend", "(", "value", ")", "\n", "\n", "", "", "return", "times_linking_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_date_from_utterance": [[91, 138], ["re.findall", "nltk.ngrams", "nltk.ngrams", "nltk.ngrams", "int", "year_match.isdigit", "year_match.isdigit", "dates.append", "dates.append", "dates.append", "dates.append", "datetime.datetime", "print", "datetime.datetime", "print", "datetime.datetime", "print", "datetime.datetime", "print", "int", "int"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_date_from_utterance", "(", "tokenized_utterance", ":", "List", "[", "Token", "]", ",", "year", ":", "int", "=", "1993", ")", "->", "List", "[", "datetime", "]", ":", "\n", "    ", "\"\"\"\n    When the year is not explicitly mentioned in the utterance, the query assumes that\n    it is 1993 so we do the same here. If there is no mention of the month or day then\n    we do not return any dates from the utterance.\n    \"\"\"", "\n", "\n", "dates", "=", "[", "]", "\n", "\n", "utterance", "=", "\" \"", ".", "join", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ")", "\n", "year_result", "=", "re", ".", "findall", "(", "r\"199[0-4]\"", ",", "utterance", ")", "\n", "if", "year_result", ":", "\n", "        ", "year", "=", "int", "(", "year_result", "[", "0", "]", ")", "\n", "", "trigrams", "=", "ngrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ",", "3", ")", "\n", "for", "month", ",", "tens", ",", "digit", "in", "trigrams", ":", "\n", "# This will match something like ``september twenty first``.", "\n", "        ", "day", "=", "\" \"", ".", "join", "(", "[", "tens", ",", "digit", "]", ")", "\n", "if", "month", "in", "MONTH_NUMBERS", "and", "day", "in", "DAY_NUMBERS", ":", "\n", "            ", "try", ":", "\n", "                ", "dates", ".", "append", "(", "datetime", "(", "year", ",", "MONTH_NUMBERS", "[", "month", "]", ",", "DAY_NUMBERS", "[", "day", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "\"invalid month day\"", ")", "\n", "\n", "", "", "", "bigrams", "=", "ngrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ",", "2", ")", "\n", "for", "month", ",", "day", "in", "bigrams", ":", "\n", "        ", "if", "month", "in", "MONTH_NUMBERS", "and", "day", "in", "DAY_NUMBERS", ":", "\n", "# This will match something like ``september first``.", "\n", "            ", "try", ":", "\n", "                ", "dates", ".", "append", "(", "datetime", "(", "year", ",", "MONTH_NUMBERS", "[", "month", "]", ",", "DAY_NUMBERS", "[", "day", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "\"invalid month day\"", ")", "\n", "\n", "", "", "", "fivegrams", "=", "ngrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ",", "5", ")", "\n", "for", "tens", ",", "digit", ",", "_", ",", "year_match", ",", "month", "in", "fivegrams", ":", "\n", "# This will match something like ``twenty first of 1993 july``.", "\n", "        ", "day", "=", "\" \"", ".", "join", "(", "[", "tens", ",", "digit", "]", ")", "\n", "if", "month", "in", "MONTH_NUMBERS", "and", "day", "in", "DAY_NUMBERS", "and", "year_match", ".", "isdigit", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "dates", ".", "append", "(", "datetime", "(", "int", "(", "year_match", ")", ",", "MONTH_NUMBERS", "[", "month", "]", ",", "DAY_NUMBERS", "[", "day", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "\"invalid month day\"", ")", "\n", "", "", "if", "month", "in", "MONTH_NUMBERS", "and", "digit", "in", "DAY_NUMBERS", "and", "year_match", ".", "isdigit", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "dates", ".", "append", "(", "datetime", "(", "int", "(", "year_match", ")", ",", "MONTH_NUMBERS", "[", "month", "]", ",", "DAY_NUMBERS", "[", "digit", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "\"invalid month day\"", ")", "\n", "", "", "", "return", "dates", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_numbers_from_utterance": [[140, 194], ["collections.defaultdict", "enumerate", "atis_tables.get_times_from_utterance", "get_times_from_utterance.items", "enumerate", "token.text.isdigit", "number_linking_dict[].extend", "NUMBER_TRIGGER_DICT.get", "enumerate", "enumerate", "enumerate", "enumerate", "atis_tables.digit_to_query_time", "atis_tables.get_approximate_times", "number_linking_dict[].append", "number_linking_dict[].append", "number_linking_dict[].append", "int", "str", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_times_from_utterance", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.digit_to_query_time", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_approximate_times", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "get_numbers_from_utterance", "(", "\n", "utterance", ":", "str", ",", "tokenized_utterance", ":", "List", "[", "Token", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Given an utterance, this function finds all the numbers that are in the action space. Since we need to\n    keep track of linking scores, we represent the numbers as a dictionary, where the keys are the string\n    representation of the number and the values are lists of the token indices that triggers that number.\n    \"\"\"", "\n", "# When we use a regex to find numbers or strings, we need a mapping from", "\n", "# the character to which token triggered it.", "\n", "char_offset_to_token_index", "=", "{", "\n", "token", ".", "idx", ":", "token_index", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "\n", "}", "\n", "\n", "# We want to look up later for each time whether it appears after a word", "\n", "# such as \"about\" or \"approximately\".", "\n", "indices_of_approximate_words", "=", "{", "\n", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "if", "token", ".", "text", "in", "APPROX_WORDS", "\n", "}", "\n", "\n", "indices_of_words_preceding_time", "=", "{", "\n", "index", "\n", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "\n", "if", "token", ".", "text", "in", "WORDS_PRECEDING_TIME", "\n", "}", "\n", "\n", "indices_of_am_pm", "=", "{", "\n", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "if", "token", ".", "text", "in", "{", "\"am\"", ",", "\"pm\"", "}", "\n", "}", "\n", "\n", "number_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "if", "token", ".", "text", ".", "isdigit", "(", ")", ":", "\n", "            ", "if", "(", "\n", "token_index", "-", "1", "in", "indices_of_words_preceding_time", "\n", "and", "token_index", "+", "1", "not", "in", "indices_of_am_pm", "\n", ")", ":", "\n", "                ", "for", "time", "in", "digit_to_query_time", "(", "token", ".", "text", ")", ":", "\n", "                    ", "number_linking_dict", "[", "str", "(", "time", ")", "]", ".", "append", "(", "token_index", ")", "\n", "", "", "", "", "times_linking_dict", "=", "get_times_from_utterance", "(", "\n", "utterance", ",", "char_offset_to_token_index", ",", "indices_of_approximate_words", "\n", ")", "\n", "for", "key", ",", "value", "in", "times_linking_dict", ".", "items", "(", ")", ":", "\n", "        ", "number_linking_dict", "[", "key", "]", ".", "extend", "(", "value", ")", "\n", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "for", "number", "in", "NUMBER_TRIGGER_DICT", ".", "get", "(", "token", ".", "text", ",", "[", "]", ")", ":", "\n", "            ", "if", "index", "-", "1", "in", "indices_of_approximate_words", ":", "\n", "                ", "for", "approx_time", "in", "get_approximate_times", "(", "[", "int", "(", "number", ")", "]", ")", ":", "\n", "                    ", "number_linking_dict", "[", "str", "(", "approx_time", ")", "]", ".", "append", "(", "index", ")", "\n", "", "", "else", ":", "\n", "                ", "number_linking_dict", "[", "number", "]", ".", "append", "(", "index", ")", "\n", "", "", "", "return", "number_linking_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_time_range_start_from_utterance": [[196, 215], ["collections.defaultdict", "enumerate", "nltk.ngrams", "enumerate", "TIME_RANGE_START_DICT.get", "TIME_RANGE_START_DICT.get", "enumerate", "time_range_start_linking_dict[].extend", "time_range_start_linking_dict[].append", "str", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "get_time_range_start_from_utterance", "(", "\n", "utterance", ":", "str", ",", "tokenized_utterance", ":", "List", "[", "Token", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "late_indices", "=", "{", "\n", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "if", "token", ".", "text", "==", "\"late\"", "\n", "}", "\n", "\n", "time_range_start_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "for", "time", "in", "TIME_RANGE_START_DICT", ".", "get", "(", "token", ".", "text", ",", "[", "]", ")", ":", "\n", "            ", "if", "token_index", "-", "1", "not", "in", "late_indices", ":", "\n", "                ", "time_range_start_linking_dict", "[", "str", "(", "time", ")", "]", ".", "append", "(", "token_index", ")", "\n", "\n", "", "", "", "bigrams", "=", "ngrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ",", "2", ")", "\n", "for", "bigram_index", ",", "bigram", "in", "enumerate", "(", "bigrams", ")", ":", "\n", "        ", "for", "time", "in", "TIME_RANGE_START_DICT", ".", "get", "(", "\" \"", ".", "join", "(", "bigram", ")", ",", "[", "]", ")", ":", "\n", "            ", "time_range_start_linking_dict", "[", "str", "(", "time", ")", "]", ".", "extend", "(", "[", "bigram_index", ",", "bigram_index", "+", "1", "]", ")", "\n", "\n", "", "", "return", "time_range_start_linking_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_time_range_end_from_utterance": [[217, 236], ["collections.defaultdict", "enumerate", "nltk.ngrams", "enumerate", "TIME_RANGE_END_DICT.get", "TIME_RANGE_END_DICT.get", "enumerate", "time_range_end_linking_dict[].extend", "time_range_end_linking_dict[].append", "str", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "get_time_range_end_from_utterance", "(", "\n", "utterance", ":", "str", ",", "tokenized_utterance", ":", "List", "[", "Token", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "early_indices", "=", "{", "\n", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "if", "token", ".", "text", "==", "\"early\"", "\n", "}", "\n", "\n", "time_range_end_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "for", "time", "in", "TIME_RANGE_END_DICT", ".", "get", "(", "token", ".", "text", ",", "[", "]", ")", ":", "\n", "            ", "if", "token_index", "-", "1", "not", "in", "early_indices", ":", "\n", "                ", "time_range_end_linking_dict", "[", "str", "(", "time", ")", "]", ".", "append", "(", "token_index", ")", "\n", "\n", "", "", "", "bigrams", "=", "ngrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ",", "2", ")", "\n", "for", "bigram_index", ",", "bigram", "in", "enumerate", "(", "bigrams", ")", ":", "\n", "        ", "for", "time", "in", "TIME_RANGE_END_DICT", ".", "get", "(", "\" \"", ".", "join", "(", "bigram", ")", ",", "[", "]", ")", ":", "\n", "            ", "time_range_end_linking_dict", "[", "str", "(", "time", ")", "]", ".", "extend", "(", "[", "bigram_index", ",", "bigram_index", "+", "1", "]", ")", "\n", "\n", "", "", "return", "time_range_end_linking_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_costs_from_utterance": [[238, 252], ["collections.defaultdict", "enumerate", "enumerate", "token.text.isdigit", "costs_linking_dict[].append"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_costs_from_utterance", "(", "\n", "utterance", ":", "str", ",", "tokenized_utterance", ":", "List", "[", "Token", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "dollars_indices", "=", "{", "\n", "index", "\n", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "\n", "if", "token", ".", "text", "==", "\"dollars\"", "or", "token", ".", "text", "==", "\"dollar\"", "\n", "}", "\n", "\n", "costs_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "if", "token_index", "+", "1", "in", "dollars_indices", "and", "token", ".", "text", ".", "isdigit", "(", ")", ":", "\n", "            ", "costs_linking_dict", "[", "token", ".", "text", "]", ".", "append", "(", "token_index", ")", "\n", "", "", "return", "costs_linking_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_flight_numbers_from_utterance": [[254, 277], ["collections.defaultdict", "enumerate", "token.text.isdigit", "enumerate", "enumerate", "flight_numbers_linking_dict[].append", "flight_numbers_linking_dict[].append", "token.text.upper", "token.text.lower", "AIRLINE_CODES.keys"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_flight_numbers_from_utterance", "(", "\n", "utterance", ":", "str", ",", "tokenized_utterance", ":", "List", "[", "Token", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "indices_words_preceding_flight_number", "=", "{", "\n", "index", "\n", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "\n", "if", "token", ".", "text", "in", "{", "\"flight\"", ",", "\"number\"", "}", "\n", "or", "token", ".", "text", ".", "upper", "(", ")", "in", "AIRLINE_CODE_LIST", "\n", "or", "token", ".", "text", ".", "lower", "(", ")", "in", "AIRLINE_CODES", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "indices_words_succeeding_flight_number", "=", "{", "\n", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", "if", "token", ".", "text", "==", "\"flight\"", "\n", "}", "\n", "\n", "flight_numbers_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "if", "token", ".", "text", ".", "isdigit", "(", ")", ":", "\n", "            ", "if", "token_index", "-", "1", "in", "indices_words_preceding_flight_number", ":", "\n", "                ", "flight_numbers_linking_dict", "[", "token", ".", "text", "]", ".", "append", "(", "token_index", ")", "\n", "", "if", "token_index", "+", "1", "in", "indices_words_succeeding_flight_number", ":", "\n", "                ", "flight_numbers_linking_dict", "[", "token", ".", "text", "]", ".", "append", "(", "token_index", ")", "\n", "", "", "", "return", "flight_numbers_linking_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.digit_to_query_time": [[279, 290], ["len", "int", "int", "int", "int", "int"], "function", ["None"], ["", "def", "digit_to_query_time", "(", "digit", ":", "str", ")", "->", "List", "[", "int", "]", ":", "\n", "    ", "\"\"\"\n    Given a digit in the utterance, return a list of the times that it corresponds to.\n    \"\"\"", "\n", "if", "len", "(", "digit", ")", ">", "2", ":", "\n", "        ", "return", "[", "int", "(", "digit", ")", ",", "int", "(", "digit", ")", "+", "TWELVE_TO_TWENTY_FOUR", "]", "\n", "", "elif", "int", "(", "digit", ")", "%", "12", "==", "0", ":", "\n", "        ", "return", "[", "0", ",", "1200", ",", "2400", "]", "\n", "", "return", "[", "\n", "int", "(", "digit", ")", "*", "HOUR_TO_TWENTY_FOUR", ",", "\n", "(", "int", "(", "digit", ")", "*", "HOUR_TO_TWENTY_FOUR", "+", "TWELVE_TO_TWENTY_FOUR", ")", "%", "HOURS_IN_DAY", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_approximate_times": [[293, 317], ["datetime.datetime.now", "approximate_time.replace.replace", "approximate_times.extend", "int", "datetime.timedelta", "datetime.timedelta"], "function", ["None"], ["", "def", "get_approximate_times", "(", "times", ":", "List", "[", "int", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "    ", "\"\"\"\n    Given a list of times that follow a word such as ``about``,\n    we return a list of times that could appear in the query as a result\n    of this. For example if ``about 7pm`` appears in the utterance, then\n    we also want to add ``1830`` and ``1930``.\n    \"\"\"", "\n", "approximate_times", "=", "[", "]", "\n", "for", "time", "in", "times", ":", "\n", "        ", "hour", "=", "int", "(", "time", "/", "HOUR_TO_TWENTY_FOUR", ")", "%", "24", "\n", "minute", "=", "time", "%", "HOUR_TO_TWENTY_FOUR", "\n", "approximate_time", "=", "datetime", ".", "now", "(", ")", "\n", "approximate_time", "=", "approximate_time", ".", "replace", "(", "hour", "=", "hour", ",", "minute", "=", "minute", ")", "\n", "\n", "start_time_range", "=", "approximate_time", "-", "timedelta", "(", "minutes", "=", "30", ")", "\n", "end_time_range", "=", "approximate_time", "+", "timedelta", "(", "minutes", "=", "30", ")", "\n", "approximate_times", ".", "extend", "(", "\n", "[", "\n", "start_time_range", ".", "hour", "*", "HOUR_TO_TWENTY_FOUR", "+", "start_time_range", ".", "minute", ",", "\n", "end_time_range", ".", "hour", "*", "HOUR_TO_TWENTY_FOUR", "+", "end_time_range", ".", "minute", ",", "\n", "]", "\n", ")", "\n", "\n", "", "return", "approximate_times", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables._time_regex_match": [[319, 360], ["collections.defaultdict", "re.compile", "re.compile.finditer", "map_match_to_query_value.extend", "match.group", "approximate_times.extend", "match.start", "char_offset_to_token_index.get", "atis_tables.get_approximate_times", "linking_scores_dict[].extend", "match.start", "str", "match.start", "match.start", "atis_tables.pm_map_match_to_query_value", "atis_tables.am_map_match_to_query_value"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_approximate_times", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.pm_map_match_to_query_value", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.am_map_match_to_query_value"], ["", "def", "_time_regex_match", "(", "\n", "regex", ":", "str", ",", "\n", "utterance", ":", "str", ",", "\n", "char_offset_to_token_index", ":", "Dict", "[", "int", ",", "int", "]", ",", "\n", "map_match_to_query_value", ":", "Callable", "[", "[", "str", "]", ",", "List", "[", "int", "]", "]", ",", "\n", "indices_of_approximate_words", ":", "Set", "[", "int", "]", ",", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "r\"\"\"\n    Given a regex for matching times in the utterance, we want to convert the matches\n    to the values that appear in the query and token indices they correspond to.\n\n    ``char_offset_to_token_index`` is a dictionary that maps from the character offset to\n    the token index, we use this to look up what token a regex match corresponds to.\n    ``indices_of_approximate_words`` are the token indices of the words such as ``about`` or\n    ``approximately``. We use this to check if a regex match is preceded by one of these words.\n    If it is, we also want to add the times that define this approximate time range.\n\n    ``map_match_to_query_value`` is a function that converts the regex matches to the\n    values that appear in the query. For example, we may pass in a regex such as ``\\d+pm``\n    that matches times such as ``7pm``. ``map_match_to_query_value`` would be a function that\n    takes ``7pm`` as input and returns ``1900``.\n    \"\"\"", "\n", "linking_scores_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "number_regex", "=", "re", ".", "compile", "(", "regex", ")", "\n", "for", "match", "in", "number_regex", ".", "finditer", "(", "utterance", ")", ":", "\n", "        ", "query_values", "=", "map_match_to_query_value", "(", "match", ".", "group", "(", ")", ")", "\n", "# If the time appears after a word like ``about`` then we also add", "\n", "# the times that mark the start and end of the allowed range.", "\n", "approximate_times", "=", "[", "]", "\n", "if", "char_offset_to_token_index", ".", "get", "(", "match", ".", "start", "(", ")", ",", "0", ")", "-", "1", "in", "indices_of_approximate_words", ":", "\n", "            ", "approximate_times", ".", "extend", "(", "get_approximate_times", "(", "query_values", ")", ")", "\n", "", "query_values", ".", "extend", "(", "approximate_times", ")", "\n", "if", "match", ".", "start", "(", ")", "in", "char_offset_to_token_index", ":", "\n", "            ", "for", "query_value", "in", "query_values", ":", "\n", "                ", "linking_scores_dict", "[", "str", "(", "query_value", ")", "]", ".", "extend", "(", "\n", "[", "\n", "char_offset_to_token_index", "[", "match", ".", "start", "(", ")", "]", ",", "\n", "char_offset_to_token_index", "[", "match", ".", "start", "(", ")", "]", "+", "1", ",", "\n", "]", "\n", ")", "\n", "", "", "", "return", "linking_scores_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_trigger_dict": [[362, 375], ["collections.defaultdict", "trigger_dict.items", "merged_trigger_dict[].append", "merged_trigger_dict[].extend", "trigger.lower", "key.lower"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_trigger_dict", "(", "\n", "trigger_lists", ":", "List", "[", "List", "[", "str", "]", "]", ",", "trigger_dicts", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "merged_trigger_dict", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "trigger_list", "in", "trigger_lists", ":", "\n", "        ", "for", "trigger", "in", "trigger_list", ":", "\n", "            ", "merged_trigger_dict", "[", "trigger", ".", "lower", "(", ")", "]", ".", "append", "(", "trigger", ")", "\n", "\n", "", "", "for", "trigger_dict", "in", "trigger_dicts", ":", "\n", "        ", "for", "key", ",", "value", "in", "trigger_dict", ".", "items", "(", ")", ":", "\n", "            ", "merged_trigger_dict", "[", "key", ".", "lower", "(", ")", "]", ".", "extend", "(", "value", ")", "\n", "\n", "", "", "return", "merged_trigger_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.convert_to_string_list_value_dict": [[377, 379], ["str", "trigger_dict.items"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "convert_to_string_list_value_dict", "(", "trigger_dict", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "return", "{", "key", ":", "[", "str", "(", "value", ")", "]", "for", "key", ",", "value", "in", "trigger_dict", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_tables": [[155, 166], ["sorted", "set", "schema.values", "sorted", "set.update", "list", "schema.keys"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update"], ["def", "update_grammar_with_tables", "(", "\n", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "schema", ":", "Dict", "[", "str", ",", "List", "[", "TableColumn", "]", "]", "\n", ")", "->", "None", ":", "\n", "    ", "table_names", "=", "sorted", "(", "[", "f'\"{table}\"'", "for", "table", "in", "list", "(", "schema", ".", "keys", "(", ")", ")", "]", ",", "reverse", "=", "True", ")", "\n", "grammar_dictionary", "[", "\"table_name\"", "]", "=", "table_names", "\n", "\n", "all_columns", "=", "set", "(", ")", "\n", "for", "table", "in", "schema", ".", "values", "(", ")", ":", "\n", "        ", "all_columns", ".", "update", "(", "[", "column", ".", "name", "for", "column", "in", "table", "]", ")", "\n", "", "sorted_columns", "=", "sorted", "(", "[", "f'\"{column}\"'", "for", "column", "in", "all_columns", "]", ",", "reverse", "=", "True", ")", "\n", "grammar_dictionary", "[", "\"column_name\"", "]", "=", "sorted_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_table_values": [[168, 182], ["schema.items", "cursor.execute", "allennlp_semparse.common.sql.text2sql_utils.column_has_string_type", "sorted", "grammar_dictionary[].extend", "allennlp_semparse.common.sql.text2sql_utils.column_has_numeric_type", "cursor.fetchall", "sorted", "grammar_dictionary[].extend", "str", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.column_has_string_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.column_has_numeric_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "update_grammar_with_table_values", "(", "\n", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "schema", ":", "Dict", "[", "str", ",", "List", "[", "TableColumn", "]", "]", ",", "cursor", ":", "Cursor", "\n", ")", "->", "None", ":", "\n", "\n", "    ", "for", "table_name", ",", "columns", "in", "schema", ".", "items", "(", ")", ":", "\n", "        ", "for", "column", "in", "columns", ":", "\n", "            ", "cursor", ".", "execute", "(", "f\"SELECT DISTINCT {table_name}.{column.name} FROM {table_name}\"", ")", "\n", "results", "=", "[", "x", "[", "0", "]", "for", "x", "in", "cursor", ".", "fetchall", "(", ")", "]", "\n", "if", "column_has_string_type", "(", "column", ")", ":", "\n", "                ", "productions", "=", "sorted", "(", "[", "f'\"{str(result)}\"'", "for", "result", "in", "results", "]", ",", "reverse", "=", "True", ")", "\n", "grammar_dictionary", "[", "\"string\"", "]", ".", "extend", "(", "productions", ")", "\n", "", "elif", "column_has_numeric_type", "(", "column", ")", ":", "\n", "                ", "productions", "=", "sorted", "(", "[", "f'\"{str(result)}\"'", "for", "result", "in", "results", "]", ",", "reverse", "=", "True", ")", "\n", "grammar_dictionary", "[", "\"number\"", "]", ".", "extend", "(", "productions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_global_values": [[184, 189], ["GLOBAL_DATASET_VALUES.get", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "", "", "", "def", "update_grammar_with_global_values", "(", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "dataset_name", ":", "str", ")", ":", "\n", "\n", "    ", "values", "=", "GLOBAL_DATASET_VALUES", ".", "get", "(", "dataset_name", ",", "[", "]", ")", "\n", "values_for_grammar", "=", "[", "f'\"{str(value)}\"'", "for", "value", "in", "values", "]", "\n", "grammar_dictionary", "[", "\"value\"", "]", "=", "values_for_grammar", "+", "grammar_dictionary", "[", "\"value\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_to_be_variable_free": [[191, 228], ["None"], "function", ["None"], ["", "def", "update_grammar_to_be_variable_free", "(", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    SQL is a predominately variable free language in terms of simple usage, in the\n    sense that most queries do not create references to variables which are not\n    already static tables in a dataset. However, it is possible to do this via\n    derived tables. If we don't require this functionality, we can tighten the\n    grammar, because we don't need to support aliased tables.\n    \"\"\"", "\n", "\n", "# Tables in variable free grammars cannot be aliased, so we", "\n", "# remove this functionality from the grammar.", "\n", "grammar_dictionary", "[", "\"select_result\"", "]", "=", "[", "'\"*\"'", ",", "'(table_name ws \".*\")'", ",", "\"expr\"", "]", "\n", "\n", "# Similarly, collapse the definition of a source table", "\n", "# to not contain aliases and modify references to subqueries.", "\n", "grammar_dictionary", "[", "\"single_source\"", "]", "=", "[", "\"table_name\"", ",", "'(\"(\" ws query ws \")\")'", "]", "\n", "del", "grammar_dictionary", "[", "\"source_subq\"", "]", "\n", "del", "grammar_dictionary", "[", "\"source_table\"", "]", "\n", "\n", "grammar_dictionary", "[", "\"expr\"", "]", "=", "[", "\n", "\"in_expr\"", ",", "\n", "'(value wsp \"LIKE\" wsp string)'", ",", "\n", "'(value ws \"BETWEEN\" wsp value ws \"AND\" wsp value)'", ",", "\n", "\"(value ws binaryop wsp expr)\"", ",", "\n", "\"(unaryop ws expr)\"", ",", "\n", "'(col_ref ws \"IS\" ws \"NOT\" ws \"NULL\")'", ",", "\n", "'(col_ref ws \"IS\" ws \"NULL\")'", ",", "\n", "# This used to be source_subq - now", "\n", "# we don't need aliases, we can colapse it to queries.", "\n", "'(\"(\" ws query ws \")\")'", ",", "\n", "\"value\"", ",", "\n", "]", "\n", "\n", "# Finally, remove the ability to reference an arbitrary name,", "\n", "# because now we don't have aliased tables, we don't need", "\n", "# to recognise new variables.", "\n", "del", "grammar_dictionary", "[", "\"name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_untyped_entities": [[230, 244], ["grammar_dictionary[].remove", "grammar_dictionary[].remove"], "function", ["None"], ["", "def", "update_grammar_with_untyped_entities", "(", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Variables can be treated as numbers or strings if their type can be inferred -\n    however, that can be difficult, so instead, we can just treat them all as values\n    and be a bit looser on the typing we allow in our grammar. Here we just remove\n    all references to number and string from the grammar, replacing them with value.\n    \"\"\"", "\n", "grammar_dictionary", "[", "\"string_set_vals\"", "]", "=", "[", "'(value ws \",\" ws string_set_vals)'", ",", "\"value\"", "]", "\n", "grammar_dictionary", "[", "\"value\"", "]", ".", "remove", "(", "\"string\"", ")", "\n", "grammar_dictionary", "[", "\"value\"", "]", ".", "remove", "(", "\"number\"", ")", "\n", "grammar_dictionary", "[", "\"limit\"", "]", "=", "[", "'(\"LIMIT\" ws \"1\")'", ",", "'(\"LIMIT\" ws value)'", "]", "\n", "grammar_dictionary", "[", "\"expr\"", "]", "[", "1", "]", "=", "'(value wsp \"LIKE\" wsp value)'", "\n", "del", "grammar_dictionary", "[", "\"string\"", "]", "\n", "del", "grammar_dictionary", "[", "\"number\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_values_with_variables": [[246, 252], ["prelinked_entities.items"], "function", ["None"], ["", "def", "update_grammar_values_with_variables", "(", "\n", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "prelinked_entities", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "\n", ")", "->", "None", ":", "\n", "\n", "    ", "for", "variable", ",", "_", "in", "prelinked_entities", ".", "items", "(", ")", ":", "\n", "        ", "grammar_dictionary", "[", "\"value\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"value\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_numbers_and_strings_with_variables": [[254, 289], ["prelinked_entities.items", "info[].upper", "columns.get", "allennlp_semparse.common.sql.text2sql_utils.column_has_numeric_type", "allennlp_semparse.common.sql.text2sql_utils.column_has_string_type", "float", "info[].replace().isalpha", "info[].replace"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.column_has_numeric_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.column_has_string_type"], ["", "", "def", "update_grammar_numbers_and_strings_with_variables", "(", "\n", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "prelinked_entities", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", ",", "\n", "columns", ":", "Dict", "[", "str", ",", "TableColumn", "]", ",", "\n", ")", "->", "None", ":", "\n", "    ", "for", "variable", ",", "info", "in", "prelinked_entities", ".", "items", "(", ")", ":", "\n", "        ", "variable_column", "=", "info", "[", "\"type\"", "]", ".", "upper", "(", ")", "\n", "matched_column", "=", "columns", ".", "get", "(", "variable_column", ",", "None", ")", "\n", "\n", "if", "matched_column", "is", "not", "None", ":", "\n", "# Try to infer the variable's type by matching it to a column in", "\n", "# the database. If we can't, we just add it as a value.", "\n", "            ", "if", "column_has_numeric_type", "(", "matched_column", ")", ":", "\n", "                ", "grammar_dictionary", "[", "\"number\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"number\"", "]", "\n", "", "elif", "column_has_string_type", "(", "matched_column", ")", ":", "\n", "                ", "grammar_dictionary", "[", "\"string\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"string\"", "]", "\n", "", "else", ":", "\n", "                ", "grammar_dictionary", "[", "\"value\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"value\"", "]", "\n", "# Otherwise, try to infer by looking at the actual value:", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "# This is what happens if you try and do type inference", "\n", "# in a grammar which parses _strings_ in _Python_.", "\n", "# We're just seeing if the python interpreter can convert", "\n", "# to to a float - if it can, we assume it's a number.", "\n", "                ", "float", "(", "info", "[", "\"text\"", "]", ")", "\n", "is_numeric", "=", "True", "\n", "", "except", "ValueError", ":", "\n", "                ", "is_numeric", "=", "False", "\n", "", "if", "is_numeric", ":", "\n", "                ", "grammar_dictionary", "[", "\"number\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"number\"", "]", "\n", "", "elif", "info", "[", "\"text\"", "]", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "isalpha", "(", ")", ":", "\n", "                ", "grammar_dictionary", "[", "\"string\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"string\"", "]", "\n", "", "else", ":", "\n", "                ", "grammar_dictionary", "[", "\"value\"", "]", "=", "[", "f\"\\\"'{variable}'\\\"\"", "]", "+", "grammar_dictionary", "[", "\"value\"", "]", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.__init__": [[171, 175], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "grammar", ":", "Grammar", ",", "keywords_to_uppercase", ":", "List", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "action_sequence", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "self", ".", "grammar", ":", "Grammar", "=", "grammar", "\n", "self", ".", "keywords_to_uppercase", "=", "keywords_to_uppercase", "or", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.generic_visit": [[176, 182], ["sql_context_utils.SqlVisitor.add_action"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.add_action"], ["", "@", "overrides", "\n", "def", "generic_visit", "(", "self", ",", "node", ":", "Node", ",", "visited_children", ":", "List", "[", "None", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "self", ".", "add_action", "(", "node", ")", "\n", "if", "node", ".", "expr", ".", "name", "==", "\"statement\"", ":", "\n", "            ", "return", "self", ".", "action_sequence", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.add_action": [[183, 213], ["isinstance", "node.__iter__", "child_strings.append", "child.expr._as_rhs().lstrip().rstrip", "child_strings.extend", "child.expr._as_rhs().lstrip", "WHITESPACE_REGEX.split", "tok.upper", "tok.upper", "child.expr._as_rhs"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "add_action", "(", "self", ",", "node", ":", "Node", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        For each node, we accumulate the rules that generated its children in a list.\n        \"\"\"", "\n", "if", "node", ".", "expr", ".", "name", "and", "node", ".", "expr", ".", "name", "not", "in", "[", "\"ws\"", ",", "\"wsp\"", "]", ":", "\n", "            ", "nonterminal", "=", "f\"{node.expr.name} -> \"", "\n", "\n", "if", "isinstance", "(", "node", ".", "expr", ",", "Literal", ")", ":", "\n", "                ", "right_hand_side", "=", "f'[\"{node.text}\"]'", "\n", "\n", "", "else", ":", "\n", "                ", "child_strings", "=", "[", "]", "\n", "for", "child", "in", "node", ".", "__iter__", "(", ")", ":", "\n", "                    ", "if", "child", ".", "expr", ".", "name", "in", "[", "\"ws\"", ",", "\"wsp\"", "]", ":", "\n", "                        ", "continue", "\n", "", "if", "child", ".", "expr", ".", "name", "!=", "\"\"", ":", "\n", "                        ", "child_strings", ".", "append", "(", "child", ".", "expr", ".", "name", ")", "\n", "", "else", ":", "\n", "                        ", "child_right_side_string", "=", "child", ".", "expr", ".", "_as_rhs", "(", ")", ".", "lstrip", "(", "\"(\"", ")", ".", "rstrip", "(", "\")\"", ")", "\n", "child_right_side_list", "=", "[", "\n", "tok", "for", "tok", "in", "WHITESPACE_REGEX", ".", "split", "(", "child_right_side_string", ")", "if", "tok", "\n", "]", "\n", "child_right_side_list", "=", "[", "\n", "tok", ".", "upper", "(", ")", "if", "tok", ".", "upper", "(", ")", "in", "self", ".", "keywords_to_uppercase", "else", "tok", "\n", "for", "tok", "in", "child_right_side_list", "\n", "]", "\n", "child_strings", ".", "extend", "(", "child_right_side_list", ")", "\n", "", "", "right_hand_side", "=", "\"[\"", "+", "\", \"", ".", "join", "(", "child_strings", ")", "+", "\"]\"", "\n", "", "rule", "=", "nonterminal", "+", "right_hand_side", "\n", "self", ".", "action_sequence", "=", "[", "rule", "]", "+", "self", ".", "action_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.visit": [[214, 237], ["getattr", "getattr.", "sys.exc_info", "six.reraise", "sql_context_utils.SqlVisitor.visit", "parsimonious.exceptions.VisitationError", "reversed", "list"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.visit"], ["", "", "@", "overrides", "\n", "def", "visit", "(", "self", ",", "node", ")", ":", "\n", "        ", "\"\"\"\n        See the ``NodeVisitor`` visit method. This just changes the order in which\n        we visit nonterminals from right to left to left to right.\n        \"\"\"", "\n", "method", "=", "getattr", "(", "self", ",", "\"visit_\"", "+", "node", ".", "expr_name", ",", "self", ".", "generic_visit", ")", "\n", "\n", "# Call that method, and show where in the tree it failed if it blows", "\n", "# up.", "\n", "try", ":", "\n", "# Changing this to reverse here!", "\n", "            ", "return", "method", "(", "node", ",", "[", "self", ".", "visit", "(", "child", ")", "for", "child", "in", "reversed", "(", "list", "(", "node", ")", ")", "]", ")", "\n", "", "except", "(", "VisitationError", ",", "UndefinedLabel", ")", ":", "\n", "# Don't catch and re-wrap already-wrapped exceptions.", "\n", "            ", "raise", "\n", "", "except", "self", ".", "unwrapped_exceptions", ":", "\n", "            ", "raise", "\n", "", "except", "Exception", ":", "\n", "# Catch any exception, and tack on a parse tree so it's easier to", "\n", "# see where it went wrong.", "\n", "            ", "exc_class", ",", "exc", ",", "traceback", "=", "exc_info", "(", ")", "\n", "reraise", "(", "VisitationError", ",", "VisitationError", "(", "exc", ",", "exc_class", ",", "node", ")", ",", "traceback", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_grammar_string": [[17, 29], ["grammar_string.replace", "grammar_dictionary.items"], "function", ["None"], ["def", "format_grammar_string", "(", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Formats a dictionary of production rules into the string format expected\n    by the Parsimonious Grammar class.\n    \"\"\"", "\n", "grammar_string", "=", "\"\\n\"", ".", "join", "(", "\n", "[", "\n", "f\"{nonterminal} = {' / '.join(right_hand_side)}\"", "\n", "for", "nonterminal", ",", "right_hand_side", "in", "grammar_dictionary", ".", "items", "(", ")", "\n", "]", "\n", ")", "\n", "return", "grammar_string", ".", "replace", "(", "\"\\\\\"", ",", "\"\\\\\\\\\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.initialize_valid_actions": [[31, 77], ["collections.defaultdict", "isinstance", "sorted", "valid_actions[].add", "isinstance", "valid_actions.items", "sql_context_utils.format_action", "rhs._unicode_members", "isinstance", "valid_actions[].add", "rhs._unicode_members", "sql_context_utils.format_action", "valid_actions[].add", "set", "sql_context_utils.format_action", "repr"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action"], ["", "def", "initialize_valid_actions", "(", "\n", "grammar", ":", "Grammar", ",", "keywords_to_uppercase", ":", "List", "[", "str", "]", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    We initialize the valid actions with the global actions. These include the\n    valid actions that result from the grammar and also those that result from\n    the tables provided. The keys represent the nonterminals in the grammar\n    and the values are lists of the valid actions of that nonterminal.\n    \"\"\"", "\n", "valid_actions", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "\n", "for", "key", "in", "grammar", ":", "\n", "        ", "rhs", "=", "grammar", "[", "key", "]", "\n", "\n", "# Sequence represents a series of expressions that match pieces of the text in order.", "\n", "# Eg. A -> B C", "\n", "if", "isinstance", "(", "rhs", ",", "Sequence", ")", ":", "\n", "            ", "valid_actions", "[", "key", "]", ".", "add", "(", "\n", "format_action", "(", "\n", "key", ",", "\n", "\" \"", ".", "join", "(", "rhs", ".", "_unicode_members", "(", ")", ")", ",", "\n", "keywords_to_uppercase", "=", "keywords_to_uppercase", ",", "\n", ")", "\n", ")", "\n", "\n", "# OneOf represents a series of expressions, one of which matches the text.", "\n", "# Eg. A -> B / C", "\n", "", "elif", "isinstance", "(", "rhs", ",", "OneOf", ")", ":", "\n", "            ", "for", "option", "in", "rhs", ".", "_unicode_members", "(", ")", ":", "\n", "                ", "valid_actions", "[", "key", "]", ".", "add", "(", "\n", "format_action", "(", "key", ",", "option", ",", "keywords_to_uppercase", "=", "keywords_to_uppercase", ")", "\n", ")", "\n", "\n", "# A string literal, eg. \"A\"", "\n", "", "", "elif", "isinstance", "(", "rhs", ",", "Literal", ")", ":", "\n", "            ", "if", "rhs", ".", "literal", "!=", "\"\"", ":", "\n", "                ", "valid_actions", "[", "key", "]", ".", "add", "(", "\n", "format_action", "(", "\n", "key", ",", "repr", "(", "rhs", ".", "literal", ")", ",", "keywords_to_uppercase", "=", "keywords_to_uppercase", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "valid_actions", "[", "key", "]", "=", "set", "(", ")", "\n", "\n", "", "", "", "valid_action_strings", "=", "{", "key", ":", "sorted", "(", "value", ")", "for", "key", ",", "value", "in", "valid_actions", ".", "items", "(", ")", "}", "\n", "return", "valid_action_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action": [[79, 129], ["right_hand_side.lstrip().rstrip.upper", "right_hand_side.lstrip().rstrip.upper", "right_hand_side.lstrip().rstrip.lstrip().rstrip", "right_hand_side.lstrip().rstrip.lstrip", "WHITESPACE_REGEX.split", "tok.upper", "tok.upper"], "function", ["None"], ["", "def", "format_action", "(", "\n", "nonterminal", ":", "str", ",", "\n", "right_hand_side", ":", "str", ",", "\n", "is_string", ":", "bool", "=", "False", ",", "\n", "is_number", ":", "bool", "=", "False", ",", "\n", "keywords_to_uppercase", ":", "List", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    This function formats an action as it appears in models. It\n    splits productions based on the special `ws` and `wsp` rules,\n    which are used in grammars to denote whitespace, and then\n    rejoins these tokens a formatted, comma separated list.\n    Importantly, note that it `does not` split on spaces in\n    the grammar string, because these might not correspond\n    to spaces in the language the grammar recognises.\n\n    Parameters\n    ----------\n    nonterminal : ``str``, required.\n        The nonterminal in the action.\n    right_hand_side : ``str``, required.\n        The right hand side of the action\n        (i.e the thing which is produced).\n    is_string : ``bool``, optional (default = False).\n        Whether the production produces a string.\n        If it does, it is formatted as ``nonterminal -> ['string']``\n    is_number : ``bool``, optional, (default = False).\n        Whether the production produces a string.\n        If it does, it is formatted as ``nonterminal -> ['number']``\n    keywords_to_uppercase: ``List[str]``, optional, (default = None)\n        Keywords in the grammar to uppercase. In the case of sql,\n        this might be SELECT, MAX etc.\n    \"\"\"", "\n", "keywords_to_uppercase", "=", "keywords_to_uppercase", "or", "[", "]", "\n", "if", "right_hand_side", ".", "upper", "(", ")", "in", "keywords_to_uppercase", ":", "\n", "        ", "right_hand_side", "=", "right_hand_side", ".", "upper", "(", ")", "\n", "\n", "", "if", "is_string", ":", "\n", "        ", "return", "f\"{nonterminal} -> [\\\"'{right_hand_side}'\\\"]\"", "\n", "\n", "", "elif", "is_number", ":", "\n", "        ", "return", "f'{nonterminal} -> [\"{right_hand_side}\"]'", "\n", "\n", "", "else", ":", "\n", "        ", "right_hand_side", "=", "right_hand_side", ".", "lstrip", "(", "\"(\"", ")", ".", "rstrip", "(", "\")\"", ")", "\n", "child_strings", "=", "[", "token", "for", "token", "in", "WHITESPACE_REGEX", ".", "split", "(", "right_hand_side", ")", "if", "token", "]", "\n", "child_strings", "=", "[", "\n", "tok", ".", "upper", "(", ")", "if", "tok", ".", "upper", "(", ")", "in", "keywords_to_uppercase", "else", "tok", "for", "tok", "in", "child_strings", "\n", "]", "\n", "return", "f\"{nonterminal} -> [{', '.join(child_strings)}]\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.action_sequence_to_sql": [[131, 146], ["action.split", "right_hand_side[].split", "query.extend", "list", "token.strip", "enumerate"], "function", ["None"], ["", "", "def", "action_sequence_to_sql", "(", "action_sequences", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "# Convert an action sequence like ['statement -> [query, \";\"]', ...] to the", "\n", "# SQL string.", "\n", "    ", "query", "=", "[", "]", "\n", "for", "action", "in", "action_sequences", ":", "\n", "        ", "nonterminal", ",", "right_hand_side", "=", "action", ".", "split", "(", "\" -> \"", ")", "\n", "right_hand_side_tokens", "=", "right_hand_side", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", "\n", "if", "nonterminal", "==", "\"statement\"", ":", "\n", "            ", "query", ".", "extend", "(", "right_hand_side_tokens", ")", "\n", "", "else", ":", "\n", "            ", "for", "query_index", ",", "token", "in", "list", "(", "enumerate", "(", "query", ")", ")", ":", "\n", "                ", "if", "token", "==", "nonterminal", ":", "\n", "                    ", "query", "=", "query", "[", ":", "query_index", "]", "+", "right_hand_side_tokens", "+", "query", "[", "query_index", "+", "1", ":", "]", "\n", "break", "\n", "", "", "", "", "return", "\" \"", ".", "join", "(", "[", "token", ".", "strip", "(", "'\"'", ")", "for", "token", "in", "query", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.__init__": [[159, 181], ["atis_sql_table_context.AtisSqlTableContext.create_grammar_dict_and_strings", "atis_sql_table_context.AtisSqlTableContext.get_grammar_string", "parsimonious.grammar.Grammar", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.initialize_valid_actions", "allennlp.common.file_utils.cached_path", "sqlite3.connect", "atis_sql_table_context.AtisSqlTableContext.connection.cursor", "atis_sql_table_context.AtisSqlTableContext.connection.close"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.create_grammar_dict_and_strings", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.get_grammar_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.initialize_valid_actions"], ["def", "__init__", "(", "\n", "self", ",", "\n", "all_tables", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tables_with_strings", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "database_file", ":", "str", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "all_tables", "=", "all_tables", "\n", "self", ".", "tables_with_strings", "=", "tables_with_strings", "\n", "if", "database_file", ":", "\n", "            ", "self", ".", "database_file", "=", "cached_path", "(", "database_file", ")", "\n", "self", ".", "connection", "=", "sqlite3", ".", "connect", "(", "self", ".", "database_file", ")", "\n", "self", ".", "cursor", "=", "self", ".", "connection", ".", "cursor", "(", ")", "\n", "\n", "", "grammar_dictionary", ",", "strings_list", "=", "self", ".", "create_grammar_dict_and_strings", "(", ")", "\n", "self", ".", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "grammar_dictionary", "\n", "self", ".", "strings_list", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", "=", "strings_list", "\n", "\n", "self", ".", "grammar_string", ":", "str", "=", "self", ".", "get_grammar_string", "(", ")", "\n", "self", ".", "grammar", ":", "Grammar", "=", "Grammar", "(", "self", ".", "grammar_string", ")", "\n", "self", ".", "valid_actions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "initialize_valid_actions", "(", "self", ".", "grammar", ",", "KEYWORDS", ")", "\n", "if", "database_file", ":", "\n", "            ", "self", ".", "connection", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.get_grammar_dictionary": [[182, 184], ["None"], "methods", ["None"], ["", "", "def", "get_grammar_dictionary", "(", "self", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "return", "self", ".", "grammar_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.get_valid_actions": [[185, 187], ["None"], "methods", ["None"], ["", "def", "get_valid_actions", "(", "self", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "return", "self", ".", "valid_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.create_grammar_dict_and_strings": [[188, 253], ["copy.deepcopy", "sorted", "atis_sql_table_context.AtisSqlTableContext.all_tables.items", "sorted", "sorted", "atis_sql_table_context.AtisSqlTableContext.tables_with_strings.items", "sorted", "grammar_dictionary[].extend", "all_columns.extend", "biexprs.extend", "atis_sql_table_context.AtisSqlTableContext.cursor.execute", "atis_sql_table_context.AtisSqlTableContext.cursor.fetchall", "strings_list.extend", "column.endswith", "list", "atis_sql_table_context.AtisSqlTableContext.append", "sorted", "sorted", "atis_sql_table_context.AtisSqlTableContext.all_tables.keys", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_action", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "create_grammar_dict_and_strings", "(", "self", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", "]", ":", "\n", "        ", "grammar_dictionary", "=", "deepcopy", "(", "GRAMMAR_DICTIONARY", ")", "\n", "strings_list", "=", "[", "]", "\n", "\n", "if", "self", ".", "all_tables", ":", "\n", "            ", "grammar_dictionary", "[", "\"table_name\"", "]", "=", "sorted", "(", "\n", "[", "f'\"{table}\"'", "for", "table", "in", "list", "(", "self", ".", "all_tables", ".", "keys", "(", ")", ")", "]", ",", "reverse", "=", "True", "\n", ")", "\n", "grammar_dictionary", "[", "\"col_ref\"", "]", "=", "[", "'\"*\"'", ",", "\"agg\"", "]", "\n", "all_columns", "=", "[", "]", "\n", "for", "table", ",", "columns", "in", "self", ".", "all_tables", ".", "items", "(", ")", ":", "\n", "                ", "grammar_dictionary", "[", "\"col_ref\"", "]", ".", "extend", "(", "\n", "[", "f'(\"{table}\" ws \".\" ws \"{column}\")'", "for", "column", "in", "columns", "]", "\n", ")", "\n", "all_columns", ".", "extend", "(", "columns", ")", "\n", "", "grammar_dictionary", "[", "\"col_ref\"", "]", "=", "sorted", "(", "grammar_dictionary", "[", "\"col_ref\"", "]", ",", "reverse", "=", "True", ")", "\n", "grammar_dictionary", "[", "\"col\"", "]", "=", "sorted", "(", "\n", "[", "f'\"{column}\"'", "for", "column", "in", "all_columns", "]", ",", "reverse", "=", "True", "\n", ")", "\n", "\n", "", "biexprs", "=", "[", "]", "\n", "if", "self", ".", "tables_with_strings", ":", "\n", "            ", "for", "table", ",", "columns", "in", "self", ".", "tables_with_strings", ".", "items", "(", ")", ":", "\n", "                ", "biexprs", ".", "extend", "(", "\n", "[", "\n", "f'(\"{table}\" ws \".\" ws \"{column}\" ws binaryop ws {table}_{column}_string)'", "\n", "for", "column", "in", "columns", "\n", "]", "\n", ")", "\n", "for", "column", "in", "columns", ":", "\n", "                    ", "self", ".", "cursor", ".", "execute", "(", "f\"SELECT DISTINCT {table} . {column} FROM {table}\"", ")", "\n", "results", "=", "self", ".", "cursor", ".", "fetchall", "(", ")", "\n", "\n", "# Almost all the query values are in the database, we hardcode the rare case here.", "\n", "if", "table", "==", "\"flight\"", "and", "column", "==", "\"airline_code\"", ":", "\n", "                        ", "results", ".", "append", "(", "(", "\"EA\"", ",", ")", ")", "\n", "", "strings_list", ".", "extend", "(", "\n", "[", "\n", "(", "\n", "format_action", "(", "\n", "f\"{table}_{column}_string\"", ",", "\n", "str", "(", "row", "[", "0", "]", ")", ",", "\n", "is_string", "=", "\"number\"", "not", "in", "column", ",", "\n", "is_number", "=", "\"number\"", "in", "column", ",", "\n", ")", ",", "\n", "str", "(", "row", "[", "0", "]", ")", ",", "\n", ")", "\n", "for", "row", "in", "results", "\n", "]", "\n", ")", "\n", "\n", "if", "column", ".", "endswith", "(", "\"number\"", ")", ":", "\n", "                        ", "grammar_dictionary", "[", "f\"{table}_{column}_string\"", "]", "=", "sorted", "(", "\n", "[", "f'\"{str(row[0])}\"'", "for", "row", "in", "results", "]", ",", "reverse", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "grammar_dictionary", "[", "f\"{table}_{column}_string\"", "]", "=", "sorted", "(", "\n", "[", "f\"\\\"'{str(row[0])}'\\\"\"", "for", "row", "in", "results", "]", ",", "reverse", "=", "True", "\n", ")", "\n", "\n", "", "", "", "", "grammar_dictionary", "[", "\"biexpr\"", "]", "=", "sorted", "(", "biexprs", ",", "reverse", "=", "True", ")", "+", "[", "\n", "\"( col_ref ws binaryop ws value)\"", ",", "\n", "\"(value ws binaryop ws value)\"", ",", "\n", "]", "\n", "return", "grammar_dictionary", ",", "strings_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_sql_table_context.AtisSqlTableContext.get_grammar_string": [[254, 256], ["allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_grammar_string"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_grammar_string"], ["", "def", "get_grammar_string", "(", "self", ")", ":", "\n", "        ", "return", "format_grammar_string", "(", "self", ".", "grammar_dictionary", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.__init__": [[40, 75], ["set", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.DynamicTypeLogicParser", "NotImplementedError", "world.World.global_name_mapping.items"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "constant_type_prefixes", ":", "Dict", "[", "str", ",", "BasicType", "]", "=", "None", ",", "\n", "global_type_signatures", ":", "Dict", "[", "str", ",", "Type", "]", "=", "None", ",", "\n", "global_name_mapping", ":", "Dict", "[", "str", ",", "str", "]", "=", "None", ",", "\n", "num_nested_lambdas", ":", "int", "=", "0", ",", "\n", ")", "->", "None", ":", "\n", "# NLTK has a naming convention for variable types. If the world has predicate or entity names beyond", "\n", "# what's defined in the COMMON_NAME_MAPPING, they need to be added to this dict.", "\n", "# We initialize this dict with common predicate names and update it as we process logical forms.", "\n", "        ", "self", ".", "local_name_mapping", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "# Similarly, these are the type signatures not in the COMMON_TYPE_SIGNATURE.", "\n", "self", ".", "local_type_signatures", ":", "Dict", "[", "str", ",", "Type", "]", "=", "{", "}", "\n", "self", ".", "global_name_mapping", "=", "global_name_mapping", "or", "{", "}", "\n", "self", ".", "global_type_signatures", "=", "global_type_signatures", "or", "{", "}", "\n", "# We keep a reverse map as well to put the terminals back in action sequences.", "\n", "self", ".", "reverse_name_mapping", "=", "{", "\n", "mapped_name", ":", "name", "for", "name", ",", "mapped_name", "in", "self", ".", "global_name_mapping", ".", "items", "(", ")", "\n", "}", "\n", "type_prefixes", "=", "constant_type_prefixes", "or", "{", "}", "\n", "self", ".", "_num_nested_lambdas", "=", "num_nested_lambdas", "\n", "if", "num_nested_lambdas", ">", "3", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"For ease of implementation, we currently only handle at \"", "\n", "\"most three nested lambda expressions\"", "\n", ")", "\n", "", "self", ".", "_lambda_variables", "=", "set", "(", "[", "\"x\"", ",", "\"y\"", ",", "\"z\"", "]", "[", ":", "num_nested_lambdas", "]", ")", "\n", "self", ".", "_logic_parser", "=", "types", ".", "DynamicTypeLogicParser", "(", "\n", "constant_type_prefixes", "=", "type_prefixes", ",", "type_signatures", "=", "self", ".", "global_type_signatures", "\n", ")", "\n", "self", ".", "_right_side_indexed_actions", ":", "Dict", "[", "str", ",", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", "]", "=", "None", "\n", "# Caching this to avoid recompting it every time `get_valid_actions` is called.", "\n", "self", ".", "_valid_actions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", "\n", "# Caching this to avoid recompting it every time `get_multi_match_mapping` is called.", "\n", "self", ".", "_multi_match_mapping", ":", "Dict", "[", "Type", ",", "List", "[", "Type", "]", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_name_mapping": [[76, 79], ["None"], "methods", ["None"], ["", "def", "get_name_mapping", "(", "self", ")", "->", "Dict", "[", "str", ",", "str", "]", ":", "\n", "# Python 3.5 syntax for merging two dictionaries.", "\n", "        ", "return", "{", "**", "self", ".", "global_name_mapping", ",", "**", "self", ".", "local_name_mapping", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_type_signatures": [[80, 83], ["None"], "methods", ["None"], ["", "def", "get_type_signatures", "(", "self", ")", "->", "Dict", "[", "str", ",", "str", "]", ":", "\n", "# Python 3.5 syntax for merging two dictionaries.", "\n", "        ", "return", "{", "**", "self", ".", "global_type_signatures", ",", "**", "self", ".", "local_type_signatures", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.is_terminal": [[84, 95], ["None"], "methods", ["None"], ["", "def", "is_terminal", "(", "self", ",", "symbol", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        This function will be called on nodes of a logical form tree, which are either non-terminal\n        symbols that can be expanded or terminal symbols that must be leaf nodes.  Returns ``True``\n        if the given symbol is a terminal symbol.\n        \"\"\"", "\n", "# We special-case 'lambda' here because it behaves weirdly in action sequences.", "\n", "return", "(", "\n", "symbol", "in", "self", ".", "global_name_mapping", "\n", "or", "symbol", "in", "self", ".", "local_name_mapping", "\n", "or", "\"lambda\"", "in", "symbol", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_valid_actions": [[97, 109], ["world.World.get_multi_match_mapping", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.get_valid_actions", "world.World.get_name_mapping", "world.World.get_type_signatures", "world.World.get_basic_types", "world.World.get_valid_starting_types"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_multi_match_mapping", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_name_mapping", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_type_signatures", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_basic_types", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_valid_starting_types"], ["", "def", "get_valid_actions", "(", "self", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "_valid_actions", ":", "\n", "            ", "multi_match_mapping", "=", "self", ".", "get_multi_match_mapping", "(", ")", "\n", "self", ".", "_valid_actions", "=", "types", ".", "get_valid_actions", "(", "\n", "self", ".", "get_name_mapping", "(", ")", ",", "\n", "self", ".", "get_type_signatures", "(", ")", ",", "\n", "self", ".", "get_basic_types", "(", ")", ",", "\n", "valid_starting_types", "=", "self", ".", "get_valid_starting_types", "(", ")", ",", "\n", "num_nested_lambdas", "=", "self", ".", "_num_nested_lambdas", ",", "\n", "multi_match_mapping", "=", "multi_match_mapping", ",", "\n", ")", "\n", "", "return", "self", ".", "_valid_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_paths_to_root": [[110, 151], ["action.split", "world.World._get_right_side_indexed_actions", "completed_paths.append", "len", "list", "list.append", "len", "finished_new_lists.append", "unfinished_new_lists.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._get_right_side_indexed_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_paths_to_root", "(", "\n", "self", ",", "action", ":", "str", ",", "max_path_length", ":", "int", "=", "20", ",", "beam_size", ":", "int", "=", "30", ",", "max_num_paths", ":", "int", "=", "10", "\n", ")", "->", "List", "[", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"\n        For a given action, returns at most ``max_num_paths`` paths to the root (production with\n        ``START_SYMBOL``) that are not longer than ``max_path_length``.\n        \"\"\"", "\n", "action_left_side", ",", "_", "=", "action", ".", "split", "(", "\" -> \"", ")", "\n", "right_side_indexed_actions", "=", "self", ".", "_get_right_side_indexed_actions", "(", ")", "\n", "lists_to_expand", ":", "List", "[", "Tuple", "[", "str", ",", "List", "[", "str", "]", "]", "]", "=", "[", "(", "action_left_side", ",", "[", "action", "]", ")", "]", "\n", "completed_paths", "=", "[", "]", "\n", "while", "lists_to_expand", ":", "\n", "            ", "need_to_expand", "=", "False", "\n", "for", "left_side", ",", "path", "in", "lists_to_expand", ":", "\n", "                ", "if", "left_side", "==", "types", ".", "START_SYMBOL", ":", "\n", "                    ", "completed_paths", ".", "append", "(", "path", ")", "\n", "", "else", ":", "\n", "                    ", "need_to_expand", "=", "True", "\n", "", "", "if", "not", "need_to_expand", "or", "len", "(", "completed_paths", ")", ">=", "max_num_paths", ":", "\n", "                ", "break", "\n", "# We keep track of finished and unfinished lists separately because we truncate the beam", "\n", "# later, and we want the finished lists to be at the top of the beam.", "\n", "", "finished_new_lists", "=", "[", "]", "\n", "unfinished_new_lists", "=", "[", "]", "\n", "for", "left_side", ",", "actions", "in", "lists_to_expand", ":", "\n", "                ", "for", "next_left_side", ",", "next_action", "in", "right_side_indexed_actions", "[", "left_side", "]", ":", "\n", "                    ", "if", "next_action", "in", "actions", ":", "\n", "# Ignoring paths with loops (of size 1)", "\n", "                        ", "continue", "\n", "", "new_actions", "=", "list", "(", "actions", ")", "\n", "new_actions", ".", "append", "(", "next_action", ")", "\n", "# Ignoring lists that are too long, and have too many repetitions.", "\n", "path_length", "=", "len", "(", "new_actions", ")", "\n", "if", "path_length", "<=", "max_path_length", "or", "next_left_side", "==", "types", ".", "START_SYMBOL", ":", "\n", "                        ", "if", "next_left_side", "==", "types", ".", "START_SYMBOL", ":", "\n", "                            ", "finished_new_lists", ".", "append", "(", "(", "next_left_side", ",", "new_actions", ")", ")", "\n", "", "else", ":", "\n", "                            ", "unfinished_new_lists", ".", "append", "(", "(", "next_left_side", ",", "new_actions", ")", ")", "\n", "", "", "", "", "new_lists", "=", "finished_new_lists", "+", "unfinished_new_lists", "\n", "lists_to_expand", "=", "new_lists", "[", ":", "beam_size", "]", "\n", "", "return", "completed_paths", "[", ":", "max_num_paths", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.all_possible_actions": [[152, 162], ["set", "world.World.get_valid_actions().values", "range", "sorted", "set.update", "chr", "world.World.get_basic_types", "world.World.get_valid_actions", "set.add", "ord"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_basic_types", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "all_possible_actions", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "all_actions", "=", "set", "(", ")", "\n", "for", "action_set", "in", "self", ".", "get_valid_actions", "(", ")", ".", "values", "(", ")", ":", "\n", "            ", "all_actions", ".", "update", "(", "action_set", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "_num_nested_lambdas", ")", ":", "\n", "            ", "lambda_var", "=", "chr", "(", "ord", "(", "\"x\"", ")", "+", "i", ")", "\n", "for", "basic_type", "in", "self", ".", "get_basic_types", "(", ")", ":", "\n", "                ", "production", "=", "f\"{basic_type} -> {lambda_var}\"", "\n", "all_actions", ".", "add", "(", "production", ")", "\n", "", "", "return", "sorted", "(", "all_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._get_curried_functions": [[163, 165], ["NotImplementedError"], "methods", ["None"], ["", "def", "_get_curried_functions", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._get_right_side_indexed_actions": [[166, 183], ["collections.defaultdict", "world.World.all_possible_actions", "possible_action.split", "world.World._right_side_indexed_actions[].append", "right_side[].split", "world.World._right_side_indexed_actions[].append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.FakeWorldWithRecursion.all_possible_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_right_side_indexed_actions", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_right_side_indexed_actions", ":", "\n", "            ", "self", ".", "_right_side_indexed_actions", "=", "defaultdict", "(", "list", ")", "\n", "all_actions", "=", "self", ".", "all_possible_actions", "(", ")", "\n", "for", "possible_action", "in", "all_actions", ":", "\n", "                ", "left_side", ",", "right_side", "=", "possible_action", ".", "split", "(", "\" -> \"", ")", "\n", "if", "\"[\"", "not", "in", "right_side", ":", "\n", "                    ", "self", ".", "_right_side_indexed_actions", "[", "right_side", "]", ".", "append", "(", "\n", "(", "left_side", ",", "possible_action", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "right_side_parts", "=", "right_side", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", "\n", "for", "right_side_part", "in", "right_side_parts", ":", "\n", "                        ", "self", ".", "_right_side_indexed_actions", "[", "right_side_part", "]", ".", "append", "(", "\n", "(", "left_side", ",", "possible_action", ")", "\n", ")", "\n", "", "", "", "", "return", "self", ".", "_right_side_indexed_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_basic_types": [[184, 189], ["None"], "methods", ["None"], ["", "def", "get_basic_types", "(", "self", ")", "->", "Set", "[", "Type", "]", ":", "\n", "        ", "\"\"\"\n        Returns the set of basic types (types of entities) in the world.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_valid_starting_types": [[190, 196], ["None"], "methods", ["None"], ["", "def", "get_valid_starting_types", "(", "self", ")", "->", "Set", "[", "Type", "]", ":", "\n", "        ", "\"\"\"\n        Returns the set of all types t, such that actions ``{START_SYMBOL} -> t`` are valid. In other\n        words, these are all the possible types of complete logical forms in this world.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_multi_match_mapping": [[197, 218], ["world.World.get_basic_types", "isinstance", "matched_types.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_basic_types", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_multi_match_mapping", "(", "self", ")", "->", "Dict", "[", "Type", ",", "List", "[", "Type", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns a mapping from each `MultiMatchNamedBasicType` to all the `NamedBasicTypes` that it\n        matches.\n        \"\"\"", "\n", "if", "self", ".", "_multi_match_mapping", "is", "None", ":", "\n", "            ", "self", ".", "_multi_match_mapping", "=", "{", "}", "\n", "basic_types", "=", "self", ".", "get_basic_types", "(", ")", "\n", "for", "basic_type", "in", "basic_types", ":", "\n", "                ", "if", "isinstance", "(", "basic_type", ",", "types", ".", "MultiMatchNamedBasicType", ")", ":", "\n", "                    ", "matched_types", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "# We need to check if each type in the `types_to_match` field for the given", "\n", "# MultiMatchNamedBasic type is itself in the set of basic types allowed in this", "\n", "# world, and add it to the mapping only if it is. Some basic types that the", "\n", "# multi match type can match with may be diallowed in the world due to the", "\n", "# instance-specific context.", "\n", "for", "type_", "in", "basic_type", ".", "types_to_match", ":", "\n", "                        ", "if", "type_", "in", "basic_types", ":", "\n", "                            ", "matched_types", ".", "append", "(", "type_", ")", "\n", "", "", "self", ".", "_multi_match_mapping", "[", "basic_type", "]", "=", "matched_types", "\n", "", "", "", "return", "self", ".", "_multi_match_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.parse_logical_form": [[219, 247], ["allennlp_semparse.common.util.lisp_to_nested_expression", "world.World._process_nested_expression", "world.World.local_type_signatures.copy", "world.World.update", "world.World._logic_parser.parse", "re.sub.startswith", "re.sub", "re.sub"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util.lisp_to_nested_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._process_nested_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse"], ["", "def", "parse_logical_form", "(", "self", ",", "logical_form", ":", "str", ",", "remove_var_function", ":", "bool", "=", "True", ")", "->", "Expression", ":", "\n", "        ", "\"\"\"\n        Takes a logical form as a string, maps its tokens using the mapping and returns a parsed expression.\n\n        Parameters\n        ----------\n        logical_form : ``str``\n            Logical form to parse\n        remove_var_function : ``bool`` (optional)\n            ``var`` is a special function that some languages use within lambda functions to\n            indicate the usage of a variable. If your language uses it, and you do not want to\n            include it in the parsed expression, set this flag. You may want to do this if you are\n            generating an action sequence from this parsed expression, because it is easier to let\n            the decoder not produce this function due to the way constrained decoding is currently\n            implemented.\n        \"\"\"", "\n", "if", "not", "logical_form", ".", "startswith", "(", "\"(\"", ")", ":", "\n", "            ", "logical_form", "=", "f\"({logical_form})\"", "\n", "", "if", "remove_var_function", ":", "\n", "# Replace \"(x)\" with \"x\"", "\n", "            ", "logical_form", "=", "re", ".", "sub", "(", "r\"\\(([x-z])\\)\"", ",", "r\"\\1\"", ",", "logical_form", ")", "\n", "# Replace \"(var x)\" with \"(x)\"", "\n", "logical_form", "=", "re", ".", "sub", "(", "r\"\\(var ([x-z])\\)\"", ",", "r\"(\\1)\"", ",", "logical_form", ")", "\n", "", "parsed_lisp", "=", "util", ".", "lisp_to_nested_expression", "(", "logical_form", ")", "\n", "translated_string", "=", "self", ".", "_process_nested_expression", "(", "parsed_lisp", ")", "\n", "type_signature", "=", "self", ".", "local_type_signatures", ".", "copy", "(", ")", "\n", "type_signature", ".", "update", "(", "self", ".", "global_type_signatures", ")", "\n", "return", "self", ".", "_logic_parser", ".", "parse", "(", "translated_string", ",", "signature", "=", "type_signature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_action_sequence": [[248, 254], ["world.World._get_transitions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_transitions"], ["", "def", "get_action_sequence", "(", "self", ",", "expression", ":", "Expression", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Returns the sequence of actions (as strings) that resulted in the given expression.\n        \"\"\"", "\n", "# Starting with the type of the whole expression", "\n", "return", "self", ".", "_get_transitions", "(", "expression", ",", "[", "f\"{types.START_TYPE} -> {expression.type}\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_logical_form": [[255, 294], ["nltk.Tree", "allennlp_semparse.domain_languages.domain_language.nltk_tree_to_logical_form", "action.split", "world.World._construct_node_from_actions", "logger.error", "logger.error", "allennlp_semparse.common.errors.ParsingError", "logger.error"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.nltk_tree_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._construct_node_from_actions"], ["", "def", "get_logical_form", "(", "self", ",", "action_sequence", ":", "List", "[", "str", "]", ",", "add_var_function", ":", "bool", "=", "True", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Takes an action sequence and constructs a logical form from it. This is useful if you want\n        to get a logical form from a decoded sequence of actions generated by a transition based\n        semantic parser.\n\n        Parameters\n        ----------\n        action_sequence : ``List[str]``\n            The sequence of actions as strings (eg.: ``['{START_SYMBOL} -> t', 't -> <e,t>', ...]``).\n        add_var_function : ``bool`` (optional)\n             ``var`` is a special function that some languages use within lambda functions to\n             indicate the use of a variable (eg.: ``(lambda x (fb:row.row.year (var x)))``). Due to\n             the way constrained decoding is currently implemented, it is easier for the decoder to\n             not produce these functions. In that case, setting this flag adds the function in the\n             logical form even though it is not present in the action sequence.\n        \"\"\"", "\n", "# Basic outline: we assume that the bracketing that we get in the RHS of each action is the", "\n", "# correct bracketing for reconstructing the logical form.  This is true when there is no", "\n", "# currying in the action sequence.  Given this assumption, we just need to construct a tree", "\n", "# from the action sequence, then output all of the leaves in the tree, with brackets around", "\n", "# the children of all non-terminal nodes.", "\n", "\n", "remaining_actions", "=", "[", "action", ".", "split", "(", "\" -> \"", ")", "for", "action", "in", "action_sequence", "]", "\n", "tree", "=", "Tree", "(", "remaining_actions", "[", "0", "]", "[", "1", "]", ",", "[", "]", ")", "\n", "\n", "try", ":", "\n", "            ", "remaining_actions", "=", "self", ".", "_construct_node_from_actions", "(", "\n", "tree", ",", "remaining_actions", "[", "1", ":", "]", ",", "add_var_function", "\n", ")", "\n", "", "except", "ParsingError", ":", "\n", "            ", "logger", ".", "error", "(", "\"Error parsing action sequence: %s\"", ",", "action_sequence", ")", "\n", "raise", "\n", "\n", "", "if", "remaining_actions", ":", "\n", "            ", "logger", ".", "error", "(", "\"Error parsing action sequence: %s\"", ",", "action_sequence", ")", "\n", "logger", ".", "error", "(", "\"Remaining actions were: %s\"", ",", "remaining_actions", ")", "\n", "raise", "ParsingError", "(", "\"Extra actions in action sequence\"", ")", "\n", "", "return", "nltk_tree_to_logical_form", "(", "tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._construct_node_from_actions": [[295, 366], ["world.World.pop", "logger.error", "allennlp_semparse.common.errors.ParsingError", "current_node.label", "current_node.label", "right_side[].split", "world.World.is_terminal", "str", "logger.error", "logger.error", "logger.error", "allennlp_semparse.common.errors.ParsingError", "child_type.startswith", "nltk.Tree", "current_node.append", "current_node.append", "allennlp_semparse.common.errors.ParsingError", "str", "world.World.get_multi_match_mapping().items", "world.World.is_terminal", "world.World._construct_node_from_actions", "allennlp_semparse.common.errors.ParsingError", "nltk.Tree", "world.World.get_multi_match_mapping"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.is_terminal", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.is_terminal", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._construct_node_from_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_multi_match_mapping"], ["", "def", "_construct_node_from_actions", "(", "\n", "self", ",", "current_node", ":", "Tree", ",", "remaining_actions", ":", "List", "[", "List", "[", "str", "]", "]", ",", "add_var_function", ":", "bool", "\n", ")", "->", "List", "[", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"\n        Given a current node in the logical form tree, and a list of actions in an action sequence,\n        this method fills in the children of the current node from the action sequence, then\n        returns whatever actions are left.\n\n        For example, we could get a node with type ``c``, and an action sequence that begins with\n        ``c -> [<r,c>, r]``.  This method will add two children to the input node, consuming\n        actions from the action sequence for nodes of type ``<r,c>`` (and all of its children,\n        recursively) and ``r`` (and all of its children, recursively).  This method assumes that\n        action sequences are produced `depth-first`, so all actions for the subtree under ``<r,c>``\n        appear before actions for the subtree under ``r``.  If there are any actions in the action\n        sequence after the ``<r,c>`` and ``r`` subtrees have terminated in leaf nodes, they will be\n        returned.\n        \"\"\"", "\n", "if", "not", "remaining_actions", ":", "\n", "            ", "logger", ".", "error", "(", "\"No actions left to construct current node: %s\"", ",", "current_node", ")", "\n", "raise", "ParsingError", "(", "\"Incomplete action sequence\"", ")", "\n", "", "left_side", ",", "right_side", "=", "remaining_actions", ".", "pop", "(", "0", ")", "\n", "if", "left_side", "!=", "current_node", ".", "label", "(", ")", ":", "\n", "            ", "mismatch", "=", "True", "\n", "multi_match_mapping", "=", "{", "\n", "str", "(", "key", ")", ":", "[", "str", "(", "value", ")", "for", "value", "in", "values", "]", "\n", "for", "key", ",", "values", "in", "self", ".", "get_multi_match_mapping", "(", ")", ".", "items", "(", ")", "\n", "}", "\n", "current_label", "=", "current_node", ".", "label", "(", ")", "\n", "if", "(", "\n", "current_label", "in", "multi_match_mapping", "\n", "and", "left_side", "in", "multi_match_mapping", "[", "current_label", "]", "\n", ")", ":", "\n", "                ", "mismatch", "=", "False", "\n", "", "if", "mismatch", ":", "\n", "                ", "logger", ".", "error", "(", "\"Current node: %s\"", ",", "current_node", ")", "\n", "logger", ".", "error", "(", "\"Next action: %s -> %s\"", ",", "left_side", ",", "right_side", ")", "\n", "logger", ".", "error", "(", "\"Remaining actions were: %s\"", ",", "remaining_actions", ")", "\n", "raise", "ParsingError", "(", "\"Current node does not match next action\"", ")", "\n", "", "", "if", "right_side", "[", "0", "]", "==", "\"[\"", ":", "\n", "# This is a non-terminal expansion, with more than one child node.", "\n", "            ", "for", "child_type", "in", "right_side", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", ":", "\n", "                ", "if", "child_type", ".", "startswith", "(", "\"'lambda\"", ")", ":", "\n", "# We need to special-case the handling of lambda here, because it's handled a", "\n", "# bit weirdly in the action sequence.  This is stripping off the single quotes", "\n", "# around something like `'lambda x'`.", "\n", "                    ", "child_type", "=", "child_type", "[", "1", ":", "-", "1", "]", "\n", "", "child_node", "=", "Tree", "(", "child_type", ",", "[", "]", ")", "\n", "current_node", ".", "append", "(", "child_node", ")", "# you add a child to an nltk.Tree with `append`", "\n", "if", "not", "self", ".", "is_terminal", "(", "child_type", ")", ":", "\n", "                    ", "remaining_actions", "=", "self", ".", "_construct_node_from_actions", "(", "\n", "child_node", ",", "remaining_actions", ",", "add_var_function", "\n", ")", "\n", "", "", "", "elif", "self", ".", "is_terminal", "(", "right_side", ")", ":", "\n", "# The current node is a pre-terminal; we'll add a single terminal child.  We need to", "\n", "# check first for whether we need to add a (var _) around the terminal node, though.", "\n", "            ", "if", "add_var_function", "and", "right_side", "in", "self", ".", "_lambda_variables", ":", "\n", "                ", "right_side", "=", "f\"(var {right_side})\"", "\n", "", "if", "add_var_function", "and", "right_side", "==", "\"var\"", ":", "\n", "                ", "raise", "ParsingError", "(", "\"add_var_function was true, but action sequence already had var\"", ")", "\n", "", "current_node", ".", "append", "(", "\n", "Tree", "(", "right_side", ",", "[", "]", ")", "\n", ")", "# you add a child to an nltk.Tree with `append`", "\n", "", "else", ":", "\n", "# The only way this can happen is if you have a unary non-terminal production rule.", "\n", "# That is almost certainly not what you want with this kind of grammar, so we'll crash.", "\n", "# If you really do want this, open a PR with a valid use case.", "\n", "            ", "raise", "ParsingError", "(", "\n", "f\"Found a unary production rule: {left_side} -> {right_side}. \"", "\n", "\"Are you sure you want a unary production rule in your grammar?\"", "\n", ")", "\n", "", "return", "remaining_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._infer_num_arguments": [[367, 397], ["cls._infer_num_arguments"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._infer_num_arguments"], ["", "@", "classmethod", "\n", "def", "_infer_num_arguments", "(", "cls", ",", "type_signature", ":", "str", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Takes a type signature and infers the number of arguments the corresponding function takes.\n        Examples:\n            e -> 0\n            <r,e> -> 1\n            <e,<e,t>> -> 2\n            <b,<<b,#1>,<#1,b>>> -> 3\n        \"\"\"", "\n", "if", "\"<\"", "not", "in", "type_signature", ":", "\n", "            ", "return", "0", "\n", "# We need to find the return type from the signature. We do that by removing the outer most", "\n", "# angular brackets and traversing the remaining substring till the angular brackets (if any)", "\n", "# balance. Once we hit a comma after the angular brackets are balanced, whatever is left", "\n", "# after it is the return type.", "\n", "", "type_signature", "=", "type_signature", "[", "1", ":", "-", "1", "]", "\n", "num_brackets", "=", "0", "\n", "char_index", "=", "0", "\n", "for", "char", "in", "type_signature", ":", "\n", "            ", "if", "char", "==", "\"<\"", ":", "\n", "                ", "num_brackets", "+=", "1", "\n", "", "elif", "char", "==", "\">\"", ":", "\n", "                ", "num_brackets", "-=", "1", "\n", "", "elif", "char", "==", "\",\"", ":", "\n", "                ", "if", "num_brackets", "==", "0", ":", "\n", "                    ", "break", "\n", "", "", "char_index", "+=", "1", "\n", "", "return_type", "=", "type_signature", "[", "char_index", "+", "1", ":", "]", "\n", "return", "1", "+", "cls", ".", "_infer_num_arguments", "(", "return_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._process_nested_expression": [[398, 425], ["isinstance", "len", "all", "isinstance", "world.World._process_nested_expression", "isinstance", "zip", "world.World._map_name", "mapped_names.append", "mapped_names.append", "world.World._map_name", "world.World._process_nested_expression"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._process_nested_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._map_name", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._map_name", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._process_nested_expression"], ["", "def", "_process_nested_expression", "(", "self", ",", "nested_expression", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        ``nested_expression`` is the result of parsing a logical form in Lisp format.\n        We process it recursively and return a string in the format that NLTK's ``LogicParser``\n        would understand.\n        \"\"\"", "\n", "expression_is_list", "=", "isinstance", "(", "nested_expression", ",", "list", ")", "\n", "expression_size", "=", "len", "(", "nested_expression", ")", "\n", "if", "expression_is_list", "and", "expression_size", "==", "1", "and", "isinstance", "(", "nested_expression", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "return", "self", ".", "_process_nested_expression", "(", "nested_expression", "[", "0", "]", ")", "\n", "", "elements_are_leaves", "=", "[", "isinstance", "(", "element", ",", "str", ")", "for", "element", "in", "nested_expression", "]", "\n", "if", "all", "(", "elements_are_leaves", ")", ":", "\n", "            ", "mapped_names", "=", "[", "self", ".", "_map_name", "(", "name", ")", "for", "name", "in", "nested_expression", "]", "\n", "", "else", ":", "\n", "            ", "mapped_names", "=", "[", "]", "\n", "for", "element", ",", "is_leaf", "in", "zip", "(", "nested_expression", ",", "elements_are_leaves", ")", ":", "\n", "                ", "if", "is_leaf", ":", "\n", "                    ", "mapped_names", ".", "append", "(", "self", ".", "_map_name", "(", "element", ")", ")", "\n", "", "else", ":", "\n", "                    ", "mapped_names", ".", "append", "(", "self", ".", "_process_nested_expression", "(", "element", ")", ")", "\n", "", "", "", "if", "mapped_names", "[", "0", "]", "==", "\"\\\\\"", ":", "\n", "# This means the predicate is lambda. NLTK wants the variable name to not be within parantheses.", "\n", "# Adding parentheses after the variable.", "\n", "            ", "arguments", "=", "[", "mapped_names", "[", "1", "]", "]", "+", "[", "f\"({name})\"", "for", "name", "in", "mapped_names", "[", "2", ":", "]", "]", "\n", "", "else", ":", "\n", "            ", "arguments", "=", "[", "f\"({name})\"", "for", "name", "in", "mapped_names", "[", "1", ":", "]", "]", "\n", "", "return", "f'({mapped_names[0]} {\" \".join(arguments)})'", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._map_name": [[426, 449], ["None"], "methods", ["None"], ["", "def", "_map_name", "(", "self", ",", "name", ":", "str", ",", "keep_mapping", ":", "bool", "=", "False", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Takes the name of a predicate or a constant as used by Sempre, maps it to a unique string\n        such that NLTK processes it appropriately. This is needed because NLTK has a naming\n        convention for variables:\n\n            - Function variables: Single upper case letter optionally followed by digits\n            - Individual variables: Single lower case letter (except e for events) optionally\n              followed by digits\n            - Constants: Everything else\n\n        Parameters\n        ----------\n        name : ``str``\n            Token from Sempre's logical form.\n        keep_mapping : ``bool``, optional (default=False)\n            If this is ``True``, we will add the name and its mapping to our local state, so that\n            :func:`get_name_mapping` and :func:`get_valid_actions` know about it.  You typically\n            want to do this when you're `initializing` the object, but you very likely don't want\n            to when you're parsing logical forms - getting an ill-formed logical form can then\n            change your state in bad ways, for instance.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._add_name_mapping": [[450, 460], ["None"], "methods", ["None"], ["", "def", "_add_name_mapping", "(", "self", ",", "name", ":", "str", ",", "translated_name", ":", "str", ",", "name_type", ":", "Type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Utility method to add a name and its translation to the local name mapping, and the corresponding\n        signature, if available to the local type signatures. This method also updates the reverse name\n        mapping.\n        \"\"\"", "\n", "self", ".", "local_name_mapping", "[", "name", "]", "=", "translated_name", "\n", "self", ".", "reverse_name_mapping", "[", "translated_name", "]", "=", "name", "\n", "if", "name_type", ":", "\n", "            ", "self", ".", "local_type_signatures", "[", "translated_name", "]", "=", "name_type", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._get_transitions": [[461, 523], ["world.World._get_curried_functions", "expression.visit", "isinstance", "isinstance", "current_transitions.append", "world.World._get_transitions", "str", "current_transitions.append", "expression.uncurry", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World._get_curried_functions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.SqlVisitor.visit", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_transitions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "def", "_get_transitions", "(", "self", ",", "expression", ":", "Expression", ",", "current_transitions", ":", "List", "[", "str", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "# The way we handle curried functions in here is a bit of a mess, but it works.  For any", "\n", "# function that takes more than one argument, the NLTK Expression object will be curried,", "\n", "# and so the standard \"visitor\" pattern used by NLTK will result in action sequences that", "\n", "# are also curried.  We need to detect these curried functions and uncurry them in the", "\n", "# action sequence.  We do that by keeping around a dictionary mapping multi-argument", "\n", "# functions to the number of arguments they take.  When we see a multi-argument function,", "\n", "# we check to see if we're at the top-level, first instance of that function by checking", "\n", "# its number of arguments with NLTK's `uncurry()` function.  If it is, we output an action", "\n", "# using those arguments.  Otherwise, we're at an intermediate node of a curried function,", "\n", "# and we squelch the action that would normally be generated.", "\n", "# TODO(mattg): There might be some way of removing the need for `curried_functions` here,", "\n", "# using instead the `argument_types()` function I added to `ComplexType`, but my guess is", "\n", "# that it would involve needing to modify nltk, and I don't want to bother with figuring", "\n", "# that out right now.", "\n", "        ", "curried_functions", "=", "self", ".", "_get_curried_functions", "(", ")", "\n", "expression_type", "=", "expression", ".", "type", "\n", "try", ":", "\n", "# ``Expression.visit()`` takes two arguments: the first one is a function applied on", "\n", "# each sub-expression and the second is a combinator that is applied to the list of", "\n", "# values returned from the function applications. We just want the list of all", "\n", "# sub-expressions here.", "\n", "            ", "sub_expressions", "=", "expression", ".", "visit", "(", "lambda", "x", ":", "x", ",", "lambda", "x", ":", "x", ")", "\n", "transformed_types", "=", "[", "sub_exp", ".", "type", "for", "sub_exp", "in", "sub_expressions", "]", "\n", "\n", "if", "isinstance", "(", "expression", ",", "LambdaExpression", ")", ":", "\n", "# If the expression is a lambda expression, the list of sub expressions does not", "\n", "# include the \"lambda x\" term. We're adding it here so that we will see transitions", "\n", "# like", "\n", "#   <e,d> -> [\\x, d] instead of", "\n", "#   <e,d> -> [d]", "\n", "                ", "transformed_types", "=", "[", "\"lambda x\"", "]", "+", "transformed_types", "\n", "", "elif", "isinstance", "(", "expression", ",", "ApplicationExpression", ")", ":", "\n", "                ", "function", ",", "arguments", "=", "expression", ".", "uncurry", "(", ")", "\n", "function_type", "=", "function", ".", "type", "\n", "if", "function_type", "in", "curried_functions", ":", "\n", "                    ", "expected_num_arguments", "=", "curried_functions", "[", "function_type", "]", "\n", "if", "len", "(", "arguments", ")", "==", "expected_num_arguments", ":", "\n", "# This is the initial application of a curried function.  We'll use this", "\n", "# node in the expression to generate the action for this function, using", "\n", "# all of its arguments.", "\n", "                        ", "transformed_types", "=", "[", "function", ".", "type", "]", "+", "[", "\n", "argument", ".", "type", "for", "argument", "in", "arguments", "\n", "]", "\n", "", "else", ":", "\n", "# We're at an intermediate node.  We'll set `transformed_types` to `None`", "\n", "# to indicate that we need to squelch this action.", "\n", "                        ", "transformed_types", "=", "None", "\n", "\n", "", "", "", "if", "transformed_types", ":", "\n", "                ", "transition", "=", "f\"{expression_type} -> {transformed_types}\"", "\n", "current_transitions", ".", "append", "(", "transition", ")", "\n", "", "for", "sub_expression", "in", "sub_expressions", ":", "\n", "                ", "self", ".", "_get_transitions", "(", "sub_expression", ",", "current_transitions", ")", "\n", "", "", "except", "NotImplementedError", ":", "\n", "# This means that the expression is a leaf. We simply make a transition from its type to itself.", "\n", "            ", "original_name", "=", "str", "(", "expression", ")", "\n", "if", "original_name", "in", "self", ".", "reverse_name_mapping", ":", "\n", "                ", "original_name", "=", "self", ".", "reverse_name_mapping", "[", "original_name", "]", "\n", "", "transition", "=", "f\"{expression_type} -> {original_name}\"", "\n", "current_transitions", ".", "append", "(", "transition", ")", "\n", "", "return", "current_transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.__eq__": [[524, 528], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.__init__": [[69, 88], ["atis_world.AtisWorld._get_dates", "atis_world.AtisWorld._get_linked_entities", "atis_world.AtisWorld._flatten_entities", "atis_world.AtisWorld._update_grammar", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.initialize_valid_actions", "allennlp_semparse.parsimonious_languages.contexts.atis_sql_table_context.AtisSqlTableContext", "allennlp.data.tokenizers.SpacyTokenizer", "atis_world.AtisWorld.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_dates", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_linked_entities", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._flatten_entities", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._update_grammar", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.initialize_valid_actions"], ["def", "__init__", "(", "self", ",", "utterances", ":", "List", "[", "str", "]", ",", "tokenizer", ":", "Tokenizer", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "AtisWorld", ".", "sql_table_context", "is", "None", ":", "\n", "            ", "AtisWorld", ".", "sql_table_context", "=", "AtisSqlTableContext", "(", "\n", "atis_tables", ".", "ALL_TABLES", ",", "atis_tables", ".", "TABLES_WITH_STRINGS", ",", "AtisWorld", ".", "database_file", "\n", ")", "\n", "", "self", ".", "utterances", ":", "List", "[", "str", "]", "=", "utterances", "\n", "self", ".", "tokenizer", "=", "tokenizer", "if", "tokenizer", "else", "SpacyTokenizer", "(", ")", "\n", "self", ".", "tokenized_utterances", "=", "[", "\n", "self", ".", "tokenizer", ".", "tokenize", "(", "utterance", ")", "for", "utterance", "in", "self", ".", "utterances", "\n", "]", "\n", "self", ".", "dates", "=", "self", ".", "_get_dates", "(", ")", "\n", "self", ".", "linked_entities", "=", "self", ".", "_get_linked_entities", "(", ")", "\n", "\n", "entities", ",", "linking_scores", "=", "self", ".", "_flatten_entities", "(", ")", "\n", "# This has shape (num_entities, num_utterance_tokens).", "\n", "self", ".", "linking_scores", ":", "numpy", ".", "ndarray", "=", "linking_scores", "\n", "self", ".", "entities", ":", "List", "[", "str", "]", "=", "entities", "\n", "self", ".", "grammar", ":", "Grammar", "=", "self", ".", "_update_grammar", "(", ")", "\n", "self", ".", "valid_actions", "=", "initialize_valid_actions", "(", "self", ".", "grammar", ",", "KEYWORDS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._update_grammar": [[89, 225], ["copy.copy.copy", "atis_world.AtisWorld._update_expression_reference", "parsimonious.expressions.OneOf", "atis_world.AtisWorld._update_expression_reference", "atis_world.AtisWorld._get_sequence_with_spacing", "new_binary_expressions.append", "atis_world.AtisWorld._get_sequence_with_spacing", "new_binary_expressions.append", "atis_world.AtisWorld._get_sequence_with_spacing", "new_binary_expressions.append", "parsimonious.expressions.OneOf", "atis_world.AtisWorld._update_expression_reference", "atis_world.AtisWorld._add_numeric_nonterminal_to_grammar", "atis_world.AtisWorld._get_sequence_with_spacing", "atis_world.AtisWorld._get_sequence_with_spacing", "atis_world.AtisWorld._get_sequence_with_spacing", "atis_world.AtisWorld._get_sequence_with_spacing", "atis_world.AtisWorld._get_sequence_with_spacing", "atis_world.AtisWorld._get_sequence_with_spacing", "new_binary_expressions.extend", "list", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._update_expression_reference", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._update_expression_reference", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._update_expression_reference", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._add_numeric_nonterminal_to_grammar", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing"], ["", "def", "_update_grammar", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        We create a new ``Grammar`` object from the one in ``AtisSqlTableContext``, that also\n        has the new entities that are extracted from the utterance. Stitching together the expressions\n        to form the grammar is a little tedious here, but it is worth it because we don't have to create\n        a new grammar from scratch. Creating a new grammar is expensive because we have many production\n        rules that have all database values in the column on the right hand side. We update the expressions\n        bottom up, since the higher level expressions may refer to the lower level ones. For example, the\n        ternary expression will refer to the start and end times.\n        \"\"\"", "\n", "\n", "# This will give us a shallow copy. We have to be careful here because the ``Grammar`` object", "\n", "# contains ``Expression`` objects that have tuples containing the members of that expression.", "\n", "# We have to create new sub-expression objects so that original grammar is not mutated.", "\n", "new_grammar", "=", "copy", "(", "AtisWorld", ".", "sql_table_context", ".", "grammar", ")", "\n", "\n", "for", "numeric_nonterminal", "in", "NUMERIC_NONTERMINALS", ":", "\n", "            ", "self", ".", "_add_numeric_nonterminal_to_grammar", "(", "numeric_nonterminal", ",", "new_grammar", ")", "\n", "", "self", ".", "_update_expression_reference", "(", "new_grammar", ",", "\"pos_value\"", ",", "\"number\"", ")", "\n", "\n", "ternary_expressions", "=", "[", "\n", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "new_grammar", "[", "\"col_ref\"", "]", ",", "\n", "Literal", "(", "\"BETWEEN\"", ")", ",", "\n", "new_grammar", "[", "\"time_range_start\"", "]", ",", "\n", "Literal", "(", "\"AND\"", ")", ",", "\n", "new_grammar", "[", "\"time_range_end\"", "]", ",", "\n", "]", ",", "\n", ")", ",", "\n", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "new_grammar", "[", "\"col_ref\"", "]", ",", "\n", "Literal", "(", "\"NOT\"", ")", ",", "\n", "Literal", "(", "\"BETWEEN\"", ")", ",", "\n", "new_grammar", "[", "\"time_range_start\"", "]", ",", "\n", "Literal", "(", "\"AND\"", ")", ",", "\n", "new_grammar", "[", "\"time_range_end\"", "]", ",", "\n", "]", ",", "\n", ")", ",", "\n", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "new_grammar", "[", "\"col_ref\"", "]", ",", "\n", "Literal", "(", "\"not\"", ")", ",", "\n", "Literal", "(", "\"BETWEEN\"", ")", ",", "\n", "new_grammar", "[", "\"time_range_start\"", "]", ",", "\n", "Literal", "(", "\"AND\"", ")", ",", "\n", "new_grammar", "[", "\"time_range_end\"", "]", ",", "\n", "]", ",", "\n", ")", ",", "\n", "]", "\n", "\n", "new_grammar", "[", "\"ternaryexpr\"", "]", "=", "OneOf", "(", "*", "ternary_expressions", ",", "name", "=", "\"ternaryexpr\"", ")", "\n", "self", ".", "_update_expression_reference", "(", "new_grammar", ",", "\"condition\"", ",", "\"ternaryexpr\"", ")", "\n", "\n", "new_binary_expressions", "=", "[", "]", "\n", "\n", "fare_round_trip_cost_expression", "=", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "Literal", "(", "\"fare\"", ")", ",", "\n", "Literal", "(", "\".\"", ")", ",", "\n", "Literal", "(", "\"round_trip_cost\"", ")", ",", "\n", "new_grammar", "[", "\"binaryop\"", "]", ",", "\n", "new_grammar", "[", "\"fare_round_trip_cost\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "new_binary_expressions", ".", "append", "(", "fare_round_trip_cost_expression", ")", "\n", "\n", "fare_one_direction_cost_expression", "=", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "Literal", "(", "\"fare\"", ")", ",", "\n", "Literal", "(", "\".\"", ")", ",", "\n", "Literal", "(", "\"one_direction_cost\"", ")", ",", "\n", "new_grammar", "[", "\"binaryop\"", "]", ",", "\n", "new_grammar", "[", "\"fare_one_direction_cost\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "new_binary_expressions", ".", "append", "(", "fare_one_direction_cost_expression", ")", "\n", "\n", "flight_number_expression", "=", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "Literal", "(", "\"flight\"", ")", ",", "\n", "Literal", "(", "\".\"", ")", ",", "\n", "Literal", "(", "\"flight_number\"", ")", ",", "\n", "new_grammar", "[", "\"binaryop\"", "]", ",", "\n", "new_grammar", "[", "\"flight_number\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "new_binary_expressions", ".", "append", "(", "flight_number_expression", ")", "\n", "\n", "if", "self", ".", "dates", ":", "\n", "            ", "year_binary_expression", "=", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "Literal", "(", "\"date_day\"", ")", ",", "\n", "Literal", "(", "\".\"", ")", ",", "\n", "Literal", "(", "\"year\"", ")", ",", "\n", "new_grammar", "[", "\"binaryop\"", "]", ",", "\n", "new_grammar", "[", "\"year_number\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "month_binary_expression", "=", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "Literal", "(", "\"date_day\"", ")", ",", "\n", "Literal", "(", "\".\"", ")", ",", "\n", "Literal", "(", "\"month_number\"", ")", ",", "\n", "new_grammar", "[", "\"binaryop\"", "]", ",", "\n", "new_grammar", "[", "\"month_number\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "day_binary_expression", "=", "self", ".", "_get_sequence_with_spacing", "(", "\n", "new_grammar", ",", "\n", "[", "\n", "Literal", "(", "\"date_day\"", ")", ",", "\n", "Literal", "(", "\".\"", ")", ",", "\n", "Literal", "(", "\"day_number\"", ")", ",", "\n", "new_grammar", "[", "\"binaryop\"", "]", ",", "\n", "new_grammar", "[", "\"day_number\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "new_binary_expressions", ".", "extend", "(", "\n", "[", "year_binary_expression", ",", "month_binary_expression", ",", "day_binary_expression", "]", "\n", ")", "\n", "\n", "", "new_binary_expressions", "=", "new_binary_expressions", "+", "list", "(", "new_grammar", "[", "\"biexpr\"", "]", ".", "members", ")", "\n", "new_grammar", "[", "\"biexpr\"", "]", "=", "OneOf", "(", "*", "new_binary_expressions", ",", "name", "=", "\"biexpr\"", ")", "\n", "self", ".", "_update_expression_reference", "(", "new_grammar", ",", "\"condition\"", ",", "\"biexpr\"", ")", "\n", "return", "new_grammar", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_numeric_database_values": [[226, 234], ["sorted", "atis_world.AtisWorld.linked_entities[].items"], "methods", ["None"], ["", "def", "_get_numeric_database_values", "(", "self", ",", "nonterminal", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "sorted", "(", "\n", "[", "\n", "value", "[", "1", "]", "\n", "for", "key", ",", "value", "in", "self", ".", "linked_entities", "[", "\"number\"", "]", ".", "items", "(", ")", "\n", "if", "value", "[", "0", "]", "==", "nonterminal", "\n", "]", ",", "\n", "reverse", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._add_numeric_nonterminal_to_grammar": [[236, 241], ["atis_world.AtisWorld._get_numeric_database_values", "parsimonious.expressions.Literal", "parsimonious.expressions.OneOf"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_numeric_database_values"], ["", "def", "_add_numeric_nonterminal_to_grammar", "(", "self", ",", "nonterminal", ":", "str", ",", "new_grammar", ":", "Grammar", ")", "->", "None", ":", "\n", "        ", "numbers", "=", "self", ".", "_get_numeric_database_values", "(", "nonterminal", ")", "\n", "number_literals", "=", "[", "Literal", "(", "number", ")", "for", "number", "in", "numbers", "]", "\n", "if", "number_literals", ":", "\n", "            ", "new_grammar", "[", "nonterminal", "]", "=", "OneOf", "(", "*", "number_literals", ",", "name", "=", "nonterminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._update_expression_reference": [[242, 257], ["None"], "methods", ["None"], ["", "", "def", "_update_expression_reference", "(", "\n", "self", ",", "\n", "grammar", ":", "Grammar", ",", "\n", "parent_expression_nonterminal", ":", "str", ",", "\n", "child_expression_nonterminal", ":", "str", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        When we add a new expression, there may be other expressions that refer to\n        it, and we need to update those to point to the new expression.\n        \"\"\"", "\n", "grammar", "[", "parent_expression_nonterminal", "]", ".", "members", "=", "[", "\n", "member", "\n", "if", "member", ".", "name", "!=", "child_expression_nonterminal", "\n", "else", "grammar", "[", "child_expression_nonterminal", "]", "\n", "for", "member", "in", "grammar", "[", "parent_expression_nonterminal", "]", ".", "members", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing": [[259, 272], ["parsimonious.expressions.Sequence"], "methods", ["None"], ["", "def", "_get_sequence_with_spacing", "(", "\n", "self", ",", "new_grammar", ",", "expressions", ":", "List", "[", "Expression", "]", ",", "name", ":", "str", "=", "\"\"", "\n", ")", "->", "Sequence", ":", "\n", "        ", "\"\"\"\n        This is a helper method for generating sequences, since we often want a list of expressions\n        with whitespaces between them.\n        \"\"\"", "\n", "expressions", "=", "[", "\n", "subexpression", "\n", "for", "expression", "in", "expressions", "\n", "for", "subexpression", "in", "(", "expression", ",", "new_grammar", "[", "\"ws\"", "]", ")", "\n", "]", "\n", "return", "Sequence", "(", "*", "expressions", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_valid_actions": [[273, 275], ["None"], "methods", ["None"], ["", "def", "get_valid_actions", "(", "self", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "return", "self", ".", "valid_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_dates_to_number_linking_scores": [[276, 334], ["str", "str", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.MONTH_NUMBERS.items", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.DAY_NUMBERS.items", "enumerate", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_action", "enumerate", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_action", "enumerate", "enumerate", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_action", "str", "str", "nltk.bigrams", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "add_dates_to_number_linking_scores", "(", "\n", "self", ",", "\n", "number_linking_scores", ":", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "current_tokenized_utterance", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "month_reverse_lookup", "=", "{", "\n", "str", "(", "number", ")", ":", "string", "for", "string", ",", "number", "in", "atis_tables", ".", "MONTH_NUMBERS", ".", "items", "(", ")", "\n", "}", "\n", "day_reverse_lookup", "=", "{", "\n", "str", "(", "number", ")", ":", "string", "for", "string", ",", "number", "in", "atis_tables", ".", "DAY_NUMBERS", ".", "items", "(", ")", "\n", "}", "\n", "\n", "if", "self", ".", "dates", ":", "\n", "            ", "for", "date", "in", "self", ".", "dates", ":", "\n", "# Add the year linking score", "\n", "                ", "entity_linking", "=", "[", "0", "for", "token", "in", "current_tokenized_utterance", "]", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "current_tokenized_utterance", ")", ":", "\n", "                    ", "if", "token", ".", "text", "==", "str", "(", "date", ".", "year", ")", ":", "\n", "                        ", "entity_linking", "[", "token_index", "]", "=", "1", "\n", "", "", "action", "=", "format_action", "(", "\n", "nonterminal", "=", "\"year_number\"", ",", "\n", "right_hand_side", "=", "str", "(", "date", ".", "year", ")", ",", "\n", "is_number", "=", "True", ",", "\n", "keywords_to_uppercase", "=", "KEYWORDS", ",", "\n", ")", "\n", "number_linking_scores", "[", "action", "]", "=", "(", "\"year_number\"", ",", "str", "(", "date", ".", "year", ")", ",", "entity_linking", ")", "\n", "\n", "entity_linking", "=", "[", "0", "for", "token", "in", "current_tokenized_utterance", "]", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "current_tokenized_utterance", ")", ":", "\n", "                    ", "if", "token", ".", "text", "==", "month_reverse_lookup", "[", "str", "(", "date", ".", "month", ")", "]", ":", "\n", "                        ", "entity_linking", "[", "token_index", "]", "=", "1", "\n", "", "", "action", "=", "format_action", "(", "\n", "nonterminal", "=", "\"month_number\"", ",", "\n", "right_hand_side", "=", "str", "(", "date", ".", "month", ")", ",", "\n", "is_number", "=", "True", ",", "\n", "keywords_to_uppercase", "=", "KEYWORDS", ",", "\n", ")", "\n", "\n", "number_linking_scores", "[", "action", "]", "=", "(", "\"month_number\"", ",", "str", "(", "date", ".", "month", ")", ",", "entity_linking", ")", "\n", "\n", "entity_linking", "=", "[", "0", "for", "token", "in", "current_tokenized_utterance", "]", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "current_tokenized_utterance", ")", ":", "\n", "                    ", "if", "token", ".", "text", "==", "day_reverse_lookup", "[", "str", "(", "date", ".", "day", ")", "]", ":", "\n", "                        ", "entity_linking", "[", "token_index", "]", "=", "1", "\n", "", "", "for", "bigram_index", ",", "bigram", "in", "enumerate", "(", "\n", "bigrams", "(", "[", "token", ".", "text", "for", "token", "in", "current_tokenized_utterance", "]", ")", "\n", ")", ":", "\n", "                    ", "if", "\" \"", ".", "join", "(", "bigram", ")", "==", "day_reverse_lookup", "[", "str", "(", "date", ".", "day", ")", "]", ":", "\n", "                        ", "entity_linking", "[", "bigram_index", "]", "=", "1", "\n", "entity_linking", "[", "bigram_index", "+", "1", "]", "=", "1", "\n", "", "", "action", "=", "format_action", "(", "\n", "nonterminal", "=", "\"day_number\"", ",", "\n", "right_hand_side", "=", "str", "(", "date", ".", "day", ")", ",", "\n", "is_number", "=", "True", ",", "\n", "keywords_to_uppercase", "=", "KEYWORDS", ",", "\n", ")", "\n", "number_linking_scores", "[", "action", "]", "=", "(", "\"day_number\"", ",", "str", "(", "date", ".", "day", ")", ",", "entity_linking", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores": [[335, 367], ["zip", "sorted", "get_number_linking_dict", "all_numbers.update", "get_number_linking_dict.get", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_action", "get_number_linking_dict.keys", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_action"], ["", "", "", "def", "add_to_number_linking_scores", "(", "\n", "self", ",", "\n", "all_numbers", ":", "Set", "[", "str", "]", ",", "\n", "number_linking_scores", ":", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "get_number_linking_dict", ":", "Callable", "[", "[", "str", ",", "List", "[", "Token", "]", "]", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "current_tokenized_utterance", ":", "List", "[", "Token", "]", ",", "\n", "nonterminal", ":", "str", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        This is a helper method for adding different types of numbers (eg. starting time ranges) as entities.\n        We first go through all utterances in the interaction and find the numbers of a certain type and add\n        them to the set ``all_numbers``, which is initialized with default values. We want to add all numbers\n        that occur in the interaction, and not just the current turn because the query could contain numbers\n        that were triggered before the current turn. For each entity, we then check if it is triggered by tokens\n        in the current utterance and construct the linking score.\n        \"\"\"", "\n", "number_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "{", "}", "\n", "for", "utterance", ",", "tokenized_utterance", "in", "zip", "(", "self", ".", "utterances", ",", "self", ".", "tokenized_utterances", ")", ":", "\n", "            ", "number_linking_dict", "=", "get_number_linking_dict", "(", "utterance", ",", "tokenized_utterance", ")", "\n", "all_numbers", ".", "update", "(", "number_linking_dict", ".", "keys", "(", ")", ")", "\n", "", "all_numbers_list", ":", "List", "[", "str", "]", "=", "sorted", "(", "all_numbers", ",", "reverse", "=", "True", ")", "\n", "for", "number", "in", "all_numbers_list", ":", "\n", "            ", "entity_linking", "=", "[", "0", "for", "token", "in", "current_tokenized_utterance", "]", "\n", "# ``number_linking_dict`` is for the last utterance here. If the number was triggered", "\n", "# before the last utterance, then it will have linking scores of 0's.", "\n", "for", "token_index", "in", "number_linking_dict", ".", "get", "(", "number", ",", "[", "]", ")", ":", "\n", "                ", "if", "token_index", "<", "len", "(", "entity_linking", ")", ":", "\n", "                    ", "entity_linking", "[", "token_index", "]", "=", "1", "\n", "", "", "action", "=", "format_action", "(", "\n", "nonterminal", ",", "number", ",", "is_number", "=", "True", ",", "keywords_to_uppercase", "=", "KEYWORDS", "\n", ")", "\n", "number_linking_scores", "[", "action", "]", "=", "(", "nonterminal", ",", "number", ",", "entity_linking", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_linked_entities": [[368, 457], ["atis_world.AtisWorld.add_to_number_linking_scores", "atis_world.AtisWorld.add_to_number_linking_scores", "atis_world.AtisWorld.add_to_number_linking_scores", "atis_world.AtisWorld.add_to_number_linking_scores", "atis_world.AtisWorld.add_to_number_linking_scores", "atis_world.AtisWorld.add_to_number_linking_scores", "atis_world.AtisWorld.add_dates_to_number_linking_scores", "strings_list.append", "strings_list.append", "atis_world.get_strings_from_utterance", "get_strings_from_utterance.get", "action.split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.add_dates_to_number_linking_scores", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.get_strings_from_utterance"], ["", "", "def", "_get_linked_entities", "(", "self", ")", "->", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", ",", "List", "[", "int", "]", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        This method gets entities from the current utterance finds which tokens they are linked to.\n        The entities are divided into two main groups, ``numbers`` and ``strings``. We rely on these\n        entities later for updating the valid actions and the grammar.\n        \"\"\"", "\n", "current_tokenized_utterance", "=", "(", "\n", "[", "]", "if", "not", "self", ".", "tokenized_utterances", "else", "self", ".", "tokenized_utterances", "[", "-", "1", "]", "\n", ")", "\n", "\n", "# We generate a dictionary where the key is the type eg. ``number`` or ``string``.", "\n", "# The value is another dictionary where the key is the action and the value is a tuple", "\n", "# of the nonterminal, the string value and the linking score.", "\n", "entity_linking_scores", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", ",", "List", "[", "int", "]", "]", "]", "]", "=", "{", "}", "\n", "\n", "number_linking_scores", ":", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", ",", "List", "[", "int", "]", "]", "]", "=", "{", "}", "\n", "string_linking_scores", ":", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", ",", "List", "[", "int", "]", "]", "]", "=", "{", "}", "\n", "\n", "# Get time range start", "\n", "self", ".", "add_to_number_linking_scores", "(", "\n", "{", "\"0\"", "}", ",", "\n", "number_linking_scores", ",", "\n", "atis_tables", ".", "get_time_range_start_from_utterance", ",", "\n", "current_tokenized_utterance", ",", "\n", "\"time_range_start\"", ",", "\n", ")", "\n", "\n", "self", ".", "add_to_number_linking_scores", "(", "\n", "{", "\"1200\"", "}", ",", "\n", "number_linking_scores", ",", "\n", "atis_tables", ".", "get_time_range_end_from_utterance", ",", "\n", "current_tokenized_utterance", ",", "\n", "\"time_range_end\"", ",", "\n", ")", "\n", "\n", "self", ".", "add_to_number_linking_scores", "(", "\n", "{", "\"0\"", ",", "\"1\"", ",", "\"60\"", ",", "\"41\"", "}", ",", "\n", "number_linking_scores", ",", "\n", "atis_tables", ".", "get_numbers_from_utterance", ",", "\n", "current_tokenized_utterance", ",", "\n", "\"number\"", ",", "\n", ")", "\n", "\n", "self", ".", "add_to_number_linking_scores", "(", "\n", "{", "\"0\"", "}", ",", "\n", "number_linking_scores", ",", "\n", "atis_tables", ".", "get_costs_from_utterance", ",", "\n", "current_tokenized_utterance", ",", "\n", "\"fare_round_trip_cost\"", ",", "\n", ")", "\n", "\n", "self", ".", "add_to_number_linking_scores", "(", "\n", "{", "\"0\"", "}", ",", "\n", "number_linking_scores", ",", "\n", "atis_tables", ".", "get_costs_from_utterance", ",", "\n", "current_tokenized_utterance", ",", "\n", "\"fare_one_direction_cost\"", ",", "\n", ")", "\n", "\n", "self", ".", "add_to_number_linking_scores", "(", "\n", "{", "\"0\"", "}", ",", "\n", "number_linking_scores", ",", "\n", "atis_tables", ".", "get_flight_numbers_from_utterance", ",", "\n", "current_tokenized_utterance", ",", "\n", "\"flight_number\"", ",", "\n", ")", "\n", "\n", "self", ".", "add_dates_to_number_linking_scores", "(", "number_linking_scores", ",", "current_tokenized_utterance", ")", "\n", "\n", "# Add string linking dict.", "\n", "string_linking_dict", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "{", "}", "\n", "for", "tokenized_utterance", "in", "self", ".", "tokenized_utterances", ":", "\n", "            ", "string_linking_dict", "=", "get_strings_from_utterance", "(", "tokenized_utterance", ")", "\n", "", "strings_list", "=", "AtisWorld", ".", "sql_table_context", ".", "strings_list", "\n", "strings_list", ".", "append", "(", "(", "\"flight_airline_code_string -> [\\\"'EA'\\\"]\"", ",", "\"EA\"", ")", ")", "\n", "strings_list", ".", "append", "(", "(", "\"airline_airline_name_string-> [\\\"'EA'\\\"]\"", ",", "\"EA\"", ")", ")", "\n", "# We construct the linking scores for strings from the ``string_linking_dict`` here.", "\n", "for", "string", "in", "strings_list", ":", "\n", "            ", "entity_linking", "=", "[", "0", "for", "token", "in", "current_tokenized_utterance", "]", "\n", "# string_linking_dict has the strings and linking scores from the last utterance.", "\n", "# If the string is not in the last utterance, then the linking scores will be all 0.", "\n", "for", "token_index", "in", "string_linking_dict", ".", "get", "(", "string", "[", "1", "]", ",", "[", "]", ")", ":", "\n", "                ", "entity_linking", "[", "token_index", "]", "=", "1", "\n", "", "action", "=", "string", "[", "0", "]", "\n", "string_linking_scores", "[", "action", "]", "=", "(", "action", ".", "split", "(", "\" -> \"", ")", "[", "0", "]", ",", "string", "[", "1", "]", ",", "entity_linking", ")", "\n", "\n", "", "entity_linking_scores", "[", "\"number\"", "]", "=", "number_linking_scores", "\n", "entity_linking_scores", "[", "\"string\"", "]", "=", "string_linking_scores", "\n", "return", "entity_linking_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_dates": [[458, 463], ["dates.extend", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.get_date_from_utterance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_date_from_utterance"], ["", "def", "_get_dates", "(", "self", ")", ":", "\n", "        ", "dates", "=", "[", "]", "\n", "for", "tokenized_utterance", "in", "self", ".", "tokenized_utterances", ":", "\n", "            ", "dates", ".", "extend", "(", "atis_tables", ".", "get_date_from_utterance", "(", "tokenized_utterance", ")", ")", "\n", "", "return", "dates", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._ignore_dates": [[464, 481], ["query.split", "enumerate", "enumerate", "token.endswith", "enumerate", "token.endswith", "enumerate", "token.endswith", "token.isdigit", "str", "token.isdigit", "str", "token.isdigit", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "_ignore_dates", "(", "self", ",", "query", ":", "str", ")", ":", "\n", "        ", "tokens", "=", "query", ".", "split", "(", "\" \"", ")", "\n", "year_indices", "=", "[", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", "if", "token", ".", "endswith", "(", "\"year\"", ")", "]", "\n", "month_indices", "=", "[", "\n", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", "if", "token", ".", "endswith", "(", "\"month_number\"", ")", "\n", "]", "\n", "day_indices", "=", "[", "index", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", "if", "token", ".", "endswith", "(", "\"day_number\"", ")", "]", "\n", "\n", "if", "self", ".", "dates", ":", "\n", "            ", "for", "token_index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "                ", "if", "token_index", "-", "2", "in", "year_indices", "and", "token", ".", "isdigit", "(", ")", ":", "\n", "                    ", "tokens", "[", "token_index", "]", "=", "str", "(", "self", ".", "dates", "[", "0", "]", ".", "year", ")", "\n", "", "if", "token_index", "-", "2", "in", "month_indices", "and", "token", ".", "isdigit", "(", ")", ":", "\n", "                    ", "tokens", "[", "token_index", "]", "=", "str", "(", "self", ".", "dates", "[", "0", "]", ".", "month", ")", "\n", "", "if", "token_index", "-", "2", "in", "day_indices", "and", "token", ".", "isdigit", "(", ")", ":", "\n", "                    ", "tokens", "[", "token_index", "]", "=", "str", "(", "self", ".", "dates", "[", "0", "]", ".", "day", ")", "\n", "", "", "", "return", "\" \"", ".", "join", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence": [[482, 489], ["atis_world.AtisWorld._ignore_dates", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor.parse"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._ignore_dates", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse"], ["", "def", "get_action_sequence", "(", "self", ",", "query", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "query", "=", "self", ".", "_ignore_dates", "(", "query", ")", "\n", "sql_visitor", "=", "SqlVisitor", "(", "self", ".", "grammar", ",", "keywords_to_uppercase", "=", "KEYWORDS", ")", "\n", "if", "query", ":", "\n", "            ", "action_sequence", "=", "sql_visitor", ".", "parse", "(", "query", ")", "\n", "return", "action_sequence", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.all_possible_actions": [[490, 500], ["set", "atis_world.AtisWorld.valid_actions.items", "sorted", "set.add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "all_possible_actions", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Return a sorted list of strings representing all possible actions\n        of the form: nonterminal -> [right_hand_side]\n        \"\"\"", "\n", "all_actions", "=", "set", "(", ")", "\n", "for", "_", ",", "action_list", "in", "self", ".", "valid_actions", ".", "items", "(", ")", ":", "\n", "            ", "for", "action", "in", "action_list", ":", "\n", "                ", "all_actions", ".", "add", "(", "action", ")", "\n", "", "", "return", "sorted", "(", "all_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._flatten_entities": [[501, 519], ["sorted", "sorted", "entities.append", "linking_scores.append", "entities.append", "linking_scores.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_flatten_entities", "(", "self", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "numpy", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        When we first get the entities and the linking scores in ``_get_linked_entities``\n        we represent as dictionaries for easier updates to the grammar and valid actions.\n        In this method, we flatten them for the model so that the entities are represented as\n        a list, and the linking scores are a 2D numpy array of shape (num_entities, num_utterance_tokens).\n        \"\"\"", "\n", "entities", "=", "[", "]", "\n", "linking_scores", "=", "[", "]", "\n", "for", "entity", "in", "sorted", "(", "self", ".", "linked_entities", "[", "\"number\"", "]", ")", ":", "\n", "            ", "entities", ".", "append", "(", "entity", ")", "\n", "linking_scores", ".", "append", "(", "self", ".", "linked_entities", "[", "\"number\"", "]", "[", "entity", "]", "[", "2", "]", ")", "\n", "\n", "", "for", "entity", "in", "sorted", "(", "self", ".", "linked_entities", "[", "\"string\"", "]", ")", ":", "\n", "            ", "entities", ".", "append", "(", "entity", ")", "\n", "linking_scores", ".", "append", "(", "self", ".", "linked_entities", "[", "\"string\"", "]", "[", "entity", "]", "[", "2", "]", ")", "\n", "\n", "", "return", "entities", ",", "numpy", ".", "array", "(", "linking_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.__eq__": [[520, 530], ["isinstance", "all", "numpy.array_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "all", "(", "\n", "[", "\n", "self", ".", "valid_actions", "==", "other", ".", "valid_actions", ",", "\n", "numpy", ".", "array_equal", "(", "self", ".", "linking_scores", ",", "other", ".", "linking_scores", ")", ",", "\n", "self", ".", "utterances", "==", "other", ".", "utterances", ",", "\n", "]", "\n", ")", "\n", "", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.get_strings_from_utterance": [[25, 50], ["collections.defaultdict", "enumerate", "nltk.bigrams", "enumerate", "nltk.ngrams", "enumerate", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.ATIS_TRIGGER_DICT.get", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.ATIS_TRIGGER_DICT.get", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.ATIS_TRIGGER_DICT.get", "token.text.lower", "string_linking_scores[].append", "string_linking_scores[].extend", "string_linking_scores[].extend"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "get_strings_from_utterance", "(", "tokenized_utterance", ":", "List", "[", "Token", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Based on the current utterance, return a dictionary where the keys are the strings in\n    the database that map to lists of the token indices that they are linked to.\n    \"\"\"", "\n", "string_linking_scores", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "index", ",", "token", "in", "enumerate", "(", "tokenized_utterance", ")", ":", "\n", "        ", "for", "string", "in", "atis_tables", ".", "ATIS_TRIGGER_DICT", ".", "get", "(", "token", ".", "text", ".", "lower", "(", ")", ",", "[", "]", ")", ":", "\n", "            ", "string_linking_scores", "[", "string", "]", ".", "append", "(", "index", ")", "\n", "\n", "", "", "token_bigrams", "=", "bigrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ")", "\n", "for", "index", ",", "token_bigram", "in", "enumerate", "(", "token_bigrams", ")", ":", "\n", "        ", "for", "string", "in", "atis_tables", ".", "ATIS_TRIGGER_DICT", ".", "get", "(", "\" \"", ".", "join", "(", "token_bigram", ")", ".", "lower", "(", ")", ",", "[", "]", ")", ":", "\n", "            ", "string_linking_scores", "[", "string", "]", ".", "extend", "(", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "\n", "", "", "trigrams", "=", "ngrams", "(", "[", "token", ".", "text", "for", "token", "in", "tokenized_utterance", "]", ",", "3", ")", "\n", "for", "index", ",", "trigram", "in", "enumerate", "(", "trigrams", ")", ":", "\n", "        ", "if", "trigram", "[", "0", "]", "==", "\"st\"", ":", "\n", "            ", "natural_language_key", "=", "f\"st. {trigram[2]}\"", ".", "lower", "(", ")", "\n", "", "else", ":", "\n", "            ", "natural_language_key", "=", "\" \"", ".", "join", "(", "trigram", ")", ".", "lower", "(", ")", "\n", "", "for", "string", "in", "atis_tables", ".", "ATIS_TRIGGER_DICT", ".", "get", "(", "natural_language_key", ",", "[", "]", ")", ":", "\n", "            ", "string_linking_scores", "[", "string", "]", ".", "extend", "(", "[", "index", ",", "index", "+", "1", ",", "index", "+", "2", "]", ")", "\n", "", "", "return", "string_linking_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.__init__": [[69, 88], ["allennlp_semparse.common.sql.text2sql_utils.read_dataset_schema", "text2sql_world.Text2SqlWorld._initialize_grammar_dictionary", "os.path.basename().split", "copy.deepcopy", "text2sql_world.Text2SqlWorld.schema.values", "os.path.basename"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.read_dataset_schema", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld._initialize_grammar_dictionary"], ["def", "__init__", "(", "\n", "self", ",", "\n", "schema_path", ":", "str", ",", "\n", "cursor", ":", "Cursor", "=", "None", ",", "\n", "use_prelinked_entities", ":", "bool", "=", "True", ",", "\n", "variable_free", ":", "bool", "=", "True", ",", "\n", "use_untyped_entities", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "cursor", "=", "cursor", "\n", "self", ".", "schema", "=", "read_dataset_schema", "(", "schema_path", ")", "\n", "self", ".", "columns", "=", "{", "column", ".", "name", ":", "column", "for", "table", "in", "self", ".", "schema", ".", "values", "(", ")", "for", "column", "in", "table", "}", "\n", "self", ".", "dataset_name", "=", "os", ".", "path", ".", "basename", "(", "schema_path", ")", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "self", ".", "use_prelinked_entities", "=", "use_prelinked_entities", "\n", "self", ".", "variable_free", "=", "variable_free", "\n", "self", ".", "use_untyped_entities", "=", "use_untyped_entities", "\n", "\n", "# NOTE: This base dictionary should not be modified.", "\n", "self", ".", "base_grammar_dictionary", "=", "self", ".", "_initialize_grammar_dictionary", "(", "\n", "deepcopy", "(", "GRAMMAR_DICTIONARY", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.get_action_sequence_and_all_actions": [[90, 124], ["copy.deepcopy", "parsimonious.Grammar", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.initialize_valid_actions", "set", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.initialize_valid_actions.values", "sorted", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor", "allennlp.common.checks.ConfigurationError", "allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_values_with_variables", "allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_numbers_and_strings_with_variables", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_grammar_string", "set.update", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor.parse"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.initialize_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_values_with_variables", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_numbers_and_strings_with_variables", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_grammar_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse"], ["", "def", "get_action_sequence_and_all_actions", "(", "\n", "self", ",", "query", ":", "List", "[", "str", "]", "=", "None", ",", "prelinked_entities", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "grammar_with_context", "=", "deepcopy", "(", "self", ".", "base_grammar_dictionary", ")", "\n", "\n", "if", "not", "self", ".", "use_prelinked_entities", "and", "prelinked_entities", "is", "not", "None", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\n", "\"The Text2SqlWorld was specified to not use prelinked \"", "\n", "\"entities, but prelinked entities were passed.\"", "\n", ")", "\n", "", "prelinked_entities", "=", "prelinked_entities", "or", "{", "}", "\n", "\n", "if", "self", ".", "use_untyped_entities", ":", "\n", "            ", "update_grammar_values_with_variables", "(", "grammar_with_context", ",", "prelinked_entities", ")", "\n", "", "else", ":", "\n", "            ", "update_grammar_numbers_and_strings_with_variables", "(", "\n", "grammar_with_context", ",", "prelinked_entities", ",", "self", ".", "columns", "\n", ")", "\n", "\n", "", "grammar", "=", "Grammar", "(", "format_grammar_string", "(", "grammar_with_context", ")", ")", "\n", "\n", "valid_actions", "=", "initialize_valid_actions", "(", "grammar", ")", "\n", "all_actions", "=", "set", "(", ")", "\n", "for", "action_list", "in", "valid_actions", ".", "values", "(", ")", ":", "\n", "            ", "all_actions", ".", "update", "(", "action_list", ")", "\n", "", "sorted_actions", "=", "sorted", "(", "all_actions", ")", "\n", "\n", "sql_visitor", "=", "SqlVisitor", "(", "grammar", ")", "\n", "try", ":", "\n", "            ", "action_sequence", "=", "sql_visitor", ".", "parse", "(", "\" \"", ".", "join", "(", "query", ")", ")", "if", "query", "else", "[", "]", "\n", "", "except", "ParseError", ":", "\n", "            ", "action_sequence", "=", "None", "\n", "\n", "", "return", "action_sequence", ",", "sorted_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld._initialize_grammar_dictionary": [[125, 153], ["allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_with_tables", "allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_with_global_values", "allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_with_table_values", "allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_to_be_variable_free", "allennlp_semparse.parsimonious_languages.contexts.text2sql_table_context.update_grammar_with_untyped_entities"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_tables", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_global_values", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_table_values", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_to_be_variable_free", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.text2sql_table_context.update_grammar_with_untyped_entities"], ["", "def", "_initialize_grammar_dictionary", "(", "\n", "self", ",", "grammar_dictionary", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "# Add all the table and column names to the grammar.", "\n", "        ", "update_grammar_with_tables", "(", "grammar_dictionary", ",", "self", ".", "schema", ")", "\n", "\n", "if", "self", ".", "cursor", "is", "not", "None", "and", "not", "self", ".", "use_prelinked_entities", ":", "\n", "# Now if we have strings in the table, we need to be able to", "\n", "# produce them, so we find all of the strings in the tables here", "\n", "# and create production rules from them. We only do this if", "\n", "# we haven't pre-linked entities, because if we have, we don't", "\n", "# need to be able to generate the values - just the placeholder", "\n", "# symbols which link to them.", "\n", "            ", "grammar_dictionary", "[", "\"number\"", "]", "=", "[", "]", "\n", "grammar_dictionary", "[", "\"string\"", "]", "=", "[", "]", "\n", "update_grammar_with_table_values", "(", "grammar_dictionary", ",", "self", ".", "schema", ",", "self", ".", "cursor", ")", "\n", "\n", "# Finally, update the grammar with global, non-variable values", "\n", "# found in the dataset, if present.", "\n", "", "update_grammar_with_global_values", "(", "grammar_dictionary", ",", "self", ".", "dataset_name", ")", "\n", "\n", "if", "self", ".", "variable_free", ":", "\n", "            ", "update_grammar_to_be_variable_free", "(", "grammar_dictionary", ")", "\n", "\n", "", "if", "self", ".", "use_untyped_entities", ":", "\n", "            ", "update_grammar_with_untyped_entities", "(", "grammar_dictionary", ")", "\n", "\n", "", "return", "grammar_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.is_global_rule": [[154, 161], ["production_rule[].isnumeric"], "methods", ["None"], ["", "def", "is_global_rule", "(", "self", ",", "production_rule", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "use_prelinked_entities", ":", "\n", "# we are checking -4 as is not a global rule if we", "\n", "# see the 0 in the a rule like 'value -> [\"\\'city_name0\\'\"]'", "\n", "            ", "if", "\"value\"", "in", "production_rule", "and", "production_rule", "[", "-", "4", "]", ".", "isnumeric", "(", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.FakeWorldWithoutRecursion.all_possible_actions": [[8, 22], ["None"], "methods", ["None"], ["    ", "@", "overrides", "\n", "def", "all_possible_actions", "(", "self", ")", ":", "\n", "# The logical forms this grammar allows are", "\n", "# (unary_function argument)", "\n", "# (binary_function argument argument)", "\n", "        ", "actions", "=", "[", "\n", "\"@start@ -> t\"", ",", "\n", "\"t -> [<e,t>, e]\"", ",", "\n", "\"<e,t> -> unary_function\"", ",", "\n", "\"<e,t> -> [<e,<e,t>>, e]\"", ",", "\n", "\"<e,<e,t>> -> binary_function\"", ",", "\n", "\"e -> argument\"", ",", "\n", "]", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.FakeWorldWithRecursion.all_possible_actions": [[25, 33], ["world_test.FakeWorldWithoutRecursion.all_possible_actions", "super().all_possible_actions.extend"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.FakeWorldWithRecursion.all_possible_actions"], ["    ", "@", "overrides", "\n", "def", "all_possible_actions", "(", "self", ")", ":", "\n", "# In addition to the forms allowed by ``FakeWorldWithoutRecursion``, this world allows", "\n", "# (unary_function (identity .... (argument)))", "\n", "# (binary_function (identity .... (argument)) (identity .... (argument)))", "\n", "        ", "actions", "=", "super", "(", "FakeWorldWithRecursion", ",", "self", ")", ".", "all_possible_actions", "(", ")", "\n", "actions", ".", "extend", "(", "[", "\"e -> [<e,e>, e]\"", ",", "\"<e,e> -> identity\"", "]", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.TestWorld.setup_method": [[36, 40], ["super().setup_method", "world_test.FakeWorldWithoutRecursion", "world_test.FakeWorldWithRecursion"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "world_without_recursion", "=", "FakeWorldWithoutRecursion", "(", ")", "\n", "self", ".", "world_with_recursion", "=", "FakeWorldWithRecursion", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.TestWorld.test_get_paths_to_root_without_recursion": [[41, 62], ["world_test.TestWorld.world_without_recursion.get_paths_to_root", "world_test.TestWorld.world_without_recursion.get_paths_to_root", "world_test.TestWorld.world_without_recursion.get_paths_to_root"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_paths_to_root", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_paths_to_root", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_paths_to_root"], ["", "def", "test_get_paths_to_root_without_recursion", "(", "self", ")", ":", "\n", "        ", "argument_paths", "=", "self", ".", "world_without_recursion", ".", "get_paths_to_root", "(", "\"e -> argument\"", ")", "\n", "assert", "argument_paths", "==", "[", "\n", "[", "\"e -> argument\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", ",", "\n", "[", "\"e -> argument\"", ",", "\"<e,t> -> [<e,<e,t>>, e]\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", ",", "\n", "]", "\n", "unary_function_paths", "=", "self", ".", "world_without_recursion", ".", "get_paths_to_root", "(", "\n", "\"<e,t> -> unary_function\"", "\n", ")", "\n", "assert", "unary_function_paths", "==", "[", "\n", "[", "\"<e,t> -> unary_function\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", "\n", "]", "\n", "binary_function_paths", "=", "self", ".", "world_without_recursion", ".", "get_paths_to_root", "(", "\n", "\"<e,<e,t>> -> binary_function\"", "\n", ")", "\n", "assert", "binary_function_paths", "==", "[", "\n", "[", "\n", "\"<e,<e,t>> -> binary_function\"", ",", "\n", "\"<e,t> -> [<e,<e,t>>, e]\"", ",", "\n", "\"t -> [<e,t>, e]\"", ",", "\n", "\"@start@ -> t\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.TestWorld.test_get_paths_to_root_with_recursion": [[65, 91], ["world_test.TestWorld.world_with_recursion.get_paths_to_root", "world_test.TestWorld.world_with_recursion.get_paths_to_root"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_paths_to_root", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world.World.get_paths_to_root"], ["", "def", "test_get_paths_to_root_with_recursion", "(", "self", ")", ":", "\n", "        ", "argument_paths", "=", "self", ".", "world_with_recursion", ".", "get_paths_to_root", "(", "\"e -> argument\"", ")", "\n", "# Argument now has 4 paths, and the two new paths are with the identity function occurring", "\n", "# (only once) within unary and binary functions.", "\n", "assert", "argument_paths", "==", "[", "\n", "[", "\"e -> argument\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", ",", "\n", "[", "\"e -> argument\"", ",", "\"<e,t> -> [<e,<e,t>>, e]\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", ",", "\n", "[", "\"e -> argument\"", ",", "\"e -> [<e,e>, e]\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", ",", "\n", "[", "\n", "\"e -> argument\"", ",", "\n", "\"e -> [<e,e>, e]\"", ",", "\n", "\"<e,t> -> [<e,<e,t>>, e]\"", ",", "\n", "\"t -> [<e,t>, e]\"", ",", "\n", "\"@start@ -> t\"", ",", "\n", "]", ",", "\n", "]", "\n", "identity_paths", "=", "self", ".", "world_with_recursion", ".", "get_paths_to_root", "(", "\"<e,e> -> identity\"", ")", "\n", "# Two identity paths, one through each of unary and binary function productions.", "\n", "assert", "identity_paths", "==", "[", "\n", "[", "\"<e,e> -> identity\"", ",", "\"e -> [<e,e>, e]\"", ",", "\"t -> [<e,t>, e]\"", ",", "\"@start@ -> t\"", "]", ",", "\n", "[", "\n", "\"<e,e> -> identity\"", ",", "\n", "\"e -> [<e,e>, e]\"", ",", "\n", "\"<e,t> -> [<e,<e,t>>, e]\"", ",", "\n", "\"t -> [<e,t>, e]\"", ",", "\n", "\"@start@ -> t\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.setup_method": [[17, 22], ["super().setup_method", "open().readlines", "allennlp.common.file_utils.cached_path", "open"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "test_filename", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"atis\"", "/", "\"sample.json\"", "\n", "self", ".", "data", "=", "open", "(", "test_filename", ")", ".", "readlines", "(", ")", "\n", "self", ".", "database_file", "=", "cached_path", "(", "\"https://allennlp.s3.amazonaws.com/datasets/atis/atis.db\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_atis_global_actions": [[23, 365], ["allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "valid_actions.keys"], "methods", ["None"], ["", "def", "test_atis_global_actions", "(", "self", ")", ":", "\n", "        ", "world", "=", "AtisWorld", "(", "utterances", "=", "[", "]", ")", "\n", "valid_actions", "=", "world", ".", "valid_actions", "\n", "assert", "set", "(", "valid_actions", ".", "keys", "(", ")", ")", "==", "{", "\n", "\"agg\"", ",", "\n", "\"agg_func\"", ",", "\n", "\"agg_results\"", ",", "\n", "\"aircraft_aircraft_code_string\"", ",", "\n", "\"aircraft_basic_type_string\"", ",", "\n", "\"aircraft_manufacturer_string\"", ",", "\n", "\"aircraft_propulsion_string\"", ",", "\n", "\"airline_airline_code_string\"", ",", "\n", "\"airline_airline_name_string\"", ",", "\n", "\"airport_airport_code_string\"", ",", "\n", "\"airport_airport_name_string\"", ",", "\n", "\"biexpr\"", ",", "\n", "\"binaryop\"", ",", "\n", "\"boolean\"", ",", "\n", "\"city_city_code_string\"", ",", "\n", "\"city_city_name_string\"", ",", "\n", "\"city_state_code_string\"", ",", "\n", "\"class_of_service_booking_class_string\"", ",", "\n", "\"class_of_service_class_description_string\"", ",", "\n", "\"col\"", ",", "\n", "\"col_ref\"", ",", "\n", "\"col_refs\"", ",", "\n", "\"condition\"", ",", "\n", "\"conditions\"", ",", "\n", "\"conj\"", ",", "\n", "\"days_day_name_string\"", ",", "\n", "\"days_days_code_string\"", ",", "\n", "\"distinct\"", ",", "\n", "\"fare_basis_booking_class_string\"", ",", "\n", "\"fare_basis_class_type_string\"", ",", "\n", "\"fare_basis_economy_string\"", ",", "\n", "\"fare_basis_fare_basis_code_string\"", ",", "\n", "\"fare_fare_basis_code_string\"", ",", "\n", "\"fare_one_direction_cost\"", ",", "\n", "\"fare_restriction_code_string\"", ",", "\n", "\"fare_round_trip_cost\"", ",", "\n", "\"fare_round_trip_required_string\"", ",", "\n", "\"flight_airline_code_string\"", ",", "\n", "\"flight_flight_days_string\"", ",", "\n", "\"flight_number\"", ",", "\n", "\"flight_stop_stop_airport_string\"", ",", "\n", "\"food_service_compartment_string\"", ",", "\n", "\"food_service_meal_description_string\"", ",", "\n", "\"ground_service_transport_type_string\"", ",", "\n", "\"group_by_clause\"", ",", "\n", "\"in_clause\"", ",", "\n", "\"number\"", ",", "\n", "\"pos_value\"", ",", "\n", "\"query\"", ",", "\n", "\"restriction_restriction_code_string\"", ",", "\n", "\"select_results\"", ",", "\n", "\"state_state_code_string\"", ",", "\n", "\"state_state_name_string\"", ",", "\n", "\"statement\"", ",", "\n", "\"table_name\"", ",", "\n", "\"table_refs\"", ",", "\n", "\"ternaryexpr\"", ",", "\n", "\"time_range_end\"", ",", "\n", "\"time_range_start\"", ",", "\n", "\"value\"", ",", "\n", "\"where_clause\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"statement\"", "]", ")", "==", "{", "'statement -> [query, \";\"]'", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"query\"", "]", ")", "==", "{", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, group_by_clause, \")\"]'", ",", "\n", "'query -> [\"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\"where_clause]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"select_results\"", "]", ")", "==", "{", "\n", "\"select_results -> [agg]\"", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"agg\"", "]", ")", "==", "{", "\n", "'agg -> [agg_func, \"(\", col, \")\"]'", ",", "\n", "'agg -> [agg_func, \"(\", col_ref, \")\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"agg_func\"", "]", ")", "==", "{", "\n", "'agg_func -> [\"COUNT\"]'", ",", "\n", "'agg_func -> [\"MAX\"]'", ",", "\n", "'agg_func -> [\"MIN\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"col_refs\"", "]", ")", "==", "{", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_refs -> [col_ref, \",\", col_refs]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"table_refs\"", "]", ")", "==", "{", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_refs -> [table_name, \",\", table_refs]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"where_clause\"", "]", ")", "==", "{", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"conditions\"", "]", ")", "==", "{", "\n", "'conditions -> [\"(\", conditions, \")\", conj, conditions]'", ",", "\n", "'conditions -> [\"(\", conditions, \")\"]'", ",", "\n", "'conditions -> [\"NOT\", conditions]'", ",", "\n", "'conditions -> [condition, conj, \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"condition\"", "]", ")", "==", "{", "\n", "\"condition -> [biexpr]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "\"condition -> [ternaryexpr]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"in_clause\"", "]", ")", "==", "{", "'in_clause -> [col_ref, \"IN\", query]'", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"biexpr\"", "]", ")", "==", "{", "\n", "'biexpr -> [\"aircraft\", \".\", \"aircraft_code\", binaryop, '", "\n", "\"aircraft_aircraft_code_string]\"", ",", "\n", "'biexpr -> [\"aircraft\", \".\", \"basic_type\", binaryop, '", "\"aircraft_basic_type_string]\"", ",", "\n", "'biexpr -> [\"aircraft\", \".\", \"manufacturer\", binaryop, '", "\n", "\"aircraft_manufacturer_string]\"", ",", "\n", "'biexpr -> [\"aircraft\", \".\", \"propulsion\", binaryop, '", "\"aircraft_propulsion_string]\"", ",", "\n", "'biexpr -> [\"airline\", \".\", \"airline_code\", binaryop, '", "\"airline_airline_code_string]\"", ",", "\n", "'biexpr -> [\"airline\", \".\", \"airline_name\", binaryop, '", "\"airline_airline_name_string]\"", ",", "\n", "'biexpr -> [\"airport\", \".\", \"airport_code\", binaryop, '", "\"airport_airport_code_string]\"", ",", "\n", "'biexpr -> [\"airport\", \".\", \"airport_name\", binaryop, '", "\"airport_airport_name_string]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_code\", binaryop, city_city_code_string]'", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'biexpr -> [\"city\", \".\", \"state_code\", binaryop, city_state_code_string]'", ",", "\n", "'biexpr -> [\"class_of_service\", \".\", \"booking_class\", binaryop, '", "\n", "\"class_of_service_booking_class_string]\"", ",", "\n", "'biexpr -> [\"class_of_service\", \".\", \"class_description\", binaryop, '", "\n", "\"class_of_service_class_description_string]\"", ",", "\n", "'biexpr -> [\"days\", \".\", \"day_name\", binaryop, days_day_name_string]'", ",", "\n", "'biexpr -> [\"days\", \".\", \"days_code\", binaryop, days_days_code_string]'", ",", "\n", "'biexpr -> [\"fare\", \".\", \"fare_basis_code\", binaryop, '", "\"fare_fare_basis_code_string]\"", ",", "\n", "'biexpr -> [\"fare\", \".\", \"one_direction_cost\", binaryop, '", "\"fare_one_direction_cost]\"", ",", "\n", "'biexpr -> [\"fare\", \".\", \"restriction_code\", binaryop, '", "\n", "\"fare_restriction_code_string]\"", ",", "\n", "'biexpr -> [\"fare\", \".\", \"round_trip_cost\", binaryop, fare_round_trip_cost]'", ",", "\n", "'biexpr -> [\"fare\", \".\", \"round_trip_required\", binaryop, '", "\n", "\"fare_round_trip_required_string]\"", ",", "\n", "'biexpr -> [\"fare_basis\", \".\", \"booking_class\", binaryop, '", "\n", "\"fare_basis_booking_class_string]\"", ",", "\n", "'biexpr -> [\"fare_basis\", \".\", \"class_type\", binaryop, '", "\n", "\"fare_basis_class_type_string]\"", ",", "\n", "'biexpr -> [\"fare_basis\", \".\", \"economy\", binaryop, '", "\"fare_basis_economy_string]\"", ",", "\n", "'biexpr -> [\"fare_basis\", \".\", \"fare_basis_code\", binaryop, '", "\n", "\"fare_basis_fare_basis_code_string]\"", ",", "\n", "'biexpr -> [\"flight\", \".\", \"airline_code\", binaryop, '", "\"flight_airline_code_string]\"", ",", "\n", "'biexpr -> [\"flight\", \".\", \"flight_days\", binaryop, '", "\"flight_flight_days_string]\"", ",", "\n", "'biexpr -> [\"flight\", \".\", \"flight_number\", binaryop, flight_number]'", ",", "\n", "'biexpr -> [\"flight_stop\", \".\", \"stop_airport\", binaryop, '", "\n", "\"flight_stop_stop_airport_string]\"", ",", "\n", "'biexpr -> [\"food_service\", \".\", \"compartment\", binaryop, '", "\n", "\"food_service_compartment_string]\"", ",", "\n", "'biexpr -> [\"food_service\", \".\", \"meal_description\", binaryop, '", "\n", "\"food_service_meal_description_string]\"", ",", "\n", "'biexpr -> [\"ground_service\", \".\", \"transport_type\", binaryop, '", "\n", "\"ground_service_transport_type_string]\"", ",", "\n", "'biexpr -> [\"restriction\", \".\", \"restriction_code\", binaryop, '", "\n", "\"restriction_restriction_code_string]\"", ",", "\n", "'biexpr -> [\"state\", \".\", \"state_code\", binaryop, state_state_code_string]'", ",", "\n", "'biexpr -> [\"state\", \".\", \"state_name\", binaryop, state_state_name_string]'", ",", "\n", "\"biexpr -> [col_ref, binaryop, value]\"", ",", "\n", "\"biexpr -> [value, binaryop, value]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"binaryop\"", "]", ")", "==", "{", "\n", "'binaryop -> [\"*\"]'", ",", "\n", "'binaryop -> [\"+\"]'", ",", "\n", "'binaryop -> [\"-\"]'", ",", "\n", "'binaryop -> [\"/\"]'", ",", "\n", "'binaryop -> [\"<\"]'", ",", "\n", "'binaryop -> [\"<=\"]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "'binaryop -> [\">\"]'", ",", "\n", "'binaryop -> [\">=\"]'", ",", "\n", "'binaryop -> [\"IS\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"ternaryexpr\"", "]", ")", "==", "{", "\n", "'ternaryexpr -> [col_ref, \"BETWEEN\", time_range_start, \"AND\", time_range_end]'", ",", "\n", "'ternaryexpr -> [col_ref, \"NOT\", \"BETWEEN\", time_range_start, \"AND\", '", "\n", "\"time_range_end]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"value\"", "]", ")", "==", "{", "\n", "'value -> [\"NOT\", pos_value]'", ",", "\n", "\"value -> [pos_value]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"pos_value\"", "]", ")", "==", "{", "\n", "'pos_value -> [\"ALL\", query]'", ",", "\n", "'pos_value -> [\"ANY\", query]'", ",", "\n", "'pos_value -> [\"NULL\"]'", ",", "\n", "\"pos_value -> [agg_results]\"", ",", "\n", "\"pos_value -> [boolean]\"", ",", "\n", "\"pos_value -> [col_ref]\"", ",", "\n", "\"pos_value -> [number]\"", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"agg_results\"", "]", ")", "==", "{", "\n", "(", "\n", "'agg_results -> [\"(\", \"SELECT\", distinct, agg, \"FROM\", table_name, '", "\n", "'where_clause, \")\"]'", "\n", ")", ",", "\n", "'agg_results -> [\"SELECT\", distinct, agg, \"FROM\", table_name, where_clause]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"boolean\"", "]", ")", "==", "{", "'boolean -> [\"true\"]'", ",", "'boolean -> [\"false\"]'", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"conj\"", "]", ")", "==", "{", "'conj -> [\"OR\"]'", ",", "'conj -> [\"AND\"]'", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"distinct\"", "]", ")", "==", "{", "'distinct -> [\"\"]'", ",", "'distinct -> [\"DISTINCT\"]'", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"number\"", "]", ")", "==", "{", "\n", "'number -> [\"0\"]'", ",", "\n", "'number -> [\"1\"]'", ",", "\n", "'number -> [\"60\"]'", ",", "\n", "'number -> [\"41\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "valid_actions", "[", "\"col_ref\"", "]", ")", "==", "{", "\n", "'col_ref -> [\"*\"]'", ",", "\n", "\"col_ref -> [agg]\"", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"aircraft_code\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"aircraft_description\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"basic_type\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"capacity\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"manufacturer\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"pressurized\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"propulsion\"]'", ",", "\n", "'col_ref -> [\"aircraft\", \".\", \"wide_body\"]'", ",", "\n", "'col_ref -> [\"airline\", \".\", \"airline_code\"]'", ",", "\n", "'col_ref -> [\"airline\", \".\", \"airline_name\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"airport_code\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"airport_location\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"airport_name\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"country_name\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"minimum_connect_time\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"state_code\"]'", ",", "\n", "'col_ref -> [\"airport\", \".\", \"time_zone_code\"]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"direction\"]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"miles_distant\"]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"minutes_distant\"]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_name\"]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"country_name\"]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"state_code\"]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"time_zone_code\"]'", ",", "\n", "'col_ref -> [\"class_of_service\", \".\", \"booking_class\"]'", ",", "\n", "'col_ref -> [\"class_of_service\", \".\", \"class_description\"]'", ",", "\n", "'col_ref -> [\"class_of_service\", \".\", \"rank\"]'", ",", "\n", "'col_ref -> [\"date_day\", \".\", \"day_name\"]'", ",", "\n", "'col_ref -> [\"days\", \".\", \"day_name\"]'", ",", "\n", "'col_ref -> [\"days\", \".\", \"days_code\"]'", ",", "\n", "'col_ref -> [\"equipment_sequence\", \".\", \"aircraft_code\"]'", ",", "\n", "'col_ref -> [\"equipment_sequence\", \".\", \"aircraft_code_sequence\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"fare_airline\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"fare_basis_code\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"fare_id\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"from_airport\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"one_direction_cost\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"restriction_code\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"round_trip_cost\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"round_trip_required\"]'", ",", "\n", "'col_ref -> [\"fare\", \".\", \"to_airport\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"basis_days\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"booking_class\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"class_type\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"discounted\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"economy\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"fare_basis_code\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"night\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"premium\"]'", ",", "\n", "'col_ref -> [\"fare_basis\", \".\", \"season\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"aircraft_code_sequence\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"airline_code\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"airline_flight\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"arrival_time\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"connections\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"departure_time\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"dual_carrier\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"flight_days\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"flight_id\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"flight_number\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"from_airport\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"meal_code\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"stops\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"time_elapsed\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"to_airport\"]'", ",", "\n", "'col_ref -> [\"flight_fare\", \".\", \"fare_id\"]'", ",", "\n", "'col_ref -> [\"flight_fare\", \".\", \"flight_id\"]'", ",", "\n", "'col_ref -> [\"flight_leg\", \".\", \"flight_id\"]'", ",", "\n", "'col_ref -> [\"flight_leg\", \".\", \"leg_flight\"]'", ",", "\n", "'col_ref -> [\"flight_leg\", \".\", \"leg_number\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"arrival_airline\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"arrival_flight_number\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"arrival_time\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"departure_airline\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"departure_flight_number\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"departure_time\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"flight_id\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"stop_airport\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"stop_days\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"stop_number\"]'", ",", "\n", "'col_ref -> [\"flight_stop\", \".\", \"stop_time\"]'", ",", "\n", "'col_ref -> [\"food_service\", \".\", \"compartment\"]'", ",", "\n", "'col_ref -> [\"food_service\", \".\", \"meal_code\"]'", ",", "\n", "'col_ref -> [\"food_service\", \".\", \"meal_description\"]'", ",", "\n", "'col_ref -> [\"food_service\", \".\", \"meal_number\"]'", ",", "\n", "'col_ref -> [\"ground_service\", \".\", \"airport_code\"]'", ",", "\n", "'col_ref -> [\"ground_service\", \".\", \"city_code\"]'", ",", "\n", "'col_ref -> [\"ground_service\", \".\", \"ground_fare\"]'", ",", "\n", "'col_ref -> [\"ground_service\", \".\", \"transport_type\"]'", ",", "\n", "'col_ref -> [\"month\", \".\", \"month_name\"]'", ",", "\n", "'col_ref -> [\"month\", \".\", \"month_number\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"advance_purchase\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"application\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"maximum_stay\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"minimum_stay\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"no_discounts\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"restriction_code\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"saturday_stay_required\"]'", ",", "\n", "'col_ref -> [\"restriction\", \".\", \"stopovers\"]'", ",", "\n", "'col_ref -> [\"state\", \".\", \"country_name\"]'", ",", "\n", "'col_ref -> [\"state\", \".\", \"state_code\"]'", ",", "\n", "'col_ref -> [\"state\", \".\", \"state_name\"]'", ",", "\n", "}", "\n", "\n", "assert", "set", "(", "valid_actions", "[", "\"table_name\"", "]", ")", "==", "{", "\n", "'table_name -> [\"aircraft\"]'", ",", "\n", "'table_name -> [\"airline\"]'", ",", "\n", "'table_name -> [\"airport\"]'", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'table_name -> [\"class_of_service\"]'", ",", "\n", "'table_name -> [\"date_day\"]'", ",", "\n", "'table_name -> [\"days\"]'", ",", "\n", "'table_name -> [\"equipment_sequence\"]'", ",", "\n", "'table_name -> [\"fare\"]'", ",", "\n", "'table_name -> [\"fare_basis\"]'", ",", "\n", "'table_name -> [\"flight\"]'", ",", "\n", "'table_name -> [\"flight_fare\"]'", ",", "\n", "'table_name -> [\"flight_leg\"]'", ",", "\n", "'table_name -> [\"flight_stop\"]'", ",", "\n", "'table_name -> [\"food_service\"]'", ",", "\n", "'table_name -> [\"ground_service\"]'", ",", "\n", "'table_name -> [\"month\"]'", ",", "\n", "'table_name -> [\"restriction\"]'", ",", "\n", "'table_name -> [\"state\"]'", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_atis_local_actions": [[367, 429], ["allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "set", "set", "set", "set", "set", "set", "set", "set"], "methods", ["None"], ["", "def", "test_atis_local_actions", "(", "self", ")", ":", "\n", "# Check if the triggers activate correcty", "\n", "        ", "world", "=", "AtisWorld", "(", "[", "\"show me the flights from denver at 12 o'clock\"", "]", ")", "\n", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"number\"", "]", ")", "==", "{", "\n", "'number -> [\"0\"]'", ",", "\n", "'number -> [\"1\"]'", ",", "\n", "'number -> [\"60\"]'", ",", "\n", "'number -> [\"41\"]'", ",", "\n", "'number -> [\"1200\"]'", ",", "\n", "'number -> [\"2400\"]'", ",", "\n", "}", "\n", "\n", "world", "=", "AtisWorld", "(", "\n", "[", "\n", "\"show me the flights from denver at 12 o'clock\"", ",", "\n", "\"show me the delta or united flights in afternoon\"", ",", "\n", "]", "\n", ")", "\n", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"number\"", "]", ")", "==", "{", "\n", "'number -> [\"0\"]'", ",", "\n", "'number -> [\"1\"]'", ",", "\n", "'number -> [\"60\"]'", ",", "\n", "'number -> [\"41\"]'", ",", "\n", "'number -> [\"1200\"]'", ",", "\n", "'number -> [\"2400\"]'", ",", "\n", "}", "\n", "\n", "world", "=", "AtisWorld", "(", "\n", "[", "\n", "\"i would like one coach reservation for \\\n                          may ninth from pittsburgh to atlanta leaving \\\n                          pittsburgh before 10 o'clock in morning 1991 \\\n                          august twenty sixth\"", "\n", "]", "\n", ")", "\n", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"number\"", "]", ")", "==", "{", "\n", "'number -> [\"0\"]'", ",", "\n", "'number -> [\"1\"]'", ",", "\n", "'number -> [\"60\"]'", ",", "\n", "'number -> [\"41\"]'", ",", "\n", "'number -> [\"1200\"]'", ",", "\n", "'number -> [\"2200\"]'", ",", "\n", "'number -> [\"1000\"]'", ",", "\n", "}", "\n", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"time_range_start\"", "]", ")", "==", "{", "'time_range_start -> [\"0\"]'", "}", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"time_range_end\"", "]", ")", "==", "{", "\n", "'time_range_end -> [\"1200\"]'", ",", "\n", "'time_range_end -> [\"800\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"day_number\"", "]", ")", "==", "{", "\n", "'day_number -> [\"26\"]'", ",", "\n", "'day_number -> [\"9\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"month_number\"", "]", ")", "==", "{", "\n", "'month_number -> [\"5\"]'", ",", "\n", "'month_number -> [\"8\"]'", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"year_number\"", "]", ")", "==", "{", "'year_number -> [\"1991\"]'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_atis_simple_action_sequence": [[430, 606], ["allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence"], ["", "def", "test_atis_simple_action_sequence", "(", "self", ")", ":", "\n", "        ", "world", "=", "AtisWorld", "(", "\n", "[", "(", "\"give me all flights from boston to \"", "\"philadelphia next week arriving after lunch\"", ")", "]", "\n", ")", "\n", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "\n", "(", "\n", "\"(SELECT DISTINCT city . city_code , city . city_name \"", "\n", "\"FROM city WHERE ( city.city_name = 'BOSTON' ) );\"", "\n", ")", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"DISTINCT\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "'col_refs -> [col_ref, \",\", col_refs]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_name\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "]", "\n", "\n", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "\n", "(", "\n", "\"( SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service \"", "\n", "\"WHERE airport_service . city_code IN ( \"", "\n", "\"SELECT city . city_code FROM city \"", "\n", "\"WHERE city.city_name = 'BOSTON' ) ) ;\"", "\n", ")", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "]", "\n", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "\n", "(", "\n", "\"( SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service WHERE airport_service . city_code IN \"", "\n", "\"( SELECT city . city_code FROM city \"", "\n", "\"WHERE city.city_name = 'BOSTON' ) AND 1 = 1) ;\"", "\n", ")", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "'conj -> [\"AND\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "\"biexpr -> [value, binaryop, value]\"", ",", "\n", "\"value -> [pos_value]\"", ",", "\n", "\"pos_value -> [number]\"", ",", "\n", "'number -> [\"1\"]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"value -> [pos_value]\"", ",", "\n", "\"pos_value -> [number]\"", ",", "\n", "'number -> [\"1\"]'", ",", "\n", "]", "\n", "world", "=", "AtisWorld", "(", "\n", "[", "(", "\"give me all flights from boston to \"", "\"philadelphia next week arriving after lunch\"", ")", "]", "\n", ")", "\n", "\n", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "\n", "(", "\n", "\"( SELECT DISTINCT flight.flight_id \"", "\n", "\"FROM flight WHERE \"", "\n", "\"( flight . from_airport IN \"", "\n", "\"( SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service WHERE airport_service . city_code IN \"", "\n", "\"( SELECT city . city_code \"", "\n", "\"FROM city \"", "\n", "\"WHERE city.city_name = 'BOSTON' )))) ;\"", "\n", ")", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"DISTINCT\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"flight\", \".\", \"flight_id\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"flight\"]'", ",", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"from_airport\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_atis_long_action_sequence": [[608, 821], ["allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence"], ["", "def", "test_atis_long_action_sequence", "(", "self", ")", ":", "\n", "        ", "world", "=", "AtisWorld", "(", "\n", "[", "\n", "(", "\n", "\"what is the earliest flight in morning \"", "\n", "\"1993 june fourth from boston to pittsburgh\"", "\n", ")", "\n", "]", "\n", ")", "\n", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "\n", "\"( SELECT DISTINCT flight.flight_id \"", "\n", "\"FROM flight \"", "\n", "\"WHERE ( flight.departure_time = ( \"", "\n", "\"SELECT MIN ( flight.departure_time ) \"", "\n", "\"FROM flight \"", "\n", "\"WHERE ( flight.departure_time BETWEEN 0 AND 1200 AND \"", "\n", "\"( flight . from_airport IN ( \"", "\n", "\"SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service WHERE airport_service . city_code \"", "\n", "\"IN ( \"", "\n", "\"SELECT city . city_code \"", "\n", "\"FROM city WHERE city.city_name = 'BOSTON' )) \"", "\n", "\"AND flight . to_airport IN ( \"", "\n", "\"SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service \"", "\n", "\"WHERE airport_service . city_code IN ( \"", "\n", "\"SELECT city . city_code \"", "\n", "\"FROM city \"", "\n", "\"WHERE city.city_name = 'PITTSBURGH' )) ) ) ) AND \"", "\n", "\"( flight.departure_time BETWEEN 0 AND 1200 AND \"", "\n", "\"( flight . from_airport IN ( \"", "\n", "\"SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service \"", "\n", "\"WHERE airport_service . city_code IN ( \"", "\n", "\"SELECT city . city_code \"", "\n", "\"FROM city WHERE city.city_name = 'BOSTON' )) \"", "\n", "\"AND flight . to_airport IN ( \"", "\n", "\"SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service WHERE airport_service . city_code IN ( \"", "\n", "\"SELECT city . city_code \"", "\n", "\"FROM city \"", "\n", "\"WHERE city.city_name = 'PITTSBURGH' )) ) ) )   ) ;\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"DISTINCT\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"flight\", \".\", \"flight_id\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"flight\"]'", ",", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "\"biexpr -> [col_ref, binaryop, value]\"", ",", "\n", "'col_ref -> [\"flight\", \".\", \"departure_time\"]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"value -> [pos_value]\"", ",", "\n", "\"pos_value -> [agg_results]\"", ",", "\n", "'agg_results -> [\"(\", \"SELECT\", distinct, agg, \"FROM\", table_name, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "'agg -> [agg_func, \"(\", col_ref, \")\"]'", ",", "\n", "'agg_func -> [\"MIN\"]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"departure_time\"]'", ",", "\n", "'table_name -> [\"flight\"]'", ",", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"condition -> [ternaryexpr]\"", ",", "\n", "'ternaryexpr -> [col_ref, \"BETWEEN\", time_range_start, \"AND\", time_range_end]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"departure_time\"]'", ",", "\n", "'time_range_start -> [\"0\"]'", ",", "\n", "'time_range_end -> [\"1200\"]'", ",", "\n", "'conj -> [\"AND\"]'", ",", "\n", "'conditions -> [\"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"from_airport\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "'conj -> [\"AND\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"to_airport\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'PITTSBURGH'\\\"]\"", ",", "\n", "'conj -> [\"AND\"]'", ",", "\n", "'conditions -> [\"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"condition -> [ternaryexpr]\"", ",", "\n", "'ternaryexpr -> [col_ref, \"BETWEEN\", time_range_start, \"AND\", time_range_end]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"departure_time\"]'", ",", "\n", "'time_range_start -> [\"0\"]'", ",", "\n", "'time_range_end -> [\"1200\"]'", ",", "\n", "'conj -> [\"AND\"]'", ",", "\n", "'conditions -> [\"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition, conj, conditions]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"from_airport\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "'conj -> [\"AND\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"flight\", \".\", \"to_airport\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"airport_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"airport_service\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [in_clause]\"", ",", "\n", "'in_clause -> [col_ref, \"IN\", query]'", ",", "\n", "'col_ref -> [\"airport_service\", \".\", \"city_code\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", conditions]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'PITTSBURGH'\\\"]\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_atis_from_json": [[823, 834], ["json.loads", "range", "len", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence"], ["", "def", "test_atis_from_json", "(", "self", ")", ":", "\n", "        ", "line", "=", "json", ".", "loads", "(", "self", ".", "data", "[", "0", "]", ")", "\n", "for", "utterance_idx", "in", "range", "(", "len", "(", "line", "[", "\"interaction\"", "]", ")", ")", ":", "\n", "            ", "world", "=", "AtisWorld", "(", "\n", "[", "\n", "interaction", "[", "\"utterance\"", "]", "\n", "for", "interaction", "in", "line", "[", "\"interaction\"", "]", "[", ":", "utterance_idx", "+", "1", "]", "\n", "]", "\n", ")", "\n", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "line", "[", "\"interaction\"", "]", "[", "utterance_idx", "]", "[", "\"sql\"", "]", ")", "\n", "assert", "action_sequence", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_time_extraction": [[835, 847], ["allennlp_semparse.parsimonious_languages.contexts.atis_tables.get_approximate_times", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.get_approximate_times", "allennlp_semparse.parsimonious_languages.contexts.atis_tables.pm_map_match_to_query_value"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_approximate_times", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.get_approximate_times", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.atis_tables.pm_map_match_to_query_value"], ["", "", "def", "test_time_extraction", "(", "self", ")", ":", "\n", "        ", "approximate_times", "=", "get_approximate_times", "(", "[", "1900", "]", ")", "\n", "assert", "approximate_times", "==", "[", "1830", ",", "1930", "]", "\n", "\n", "approximate_times", "=", "get_approximate_times", "(", "[", "515", "]", ")", "\n", "assert", "approximate_times", "==", "[", "445", ",", "545", "]", "\n", "\n", "pm_times", "=", "[", "\n", "pm_map_match_to_query_value", "(", "string", ")", "\n", "for", "string", "in", "[", "\"12pm\"", ",", "\"1pm\"", ",", "\"830pm\"", ",", "\"1230pm\"", ",", "\"115pm\"", "]", "\n", "]", "\n", "assert", "pm_times", "==", "[", "[", "1200", "]", ",", "[", "1300", "]", ",", "[", "2030", "]", ",", "[", "1230", "]", ",", "[", "1315", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world_test.TestAtisWorld.test_atis_helper_methods": [[848, 883], ["allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld._get_numeric_database_values", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld._get_sequence_with_spacing", "parsimonious.expressions.Sequence", "datetime.datetime.datetime", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal", "datetime.datetime.datetime", "parsimonious.expressions.Literal", "parsimonious.expressions.Literal"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_numeric_database_values", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld._get_sequence_with_spacing"], ["", "def", "test_atis_helper_methods", "(", "self", ")", ":", "\n", "        ", "world", "=", "AtisWorld", "(", "\n", "[", "\n", "(", "\n", "\"what is the earliest flight in morning \"", "\n", "\"1993 june fourth from boston to pittsburgh\"", "\n", ")", "\n", "]", "\n", ")", "\n", "assert", "world", ".", "dates", "==", "[", "datetime", "(", "1993", ",", "6", ",", "4", ",", "0", ",", "0", ")", "]", "\n", "assert", "world", ".", "_get_numeric_database_values", "(", "\"time_range_end\"", ")", "==", "[", "\"800\"", ",", "\"1200\"", "]", "\n", "assert", "world", ".", "_get_sequence_with_spacing", "(", "\n", "world", ".", "grammar", ",", "\n", "[", "\n", "world", ".", "grammar", "[", "\"col_ref\"", "]", ",", "\n", "Literal", "(", "\"BETWEEN\"", ")", ",", "\n", "world", ".", "grammar", "[", "\"time_range_start\"", "]", ",", "\n", "Literal", "(", "\"AND\"", ")", ",", "\n", "world", ".", "grammar", "[", "\"time_range_end\"", "]", ",", "\n", "]", ",", "\n", ")", "==", "Sequence", "(", "\n", "world", ".", "grammar", "[", "\"col_ref\"", "]", ",", "\n", "world", ".", "grammar", "[", "\"ws\"", "]", ",", "\n", "Literal", "(", "\"BETWEEN\"", ")", ",", "\n", "world", ".", "grammar", "[", "\"ws\"", "]", ",", "\n", "world", ".", "grammar", "[", "\"time_range_start\"", "]", ",", "\n", "world", ".", "grammar", "[", "\"ws\"", "]", ",", "\n", "Literal", "(", "\"AND\"", ")", ",", "\n", "world", ".", "grammar", "[", "\"ws\"", "]", ",", "\n", "world", ".", "grammar", "[", "\"time_range_end\"", "]", ",", "\n", "world", ".", "grammar", "[", "\"ws\"", "]", ",", "\n", ")", "\n", "\n", "world", "=", "AtisWorld", "(", "[", "\"i plan to travel on the tenth of 1993 july\"", "]", ")", "\n", "assert", "world", ".", "dates", "==", "[", "datetime", "(", "1993", ",", "7", ",", "10", ",", "0", ",", "0", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.setup_method": [[16, 20], ["super().setup_method", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "schema", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants-schema.csv\"", ")", "\n", "self", ".", "database_path", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants.db\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_untyped_grammar_has_no_string_or_number_references": [[21, 33], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "grammar_dictionary.items", "all", "all", "all", "all"], "methods", ["None"], ["", "def", "test_untyped_grammar_has_no_string_or_number_references", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ",", "use_untyped_entities", "=", "True", ")", "\n", "grammar_dictionary", "=", "world", ".", "base_grammar_dictionary", "\n", "\n", "for", "key", ",", "value", "in", "grammar_dictionary", ".", "items", "(", ")", ":", "\n", "            ", "assert", "key", "not", "in", "{", "\"number\"", ",", "\"string\"", "}", "\n", "# We don't check for string directly here because", "\n", "# string_set is a valid non-terminal.", "\n", "assert", "all", "(", "[", "\"number\"", "not", "in", "production", "for", "production", "in", "value", "]", ")", "\n", "assert", "all", "(", "[", "\"string)\"", "not", "in", "production", "for", "production", "in", "value", "]", ")", "\n", "assert", "all", "(", "[", "\"string \"", "not", "in", "production", "for", "production", "in", "value", "]", ")", "\n", "assert", "all", "(", "[", "\"(string \"", "not", "in", "production", "for", "production", "in", "value", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_world_modifies_unconstrained_grammar_correctly": [[34, 48], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld"], "methods", ["None"], ["", "", "def", "test_world_modifies_unconstrained_grammar_correctly", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "grammar_dictionary", "=", "world", ".", "base_grammar_dictionary", "\n", "assert", "grammar_dictionary", "[", "\"table_name\"", "]", "==", "[", "'\"RESTAURANT\"'", ",", "'\"LOCATION\"'", ",", "'\"GEOGRAPHIC\"'", "]", "\n", "assert", "grammar_dictionary", "[", "\"column_name\"", "]", "==", "[", "\n", "'\"STREET_NAME\"'", ",", "\n", "'\"RESTAURANT_ID\"'", ",", "\n", "'\"REGION\"'", ",", "\n", "'\"RATING\"'", ",", "\n", "'\"NAME\"'", ",", "\n", "'\"HOUSE_NUMBER\"'", ",", "\n", "'\"FOOD_TYPE\"'", ",", "\n", "'\"COUNTY\"'", ",", "\n", "'\"CITY_NAME\"'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_world_modifies_grammar_with_global_values_for_dataset": [[50, 64], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld"], "methods", ["None"], ["", "def", "test_world_modifies_grammar_with_global_values_for_dataset", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "grammar_dictionary", "=", "world", ".", "base_grammar_dictionary", "\n", "# Should have added 2.5 because it is a global value", "\n", "# for the restaurants dataset.", "\n", "assert", "grammar_dictionary", "[", "\"value\"", "]", "==", "[", "\n", "'\"2.5\"'", ",", "\n", "\"parenval\"", ",", "\n", "'\"YEAR(CURDATE())\"'", ",", "\n", "\"number\"", ",", "\n", "\"boolean\"", ",", "\n", "\"function\"", ",", "\n", "\"col_ref\"", ",", "\n", "\"string\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_variable_free_world_cannot_parse_as_statements": [[66, 149], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "grammar_dictionary.items", "parsimonious.Grammar", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor.parse", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_grammar_string", "pytest.raises", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor.parse"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_grammar_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse"], ["", "def", "test_variable_free_world_cannot_parse_as_statements", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "grammar_dictionary", "=", "world", ".", "base_grammar_dictionary", "\n", "for", "productions", "in", "grammar_dictionary", ".", "items", "(", ")", ":", "\n", "            ", "assert", "\"AS\"", "not", "in", "productions", "\n", "\n", "", "sql_with_as", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "grammar", "=", "Grammar", "(", "format_grammar_string", "(", "world", ".", "base_grammar_dictionary", ")", ")", "\n", "sql_visitor", "=", "SqlVisitor", "(", "grammar", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "ParseError", ")", ":", "\n", "            ", "sql_visitor", ".", "parse", "(", "\" \"", ".", "join", "(", "sql_with_as", ")", ")", "\n", "\n", "", "sql", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "# Without the AS we should still be able to parse it.", "\n", "sql_visitor", "=", "SqlVisitor", "(", "grammar", ")", "\n", "sql_visitor", ".", "parse", "(", "\" \"", ".", "join", "(", "sql", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_grammar_from_world_can_parse_statements": [[150, 188], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "parsimonious.Grammar", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.SqlVisitor.parse", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.format_grammar_string"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.DateValue.parse", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.format_grammar_string"], ["", "def", "test_grammar_from_world_can_parse_statements", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "sql", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "grammar", "=", "Grammar", "(", "format_grammar_string", "(", "world", ".", "base_grammar_dictionary", ")", ")", "\n", "sql_visitor", "=", "SqlVisitor", "(", "grammar", ")", "\n", "sql_visitor", ".", "parse", "(", "\" \"", ".", "join", "(", "sql", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_world_identifies_non_global_rules": [[189, 192], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld.is_global_rule"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.is_global_rule"], ["", "def", "test_world_identifies_non_global_rules", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "assert", "not", "world", ".", "is_global_rule", "(", "\"value -> [\\\"'food_type0'\\\"]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_grammar_from_world_can_produce_entities_as_values": [[193, 237], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld.get_action_sequence_and_all_actions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.get_action_sequence_and_all_actions"], ["", "def", "test_grammar_from_world_can_produce_entities_as_values", "(", "self", ")", ":", "\n", "        ", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "sql", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "entities", "=", "{", "\n", "\"city_name0\"", ":", "{", "\"text\"", ":", "\"San fran\"", ",", "\"type\"", ":", "\"location\"", "}", ",", "\n", "\"name0\"", ":", "{", "\"text\"", ":", "\"Matt Gardinios Pizza\"", ",", "\"type\"", ":", "\"restaurant\"", "}", ",", "\n", "}", "\n", "action_sequence", ",", "actions", "=", "world", ".", "get_action_sequence_and_all_actions", "(", "sql", ",", "entities", ")", "\n", "assert", "\"string -> [\\\"'city_name0'\\\"]\"", "in", "action_sequence", "\n", "assert", "\"string -> [\\\"'name0'\\\"]\"", "in", "action_sequence", "\n", "assert", "\"string -> [\\\"'city_name0'\\\"]\"", "in", "actions", "\n", "assert", "\"string -> [\\\"'name0'\\\"]\"", "in", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world_test.TestText2SqlWorld.test_world_adds_values_from_tables": [[238, 286], ["sqlite3.connect", "sqlite3.connect.cursor", "allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld"], "methods", ["None"], ["", "def", "test_world_adds_values_from_tables", "(", "self", ")", ":", "\n", "        ", "connection", "=", "sqlite3", ".", "connect", "(", "self", ".", "database_path", ")", "\n", "cursor", "=", "connection", ".", "cursor", "(", ")", "\n", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ",", "cursor", "=", "cursor", ",", "use_prelinked_entities", "=", "False", ")", "\n", "assert", "world", ".", "base_grammar_dictionary", "[", "\"number\"", "]", "==", "[", "\n", "'\"229\"'", ",", "\n", "'\"228\"'", ",", "\n", "'\"227\"'", ",", "\n", "'\"226\"'", ",", "\n", "'\"225\"'", ",", "\n", "'\"5\"'", ",", "\n", "'\"4\"'", ",", "\n", "'\"3\"'", ",", "\n", "'\"2\"'", ",", "\n", "'\"1\"'", ",", "\n", "'\"833\"'", ",", "\n", "'\"430\"'", ",", "\n", "'\"242\"'", ",", "\n", "'\"135\"'", ",", "\n", "'\"1103\"'", ",", "\n", "]", "\n", "\n", "assert", "world", ".", "base_grammar_dictionary", "[", "\"string\"", "]", "==", "[", "\n", "'\"tommy\\'s\"'", ",", "\n", "'\"rod\\'s hickory pit restaurant\"'", ",", "\n", "'\"lyons restaurant\"'", ",", "\n", "'\"jamerican cuisine\"'", ",", "\n", "'\"denny\\'s restaurant\"'", ",", "\n", "'\"american\"'", ",", "\n", "'\"vallejo\"'", ",", "\n", "'\"w. el camino real\"'", ",", "\n", "'\"el camino real\"'", ",", "\n", "'\"e. el camino real\"'", ",", "\n", "'\"church st\"'", ",", "\n", "'\"broadway\"'", ",", "\n", "'\"sunnyvale\"'", ",", "\n", "'\"san francisco\"'", ",", "\n", "'\"san carlos\"'", ",", "\n", "'\"american canyon\"'", ",", "\n", "'\"alviso\"'", ",", "\n", "'\"albany\"'", ",", "\n", "'\"alamo\"'", ",", "\n", "'\"alameda\"'", ",", "\n", "'\"unknown\"'", ",", "\n", "'\"santa clara county\"'", ",", "\n", "'\"contra costa county\"'", ",", "\n", "'\"alameda county\"'", ",", "\n", "'\"bay area\"'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.ComplexType.return_type": [[36, 48], ["isinstance"], "methods", ["None"], ["def", "return_type", "(", "self", ")", "->", "Type", ":", "\n", "        ", "\"\"\"\n        Gives the final return type for this function.  If the function takes a single argument,\n        this is just ``self.second``.  If the function takes multiple arguments and returns a basic\n        type, this should be the final ``.second`` after following all complex types.  That is the\n        implementation here in the base class.  If you have a higher-order function that returns a\n        function itself, you need to override this method.\n        \"\"\"", "\n", "return_type", "=", "self", ".", "second", "\n", "while", "isinstance", "(", "return_type", ",", "ComplexType", ")", ":", "\n", "            ", "return_type", "=", "return_type", ".", "second", "\n", "", "return", "return_type", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.ComplexType.argument_types": [[49, 62], ["isinstance", "arguments.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "argument_types", "(", "self", ")", "->", "List", "[", "Type", "]", ":", "\n", "        ", "\"\"\"\n        Gives the types of all arguments to this function.  For functions returning a basic type,\n        we grab all ``.first`` types until ``.second`` is no longer a ``ComplexType``.  That logic\n        is implemented here in the base class.  If you have a higher-order function that returns a\n        function itself, you need to override this method.\n        \"\"\"", "\n", "arguments", "=", "[", "self", ".", "first", "]", "\n", "remaining_type", "=", "self", ".", "second", "\n", "while", "isinstance", "(", "remaining_type", ",", "ComplexType", ")", ":", "\n", "            ", "arguments", ".", "append", "(", "remaining_type", ".", "first", ")", "\n", "remaining_type", "=", "remaining_type", ".", "second", "\n", "", "return", "arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.ComplexType.substitute_any_type": [[63, 73], ["type_declaration.ComplexType.substitute_any_type"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.substitute_any_type"], ["", "def", "substitute_any_type", "(", "self", ",", "basic_types", ":", "Set", "[", "BasicType", "]", ")", "->", "List", "[", "Type", "]", ":", "\n", "        ", "\"\"\"\n        Takes a set of ``BasicTypes`` and replaces any instances of ``ANY_TYPE`` inside this\n        complex type with each of those basic types.\n        \"\"\"", "\n", "substitutions", "=", "[", "]", "\n", "for", "first_type", "in", "substitute_any_type", "(", "self", ".", "first", ",", "basic_types", ")", ":", "\n", "            ", "for", "second_type", "in", "substitute_any_type", "(", "self", ".", "second", ",", "basic_types", ")", ":", "\n", "                ", "substitutions", ".", "append", "(", "self", ".", "__class__", "(", "first_type", ",", "second_type", ")", ")", "\n", "", "", "return", "substitutions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.HigherOrderType.__init__": [[92, 95], ["nltk.sem.logic.ComplexType.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "self", ",", "num_arguments", ":", "int", ",", "first", ":", "Type", ",", "second", ":", "Type", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "first", ",", "second", ")", "\n", "self", ".", "num_arguments", "=", "num_arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.HigherOrderType.return_type": [[96, 102], ["range"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "return_type", "(", "self", ")", "->", "Type", ":", "\n", "        ", "return_type", "=", "self", ".", "second", "\n", "for", "_", "in", "range", "(", "self", ".", "num_arguments", "-", "1", ")", ":", "\n", "            ", "return_type", "=", "return_type", ".", "second", "\n", "", "return", "return_type", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.HigherOrderType.argument_types": [[103, 111], ["range", "arguments.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "argument_types", "(", "self", ")", "->", "List", "[", "Type", "]", ":", "\n", "        ", "arguments", "=", "[", "self", ".", "first", "]", "\n", "remaining_type", "=", "self", ".", "second", "\n", "for", "_", "in", "range", "(", "self", ".", "num_arguments", "-", "1", ")", ":", "\n", "            ", "arguments", ".", "append", "(", "remaining_type", ".", "first", ")", "\n", "remaining_type", "=", "remaining_type", ".", "second", "\n", "", "return", "arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NamedBasicType.__init__": [[125, 127], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "string_rep", ")", "->", "None", ":", "\n", "        ", "self", ".", "_string_rep", "=", "string_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NamedBasicType.__str__": [[128, 135], ["type_declaration.NamedBasicType._string_rep.lower"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "# TODO (pradeep): This limits the number of basic types we can have to 26. We may want to", "\n", "# change this in the future if we extend to domains where we have more than 26 basic types.", "\n", "        ", "if", "self", ".", "_string_rep", "==", "START_SYMBOL", ":", "\n", "            ", "return", "START_SYMBOL", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_string_rep", ".", "lower", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NamedBasicType.str": [[136, 138], ["None"], "methods", ["None"], ["", "", "def", "str", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_string_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.MultiMatchNamedBasicType.__init__": [[154, 157], ["type_declaration.NamedBasicType.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "self", ",", "string_rep", ",", "types_to_match", ":", "List", "[", "BasicType", "]", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "string_rep", ")", "\n", "self", ".", "types_to_match", "=", "set", "(", "types_to_match", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.MultiMatchNamedBasicType.matches": [[158, 161], ["super().matches"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.matches"], ["", "@", "overrides", "\n", "def", "matches", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "matches", "(", "other", ")", "or", "other", "in", "self", ".", "types_to_match", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.resolve": [[192, 216], ["None"], "methods", ["None"], ["@", "overrides", "\n", "def", "resolve", "(", "self", ",", "other", ":", "Type", ")", "->", "Optional", "[", "Type", "]", ":", "\n", "        ", "\"\"\"\n        This method is central to type inference and checking. When a variable's type is being\n        checked, we compare what we know of its type against what is expected of its type by its\n        context. The expectation is provided as ``other``. We make sure that there are no\n        contradictions between this type and other, and return an updated type which may be more\n        specific than the original type.\n\n        For example, say this type is of the function variable F in F(cell), and we start out with\n        ``<?, d>`` (that is, it takes any type and returns ``d`` ). Now we have already resolved\n        cell to be of type ``e`` . Then ``resolve`` gets called with ``other = <e, ?>`` , because\n        we know F is a function that took a constant of type ``e`` . When we resolve ``<e, ?>``\n        against ``<?, d>`` , there will not be a contradiction, because any type can be\n        successfully resolved against ``?`` . Finally we return ``<e, d>`` as the resolved type.\n\n        As a counter example, if we are trying to resolve ``<?, d>`` against ``<?, e>`` , the\n        resolution fails, and in that case, this method returns ``None`` .\n\n        Note that a successful resolution does not imply equality of types because of one of them\n        may be ANY_TYPE, and so in the subclasses of this type, we explicitly resolve in both\n        directions.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.get_application_type": [[217, 223], ["None"], "methods", ["None"], ["", "def", "get_application_type", "(", "self", ",", "argument_type", ":", "Type", ")", "->", "Type", ":", "\n", "        ", "\"\"\"\n        This method returns the resulting type when this type is applied as a function to an argument of\n        the given type.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.substitute_any_type": [[224, 232], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "substitute_any_type", "(", "self", ",", "basic_types", ":", "Set", "[", "BasicType", "]", ")", "->", "List", "[", "Type", "]", ":", "\n", "        ", "\"\"\"\n        Placeholders mess with substitutions, so even though this method is implemented in the\n        superclass, we override it here with a ``NotImplementedError`` to be sure that subclasses\n        think about what the right thing to do here is, and do it correctly.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.__eq__": [[233, 236], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "__eq__", "(", "self", ",", "other", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "__class__", "==", "other", ".", "__class__", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.matches": [[237, 241], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "matches", "(", "self", ",", "other", ")", "->", "bool", ":", "\n", "# self == ANY_TYPE = True iff self.first == ANY_TYPE and self.second == ANY_TYPE.", "\n", "        ", "return", "self", "==", "other", "or", "self", "==", "ANY_TYPE", "or", "other", "==", "ANY_TYPE", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.__str__": [[242, 249], ["type_declaration.PlaceholderType.str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "@", "overrides", "\n", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", "==", "ANY_TYPE", ":", "\n", "# If the type remains unresolved, we return ? instead of its signature.", "\n", "            ", "return", "str", "(", "ANY_TYPE", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_signature", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str": [[250, 256], ["nltk.sem.logic.ANY_TYPE.str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "", "@", "overrides", "\n", "def", "str", "(", "self", ")", ":", "\n", "        ", "if", "self", "==", "ANY_TYPE", ":", "\n", "            ", "return", "ANY_TYPE", ".", "str", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_signature", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.UnaryOpType.__init__": [[280, 289], ["nltk.sem.logic.ComplexType.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "type_", ":", "BasicType", "=", "ANY_TYPE", ",", "\n", "allowed_substitutions", ":", "Set", "[", "BasicType", "]", "=", "None", ",", "\n", "signature", ":", "str", "=", "\"<#1,#1>\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "type_", ",", "type_", ")", "\n", "self", ".", "_allowed_substitutions", "=", "allowed_substitutions", "\n", "self", ".", "_signature", "=", "signature", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.UnaryOpType.resolve": [[290, 302], ["other.first.resolve", "other.second.resolve", "type_declaration.UnaryOpType", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve"], ["", "@", "overrides", "\n", "def", "resolve", "(", "self", ",", "other", ")", "->", "Optional", "[", "Type", "]", ":", "\n", "        ", "\"\"\"See ``PlaceholderType.resolve``\"\"\"", "\n", "if", "not", "isinstance", "(", "other", ",", "NltkComplexType", ")", ":", "\n", "            ", "return", "None", "\n", "", "other_first", "=", "other", ".", "first", ".", "resolve", "(", "other", ".", "second", ")", "\n", "if", "not", "other_first", ":", "\n", "            ", "return", "None", "\n", "", "other_second", "=", "other", ".", "second", ".", "resolve", "(", "other_first", ")", "\n", "if", "not", "other_second", ":", "\n", "            ", "return", "None", "\n", "", "return", "UnaryOpType", "(", "other_first", ",", "self", ".", "_allowed_substitutions", ",", "self", ".", "_signature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.UnaryOpType.get_application_type": [[303, 306], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_application_type", "(", "self", ",", "argument_type", ":", "Type", ")", "->", "Type", ":", "\n", "        ", "return", "argument_type", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.UnaryOpType.substitute_any_type": [[307, 317], ["type_declaration.UnaryOpType"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "substitute_any_type", "(", "self", ",", "basic_types", ":", "Set", "[", "BasicType", "]", ")", "->", "List", "[", "Type", "]", ":", "\n", "        ", "if", "self", ".", "first", "!=", "ANY_TYPE", ":", "\n", "            ", "return", "[", "self", "]", "\n", "", "allowed_basic_types", "=", "(", "\n", "self", ".", "_allowed_substitutions", "if", "self", ".", "_allowed_substitutions", "else", "basic_types", "\n", ")", "\n", "return", "[", "\n", "UnaryOpType", "(", "basic_type", ",", "self", ".", "_allowed_substitutions", ",", "self", ".", "_signature", ")", "\n", "for", "basic_type", "in", "allowed_basic_types", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.__init__": [[340, 349], ["nltk.sem.logic.ComplexType.__init__", "type_declaration.ComplexType"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "type_", ":", "BasicType", "=", "ANY_TYPE", ",", "\n", "allowed_substitutions", ":", "Set", "[", "BasicType", "]", "=", "None", ",", "\n", "signature", ":", "str", "=", "\"<#1,<#1,#1>>\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "type_", ",", "ComplexType", "(", "type_", ",", "type_", ")", ")", "\n", "self", ".", "_allowed_substitutions", "=", "allowed_substitutions", "\n", "self", ".", "_signature", "=", "signature", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve": [[350, 367], ["other.first.resolve", "other_first.resolve.resolve.resolve", "other.second.resolve", "type_declaration.BinaryOpType", "isinstance", "isinstance", "type_declaration.ComplexType"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve"], ["", "@", "overrides", "\n", "def", "resolve", "(", "self", ",", "other", ":", "Type", ")", "->", "Optional", "[", "Type", "]", ":", "\n", "        ", "\"\"\"See ``PlaceholderType.resolve``\"\"\"", "\n", "if", "not", "isinstance", "(", "other", ",", "NltkComplexType", ")", ":", "\n", "            ", "return", "None", "\n", "", "if", "not", "isinstance", "(", "other", ".", "second", ",", "NltkComplexType", ")", ":", "\n", "            ", "return", "None", "\n", "", "other_first", "=", "other", ".", "first", ".", "resolve", "(", "other", ".", "second", ".", "first", ")", "\n", "if", "other_first", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "other_first", "=", "other_first", ".", "resolve", "(", "other", ".", "second", ".", "second", ")", "\n", "if", "not", "other_first", ":", "\n", "            ", "return", "None", "\n", "", "other_second", "=", "other", ".", "second", ".", "resolve", "(", "ComplexType", "(", "other_first", ",", "other_first", ")", ")", "\n", "if", "not", "other_second", ":", "\n", "            ", "return", "None", "\n", "", "return", "BinaryOpType", "(", "other_first", ",", "self", ".", "_allowed_substitutions", ",", "self", ".", "_signature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.get_application_type": [[368, 371], ["type_declaration.ComplexType"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_application_type", "(", "self", ",", "argument_type", ":", "Type", ")", "->", "Type", ":", "\n", "        ", "return", "ComplexType", "(", "argument_type", ",", "argument_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.substitute_any_type": [[372, 382], ["type_declaration.BinaryOpType"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "substitute_any_type", "(", "self", ",", "basic_types", ":", "Set", "[", "BasicType", "]", ")", "->", "List", "[", "Type", "]", ":", "\n", "        ", "if", "self", ".", "first", "!=", "ANY_TYPE", ":", "\n", "            ", "return", "[", "self", "]", "\n", "", "allowed_basic_types", "=", "(", "\n", "self", ".", "_allowed_substitutions", "if", "self", ".", "_allowed_substitutions", "else", "basic_types", "\n", ")", "\n", "return", "[", "\n", "BinaryOpType", "(", "basic_type", ",", "self", ".", "_allowed_substitutions", ",", "self", ".", "_signature", ")", "\n", "for", "basic_type", "in", "allowed_basic_types", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.TypedConstantExpression.__init__": [[391, 394], ["nltk.sem.logic.ConstantExpression.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "self", ",", "variable", ",", "default_type", ":", "Type", ")", "->", "None", ":", "\n", "        ", "super", "(", "TypedConstantExpression", ",", "self", ")", ".", "__init__", "(", "variable", ")", "\n", "self", ".", "_default_type", "=", "default_type", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.TypedConstantExpression._set_type": [[395, 401], ["super()._set_type", "super()._set_type"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression._set_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression._set_type"], ["", "@", "overrides", "\n", "def", "_set_type", "(", "self", ",", "other_type", "=", "ANY_TYPE", ",", "signature", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "other_type", "==", "ANY_TYPE", ":", "\n", "            ", "super", "(", "TypedConstantExpression", ",", "self", ")", ".", "_set_type", "(", "self", ".", "_default_type", ",", "signature", ")", "\n", "", "else", ":", "\n", "            ", "super", "(", "TypedConstantExpression", ",", "self", ")", ".", "_set_type", "(", "other_type", ",", "signature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.__init__": [[420, 425], ["nltk.sem.logic.ApplicationExpression.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "function", ":", "Expression", ",", "argument", ":", "Expression", ",", "variables_with_placeholders", ":", "Set", "[", "str", "]", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "DynamicTypeApplicationExpression", ",", "self", ")", ".", "__init__", "(", "function", ",", "argument", ")", "\n", "self", ".", "_variables_with_placeholders", "=", "variables_with_placeholders", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type": [[426, 437], ["type_declaration.DynamicTypeApplicationExpression.function.type.get_application_type", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.get_application_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "@", "property", "\n", "def", "type", "(", "self", ")", ":", "\n", "# This gets called when the tree is being built by ``LogicParser.parse``. So, we do not", "\n", "# have access to the type signatures yet. Thus, we need to look at the name of the function", "\n", "# to return the type.", "\n", "        ", "if", "not", "str", "(", "self", ".", "function", ")", "in", "self", ".", "_variables_with_placeholders", ":", "\n", "            ", "return", "super", "(", "DynamicTypeApplicationExpression", ",", "self", ")", ".", "type", "\n", "", "if", "self", ".", "function", ".", "type", "==", "ANY_TYPE", ":", "\n", "            ", "return", "ANY_TYPE", "\n", "", "argument_type", "=", "self", ".", "argument", ".", "type", "\n", "return", "self", ".", "function", ".", "type", ".", "get_application_type", "(", "argument_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression._set_type": [[438, 462], ["super()._set_type", "isinstance", "type_declaration.DynamicTypeApplicationExpression.argument.argument._set_type", "type_declaration.DynamicTypeApplicationExpression.argument._set_type", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression._set_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression._set_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression._set_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "_set_type", "(", "self", ",", "other_type", ":", "Type", "=", "ANY_TYPE", ",", "signature", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        We override this method to do just one thing on top of ``ApplicationExpression._set_type``.\n        In lambda expressions of the form /x F(x), where the function is F and the argument is x,\n        we can use the type of F to infer the type of x. That is, if F is of type <a, b>, we can\n        resolve the type of x against a. We do this as the additional step after setting the type\n        of F(x).\n\n        So why does NLTK not already do this? NLTK assumes all variables (x) are of type entity\n        (e).  So it does not have to resolve the type of x anymore. However, this would cause type\n        inference failures in our case since x can bind to rows, numbers or cells, each of which\n        has a different type. To deal with this issue, we made X of type ANY_TYPE. Also, LambdaDCS\n        (and some other languages) contain a var function that indicate the usage of variables\n        within lambda functions. We map var to V, and made it of type <#1, #1>. We cannot leave X\n        as ANY_TYPE because that would propagate up the tree. We need to set its type when we have\n        the information about F. Hence this method. Note that the language may or may not contain\n        the var function. We deal with both cases below.\n        \"\"\"", "\n", "super", "(", "DynamicTypeApplicationExpression", ",", "self", ")", ".", "_set_type", "(", "other_type", ",", "signature", ")", "\n", "# TODO(pradeep): Assuming the mapping of \"var\" function is \"V\". Do something better.", "\n", "if", "isinstance", "(", "self", ".", "argument", ",", "ApplicationExpression", ")", "and", "str", "(", "self", ".", "argument", ".", "function", ")", "==", "\"V\"", ":", "\n", "            ", "self", ".", "argument", ".", "argument", ".", "_set_type", "(", "self", ".", "function", ".", "type", ".", "first", ")", "\n", "", "if", "str", "(", "self", ".", "argument", ")", "==", "\"X\"", "and", "str", "(", "self", ".", "function", ")", "!=", "\"V\"", ":", "\n", "            ", "self", ".", "argument", ".", "_set_type", "(", "self", ".", "function", ".", "type", ".", "first", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeLogicParser.__init__": [[478, 488], ["nltk.sem.logic.LogicParser.__init__", "type_signatures.items", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "type_check", ":", "bool", "=", "True", ",", "\n", "constant_type_prefixes", ":", "Dict", "[", "str", ",", "BasicType", "]", "=", "None", ",", "\n", "type_signatures", ":", "Dict", "[", "str", ",", "Type", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "DynamicTypeLogicParser", ",", "self", ")", ".", "__init__", "(", "type_check", ")", "\n", "self", ".", "_constant_type_prefixes", "=", "constant_type_prefixes", "or", "{", "}", "\n", "self", ".", "_variables_with_placeholders", "=", "{", "\n", "name", "for", "name", ",", "type_", "in", "type_signatures", ".", "items", "(", ")", "if", "isinstance", "(", "type_", ",", "PlaceholderType", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeLogicParser.make_ApplicationExpression": [[490, 494], ["type_declaration.DynamicTypeApplicationExpression"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "make_ApplicationExpression", "(", "self", ",", "function", ",", "argument", ")", ":", "\n", "        ", "return", "DynamicTypeApplicationExpression", "(", "\n", "function", ",", "argument", ",", "self", ".", "_variables_with_placeholders", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeLogicParser.make_VariableExpression": [[496, 507], ["super().make_VariableExpression", "name.split", "type_declaration.TypedConstantExpression", "RuntimeError", "nltk.sem.logic.Variable"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeLogicParser.make_VariableExpression"], ["", "@", "overrides", "\n", "def", "make_VariableExpression", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "\":\"", "in", "name", ":", "\n", "            ", "prefix", "=", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "if", "prefix", "in", "self", ".", "_constant_type_prefixes", ":", "\n", "                ", "return", "TypedConstantExpression", "(", "Variable", "(", "name", ")", ",", "self", ".", "_constant_type_prefixes", "[", "prefix", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "f\"Unknown prefix: {prefix}. Did you forget to pass it to the constructor?\"", "\n", ")", "\n", "", "", "return", "super", "(", "DynamicTypeLogicParser", ",", "self", ")", ".", "make_VariableExpression", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeLogicParser.__eq__": [[508, 512], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NameMapper.__init__": [[535, 545], ["alias_prefix.upper", "alias_prefix.isalpha", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "language_has_lambda", ":", "bool", "=", "False", ",", "alias_prefix", ":", "str", "=", "\"F\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "name_mapping", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "if", "language_has_lambda", ":", "\n", "            ", "self", ".", "name_mapping", "[", "\"lambda\"", "]", "=", "\"\\\\\"", "\n", "", "self", ".", "type_signatures", ":", "Dict", "[", "str", ",", "Type", "]", "=", "{", "}", "\n", "assert", "len", "(", "alias_prefix", ")", "==", "1", "and", "alias_prefix", ".", "isalpha", "(", ")", ",", "(", "\n", "f\"Invalid alias prefix: {alias_prefix}\"", "\"Needs to be a single upper case character.\"", "\n", ")", "\n", "self", ".", "_alias_prefix", "=", "alias_prefix", ".", "upper", "(", ")", "\n", "self", ".", "_name_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NameMapper.map_name_with_signature": [[546, 560], ["RuntimeError"], "methods", ["None"], ["", "def", "map_name_with_signature", "(", "self", ",", "name", ":", "str", ",", "signature", ":", "Type", ",", "alias", ":", "str", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "name", "in", "self", ".", "name_mapping", ":", "\n", "            ", "alias", "=", "self", ".", "name_mapping", "[", "name", "]", "\n", "old_signature", "=", "self", ".", "type_signatures", "[", "alias", "]", "\n", "if", "old_signature", "!=", "signature", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "f\"{name} already added with signature {old_signature}. \"", "\n", "f\"Cannot add it again with {signature}!\"", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "alias", "=", "alias", "or", "f\"{self._alias_prefix}{self._name_counter}\"", "\n", "self", ".", "_name_counter", "+=", "1", "\n", "self", ".", "name_mapping", "[", "name", "]", "=", "alias", "\n", "self", ".", "type_signatures", "[", "alias", "]", "=", "signature", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NameMapper.get_alias": [[561, 565], ["RuntimeError"], "methods", ["None"], ["", "", "def", "get_alias", "(", "self", ",", "name", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "name", "not", "in", "self", ".", "name_mapping", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"Unmapped name: {name}\"", ")", "\n", "", "return", "self", ".", "name_mapping", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NameMapper.get_signature": [[566, 569], ["type_declaration.NameMapper.get_alias"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.NameMapper.get_alias"], ["", "def", "get_signature", "(", "self", ",", "name", ":", "str", ")", "->", "Type", ":", "\n", "        ", "alias", "=", "self", ".", "get_alias", "(", "name", ")", "\n", "return", "self", ".", "type_signatures", "[", "alias", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.substitute_any_type": [[571, 586], ["isinstance", "type_.substitute_any_type", "list"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.substitute_any_type"], ["", "", "def", "substitute_any_type", "(", "type_", ":", "Type", ",", "basic_types", ":", "Set", "[", "BasicType", "]", ")", "->", "List", "[", "Type", "]", ":", "\n", "    ", "\"\"\"\n    Takes a type and a set of basic types, and substitutes all instances of ANY_TYPE with all\n    possible basic types and returns a list with all possible combinations.  Note that this\n    substitution is unconstrained.  That is, If you have a type with placeholders, <#1,#1> for\n    example, this may substitute the placeholders with different basic types. In that case, you'd\n    want to use ``_substitute_placeholder_type`` instead.\n    \"\"\"", "\n", "if", "type_", "==", "ANY_TYPE", ":", "\n", "        ", "return", "list", "(", "basic_types", ")", "\n", "", "if", "isinstance", "(", "type_", ",", "BasicType", ")", ":", "\n", "        ", "return", "[", "type_", "]", "\n", "# If we've made it this far, we have a ComplexType, and we can just call", "\n", "# `type_.substitute_any_type()`.", "\n", "", "return", "type_", ".", "substitute_any_type", "(", "basic_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._make_production_string": [[588, 590], ["None"], "function", ["None"], ["", "def", "_make_production_string", "(", "source", ":", "Type", ",", "target", ":", "Union", "[", "List", "[", "Type", "]", ",", "Type", "]", ")", "->", "str", ":", "\n", "    ", "return", "f\"{source} -> {target}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._get_complex_type_production": [[592, 639], ["complex_type.return_type", "isinstance", "complex_type.argument_types", "list", "isinstance", "itertools.product", "list", "argument_types_matched.append", "argument_types_matched.append", "complex_type_productions.append", "type_declaration._make_production_string", "list"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.HigherOrderType.return_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.HigherOrderType.argument_types", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._make_production_string"], ["", "def", "_get_complex_type_production", "(", "\n", "complex_type", ":", "ComplexType", ",", "multi_match_mapping", ":", "Dict", "[", "Type", ",", "List", "[", "Type", "]", "]", "\n", ")", "->", "List", "[", "Tuple", "[", "Type", ",", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    Takes a complex type (without any placeholders), gets its return values, and returns productions\n    (perhaps each with multiple arguments) that produce the return values.  This method also takes\n    care of ``MultiMatchNamedBasicTypes``. If one of the arguments or the return types is a multi\n    match type, it gets all the substitutions of those types from ``multi_match_mapping`` and forms\n    a list with all possible combinations of substitutions. If the complex type passed to this method\n    has no ``MultiMatchNamedBasicTypes``, the returned list will contain a single tuple.  For\n    example, if the complex is type ``<a,<<b,c>,d>>``, and ``a`` is a multi match type that matches\n    ``e`` and ``f``, this gives the following list of tuples: ``[('d', 'd -> [<a,<<b,c>,d>, e,\n    <b,c>]), ('d', 'd -> [<a,<<b,c>,d>, f, <b,c>])]`` Note that we assume there will be no\n    productions from the multi match type, and the list above does not contain ``('d', 'd ->\n    [<a,<<b,c>,d>, a, <b,c>>]')``.\n    \"\"\"", "\n", "return_type", "=", "complex_type", ".", "return_type", "(", ")", "\n", "if", "isinstance", "(", "return_type", ",", "MultiMatchNamedBasicType", ")", ":", "\n", "        ", "return_types_matched", "=", "list", "(", "\n", "multi_match_mapping", "[", "return_type", "]", "\n", "if", "return_type", "in", "multi_match_mapping", "\n", "else", "return_type", ".", "types_to_match", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return_types_matched", "=", "[", "return_type", "]", "\n", "", "arguments", "=", "complex_type", ".", "argument_types", "(", ")", "\n", "argument_types_matched", "=", "[", "]", "\n", "for", "argument_type", "in", "arguments", ":", "\n", "        ", "if", "isinstance", "(", "argument_type", ",", "MultiMatchNamedBasicType", ")", ":", "\n", "            ", "matched_types", "=", "list", "(", "\n", "multi_match_mapping", "[", "argument_type", "]", "\n", "if", "argument_type", "in", "multi_match_mapping", "\n", "else", "argument_type", ".", "types_to_match", "\n", ")", "\n", "argument_types_matched", ".", "append", "(", "matched_types", ")", "\n", "", "else", ":", "\n", "            ", "argument_types_matched", ".", "append", "(", "[", "argument_type", "]", ")", "\n", "", "", "complex_type_productions", ":", "List", "[", "Tuple", "[", "Type", ",", "str", "]", "]", "=", "[", "]", "\n", "for", "matched_return_type", "in", "return_types_matched", ":", "\n", "        ", "for", "matched_arguments", "in", "itertools", ".", "product", "(", "*", "argument_types_matched", ")", ":", "\n", "            ", "complex_type_productions", ".", "append", "(", "\n", "(", "\n", "matched_return_type", ",", "\n", "_make_production_string", "(", "return_type", ",", "[", "complex_type", "]", "+", "list", "(", "matched_arguments", ")", ")", ",", "\n", ")", "\n", ")", "\n", "", "", "return", "complex_type_productions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.get_valid_actions": [[641, 741], ["collections.defaultdict", "set", "name_mapping.items", "range", "valid_actions[].add", "type_declaration.substitute_any_type", "type_declaration.substitute_any_type", "chr", "sorted", "type_declaration._make_production_string", "valid_actions[].add", "isinstance", "set.add", "type_declaration._get_complex_type_production", "valid_actions.items", "type_declaration._make_production_string", "valid_actions[].add", "ord", "type_declaration.ComplexType", "type_declaration._make_production_string", "valid_actions[].add", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.substitute_any_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.substitute_any_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._make_production_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._get_complex_type_production", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._make_production_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration._make_production_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "get_valid_actions", "(", "\n", "name_mapping", ":", "Dict", "[", "str", ",", "str", "]", ",", "\n", "type_signatures", ":", "Dict", "[", "str", ",", "Type", "]", ",", "\n", "basic_types", ":", "Set", "[", "Type", "]", ",", "\n", "multi_match_mapping", ":", "Dict", "[", "Type", ",", "List", "[", "Type", "]", "]", "=", "None", ",", "\n", "valid_starting_types", ":", "Set", "[", "Type", "]", "=", "None", ",", "\n", "num_nested_lambdas", ":", "int", "=", "0", ",", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    Generates all the valid actions starting from each non-terminal. For terminals of a specific\n    type, we simply add a production from the type to the terminal. For all terminal `functions`,\n    we additionally add a rule that allows their return type to be generated from an application of\n    the function.  For example, the function ``<e,<r,<d,r>>>``, which takes three arguments and\n    returns an ``r`` would generate a the production rule ``r -> [<e,<r,<d,r>>>, e, r, d]``.\n\n    For functions that do not contain ANY_TYPE or placeholder types, this is straight-forward.\n    When there are ANY_TYPES or placeholders, we substitute the ANY_TYPE with all possible basic\n    types, and then produce a similar rule.  For example, the identity function, with type\n    ``<#1,#1>`` and basic types ``e`` and ``r``,  would produce the rules ``e -> [<#1,#1>, e]`` and\n    ``r -> [<#1,#1>, r]``.\n\n    We additionally add a valid action from the start symbol to all ``valid_starting_types``.\n\n    Parameters\n    ----------\n    name_mapping : ``Dict[str, str]``\n        The mapping of names that appear in your logical form languages to their aliases for NLTK.\n        If you are getting all valid actions for a type declaration, this can be the\n        ``COMMON_NAME_MAPPING``.\n    type_signatures : ``Dict[str, Type]``\n        The mapping from name aliases to their types. If you are getting all valid actions for a\n        type declaration, this can be the ``COMMON_TYPE_SIGNATURE``.\n    basic_types : ``Set[Type]``\n        Set of all basic types in the type declaration.\n    multi_match_mapping : ``Dict[Type, List[Type]]`` (optional)\n        A mapping from `MultiMatchNamedBasicTypes` to the types they can match. This may be\n        different from the type's ``types_to_match`` field based on the context. While building action\n        sequences that lead to complex types with ``MultiMatchNamedBasicTypes``, if a type does not\n        occur in this mapping, the default set of ``types_to_match`` for that type will be used.\n    valid_starting_types : ``Set[Type]``, optional\n        These are the valid starting types for your grammar; e.g., what types are we allowed to\n        parse expressions into?  We will add a \"START -> TYPE\" rule for each of these types.  If\n        this is ``None``, we default to using ``basic_types``.\n    num_nested_lambdas : ``int`` (optional)\n        Does the language used permit lambda expressions?  And if so, how many nested lambdas do we\n        need to worry about?  We'll add rules like \"<r,d> -> ['lambda x', d]\" for all complex\n        types, where the variable is determined by the number of nestings.  We currently only\n        permit up to three levels of nesting, just for ease of implementation.\n    \"\"\"", "\n", "valid_actions", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "\n", "valid_starting_types", "=", "valid_starting_types", "or", "basic_types", "\n", "for", "type_", "in", "valid_starting_types", ":", "\n", "        ", "valid_actions", "[", "str", "(", "START_TYPE", ")", "]", ".", "add", "(", "_make_production_string", "(", "START_TYPE", ",", "type_", ")", ")", "\n", "\n", "", "complex_types", "=", "set", "(", ")", "\n", "for", "name", ",", "alias", "in", "name_mapping", ".", "items", "(", ")", ":", "\n", "# Lambda functions and variables associated with them get produced in specific contexts. So", "\n", "# we do not add them to ``valid_actions`` here, and let ``GrammarState`` deal with it.", "\n", "# ``var`` is a special function that some languages (like LambdaDCS) use within lambda", "\n", "# functions to indicate the use of a variable (eg.: ``(lambda x (fb:row.row.year (var x)))``)", "\n", "# We do not have to produce this function outside the scope of lambda. Even within lambdas,", "\n", "# it is a lot easier to not do it, and let the action sequence to logical form transformation", "\n", "# logic add it to the output logical forms instead.", "\n", "        ", "if", "name", "in", "[", "\"lambda\"", ",", "\"var\"", ",", "\"x\"", ",", "\"y\"", ",", "\"z\"", "]", ":", "\n", "            ", "continue", "\n", "", "name_type", "=", "type_signatures", "[", "alias", "]", "\n", "# Type to terminal productions.", "\n", "for", "substituted_type", "in", "substitute_any_type", "(", "name_type", ",", "basic_types", ")", ":", "\n", "            ", "valid_actions", "[", "str", "(", "substituted_type", ")", "]", ".", "add", "(", "\n", "_make_production_string", "(", "substituted_type", ",", "name", ")", "\n", ")", "\n", "# Keeping track of complex types.", "\n", "", "if", "isinstance", "(", "name_type", ",", "ComplexType", ")", "and", "name_type", "!=", "ANY_TYPE", ":", "\n", "            ", "complex_types", ".", "add", "(", "name_type", ")", "\n", "\n", "", "", "for", "complex_type", "in", "complex_types", ":", "\n", "        ", "for", "substituted_type", "in", "substitute_any_type", "(", "complex_type", ",", "basic_types", ")", ":", "\n", "            ", "for", "head", ",", "production", "in", "_get_complex_type_production", "(", "\n", "substituted_type", ",", "multi_match_mapping", "or", "{", "}", "\n", ")", ":", "\n", "                ", "valid_actions", "[", "str", "(", "head", ")", "]", ".", "add", "(", "production", ")", "\n", "\n", "# We can produce complex types with a lambda expression, though we'll leave out", "\n", "# placeholder types for now.", "\n", "", "", "", "for", "i", "in", "range", "(", "num_nested_lambdas", ")", ":", "\n", "        ", "lambda_var", "=", "chr", "(", "ord", "(", "\"x\"", ")", "+", "i", ")", "\n", "# We'll only allow lambdas to be functions that take and return basic types as their", "\n", "# arguments, for now.  Also, we're doing this for all possible complex types where", "\n", "# the first and second types are basic types. So we may be overgenerating a bit.", "\n", "for", "first_type", "in", "basic_types", ":", "\n", "            ", "for", "second_type", "in", "basic_types", ":", "\n", "                ", "key", "=", "ComplexType", "(", "first_type", ",", "second_type", ")", "\n", "production_string", "=", "_make_production_string", "(", "\n", "key", ",", "[", "\"lambda \"", "+", "lambda_var", ",", "second_type", "]", "\n", ")", "\n", "valid_actions", "[", "str", "(", "key", ")", "]", ".", "add", "(", "production_string", ")", "\n", "\n", "", "", "", "valid_action_strings", "=", "{", "key", ":", "sorted", "(", "value", ")", "for", "key", ",", "value", "in", "valid_actions", ".", "items", "(", ")", "}", "\n", "return", "valid_action_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.is_nonterminal": [[752, 770], ["production.startswith", "production[].islower", "len"], "function", ["None"], ["def", "is_nonterminal", "(", "production", ":", "str", ")", "->", "bool", ":", "\n", "# TODO(pradeep): This is pretty specific to the assumptions made in converting types to", "\n", "# strings (e.g., that we're only using the first letter for types, lowercased).", "\n", "# TODO(pradeep): Also we simply check the surface forms here, and this works for", "\n", "# wikitables and nlvr. We should ideally let the individual type declarations define their own", "\n", "# variants of this method.", "\n", "    ", "if", "production", "in", "[", "\"<=\"", ",", "\"<\"", "]", ":", "\n", "# Some grammars (including the wikitables grammar) have \"less than\" and \"less than or", "\n", "# equal to\" functions that are terminals.  We don't want to treat those like our", "\n", "# \"<t,d>\" types.", "\n", "        ", "return", "False", "\n", "", "if", "production", "[", "0", "]", "==", "\"<\"", ":", "\n", "        ", "return", "True", "\n", "", "if", "production", ".", "startswith", "(", "\"fb:\"", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "len", "(", "production", ")", ">", "1", "or", "production", "in", "LAMBDA_VARIABLES", ":", "\n", "        ", "return", "False", "\n", "", "return", "production", "[", "0", "]", ".", "islower", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration_test.TestTypeDeclaration.test_basic_types_conflict_on_names": [[18, 22], ["allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType.resolve"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve"], ["    ", "def", "test_basic_types_conflict_on_names", "(", "self", ")", ":", "\n", "        ", "type_a", "=", "NamedBasicType", "(", "\"A\"", ")", "\n", "type_b", "=", "NamedBasicType", "(", "\"B\"", ")", "\n", "assert", "type_a", ".", "resolve", "(", "type_b", ")", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration_test.TestTypeDeclaration.test_unary_ops_resolve_correctly": [[23, 43], ["allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve"], ["", "def", "test_unary_ops_resolve_correctly", "(", "self", ")", ":", "\n", "        ", "unary_type", "=", "UnaryOpType", "(", ")", "\n", "\n", "# Resolution should fail against a basic type", "\n", "assert", "unary_type", ".", "resolve", "(", "ROW_TYPE", ")", "is", "None", "\n", "\n", "# Resolution should fail against a complex type where the argument and return types are not same", "\n", "assert", "unary_type", ".", "resolve", "(", "ComplexType", "(", "CELL_TYPE", ",", "ROW_TYPE", ")", ")", "is", "None", "\n", "\n", "# Resolution should resolve ANY_TYPE given the other type", "\n", "resolution", "=", "unary_type", ".", "resolve", "(", "ComplexType", "(", "ANY_TYPE", ",", "ROW_TYPE", ")", ")", "\n", "assert", "resolution", "==", "UnaryOpType", "(", "ROW_TYPE", ")", "\n", "resolution", "=", "unary_type", ".", "resolve", "(", "ComplexType", "(", "CELL_TYPE", ",", "ANY_TYPE", ")", ")", "\n", "assert", "resolution", "==", "UnaryOpType", "(", "CELL_TYPE", ")", "\n", "\n", "reverse_type", "=", "ComplexType", "(", "\n", "ComplexType", "(", "CELL_TYPE", ",", "ROW_TYPE", ")", ",", "ComplexType", "(", "CELL_TYPE", ",", "ROW_TYPE", ")", "\n", ")", "\n", "resolution", "=", "unary_type", ".", "resolve", "(", "reverse_type", ")", "\n", "assert", "resolution", "==", "UnaryOpType", "(", "ComplexType", "(", "CELL_TYPE", ",", "ROW_TYPE", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration_test.TestTypeDeclaration.test_binary_ops_resolve_correctly": [[44, 70], ["allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType.resolve", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.BinaryOpType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.BinaryOpType.resolve"], ["", "def", "test_binary_ops_resolve_correctly", "(", "self", ")", ":", "\n", "        ", "binary_type", "=", "BinaryOpType", "(", ")", "\n", "\n", "# Resolution must fail against a basic type and a complex type that returns a basic type", "\n", "assert", "binary_type", ".", "resolve", "(", "CELL_TYPE", ")", "is", "None", "\n", "assert", "binary_type", ".", "resolve", "(", "ComplexType", "(", "CELL_TYPE", ",", "ROW_TYPE", ")", ")", "is", "None", "\n", "\n", "# Resolution must fail against incompatible types", "\n", "complex_type", "=", "ComplexType", "(", "ANY_TYPE", ",", "ComplexType", "(", "CELL_TYPE", ",", "ROW_TYPE", ")", ")", "\n", "assert", "binary_type", ".", "resolve", "(", "complex_type", ")", "is", "None", "\n", "\n", "complex_type", "=", "ComplexType", "(", "ROW_TYPE", ",", "ComplexType", "(", "CELL_TYPE", ",", "ANY_TYPE", ")", ")", "\n", "assert", "binary_type", ".", "resolve", "(", "complex_type", ")", "is", "None", "\n", "\n", "complex_type", "=", "ComplexType", "(", "ROW_TYPE", ",", "ComplexType", "(", "ANY_TYPE", ",", "CELL_TYPE", ")", ")", "\n", "assert", "binary_type", ".", "resolve", "(", "complex_type", ")", "is", "None", "\n", "\n", "# Resolution must resolve any types appropriately", "\n", "complex_type", "=", "ComplexType", "(", "ROW_TYPE", ",", "ComplexType", "(", "ANY_TYPE", ",", "ROW_TYPE", ")", ")", "\n", "assert", "binary_type", ".", "resolve", "(", "complex_type", ")", "==", "BinaryOpType", "(", "ROW_TYPE", ")", "\n", "\n", "complex_type", "=", "ComplexType", "(", "ROW_TYPE", ",", "ComplexType", "(", "ANY_TYPE", ",", "ANY_TYPE", ")", ")", "\n", "assert", "binary_type", ".", "resolve", "(", "complex_type", ")", "==", "BinaryOpType", "(", "ROW_TYPE", ")", "\n", "\n", "complex_type", "=", "ComplexType", "(", "ANY_TYPE", ",", "ComplexType", "(", "ROW_TYPE", ",", "ANY_TYPE", ")", ")", "\n", "assert", "binary_type", ".", "resolve", "(", "complex_type", ")", "==", "BinaryOpType", "(", "ROW_TYPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration_test.TestTypeDeclaration.test_get_valid_actions": [[71, 86], ["allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.get_valid_actions", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "len", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions", "(", "self", ")", ":", "\n", "        ", "type_r", "=", "NamedBasicType", "(", "\"R\"", ")", "\n", "type_d", "=", "NamedBasicType", "(", "\"D\"", ")", "\n", "type_e", "=", "NamedBasicType", "(", "\"E\"", ")", "\n", "name_mapping", "=", "{", "\"sample_function\"", ":", "\"F\"", "}", "\n", "# <e,<r,<d,r>>>", "\n", "type_signatures", "=", "{", "\n", "\"F\"", ":", "ComplexType", "(", "type_e", ",", "ComplexType", "(", "type_r", ",", "ComplexType", "(", "type_d", ",", "type_r", ")", ")", ")", "\n", "}", "\n", "basic_types", "=", "{", "type_r", ",", "type_d", ",", "type_e", "}", "\n", "valid_actions", "=", "types", ".", "get_valid_actions", "(", "name_mapping", ",", "type_signatures", ",", "basic_types", ")", "\n", "assert", "len", "(", "valid_actions", ")", "==", "3", "\n", "assert", "valid_actions", "[", "\"<e,<r,<d,r>>>\"", "]", "==", "[", "\"<e,<r,<d,r>>> -> sample_function\"", "]", "\n", "assert", "valid_actions", "[", "\"r\"", "]", "==", "[", "\"r -> [<e,<r,<d,r>>>, e, r, d]\"", "]", "\n", "assert", "valid_actions", "[", "\"@start@\"", "]", "==", "[", "\"@start@ -> d\"", ",", "\"@start@ -> e\"", ",", "\"@start@ -> r\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration_test.TestTypeDeclaration.test_get_valid_actions_with_placeholder_type": [[87, 102], ["allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.get_valid_actions", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.UnaryOpType", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions_with_placeholder_type", "(", "self", ")", ":", "\n", "        ", "type_r", "=", "NamedBasicType", "(", "\"R\"", ")", "\n", "type_d", "=", "NamedBasicType", "(", "\"D\"", ")", "\n", "type_e", "=", "NamedBasicType", "(", "\"E\"", ")", "\n", "name_mapping", "=", "{", "\"sample_function\"", ":", "\"F\"", "}", "\n", "# <#1,#1>", "\n", "type_signatures", "=", "{", "\"F\"", ":", "UnaryOpType", "(", ")", "}", "\n", "basic_types", "=", "{", "type_r", ",", "type_d", ",", "type_e", "}", "\n", "valid_actions", "=", "types", ".", "get_valid_actions", "(", "name_mapping", ",", "type_signatures", ",", "basic_types", ")", "\n", "assert", "len", "(", "valid_actions", ")", "==", "5", "\n", "assert", "valid_actions", "[", "\"<#1,#1>\"", "]", "==", "[", "\"<#1,#1> -> sample_function\"", "]", "\n", "assert", "valid_actions", "[", "\"e\"", "]", "==", "[", "\"e -> [<#1,#1>, e]\"", "]", "\n", "assert", "valid_actions", "[", "\"r\"", "]", "==", "[", "\"r -> [<#1,#1>, r]\"", "]", "\n", "assert", "valid_actions", "[", "\"d\"", "]", "==", "[", "\"d -> [<#1,#1>, d]\"", "]", "\n", "assert", "valid_actions", "[", "\"@start@\"", "]", "==", "[", "\"@start@ -> d\"", ",", "\"@start@ -> e\"", ",", "\"@start@ -> r\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration_test.TestTypeDeclaration.test_get_valid_actions_with_any_type": [[103, 122], ["allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.NamedBasicType", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.get_valid_actions", "allennlp_semparse.nltk_languages.type_declarations.type_declaration.ComplexType", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions_with_any_type", "(", "self", ")", ":", "\n", "        ", "type_r", "=", "NamedBasicType", "(", "\"R\"", ")", "\n", "type_d", "=", "NamedBasicType", "(", "\"D\"", ")", "\n", "type_e", "=", "NamedBasicType", "(", "\"E\"", ")", "\n", "name_mapping", "=", "{", "\"sample_function\"", ":", "\"F\"", "}", "\n", "# The purpose of this test is to ensure that ANY_TYPE gets substituted by every possible basic type,", "\n", "# to simulate an intermediate step while getting actions for a placeholder type.", "\n", "# I do not foresee defining a function type with ANY_TYPE. We should just use a ``PlaceholderType``", "\n", "# instead.", "\n", "# <?,r>", "\n", "type_signatures", "=", "{", "\"F\"", ":", "ComplexType", "(", "ANY_TYPE", ",", "type_r", ")", "}", "\n", "basic_types", "=", "{", "type_r", ",", "type_d", ",", "type_e", "}", "\n", "valid_actions", "=", "types", ".", "get_valid_actions", "(", "name_mapping", ",", "type_signatures", ",", "basic_types", ")", "\n", "assert", "len", "(", "valid_actions", ")", "==", "5", "\n", "assert", "valid_actions", "[", "\"<d,r>\"", "]", "==", "[", "\"<d,r> -> sample_function\"", "]", "\n", "assert", "valid_actions", "[", "\"<e,r>\"", "]", "==", "[", "\"<e,r> -> sample_function\"", "]", "\n", "assert", "valid_actions", "[", "\"<r,r>\"", "]", "==", "[", "\"<r,r> -> sample_function\"", "]", "\n", "assert", "valid_actions", "[", "\"r\"", "]", "==", "[", "\"r -> [<d,r>, d]\"", ",", "\"r -> [<e,r>, e]\"", ",", "\"r -> [<r,r>, r]\"", "]", "\n", "assert", "valid_actions", "[", "\"@start@\"", "]", "==", "[", "\"@start@ -> d\"", ",", "\"@start@ -> e\"", ",", "\"@start@ -> r\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.__init__": [[20, 25], ["allennlp.common.file_utils.cached_path", "sqlite3.connect", "sql_executor.SqlExecutor._connection.cursor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "database_file", ":", "str", ")", "->", "None", ":", "\n", "# Initialize a cursor to our sqlite database, so we can execute SQL queries for denotation accuracy.", "\n", "        ", "self", ".", "_database_file", "=", "cached_path", "(", "database_file", ")", "\n", "self", ".", "_connection", "=", "sqlite3", ".", "connect", "(", "self", ".", "_database_file", ")", "\n", "self", ".", "_cursor", "=", "self", ".", "_connection", ".", "cursor", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.evaluate_sql_query": [[26, 51], ["MULTIPROCESSING_LOGGER.setLevel", "multiprocessing.Process", "multiprocessing.Process.start", "multiprocessing.Process.join", "multiprocessing.Process.is_alive", "logger.warning", "multiprocessing.Process.terminate", "multiprocessing.Process.join"], "methods", ["None"], ["", "def", "evaluate_sql_query", "(", "self", ",", "predicted_sql_query", ":", "str", ",", "sql_query_labels", ":", "List", "[", "str", "]", ")", "->", "int", ":", "\n", "# We set the logging level for the subprocesses to warning, otherwise, it will", "\n", "# log every time a process starts and stops.", "\n", "        ", "MULTIPROCESSING_LOGGER", ".", "setLevel", "(", "logging", ".", "WARNING", ")", "\n", "\n", "# Since the query might hang, we run in another process and kill it if it", "\n", "# takes too long.", "\n", "process", "=", "Process", "(", "\n", "target", "=", "self", ".", "_evaluate_sql_query_subprocess", ",", "args", "=", "(", "predicted_sql_query", ",", "sql_query_labels", ")", "\n", ")", "\n", "process", ".", "start", "(", ")", "\n", "\n", "# If the query has not finished in 3 seconds then we will proceed.", "\n", "process", ".", "join", "(", "3", ")", "\n", "denotation_correct", "=", "process", ".", "exitcode", "# type: ignore", "\n", "\n", "if", "process", ".", "is_alive", "(", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Evaluating query took over 3 seconds, skipping query\"", ")", "\n", "process", ".", "terminate", "(", ")", "\n", "process", ".", "join", "(", ")", "\n", "\n", "", "if", "denotation_correct", "is", "None", ":", "\n", "            ", "denotation_correct", "=", "0", "\n", "\n", "", "return", "denotation_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor._evaluate_sql_query_subprocess": [[52, 82], ["sql_executor.SqlExecutor.postprocess_query_sqlite", "exit", "sql_executor.SqlExecutor._cursor.execute", "sql_executor.SqlExecutor._cursor.fetchall", "sql_executor.SqlExecutor.postprocess_query_sqlite", "logger.warning", "exit", "sql_executor.SqlExecutor._cursor.execute", "sql_executor.SqlExecutor._cursor.fetchall", "exit", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.postprocess_query_sqlite", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.postprocess_query_sqlite", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "_evaluate_sql_query_subprocess", "(", "\n", "self", ",", "predicted_query", ":", "str", ",", "sql_query_labels", ":", "List", "[", "str", "]", "\n", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        We evaluate here whether the predicted query and the query label evaluate to the\n        exact same table. This method is only called by the subprocess, so we just exit with\n        1 if it is correct and 0 otherwise.\n        \"\"\"", "\n", "\n", "postprocessed_predicted_query", "=", "self", ".", "postprocess_query_sqlite", "(", "predicted_query", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "_cursor", ".", "execute", "(", "postprocessed_predicted_query", ")", "\n", "predicted_rows", "=", "self", ".", "_cursor", ".", "fetchall", "(", ")", "\n", "", "except", "sqlite3", ".", "Error", "as", "error", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Error executing predicted: {error}\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "# If predicted table matches any of the reference tables then it is counted as correct.", "\n", "", "target_rows", "=", "None", "\n", "for", "sql_query_label", "in", "sql_query_labels", ":", "\n", "            ", "postprocessed_sql_query_label", "=", "self", ".", "postprocess_query_sqlite", "(", "sql_query_label", ")", "\n", "try", ":", "\n", "                ", "self", ".", "_cursor", ".", "execute", "(", "postprocessed_sql_query_label", ")", "\n", "target_rows", "=", "self", ".", "_cursor", ".", "fetchall", "(", ")", "\n", "", "except", "sqlite3", ".", "Error", "as", "error", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Error executing predicted: {error}\"", ")", "\n", "", "if", "predicted_rows", "==", "target_rows", ":", "\n", "                ", "exit", "(", "1", ")", "\n", "", "", "exit", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.postprocess_query_sqlite": [[83, 91], ["query.strip.strip.strip", "query.strip.strip.startswith", "query.strip.strip.rfind"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "postprocess_query_sqlite", "(", "query", ":", "str", ")", ":", "\n", "# The dialect of SQL that SQLite takes is not exactly the same as the labeled data.", "\n", "# We strip off the parentheses that surround the entire query here.", "\n", "        ", "query", "=", "query", ".", "strip", "(", ")", "\n", "if", "query", ".", "startswith", "(", "\"(\"", ")", ":", "\n", "            ", "return", "query", "[", "1", ":", "query", ".", "rfind", "(", "\")\"", ")", "]", "+", "\";\"", "\n", "", "return", "query", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor_test.TestSqlExecutor.setup_method": [[7, 10], ["super().setup_method"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "_database_file", "=", "\"https://allennlp.s3.amazonaws.com/datasets/atis/atis.db\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor_test.TestSqlExecutor.test_sql_accuracy_is_scored_correctly": [[11, 45], ["allennlp_semparse.parsimonious_languages.executors.SqlExecutor", "allennlp_semparse.parsimonious_languages.executors.SqlExecutor.postprocess_query_sqlite", "allennlp_semparse.parsimonious_languages.executors.SqlExecutor.postprocess_query_sqlite", "allennlp_semparse.parsimonious_languages.executors.SqlExecutor.evaluate_sql_query", "allennlp_semparse.parsimonious_languages.executors.SqlExecutor.evaluate_sql_query"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.postprocess_query_sqlite", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.postprocess_query_sqlite", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.evaluate_sql_query", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.evaluate_sql_query"], ["", "def", "test_sql_accuracy_is_scored_correctly", "(", "self", ")", ":", "\n", "        ", "sql_query_label", "=", "(", "\n", "\"( SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service \"", "\n", "\"WHERE airport_service . city_code IN ( \"", "\n", "\"SELECT city . city_code FROM city \"", "\n", "\"WHERE city.city_name = 'BOSTON' ) ) ;\"", "\n", ")", "\n", "\n", "executor", "=", "SqlExecutor", "(", "self", ".", "_database_file", ")", "\n", "postprocessed_sql_query_label", "=", "executor", ".", "postprocess_query_sqlite", "(", "sql_query_label", ")", "\n", "# If the predicted query and the label are the same, then we should get 1.", "\n", "assert", "(", "\n", "executor", ".", "evaluate_sql_query", "(", "\n", "postprocessed_sql_query_label", ",", "[", "postprocessed_sql_query_label", "]", "\n", ")", "\n", "==", "1", "\n", ")", "\n", "\n", "predicted_sql_query", "=", "(", "\n", "\"( SELECT airport_service . airport_code \"", "\n", "\"FROM airport_service \"", "\n", "\"WHERE airport_service . city_code IN ( \"", "\n", "\"SELECT city . city_code FROM city \"", "\n", "\"WHERE city.city_name = 'SEATTLE' ) ) ;\"", "\n", ")", "\n", "\n", "postprocessed_predicted_sql_query", "=", "executor", ".", "postprocess_query_sqlite", "(", "predicted_sql_query", ")", "\n", "# If the predicted query and the label are different we should get 0.", "\n", "assert", "(", "\n", "executor", ".", "evaluate_sql_query", "(", "\n", "postprocessed_predicted_sql_query", ",", "[", "postprocessed_sql_query_label", "]", "\n", ")", "\n", "==", "0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.template_text2sql.TemplateText2SqlDatasetReader.__init__": [[43, 54], ["allennlp.data.DatasetReader.__init__", "str", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["def", "__init__", "(", "\n", "self", ",", "\n", "use_all_sql", ":", "bool", "=", "False", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "cross_validation_split_to_exclude", ":", "int", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "_use_all_sql", "=", "use_all_sql", "\n", "self", ".", "_cross_validation_split_to_exclude", "=", "str", "(", "cross_validation_split_to_exclude", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.template_text2sql.TemplateText2SqlDatasetReader._read": [[55, 83], ["allennlp_semparse.common.sql.text2sql_utils.process_sql_data", "glob.glob", "open", "json.load", "os.path.basename", "allennlp.common.file_utils.cached_path", "template_text2sql.TemplateText2SqlDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        This dataset reader consumes the data from\n        https://github.com/jkkummerfeld/text2sql-data/tree/master/data\n        formatted using ``scripts/reformat_text2sql_data.py``.\n\n        Parameters\n        ----------\n        file_path : ``str``, required.\n            For this dataset reader, file_path can either be a path to a file `or` a\n            path to a directory containing json files. The reason for this is because\n            some of the text2sql datasets require cross validation, which means they are split\n            up into many small files, for which you only want to exclude one.\n        \"\"\"", "\n", "files", "=", "[", "\n", "p", "\n", "for", "p", "in", "glob", ".", "glob", "(", "file_path", ")", "\n", "if", "self", ".", "_cross_validation_split_to_exclude", "not", "in", "os", ".", "path", ".", "basename", "(", "p", ")", "\n", "]", "\n", "\n", "for", "path", "in", "files", ":", "\n", "            ", "with", "open", "(", "cached_path", "(", "path", ")", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "                ", "data", "=", "json", ".", "load", "(", "data_file", ")", "\n", "\n", "", "for", "sql_data", "in", "text2sql_utils", ".", "process_sql_data", "(", "data", ",", "self", ".", "_use_all_sql", ")", ":", "\n", "                ", "template", "=", "\" \"", ".", "join", "(", "sql_data", ".", "sql", ")", "\n", "yield", "self", ".", "text_to_instance", "(", "sql_data", ".", "text", ",", "sql_data", ".", "variable_tags", ",", "template", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.template_text2sql.TemplateText2SqlDatasetReader.text_to_instance": [[84, 102], ["allennlp.data.fields.TextField", "allennlp.data.instance.Instance", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.LabelField", "allennlp.data.tokenizers.Token"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "\n", "self", ",", "# type: ignore", "\n", "query", ":", "List", "[", "str", "]", ",", "\n", "slot_tags", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "sql_template", ":", "str", "=", "None", ",", "\n", ")", "->", "Instance", ":", "\n", "        ", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "tokens", "=", "TextField", "(", "[", "Token", "(", "t", ")", "for", "t", "in", "query", "]", ",", "self", ".", "_token_indexers", ")", "\n", "fields", "[", "\"tokens\"", "]", "=", "tokens", "\n", "\n", "if", "slot_tags", "is", "not", "None", "and", "sql_template", "is", "not", "None", ":", "\n", "            ", "slot_field", "=", "SequenceLabelField", "(", "slot_tags", ",", "tokens", ",", "label_namespace", "=", "\"slot_tags\"", ")", "\n", "template", "=", "LabelField", "(", "sql_template", ",", "label_namespace", "=", "\"template_labels\"", ")", "\n", "fields", "[", "\"slot_tags\"", "]", "=", "slot_field", "\n", "fields", "[", "\"template\"", "]", "=", "template", "\n", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.grammar_based_text2sql.GrammarBasedText2SqlDatasetReader.__init__": [[60, 101], ["allennlp.data.DatasetReader.__init__", "str", "allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "allennlp.common.checks.ConfigurationError", "allennlp.common.file_utils.cached_path", "sqlite3.connect", "sqlite3.connect.cursor", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["def", "__init__", "(", "\n", "self", ",", "\n", "schema_path", ":", "str", ",", "\n", "database_file", ":", "str", "=", "None", ",", "\n", "use_all_sql", ":", "bool", "=", "False", ",", "\n", "remove_unneeded_aliases", ":", "bool", "=", "True", ",", "\n", "use_prelinked_entities", ":", "bool", "=", "True", ",", "\n", "use_untyped_entities", ":", "bool", "=", "True", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "cross_validation_split_to_exclude", ":", "int", "=", "None", ",", "\n", "keep_if_unparseable", ":", "bool", "=", "True", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "_use_all_sql", "=", "use_all_sql", "\n", "self", ".", "_remove_unneeded_aliases", "=", "remove_unneeded_aliases", "\n", "self", ".", "_use_prelinked_entities", "=", "use_prelinked_entities", "\n", "self", ".", "_keep_if_unparsable", "=", "keep_if_unparseable", "\n", "\n", "if", "not", "self", ".", "_use_prelinked_entities", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\n", "\"The grammar based text2sql dataset reader \"", "\n", "\"currently requires the use of entity pre-linking.\"", "\n", ")", "\n", "\n", "", "self", ".", "_cross_validation_split_to_exclude", "=", "str", "(", "cross_validation_split_to_exclude", ")", "\n", "\n", "if", "database_file", "is", "not", "None", ":", "\n", "            ", "database_file", "=", "cached_path", "(", "database_file", ")", "\n", "connection", "=", "sqlite3", ".", "connect", "(", "database_file", ")", "\n", "self", ".", "_cursor", "=", "connection", ".", "cursor", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_cursor", "=", "None", "\n", "\n", "", "self", ".", "_schema_path", "=", "schema_path", "\n", "self", ".", "_world", "=", "Text2SqlWorld", "(", "\n", "schema_path", ",", "\n", "self", ".", "_cursor", ",", "\n", "use_prelinked_entities", "=", "use_prelinked_entities", ",", "\n", "use_untyped_entities", "=", "use_untyped_entities", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.grammar_based_text2sql.GrammarBasedText2SqlDatasetReader._read": [[103, 141], ["allennlp_semparse.common.sql.text2sql_utils.read_dataset_schema", "allennlp_semparse.common.sql.text2sql_utils.process_sql_data", "glob.glob", "open", "json.load", "grammar_based_text2sql.GrammarBasedText2SqlDatasetReader.text_to_instance", "os.path.basename", "allennlp.common.file_utils.cached_path"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.read_dataset_schema", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        This dataset reader consumes the data from\n        https://github.com/jkkummerfeld/text2sql-data/tree/master/data\n        formatted using ``scripts/reformat_text2sql_data.py``.\n\n        Parameters\n        ----------\n        file_path : ``str``, required.\n            For this dataset reader, file_path can either be a path to a file `or` a\n            path to a directory containing json files. The reason for this is because\n            some of the text2sql datasets require cross validation, which means they are split\n            up into many small files, for which you only want to exclude one.\n        \"\"\"", "\n", "files", "=", "[", "\n", "p", "\n", "for", "p", "in", "glob", ".", "glob", "(", "file_path", ")", "\n", "if", "self", ".", "_cross_validation_split_to_exclude", "not", "in", "os", ".", "path", ".", "basename", "(", "p", ")", "\n", "]", "\n", "schema", "=", "util", ".", "read_dataset_schema", "(", "self", ".", "_schema_path", ")", "\n", "\n", "for", "path", "in", "files", ":", "\n", "            ", "with", "open", "(", "cached_path", "(", "path", ")", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "                ", "data", "=", "json", ".", "load", "(", "data_file", ")", "\n", "\n", "", "for", "sql_data", "in", "util", ".", "process_sql_data", "(", "\n", "data", ",", "\n", "use_all_sql", "=", "self", ".", "_use_all_sql", ",", "\n", "remove_unneeded_aliases", "=", "self", ".", "_remove_unneeded_aliases", ",", "\n", "schema", "=", "schema", ",", "\n", ")", ":", "\n", "                ", "linked_entities", "=", "sql_data", ".", "sql_variables", "if", "self", ".", "_use_prelinked_entities", "else", "None", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "\n", "sql_data", ".", "text_with_variables", ",", "linked_entities", ",", "sql_data", ".", "sql", "\n", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                    ", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.grammar_based_text2sql.GrammarBasedText2SqlDatasetReader.text_to_instance": [[142, 190], ["allennlp.data.fields.TextField", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "allennlp.data.instance.Instance", "grammar_based_text2sql.GrammarBasedText2SqlDatasetReader._world.get_action_sequence_and_all_actions", "production_rule.split", "allennlp_semparse.fields.ProductionRuleField", "production_rule_fields.append", "index_fields.append", "allennlp.data.tokenizers.Token", "print", "production_rule.split", "grammar_based_text2sql.GrammarBasedText2SqlDatasetReader._world.is_global_rule", "enumerate", "allennlp.data.fields.IndexField", "allennlp.data.fields.IndexField"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.get_action_sequence_and_all_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.is_global_rule"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "\n", "self", ",", "# type: ignore", "\n", "query", ":", "List", "[", "str", "]", ",", "\n", "prelinked_entities", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "sql", ":", "List", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "Instance", ":", "\n", "        ", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "tokens", "=", "TextField", "(", "[", "Token", "(", "t", ")", "for", "t", "in", "query", "]", ",", "self", ".", "_token_indexers", ")", "\n", "fields", "[", "\"tokens\"", "]", "=", "tokens", "\n", "\n", "if", "sql", "is", "not", "None", ":", "\n", "            ", "action_sequence", ",", "all_actions", "=", "self", ".", "_world", ".", "get_action_sequence_and_all_actions", "(", "\n", "sql", ",", "prelinked_entities", "\n", ")", "\n", "if", "action_sequence", "is", "None", "and", "self", ".", "_keep_if_unparsable", ":", "\n", "                ", "print", "(", "\"Parse error\"", ")", "\n", "action_sequence", "=", "[", "]", "\n", "", "elif", "action_sequence", "is", "None", ":", "\n", "                ", "return", "None", "\n", "\n", "", "", "index_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "production_rule_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "\n", "for", "production_rule", "in", "all_actions", ":", "\n", "            ", "nonterminal", ",", "_", "=", "production_rule", ".", "split", "(", "\" ->\"", ")", "\n", "production_rule", "=", "\" \"", ".", "join", "(", "production_rule", ".", "split", "(", "\" \"", ")", ")", "\n", "field", "=", "ProductionRuleField", "(", "\n", "production_rule", ",", "self", ".", "_world", ".", "is_global_rule", "(", "nonterminal", ")", ",", "nonterminal", "=", "nonterminal", "\n", ")", "\n", "production_rule_fields", ".", "append", "(", "field", ")", "\n", "\n", "", "valid_actions_field", "=", "ListField", "(", "production_rule_fields", ")", "\n", "fields", "[", "\"valid_actions\"", "]", "=", "valid_actions_field", "\n", "\n", "action_map", "=", "{", "\n", "action", ".", "rule", ":", "i", "# type: ignore", "\n", "for", "i", ",", "action", "in", "enumerate", "(", "valid_actions_field", ".", "field_list", ")", "\n", "}", "\n", "\n", "for", "production_rule", "in", "action_sequence", ":", "\n", "            ", "index_fields", ".", "append", "(", "IndexField", "(", "action_map", "[", "production_rule", "]", ",", "valid_actions_field", ")", ")", "\n", "", "if", "not", "action_sequence", ":", "\n", "            ", "index_fields", "=", "[", "IndexField", "(", "-", "1", ",", "valid_actions_field", ")", "]", "\n", "\n", "", "action_sequence_field", "=", "ListField", "(", "index_fields", ")", "\n", "fields", "[", "\"action_sequence\"", "]", "=", "action_sequence_field", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis.AtisDatasetReader.__init__": [[75, 90], ["allennlp.data.DatasetReader.__init__", "allennlp.data.tokenizers.SpacyTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "keep_if_unparseable", ":", "bool", "=", "False", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "database_file", ":", "str", "=", "None", ",", "\n", "num_turns_to_concatenate", ":", "int", "=", "1", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_keep_if_unparseable", "=", "keep_if_unparseable", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "SpacyTokenizer", "(", ")", "\n", "self", ".", "_database_file", "=", "database_file", "\n", "self", ".", "_num_turns_to_concatenate", "=", "num_turns_to_concatenate", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis.AtisDatasetReader._read": [[91, 111], ["allennlp.common.file_utils.cached_path", "open", "logger.info", "atis._lazy_parse", "atis_file.read", "utterances.append", "atis.AtisDatasetReader.text_to_instance", "copy.deepcopy", "current_interaction[].split"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis._lazy_parse", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "# if `file_path` is a URL, redirect to the cache", "\n", "        ", "file_path", "=", "cached_path", "(", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ")", "as", "atis_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading ATIS instances from dataset at : %s\"", ",", "file_path", ")", "\n", "for", "line", "in", "_lazy_parse", "(", "atis_file", ".", "read", "(", ")", ")", ":", "\n", "                ", "utterances", "=", "[", "]", "\n", "for", "current_interaction", "in", "line", "[", "\"interaction\"", "]", ":", "\n", "                    ", "if", "not", "current_interaction", "[", "\"utterance\"", "]", "or", "not", "current_interaction", "[", "\"sql\"", "]", ":", "\n", "                        ", "continue", "\n", "", "utterances", ".", "append", "(", "current_interaction", "[", "\"utterance\"", "]", ")", "\n", "sql_query_labels", "=", "[", "\n", "query", "for", "query", "in", "current_interaction", "[", "\"sql\"", "]", ".", "split", "(", "\"\\n\"", ")", "if", "query", "\n", "]", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "deepcopy", "(", "utterances", ")", ",", "sql_query_labels", ")", "\n", "if", "not", "instance", ":", "\n", "                        ", "continue", "\n", "", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis.AtisDatasetReader.text_to_instance": [[112, 189], ["allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld", "atis.AtisDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.all_possible_actions", "allennlp.data.fields.ListField", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "min", "utterance.lower", "production_rule.split", "allennlp_semparse.fields.ProductionRuleField", "production_rule_fields.append", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp_semparse.parsimonious_languages.worlds.atis_world.AtisWorld.get_action_sequence", "atis.AtisDatasetReader._is_global_rule", "enumerate", "allennlp.data.fields.ListField", "logger.debug", "index_fields.append", "production_rule.split", "allennlp.data.fields.IndexField", "allennlp.data.fields.IndexField"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.world_test.FakeWorldWithRecursion.all_possible_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.atis_world.AtisWorld.get_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis.AtisDatasetReader._is_global_rule", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "# type: ignore", "\n", "self", ",", "utterances", ":", "List", "[", "str", "]", ",", "sql_query_labels", ":", "List", "[", "str", "]", "=", "None", "\n", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        utterances: ``List[str]``, required.\n            List of utterances in the interaction, the last element is the current utterance.\n        sql_query_labels: ``List[str]``, optional\n            The SQL queries that are given as labels during training or validation.\n        \"\"\"", "\n", "if", "self", ".", "_num_turns_to_concatenate", ":", "\n", "            ", "utterances", "[", "-", "1", "]", "=", "f\" {END_OF_UTTERANCE_TOKEN} \"", ".", "join", "(", "\n", "utterances", "[", "-", "self", ".", "_num_turns_to_concatenate", ":", "]", "\n", ")", "\n", "\n", "", "utterance", "=", "utterances", "[", "-", "1", "]", "\n", "action_sequence", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "if", "not", "utterance", ":", "\n", "            ", "return", "None", "\n", "\n", "", "world", "=", "AtisWorld", "(", "utterances", "=", "utterances", ")", "\n", "\n", "if", "sql_query_labels", ":", "\n", "# If there are multiple sql queries given as labels, we use the shortest", "\n", "# one for training.", "\n", "            ", "sql_query", "=", "min", "(", "sql_query_labels", ",", "key", "=", "len", ")", "\n", "try", ":", "\n", "                ", "action_sequence", "=", "world", ".", "get_action_sequence", "(", "sql_query", ")", "\n", "", "except", "ParseError", ":", "\n", "                ", "action_sequence", "=", "[", "]", "\n", "logger", ".", "debug", "(", "\"Parsing error\"", ")", "\n", "\n", "", "", "tokenized_utterance", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "utterance", ".", "lower", "(", ")", ")", "\n", "utterance_field", "=", "TextField", "(", "tokenized_utterance", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "production_rule_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "\n", "for", "production_rule", "in", "world", ".", "all_possible_actions", "(", ")", ":", "\n", "            ", "nonterminal", ",", "_", "=", "production_rule", ".", "split", "(", "\" ->\"", ")", "\n", "# The whitespaces are not semantically meaningful, so we filter them out.", "\n", "production_rule", "=", "\" \"", ".", "join", "(", "\n", "[", "token", "for", "token", "in", "production_rule", ".", "split", "(", "\" \"", ")", "if", "token", "!=", "\"ws\"", "]", "\n", ")", "\n", "field", "=", "ProductionRuleField", "(", "production_rule", ",", "self", ".", "_is_global_rule", "(", "nonterminal", ")", ")", "\n", "production_rule_fields", ".", "append", "(", "field", ")", "\n", "\n", "", "action_field", "=", "ListField", "(", "production_rule_fields", ")", "\n", "action_map", "=", "{", "\n", "action", ".", "rule", ":", "i", "for", "i", ",", "action", "in", "enumerate", "(", "action_field", ".", "field_list", ")", "# type: ignore", "\n", "}", "\n", "index_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "world_field", "=", "MetadataField", "(", "world", ")", "\n", "fields", "=", "{", "\n", "\"utterance\"", ":", "utterance_field", ",", "\n", "\"actions\"", ":", "action_field", ",", "\n", "\"world\"", ":", "world_field", ",", "\n", "\"linking_scores\"", ":", "ArrayField", "(", "world", ".", "linking_scores", ")", ",", "\n", "}", "\n", "\n", "if", "sql_query_labels", "is", "not", "None", ":", "\n", "            ", "fields", "[", "\"sql_queries\"", "]", "=", "MetadataField", "(", "sql_query_labels", ")", "\n", "if", "self", ".", "_keep_if_unparseable", "or", "action_sequence", ":", "\n", "                ", "for", "production_rule", "in", "action_sequence", ":", "\n", "                    ", "index_fields", ".", "append", "(", "IndexField", "(", "action_map", "[", "production_rule", "]", ",", "action_field", ")", ")", "\n", "", "if", "not", "action_sequence", ":", "\n", "                    ", "index_fields", "=", "[", "IndexField", "(", "-", "1", ",", "action_field", ")", "]", "\n", "", "action_sequence_field", "=", "ListField", "(", "index_fields", ")", "\n", "fields", "[", "\"target_action_sequence\"", "]", "=", "action_sequence_field", "\n", "", "else", ":", "\n", "# If we are given a SQL query, but we are unable to parse it, and we do not specify explicitly", "\n", "# to keep it, then we will skip the it.", "\n", "                ", "return", "None", "\n", "\n", "", "", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis.AtisDatasetReader._is_global_rule": [[190, 197], ["nonterminal.endswith"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_global_rule", "(", "nonterminal", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "nonterminal", "in", "NUMERIC_NONTERMINALS", ":", "\n", "            ", "return", "False", "\n", "", "elif", "nonterminal", ".", "endswith", "(", "\"string\"", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis._lazy_parse": [[27, 31], ["text.split", "json.loads"], "function", ["None"], ["def", "_lazy_parse", "(", "text", ":", "str", ")", ":", "\n", "    ", "for", "interaction", "in", "text", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "        ", "if", "interaction", ":", "\n", "            ", "yield", "json", ".", "loads", "(", "interaction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr.NlvrDatasetReader.__init__": [[84, 105], ["allennlp.data.DatasetReader.__init__", "allennlp.data.tokenizers.SpacyTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "sentence_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "nonterminal_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "terminal_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "output_agendas", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "SpacyTokenizer", "(", ")", "\n", "self", ".", "_sentence_token_indexers", "=", "sentence_token_indexers", "or", "{", "\n", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "\n", "}", "\n", "self", ".", "_nonterminal_indexers", "=", "nonterminal_indexers", "or", "{", "\n", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "\"rule_labels\"", ")", "\n", "}", "\n", "self", ".", "_terminal_indexers", "=", "terminal_indexers", "or", "{", "\n", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "\"rule_labels\"", ")", "\n", "}", "\n", "self", ".", "_output_agendas", "=", "output_agendas", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr.NlvrDatasetReader._read": [[106, 141], ["open", "logger.info", "line.strip.strip.strip", "json.loads", "nlvr.NlvrDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading instances from lines in file: %s\"", ",", "file_path", ")", "\n", "for", "line", "in", "data_file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "\"\\n\"", ")", "\n", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "sentence", "=", "data", "[", "\"sentence\"", "]", "\n", "identifier", "=", "data", "[", "\"identifier\"", "]", "if", "\"identifier\"", "in", "data", "else", "data", "[", "\"id\"", "]", "\n", "if", "\"worlds\"", "in", "data", ":", "\n", "# This means that we are reading grouped nlvr data. There will be multiple", "\n", "# worlds and corresponding labels per sentence.", "\n", "                    ", "labels", "=", "data", "[", "\"labels\"", "]", "\n", "structured_representations", "=", "data", "[", "\"worlds\"", "]", "\n", "", "else", ":", "\n", "# We will make lists of labels and structured representations, each with just", "\n", "# one element for consistency.", "\n", "                    ", "labels", "=", "[", "data", "[", "\"label\"", "]", "]", "\n", "structured_representations", "=", "[", "data", "[", "\"structured_rep\"", "]", "]", "\n", "\n", "", "target_sequences", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "# TODO(pradeep): The processed file also has incorrect sequences as well, which are", "\n", "# needed if we want to define some sort of a hinge-loss based trainer. Deal with", "\n", "# them.", "\n", "if", "\"correct_sequences\"", "in", "data", ":", "\n", "# We are reading the processed file and these are the \"correct\" logical form", "\n", "# sequences. See ``scripts/nlvr/get_nlvr_logical_forms.py``.", "\n", "                    ", "target_sequences", "=", "data", "[", "\"correct_sequences\"", "]", "\n", "", "instance", "=", "self", ".", "text_to_instance", "(", "\n", "sentence", ",", "structured_representations", ",", "labels", ",", "target_sequences", ",", "identifier", "\n", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                    ", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr.NlvrDatasetReader.text_to_instance": [[142, 228], ["nlvr.NlvrDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "worlds[].all_possible_productions", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "allennlp.data.instance.Instance", "worlds.append", "len", "allennlp_semparse.fields.ProductionRuleField", "production_rule_fields.append", "allennlp.data.fields.MetadataField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "allennlp_semparse.domain_languages.nlvr_language.Box", "allennlp_semparse.domain_languages.NlvrLanguage", "allennlp.data.fields.MetadataField", "allennlp.data.fields.ListField", "action_sequence_fields.append", "worlds[].get_agenda_for_sentence", "allennlp.data.fields.ListField", "enumerate", "allennlp.data.fields.LabelField", "allennlp.data.fields.IndexField", "allennlp.data.fields.IndexField"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.all_possible_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "\n", "self", ",", "# type: ignore", "\n", "sentence", ":", "str", ",", "\n", "structured_representations", ":", "List", "[", "List", "[", "List", "[", "JsonDict", "]", "]", "]", ",", "\n", "labels", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "target_sequences", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "identifier", ":", "str", "=", "None", ",", "\n", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        sentence : ``str``\n            The query sentence.\n        structured_representations : ``List[List[List[JsonDict]]]``\n            A list of Json representations of all the worlds. See expected format in this class' docstring.\n        labels : ``List[str]`` (optional)\n            List of string representations of the labels (true or false) corresponding to the\n            ``structured_representations``. Not required while testing.\n        target_sequences : ``List[List[str]]`` (optional)\n            List of target action sequences for each element which lead to the correct denotation in\n            worlds corresponding to the structured representations.\n        identifier : ``str`` (optional)\n            The identifier from the dataset if available.\n        \"\"\"", "\n", "worlds", "=", "[", "]", "\n", "for", "structured_representation", "in", "structured_representations", ":", "\n", "            ", "boxes", "=", "{", "\n", "Box", "(", "object_list", ",", "box_id", ")", "\n", "for", "box_id", ",", "object_list", "in", "enumerate", "(", "structured_representation", ")", "\n", "}", "\n", "worlds", ".", "append", "(", "NlvrLanguage", "(", "boxes", ")", ")", "\n", "", "tokenized_sentence", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "sentence", ")", "\n", "sentence_field", "=", "TextField", "(", "tokenized_sentence", ",", "self", ".", "_sentence_token_indexers", ")", "\n", "production_rule_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "instance_action_ids", ":", "Dict", "[", "str", ",", "int", "]", "=", "{", "}", "\n", "# TODO(pradeep): Assuming that possible actions are the same in all worlds. This may change", "\n", "# later.", "\n", "for", "production_rule", "in", "worlds", "[", "0", "]", ".", "all_possible_productions", "(", ")", ":", "\n", "            ", "instance_action_ids", "[", "production_rule", "]", "=", "len", "(", "instance_action_ids", ")", "\n", "field", "=", "ProductionRuleField", "(", "production_rule", ",", "is_global_rule", "=", "True", ")", "\n", "production_rule_fields", ".", "append", "(", "field", ")", "\n", "", "action_field", "=", "ListField", "(", "production_rule_fields", ")", "\n", "worlds_field", "=", "ListField", "(", "[", "MetadataField", "(", "world", ")", "for", "world", "in", "worlds", "]", ")", "\n", "metadata", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "\"sentence_tokens\"", ":", "[", "x", ".", "text", "for", "x", "in", "tokenized_sentence", "]", "}", "\n", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "\n", "\"sentence\"", ":", "sentence_field", ",", "\n", "\"worlds\"", ":", "worlds_field", ",", "\n", "\"actions\"", ":", "action_field", ",", "\n", "\"metadata\"", ":", "MetadataField", "(", "metadata", ")", ",", "\n", "}", "\n", "if", "identifier", "is", "not", "None", ":", "\n", "            ", "fields", "[", "\"identifier\"", "]", "=", "MetadataField", "(", "identifier", ")", "\n", "# Depending on the type of supervision used for training the parser, we may want either", "\n", "# target action sequences or an agenda in our instance. We check if target sequences are", "\n", "# provided, and include them if they are. If not, we'll get an agenda for the sentence, and", "\n", "# include that in the instance.", "\n", "", "if", "target_sequences", ":", "\n", "            ", "action_sequence_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "for", "target_sequence", "in", "target_sequences", ":", "\n", "                ", "index_fields", "=", "ListField", "(", "\n", "[", "\n", "IndexField", "(", "instance_action_ids", "[", "action", "]", ",", "action_field", ")", "\n", "for", "action", "in", "target_sequence", "\n", "]", "\n", ")", "\n", "action_sequence_fields", ".", "append", "(", "index_fields", ")", "\n", "# TODO(pradeep): Define a max length for this field.", "\n", "", "fields", "[", "\"target_action_sequences\"", "]", "=", "ListField", "(", "action_sequence_fields", ")", "\n", "", "elif", "self", ".", "_output_agendas", ":", "\n", "# TODO(pradeep): Assuming every world gives the same agenda for a sentence. This is true", "\n", "# now, but may change later too.", "\n", "            ", "agenda", "=", "worlds", "[", "0", "]", ".", "get_agenda_for_sentence", "(", "sentence", ")", "\n", "assert", "agenda", ",", "\"No agenda found for sentence: %s\"", "%", "sentence", "\n", "# agenda_field contains indices into actions.", "\n", "agenda_field", "=", "ListField", "(", "\n", "[", "IndexField", "(", "instance_action_ids", "[", "action", "]", ",", "action_field", ")", "for", "action", "in", "agenda", "]", "\n", ")", "\n", "fields", "[", "\"agenda\"", "]", "=", "agenda_field", "\n", "", "if", "labels", ":", "\n", "            ", "labels_field", "=", "ListField", "(", "\n", "[", "LabelField", "(", "label", ",", "label_namespace", "=", "\"denotations\"", ")", "for", "label", "in", "labels", "]", "\n", ")", "\n", "fields", "[", "\"labels\"", "]", "=", "labels_field", "\n", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.__init__": [[125, 152], ["allennlp.data.DatasetReader.__init__", "allennlp.data.tokenizers.SpacyTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "tables_directory", ":", "str", "=", "None", ",", "\n", "offline_logical_forms_directory", ":", "str", "=", "None", ",", "\n", "max_offline_logical_forms", ":", "int", "=", "10", ",", "\n", "keep_if_no_logical_forms", ":", "bool", "=", "False", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "question_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "table_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "use_table_for_vocab", ":", "bool", "=", "False", ",", "\n", "max_table_tokens", ":", "int", "=", "None", ",", "\n", "output_agendas", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "lazy", ")", "\n", "self", ".", "_tables_directory", "=", "tables_directory", "\n", "self", ".", "_offline_logical_forms_directory", "=", "offline_logical_forms_directory", "\n", "self", ".", "_max_offline_logical_forms", "=", "max_offline_logical_forms", "\n", "self", ".", "_keep_if_no_logical_forms", "=", "keep_if_no_logical_forms", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "SpacyTokenizer", "(", "pos_tags", "=", "True", ")", "\n", "self", ".", "_question_token_indexers", "=", "question_token_indexers", "or", "{", "\n", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "\n", "}", "\n", "self", ".", "_table_token_indexers", "=", "table_token_indexers", "or", "self", ".", "_question_token_indexers", "\n", "self", ".", "_use_table_for_vocab", "=", "use_table_for_vocab", "\n", "self", ".", "_max_table_tokens", "=", "max_table_tokens", "\n", "self", ".", "_output_agendas", "=", "output_agendas", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader._read": [[153, 231], ["os.listdir", "open", "data_file.readlines", "logger.info", "logger.info", "filename.endswith", "logger.info", "logger.info", "tarfile.open().extractall", "line.strip.strip.strip", "wikitables.parse_example_line", "os.path.join", "wikitables.WikiTablesDatasetReader.text_to_instance", "os.path.join", "parsed_info[].replace", "os.path.join", "line.strip.strip.split", "tarfile.open", "print", "gzip.open", "open().readlines", "logical_forms.append", "logger.debug", "logical_form_line.strip().decode", "open", "logical_form_line.strip"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.parse_example_line", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "# Checking if there is a single tarball with all the logical forms. If so, untaring it", "\n", "# first.", "\n", "        ", "if", "self", ".", "_offline_logical_forms_directory", ":", "\n", "            ", "tarball_with_all_lfs", ":", "str", "=", "None", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "_offline_logical_forms_directory", ")", ":", "\n", "                ", "if", "filename", ".", "endswith", "(", "\".tar.gz\"", ")", ":", "\n", "                    ", "tarball_with_all_lfs", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_offline_logical_forms_directory", ",", "filename", "\n", ")", "\n", "break", "\n", "", "", "if", "tarball_with_all_lfs", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "f\"Found a tarball in offline logical forms directory: {tarball_with_all_lfs}\"", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Assuming it contains logical forms for all questions and un-taring it.\"", "\n", ")", "\n", "# If you're running this with beaker, the input directory will be read-only and we", "\n", "# cannot untar the files in the directory itself. So we will do so in /tmp, but that", "\n", "# means the new offline logical forms directory will be /tmp.", "\n", "self", ".", "_offline_logical_forms_directory", "=", "\"/tmp/\"", "\n", "tarfile", ".", "open", "(", "tarball_with_all_lfs", ",", "mode", "=", "\"r:gz\"", ")", ".", "extractall", "(", "\n", "path", "=", "self", ".", "_offline_logical_forms_directory", "\n", ")", "\n", "", "", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "num_missing_logical_forms", "=", "0", "\n", "num_lines", "=", "0", "\n", "num_instances", "=", "0", "\n", "for", "line", "in", "data_file", ".", "readlines", "(", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "\"\\n\"", ")", "\n", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "", "num_lines", "+=", "1", "\n", "parsed_info", "=", "parse_example_line", "(", "line", ")", "\n", "question", "=", "parsed_info", "[", "\"question\"", "]", "\n", "# We want the tagged file, but the ``*.examples`` files typically point to CSV.", "\n", "table_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_tables_directory", ",", "parsed_info", "[", "\"table_filename\"", "]", ".", "replace", "(", "\"csv\"", ",", "\"tagged\"", ")", "\n", ")", "\n", "if", "self", ".", "_offline_logical_forms_directory", ":", "\n", "                    ", "logical_forms_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_offline_logical_forms_directory", ",", "parsed_info", "[", "\"id\"", "]", "+", "\".gz\"", "\n", ")", "\n", "try", ":", "\n", "                        ", "print", "(", "logical_forms_filename", ")", "\n", "logical_forms_file", "=", "gzip", ".", "open", "(", "logical_forms_filename", ")", "\n", "logical_forms", "=", "[", "]", "\n", "for", "logical_form_line", "in", "logical_forms_file", ":", "\n", "                            ", "logical_forms", ".", "append", "(", "logical_form_line", ".", "strip", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ")", "\n", "", "", "except", "FileNotFoundError", ":", "\n", "                        ", "logger", ".", "debug", "(", "\n", "f'Missing search output for instance {parsed_info[\"id\"]}; skipping...'", "\n", ")", "\n", "logical_forms", "=", "None", "\n", "num_missing_logical_forms", "+=", "1", "\n", "if", "not", "self", ".", "_keep_if_no_logical_forms", ":", "\n", "                            ", "continue", "\n", "", "", "", "else", ":", "\n", "                    ", "logical_forms", "=", "None", "\n", "\n", "", "table_lines", "=", "[", "line", ".", "split", "(", "\"\\t\"", ")", "for", "line", "in", "open", "(", "table_filename", ")", ".", "readlines", "(", ")", "]", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "\n", "question", "=", "question", ",", "\n", "table_lines", "=", "table_lines", ",", "\n", "target_values", "=", "parsed_info", "[", "\"target_values\"", "]", ",", "\n", "offline_search_output", "=", "logical_forms", ",", "\n", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                    ", "num_instances", "+=", "1", "\n", "yield", "instance", "\n", "\n", "", "", "", "if", "self", ".", "_offline_logical_forms_directory", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Missing logical forms for {num_missing_logical_forms} out of {num_lines} instances\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Kept {num_instances} instances\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance": [[232, 342], ["wikitables.WikiTablesDatasetReader._tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_lines", "allennlp_semparse.domain_languages.WikiTablesLanguage", "allennlp.data.fields.MetadataField", "allennlp_semparse.fields.KnowledgeGraphField", "allennlp_semparse.domain_languages.WikiTablesLanguage.all_possible_productions", "allennlp.data.fields.ListField", "allennlp.data.instance.Instance", "question.lower", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_lines.get_table_knowledge_graph", "production_rule.split", "allennlp_semparse.fields.ProductionRuleField", "production_rule_fields.append", "allennlp.data.fields.MetadataField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.ListField", "allennlp_semparse.domain_languages.WikiTablesLanguage.get_agenda", "allennlp.data.fields.ListField", "allennlp_semparse.domain_languages.WikiTablesLanguage.is_instance_specific_entity", "enumerate", "agenda_index_fields.append", "allennlp_semparse.domain_languages.WikiTablesLanguage.logical_form_to_action_sequence", "action_sequence_fields.append", "len", "allennlp.data.fields.IndexField", "allennlp.data.fields.IndexField", "index_fields.append", "allennlp.data.fields.ListField", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.error", "allennlp.data.fields.IndexField"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_lines", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.all_possible_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_knowledge_graph", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.is_instance_specific_entity", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "def", "text_to_instance", "(", "\n", "self", ",", "# type: ignore", "\n", "question", ":", "str", ",", "\n", "table_lines", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "target_values", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "offline_search_output", ":", "List", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Reads text inputs and makes an instance. We pass the ``table_lines`` to ``TableQuestionContext``, and that\n        method accepts this field either as lines from CoreNLP processed tagged files that come with the dataset,\n        or simply in a tsv format where each line corresponds to a row and the cells are tab-separated.\n\n        Parameters\n        ----------\n        question : ``str``\n            Input question\n        table_lines : ``List[List[str]]``\n            The table content optionally preprocessed by CoreNLP. See ``TableQuestionContext.read_from_lines``\n            for the expected format.\n        target_values : ``List[str]``, optional\n            Target values for the denotations the logical forms should execute to. Not required for testing.\n        offline_search_output : ``List[str]``, optional\n            List of logical forms, produced by offline search. Not required during test.\n        \"\"\"", "\n", "tokenized_question", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "question", ".", "lower", "(", ")", ")", "\n", "question_field", "=", "TextField", "(", "tokenized_question", ",", "self", ".", "_question_token_indexers", ")", "\n", "metadata", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "\"question_tokens\"", ":", "[", "x", ".", "text", "for", "x", "in", "tokenized_question", "]", "}", "\n", "table_context", "=", "TableQuestionContext", ".", "read_from_lines", "(", "table_lines", ",", "tokenized_question", ")", "\n", "world", "=", "WikiTablesLanguage", "(", "table_context", ")", "\n", "world_field", "=", "MetadataField", "(", "world", ")", "\n", "# Note: Not passing any featre extractors when instantiating the field below. This will make", "\n", "# it use all the available extractors.", "\n", "table_field", "=", "KnowledgeGraphField", "(", "\n", "table_context", ".", "get_table_knowledge_graph", "(", ")", ",", "\n", "tokenized_question", ",", "\n", "self", ".", "_table_token_indexers", ",", "\n", "tokenizer", "=", "self", ".", "_tokenizer", ",", "\n", "include_in_vocab", "=", "self", ".", "_use_table_for_vocab", ",", "\n", "max_table_tokens", "=", "self", ".", "_max_table_tokens", ",", "\n", ")", "\n", "production_rule_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "for", "production_rule", "in", "world", ".", "all_possible_productions", "(", ")", ":", "\n", "            ", "_", ",", "rule_right_side", "=", "production_rule", ".", "split", "(", "\" -> \"", ")", "\n", "is_global_rule", "=", "not", "world", ".", "is_instance_specific_entity", "(", "rule_right_side", ")", "\n", "field", "=", "ProductionRuleField", "(", "production_rule", ",", "is_global_rule", "=", "is_global_rule", ")", "\n", "production_rule_fields", ".", "append", "(", "field", ")", "\n", "", "action_field", "=", "ListField", "(", "production_rule_fields", ")", "\n", "\n", "fields", "=", "{", "\n", "\"question\"", ":", "question_field", ",", "\n", "\"metadata\"", ":", "MetadataField", "(", "metadata", ")", ",", "\n", "\"table\"", ":", "table_field", ",", "\n", "\"world\"", ":", "world_field", ",", "\n", "\"actions\"", ":", "action_field", ",", "\n", "}", "\n", "\n", "if", "target_values", "is", "not", "None", ":", "\n", "            ", "target_values_field", "=", "MetadataField", "(", "target_values", ")", "\n", "fields", "[", "\"target_values\"", "]", "=", "target_values_field", "\n", "\n", "# We'll make each target action sequence a List[IndexField], where the index is into", "\n", "# the action list we made above.  We need to ignore the type here because mypy doesn't", "\n", "# like `action.rule` - it's hard to tell mypy that the ListField is made up of", "\n", "# ProductionRuleFields.", "\n", "", "action_map", "=", "{", "\n", "action", ".", "rule", ":", "i", "for", "i", ",", "action", "in", "enumerate", "(", "action_field", ".", "field_list", ")", "\n", "}", "# type: ignore", "\n", "if", "offline_search_output", ":", "\n", "            ", "action_sequence_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "for", "logical_form", "in", "offline_search_output", ":", "\n", "                ", "try", ":", "\n", "                    ", "action_sequence", "=", "world", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "index_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "for", "production_rule", "in", "action_sequence", ":", "\n", "                        ", "index_fields", ".", "append", "(", "IndexField", "(", "action_map", "[", "production_rule", "]", ",", "action_field", ")", ")", "\n", "", "action_sequence_fields", ".", "append", "(", "ListField", "(", "index_fields", ")", ")", "\n", "", "except", "ParsingError", "as", "error", ":", "\n", "                    ", "logger", ".", "debug", "(", "f\"Parsing error: {error.message}, skipping logical form\"", ")", "\n", "logger", ".", "debug", "(", "f\"Question was: {question}\"", ")", "\n", "logger", ".", "debug", "(", "f\"Logical form was: {logical_form}\"", ")", "\n", "logger", ".", "debug", "(", "f\"Table info was: {table_lines}\"", ")", "\n", "continue", "\n", "", "except", "KeyError", "as", "error", ":", "\n", "                    ", "logger", ".", "debug", "(", "f\"Missing production rule: {error.args}, skipping logical form\"", ")", "\n", "logger", ".", "debug", "(", "f\"Question was: {question}\"", ")", "\n", "logger", ".", "debug", "(", "f\"Table info was: {table_lines}\"", ")", "\n", "logger", ".", "debug", "(", "f\"Logical form was: {logical_form}\"", ")", "\n", "continue", "\n", "", "except", ":", "# noqa", "\n", "                    ", "logger", ".", "error", "(", "logical_form", ")", "\n", "raise", "\n", "", "if", "len", "(", "action_sequence_fields", ")", ">=", "self", ".", "_max_offline_logical_forms", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "not", "action_sequence_fields", ":", "\n", "# This is not great, but we're only doing it when we're passed logical form", "\n", "# supervision, so we're expecting labeled logical forms, but we can't actually", "\n", "# produce the logical forms.  We should skip this instance.  Note that this affects", "\n", "# _dev_ and _test_ instances, too, so your metrics could be over-estimates on the", "\n", "# full test data.", "\n", "                ", "return", "None", "\n", "", "fields", "[", "\"target_action_sequences\"", "]", "=", "ListField", "(", "action_sequence_fields", ")", "\n", "", "if", "self", ".", "_output_agendas", ":", "\n", "            ", "agenda_index_fields", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "for", "agenda_string", "in", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ":", "\n", "                ", "agenda_index_fields", ".", "append", "(", "IndexField", "(", "action_map", "[", "agenda_string", "]", ",", "action_field", ")", ")", "\n", "", "if", "not", "agenda_index_fields", ":", "\n", "                ", "agenda_index_fields", "=", "[", "IndexField", "(", "-", "1", ",", "action_field", ")", "]", "\n", "", "fields", "[", "\"agenda\"", "]", "=", "ListField", "(", "agenda_index_fields", ")", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.parse_example_line": [[29, 54], ["lisp_string.split", "rest.split", "rest.split", "rest.strip().split", "id_piece.split", "string.replace().replace().strip.replace().replace().strip", "rest.strip", "target_values.append", "string.replace().replace().strip.replace().replace", "string.replace().replace().strip.replace"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["def", "parse_example_line", "(", "lisp_string", ":", "str", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"\n    Training data in WikitableQuestions comes with examples in the form of lisp strings in the format:\n        (example (id <example-id>)\n                 (utterance <question>)\n                 (context (graph tables.TableKnowledgeGraph <table-filename>))\n                 (targetValue (list (description <answer1>) (description <answer2>) ...)))\n\n    We parse such strings and return the parsed information here.\n    \"\"\"", "\n", "id_piece", ",", "rest", "=", "lisp_string", ".", "split", "(", "') (utterance \"'", ")", "\n", "example_id", "=", "id_piece", ".", "split", "(", "\"(id \"", ")", "[", "1", "]", "\n", "question", ",", "rest", "=", "rest", ".", "split", "(", "'\") (context (graph tables.TableKnowledgeGraph '", ")", "\n", "table_filename", ",", "rest", "=", "rest", ".", "split", "(", "\")) (targetValue (list\"", ")", "\n", "target_value_strings", "=", "rest", ".", "strip", "(", ")", ".", "split", "(", "\"(description\"", ")", "\n", "target_values", "=", "[", "]", "\n", "for", "string", "in", "target_value_strings", ":", "\n", "        ", "string", "=", "string", ".", "replace", "(", "\")\"", ",", "\"\"", ")", ".", "replace", "(", "'\"'", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "if", "string", "!=", "\"\"", ":", "\n", "            ", "target_values", ".", "append", "(", "string", ")", "\n", "", "", "return", "{", "\n", "\"id\"", ":", "example_id", ",", "\n", "\"question\"", ":", "question", ",", "\n", "\"table_filename\"", ":", "table_filename", ",", "\n", "\"target_values\"", ":", "target_values", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr_test.TestNlvrDatasetReader.test_reader_reads_ungrouped_data": [[8, 54], ["str", "allennlp_semparse.dataset_readers.NlvrDatasetReader().read", "list", "isinstance", "len", "instance.fields.keys", "len", "set", "set", "world_field.as_tensor", "allennlp_semparse.dataset_readers.NlvrDatasetReader"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor"], ["    ", "def", "test_reader_reads_ungrouped_data", "(", "self", ")", ":", "\n", "        ", "test_file", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_ungrouped_data.jsonl\"", ")", "\n", "dataset", "=", "NlvrDatasetReader", "(", ")", ".", "read", "(", "test_file", ")", "\n", "instances", "=", "list", "(", "dataset", ")", "\n", "assert", "len", "(", "instances", ")", "==", "3", "\n", "instance", "=", "instances", "[", "0", "]", "\n", "assert", "instance", ".", "fields", ".", "keys", "(", ")", "==", "{", "\n", "\"sentence\"", ",", "\n", "\"agenda\"", ",", "\n", "\"worlds\"", ",", "\n", "\"actions\"", ",", "\n", "\"labels\"", ",", "\n", "\"identifier\"", ",", "\n", "\"metadata\"", ",", "\n", "}", "\n", "sentence_tokens", "=", "instance", ".", "fields", "[", "\"sentence\"", "]", ".", "tokens", "\n", "expected_tokens", "=", "[", "\n", "\"There\"", ",", "\n", "\"is\"", ",", "\n", "\"a\"", ",", "\n", "\"circle\"", ",", "\n", "\"closely\"", ",", "\n", "\"touching\"", ",", "\n", "\"a\"", ",", "\n", "\"corner\"", ",", "\n", "\"of\"", ",", "\n", "\"a\"", ",", "\n", "\"box\"", ",", "\n", "\".\"", ",", "\n", "]", "\n", "assert", "[", "t", ".", "text", "for", "t", "in", "sentence_tokens", "]", "==", "expected_tokens", "\n", "actions", "=", "[", "action", ".", "rule", "for", "action", "in", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", "]", "\n", "assert", "len", "(", "actions", ")", "==", "115", "\n", "agenda", "=", "[", "item", ".", "sequence_index", "for", "item", "in", "instance", ".", "fields", "[", "\"agenda\"", "]", ".", "field_list", "]", "\n", "agenda_strings", "=", "[", "actions", "[", "rule_id", "]", "for", "rule_id", "in", "agenda", "]", "\n", "assert", "set", "(", "agenda_strings", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> circle\"", ",", "\n", "\"<Set[Object]:bool> -> object_exists\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_corner\"", ",", "\n", "]", "\n", ")", "\n", "worlds", "=", "[", "world_field", ".", "as_tensor", "(", "{", "}", ")", "for", "world_field", "in", "instance", ".", "fields", "[", "\"worlds\"", "]", ".", "field_list", "]", "\n", "assert", "isinstance", "(", "worlds", "[", "0", "]", ",", "NlvrLanguage", ")", "\n", "label", "=", "instance", ".", "fields", "[", "\"labels\"", "]", ".", "field_list", "[", "0", "]", ".", "label", "\n", "assert", "label", "==", "\"true\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr_test.TestNlvrDatasetReader.test_agenda_indices_are_correct": [[55, 69], ["allennlp_semparse.dataset_readers.NlvrDatasetReader", "str", "allennlp_semparse.dataset_readers.NlvrDatasetReader.read", "list", "instance.fields[].field_list[].as_tensor", "instance.fields[].field_list[].as_tensor.get_agenda_for_sentence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence"], ["", "def", "test_agenda_indices_are_correct", "(", "self", ")", ":", "\n", "        ", "reader", "=", "NlvrDatasetReader", "(", ")", "\n", "test_file", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_ungrouped_data.jsonl\"", ")", "\n", "dataset", "=", "reader", ".", "read", "(", "test_file", ")", "\n", "instances", "=", "list", "(", "dataset", ")", "\n", "instance", "=", "instances", "[", "0", "]", "\n", "sentence_tokens", "=", "instance", ".", "fields", "[", "\"sentence\"", "]", ".", "tokens", "\n", "sentence", "=", "\" \"", ".", "join", "(", "[", "t", ".", "text", "for", "t", "in", "sentence_tokens", "]", ")", "\n", "agenda", "=", "[", "item", ".", "sequence_index", "for", "item", "in", "instance", ".", "fields", "[", "\"agenda\"", "]", ".", "field_list", "]", "\n", "actions", "=", "[", "action", ".", "rule", "for", "action", "in", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", "]", "\n", "agenda_actions", "=", "[", "actions", "[", "i", "]", "for", "i", "in", "agenda", "]", "\n", "world", "=", "instance", ".", "fields", "[", "\"worlds\"", "]", ".", "field_list", "[", "0", "]", ".", "as_tensor", "(", "{", "}", ")", "\n", "expected_agenda_actions", "=", "world", ".", "get_agenda_for_sentence", "(", "sentence", ")", "\n", "assert", "expected_agenda_actions", "==", "agenda_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr_test.TestNlvrDatasetReader.test_reader_reads_grouped_data": [[70, 116], ["str", "allennlp_semparse.dataset_readers.NlvrDatasetReader().read", "list", "all", "len", "instance.fields.keys", "len", "set", "set", "world_field.as_tensor", "allennlp_semparse.dataset_readers.NlvrDatasetReader", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor"], ["", "def", "test_reader_reads_grouped_data", "(", "self", ")", ":", "\n", "        ", "test_file", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_grouped_data.jsonl\"", ")", "\n", "dataset", "=", "NlvrDatasetReader", "(", ")", ".", "read", "(", "test_file", ")", "\n", "instances", "=", "list", "(", "dataset", ")", "\n", "assert", "len", "(", "instances", ")", "==", "2", "\n", "instance", "=", "instances", "[", "0", "]", "\n", "assert", "instance", ".", "fields", ".", "keys", "(", ")", "==", "{", "\n", "\"sentence\"", ",", "\n", "\"agenda\"", ",", "\n", "\"worlds\"", ",", "\n", "\"actions\"", ",", "\n", "\"labels\"", ",", "\n", "\"identifier\"", ",", "\n", "\"metadata\"", ",", "\n", "}", "\n", "sentence_tokens", "=", "instance", ".", "fields", "[", "\"sentence\"", "]", ".", "tokens", "\n", "expected_tokens", "=", "[", "\n", "\"There\"", ",", "\n", "\"is\"", ",", "\n", "\"a\"", ",", "\n", "\"circle\"", ",", "\n", "\"closely\"", ",", "\n", "\"touching\"", ",", "\n", "\"a\"", ",", "\n", "\"corner\"", ",", "\n", "\"of\"", ",", "\n", "\"a\"", ",", "\n", "\"box\"", ",", "\n", "\".\"", ",", "\n", "]", "\n", "assert", "[", "t", ".", "text", "for", "t", "in", "sentence_tokens", "]", "==", "expected_tokens", "\n", "actions", "=", "[", "action", ".", "rule", "for", "action", "in", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", "]", "\n", "assert", "len", "(", "actions", ")", "==", "115", "\n", "agenda", "=", "[", "item", ".", "sequence_index", "for", "item", "in", "instance", ".", "fields", "[", "\"agenda\"", "]", ".", "field_list", "]", "\n", "agenda_strings", "=", "[", "actions", "[", "rule_id", "]", "for", "rule_id", "in", "agenda", "]", "\n", "assert", "set", "(", "agenda_strings", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> circle\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_corner\"", ",", "\n", "\"<Set[Object]:bool> -> object_exists\"", ",", "\n", "]", "\n", ")", "\n", "worlds", "=", "[", "world_field", ".", "as_tensor", "(", "{", "}", ")", "for", "world_field", "in", "instance", ".", "fields", "[", "\"worlds\"", "]", ".", "field_list", "]", "\n", "assert", "all", "(", "[", "isinstance", "(", "world", ",", "NlvrLanguage", ")", "for", "world", "in", "worlds", "]", ")", "\n", "labels", "=", "[", "label", ".", "label", "for", "label", "in", "instance", ".", "fields", "[", "\"labels\"", "]", ".", "field_list", "]", "\n", "assert", "labels", "==", "[", "\"true\"", ",", "\"false\"", ",", "\"true\"", ",", "\"false\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.nlvr_test.TestNlvrDatasetReader.test_reader_reads_processed_data": [[117, 150], ["str", "allennlp_semparse.dataset_readers.NlvrDatasetReader().read", "list", "len", "instance.fields.keys", "len", "allennlp_semparse.dataset_readers.NlvrDatasetReader"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_reader_reads_processed_data", "(", "self", ")", ":", "\n", "# Processed data contains action sequences that yield the correct denotations, obtained from", "\n", "# an offline search.", "\n", "        ", "test_file", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_processed_data.jsonl\"", ")", "\n", "dataset", "=", "NlvrDatasetReader", "(", ")", ".", "read", "(", "test_file", ")", "\n", "instances", "=", "list", "(", "dataset", ")", "\n", "assert", "len", "(", "instances", ")", "==", "2", "\n", "instance", "=", "instances", "[", "0", "]", "\n", "assert", "instance", ".", "fields", ".", "keys", "(", ")", "==", "{", "\n", "\"sentence\"", ",", "\n", "\"target_action_sequences\"", ",", "\n", "\"worlds\"", ",", "\n", "\"actions\"", ",", "\n", "\"labels\"", ",", "\n", "\"identifier\"", ",", "\n", "\"metadata\"", ",", "\n", "}", "\n", "all_action_sequence_indices", "=", "instance", ".", "fields", "[", "\"target_action_sequences\"", "]", ".", "field_list", "\n", "assert", "len", "(", "all_action_sequence_indices", ")", "==", "20", "\n", "action_sequence_indices", "=", "[", "\n", "item", ".", "sequence_index", "for", "item", "in", "all_action_sequence_indices", "[", "0", "]", ".", "field_list", "\n", "]", "\n", "actions", "=", "[", "action", ".", "rule", "for", "action", "in", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", "]", "\n", "action_sequence", "=", "[", "actions", "[", "rule_id", "]", "for", "rule_id", "in", "action_sequence_indices", "]", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> bool\"", ",", "\n", "\"bool -> [<Set[Object]:bool>, Set[Object]]\"", ",", "\n", "\"<Set[Object]:bool> -> object_exists\"", ",", "\n", "\"Set[Object] -> [<Set[Object]:Set[Object]>, Set[Object]]\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_corner\"", ",", "\n", "\"Set[Object] -> [<Set[Object]:Set[Object]>, Set[Object]]\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> circle\"", ",", "\n", "\"Set[Object] -> all_objects\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables_test.TestWikiTablesDatasetReader.test_reader_reads": [[83, 95], ["allennlp_semparse.dataset_readers.WikiTablesDatasetReader.from_params", "allennlp_semparse.dataset_readers.WikiTablesDatasetReader.from_params.read", "wikitables_test.assert_dataset_correct", "allennlp.common.Params"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables_test.assert_dataset_correct"], ["    ", "def", "test_reader_reads", "(", "self", ")", ":", "\n", "        ", "offline_search_directory", "=", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"action_space_walker_output\"", "\n", ")", "\n", "params", "=", "{", "\n", "\"lazy\"", ":", "False", ",", "\n", "\"tables_directory\"", ":", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", ",", "\n", "\"offline_logical_forms_directory\"", ":", "offline_search_directory", ",", "\n", "}", "\n", "reader", "=", "WikiTablesDatasetReader", ".", "from_params", "(", "Params", "(", "params", ")", ")", "\n", "dataset", "=", "reader", ".", "read", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"sample_data.examples\"", ")", "\n", "assert_dataset_correct", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables_test.TestWikiTablesDatasetReader.test_reader_reads_with_lfs_in_tarball": [[96, 111], ["allennlp_semparse.dataset_readers.WikiTablesDatasetReader.from_params", "allennlp_semparse.dataset_readers.WikiTablesDatasetReader.from_params.read", "wikitables_test.assert_dataset_correct", "allennlp.common.Params"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables_test.assert_dataset_correct"], ["", "def", "test_reader_reads_with_lfs_in_tarball", "(", "self", ")", ":", "\n", "        ", "offline_search_directory", "=", "(", "\n", "self", ".", "FIXTURES_ROOT", "\n", "/", "\"data\"", "\n", "/", "\"wikitables\"", "\n", "/", "\"action_space_walker_output_with_single_tarball\"", "\n", ")", "\n", "params", "=", "{", "\n", "\"lazy\"", ":", "False", ",", "\n", "\"tables_directory\"", ":", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", ",", "\n", "\"offline_logical_forms_directory\"", ":", "offline_search_directory", ",", "\n", "}", "\n", "reader", "=", "WikiTablesDatasetReader", ".", "from_params", "(", "Params", "(", "params", ")", ")", "\n", "dataset", "=", "reader", ".", "read", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"sample_data.examples\"", ")", "\n", "assert_dataset_correct", "(", "dataset", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables_test.assert_dataset_correct": [[8, 79], ["list", "isinstance", "len", "len", "instance.fields.keys", "instance.fields[].as_tensor", "instance.fields[].as_tensor"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor"], ["def", "assert_dataset_correct", "(", "dataset", ")", ":", "\n", "    ", "instances", "=", "list", "(", "dataset", ")", "\n", "assert", "len", "(", "instances", ")", "==", "2", "\n", "instance", "=", "instances", "[", "0", "]", "\n", "\n", "assert", "instance", ".", "fields", ".", "keys", "(", ")", "==", "{", "\n", "\"question\"", ",", "\n", "\"metadata\"", ",", "\n", "\"table\"", ",", "\n", "\"world\"", ",", "\n", "\"actions\"", ",", "\n", "\"target_action_sequences\"", ",", "\n", "\"target_values\"", ",", "\n", "}", "\n", "\n", "question_tokens", "=", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"last\"", ",", "\n", "\"year\"", ",", "\n", "\"where\"", ",", "\n", "\"this\"", ",", "\n", "\"team\"", ",", "\n", "\"was\"", ",", "\n", "\"a\"", ",", "\n", "\"part\"", ",", "\n", "\"of\"", ",", "\n", "\"the\"", ",", "\n", "\"usl\"", ",", "\n", "\"a\"", ",", "\n", "\"-\"", ",", "\n", "\"league\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "[", "t", ".", "text", "for", "t", "in", "instance", ".", "fields", "[", "\"question\"", "]", ".", "tokens", "]", "==", "question_tokens", "\n", "\n", "assert", "instance", ".", "fields", "[", "\"metadata\"", "]", ".", "as_tensor", "(", "{", "}", ")", "[", "\"question_tokens\"", "]", "==", "question_tokens", "\n", "\n", "# The content of this will be tested indirectly by checking the actions; we'll just make", "\n", "# sure we get a WikiTablesWorld object in here.", "\n", "assert", "isinstance", "(", "instance", ".", "fields", "[", "\"world\"", "]", ".", "as_tensor", "(", "{", "}", ")", ",", "WikiTablesLanguage", ")", "\n", "\n", "action_fields", "=", "instance", ".", "fields", "[", "\"actions\"", "]", ".", "field_list", "\n", "actions", "=", "[", "action_field", ".", "rule", "for", "action_field", "in", "action_fields", "]", "\n", "\n", "# We should have been able to read all of the logical forms in the file.  If one of them can't", "\n", "# be parsed, or the action sequences can't be mapped correctly, the DatasetReader will skip the", "\n", "# logical form, log an error, and keep going (i.e., it won't crash).", "\n", "num_action_sequences", "=", "len", "(", "instance", ".", "fields", "[", "\"target_action_sequences\"", "]", ".", "field_list", ")", "\n", "assert", "num_action_sequences", "==", "10", "\n", "\n", "# We should have sorted the logical forms by length.  This is the action sequence", "\n", "# corresponding to the shortest logical form in the examples _by tree size_, which is _not_ the", "\n", "# first one in the file, or the shortest logical form by _string length_.  It's also a totally", "\n", "# made up logical form, just to demonstrate that we're sorting things correctly.", "\n", "action_sequence", "=", "instance", ".", "fields", "[", "\"target_action_sequences\"", "]", ".", "field_list", "[", "0", "]", "\n", "action_indices", "=", "[", "action", ".", "sequence_index", "for", "action", "in", "action_sequence", ".", "field_list", "]", "\n", "actions", "=", "[", "actions", "[", "i", "]", "for", "i", "in", "action_indices", "]", "\n", "assert", "actions", "==", "[", "\n", "\"@start@ -> Number\"", ",", "\n", "\"Number -> [<List[Row],NumberColumn:Number>, List[Row], NumberColumn]\"", ",", "\n", "\"<List[Row],NumberColumn:Number> -> average\"", ",", "\n", "\"List[Row] -> [<List[Row]:List[Row]>, List[Row]]\"", ",", "\n", "\"<List[Row]:List[Row]> -> last\"", ",", "\n", "\"List[Row] -> [<List[Row],StringColumn,List[str]:List[Row]>, List[Row], StringColumn, List[str]]\"", ",", "\n", "\"<List[Row],StringColumn,List[str]:List[Row]> -> filter_in\"", ",", "\n", "\"List[Row] -> all_rows\"", ",", "\n", "\"StringColumn -> string_column:league\"", ",", "\n", "\"List[str] -> string:usl_a_league\"", ",", "\n", "\"NumberColumn -> number_column:year\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.grammar_based_text2sql_test.TestGrammarBasedText2SqlDatasetReader.setup_method": [[12, 19], ["super().setup_method", "str", "str", "str", "allennlp_semparse.dataset_readers.grammar_based_text2sql.GrammarBasedText2SqlDatasetReader"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "data_path", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"*.json\"", ")", "\n", "self", ".", "schema", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants-schema.csv\"", ")", "\n", "self", ".", "database", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants.db\"", ")", "\n", "\n", "self", ".", "reader", "=", "GrammarBasedText2SqlDatasetReader", "(", "self", ".", "schema", ",", "self", ".", "database", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.grammar_based_text2sql_test.TestGrammarBasedText2SqlDatasetReader.test_reader_can_read_data_with_entity_pre_linking": [[20, 227], ["grammar_based_text2sql_test.TestGrammarBasedText2SqlDatasetReader.reader.read", "list", "len"], "methods", ["None"], ["", "def", "test_reader_can_read_data_with_entity_pre_linking", "(", "self", ")", ":", "\n", "        ", "instances", "=", "self", ".", "reader", ".", "read", "(", "self", ".", "data_path", ")", "\n", "instances", "=", "list", "(", "instances", ")", "\n", "assert", "len", "(", "instances", ")", "==", "5", "\n", "\n", "fields", "=", "instances", "[", "0", "]", ".", "fields", "\n", "token_field", "=", "fields", "[", "\"tokens\"", "]", "\n", "tokens", "=", "[", "t", ".", "text", "for", "t", "in", "token_field", ".", "tokens", "]", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"buttercup\"", ",", "\n", "\"kitchen\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"san\"", ",", "\n", "\"francisco\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "\n", "action_sequence", "=", "fields", "[", "\"action_sequence\"", "]", ".", "field_list", "\n", "indices", "=", "[", "x", ".", "sequence_index", "for", "x", "in", "action_sequence", "]", "\n", "\n", "assert", "indices", "==", "[", "\n", "93", ",", "\n", "75", ",", "\n", "78", ",", "\n", "88", ",", "\n", "86", ",", "\n", "82", ",", "\n", "39", ",", "\n", "113", ",", "\n", "48", ",", "\n", "42", ",", "\n", "2", ",", "\n", "46", ",", "\n", "91", ",", "\n", "90", ",", "\n", "102", ",", "\n", "92", ",", "\n", "90", ",", "\n", "103", ",", "\n", "118", ",", "\n", "34", ",", "\n", "5", ",", "\n", "112", ",", "\n", "21", ",", "\n", "102", ",", "\n", "23", ",", "\n", "13", ",", "\n", "34", ",", "\n", "5", ",", "\n", "116", ",", "\n", "95", ",", "\n", "16", ",", "\n", "34", ",", "\n", "5", ",", "\n", "112", ",", "\n", "21", ",", "\n", "103", ",", "\n", "30", ",", "\n", "13", ",", "\n", "34", ",", "\n", "5", ",", "\n", "112", ",", "\n", "21", ",", "\n", "102", ",", "\n", "30", ",", "\n", "16", ",", "\n", "34", ",", "\n", "5", ",", "\n", "112", ",", "\n", "21", ",", "\n", "103", ",", "\n", "27", ",", "\n", "13", ",", "\n", "39", ",", "\n", "116", ",", "\n", "96", ",", "\n", "]", "\n", "\n", "action_fields", "=", "fields", "[", "\"valid_actions\"", "]", ".", "field_list", "\n", "production_rules", "=", "[", "(", "x", ".", "rule", ",", "x", ".", "is_global_rule", ")", "for", "x", "in", "action_fields", "]", "\n", "\n", "assert", "production_rules", "==", "[", "\n", "(", "'arg_list -> [expr, \",\", arg_list]'", ",", "True", ")", ",", "\n", "(", "\"arg_list -> [expr]\"", ",", "True", ")", ",", "\n", "(", "'arg_list_or_star -> [\"*\"]'", ",", "True", ")", ",", "\n", "(", "\"arg_list_or_star -> [arg_list]\"", ",", "True", ")", ",", "\n", "(", "'between_expr -> [value, \"BETWEEN\", value, \"AND\", value]'", ",", "True", ")", ",", "\n", "(", "\"binary_expr -> [value, binaryop, expr]\"", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"*\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"+\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"-\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"/\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"<\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"<=\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"<>\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"=\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\">\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\">=\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"AND\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"LIKE\"]'", ",", "True", ")", ",", "\n", "(", "'binaryop -> [\"OR\"]'", ",", "True", ")", ",", "\n", "(", "'boolean -> [\"false\"]'", ",", "True", ")", ",", "\n", "(", "'boolean -> [\"true\"]'", ",", "True", ")", ",", "\n", "(", "'col_ref -> [table_name, \".\", column_name]'", ",", "True", ")", ",", "\n", "(", "\"col_ref -> [table_name]\"", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"CITY_NAME\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"COUNTY\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"FOOD_TYPE\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"HOUSE_NUMBER\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"NAME\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"RATING\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"REGION\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"RESTAURANT_ID\"]'", ",", "True", ")", ",", "\n", "(", "'column_name -> [\"STREET_NAME\"]'", ",", "True", ")", ",", "\n", "(", "'expr -> [\"(\", query, \")\"]'", ",", "True", ")", ",", "\n", "(", "\"expr -> [between_expr]\"", ",", "True", ")", ",", "\n", "(", "\"expr -> [binary_expr]\"", ",", "True", ")", ",", "\n", "(", "\"expr -> [in_expr]\"", ",", "True", ")", ",", "\n", "(", "\"expr -> [like_expr]\"", ",", "True", ")", ",", "\n", "(", "\"expr -> [null_check_expr]\"", ",", "True", ")", ",", "\n", "(", "\"expr -> [unary_expr]\"", ",", "True", ")", ",", "\n", "(", "\"expr -> [value]\"", ",", "True", ")", ",", "\n", "(", "'fname -> [\"ALL\"]'", ",", "True", ")", ",", "\n", "(", "'fname -> [\"AVG\"]'", ",", "True", ")", ",", "\n", "(", "'fname -> [\"COUNT\"]'", ",", "True", ")", ",", "\n", "(", "'fname -> [\"MAX\"]'", ",", "True", ")", ",", "\n", "(", "'fname -> [\"MIN\"]'", ",", "True", ")", ",", "\n", "(", "'fname -> [\"SUM\"]'", ",", "True", ")", ",", "\n", "(", "'from_clause -> [\"FROM\", source]'", ",", "True", ")", ",", "\n", "(", "'function -> [fname, \"(\", \"DISTINCT\", arg_list_or_star, \")\"]'", ",", "True", ")", ",", "\n", "(", "'function -> [fname, \"(\", arg_list_or_star, \")\"]'", ",", "True", ")", ",", "\n", "(", "'group_clause -> [expr, \",\" group_clause]'", ",", "True", ")", ",", "\n", "(", "\"group_clause -> [expr]\"", ",", "True", ")", ",", "\n", "(", "'groupby_clause -> [\"GROUP\", \"BY\" group_clause, \"HAVING\", expr]'", ",", "True", ")", ",", "\n", "(", "'groupby_clause -> [\"GROUP\", \"BY\" group_clause]'", ",", "True", ")", ",", "\n", "(", "'in_expr -> [value, \"IN\", expr]'", ",", "True", ")", ",", "\n", "(", "'in_expr -> [value, \"IN\", string_set]'", ",", "True", ")", ",", "\n", "(", "'in_expr -> [value, \"NOT\", \"IN\", expr]'", ",", "True", ")", ",", "\n", "(", "'in_expr -> [value, \"NOT\", \"IN\", string_set]'", ",", "True", ")", ",", "\n", "(", "'like_expr -> [value, \"LIKE\", string]'", ",", "True", ")", ",", "\n", "(", "'limit -> [\"LIMIT\", number]'", ",", "True", ")", ",", "\n", "(", "'null_check_expr -> [col_ref, \"IS\", \"NOT\", \"NULL\"]'", ",", "True", ")", ",", "\n", "(", "'null_check_expr -> [col_ref, \"IS\", \"NULL\"]'", ",", "True", ")", ",", "\n", "(", "'order_clause -> [ordering_term, \",\" order_clause]'", ",", "True", ")", ",", "\n", "(", "\"order_clause -> [ordering_term]\"", ",", "True", ")", ",", "\n", "(", "'orderby_clause -> [\"ORDER\", \"BY\" order_clause]'", ",", "True", ")", ",", "\n", "(", "'ordering -> [\"ASC\"]'", ",", "True", ")", ",", "\n", "(", "'ordering -> [\"DESC\"]'", ",", "True", ")", ",", "\n", "(", "\"ordering_term -> [expr ordering]\"", ",", "True", ")", ",", "\n", "(", "\"ordering_term -> [expr]\"", ",", "True", ")", ",", "\n", "(", "'parenval -> [\"(\", expr, \")\"]'", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core groupby_clause, limit]\"", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core groupby_clause, orderby_clause, limit]\"", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core groupby_clause, orderby_clause]\"", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core groupby_clause]\"", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core orderby_clause, limit]\"", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core orderby_clause]\"", ",", "True", ")", ",", "\n", "(", "\"query -> [select_core]\"", ",", "True", ")", ",", "\n", "(", "\"sel_res_all_star -> ['*']\"", ",", "True", ")", ",", "\n", "(", "'sel_res_tab_star -> [table_name \".*\"]'", ",", "True", ")", ",", "\n", "(", "\"select_core -> [select_with_distinct select_results from_clause where_clause]\"", ",", "True", ")", ",", "\n", "(", "\"select_core -> [select_with_distinct select_results from_clause]\"", ",", "True", ")", ",", "\n", "(", "\"select_core -> [select_with_distinct select_results where_clause]\"", ",", "True", ")", ",", "\n", "(", "\"select_core -> [select_with_distinct select_results]\"", ",", "True", ")", ",", "\n", "(", "\"select_result -> [expr]\"", ",", "True", ")", ",", "\n", "(", "\"select_result -> [sel_res_all_star]\"", ",", "True", ")", ",", "\n", "(", "\"select_result -> [sel_res_tab_star]\"", ",", "True", ")", ",", "\n", "(", "'select_results -> [select_result, \",\", select_results]'", ",", "True", ")", ",", "\n", "(", "\"select_results -> [select_result]\"", ",", "True", ")", ",", "\n", "(", "'select_with_distinct -> [\"SELECT\", \"DISTINCT\"]'", ",", "True", ")", ",", "\n", "(", "'select_with_distinct -> [\"SELECT\"]'", ",", "True", ")", ",", "\n", "(", "'single_source -> [\"(\", query, \")\"]'", ",", "True", ")", ",", "\n", "(", "\"single_source -> [table_name]\"", ",", "True", ")", ",", "\n", "(", "'source -> [single_source, \",\", source]'", ",", "True", ")", ",", "\n", "(", "\"source -> [single_source]\"", ",", "True", ")", ",", "\n", "(", "'statement -> [query, \";\"]'", ",", "True", ")", ",", "\n", "(", "\"statement -> [query]\"", ",", "True", ")", ",", "\n", "(", "\"string -> [\\\"'city_name0'\\\"]\"", ",", "True", ")", ",", "\n", "(", "\"string -> [\\\"'name0'\\\"]\"", ",", "True", ")", ",", "\n", "(", "\"string -> [~\\\"'.*?'\\\"iu]\"", ",", "True", ")", ",", "\n", "(", "'string_set -> [\"(\", string_set_vals, \")\"]'", ",", "True", ")", ",", "\n", "(", "'string_set_vals -> [string, \",\", string_set_vals]'", ",", "True", ")", ",", "\n", "(", "\"string_set_vals -> [string]\"", ",", "True", ")", ",", "\n", "(", "'table_name -> [\"GEOGRAPHIC\"]'", ",", "True", ")", ",", "\n", "(", "'table_name -> [\"LOCATION\"]'", ",", "True", ")", ",", "\n", "(", "'table_name -> [\"RESTAURANT\"]'", ",", "True", ")", ",", "\n", "(", "\"unary_expr -> [unaryop expr]\"", ",", "True", ")", ",", "\n", "(", "'unaryop -> [\"+\"]'", ",", "True", ")", ",", "\n", "(", "'unaryop -> [\"-\"]'", ",", "True", ")", ",", "\n", "(", "'unaryop -> [\"NOT\"]'", ",", "True", ")", ",", "\n", "(", "'unaryop -> [\"not\"]'", ",", "True", ")", ",", "\n", "(", "'value -> [\"2.5\"]'", ",", "True", ")", ",", "\n", "(", "'value -> [\"YEAR(CURDATE())\"]'", ",", "True", ")", ",", "\n", "(", "\"value -> [boolean]\"", ",", "True", ")", ",", "\n", "(", "\"value -> [col_ref]\"", ",", "True", ")", ",", "\n", "(", "\"value -> [function]\"", ",", "True", ")", ",", "\n", "(", "\"value -> [number]\"", ",", "True", ")", ",", "\n", "(", "\"value -> [parenval]\"", ",", "True", ")", ",", "\n", "(", "\"value -> [string]\"", ",", "True", ")", ",", "\n", "(", "'where_clause -> [\"WHERE\", expr where_conj]'", ",", "True", ")", ",", "\n", "(", "'where_clause -> [\"WHERE\", expr]'", ",", "True", ")", ",", "\n", "(", "'where_conj -> [\"AND\", expr where_conj]'", ",", "True", ")", ",", "\n", "(", "'where_conj -> [\"AND\", expr]'", ",", "True", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.template_text2sql_test.TestTemplateText2SqlDatasetReader.test_reader": [[8, 165], ["allennlp_semparse.dataset_readers.TemplateText2SqlDatasetReader", "allennlp_semparse.dataset_readers.TemplateText2SqlDatasetReader.read", "allennlp.common.util.ensure_list", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["    ", "def", "test_reader", "(", "self", ")", ":", "\n", "        ", "reader", "=", "TemplateText2SqlDatasetReader", "(", ")", "\n", "\n", "instances", "=", "reader", ".", "read", "(", "\n", "str", "(", "SemparseTestCase", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"*.json\"", ")", "\n", ")", "\n", "instances", "=", "ensure_list", "(", "instances", ")", "\n", "\n", "fields", "=", "instances", "[", "0", "]", ".", "fields", "\n", "tokens", "=", "[", "t", ".", "text", "for", "t", "in", "fields", "[", "\"tokens\"", "]", ".", "tokens", "]", "\n", "tags", "=", "fields", "[", "\"slot_tags\"", "]", ".", "labels", "\n", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"buttercup\"", ",", "\n", "\"kitchen\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"san\"", ",", "\n", "\"francisco\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "tags", "==", "[", "\"O\"", ",", "\"O\"", ",", "\"name0\"", ",", "\"name0\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"city_name0\"", ",", "\"city_name0\"", ",", "\"O\"", "]", "\n", "assert", "(", "\n", "fields", "[", "\"template\"", "]", ".", "label", "\n", "==", "\"SELECT COUNT ( * ) FROM LOCATION AS LOCATIONalias0 , RESTAURANT \"", "\n", "\"AS RESTAURANTalias0 WHERE LOCATIONalias0 . CITY_NAME = 'city_name0' \"", "\n", "\"AND RESTAURANTalias0 . ID = LOCATIONalias0 . RESTAURANT_ID AND \"", "\n", "\"RESTAURANTalias0 . NAME = 'name0' ;\"", "\n", ")", "\n", "\n", "fields", "=", "instances", "[", "1", "]", ".", "fields", "\n", "tokens", "=", "[", "t", ".", "text", "for", "t", "in", "fields", "[", "\"tokens\"", "]", ".", "tokens", "]", "\n", "tags", "=", "fields", "[", "\"slot_tags\"", "]", ".", "labels", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"chinese\"", ",", "\n", "\"restaurants\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "tags", "==", "[", "\"O\"", ",", "\"O\"", ",", "\"food_type0\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"region0\"", ",", "\"region0\"", ",", "\"O\"", "]", "\n", "assert", "(", "\n", "fields", "[", "\"template\"", "]", ".", "label", "\n", "==", "\"SELECT COUNT ( * ) FROM GEOGRAPHIC AS GEOGRAPHICalias0 , RESTAURANT AS \"", "\n", "\"RESTAURANTalias0 WHERE GEOGRAPHICalias0 . REGION = 'region0' AND \"", "\n", "\"RESTAURANTalias0 . CITY_NAME = GEOGRAPHICalias0 . CITY_NAME AND \"", "\n", "\"RESTAURANTalias0 . FOOD_TYPE = 'food_type0' ;\"", "\n", ")", "\n", "\n", "fields", "=", "instances", "[", "2", "]", ".", "fields", "\n", "tokens", "=", "[", "t", ".", "text", "for", "t", "in", "fields", "[", "\"tokens\"", "]", ".", "tokens", "]", "\n", "tags", "=", "fields", "[", "\"slot_tags\"", "]", ".", "labels", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"places\"", ",", "\n", "\"for\"", ",", "\n", "\"chinese\"", ",", "\n", "\"food\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "tags", "==", "[", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"food_type0\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"region0\"", ",", "\n", "\"region0\"", ",", "\n", "\"O\"", ",", "\n", "]", "\n", "assert", "(", "\n", "fields", "[", "\"template\"", "]", ".", "label", "\n", "==", "\"SELECT COUNT ( * ) FROM GEOGRAPHIC AS GEOGRAPHICalias0 , RESTAURANT AS \"", "\n", "\"RESTAURANTalias0 WHERE GEOGRAPHICalias0 . REGION = 'region0' AND \"", "\n", "\"RESTAURANTalias0 . CITY_NAME = GEOGRAPHICalias0 . CITY_NAME AND \"", "\n", "\"RESTAURANTalias0 . FOOD_TYPE = 'food_type0' ;\"", "\n", ")", "\n", "\n", "fields", "=", "instances", "[", "3", "]", ".", "fields", "\n", "tokens", "=", "[", "t", ".", "text", "for", "t", "in", "fields", "[", "\"tokens\"", "]", ".", "tokens", "]", "\n", "tags", "=", "fields", "[", "\"slot_tags\"", "]", ".", "labels", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"chinese\"", ",", "\n", "\"places\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "tags", "==", "[", "\"O\"", ",", "\"O\"", ",", "\"food_type0\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"region0\"", ",", "\"region0\"", ",", "\"O\"", "]", "\n", "assert", "(", "\n", "fields", "[", "\"template\"", "]", ".", "label", "\n", "==", "\"SELECT COUNT ( * ) FROM GEOGRAPHIC AS GEOGRAPHICalias0 , RESTAURANT AS \"", "\n", "\"RESTAURANTalias0 WHERE GEOGRAPHICalias0 . REGION = 'region0' AND \"", "\n", "\"RESTAURANTalias0 . CITY_NAME = GEOGRAPHICalias0 . CITY_NAME AND \"", "\n", "\"RESTAURANTalias0 . FOOD_TYPE = 'food_type0' ;\"", "\n", ")", "\n", "fields", "=", "instances", "[", "4", "]", ".", "fields", "\n", "tokens", "=", "[", "t", ".", "text", "for", "t", "in", "fields", "[", "\"tokens\"", "]", ".", "tokens", "]", "\n", "tags", "=", "fields", "[", "\"slot_tags\"", "]", ".", "labels", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"places\"", ",", "\n", "\"for\"", ",", "\n", "\"chinese\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "tags", "==", "[", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"food_type0\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"O\"", ",", "\n", "\"region0\"", ",", "\n", "\"region0\"", ",", "\n", "\"O\"", ",", "\n", "]", "\n", "assert", "(", "\n", "fields", "[", "\"template\"", "]", ".", "label", "\n", "==", "\"SELECT COUNT ( * ) FROM GEOGRAPHIC AS GEOGRAPHICalias0 , RESTAURANT AS \"", "\n", "\"RESTAURANTalias0 WHERE GEOGRAPHICalias0 . REGION = 'region0' AND \"", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis_test.TestAtisReader.test_atis_keep_unparseable": [[9, 21], ["allennlp.common.file_utils.cached_path", "allennlp_semparse.dataset_readers.AtisDatasetReader", "allennlp_semparse.dataset_readers.AtisDatasetReader.text_to_instance", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.wikitables.WikiTablesDatasetReader.text_to_instance"], ["    ", "def", "test_atis_keep_unparseable", "(", "self", ")", ":", "\n", "        ", "database_file", "=", "cached_path", "(", "\"https://allennlp.s3.amazonaws.com/datasets/atis/atis.db\"", ")", "\n", "reader", "=", "AtisDatasetReader", "(", "database_file", "=", "database_file", ",", "keep_if_unparseable", "=", "True", ")", "\n", "instance", "=", "reader", ".", "text_to_instance", "(", "\n", "utterances", "=", "[", "\"show me the one way flights from detroit me to westchester county\"", "]", ",", "\n", "sql_query_labels", "=", "[", "\"this is not a query that can be parsed\"", "]", ",", "\n", ")", "\n", "\n", "# If we have a query that can't be parsed, we check that it only has one element in the list", "\n", "# of index fields and that index is the padding index, -1.", "\n", "assert", "len", "(", "instance", ".", "fields", "[", "\"target_action_sequence\"", "]", ".", "field_list", ")", "==", "1", "\n", "assert", "instance", ".", "fields", "[", "\"target_action_sequence\"", "]", ".", "field_list", "[", "0", "]", ".", "sequence_index", "==", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.dataset_readers.atis_test.TestAtisReader.test_atis_read_from_file": [[22, 146], ["allennlp_semparse.dataset_readers.AtisDatasetReader", "list", "isinstance", "allennlp_semparse.dataset_readers.AtisDatasetReader.read", "len", "set", "instance.fields[].as_tensor", "set", "str", "instance.fields.keys"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_atis_read_from_file", "(", "self", ")", ":", "\n", "        ", "data_path", "=", "SemparseTestCase", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"atis\"", "/", "\"sample.json\"", "\n", "database_file", "=", "\"https://allennlp.s3.amazonaws.com/datasets/atis/atis.db\"", "\n", "reader", "=", "AtisDatasetReader", "(", "database_file", "=", "database_file", ")", "\n", "\n", "instances", "=", "list", "(", "reader", ".", "read", "(", "str", "(", "data_path", ")", ")", ")", "\n", "\n", "assert", "len", "(", "instances", ")", "==", "13", "\n", "instance", "=", "instances", "[", "0", "]", "\n", "\n", "assert", "set", "(", "instance", ".", "fields", ".", "keys", "(", ")", ")", "==", "{", "\n", "\"utterance\"", ",", "\n", "\"actions\"", ",", "\n", "\"world\"", ",", "\n", "\"sql_queries\"", ",", "\n", "\"target_action_sequence\"", ",", "\n", "\"linking_scores\"", ",", "\n", "}", "\n", "\n", "assert", "[", "t", ".", "text", "for", "t", "in", "instance", ".", "fields", "[", "\"utterance\"", "]", ".", "tokens", "]", "==", "[", "\n", "\"show\"", ",", "\n", "\"me\"", ",", "\n", "\"the\"", ",", "\n", "\"one\"", ",", "\n", "\"way\"", ",", "\n", "\"flights\"", ",", "\n", "\"from\"", ",", "\n", "\"detroit\"", ",", "\n", "\"to\"", ",", "\n", "\"westchester\"", ",", "\n", "\"county\"", ",", "\n", "]", "\n", "\n", "assert", "isinstance", "(", "instance", ".", "fields", "[", "\"world\"", "]", ".", "as_tensor", "(", "{", "}", ")", ",", "AtisWorld", ")", "\n", "\n", "world", "=", "instance", ".", "fields", "[", "\"world\"", "]", ".", "metadata", "\n", "assert", "set", "(", "world", ".", "valid_actions", "[", "\"number\"", "]", ")", "==", "{", "\n", "'number -> [\"1\"]'", ",", "\n", "'number -> [\"0\"]'", ",", "\n", "'number -> [\"41\"]'", ",", "\n", "'number -> [\"60\"]'", ",", "\n", "}", "\n", "\n", "assert", "world", ".", "linked_entities", "[", "\"string\"", "]", "[", "\"airport_airport_code_string -> [\\\"'DTW'\\\"]\"", "]", "[", "2", "]", "==", "[", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "1", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "]", "# ``detroit`` -> ``DTW``", "\n", "assert", "world", ".", "linked_entities", "[", "\"string\"", "]", "[", "\"flight_stop_stop_airport_string -> [\\\"'DTW'\\\"]\"", "]", "[", "\n", "2", "\n", "]", "==", "[", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "1", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "]", "# ``detroit`` -> ``DTW``", "\n", "assert", "world", ".", "linked_entities", "[", "\"string\"", "]", "[", "\"city_city_code_string -> [\\\"'DDTT'\\\"]\"", "]", "[", "2", "]", "==", "[", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "1", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "]", "# ``detroit`` -> ``DDTT``", "\n", "assert", "world", ".", "linked_entities", "[", "\"string\"", "]", "[", "\"fare_basis_economy_string -> [\\\"'NO'\\\"]\"", "]", "[", "2", "]", "==", "[", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "1", ",", "\n", "1", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "]", "# ``one way`` -> ``NO``", "\n", "assert", "world", ".", "linked_entities", "[", "\"string\"", "]", "[", "\n", "\"city_city_name_string -> [\\\"'WESTCHESTER COUNTY'\\\"]\"", "\n", "]", "[", "2", "]", "==", "[", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "1", ",", "\n", "1", ",", "\n", "]", "# ``westchester county`` -> ``WESTCHESTER COUNTY``", "\n", "assert", "world", ".", "linked_entities", "[", "\"string\"", "]", "[", "\"city_city_code_string -> [\\\"'HHPN'\\\"]\"", "]", "[", "2", "]", "==", "[", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "0", ",", "\n", "1", ",", "\n", "1", ",", "\n", "]", "# ``westchester county`` -> ``HHPN``", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser.__init__": [[59, 118], ["allennlp.nn.initializers.InitializerApplicator", "allennlp.models.model.Model.__init__", "torch.nn.Dropout", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "vocab.get_vocab_size", "allennlp.modules.Embedding", "allennlp.modules.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "allennlp_semparse.state_machines.trainers.MaximumMarginalLikelihood", "allennlp_semparse.state_machines.transition_functions.BasicTransitionFunction", "initializer", "torch.FloatTensor", "torch.FloatTensor", "encoder.get_output_dim", "text2sql_parser.Text2SqlParser._encoder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "utterance_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "decoder_beam_search", ":", "BeamSearch", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "input_attention", ":", "Attention", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "_utterance_embedder", "=", "utterance_embedder", "\n", "self", ".", "_encoder", "=", "encoder", "\n", "self", ".", "_max_decoding_steps", "=", "max_decoding_steps", "\n", "self", ".", "_add_action_bias", "=", "add_action_bias", "\n", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "self", ".", "_exact_match", "=", "Average", "(", ")", "\n", "self", ".", "_valid_sql_query", "=", "Average", "(", ")", "\n", "self", ".", "_action_similarity", "=", "Average", "(", ")", "\n", "self", ".", "_denotation_accuracy", "=", "Average", "(", ")", "\n", "\n", "# the padding value used by IndexField", "\n", "self", ".", "_action_padding_index", "=", "-", "1", "\n", "num_actions", "=", "vocab", ".", "get_vocab_size", "(", "\"rule_labels\"", ")", "\n", "input_action_dim", "=", "action_embedding_dim", "\n", "if", "self", ".", "_add_action_bias", ":", "\n", "            ", "input_action_dim", "+=", "1", "\n", "", "self", ".", "_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "input_action_dim", "\n", ")", "\n", "self", ".", "_output_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "action_embedding_dim", "\n", ")", "\n", "\n", "# This is what we pass as input in the first step of decoding, when we don't have a", "\n", "# previous action, or a previous utterance attention.", "\n", "self", ".", "_first_action_embedding", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "action_embedding_dim", ")", ")", "\n", "self", ".", "_first_attended_utterance", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "encoder", ".", "get_output_dim", "(", ")", ")", "\n", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_action_embedding", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_attended_utterance", ")", "\n", "\n", "self", ".", "_beam_search", "=", "decoder_beam_search", "\n", "self", ".", "_decoder_trainer", "=", "MaximumMarginalLikelihood", "(", "beam_size", "=", "1", ")", "\n", "self", ".", "_transition_function", "=", "BasicTransitionFunction", "(", "\n", "encoder_output_dim", "=", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "input_attention", ",", "\n", "add_action_bias", "=", "self", ".", "_add_action_bias", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser.forward": [[119, 228], ["text2sql_parser.Text2SqlParser._utterance_embedder", "allennlp.nn.util.get_text_field_mask", "text2sql_parser.Text2SqlParser.size", "text2sql_parser.Text2SqlParser._dropout", "text2sql_parser.Text2SqlParser._get_initial_state", "text2sql_parser.Text2SqlParser._encoder", "action_sequence.squeeze.squeeze.squeeze", "text2sql_parser.Text2SqlParser._decoder_trainer.decode", "outputs.update", "text2sql_parser.Text2SqlParser._beam_search.search", "range", "enumerate", "action_mapping.append", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.action_sequence_to_sql", "outputs[].append", "outputs[].append", "outputs[].append", "action_sequence.squeeze.squeeze.unsqueeze", "target_mask.unsqueeze", "range", "text2sql_parser.Text2SqlParser._exact_match", "text2sql_parser.Text2SqlParser._denotation_accuracy", "text2sql_parser.Text2SqlParser._valid_sql_query", "text2sql_parser.Text2SqlParser._action_similarity", "outputs[].append", "text2sql_parser.Text2SqlParser._action_history_match", "text2sql_parser.Text2SqlParser._exact_match", "difflib.SequenceMatcher", "text2sql_parser.Text2SqlParser._action_similarity", "sqlparse.format", "difflib.SequenceMatcher.ratio"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_initial_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.action_sequence_to_sql", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._action_history_match"], ["", "@", "overrides", "\n", "def", "forward", "(", "\n", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "valid_actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "action_sequence", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        We set up the initial state for the decoder, and pass that state off to either a DecoderTrainer,\n        if we're training, or a BeamSearch for inference, if we're not.\n\n        Parameters\n        ----------\n        tokens : Dict[str, torch.LongTensor]\n            The output of ``TextField.as_array()`` applied on the tokens ``TextField``. This will\n            be passed through a ``TextFieldEmbedder`` and then through an encoder.\n        valid_actions : ``List[List[ProductionRule]]``\n            A list of all possible actions for each ``World`` in the batch, indexed into a\n            ``ProductionRule`` using a ``ProductionRuleField``.  We will embed all of these\n            and use the embeddings to determine which action to take at each timestep in the\n            decoder.\n        action_sequence : torch.Tensor, optional (default=None)\n            The action sequence for the correct action sequence, where each action is an index into the list\n            of possible actions.  This tensor has shape ``(batch_size, sequence_length, 1)``. We remove the\n            trailing dimension.\n        \"\"\"", "\n", "embedded_utterance", "=", "self", ".", "_utterance_embedder", "(", "tokens", ")", "\n", "mask", "=", "util", ".", "get_text_field_mask", "(", "tokens", ")", "\n", "batch_size", "=", "embedded_utterance", ".", "size", "(", "0", ")", "\n", "\n", "# (batch_size, num_tokens, encoder_output_dim)", "\n", "encoder_outputs", "=", "self", ".", "_dropout", "(", "self", ".", "_encoder", "(", "embedded_utterance", ",", "mask", ")", ")", "\n", "initial_state", "=", "self", ".", "_get_initial_state", "(", "encoder_outputs", ",", "mask", ",", "valid_actions", ")", "\n", "\n", "if", "action_sequence", "is", "not", "None", ":", "\n", "# Remove the trailing dimension (from ListField[ListField[IndexField]]).", "\n", "            ", "action_sequence", "=", "action_sequence", ".", "squeeze", "(", "-", "1", ")", "\n", "target_mask", "=", "action_sequence", "!=", "self", ".", "_action_padding_index", "\n", "", "else", ":", "\n", "            ", "target_mask", "=", "None", "\n", "\n", "", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "if", "action_sequence", "is", "not", "None", ":", "\n", "# target_action_sequence is of shape (batch_size, 1, target_sequence_length)", "\n", "# here after we unsqueeze it for the MML trainer.", "\n", "            ", "loss_output", "=", "self", ".", "_decoder_trainer", ".", "decode", "(", "\n", "initial_state", ",", "\n", "self", ".", "_transition_function", ",", "\n", "(", "action_sequence", ".", "unsqueeze", "(", "1", ")", ",", "target_mask", ".", "unsqueeze", "(", "1", ")", ")", ",", "\n", ")", "\n", "outputs", ".", "update", "(", "loss_output", ")", "\n", "\n", "", "if", "not", "self", ".", "training", ":", "\n", "            ", "action_mapping", "=", "[", "]", "\n", "for", "batch_actions", "in", "valid_actions", ":", "\n", "                ", "batch_action_mapping", "=", "{", "}", "\n", "for", "action_index", ",", "action", "in", "enumerate", "(", "batch_actions", ")", ":", "\n", "                    ", "batch_action_mapping", "[", "action_index", "]", "=", "action", "[", "0", "]", "\n", "", "action_mapping", ".", "append", "(", "batch_action_mapping", ")", "\n", "\n", "", "outputs", "[", "\"action_mapping\"", "]", "=", "action_mapping", "\n", "# This tells the state to start keeping track of debug info, which we'll pass along in", "\n", "# our output dictionary.", "\n", "initial_state", ".", "debug_info", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "best_final_states", "=", "self", ".", "_beam_search", ".", "search", "(", "\n", "self", ".", "_max_decoding_steps", ",", "\n", "initial_state", ",", "\n", "self", ".", "_transition_function", ",", "\n", "keep_final_unfinished_states", "=", "True", ",", "\n", ")", "\n", "outputs", "[", "\"best_action_sequence\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"debug_info\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"predicted_sql_query\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"sql_queries\"", "]", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# Decoding may not have terminated with any completed valid SQL queries, if `num_steps`", "\n", "# isn't long enough (or if the model is not trained enough and gets into an", "\n", "# infinite action loop).", "\n", "                ", "if", "i", "not", "in", "best_final_states", ":", "\n", "                    ", "self", ".", "_exact_match", "(", "0", ")", "\n", "self", ".", "_denotation_accuracy", "(", "0", ")", "\n", "self", ".", "_valid_sql_query", "(", "0", ")", "\n", "self", ".", "_action_similarity", "(", "0", ")", "\n", "outputs", "[", "\"predicted_sql_query\"", "]", ".", "append", "(", "\"\"", ")", "\n", "continue", "\n", "\n", "", "best_action_indices", "=", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "\n", "\n", "action_strings", "=", "[", "\n", "action_mapping", "[", "i", "]", "[", "action_index", "]", "for", "action_index", "in", "best_action_indices", "\n", "]", "\n", "\n", "predicted_sql_query", "=", "action_sequence_to_sql", "(", "action_strings", ")", "\n", "if", "action_sequence", "is", "not", "None", ":", "\n", "# Use a Tensor, not a Variable, to avoid a memory leak.", "\n", "                    ", "targets", "=", "action_sequence", "[", "i", "]", ".", "data", "\n", "sequence_in_targets", "=", "0", "\n", "sequence_in_targets", "=", "self", ".", "_action_history_match", "(", "best_action_indices", ",", "targets", ")", "\n", "self", ".", "_exact_match", "(", "sequence_in_targets", ")", "\n", "\n", "similarity", "=", "difflib", ".", "SequenceMatcher", "(", "None", ",", "best_action_indices", ",", "targets", ")", "\n", "self", ".", "_action_similarity", "(", "similarity", ".", "ratio", "(", ")", ")", "\n", "\n", "", "outputs", "[", "\"best_action_sequence\"", "]", ".", "append", "(", "action_strings", ")", "\n", "outputs", "[", "\"predicted_sql_query\"", "]", ".", "append", "(", "\n", "sqlparse", ".", "format", "(", "predicted_sql_query", ",", "reindent", "=", "True", ")", "\n", ")", "\n", "outputs", "[", "\"debug_info\"", "]", ".", "append", "(", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "debug_info", "[", "0", "]", ")", "# type: ignore", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser._get_initial_state": [[229, 274], ["encoder_outputs.size", "allennlp.nn.util.get_final_encoder_states", "encoder_outputs.new_zeros", "encoder_outputs.data.new_zeros", "range", "allennlp_semparse.state_machines.states.GrammarBasedState", "text2sql_parser.Text2SqlParser._encoder.is_bidirectional", "text2sql_parser.Text2SqlParser._encoder.get_output_dim", "initial_rnn_state.append", "text2sql_parser.Text2SqlParser._create_grammar_state", "range", "range", "range", "allennlp_semparse.state_machines.states.RnnStatelet", "range", "list", "range", "range"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._create_grammar_state"], ["", "def", "_get_initial_state", "(", "\n", "self", ",", "encoder_outputs", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", "\n", ")", "->", "GrammarBasedState", ":", "\n", "\n", "        ", "batch_size", "=", "encoder_outputs", ".", "size", "(", "0", ")", "\n", "# This will be our initial hidden state and memory cell for the decoder LSTM.", "\n", "final_encoder_output", "=", "util", ".", "get_final_encoder_states", "(", "\n", "encoder_outputs", ",", "mask", ",", "self", ".", "_encoder", ".", "is_bidirectional", "(", ")", "\n", ")", "\n", "memory_cell", "=", "encoder_outputs", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ")", "\n", "initial_score", "=", "encoder_outputs", ".", "data", ".", "new_zeros", "(", "batch_size", ")", "\n", "\n", "# To make grouping states together in the decoder easier, we convert the batch dimension in", "\n", "# all of our tensors into an outer list.  For instance, the encoder outputs have shape", "\n", "# `(batch_size, utterance_length, encoder_output_dim)`.  We need to convert this into a list", "\n", "# of `batch_size` tensors, each of shape `(utterance_length, encoder_output_dim)`.  Then we", "\n", "# won't have to do any index selects, or anything, we'll just do some `torch.cat()`s.", "\n", "initial_score_list", "=", "[", "initial_score", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "encoder_output_list", "=", "[", "encoder_outputs", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "utterance_mask_list", "=", "[", "mask", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_rnn_state", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "initial_rnn_state", ".", "append", "(", "\n", "RnnStatelet", "(", "\n", "final_encoder_output", "[", "i", "]", ",", "\n", "memory_cell", "[", "i", "]", ",", "\n", "self", ".", "_first_action_embedding", ",", "\n", "self", ".", "_first_attended_utterance", ",", "\n", "encoder_output_list", ",", "\n", "utterance_mask_list", ",", "\n", ")", "\n", ")", "\n", "\n", "", "initial_grammar_state", "=", "[", "self", ".", "_create_grammar_state", "(", "actions", "[", "i", "]", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "initial_state", "=", "GrammarBasedState", "(", "\n", "batch_indices", "=", "list", "(", "range", "(", "batch_size", ")", ")", ",", "\n", "action_history", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "\n", "score", "=", "initial_score_list", ",", "\n", "rnn_state", "=", "initial_rnn_state", ",", "\n", "grammar_state", "=", "initial_grammar_state", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "debug_info", "=", "None", ",", "\n", ")", "\n", "return", "initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser._action_history_match": [[275, 285], ["targets.new_tensor", "targets.new_tensor.equal", "len", "targets.size", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_action_history_match", "(", "predicted", ":", "List", "[", "int", "]", ",", "targets", ":", "torch", ".", "LongTensor", ")", "->", "int", ":", "\n", "# TODO(mattg): this could probably be moved into a FullSequenceMatch metric, or something.", "\n", "# Check if target is big enough to cover prediction (including start/end symbols)", "\n", "        ", "if", "len", "(", "predicted", ")", ">", "targets", ".", "size", "(", "0", ")", ":", "\n", "            ", "return", "0", "\n", "", "predicted_tensor", "=", "targets", ".", "new_tensor", "(", "predicted", ")", "\n", "targets_trimmed", "=", "targets", "[", ":", "len", "(", "predicted", ")", "]", "\n", "# Return 1 if the predicted sequence is anywhere in the list of targets.", "\n", "return", "predicted_tensor", ".", "equal", "(", "targets_trimmed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser.is_nonterminal": [[286, 291], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_nonterminal", "(", "token", ":", "str", ")", ":", "\n", "        ", "if", "token", "[", "0", "]", "==", "'\"'", "and", "token", "[", "-", "1", "]", "==", "'\"'", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser.get_metrics": [[292, 325], ["text2sql_parser.Text2SqlParser._exact_match.get_metric", "text2sql_parser.Text2SqlParser._denotation_accuracy.get_metric", "text2sql_parser.Text2SqlParser._valid_sql_query.get_metric", "text2sql_parser.Text2SqlParser._action_similarity.get_metric"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        We track four metrics here:\n\n            1. exact_match, which is the percentage of the time that our best output action sequence\n            matches the SQL query exactly.\n\n            2. denotation_acc, which is the percentage of examples where we get the correct\n            denotation.  This is the typical \"accuracy\" metric, and it is what you should usually\n            report in an experimental result.  You need to be careful, though, that you're\n            computing this on the full data, and not just the subset that can be parsed. (make sure\n            you pass \"keep_if_unparseable=True\" to the dataset reader, which we do for validation data,\n            but not training data).\n\n            3. valid_sql_query, which is the percentage of time that decoding actually produces a\n            valid SQL query.  We might not produce a valid SQL query if the decoder gets\n            into a repetitive loop, or we're trying to produce a super long SQL query and run\n            out of time steps, or something.\n\n            4. action_similarity, which is how similar the action sequence predicted is to the actual\n            action sequence. This is basically a soft measure of exact_match.\n        \"\"\"", "\n", "\n", "validation_correct", "=", "self", ".", "_exact_match", ".", "_total_value", "\n", "validation_total", "=", "self", ".", "_exact_match", ".", "_count", "\n", "return", "{", "\n", "\"_exact_match_count\"", ":", "validation_correct", ",", "\n", "\"_example_count\"", ":", "validation_total", ",", "\n", "\"exact_match\"", ":", "self", ".", "_exact_match", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"denotation_acc\"", ":", "self", ".", "_denotation_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"valid_sql_query\"", ":", "self", ".", "_valid_sql_query", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"action_similarity\"", ":", "self", ".", "_action_similarity", ".", "get_metric", "(", "reset", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser._create_grammar_state": [[327, 385], ["allennlp.nn.util.get_device_of", "collections.defaultdict", "enumerate", "actions_grouped_by_nonterminal.items", "allennlp_semparse.state_machines.states.GrammarStatelet", "actions_grouped_by_nonterminal[].append", "ValueError", "global_actions.append", "zip", "torch.cat().long", "text2sql_parser.Text2SqlParser._action_embedder", "text2sql_parser.Text2SqlParser._output_action_embedder", "global_action_tensor.to.to.to", "list", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_create_grammar_state", "(", "self", ",", "possible_actions", ":", "List", "[", "ProductionRule", "]", ")", "->", "GrammarStatelet", ":", "\n", "        ", "\"\"\"\n        This method creates the GrammarStatelet object that's used for decoding.  Part of creating\n        that is creating the `valid_actions` dictionary, which contains embedded representations of\n        all of the valid actions.  So, we create that here as well.\n\n        The inputs to this method are for a `single instance in the batch`; none of the tensors we\n        create here are batched.  We grab the global action ids from the input\n        ``ProductionRules``, and we use those to embed the valid actions for every\n        non-terminal type.  We use the input ``linking_scores`` for non-global actions.\n\n        Parameters\n        ----------\n        possible_actions : ``List[ProductionRule]``\n            From the input to ``forward`` for a single batch instance.\n        \"\"\"", "\n", "device", "=", "util", ".", "get_device_of", "(", "self", ".", "_action_embedder", ".", "weight", ")", "\n", "# TODO(Mark): This type is pure \\(- . ^)/", "\n", "translated_valid_actions", ":", "Dict", "[", "\n", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", "\n", "]", "=", "{", "}", "\n", "\n", "actions_grouped_by_nonterminal", ":", "Dict", "[", "str", ",", "List", "[", "Tuple", "[", "ProductionRule", ",", "int", "]", "]", "]", "=", "defaultdict", "(", "\n", "list", "\n", ")", "\n", "for", "i", ",", "action", "in", "enumerate", "(", "possible_actions", ")", ":", "\n", "            ", "if", "action", ".", "rule", "==", "\"\"", ":", "\n", "                ", "continue", "\n", "", "if", "action", ".", "is_global_rule", ":", "\n", "                ", "actions_grouped_by_nonterminal", "[", "action", ".", "nonterminal", "]", ".", "append", "(", "(", "action", ",", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"The sql parser doesn't support non-global actions yet.\"", ")", "\n", "\n", "", "", "for", "key", ",", "production_rule_arrays", "in", "actions_grouped_by_nonterminal", ".", "items", "(", ")", ":", "\n", "            ", "translated_valid_actions", "[", "key", "]", "=", "{", "}", "\n", "# `key` here is a non-terminal from the grammar, and `action_strings` are all the valid", "\n", "# productions of that non-terminal.  We'll first split those productions by global vs.", "\n", "# linked action.", "\n", "global_actions", "=", "[", "]", "\n", "for", "production_rule_array", ",", "action_index", "in", "production_rule_arrays", ":", "\n", "                ", "global_actions", ".", "append", "(", "(", "production_rule_array", ".", "rule_id", ",", "action_index", ")", ")", "\n", "\n", "", "if", "global_actions", ":", "\n", "                ", "global_action_tensors", ",", "global_action_ids", "=", "zip", "(", "*", "global_actions", ")", "\n", "global_action_tensor", "=", "torch", ".", "cat", "(", "global_action_tensors", ",", "dim", "=", "0", ")", ".", "long", "(", ")", "\n", "if", "device", ">=", "0", ":", "\n", "                    ", "global_action_tensor", "=", "global_action_tensor", ".", "to", "(", "device", ")", "\n", "\n", "", "global_input_embeddings", "=", "self", ".", "_action_embedder", "(", "global_action_tensor", ")", "\n", "global_output_embeddings", "=", "self", ".", "_output_action_embedder", "(", "global_action_tensor", ")", "\n", "\n", "translated_valid_actions", "[", "key", "]", "[", "\"global\"", "]", "=", "(", "\n", "global_input_embeddings", ",", "\n", "global_output_embeddings", ",", "\n", "list", "(", "global_action_ids", ")", ",", "\n", ")", "\n", "", "", "return", "GrammarStatelet", "(", "\n", "[", "\"statement\"", "]", ",", "translated_valid_actions", ",", "self", ".", "is_nonterminal", ",", "reverse_productions", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser.Text2SqlParser.make_output_human_readable": [[387, 425], ["enumerate", "zip", "zip", "batch_action_info.append", "zip", "actions.sort", "zip", "action_debug_info.get", "instance_action_info.append", "actions.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "make_output_human_readable", "(", "\n", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        This method overrides ``Model.decode``, which gets called after ``Model.forward``, at test\n        time, to finalize predictions.  This is (confusingly) a separate notion from the \"decoder\"\n        in \"encoder/decoder\", where that decoder logic lives in ``TransitionFunction``.\n\n        This method trims the output predictions to the first end symbol, replaces indices with\n        corresponding tokens, and adds a field called ``predicted_actions`` to the ``output_dict``.\n        \"\"\"", "\n", "action_mapping", "=", "output_dict", "[", "\"action_mapping\"", "]", "\n", "best_actions", "=", "output_dict", "[", "\"best_action_sequence\"", "]", "\n", "debug_infos", "=", "output_dict", "[", "\"debug_info\"", "]", "\n", "batch_action_info", "=", "[", "]", "\n", "for", "batch_index", ",", "(", "predicted_actions", ",", "debug_info", ")", "in", "enumerate", "(", "\n", "zip", "(", "best_actions", ",", "debug_infos", ")", "\n", ")", ":", "\n", "            ", "instance_action_info", "=", "[", "]", "\n", "for", "predicted_action", ",", "action_debug_info", "in", "zip", "(", "predicted_actions", ",", "debug_info", ")", ":", "\n", "                ", "action_info", "=", "{", "}", "\n", "action_info", "[", "\"predicted_action\"", "]", "=", "predicted_action", "\n", "considered_actions", "=", "action_debug_info", "[", "\"considered_actions\"", "]", "\n", "probabilities", "=", "action_debug_info", "[", "\"probabilities\"", "]", "\n", "actions", "=", "[", "]", "\n", "for", "action", ",", "probability", "in", "zip", "(", "considered_actions", ",", "probabilities", ")", ":", "\n", "                    ", "if", "action", "!=", "-", "1", ":", "\n", "                        ", "actions", ".", "append", "(", "(", "action_mapping", "[", "batch_index", "]", "[", "action", "]", ",", "probability", ")", ")", "\n", "", "", "actions", ".", "sort", "(", ")", "\n", "considered_actions", ",", "probabilities", "=", "zip", "(", "*", "actions", ")", "\n", "action_info", "[", "\"considered_actions\"", "]", "=", "considered_actions", "\n", "action_info", "[", "\"action_probabilities\"", "]", "=", "probabilities", "\n", "action_info", "[", "\"utterance_attention\"", "]", "=", "action_debug_info", ".", "get", "(", "\"question_attention\"", ",", "[", "]", ")", "\n", "instance_action_info", ".", "append", "(", "action_info", ")", "\n", "", "batch_action_info", ".", "append", "(", "instance_action_info", ")", "\n", "", "output_dict", "[", "\"predicted_actions\"", "]", "=", "batch_action_info", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser_test.TestText2SqlParser.setup_method": [[9, 17], ["super().setup_method", "text2sql_parser_test.TestText2SqlParser.set_up_model", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "\n", "self", ".", "set_up_model", "(", "\n", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"text2sql\"", "/", "\"experiment.json\"", ")", ",", "\n", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants_tiny.json\"", ")", ",", "\n", ")", "\n", "self", ".", "schema", "=", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants-schema.csv\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser_test.TestText2SqlParser.test_model_can_train_save_and_load": [[18, 20], ["text2sql_parser_test.TestText2SqlParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "def", "test_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.models.text2sql_parser_test.TestText2SqlParser.test_grammar_statelet": [[21, 34], ["allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld", "allennlp_semparse.parsimonious_languages.worlds.text2sql_world.Text2SqlWorld.get_action_sequence_and_all_actions", "allennlp_semparse.state_machines.states.GrammarStatelet", "grammar_state.take_action.take_action.take_action"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.worlds.text2sql_world.Text2SqlWorld.get_action_sequence_and_all_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["", "def", "test_grammar_statelet", "(", "self", ")", ":", "\n", "        ", "valid_actions", "=", "None", "\n", "world", "=", "Text2SqlWorld", "(", "self", ".", "schema", ")", "\n", "\n", "sql", "=", "[", "\"SELECT\"", ",", "\"COUNT\"", ",", "\"(\"", ",", "\"*\"", ",", "\")\"", ",", "\"FROM\"", ",", "\"LOCATION\"", ",", "\",\"", ",", "\"RESTAURANT\"", ",", "\";\"", "]", "\n", "action_sequence", ",", "valid_actions", "=", "world", ".", "get_action_sequence_and_all_actions", "(", "sql", ")", "\n", "\n", "grammar_state", "=", "GrammarStatelet", "(", "\n", "[", "\"statement\"", "]", ",", "valid_actions", ",", "Text2SqlParser", ".", "is_nonterminal", ",", "reverse_productions", "=", "True", "\n", ")", "\n", "for", "action", "in", "action_sequence", ":", "\n", "            ", "grammar_state", "=", "grammar_state", ".", "take_action", "(", "action", ")", "\n", "", "assert", "grammar_state", ".", "_nonterminal_stack", "==", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.__init__": [[68, 138], ["allennlp.models.model.Model.__init__", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp_semparse.parsimonious_languages.executors.SqlExecutor", "vocab.get_vocab_size", "allennlp.modules.Embedding", "allennlp.modules.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "allennlp.modules.Embedding", "allennlp_semparse.state_machines.trainers.MaximumMarginalLikelihood", "allennlp_semparse.state_machines.transition_functions.LinkingTransitionFunction", "torch.nn.Dropout", "torch.FloatTensor", "torch.FloatTensor", "encoder.get_output_dim", "atis_semantic_parser.AtisSemanticParser._encoder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "utterance_embedder", ":", "TextFieldEmbedder", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "decoder_beam_search", ":", "BeamSearch", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "input_attention", ":", "Attention", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "training_beam_size", ":", "int", "=", "None", ",", "\n", "decoder_num_layers", ":", "int", "=", "1", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "rule_namespace", ":", "str", "=", "\"rule_labels\"", ",", "\n", "database_file", "=", "\"/atis/atis.db\"", ",", "\n", ")", "->", "None", ":", "\n", "# Atis semantic parser init", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "_utterance_embedder", "=", "utterance_embedder", "\n", "self", ".", "_encoder", "=", "encoder", "\n", "self", ".", "_max_decoding_steps", "=", "max_decoding_steps", "\n", "self", ".", "_add_action_bias", "=", "add_action_bias", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dropout", "=", "lambda", "x", ":", "x", "\n", "", "self", ".", "_rule_namespace", "=", "rule_namespace", "\n", "self", ".", "_exact_match", "=", "Average", "(", ")", "\n", "self", ".", "_valid_sql_query", "=", "Average", "(", ")", "\n", "self", ".", "_action_similarity", "=", "Average", "(", ")", "\n", "self", ".", "_denotation_accuracy", "=", "Average", "(", ")", "\n", "\n", "self", ".", "_executor", "=", "SqlExecutor", "(", "database_file", ")", "\n", "self", ".", "_action_padding_index", "=", "-", "1", "# the padding value used by IndexField", "\n", "num_actions", "=", "vocab", ".", "get_vocab_size", "(", "self", ".", "_rule_namespace", ")", "\n", "if", "self", ".", "_add_action_bias", ":", "\n", "            ", "input_action_dim", "=", "action_embedding_dim", "+", "1", "\n", "", "else", ":", "\n", "            ", "input_action_dim", "=", "action_embedding_dim", "\n", "", "self", ".", "_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "input_action_dim", "\n", ")", "\n", "self", ".", "_output_action_embedder", "=", "Embedding", "(", "\n", "num_embeddings", "=", "num_actions", ",", "embedding_dim", "=", "action_embedding_dim", "\n", ")", "\n", "\n", "# This is what we pass as input in the first step of decoding, when we don't have a", "\n", "# previous action, or a previous utterance attention.", "\n", "self", ".", "_first_action_embedding", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "action_embedding_dim", ")", ")", "\n", "self", ".", "_first_attended_utterance", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "encoder", ".", "get_output_dim", "(", ")", ")", "\n", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_action_embedding", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "_first_attended_utterance", ")", "\n", "\n", "self", ".", "_num_entity_types", "=", "2", "# TODO(kevin): get this in a more principled way somehow?", "\n", "self", ".", "_entity_type_decoder_embedding", "=", "Embedding", "(", "\n", "num_embeddings", "=", "self", ".", "_num_entity_types", ",", "embedding_dim", "=", "action_embedding_dim", "\n", ")", "\n", "self", ".", "_decoder_num_layers", "=", "decoder_num_layers", "\n", "\n", "self", ".", "_beam_search", "=", "decoder_beam_search", "\n", "self", ".", "_decoder_trainer", "=", "MaximumMarginalLikelihood", "(", "training_beam_size", ")", "\n", "self", ".", "_transition_function", "=", "LinkingTransitionFunction", "(", "\n", "encoder_output_dim", "=", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "input_attention", ",", "\n", "add_action_bias", "=", "self", ".", "_add_action_bias", ",", "\n", "dropout", "=", "dropout", ",", "\n", "num_layers", "=", "self", ".", "_decoder_num_layers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.forward": [[140, 274], ["atis_semantic_parser.AtisSemanticParser._get_initial_state", "target_action_sequence.squeeze.squeeze.squeeze", "atis_semantic_parser.AtisSemanticParser._decoder_trainer.decode", "enumerate", "atis_semantic_parser.AtisSemanticParser._beam_search.search", "range", "enumerate", "allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.action_sequence_to_sql", "outputs[].append", "outputs[].append", "outputs[].append", "outputs[].append", "outputs[].append", "outputs[].append", "target_action_sequence.squeeze.squeeze.unsqueeze", "target_mask.unsqueeze", "atis_semantic_parser.AtisSemanticParser._decoder_trainer.decode", "range", "atis_semantic_parser.AtisSemanticParser._exact_match", "atis_semantic_parser.AtisSemanticParser._denotation_accuracy", "atis_semantic_parser.AtisSemanticParser._valid_sql_query", "atis_semantic_parser.AtisSemanticParser._action_similarity", "outputs[].append", "atis_semantic_parser.AtisSemanticParser._action_history_match", "atis_semantic_parser.AtisSemanticParser._exact_match", "difflib.SequenceMatcher", "atis_semantic_parser.AtisSemanticParser._action_similarity", "atis_semantic_parser.AtisSemanticParser._executor.evaluate_sql_query", "atis_semantic_parser.AtisSemanticParser._denotation_accuracy", "outputs[].append", "sqlparse.format", "difflib.SequenceMatcher.ratio", "target_action_sequence.squeeze.squeeze.unsqueeze", "target_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_initial_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.action_sequence_to_sql", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._action_history_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.executors.sql_executor.SqlExecutor.evaluate_sql_query", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "forward", "(", "\n", "self", ",", "# type: ignore", "\n", "utterance", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "world", ":", "List", "[", "AtisWorld", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "linking_scores", ":", "torch", ".", "Tensor", ",", "\n", "target_action_sequence", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "sql_queries", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        We set up the initial state for the decoder, and pass that state off to either a DecoderTrainer,\n        if we're training, or a BeamSearch for inference, if we're not.\n\n        Parameters\n        ----------\n        utterance : Dict[str, torch.LongTensor]\n            The output of ``TextField.as_array()`` applied on the utterance ``TextField``. This will\n            be passed through a ``TextFieldEmbedder`` and then through an encoder.\n        world : ``List[AtisWorld]``\n            We use a ``MetadataField`` to get the ``World`` for each input instance.  Because of\n            how ``MetadataField`` works, this gets passed to us as a ``List[AtisWorld]``,\n        actions : ``List[List[ProductionRule]]``\n            A list of all possible actions for each ``World`` in the batch, indexed into a\n            ``ProductionRule`` using a ``ProductionRuleField``.  We will embed all of these\n            and use the embeddings to determine which action to take at each timestep in the\n            decoder.\n        linking_scores: ``torch.Tensor``\n            A matrix of the linking the utterance tokens and the entities. This is a binary matrix that\n            is deterministically generated where each entry indicates whether a token generated an entity.\n            This tensor has shape ``(batch_size, num_entities, num_utterance_tokens)``.\n        target_action_sequence : torch.Tensor, optional (default=None)\n            The action sequence for the correct action sequence, where each action is an index into the list\n            of possible actions.  This tensor has shape ``(batch_size, sequence_length, 1)``. We remove the\n            trailing dimension.\n        sql_queries : List[List[str]], optional (default=None)\n            A list of the SQL queries that are given during training or validation.\n        \"\"\"", "\n", "initial_state", "=", "self", ".", "_get_initial_state", "(", "utterance", ",", "world", ",", "actions", ",", "linking_scores", ")", "\n", "batch_size", "=", "linking_scores", ".", "shape", "[", "0", "]", "\n", "if", "target_action_sequence", "is", "not", "None", ":", "\n", "# Remove the trailing dimension (from ListField[ListField[IndexField]]).", "\n", "            ", "target_action_sequence", "=", "target_action_sequence", ".", "squeeze", "(", "-", "1", ")", "\n", "target_mask", "=", "target_action_sequence", "!=", "self", ".", "_action_padding_index", "\n", "", "else", ":", "\n", "            ", "target_mask", "=", "None", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "# target_action_sequence is of shape (batch_size, 1, sequence_length) here after we unsqueeze it for", "\n", "# the MML trainer.", "\n", "            ", "return", "self", ".", "_decoder_trainer", ".", "decode", "(", "\n", "initial_state", ",", "\n", "self", ".", "_transition_function", ",", "\n", "(", "target_action_sequence", ".", "unsqueeze", "(", "1", ")", ",", "target_mask", ".", "unsqueeze", "(", "1", ")", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "# TODO(kevin) Move some of this functionality to a separate method for computing validation outputs.", "\n", "            ", "action_mapping", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_actions", "in", "enumerate", "(", "actions", ")", ":", "\n", "                ", "for", "action_index", ",", "action", "in", "enumerate", "(", "batch_actions", ")", ":", "\n", "                    ", "action_mapping", "[", "(", "batch_index", ",", "action_index", ")", "]", "=", "action", "[", "0", "]", "\n", "", "", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "\"action_mapping\"", ":", "action_mapping", "}", "\n", "outputs", "[", "\"linking_scores\"", "]", "=", "linking_scores", "\n", "if", "target_action_sequence", "is", "not", "None", ":", "\n", "                ", "outputs", "[", "\"loss\"", "]", "=", "self", ".", "_decoder_trainer", ".", "decode", "(", "\n", "initial_state", ",", "\n", "self", ".", "_transition_function", ",", "\n", "(", "target_action_sequence", ".", "unsqueeze", "(", "1", ")", ",", "target_mask", ".", "unsqueeze", "(", "1", ")", ")", ",", "\n", ")", "[", "\"loss\"", "]", "\n", "", "num_steps", "=", "self", ".", "_max_decoding_steps", "\n", "# This tells the state to start keeping track of debug info, which we'll pass along in", "\n", "# our output dictionary.", "\n", "initial_state", ".", "debug_info", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "best_final_states", "=", "self", ".", "_beam_search", ".", "search", "(", "\n", "num_steps", ",", "\n", "initial_state", ",", "\n", "self", ".", "_transition_function", ",", "\n", "keep_final_unfinished_states", "=", "False", ",", "\n", ")", "\n", "outputs", "[", "\"best_action_sequence\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"debug_info\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"entities\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"predicted_sql_query\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"sql_queries\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"utterance\"", "]", "=", "[", "]", "\n", "outputs", "[", "\"tokenized_utterance\"", "]", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# Decoding may not have terminated with any completed valid SQL queries, if `num_steps`", "\n", "# isn't long enough (or if the model is not trained enough and gets into an", "\n", "# infinite action loop).", "\n", "                ", "if", "i", "not", "in", "best_final_states", ":", "\n", "                    ", "self", ".", "_exact_match", "(", "0", ")", "\n", "self", ".", "_denotation_accuracy", "(", "0", ")", "\n", "self", ".", "_valid_sql_query", "(", "0", ")", "\n", "self", ".", "_action_similarity", "(", "0", ")", "\n", "outputs", "[", "\"predicted_sql_query\"", "]", ".", "append", "(", "\"\"", ")", "\n", "continue", "\n", "\n", "", "best_action_indices", "=", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "\n", "\n", "action_strings", "=", "[", "\n", "action_mapping", "[", "(", "i", ",", "action_index", ")", "]", "for", "action_index", "in", "best_action_indices", "\n", "]", "\n", "predicted_sql_query", "=", "action_sequence_to_sql", "(", "action_strings", ")", "\n", "\n", "if", "target_action_sequence", "is", "not", "None", ":", "\n", "# Use a Tensor, not a Variable, to avoid a memory leak.", "\n", "                    ", "targets", "=", "target_action_sequence", "[", "i", "]", ".", "data", "\n", "sequence_in_targets", "=", "0", "\n", "sequence_in_targets", "=", "self", ".", "_action_history_match", "(", "best_action_indices", ",", "targets", ")", "\n", "self", ".", "_exact_match", "(", "sequence_in_targets", ")", "\n", "\n", "similarity", "=", "difflib", ".", "SequenceMatcher", "(", "None", ",", "best_action_indices", ",", "targets", ")", "\n", "self", ".", "_action_similarity", "(", "similarity", ".", "ratio", "(", ")", ")", "\n", "\n", "", "if", "sql_queries", "and", "sql_queries", "[", "i", "]", ":", "\n", "                    ", "denotation_correct", "=", "self", ".", "_executor", ".", "evaluate_sql_query", "(", "\n", "predicted_sql_query", ",", "sql_queries", "[", "i", "]", "\n", ")", "\n", "self", ".", "_denotation_accuracy", "(", "denotation_correct", ")", "\n", "outputs", "[", "\"sql_queries\"", "]", ".", "append", "(", "sql_queries", "[", "i", "]", ")", "\n", "\n", "", "outputs", "[", "\"utterance\"", "]", ".", "append", "(", "world", "[", "i", "]", ".", "utterances", "[", "-", "1", "]", ")", "\n", "outputs", "[", "\"tokenized_utterance\"", "]", ".", "append", "(", "\n", "[", "token", ".", "text", "for", "token", "in", "world", "[", "i", "]", ".", "tokenized_utterances", "[", "-", "1", "]", "]", "\n", ")", "\n", "outputs", "[", "\"entities\"", "]", ".", "append", "(", "world", "[", "i", "]", ".", "entities", ")", "\n", "outputs", "[", "\"best_action_sequence\"", "]", ".", "append", "(", "action_strings", ")", "\n", "outputs", "[", "\"predicted_sql_query\"", "]", ".", "append", "(", "\n", "sqlparse", ".", "format", "(", "predicted_sql_query", ",", "reindent", "=", "True", ")", "\n", ")", "\n", "outputs", "[", "\"debug_info\"", "]", ".", "append", "(", "best_final_states", "[", "i", "]", "[", "0", "]", ".", "debug_info", "[", "0", "]", ")", "# type: ignore", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_initial_state": [[275, 352], ["atis_semantic_parser.AtisSemanticParser._utterance_embedder", "allennlp.nn.util.get_text_field_mask", "atis_semantic_parser.AtisSemanticParser.size", "max", "atis_semantic_parser.AtisSemanticParser._get_type_vector", "atis_semantic_parser.AtisSemanticParser._dropout", "allennlp.nn.util.get_final_encoder_states", "atis_semantic_parser.AtisSemanticParser.new_zeros", "atis_semantic_parser.AtisSemanticParser.data.new_zeros", "range", "allennlp_semparse.state_machines.states.GrammarBasedState", "atis_semantic_parser.AtisSemanticParser._encoder", "atis_semantic_parser.AtisSemanticParser._encoder.is_bidirectional", "atis_semantic_parser.AtisSemanticParser._encoder.get_output_dim", "atis_semantic_parser.AtisSemanticParser._create_grammar_state", "len", "range", "range", "range", "initial_rnn_state.append", "initial_rnn_state.append", "range", "list", "allennlp_semparse.state_machines.states.RnnStatelet", "allennlp_semparse.state_machines.states.RnnStatelet", "range", "final_encoder_output[].repeat", "memory_cell[].repeat", "range"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_type_vector", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._create_grammar_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "def", "_get_initial_state", "(", "\n", "self", ",", "\n", "utterance", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "worlds", ":", "List", "[", "AtisWorld", "]", ",", "\n", "actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "linking_scores", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "GrammarBasedState", ":", "\n", "        ", "embedded_utterance", "=", "self", ".", "_utterance_embedder", "(", "utterance", ")", "\n", "utterance_mask", "=", "util", ".", "get_text_field_mask", "(", "utterance", ")", "\n", "\n", "batch_size", "=", "embedded_utterance", ".", "size", "(", "0", ")", "\n", "num_entities", "=", "max", "(", "[", "len", "(", "world", ".", "entities", ")", "for", "world", "in", "worlds", "]", ")", "\n", "\n", "# entity_types: tensor with shape (batch_size, num_entities)", "\n", "entity_types", ",", "_", "=", "self", ".", "_get_type_vector", "(", "worlds", ",", "num_entities", ",", "embedded_utterance", ")", "\n", "\n", "# (batch_size, num_utterance_tokens, embedding_dim)", "\n", "encoder_input", "=", "embedded_utterance", "\n", "\n", "# (batch_size, utterance_length, encoder_output_dim)", "\n", "encoder_outputs", "=", "self", ".", "_dropout", "(", "self", ".", "_encoder", "(", "encoder_input", ",", "utterance_mask", ")", ")", "\n", "\n", "# This will be our initial hidden state and memory cell for the decoder LSTM.", "\n", "final_encoder_output", "=", "util", ".", "get_final_encoder_states", "(", "\n", "encoder_outputs", ",", "utterance_mask", ",", "self", ".", "_encoder", ".", "is_bidirectional", "(", ")", "\n", ")", "\n", "memory_cell", "=", "encoder_outputs", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "_encoder", ".", "get_output_dim", "(", ")", ")", "\n", "initial_score", "=", "embedded_utterance", ".", "data", ".", "new_zeros", "(", "batch_size", ")", "\n", "\n", "# To make grouping states together in the decoder easier, we convert the batch dimension in", "\n", "# all of our tensors into an outer list.  For instance, the encoder outputs have shape", "\n", "# `(batch_size, utterance_length, encoder_output_dim)`.  We need to convert this into a list", "\n", "# of `batch_size` tensors, each of shape `(utterance_length, encoder_output_dim)`.  Then we", "\n", "# won't have to do any index selects, or anything, we'll just do some `torch.cat()`s.", "\n", "initial_score_list", "=", "[", "initial_score", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "encoder_output_list", "=", "[", "encoder_outputs", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "utterance_mask_list", "=", "[", "utterance_mask", "[", "i", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "initial_rnn_state", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "self", ".", "_decoder_num_layers", ">", "1", ":", "\n", "                ", "initial_rnn_state", ".", "append", "(", "\n", "RnnStatelet", "(", "\n", "final_encoder_output", "[", "i", "]", ".", "repeat", "(", "self", ".", "_decoder_num_layers", ",", "1", ")", ",", "\n", "memory_cell", "[", "i", "]", ".", "repeat", "(", "self", ".", "_decoder_num_layers", ",", "1", ")", ",", "\n", "self", ".", "_first_action_embedding", ",", "\n", "self", ".", "_first_attended_utterance", ",", "\n", "encoder_output_list", ",", "\n", "utterance_mask_list", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "initial_rnn_state", ".", "append", "(", "\n", "RnnStatelet", "(", "\n", "final_encoder_output", "[", "i", "]", ",", "\n", "memory_cell", "[", "i", "]", ",", "\n", "self", ".", "_first_action_embedding", ",", "\n", "self", ".", "_first_attended_utterance", ",", "\n", "encoder_output_list", ",", "\n", "utterance_mask_list", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "initial_grammar_state", "=", "[", "\n", "self", ".", "_create_grammar_state", "(", "worlds", "[", "i", "]", ",", "actions", "[", "i", "]", ",", "linking_scores", "[", "i", "]", ",", "entity_types", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "initial_state", "=", "GrammarBasedState", "(", "\n", "batch_indices", "=", "list", "(", "range", "(", "batch_size", ")", ")", ",", "\n", "action_history", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "\n", "score", "=", "initial_score_list", ",", "\n", "rnn_state", "=", "initial_rnn_state", ",", "\n", "grammar_state", "=", "initial_grammar_state", ",", "\n", "possible_actions", "=", "actions", ",", "\n", "debug_info", "=", "None", ",", "\n", ")", "\n", "return", "initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._get_type_vector": [[353, 409], ["enumerate", "enumerate", "allennlp.common.util.pad_sequence_to_length", "batch_types.append", "tensor.new_tensor", "types.append", "any", "entity.startswith"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_get_type_vector", "(", "\n", "worlds", ":", "List", "[", "AtisWorld", "]", ",", "num_entities", ":", "int", ",", "tensor", ":", "torch", ".", "Tensor", "=", "None", "\n", ")", "->", "Tuple", "[", "torch", ".", "LongTensor", ",", "Dict", "[", "int", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Produces the encoding for each entity's type. In addition, a map from a flattened entity\n        index to type is returned to combine entity type operations into one method.\n\n        Parameters\n        ----------\n        worlds : ``List[AtisWorld]``\n        num_entities : ``int``\n        tensor : ``torch.Tensor``\n            Used for copying the constructed list onto the right device.\n\n        Returns\n        -------\n        A ``torch.LongTensor`` with shape ``(batch_size, num_entities, num_types)``.\n        entity_types : ``Dict[int, int]``\n            This is a mapping from ((batch_index * num_entities) + entity_index) to entity type id.\n        \"\"\"", "\n", "entity_types", "=", "{", "}", "\n", "batch_types", "=", "[", "]", "\n", "\n", "for", "batch_index", ",", "world", "in", "enumerate", "(", "worlds", ")", ":", "\n", "            ", "types", "=", "[", "]", "\n", "entities", "=", "[", "\n", "(", "\"number\"", ",", "entity", ")", "\n", "if", "any", "(", "\n", "[", "\n", "entity", ".", "startswith", "(", "numeric_nonterminal", ")", "\n", "for", "numeric_nonterminal", "in", "NUMERIC_NONTERMINALS", "\n", "]", "\n", ")", "\n", "else", "(", "\"string\"", ",", "entity", ")", "\n", "for", "entity", "in", "world", ".", "entities", "\n", "]", "\n", "\n", "for", "entity_index", ",", "entity", "in", "enumerate", "(", "entities", ")", ":", "\n", "# We need numbers to be first, then strings, since our entities are going to be", "\n", "# sorted. We do a split by type and then a merge later, and it relies on this sorting.", "\n", "                ", "if", "entity", "[", "0", "]", "==", "\"number\"", ":", "\n", "                    ", "entity_type", "=", "1", "\n", "", "else", ":", "\n", "                    ", "entity_type", "=", "0", "\n", "", "types", ".", "append", "(", "entity_type", ")", "\n", "\n", "# For easier lookups later, we're actually using a _flattened_ version", "\n", "# of (batch_index, entity_index) for the key, because this is how the", "\n", "# linking scores are stored.", "\n", "flattened_entity_index", "=", "batch_index", "*", "num_entities", "+", "entity_index", "\n", "entity_types", "[", "flattened_entity_index", "]", "=", "entity_type", "\n", "", "padded", "=", "pad_sequence_to_length", "(", "types", ",", "num_entities", ",", "lambda", ":", "0", ")", "\n", "batch_types", ".", "append", "(", "padded", ")", "\n", "\n", "", "return", "tensor", ".", "new_tensor", "(", "batch_types", ",", "dtype", "=", "torch", ".", "long", ")", ",", "entity_types", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._action_history_match": [[410, 420], ["targets.new_tensor", "targets.new_tensor.equal", "len", "targets.size", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_action_history_match", "(", "predicted", ":", "List", "[", "int", "]", ",", "targets", ":", "torch", ".", "LongTensor", ")", "->", "int", ":", "\n", "# TODO(mattg): this could probably be moved into a FullSequenceMatch metric, or something.", "\n", "# Check if target is big enough to cover prediction (including start/end symbols)", "\n", "        ", "if", "len", "(", "predicted", ")", ">", "targets", ".", "size", "(", "0", ")", ":", "\n", "            ", "return", "0", "\n", "", "predicted_tensor", "=", "targets", ".", "new_tensor", "(", "predicted", ")", "\n", "targets_trimmed", "=", "targets", "[", ":", "len", "(", "predicted", ")", "]", "\n", "# Return 1 if the predicted sequence is anywhere in the list of targets.", "\n", "return", "predicted_tensor", ".", "equal", "(", "targets_trimmed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.is_nonterminal": [[421, 426], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_nonterminal", "(", "token", ":", "str", ")", ":", "\n", "        ", "if", "token", "[", "0", "]", "==", "'\"'", "and", "token", "[", "-", "1", "]", "==", "'\"'", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.get_metrics": [[427, 455], ["atis_semantic_parser.AtisSemanticParser._exact_match.get_metric", "atis_semantic_parser.AtisSemanticParser._denotation_accuracy.get_metric", "atis_semantic_parser.AtisSemanticParser._valid_sql_query.get_metric", "atis_semantic_parser.AtisSemanticParser._action_similarity.get_metric"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        We track four metrics here:\n\n            1. exact_match, which is the percentage of the time that our best output action sequence\n            matches the SQL query exactly.\n\n            2. denotation_acc, which is the percentage of examples where we get the correct\n            denotation.  This is the typical \"accuracy\" metric, and it is what you should usually\n            report in an experimental result.  You need to be careful, though, that you're\n            computing this on the full data, and not just the subset that can be parsed. (make sure\n            you pass \"keep_if_unparseable=True\" to the dataset reader, which we do for validation data,\n            but not training data).\n\n            3. valid_sql_query, which is the percentage of time that decoding actually produces a\n            valid SQL query.  We might not produce a valid SQL query if the decoder gets\n            into a repetitive loop, or we're trying to produce a super long SQL query and run\n            out of time steps, or something.\n\n            4. action_similarity, which is how similar the action sequence predicted is to the actual\n            action sequence. This is basically a soft measure of exact_match.\n        \"\"\"", "\n", "return", "{", "\n", "\"exact_match\"", ":", "self", ".", "_exact_match", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"denotation_acc\"", ":", "self", ".", "_denotation_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"valid_sql_query\"", ":", "self", ".", "_valid_sql_query", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"action_similarity\"", ":", "self", ".", "_action_similarity", ".", "get_metric", "(", "reset", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser._create_grammar_state": [[457, 547], ["enumerate", "enumerate", "valid_actions.items", "allennlp_semparse.state_machines.states.GrammarStatelet", "zip", "torch.cat().to().long", "atis_semantic_parser.AtisSemanticParser._action_embedder", "atis_semantic_parser.AtisSemanticParser._output_action_embedder", "zip", "atis_semantic_parser.AtisSemanticParser._entity_type_decoder_embedding().to().float", "global_actions.append", "linked_actions.append", "list", "list", "torch.cat().to", "atis_semantic_parser.AtisSemanticParser._entity_type_decoder_embedding().to", "torch.cat", "atis_semantic_parser.AtisSemanticParser._entity_type_decoder_embedding"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_create_grammar_state", "(", "\n", "self", ",", "\n", "world", ":", "AtisWorld", ",", "\n", "possible_actions", ":", "List", "[", "ProductionRule", "]", ",", "\n", "linking_scores", ":", "torch", ".", "Tensor", ",", "\n", "entity_types", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "GrammarStatelet", ":", "\n", "        ", "\"\"\"\n        This method creates the GrammarStatelet object that's used for decoding.  Part of creating\n        that is creating the `valid_actions` dictionary, which contains embedded representations of\n        all of the valid actions.  So, we create that here as well.\n\n        The inputs to this method are for a `single instance in the batch`; none of the tensors we\n        create here are batched.  We grab the global action ids from the input\n        ``ProductionRules``, and we use those to embed the valid actions for every\n        non-terminal type.  We use the input ``linking_scores`` for non-global actions.\n\n        Parameters\n        ----------\n        world : ``AtisWorld``\n            From the input to ``forward`` for a single batch instance.\n        possible_actions : ``List[ProductionRule]``\n            From the input to ``forward`` for a single batch instance.\n        linking_scores : ``torch.Tensor``\n            Assumed to have shape ``(num_entities, num_utterance_tokens)`` (i.e., there is no batch\n            dimension).\n        entity_types : ``torch.Tensor``\n            Assumed to have shape ``(num_entities,)`` (i.e., there is no batch dimension).\n        \"\"\"", "\n", "action_map", "=", "{", "}", "\n", "for", "action_index", ",", "action", "in", "enumerate", "(", "possible_actions", ")", ":", "\n", "            ", "action_string", "=", "action", "[", "0", "]", "\n", "action_map", "[", "action_string", "]", "=", "action_index", "\n", "\n", "", "valid_actions", "=", "world", ".", "valid_actions", "\n", "entity_map", "=", "{", "}", "\n", "entities", ":", "Iterable", "[", "str", "]", "=", "world", ".", "entities", "\n", "\n", "for", "entity_index", ",", "entity", "in", "enumerate", "(", "entities", ")", ":", "\n", "            ", "entity_map", "[", "entity", "]", "=", "entity_index", "\n", "\n", "", "translated_valid_actions", ":", "Dict", "[", "\n", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", "\n", "]", "=", "{", "}", "\n", "for", "key", ",", "action_strings", "in", "valid_actions", ".", "items", "(", ")", ":", "\n", "            ", "translated_valid_actions", "[", "key", "]", "=", "{", "}", "\n", "# `key` here is a non-terminal from the grammar, and `action_strings` are all the valid", "\n", "# productions of that non-terminal.  We'll first split those productions by global vs.", "\n", "# linked action.", "\n", "\n", "action_indices", "=", "[", "action_map", "[", "action_string", "]", "for", "action_string", "in", "action_strings", "]", "\n", "production_rule_arrays", "=", "[", "(", "possible_actions", "[", "index", "]", ",", "index", ")", "for", "index", "in", "action_indices", "]", "\n", "global_actions", "=", "[", "]", "\n", "linked_actions", "=", "[", "]", "\n", "for", "production_rule_array", ",", "action_index", "in", "production_rule_arrays", ":", "\n", "                ", "if", "production_rule_array", "[", "1", "]", ":", "\n", "                    ", "global_actions", ".", "append", "(", "(", "production_rule_array", "[", "2", "]", ",", "action_index", ")", ")", "\n", "", "else", ":", "\n", "                    ", "linked_actions", ".", "append", "(", "(", "production_rule_array", "[", "0", "]", ",", "action_index", ")", ")", "\n", "\n", "", "", "if", "global_actions", ":", "\n", "                ", "global_action_tensors", ",", "global_action_ids", "=", "zip", "(", "*", "global_actions", ")", "\n", "global_action_tensor", "=", "(", "\n", "torch", ".", "cat", "(", "global_action_tensors", ",", "dim", "=", "0", ")", ".", "to", "(", "entity_types", ".", "device", ")", ".", "long", "(", ")", "\n", ")", "\n", "global_input_embeddings", "=", "self", ".", "_action_embedder", "(", "global_action_tensor", ")", "\n", "global_output_embeddings", "=", "self", ".", "_output_action_embedder", "(", "global_action_tensor", ")", "\n", "translated_valid_actions", "[", "key", "]", "[", "\"global\"", "]", "=", "(", "\n", "global_input_embeddings", ",", "\n", "global_output_embeddings", ",", "\n", "list", "(", "global_action_ids", ")", ",", "\n", ")", "\n", "", "if", "linked_actions", ":", "\n", "                ", "linked_rules", ",", "linked_action_ids", "=", "zip", "(", "*", "linked_actions", ")", "\n", "entities", "=", "linked_rules", "\n", "entity_ids", "=", "[", "entity_map", "[", "entity", "]", "for", "entity", "in", "entities", "]", "\n", "entity_linking_scores", "=", "linking_scores", "[", "entity_ids", "]", "\n", "entity_type_tensor", "=", "entity_types", "[", "entity_ids", "]", "\n", "entity_type_embeddings", "=", "(", "\n", "self", ".", "_entity_type_decoder_embedding", "(", "entity_type_tensor", ")", "\n", ".", "to", "(", "entity_types", ".", "device", ")", "\n", ".", "float", "(", ")", "\n", ")", "\n", "translated_valid_actions", "[", "key", "]", "[", "\"linked\"", "]", "=", "(", "\n", "entity_linking_scores", ",", "\n", "entity_type_embeddings", ",", "\n", "list", "(", "linked_action_ids", ")", ",", "\n", ")", "\n", "\n", "", "", "return", "GrammarStatelet", "(", "[", "\"statement\"", "]", ",", "translated_valid_actions", ",", "self", ".", "is_nonterminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser.AtisSemanticParser.make_output_human_readable": [[548, 586], ["enumerate", "zip", "zip", "batch_action_info.append", "zip", "actions.sort", "zip", "action_debug_info.get", "instance_action_info.append", "actions.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "make_output_human_readable", "(", "\n", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        This method overrides ``Model.decode``, which gets called after ``Model.forward``, at test\n        time, to finalize predictions.  This is (confusingly) a separate notion from the \"decoder\"\n        in \"encoder/decoder\", where that decoder logic lives in ``TransitionFunction``.\n\n        This method trims the output predictions to the first end symbol, replaces indices with\n        corresponding tokens, and adds a field called ``predicted_actions`` to the ``output_dict``.\n        \"\"\"", "\n", "action_mapping", "=", "output_dict", "[", "\"action_mapping\"", "]", "\n", "best_actions", "=", "output_dict", "[", "\"best_action_sequence\"", "]", "\n", "debug_infos", "=", "output_dict", "[", "\"debug_info\"", "]", "\n", "batch_action_info", "=", "[", "]", "\n", "for", "batch_index", ",", "(", "predicted_actions", ",", "debug_info", ")", "in", "enumerate", "(", "\n", "zip", "(", "best_actions", ",", "debug_infos", ")", "\n", ")", ":", "\n", "            ", "instance_action_info", "=", "[", "]", "\n", "for", "predicted_action", ",", "action_debug_info", "in", "zip", "(", "predicted_actions", ",", "debug_info", ")", ":", "\n", "                ", "action_info", "=", "{", "}", "\n", "action_info", "[", "\"predicted_action\"", "]", "=", "predicted_action", "\n", "considered_actions", "=", "action_debug_info", "[", "\"considered_actions\"", "]", "\n", "probabilities", "=", "action_debug_info", "[", "\"probabilities\"", "]", "\n", "actions", "=", "[", "]", "\n", "for", "action", ",", "probability", "in", "zip", "(", "considered_actions", ",", "probabilities", ")", ":", "\n", "                    ", "if", "action", "!=", "-", "1", ":", "\n", "                        ", "actions", ".", "append", "(", "(", "action_mapping", "[", "(", "batch_index", ",", "action", ")", "]", ",", "probability", ")", ")", "\n", "", "", "actions", ".", "sort", "(", ")", "\n", "considered_actions", ",", "probabilities", "=", "zip", "(", "*", "actions", ")", "\n", "action_info", "[", "\"considered_actions\"", "]", "=", "considered_actions", "\n", "action_info", "[", "\"action_probabilities\"", "]", "=", "probabilities", "\n", "action_info", "[", "\"utterance_attention\"", "]", "=", "action_debug_info", ".", "get", "(", "\"question_attention\"", ",", "[", "]", ")", "\n", "instance_action_info", ".", "append", "(", "action_info", ")", "\n", "", "batch_action_info", ".", "append", "(", "instance_action_info", ")", "\n", "", "output_dict", "[", "\"predicted_actions\"", "]", "=", "batch_action_info", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_grammar_statelet_test.TestAtisGrammarStatelet.test_atis_grammar_statelet": [[13, 43], ["allennlp_semparse.parsimonious_languages.worlds.AtisWorld", "allennlp_semparse.state_machines.states.GrammarStatelet", "grammar_state.take_action.take_action.take_action"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["    ", "def", "test_atis_grammar_statelet", "(", "self", ")", ":", "\n", "        ", "world", "=", "AtisWorld", "(", "\n", "[", "(", "\"give me all flights from boston to \"", "\"philadelphia next week arriving after lunch\"", ")", "]", "\n", ")", "\n", "action_sequence", "=", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"DISTINCT\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "'col_refs -> [col_ref, \",\", col_refs]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_name\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "]", "\n", "\n", "grammar_state", "=", "GrammarStatelet", "(", "\n", "[", "\"statement\"", "]", ",", "world", ".", "valid_actions", ",", "AtisSemanticParser", ".", "is_nonterminal", "\n", ")", "\n", "for", "action", "in", "action_sequence", ":", "\n", "            ", "grammar_state", "=", "grammar_state", ".", "take_action", "(", "action", ")", "\n", "", "assert", "grammar_state", ".", "_nonterminal_stack", "==", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser_test.TestAtisSemanticParser.setup_method": [[10, 15], ["super().setup_method", "atis_semantic_parser_test.TestAtisSemanticParser.set_up_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "set_up_model", "(", "\n", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"atis\"", "/", "\"experiment.json\"", ")", ",", "\n", "str", "(", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"atis\"", "/", "\"sample.json\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser_test.TestAtisSemanticParser.test_atis_model_can_train_save_and_load": [[17, 20], ["atis_semantic_parser_test.TestAtisSemanticParser.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "@", "flaky", "\n", "def", "test_atis_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.atis.atis_semantic_parser_test.TestAtisSemanticParser.test_action_sequence_to_sql": [[21, 45], ["allennlp_semparse.parsimonious_languages.contexts.sql_context_utils.action_sequence_to_sql"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.contexts.sql_context_utils.action_sequence_to_sql"], ["", "def", "test_action_sequence_to_sql", "(", "self", ")", ":", "\n", "        ", "action_sequence", "=", "[", "\n", "'statement -> [query, \";\"]'", ",", "\n", "'query -> [\"(\", \"SELECT\", distinct, select_results, \"FROM\", table_refs, '", "\n", "'where_clause, \")\"]'", ",", "\n", "'distinct -> [\"DISTINCT\"]'", ",", "\n", "\"select_results -> [col_refs]\"", ",", "\n", "'col_refs -> [col_ref, \",\", col_refs]'", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_code\"]'", ",", "\n", "\"col_refs -> [col_ref]\"", ",", "\n", "'col_ref -> [\"city\", \".\", \"city_name\"]'", ",", "\n", "\"table_refs -> [table_name]\"", ",", "\n", "'table_name -> [\"city\"]'", ",", "\n", "'where_clause -> [\"WHERE\", \"(\", conditions, \")\"]'", ",", "\n", "\"conditions -> [condition]\"", ",", "\n", "\"condition -> [biexpr]\"", ",", "\n", "'biexpr -> [\"city\", \".\", \"city_name\", binaryop, city_city_name_string]'", ",", "\n", "'binaryop -> [\"=\"]'", ",", "\n", "\"city_city_name_string -> [\\\"'BOSTON'\\\"]\"", ",", "\n", "]", "\n", "\n", "sql_query", "=", "action_sequence_to_sql", "(", "action_sequence", ")", "\n", "assert", "(", "\n", "sql_query", "==", "\"( SELECT DISTINCT city . city_code , city . city_name \"", "\n", "\"FROM city WHERE ( city . city_name = 'BOSTON' ) ) ;\"", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.__init__": [[59, 146], ["allennlp_semparse.domain_languages.domain_language.DomainLanguage.__init__", "table_context.get_table_knowledge_graph", "table_context.get_entities_from_question", "wikitables_language.WikiTablesLanguage._function_types.items", "wikitables_language.Row", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_constant", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_predicate", "wikitables_language.WikiTablesLanguage.add_constant", "wikitables_language.WikiTablesLanguage.add_constant", "[].replace", "wikitables_language.WikiTablesLanguage.add_constant", "wikitables_language.WikiTablesLanguage.add_constant", "str", "wikitables_language.WikiTablesLanguage._get_start_types_in_context", "str", "float", "wikitables_language.StringColumn", "allennlp_semparse.domain_languages.domain_language.PredicateType.get_type", "wikitables_language.DateColumn", "wikitables_language.WikiTablesLanguage.add_constant", "type", "column_name.split", "wikitables_language.NumberColumn", "wikitables_language.WikiTablesLanguage.add_constant"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_knowledge_graph", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_entities_from_question", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_start_types_in_context", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant"], ["def", "__init__", "(", "self", ",", "table_context", ":", "TableQuestionContext", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "start_types", "=", "self", ".", "_get_start_types_in_context", "(", "table_context", ")", ")", "\n", "self", ".", "table_context", "=", "table_context", "\n", "self", ".", "table_data", "=", "[", "Row", "(", "row", ")", "for", "row", "in", "table_context", ".", "table_data", "]", "\n", "\n", "column_types", "=", "table_context", ".", "column_types", "\n", "self", ".", "_table_has_string_columns", "=", "False", "\n", "self", ".", "_table_has_date_columns", "=", "False", "\n", "self", ".", "_table_has_number_columns", "=", "False", "\n", "if", "\"string\"", "in", "column_types", ":", "\n", "            ", "self", ".", "add_predicate", "(", "\"filter_in\"", ",", "self", ".", "filter_in", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_not_in\"", ",", "self", ".", "filter_not_in", ")", "\n", "self", ".", "_table_has_string_columns", "=", "True", "\n", "", "if", "\"date\"", "in", "column_types", ":", "\n", "            ", "self", ".", "add_predicate", "(", "\"filter_date_greater\"", ",", "self", ".", "filter_date_greater", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_date_greater_equals\"", ",", "self", ".", "filter_date_greater_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_date_lesser\"", ",", "self", ".", "filter_date_lesser", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_date_lesser_equals\"", ",", "self", ".", "filter_date_lesser_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_date_equals\"", ",", "self", ".", "filter_date_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_date_not_equals\"", ",", "self", ".", "filter_date_not_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"max_date\"", ",", "self", ".", "max_date", ")", "\n", "self", ".", "add_predicate", "(", "\"min_date\"", ",", "self", ".", "min_date", ")", "\n", "# Adding -1 to mapping because we need it for dates where not all three fields are", "\n", "# specified. We want to do this only when the table has a date column. This is because", "\n", "# the knowledge graph is also constructed in such a way that -1 is an entity with date", "\n", "# columns as the neighbors only if any date columns exist in the table.", "\n", "self", ".", "add_constant", "(", "\"-1\"", ",", "-", "1", ",", "type_", "=", "Number", ")", "\n", "self", ".", "_table_has_date_columns", "=", "True", "\n", "", "if", "\"number\"", "in", "column_types", "or", "\"num2\"", "in", "column_types", ":", "\n", "            ", "self", ".", "add_predicate", "(", "\"filter_number_greater\"", ",", "self", ".", "filter_number_greater", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_number_greater_equals\"", ",", "self", ".", "filter_number_greater_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_number_lesser\"", ",", "self", ".", "filter_number_lesser", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_number_lesser_equals\"", ",", "self", ".", "filter_number_lesser_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_number_equals\"", ",", "self", ".", "filter_number_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"filter_number_not_equals\"", ",", "self", ".", "filter_number_not_equals", ")", "\n", "self", ".", "add_predicate", "(", "\"max_number\"", ",", "self", ".", "max_number", ")", "\n", "self", ".", "add_predicate", "(", "\"min_number\"", ",", "self", ".", "min_number", ")", "\n", "self", ".", "add_predicate", "(", "\"average\"", ",", "self", ".", "average", ")", "\n", "self", ".", "add_predicate", "(", "\"sum\"", ",", "self", ".", "sum", ")", "\n", "self", ".", "add_predicate", "(", "\"diff\"", ",", "self", ".", "diff", ")", "\n", "self", ".", "_table_has_number_columns", "=", "True", "\n", "", "if", "\"date\"", "in", "column_types", "or", "\"number\"", "in", "column_types", "or", "\"num2\"", "in", "column_types", ":", "\n", "            ", "self", ".", "add_predicate", "(", "\"argmax\"", ",", "self", ".", "argmax", ")", "\n", "self", ".", "add_predicate", "(", "\"argmin\"", ",", "self", ".", "argmin", ")", "\n", "\n", "", "self", ".", "table_graph", "=", "table_context", ".", "get_table_knowledge_graph", "(", ")", "\n", "\n", "# Adding entities and numbers seen in questions as constants.", "\n", "question_entities", ",", "question_numbers", "=", "table_context", ".", "get_entities_from_question", "(", ")", "\n", "self", ".", "_question_entities", "=", "[", "entity", "for", "entity", ",", "_", "in", "question_entities", "]", "\n", "self", ".", "_question_numbers", "=", "[", "number", "for", "number", ",", "_", "in", "question_numbers", "]", "\n", "for", "entity", "in", "self", ".", "_question_entities", ":", "\n", "# Forcing the type of entities to be List[str] here to ensure that the language deals with the outputs", "\n", "# of select-like statements and constants similarly.", "\n", "            ", "self", ".", "add_constant", "(", "entity", ",", "entity", ",", "type_", "=", "List", "[", "str", "]", ")", "\n", "\n", "", "for", "number", "in", "self", ".", "_question_numbers", ":", "\n", "            ", "self", ".", "add_constant", "(", "str", "(", "number", ")", ",", "float", "(", "number", ")", ",", "type_", "=", "Number", ")", "\n", "\n", "# Keeps track of column name productions so that we can add them to the agenda.", "\n", "", "self", ".", "_column_productions_for_agenda", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "\n", "# Adding column names as constants.", "\n", "for", "column_name", "in", "table_context", ".", "column_names", ":", "\n", "            ", "column_type", "=", "column_name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "replace", "(", "\"_column\"", ",", "\"\"", ")", "\n", "column", ":", "Column", "=", "None", "\n", "if", "column_type", "==", "\"string\"", ":", "\n", "                ", "column", "=", "StringColumn", "(", "column_name", ")", "\n", "", "elif", "column_type", "==", "\"date\"", ":", "\n", "                ", "column", "=", "DateColumn", "(", "column_name", ")", "\n", "self", ".", "add_constant", "(", "column_name", ",", "column", ",", "type_", "=", "ComparableColumn", ")", "\n", "", "elif", "column_type", "in", "{", "\"number\"", ",", "\"num2\"", "}", ":", "\n", "                ", "column", "=", "NumberColumn", "(", "column_name", ")", "\n", "self", ".", "add_constant", "(", "column_name", ",", "column", ",", "type_", "=", "ComparableColumn", ")", "\n", "", "self", ".", "add_constant", "(", "column_name", ",", "column", ",", "type_", "=", "Column", ")", "\n", "self", ".", "add_constant", "(", "column_name", ",", "column", ")", "\n", "column_type_name", "=", "str", "(", "PredicateType", ".", "get_type", "(", "type", "(", "column", ")", ")", ")", "\n", "self", ".", "_column_productions_for_agenda", "[", "\n", "column_name", "\n", "]", "=", "f\"{column_type_name} -> {column_name}\"", "\n", "\n", "# Mapping from terminal strings to productions that produce them.  We use this in the", "\n", "# agenda-related methods, and some models that use this language look at this field to know", "\n", "# how many terminals to plan for.", "\n", "", "self", ".", "terminal_productions", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "for", "name", ",", "types", "in", "self", ".", "_function_types", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "terminal_productions", "[", "name", "]", "=", "\"%s -> %s\"", "%", "(", "types", "[", "0", "]", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_start_types_in_context": [[147, 156], ["set", "start_types.add", "start_types.add", "start_types.add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "", "def", "_get_start_types_in_context", "(", "self", ",", "table_context", ":", "TableQuestionContext", ")", "->", "Set", "[", "Type", "]", ":", "\n", "        ", "start_types", ":", "Set", "[", "Type", "]", "=", "set", "(", ")", "\n", "if", "\"string\"", "in", "table_context", ".", "column_types", ":", "\n", "            ", "start_types", ".", "add", "(", "List", "[", "str", "]", ")", "\n", "", "if", "\"number\"", "in", "table_context", ".", "column_types", "or", "\"num2\"", "in", "table_context", ".", "column_types", ":", "\n", "            ", "start_types", ".", "add", "(", "Number", ")", "\n", "", "if", "\"date\"", "in", "table_context", ".", "column_types", ":", "\n", "            ", "start_types", ".", "add", "(", "Date", ")", "\n", "", "return", "start_types", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda": [[157, 349], ["set", "re.sub", "set", "dict.items", "any", "wikitables_language.WikiTablesLanguage._column_productions_for_agenda.items", "dict", "list", "list", "agenda_items.append", "agenda_items.append", "agenda_items.append", "any", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda.append", "column_name.split", "column_name_with_type.split", "agenda.append", "column_name.split", "entity.replace", "agenda.append", "agenda.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append", "entity.replace", "list.append", "list.append", "tokens_in_column_names.add", "agenda_items.append", "agenda_items.append", "token.isdigit", "agenda_items.append", "agenda_items.append", "len", "int", "int", "agenda_items.append", "agenda_items.append", "agenda_items.append", "agenda_items.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_agenda", "(", "self", ",", "conservative", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns an agenda that can be used guide search.\n\n        Parameters\n        ----------\n        conservative : ``bool``\n            Setting this flag will return a subset of the agenda items that correspond to high\n            confidence lexical matches. You'll need this if you are going to use this agenda to\n            penalize a model for producing logical forms that do not contain some items in it. In\n            that case, you'll want this agenda to have close to perfect precision, at the cost of a\n            lower recall. You may not want to set this flag if you are sorting the output from a\n            search procedure based on how much of this agenda is satisfied.\n        \"\"\"", "\n", "agenda_items", "=", "[", "]", "\n", "question_tokens", "=", "[", "token", ".", "text", "for", "token", "in", "self", ".", "table_context", ".", "question_tokens", "]", "\n", "question", "=", "\" \"", ".", "join", "(", "question_tokens", ")", "\n", "\n", "added_number_filters", "=", "False", "\n", "if", "self", ".", "_table_has_number_columns", ":", "\n", "            ", "if", "\"at least\"", "in", "question", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"filter_number_greater_equals\"", ")", "\n", "", "if", "\"at most\"", "in", "question", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"filter_number_lesser_equals\"", ")", "\n", "\n", "", "comparison_triggers", "=", "[", "\"greater\"", ",", "\"larger\"", ",", "\"more\"", "]", "\n", "if", "any", "(", "f\"no {word} than\"", "in", "question", "for", "word", "in", "comparison_triggers", ")", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"filter_number_lesser_equals\"", ")", "\n", "", "elif", "any", "(", "f\"{word} than\"", "in", "question", "for", "word", "in", "comparison_triggers", ")", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"filter_number_greater\"", ")", "\n", "\n", "# We want to keep track of this because we do not want to add both number and date", "\n", "# filters to the agenda if we want to be conservative.", "\n", "", "if", "agenda_items", ":", "\n", "                ", "added_number_filters", "=", "True", "\n", "", "", "for", "token", "in", "question_tokens", ":", "\n", "            ", "if", "token", "in", "[", "\"next\"", ",", "\"below\"", "]", "or", "(", "token", "==", "\"after\"", "and", "not", "conservative", ")", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"next\"", ")", "\n", "", "if", "token", "in", "[", "\"previous\"", ",", "\"above\"", "]", "or", "(", "token", "==", "\"before\"", "and", "not", "conservative", ")", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"previous\"", ")", "\n", "", "if", "token", "in", "[", "\"first\"", ",", "\"top\"", "]", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"first\"", ")", "\n", "", "if", "token", "in", "[", "\"last\"", ",", "\"bottom\"", "]", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"last\"", ")", "\n", "", "if", "token", "==", "\"same\"", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"same_as\"", ")", "\n", "\n", "", "if", "self", ".", "_table_has_number_columns", ":", "\n", "# \"total\" does not always map to an actual summing operation.", "\n", "                ", "if", "token", "==", "\"total\"", "and", "not", "conservative", ":", "\n", "                    ", "agenda_items", ".", "append", "(", "\"sum\"", ")", "\n", "", "if", "(", "\n", "token", "==", "\"difference\"", "\n", "or", "\"how many more\"", "in", "question", "\n", "or", "\"how much more\"", "in", "question", "\n", ")", ":", "\n", "                    ", "agenda_items", ".", "append", "(", "\"diff\"", ")", "\n", "", "if", "token", "==", "\"average\"", ":", "\n", "                    ", "agenda_items", ".", "append", "(", "\"average\"", ")", "\n", "", "if", "(", "\n", "token", "in", "[", "\"least\"", ",", "\"smallest\"", ",", "\"shortest\"", ",", "\"lowest\"", "]", "\n", "and", "\"at least\"", "not", "in", "question", "\n", ")", ":", "\n", "# This condition is too brittle. But for most logical forms with \"min\", there are", "\n", "# semantically equivalent ones with \"argmin\". The exceptions are rare.", "\n", "                    ", "if", "\"what is the least\"", "not", "in", "question", ":", "\n", "                        ", "agenda_items", ".", "append", "(", "\"argmin\"", ")", "\n", "", "", "if", "(", "\n", "token", "in", "[", "\"most\"", ",", "\"largest\"", ",", "\"highest\"", ",", "\"longest\"", ",", "\"greatest\"", "]", "\n", "and", "\"at most\"", "not", "in", "question", "\n", ")", ":", "\n", "# This condition is too brittle. But for most logical forms with \"max\", there are", "\n", "# semantically equivalent ones with \"argmax\". The exceptions are rare.", "\n", "                    ", "if", "\"what is the most\"", "not", "in", "question", ":", "\n", "                        ", "agenda_items", ".", "append", "(", "\"argmax\"", ")", "\n", "\n", "", "", "", "if", "self", ".", "_table_has_date_columns", ":", "\n", "                ", "if", "token", "in", "MONTH_NUMBERS", "or", "(", "\n", "token", ".", "isdigit", "(", ")", "and", "len", "(", "token", ")", "==", "4", "and", "int", "(", "token", ")", "<", "2100", "and", "int", "(", "token", ")", ">", "1100", "\n", ")", ":", "\n", "# Token is either a month or an year. We'll add date functions.", "\n", "                    ", "if", "not", "added_number_filters", "or", "not", "conservative", ":", "\n", "                        ", "if", "\"after\"", "in", "question_tokens", ":", "\n", "                            ", "agenda_items", ".", "append", "(", "\"filter_date_greater\"", ")", "\n", "", "elif", "\"before\"", "in", "question_tokens", ":", "\n", "                            ", "agenda_items", ".", "append", "(", "\"filter_date_lesser\"", ")", "\n", "", "elif", "\"not\"", "in", "question_tokens", ":", "\n", "                            ", "agenda_items", ".", "append", "(", "\"filter_date_not_equals\"", ")", "\n", "", "else", ":", "\n", "                            ", "agenda_items", ".", "append", "(", "\"filter_date_equals\"", ")", "\n", "\n", "", "", "", "", "if", "\"what is the least\"", "in", "question", "and", "self", ".", "_table_has_number_columns", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"min_number\"", ")", "\n", "", "if", "\"what is the most\"", "in", "question", "and", "self", ".", "_table_has_number_columns", ":", "\n", "                ", "agenda_items", ".", "append", "(", "\"max_number\"", ")", "\n", "", "if", "\"when\"", "in", "question_tokens", "and", "self", ".", "_table_has_date_columns", ":", "\n", "                ", "if", "\"last\"", "in", "question_tokens", ":", "\n", "                    ", "agenda_items", ".", "append", "(", "\"max_date\"", ")", "\n", "", "elif", "\"first\"", "in", "question_tokens", ":", "\n", "                    ", "agenda_items", ".", "append", "(", "\"min_date\"", ")", "\n", "", "else", ":", "\n", "                    ", "agenda_items", ".", "append", "(", "\"select_date\"", ")", "\n", "\n", "", "", "", "if", "\"how many\"", "in", "question", ":", "\n", "            ", "if", "\"sum\"", "not", "in", "agenda_items", "and", "\"average\"", "not", "in", "agenda_items", ":", "\n", "# The question probably just requires counting the rows. But this is not very", "\n", "# accurate. The question could also be asking for a value that is in the table.", "\n", "                ", "agenda_items", ".", "append", "(", "\"count\"", ")", "\n", "", "", "agenda", "=", "[", "]", "\n", "# Adding productions from the global set.", "\n", "for", "agenda_item", "in", "set", "(", "agenda_items", ")", ":", "\n", "# Some agenda items may not be present in the terminal productions because some of these", "\n", "# terminals are table-content specific. For example, if the question triggered \"sum\",", "\n", "# and the table does not have number columns, we should not add \"<r,<f,n>> -> sum\" to", "\n", "# the agenda.", "\n", "            ", "if", "agenda_item", "in", "self", ".", "terminal_productions", ":", "\n", "                ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "agenda_item", "]", ")", "\n", "\n", "", "", "if", "conservative", ":", "\n", "# Some of the columns in the table have multiple types, and thus occur in the KG as", "\n", "# different columns. We do not want to add them all to the agenda if their names,", "\n", "# because it is unlikely that logical forms use them all. In fact, to be conservative,", "\n", "# we won't add any of them. So we'll first identify such column names.", "\n", "            ", "refined_column_productions", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "for", "column_name", ",", "signature", "in", "self", ".", "_column_productions_for_agenda", ".", "items", "(", ")", ":", "\n", "                ", "column_type", ",", "name", "=", "column_name", ".", "split", "(", "\":\"", ")", "\n", "if", "column_type", "==", "\"string_column\"", ":", "\n", "                    ", "if", "(", "\n", "f\"number_column:{name}\"", "not", "in", "self", ".", "_column_productions_for_agenda", "\n", "and", "f\"date_column:{name}\"", "not", "in", "self", ".", "_column_productions_for_agenda", "\n", ")", ":", "\n", "                        ", "refined_column_productions", "[", "column_name", "]", "=", "signature", "\n", "\n", "", "", "elif", "column_type", "==", "\"number_column\"", ":", "\n", "                    ", "if", "(", "\n", "f\"string_column:{name}\"", "not", "in", "self", ".", "_column_productions_for_agenda", "\n", "and", "f\"date_column:{name}\"", "not", "in", "self", ".", "_column_productions_for_agenda", "\n", ")", ":", "\n", "                        ", "refined_column_productions", "[", "column_name", "]", "=", "signature", "\n", "\n", "", "", "else", ":", "\n", "                    ", "if", "(", "\n", "f\"string_column:{name}\"", "not", "in", "self", ".", "_column_productions_for_agenda", "\n", "and", "f\"number_column:{name}\"", "not", "in", "self", ".", "_column_productions_for_agenda", "\n", ")", ":", "\n", "                        ", "refined_column_productions", "[", "column_name", "]", "=", "signature", "\n", "# Similarly, we do not want the same spans in the question to be added to the agenda as", "\n", "# both string and number productions.", "\n", "", "", "", "refined_entities", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "refined_numbers", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "for", "entity", "in", "self", ".", "_question_entities", ":", "\n", "                ", "if", "entity", ".", "replace", "(", "\"string:\"", ",", "\"\"", ")", "not", "in", "self", ".", "_question_numbers", ":", "\n", "                    ", "refined_entities", ".", "append", "(", "entity", ")", "\n", "", "", "for", "number", "in", "self", ".", "_question_numbers", ":", "\n", "                ", "if", "f\"string:{number}\"", "not", "in", "self", ".", "_question_entities", ":", "\n", "                    ", "refined_numbers", ".", "append", "(", "number", ")", "\n", "", "", "", "else", ":", "\n", "            ", "refined_column_productions", "=", "dict", "(", "self", ".", "_column_productions_for_agenda", ")", "\n", "refined_entities", "=", "list", "(", "self", ".", "_question_entities", ")", "\n", "refined_numbers", "=", "list", "(", "self", ".", "_question_numbers", ")", "\n", "\n", "# Adding column names that occur in question.", "\n", "", "question_with_underscores", "=", "\"_\"", ".", "join", "(", "question_tokens", ")", "\n", "normalized_question", "=", "re", ".", "sub", "(", "\"[^a-z0-9_]\"", ",", "\"\"", ",", "question_with_underscores", ")", "\n", "# We keep track of tokens that are in column names being added to the agenda. We will not", "\n", "# add string productions to the agenda if those tokens were already captured as column", "\n", "# names.", "\n", "# Note: If the same string occurs multiple times, this may cause string productions being", "\n", "# omitted from the agenda unnecessarily. That is fine, as we want to err on the side of", "\n", "# adding fewer rules to the agenda.", "\n", "tokens_in_column_names", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "for", "column_name_with_type", ",", "signature", "in", "refined_column_productions", ".", "items", "(", ")", ":", "\n", "            ", "column_name", "=", "column_name_with_type", ".", "split", "(", "\":\"", ")", "[", "1", "]", "\n", "# Underscores ensure that the match is of whole words.", "\n", "if", "f\"_{column_name}_\"", "in", "normalized_question", ":", "\n", "                ", "agenda", ".", "append", "(", "signature", ")", "\n", "for", "token", "in", "column_name", ".", "split", "(", "\"_\"", ")", ":", "\n", "                    ", "tokens_in_column_names", ".", "add", "(", "token", ")", "\n", "\n", "# Adding all productions that lead to entities and numbers extracted from the question.", "\n", "", "", "", "for", "entity", "in", "refined_entities", ":", "\n", "            ", "if", "entity", ".", "replace", "(", "\"string:\"", ",", "\"\"", ")", "not", "in", "tokens_in_column_names", ":", "\n", "                ", "agenda", ".", "append", "(", "f\"List[str] -> {entity}\"", ")", "\n", "\n", "", "", "for", "number", "in", "refined_numbers", ":", "\n", "# The reason we check for the presence of the number in the question again is because", "\n", "# some of these numbers are extracted from number words like month names and ordinals", "\n", "# like \"first\". On looking at some agenda outputs, I found that they hurt more than help", "\n", "# in the agenda.", "\n", "            ", "if", "f\"_{number}_\"", "in", "normalized_question", ":", "\n", "                ", "agenda", ".", "append", "(", "f\"Number -> {number}\"", ")", "\n", "", "", "return", "agenda", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.is_instance_specific_entity": [[350, 364], ["float", "entity_name.startswith"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_instance_specific_entity", "(", "entity_name", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Instance specific entities are column names, strings and numbers. Returns True if the entity\n        is one of those.\n        \"\"\"", "\n", "entity_is_number", "=", "False", "\n", "try", ":", "\n", "            ", "float", "(", "entity_name", ")", "\n", "entity_is_number", "=", "True", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "# Column names start with \"*_column:\", strings start with \"string:\"", "\n", "", "return", "\"_column:\"", "in", "entity_name", "or", "entity_name", ".", "startswith", "(", "\"string:\"", ")", "or", "entity_is_number", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_logical_form": [[365, 377], ["wikitables_language.WikiTablesLanguage.evaluate_denotation", "wikitables_language.WikiTablesLanguage.execute", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_denotation", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "evaluate_logical_form", "(", "self", ",", "logical_form", ":", "str", ",", "target_list", ":", "List", "[", "str", "]", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Takes a logical form, and the list of target values as strings from the original lisp\n        string, and returns True iff the logical form executes to the target list, using the\n        official WikiTableQuestions evaluation script.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "denotation", "=", "self", ".", "execute", "(", "logical_form", ")", "\n", "", "except", "ExecutionError", "as", "error", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Failed to execute: {logical_form}. Error: {error}\"", ")", "\n", "return", "False", "\n", "", "return", "self", ".", "evaluate_denotation", "(", "denotation", ",", "target_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_action_sequence": [[378, 390], ["wikitables_language.WikiTablesLanguage.evaluate_denotation", "wikitables_language.WikiTablesLanguage.execute_action_sequence", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_denotation", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence"], ["", "def", "evaluate_action_sequence", "(", "self", ",", "action_sequence", ":", "List", "[", "str", "]", ",", "target_list", ":", "List", "[", "str", "]", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Similar to ``evaluate_logical_form`` except that it takes an action sequence instead. The reason this is\n        separate is because there is a separate method ``DomainLanguage.execute_action_sequence`` that executes the\n        action sequence directly.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "denotation", "=", "self", ".", "execute_action_sequence", "(", "action_sequence", ")", "\n", "", "except", "ExecutionError", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Failed to execute action sequence: {action_sequence}\"", ")", "\n", "return", "False", "\n", "", "return", "self", ".", "evaluate_denotation", "(", "denotation", ",", "target_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_denotation": [[391, 406], ["allennlp_semparse.common.wikitables.wikitables_evaluator.to_value_list", "isinstance", "allennlp_semparse.common.wikitables.wikitables_evaluator.to_value_list", "allennlp_semparse.common.wikitables.wikitables_evaluator.check_denotation", "allennlp_semparse.common.wikitables.TableQuestionContext.normalize_string", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value_list", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.to_value_list", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.wikitables_evaluator.check_denotation", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.normalize_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "evaluate_denotation", "(", "self", ",", "denotation", ":", "Any", ",", "target_list", ":", "List", "[", "str", "]", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Compares denotation with a target list and returns whether they are both the same according to the official\n        evaluator.\n        \"\"\"", "\n", "normalized_target_list", "=", "[", "\n", "TableQuestionContext", ".", "normalize_string", "(", "value", ")", "for", "value", "in", "target_list", "\n", "]", "\n", "target_value_list", "=", "evaluator", ".", "to_value_list", "(", "normalized_target_list", ")", "\n", "if", "isinstance", "(", "denotation", ",", "list", ")", ":", "\n", "            ", "denotation_list", "=", "[", "str", "(", "denotation_item", ")", "for", "denotation_item", "in", "denotation", "]", "\n", "", "else", ":", "\n", "            ", "denotation_list", "=", "[", "str", "(", "denotation", ")", "]", "\n", "", "denotation_value_list", "=", "evaluator", ".", "to_value_list", "(", "denotation_list", ")", "\n", "return", "evaluator", ".", "check_denotation", "(", "target_value_list", ",", "denotation_value_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.all_rows": [[412, 415], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "all_rows", "(", "self", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "return", "self", ".", "table_data", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.select_string": [[416, 423], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "@", "predicate", "\n", "def", "select_string", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "StringColumn", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Select function takes a list of rows and a column name and returns a list of strings as\n        in cells.\n        \"\"\"", "\n", "return", "[", "str", "(", "row", ".", "values", "[", "column", ".", "name", "]", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.select_number": [[424, 437], ["isinstance", "numbers.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "predicate", "\n", "def", "select_number", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Select function takes a row (as a list) and a column name and returns the number in that\n        column. If multiple rows are given, will return the first number that is not None.\n        \"\"\"", "\n", "numbers", ":", "List", "[", "float", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "float", ")", ":", "\n", "                ", "numbers", ".", "append", "(", "cell_value", ")", "\n", "\n", "", "", "return", "numbers", "[", "0", "]", "if", "numbers", "else", "-", "1", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.select_date": [[438, 450], ["isinstance", "allennlp_semparse.common.Date", "dates.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "predicate", "\n", "def", "select_date", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ")", "->", "Date", ":", "\n", "        ", "\"\"\"\n        Select function takes a row as a list and a column name and returns the date in that column.\n        \"\"\"", "\n", "dates", ":", "List", "[", "Date", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "dates", ".", "append", "(", "cell_value", ")", "\n", "\n", "", "", "return", "dates", "[", "0", "]", "if", "dates", "else", "Date", "(", "-", "1", ",", "-", "1", ",", "-", "1", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.same_as": [[451, 468], ["return_list.append", "isinstance", "type"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type"], ["", "@", "predicate", "\n", "def", "same_as", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "Column", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes a row and a column and returns a list of rows from the full set of rows that contain\n        the same value under the given column as the given row.\n        \"\"\"", "\n", "return_list", ":", "List", "[", "Row", "]", "=", "[", "]", "\n", "if", "not", "rows", ":", "\n", "            ", "return", "return_list", "\n", "", "cell_value", "=", "rows", "[", "0", "]", ".", "values", "[", "column", ".", "name", "]", "\n", "for", "table_row", "in", "self", ".", "table_data", ":", "\n", "            ", "new_cell_value", "=", "table_row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "new_cell_value", "is", "None", "or", "not", "isinstance", "(", "new_cell_value", ",", "type", "(", "cell_value", ")", ")", ":", "\n", "                ", "continue", "\n", "", "if", "new_cell_value", "==", "cell_value", ":", "\n", "                ", "return_list", ".", "append", "(", "table_row", ")", "\n", "", "", "return", "return_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.date": [[469, 476], ["allennlp_semparse.common.Date"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "date", "(", "self", ",", "year", ":", "Number", ",", "month", ":", "Number", ",", "day", ":", "Number", ")", "->", "Date", ":", "\n", "        ", "\"\"\"\n        Takes three numbers and returns a ``Date`` object whose year, month, and day are the three\n        numbers in that order.\n        \"\"\"", "\n", "return", "Date", "(", "year", ",", "month", ",", "day", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.first": [[477, 487], ["logger.warning"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "first", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes an expression that evaluates to a list of rows, and returns the first one in that\n        list.\n        \"\"\"", "\n", "if", "not", "rows", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Trying to get first row from an empty list\"", ")", "\n", "return", "[", "]", "\n", "", "return", "[", "rows", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.last": [[488, 498], ["logger.warning"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "last", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes an expression that evaluates to a list of rows, and returns the last one in that\n        list.\n        \"\"\"", "\n", "if", "not", "rows", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Trying to get last row from an empty list\"", ")", "\n", "return", "[", "]", "\n", "", "return", "[", "rows", "[", "-", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.previous": [[499, 512], ["wikitables_language.WikiTablesLanguage._get_row_index"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_row_index"], ["", "@", "predicate", "\n", "def", "previous", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes an expression that evaluates to a single row, and returns the row that occurs before\n        the input row in the original set of rows. If the input row happens to be the top row, we\n        will return an empty list.\n        \"\"\"", "\n", "if", "not", "rows", ":", "\n", "            ", "return", "[", "]", "\n", "", "input_row_index", "=", "self", ".", "_get_row_index", "(", "rows", "[", "0", "]", ")", "\n", "if", "input_row_index", ">", "0", ":", "\n", "            ", "return", "[", "self", ".", "table_data", "[", "input_row_index", "-", "1", "]", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.next": [[513, 526], ["wikitables_language.WikiTablesLanguage._get_row_index", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_row_index"], ["", "@", "predicate", "\n", "def", "next", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes an expression that evaluates to a single row, and returns the row that occurs after\n        the input row in the original set of rows. If the input row happens to be the last row, we\n        will return an empty list.\n        \"\"\"", "\n", "if", "not", "rows", ":", "\n", "            ", "return", "[", "]", "\n", "", "input_row_index", "=", "self", ".", "_get_row_index", "(", "rows", "[", "0", "]", ")", "\n", "if", "input_row_index", "<", "len", "(", "self", ".", "table_data", ")", "-", "1", "and", "input_row_index", "!=", "-", "1", ":", "\n", "            ", "return", "[", "self", ".", "table_data", "[", "input_row_index", "+", "1", "]", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.count": [[527, 530], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "count", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ")", "->", "Number", ":", "\n", "        ", "return", "len", "(", "rows", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.mode_string": [[531, 543], ["wikitables_language.WikiTablesLanguage._get_most_frequent_values", "all", "allennlp_semparse.common.ExecutionError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_most_frequent_values"], ["", "@", "predicate", "\n", "def", "mode_string", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "StringColumn", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the most frequent values (one or more) under\n        that column in those rows.\n        \"\"\"", "\n", "most_frequent_list", "=", "self", ".", "_get_most_frequent_values", "(", "rows", ",", "column", ")", "\n", "if", "not", "most_frequent_list", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "not", "all", "(", "[", "isinstance", "(", "value", ",", "str", ")", "for", "value", "in", "most_frequent_list", "]", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for mode_string: {most_frequent_list}\"", ")", "\n", "", "return", "most_frequent_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.mode_number": [[544, 557], ["wikitables_language.WikiTablesLanguage._get_most_frequent_values", "isinstance", "allennlp_semparse.common.ExecutionError"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_most_frequent_values"], ["", "@", "predicate", "\n", "def", "mode_number", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the most frequent value under\n        that column in those rows.\n        \"\"\"", "\n", "most_frequent_list", "=", "self", ".", "_get_most_frequent_values", "(", "rows", ",", "column", ")", "\n", "if", "not", "most_frequent_list", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "most_frequent_value", "=", "most_frequent_list", "[", "0", "]", "\n", "if", "not", "isinstance", "(", "most_frequent_value", ",", "Number", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for mode_number: {most_frequent_value}\"", ")", "\n", "", "return", "most_frequent_value", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.mode_date": [[558, 571], ["wikitables_language.WikiTablesLanguage._get_most_frequent_values", "allennlp_semparse.common.Date", "isinstance", "allennlp_semparse.common.ExecutionError"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_most_frequent_values"], ["", "@", "predicate", "\n", "def", "mode_date", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ")", "->", "Date", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the most frequent value under\n        that column in those rows.\n        \"\"\"", "\n", "most_frequent_list", "=", "self", ".", "_get_most_frequent_values", "(", "rows", ",", "column", ")", "\n", "if", "not", "most_frequent_list", ":", "\n", "            ", "return", "Date", "(", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "most_frequent_value", "=", "most_frequent_list", "[", "0", "]", "\n", "if", "not", "isinstance", "(", "most_frequent_value", ",", "Date", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for mode_date: {most_frequent_value}\"", ")", "\n", "", "return", "most_frequent_value", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.argmax": [[575, 591], ["sorted"], "methods", ["None"], ["", "def", "argmax", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "ComparableColumn", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column name and returns a list containing a single row (dict from\n        columns to cells) that has the maximum numerical value in the given column. We return a list\n        instead of a single dict to be consistent with the return type of ``select`` and\n        ``all_rows``.\n        \"\"\"", "\n", "if", "not", "rows", ":", "\n", "            ", "return", "[", "]", "\n", "", "value_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "value_row_pairs", ":", "\n", "            ", "return", "[", "]", "\n", "# Returns a list containing the row with the max cell value.", "\n", "", "return", "[", "sorted", "(", "value_row_pairs", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "[", "0", "]", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.argmin": [[592, 608], ["sorted"], "methods", ["None"], ["", "def", "argmin", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "ComparableColumn", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns a list containing a single row (dict from\n        columns to cells) that has the minimum numerical value in the given column. We return a list\n        instead of a single dict to be consistent with the return type of ``select`` and\n        ``all_rows``.\n        \"\"\"", "\n", "if", "not", "rows", ":", "\n", "            ", "return", "[", "]", "\n", "", "value_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "value_row_pairs", ":", "\n", "            ", "return", "[", "]", "\n", "# Returns a list containing the row with the max cell value.", "\n", "", "return", "[", "sorted", "(", "value_row_pairs", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", "0", "]", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_number_greater": [[613, 621], ["None"], "methods", ["None"], ["", "def", "filter_number_greater", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ",", "filter_value", ":", "Number", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "return", "[", "\n", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", ">", "filter_value", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_number_greater_equals": [[623, 631], ["None"], "methods", ["None"], ["", "def", "filter_number_greater_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ",", "filter_value", ":", "Number", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "return", "[", "\n", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", ">=", "filter_value", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_number_lesser": [[633, 641], ["None"], "methods", ["None"], ["", "def", "filter_number_lesser", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ",", "filter_value", ":", "Number", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "return", "[", "\n", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "<", "filter_value", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_number_lesser_equals": [[643, 651], ["None"], "methods", ["None"], ["", "def", "filter_number_lesser_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ",", "filter_value", ":", "Number", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "return", "[", "\n", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "<=", "filter_value", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_number_equals": [[653, 661], ["None"], "methods", ["None"], ["", "def", "filter_number_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ",", "filter_value", ":", "Number", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "return", "[", "\n", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "==", "filter_value", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_number_not_equals": [[663, 671], ["None"], "methods", ["None"], ["", "def", "filter_number_not_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ",", "filter_value", ":", "Number", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", "=", "[", "\n", "(", "row", ".", "values", "[", "column", ".", "name", "]", ",", "row", ")", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "return", "[", "\n", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "!=", "filter_value", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_date_greater": [[676, 686], ["isinstance", "cell_row_pairs.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_date_greater", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ",", "filter_value", ":", "Date", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", ":", "List", "[", "Tuple", "[", "Date", ",", "Row", "]", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "cell_row_pairs", ".", "append", "(", "(", "cell_value", ",", "row", ")", ")", "\n", "\n", "", "", "return", "[", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", ">", "filter_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_date_greater_equals": [[687, 696], ["isinstance", "cell_row_pairs.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_date_greater_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ",", "filter_value", ":", "Date", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", ":", "List", "[", "Tuple", "[", "Date", ",", "Row", "]", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "cell_row_pairs", ".", "append", "(", "(", "cell_value", ",", "row", ")", ")", "\n", "", "", "return", "[", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", ">=", "filter_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_date_lesser": [[697, 706], ["isinstance", "cell_row_pairs.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_date_lesser", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ",", "filter_value", ":", "Date", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", ":", "List", "[", "Tuple", "[", "Date", ",", "Row", "]", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "cell_row_pairs", ".", "append", "(", "(", "cell_value", ",", "row", ")", ")", "\n", "", "", "return", "[", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "<", "filter_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_date_lesser_equals": [[707, 716], ["isinstance", "cell_row_pairs.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_date_lesser_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ",", "filter_value", ":", "Date", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", ":", "List", "[", "Tuple", "[", "Date", ",", "Row", "]", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "cell_row_pairs", ".", "append", "(", "(", "cell_value", ",", "row", ")", ")", "\n", "", "", "return", "[", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "<=", "filter_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_date_equals": [[717, 726], ["isinstance", "cell_row_pairs.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_date_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ",", "filter_value", ":", "Date", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", ":", "List", "[", "Tuple", "[", "Date", ",", "Row", "]", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "cell_row_pairs", ".", "append", "(", "(", "cell_value", ",", "row", ")", ")", "\n", "", "", "return", "[", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "==", "filter_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_date_not_equals": [[727, 736], ["isinstance", "cell_row_pairs.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_date_not_equals", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ",", "filter_value", ":", "Date", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "        ", "cell_row_pairs", ":", "List", "[", "Tuple", "[", "Date", ",", "Row", "]", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "Date", ")", ":", "\n", "                ", "cell_row_pairs", ".", "append", "(", "(", "cell_value", ",", "row", ")", ")", "\n", "", "", "return", "[", "row", "for", "cell_value", ",", "row", "in", "cell_row_pairs", "if", "cell_value", "!=", "filter_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_in": [[742, 766], ["isinstance", "filter_value.lstrip.lstrip.lstrip", "allennlp_semparse.common.ExecutionError", "isinstance", "allennlp_semparse.common.ExecutionError", "isinstance", "filtered_rows.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_in", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "StringColumn", ",", "filter_values", ":", "List", "[", "str", "]", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "# We accept a list of filter values instead of a single string to allow the outputs of select like", "\n", "# operations to be passed in as filter values.", "\n", "# Assuming filter value has underscores for spaces. The cell values also have underscores", "\n", "# for spaces, so we do not need to replace them here.", "\n", "# Note that if a list of filter values is passed, we only use the first one.", "\n", "        ", "if", "not", "filter_values", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Unexpected filter value: {filter_values}\"", ")", "\n", "", "if", "isinstance", "(", "filter_values", ",", "str", ")", ":", "\n", "            ", "filter_value", "=", "filter_values", "\n", "", "elif", "isinstance", "(", "filter_values", ",", "list", ")", ":", "\n", "            ", "filter_value", "=", "filter_values", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Unexpected filter value: {filter_values}\"", ")", "\n", "# Also, we need to remove the \"string:\" that was prepended to the entity name in the language.", "\n", "", "filter_value", "=", "filter_value", ".", "lstrip", "(", "\"string:\"", ")", "\n", "filtered_rows", ":", "List", "[", "Row", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "str", ")", "and", "filter_value", "in", "cell_value", ":", "\n", "                ", "filtered_rows", ".", "append", "(", "row", ")", "\n", "", "", "return", "filtered_rows", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.filter_not_in": [[767, 791], ["isinstance", "filter_value.lstrip.lstrip.lstrip", "allennlp_semparse.common.ExecutionError", "isinstance", "allennlp_semparse.common.ExecutionError", "isinstance", "filtered_rows.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "filter_not_in", "(", "\n", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "StringColumn", ",", "filter_values", ":", "List", "[", "str", "]", "\n", ")", "->", "List", "[", "Row", "]", ":", "\n", "# We accept a list of filter values instead of a single string to allow the outputs of select like", "\n", "# operations to be passed in as filter values.", "\n", "# Assuming filter value has underscores for spaces. The cell values also have underscores", "\n", "# for spaces, so we do not need to replace them here.", "\n", "# Note that if a list of filter values is passed, we only use the first one.", "\n", "        ", "if", "not", "filter_values", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Unexpected filter value: {filter_values}\"", ")", "\n", "", "if", "isinstance", "(", "filter_values", ",", "str", ")", ":", "\n", "            ", "filter_value", "=", "filter_values", "\n", "", "elif", "isinstance", "(", "filter_values", ",", "list", ")", ":", "\n", "            ", "filter_value", "=", "filter_values", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Unexpected filter value: {filter_values}\"", ")", "\n", "# Also, we need to remove the \"string:\" that was prepended to the entity name in the language.", "\n", "", "filter_value", "=", "filter_value", ".", "lstrip", "(", "\"string:\"", ")", "\n", "filtered_rows", ":", "List", "[", "Row", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "cell_value", ",", "str", ")", "and", "filter_value", "not", "in", "cell_value", ":", "\n", "                ", "filtered_rows", ".", "append", "(", "row", ")", "\n", "", "", "return", "filtered_rows", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.max_date": [[794, 807], ["max", "allennlp_semparse.common.Date", "all", "allennlp_semparse.common.ExecutionError", "isinstance"], "methods", ["None"], ["", "def", "max_date", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ")", "->", "Date", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the max of the values under that column in\n        those rows.\n        \"\"\"", "\n", "cell_values", "=", "[", "\n", "row", ".", "values", "[", "column", ".", "name", "]", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "cell_values", ":", "\n", "            ", "return", "Date", "(", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "if", "not", "all", "(", "[", "isinstance", "(", "value", ",", "Date", ")", "for", "value", "in", "cell_values", "]", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for date selection function: {cell_values}\"", ")", "\n", "", "return", "max", "(", "cell_values", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.min_date": [[808, 821], ["min", "allennlp_semparse.common.Date", "all", "allennlp_semparse.common.ExecutionError", "isinstance"], "methods", ["None"], ["", "def", "min_date", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "DateColumn", ")", "->", "Date", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the min of the values under that column in\n        those rows.\n        \"\"\"", "\n", "cell_values", "=", "[", "\n", "row", ".", "values", "[", "column", ".", "name", "]", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "cell_values", ":", "\n", "            ", "return", "Date", "(", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "if", "not", "all", "(", "[", "isinstance", "(", "value", ",", "Date", ")", "for", "value", "in", "cell_values", "]", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for date selection function: {cell_values}\"", ")", "\n", "", "return", "min", "(", "cell_values", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.max_number": [[825, 838], ["max", "all", "allennlp_semparse.common.ExecutionError", "isinstance"], "methods", ["None"], ["", "def", "max_number", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the max of the values under that column in\n        those rows.\n        \"\"\"", "\n", "cell_values", "=", "[", "\n", "row", ".", "values", "[", "column", ".", "name", "]", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "cell_values", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "if", "not", "all", "(", "[", "isinstance", "(", "value", ",", "Number", ")", "for", "value", "in", "cell_values", "]", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for number selection function: {cell_values}\"", ")", "\n", "", "return", "max", "(", "cell_values", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.min_number": [[839, 852], ["min", "all", "allennlp_semparse.common.ExecutionError", "isinstance"], "methods", ["None"], ["", "def", "min_number", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the min of the values under that column in\n        those rows.\n        \"\"\"", "\n", "cell_values", "=", "[", "\n", "row", ".", "values", "[", "column", ".", "name", "]", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "cell_values", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "if", "not", "all", "(", "[", "isinstance", "(", "value", ",", "Number", ")", "for", "value", "in", "cell_values", "]", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid values for number selection function: {cell_values}\"", ")", "\n", "", "return", "min", "(", "cell_values", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.sum": [[853, 864], ["wikitables_language.WikiTablesLanguage.sum"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum"], ["", "def", "sum", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the sum of the values under that column in\n        those rows.\n        \"\"\"", "\n", "cell_values", "=", "[", "\n", "row", ".", "values", "[", "column", ".", "name", "]", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "cell_values", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "return", "sum", "(", "cell_values", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.average": [[865, 876], ["wikitables_language.WikiTablesLanguage.sum"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum"], ["", "def", "average", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Takes a list of rows and a column and returns the mean of the values under that column in\n        those rows.\n        \"\"\"", "\n", "cell_values", "=", "[", "\n", "row", ".", "values", "[", "column", ".", "name", "]", "for", "row", "in", "rows", "if", "row", ".", "values", "[", "column", ".", "name", "]", "is", "not", "None", "\n", "]", "\n", "if", "not", "cell_values", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "return", "sum", "(", "cell_values", ")", "/", "len", "(", "cell_values", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.diff": [[877, 892], ["isinstance", "isinstance", "allennlp_semparse.common.ExecutionError"], "methods", ["None"], ["", "def", "diff", "(", "self", ",", "first_row", ":", "List", "[", "Row", "]", ",", "second_row", ":", "List", "[", "Row", "]", ",", "column", ":", "NumberColumn", ")", "->", "Number", ":", "\n", "        ", "\"\"\"\n        Takes a two rows and a number column and returns the difference between the values under\n        that column in those two rows.\n        \"\"\"", "\n", "if", "not", "first_row", "or", "not", "second_row", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "first_value", "=", "first_row", "[", "0", "]", ".", "values", "[", "column", ".", "name", "]", "\n", "second_value", "=", "second_row", "[", "0", "]", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "isinstance", "(", "first_value", ",", "float", ")", "and", "isinstance", "(", "second_value", ",", "float", ")", ":", "\n", "            ", "return", "first_value", "-", "second_value", "# type: ignore", "\n", "", "elif", "first_value", "is", "None", "or", "second_value", "is", "None", ":", "\n", "            ", "return", "0.0", "# type: ignore", "\n", "", "else", ":", "\n", "            ", "raise", "ExecutionError", "(", "f\"Invalid column for diff: {column.name}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.__eq__": [[896, 900], ["isinstance"], "methods", ["None"], ["", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "WikiTablesLanguage", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "table_data", "==", "other", ".", "table_data", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._make_date": [[901, 916], ["cell_string.split", "allennlp_semparse.common.Date", "part.isdigit", "len", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_date", "(", "cell_string", ":", "str", ")", "->", "Date", ":", "\n", "        ", "string_parts", "=", "cell_string", ".", "split", "(", "\"_\"", ")", "\n", "year", "=", "-", "1", "\n", "month", "=", "-", "1", "\n", "day", "=", "-", "1", "\n", "for", "part", "in", "string_parts", ":", "\n", "            ", "if", "part", ".", "isdigit", "(", ")", ":", "\n", "                ", "if", "len", "(", "part", ")", "==", "4", ":", "\n", "                    ", "year", "=", "int", "(", "part", ")", "\n", "", "else", ":", "\n", "                    ", "day", "=", "int", "(", "part", ")", "\n", "", "", "elif", "part", "in", "MONTH_NUMBERS", ":", "\n", "                ", "month", "=", "MONTH_NUMBERS", "[", "part", "]", "\n", "", "", "return", "Date", "(", "year", ",", "month", ",", "day", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_row_index": [[917, 929], ["enumerate"], "methods", ["None"], ["", "def", "_get_row_index", "(", "self", ",", "row", ":", "Row", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Takes a row and returns its index in the full list of rows. If the row does not occur in the\n        table (which should never happen because this function will only be called with a row that\n        is the result of applying one or more functions on the table rows), the method returns -1.\n        \"\"\"", "\n", "row_index", "=", "-", "1", "\n", "for", "index", ",", "table_row", "in", "enumerate", "(", "self", ".", "table_data", ")", ":", "\n", "            ", "if", "table_row", ".", "values", "==", "row", ".", "values", ":", "\n", "                ", "row_index", "=", "index", "\n", "break", "\n", "", "", "return", "row_index", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage._get_most_frequent_values": [[930, 945], ["collections.defaultdict", "most_frequent_list.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_most_frequent_values", "(", "self", ",", "rows", ":", "List", "[", "Row", "]", ",", "column", ":", "Column", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "value_frequencies", ":", "Dict", "[", "CellValueType", ",", "int", "]", "=", "defaultdict", "(", "int", ")", "\n", "max_frequency", "=", "0", "\n", "most_frequent_list", ":", "List", "[", "CellValueType", "]", "=", "[", "]", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "cell_value", "=", "row", ".", "values", "[", "column", ".", "name", "]", "\n", "if", "cell_value", "is", "not", "None", ":", "\n", "                ", "value_frequencies", "[", "cell_value", "]", "+=", "1", "\n", "frequency", "=", "value_frequencies", "[", "cell_value", "]", "\n", "if", "frequency", ">", "max_frequency", ":", "\n", "                    ", "max_frequency", "=", "frequency", "\n", "most_frequent_list", "=", "[", "cell_value", "]", "\n", "", "elif", "frequency", "==", "max_frequency", ":", "\n", "                    ", "most_frequent_list", ".", "append", "(", "cell_value", ")", "\n", "", "", "", "return", "most_frequent_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Object.__init__": [[22, 35], ["attributes[].lower", "attributes[].lower.startswith", "attributes[].lower"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "attributes", ":", "JsonDict", ",", "box_id", ":", "str", ")", "->", "None", ":", "\n", "        ", "object_color", "=", "attributes", "[", "\"color\"", "]", ".", "lower", "(", ")", "\n", "# The dataset has a hex code only for blue for some reason.", "\n", "if", "object_color", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "            ", "self", ".", "color", "=", "\"blue\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "color", "=", "object_color", "\n", "", "object_shape", "=", "attributes", "[", "\"type\"", "]", ".", "lower", "(", ")", "\n", "self", ".", "shape", "=", "object_shape", "\n", "self", ".", "x_loc", "=", "attributes", "[", "\"x_loc\"", "]", "\n", "self", ".", "y_loc", "=", "attributes", "[", "\"y_loc\"", "]", "\n", "self", ".", "size", "=", "attributes", "[", "\"size\"", "]", "\n", "self", ".", "_box_id", "=", "box_id", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Object.__str__": [[36, 44], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "size", "==", "10", ":", "\n", "            ", "size", "=", "\"small\"", "\n", "", "elif", "self", ".", "size", "==", "20", ":", "\n", "            ", "size", "=", "\"medium\"", "\n", "", "else", ":", "\n", "            ", "size", "=", "\"big\"", "\n", "", "return", "f\"{size} {self.color} {self.shape} at ({self.x_loc}, {self.y_loc}) in {self._box_id}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Object.__hash__": [[45, 47], ["hash", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "str", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Object.__eq__": [[48, 50], ["str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "==", "str", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Box.__init__": [[64, 70], ["str", "nlvr_language.Object", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["def", "__init__", "(", "self", ",", "objects_list", ":", "List", "[", "JsonDict", "]", ",", "box_id", ":", "int", ")", "->", "None", ":", "\n", "        ", "self", ".", "_name", "=", "f\"box {box_id + 1}\"", "\n", "self", ".", "_objects_string", "=", "str", "(", "[", "str", "(", "_object", ")", "for", "_object", "in", "objects_list", "]", ")", "\n", "self", ".", "objects", "=", "{", "Object", "(", "object_dict", ",", "self", ".", "_name", ")", "for", "object_dict", "in", "objects_list", "}", "\n", "self", ".", "colors", "=", "{", "obj", ".", "color", "for", "obj", "in", "self", ".", "objects", "}", "\n", "self", ".", "shapes", "=", "{", "obj", ".", "shape", "for", "obj", "in", "self", ".", "objects", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Box.__str__": [[71, 73], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_objects_string", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Box.__hash__": [[74, 76], ["hash", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "str", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.Box.__eq__": [[77, 79], ["str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "==", "str", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.__init__": [[90, 121], ["set", "allennlp_semparse.domain_languages.domain_language.DomainLanguage.__init__", "nlvr_language.NlvrLanguage._function_types.items", "nlvr_language.NlvrLanguage.objects.update", "nlvr_language.Color", "nlvr_language.Color", "nlvr_language.Color", "nlvr_language.Shape", "nlvr_language.Shape", "nlvr_language.Shape"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update"], ["    ", "def", "__init__", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ")", "->", "None", ":", "\n", "        ", "self", ".", "boxes", "=", "boxes", "\n", "self", ".", "objects", ":", "Set", "[", "Object", "]", "=", "set", "(", ")", "\n", "for", "box", "in", "self", ".", "boxes", ":", "\n", "            ", "self", ".", "objects", ".", "update", "(", "box", ".", "objects", ")", "\n", "", "allowed_constants", "=", "{", "\n", "\"color_blue\"", ":", "Color", "(", "\"blue\"", ")", ",", "\n", "\"color_black\"", ":", "Color", "(", "\"black\"", ")", ",", "\n", "\"color_yellow\"", ":", "Color", "(", "\"yellow\"", ")", ",", "\n", "\"shape_triangle\"", ":", "Shape", "(", "\"triangle\"", ")", ",", "\n", "\"shape_square\"", ":", "Shape", "(", "\"square\"", ")", ",", "\n", "\"shape_circle\"", ":", "Shape", "(", "\"circle\"", ")", ",", "\n", "\"1\"", ":", "1", ",", "\n", "\"2\"", ":", "2", ",", "\n", "\"3\"", ":", "3", ",", "\n", "\"4\"", ":", "4", ",", "\n", "\"5\"", ":", "5", ",", "\n", "\"6\"", ":", "6", ",", "\n", "\"7\"", ":", "7", ",", "\n", "\"8\"", ":", "8", ",", "\n", "\"9\"", ":", "9", ",", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "start_types", "=", "{", "bool", "}", ",", "allowed_constants", "=", "allowed_constants", ")", "\n", "\n", "# Mapping from terminal strings to productions that produce them.", "\n", "# Eg.: \"yellow\" -> \"<Set[Object]:Set[Object]> -> yellow\"", "\n", "# We use this in the agenda-related methods, and some models that use this language look at", "\n", "# this field to know how many terminals to plan for.", "\n", "self", ".", "terminal_productions", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "for", "name", ",", "types", "in", "self", ".", "_function_types", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "terminal_productions", "[", "name", "]", "=", "f\"{types[0]} -> {name}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence": [[125, 203], ["sentence.lower.lower.lower", "nlvr_language.NlvrLanguage.terminal_productions.items", "nlvr_language.NlvrLanguage._get_number_productions", "sentence.lower.lower.startswith", "sentence.lower.lower.startswith", "agenda.append", "sentence.lower.lower.startswith", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append", "agenda.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._get_number_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "def", "get_agenda_for_sentence", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Given a ``sentence``, returns a list of actions the sentence triggers as an ``agenda``. The\n        ``agenda`` can be used while by a parser to guide the decoder.  sequences as possible. This\n        is a simplistic mapping at this point, and can be expanded.\n\n        Parameters\n        ----------\n        sentence : ``str``\n            The sentence for which an agenda will be produced.\n        \"\"\"", "\n", "agenda", "=", "[", "]", "\n", "sentence", "=", "sentence", ".", "lower", "(", ")", "\n", "if", "sentence", ".", "startswith", "(", "\"there is a box\"", ")", "or", "sentence", ".", "startswith", "(", "\"there is a tower \"", ")", ":", "\n", "            ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"box_exists\"", "]", ")", "\n", "", "elif", "sentence", ".", "startswith", "(", "\"there is a \"", ")", ":", "\n", "            ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"object_exists\"", "]", ")", "\n", "\n", "", "if", "\"<Set[Box]:bool> -> box_exists\"", "not", "in", "agenda", ":", "\n", "# These are object filters and do not apply if we have a box_exists at the top.", "\n", "            ", "if", "\"touch\"", "in", "sentence", ":", "\n", "                ", "if", "\"top\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_top\"", "]", ")", "\n", "", "elif", "\"bottom\"", "in", "sentence", "or", "\"base\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_bottom\"", "]", ")", "\n", "", "elif", "\"corner\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_corner\"", "]", ")", "\n", "", "elif", "\"right\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_right\"", "]", ")", "\n", "", "elif", "\"left\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_left\"", "]", ")", "\n", "", "elif", "\"wall\"", "in", "sentence", "or", "\"edge\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_wall\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"touch_object\"", "]", ")", "\n", "", "", "else", ":", "\n", "# The words \"top\" and \"bottom\" may be referring to top and bottom blocks in a tower.", "\n", "                ", "if", "\"top\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"top\"", "]", ")", "\n", "", "elif", "\"bottom\"", "in", "sentence", "or", "\"base\"", "in", "sentence", ":", "\n", "                    ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"bottom\"", "]", ")", "\n", "\n", "", "", "if", "\" not \"", "in", "sentence", ":", "\n", "                ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"negate_filter\"", "]", ")", "\n", "\n", "", "", "if", "\" contains \"", "in", "sentence", "or", "\" has \"", "in", "sentence", ":", "\n", "            ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"all_boxes\"", "]", ")", "\n", "# This takes care of shapes, colors, top, bottom, big, small etc.", "\n", "", "for", "constant", ",", "production", "in", "self", ".", "terminal_productions", ".", "items", "(", ")", ":", "\n", "# TODO(pradeep): Deal with constant names with underscores.", "\n", "            ", "if", "\"top\"", "in", "constant", "or", "\"bottom\"", "in", "constant", ":", "\n", "# We already dealt with top, bottom, touch_top and touch_bottom above.", "\n", "                ", "continue", "\n", "", "if", "constant", "in", "sentence", ":", "\n", "                ", "if", "(", "\n", "\"<Set[Object]:Set[Object]> ->\"", "in", "production", "\n", "and", "\"<Set[Box]:bool> -> box_exists\"", "in", "agenda", "\n", ")", ":", "\n", "                    ", "if", "constant", "in", "[", "\"square\"", ",", "\"circle\"", ",", "\"triangle\"", "]", ":", "\n", "                        ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "f\"shape_{constant}\"", "]", ")", "\n", "", "elif", "constant", "in", "[", "\"yellow\"", ",", "\"blue\"", ",", "\"black\"", "]", ":", "\n", "                        ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "f\"color_{constant}\"", "]", ")", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "", "", "else", ":", "\n", "                    ", "agenda", ".", "append", "(", "production", ")", "\n", "# TODO (pradeep): Rules for \"member_*\" productions (\"tower\" or \"box\" followed by a color,", "\n", "# shape or number...)", "\n", "", "", "", "number_productions", "=", "self", ".", "_get_number_productions", "(", "sentence", ")", "\n", "for", "production", "in", "number_productions", ":", "\n", "            ", "agenda", ".", "append", "(", "production", ")", "\n", "", "if", "not", "agenda", ":", "\n", "# None of the rules above was triggered!", "\n", "            ", "if", "\"box\"", "in", "sentence", ":", "\n", "                ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"all_boxes\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "agenda", ".", "append", "(", "self", ".", "terminal_productions", "[", "\"all_objects\"", "]", ")", "\n", "", "", "return", "agenda", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._get_number_productions": [[204, 232], ["sentence.split", "number_strings.values", "number_productions.append", "number_productions.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_get_number_productions", "(", "sentence", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Gathers all the numbers in the sentence, and returns productions that lead to them.\n        \"\"\"", "\n", "# The mapping here is very simple and limited, which also shouldn't be a problem", "\n", "# because numbers seem to be represented fairly regularly.", "\n", "number_strings", "=", "{", "\n", "\"one\"", ":", "\"1\"", ",", "\n", "\"two\"", ":", "\"2\"", ",", "\n", "\"three\"", ":", "\"3\"", ",", "\n", "\"four\"", ":", "\"4\"", ",", "\n", "\"five\"", ":", "\"5\"", ",", "\n", "\"six\"", ":", "\"6\"", ",", "\n", "\"seven\"", ":", "\"7\"", ",", "\n", "\"eight\"", ":", "\"8\"", ",", "\n", "\"nine\"", ":", "\"9\"", ",", "\n", "\"ten\"", ":", "\"10\"", ",", "\n", "}", "\n", "number_productions", "=", "[", "]", "\n", "tokens", "=", "sentence", ".", "split", "(", ")", "\n", "numbers", "=", "number_strings", ".", "values", "(", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "token", "in", "numbers", ":", "\n", "                ", "number_productions", ".", "append", "(", "f\"int -> {token}\"", ")", "\n", "", "elif", "token", "in", "number_strings", ":", "\n", "                ", "number_productions", ".", "append", "(", "f\"int -> {number_strings[token]}\"", ")", "\n", "", "", "return", "number_productions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.__eq__": [[233, 237], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "boxes", "==", "other", ".", "boxes", "and", "self", ".", "objects", "==", "other", ".", "objects", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.all_boxes": [[240, 243], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "all_boxes", "(", "self", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "self", ".", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.all_objects": [[244, 247], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "all_objects", "(", "self", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "self", ".", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_exists": [[248, 251], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_exists", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_exists": [[252, 255], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_exists", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_in_box": [[256, 262], ["set", "return_set.update"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update"], ["", "@", "predicate", "\n", "def", "object_in_box", "(", "self", ",", "box", ":", "Set", "[", "Box", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return_set", ":", "Set", "[", "Object", "]", "=", "set", "(", ")", "\n", "for", "box_", "in", "box", ":", "\n", "            ", "return_set", ".", "update", "(", "box_", ".", "objects", ")", "\n", "", "return", "return_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.black": [[263, 266], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "black", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "color", "==", "\"black\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.blue": [[267, 270], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "blue", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "color", "==", "\"blue\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.yellow": [[271, 274], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "yellow", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "color", "==", "\"yellow\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.circle": [[275, 278], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "circle", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "shape", "==", "\"circle\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.square": [[279, 282], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "square", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "shape", "==", "\"square\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.triangle": [[283, 286], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "triangle", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "shape", "==", "\"triangle\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.same_color": [[287, 298], ["nlvr_language.NlvrLanguage._get_objects_with_same_attribute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._get_objects_with_same_attribute"], ["", "@", "predicate", "\n", "def", "same_color", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Filters the set of objects, and returns those objects whose color is the most frequent\n        color in the initial set of objects, if the highest frequency is greater than 1, or an\n        empty set otherwise.\n\n        This is an unusual name for what the method does, but just as ``blue`` filters objects to\n        those that are blue, this filters objects to those that are of the same color.\n        \"\"\"", "\n", "return", "self", ".", "_get_objects_with_same_attribute", "(", "objects", ",", "lambda", "x", ":", "x", ".", "color", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.same_shape": [[299, 310], ["nlvr_language.NlvrLanguage._get_objects_with_same_attribute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._get_objects_with_same_attribute"], ["", "@", "predicate", "\n", "def", "same_shape", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Filters the set of objects, and returns those objects whose color is the most frequent\n        color in the initial set of objects, if the highest frequency is greater than 1, or an\n        empty set otherwise.\n\n        This is an unusual name for what the method does, but just as ``triangle`` filters objects\n        to those that are triangles, this filters objects to those that are of the same shape.\n        \"\"\"", "\n", "return", "self", ".", "_get_objects_with_same_attribute", "(", "objects", ",", "lambda", "x", ":", "x", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_bottom": [[311, 314], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "touch_bottom", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "y_loc", "+", "obj", ".", "size", "==", "100", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_left": [[315, 318], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "touch_left", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "x_loc", "==", "0", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_top": [[319, 322], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "touch_top", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "y_loc", "==", "0", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_right": [[323, 326], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "touch_right", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "x_loc", "+", "obj", ".", "size", "==", "100", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_wall": [[327, 335], ["set", "return_set.union", "nlvr_language.NlvrLanguage.touch_top", "nlvr_language.NlvrLanguage.touch_left", "nlvr_language.NlvrLanguage.touch_right", "nlvr_language.NlvrLanguage.touch_bottom"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_top", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_left", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_right", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_bottom"], ["", "@", "predicate", "\n", "def", "touch_wall", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return_set", ":", "Set", "[", "Object", "]", "=", "set", "(", ")", "\n", "return", "return_set", ".", "union", "(", "\n", "self", ".", "touch_top", "(", "objects", ")", ",", "\n", "self", ".", "touch_left", "(", "objects", ")", ",", "\n", "self", ".", "touch_right", "(", "objects", ")", ",", "\n", "self", ".", "touch_bottom", "(", "objects", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_corner": [[337, 345], ["set", "return_set.union", "nlvr_language.NlvrLanguage.touch_top().intersection", "nlvr_language.NlvrLanguage.touch_top().intersection", "nlvr_language.NlvrLanguage.touch_bottom().intersection", "nlvr_language.NlvrLanguage.touch_bottom().intersection", "nlvr_language.NlvrLanguage.touch_right", "nlvr_language.NlvrLanguage.touch_left", "nlvr_language.NlvrLanguage.touch_right", "nlvr_language.NlvrLanguage.touch_left", "nlvr_language.NlvrLanguage.touch_top", "nlvr_language.NlvrLanguage.touch_top", "nlvr_language.NlvrLanguage.touch_bottom", "nlvr_language.NlvrLanguage.touch_bottom"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_right", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_left", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_right", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_left", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_top", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_top", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_bottom", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_bottom"], ["", "@", "predicate", "\n", "def", "touch_corner", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return_set", ":", "Set", "[", "Object", "]", "=", "set", "(", ")", "\n", "return", "return_set", ".", "union", "(", "\n", "self", ".", "touch_top", "(", "objects", ")", ".", "intersection", "(", "self", ".", "touch_right", "(", "objects", ")", ")", ",", "\n", "self", ".", "touch_top", "(", "objects", ")", ".", "intersection", "(", "self", ".", "touch_left", "(", "objects", ")", ")", ",", "\n", "self", ".", "touch_bottom", "(", "objects", ")", ".", "intersection", "(", "self", ".", "touch_right", "(", "objects", ")", ")", ",", "\n", "self", ".", "touch_bottom", "(", "objects", ")", ".", "intersection", "(", "self", ".", "touch_left", "(", "objects", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.touch_object": [[347, 361], ["nlvr_language.NlvrLanguage._separate_objects_by_boxes", "set", "nlvr_language.NlvrLanguage.items", "nlvr_language.NlvrLanguage._objects_touch_each_other", "set.add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._separate_objects_by_boxes", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._objects_touch_each_other", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "@", "predicate", "\n", "def", "touch_object", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Returns all objects that touch the given set of objects.\n        \"\"\"", "\n", "objects_per_box", "=", "self", ".", "_separate_objects_by_boxes", "(", "objects", ")", "\n", "return_set", "=", "set", "(", ")", "\n", "for", "box", ",", "box_objects", "in", "objects_per_box", ".", "items", "(", ")", ":", "\n", "            ", "candidate_objects", "=", "box", ".", "objects", "\n", "for", "object_", "in", "box_objects", ":", "\n", "                ", "for", "candidate_object", "in", "candidate_objects", ":", "\n", "                    ", "if", "self", ".", "_objects_touch_each_other", "(", "object_", ",", "candidate_object", ")", ":", "\n", "                        ", "return_set", ".", "add", "(", "candidate_object", ")", "\n", "", "", "", "", "return", "return_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.top": [[362, 374], ["nlvr_language.NlvrLanguage._separate_objects_by_boxes", "set", "nlvr_language.NlvrLanguage.items", "min", "return_set.update"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._separate_objects_by_boxes", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update"], ["", "@", "predicate", "\n", "def", "top", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Return the topmost objects (i.e. minimum y_loc). The comparison is done separately for each\n        box.\n        \"\"\"", "\n", "objects_per_box", "=", "self", ".", "_separate_objects_by_boxes", "(", "objects", ")", "\n", "return_set", ":", "Set", "[", "Object", "]", "=", "set", "(", ")", "\n", "for", "_", ",", "box_objects", "in", "objects_per_box", ".", "items", "(", ")", ":", "\n", "            ", "min_y_loc", "=", "min", "(", "[", "obj", ".", "y_loc", "for", "obj", "in", "box_objects", "]", ")", "\n", "return_set", ".", "update", "(", "{", "obj", "for", "obj", "in", "box_objects", "if", "obj", ".", "y_loc", "==", "min_y_loc", "}", ")", "\n", "", "return", "return_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.bottom": [[375, 387], ["nlvr_language.NlvrLanguage._separate_objects_by_boxes", "set", "nlvr_language.NlvrLanguage.items", "max", "return_set.update"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._separate_objects_by_boxes", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update"], ["", "@", "predicate", "\n", "def", "bottom", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Return the bottom most objects(i.e. maximum y_loc). The comparison is done separately for\n        each box.\n        \"\"\"", "\n", "objects_per_box", "=", "self", ".", "_separate_objects_by_boxes", "(", "objects", ")", "\n", "return_set", ":", "Set", "[", "Object", "]", "=", "set", "(", ")", "\n", "for", "_", ",", "box_objects", "in", "objects_per_box", ".", "items", "(", ")", ":", "\n", "            ", "max_y_loc", "=", "max", "(", "[", "obj", ".", "y_loc", "for", "obj", "in", "box_objects", "]", ")", "\n", "return_set", ".", "update", "(", "{", "obj", "for", "obj", "in", "box_objects", "if", "obj", ".", "y_loc", "==", "max_y_loc", "}", ")", "\n", "", "return", "return_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.above": [[388, 404], ["nlvr_language.NlvrLanguage._separate_objects_by_boxes", "set", "min", "set.add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._separate_objects_by_boxes", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "@", "predicate", "\n", "def", "above", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Returns the set of objects in the same boxes that are above the given objects. That is, if\n        the input is a set of two objects, one in each box, we will return a union of the objects\n        above the first object in the first box, and those above the second object in the second box.\n        \"\"\"", "\n", "objects_per_box", "=", "self", ".", "_separate_objects_by_boxes", "(", "objects", ")", "\n", "return_set", "=", "set", "(", ")", "\n", "for", "box", "in", "objects_per_box", ":", "\n", "# min_y_loc corresponds to the top-most object.", "\n", "            ", "min_y_loc", "=", "min", "(", "[", "obj", ".", "y_loc", "for", "obj", "in", "objects_per_box", "[", "box", "]", "]", ")", "\n", "for", "candidate_obj", "in", "box", ".", "objects", ":", "\n", "                ", "if", "candidate_obj", ".", "y_loc", "<", "min_y_loc", ":", "\n", "                    ", "return_set", ".", "add", "(", "candidate_obj", ")", "\n", "", "", "", "return", "return_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.below": [[405, 421], ["nlvr_language.NlvrLanguage._separate_objects_by_boxes", "set", "max", "set.add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._separate_objects_by_boxes", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "@", "predicate", "\n", "def", "below", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Returns the set of objects in the same boxes that are below the given objects. That is, if\n        the input is a set of two objects, one in each box, we will return a union of the objects\n        below the first object in the first box, and those below the second object in the second box.\n        \"\"\"", "\n", "objects_per_box", "=", "self", ".", "_separate_objects_by_boxes", "(", "objects", ")", "\n", "return_set", "=", "set", "(", ")", "\n", "for", "box", "in", "objects_per_box", ":", "\n", "# max_y_loc corresponds to the bottom-most object.", "\n", "            ", "max_y_loc", "=", "max", "(", "[", "obj", ".", "y_loc", "for", "obj", "in", "objects_per_box", "[", "box", "]", "]", ")", "\n", "for", "candidate_obj", "in", "box", ".", "objects", ":", "\n", "                ", "if", "candidate_obj", ".", "y_loc", ">", "max_y_loc", ":", "\n", "                    ", "return_set", ".", "add", "(", "candidate_obj", ")", "\n", "", "", "", "return", "return_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.small": [[422, 425], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "small", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "size", "==", "10", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.medium": [[426, 429], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "medium", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "size", "==", "20", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.big": [[430, 433], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "big", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "{", "obj", "for", "obj", "in", "objects", "if", "obj", ".", "size", "==", "30", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_count_equals": [[434, 437], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_count_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", "==", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_count_not_equals": [[438, 441], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_count_not_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", "!=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_count_greater": [[442, 445], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_count_greater", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", ">", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_count_greater_equals": [[446, 449], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_count_greater_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", ">=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_count_lesser": [[450, 453], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_count_lesser", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", "<", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.box_count_lesser_equals": [[454, 457], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "box_count_lesser_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "boxes", ")", "<=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_all_equals": [[458, 461], ["all"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_all_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "color", ":", "Color", ")", "->", "bool", ":", "\n", "        ", "return", "all", "(", "[", "obj", ".", "color", "==", "color", ".", "color", "for", "obj", "in", "objects", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_any_equals": [[462, 465], ["any"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_any_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "color", ":", "Color", ")", "->", "bool", ":", "\n", "        ", "return", "any", "(", "[", "obj", ".", "color", "==", "color", ".", "color", "for", "obj", "in", "objects", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_none_equals": [[466, 469], ["all"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_none_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "color", ":", "Color", ")", "->", "bool", ":", "\n", "        ", "return", "all", "(", "[", "obj", ".", "color", "!=", "color", ".", "color", "for", "obj", "in", "objects", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_all_equals": [[470, 473], ["all"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_all_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "shape", ":", "Shape", ")", "->", "bool", ":", "\n", "        ", "return", "all", "(", "[", "obj", ".", "shape", "==", "shape", ".", "shape", "for", "obj", "in", "objects", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_any_equals": [[474, 477], ["any"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_any_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "shape", ":", "Shape", ")", "->", "bool", ":", "\n", "        ", "return", "any", "(", "[", "obj", ".", "shape", "==", "shape", ".", "shape", "for", "obj", "in", "objects", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_none_equals": [[478, 481], ["all"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_none_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "shape", ":", "Shape", ")", "->", "bool", ":", "\n", "        ", "return", "all", "(", "[", "obj", ".", "shape", "!=", "shape", ".", "shape", "for", "obj", "in", "objects", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_count_equals": [[482, 485], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_count_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", "==", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_count_not_equals": [[486, 489], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_count_not_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", "!=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_count_greater": [[490, 493], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_count_greater", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", ">", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_count_greater_equals": [[494, 497], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_count_greater_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", ">=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_count_lesser": [[498, 501], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_count_lesser", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", "<", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_count_lesser_equals": [[502, 505], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_count_lesser_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "objects", ")", "<=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_equals": [[506, 509], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_count_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "color", "for", "obj", "in", "objects", "}", ")", "==", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_not_equals": [[510, 513], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_count_not_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "color", "for", "obj", "in", "objects", "}", ")", "!=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_greater": [[514, 517], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_count_greater", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "color", "for", "obj", "in", "objects", "}", ")", ">", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_greater_equals": [[518, 521], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_count_greater_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "color", "for", "obj", "in", "objects", "}", ")", ">=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_lesser": [[522, 525], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_count_lesser", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "color", "for", "obj", "in", "objects", "}", ")", "<", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_lesser_equals": [[526, 529], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_color_count_lesser_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "color", "for", "obj", "in", "objects", "}", ")", "<=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_equals": [[530, 533], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_count_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "shape", "for", "obj", "in", "objects", "}", ")", "==", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_not_equals": [[534, 537], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_count_not_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "shape", "for", "obj", "in", "objects", "}", ")", "!=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_greater": [[538, 541], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_count_greater", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "shape", "for", "obj", "in", "objects", "}", ")", ">", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_greater_equals": [[542, 545], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_count_greater_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "shape", "for", "obj", "in", "objects", "}", ")", ">=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_lesser": [[546, 549], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_count_lesser", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "shape", "for", "obj", "in", "objects", "}", ")", "<", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_lesser_equals": [[550, 553], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "object_shape_count_lesser_equals", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "count", ":", "int", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "{", "obj", ".", "shape", "for", "obj", "in", "objects", "}", ")", "<=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_count_equals": [[554, 557], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_count_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "objects", ")", "==", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_count_not_equals": [[558, 561], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_count_not_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "objects", ")", "!=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_count_greater": [[562, 565], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_count_greater", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "objects", ")", ">", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_count_greater_equals": [[566, 569], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_count_greater_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "objects", ")", ">=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_count_lesser": [[570, 573], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_count_lesser", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "objects", ")", "<", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_count_lesser_equals": [[574, 577], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_count_lesser_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "objects", ")", "<=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_count_equals": [[578, 581], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_color_count_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "colors", ")", "==", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_count_not_equals": [[582, 585], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_color_count_not_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "colors", ")", "!=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_count_greater": [[586, 589], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_color_count_greater", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "colors", ")", ">", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_count_greater_equals": [[590, 593], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_color_count_greater_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "colors", ")", ">=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_count_lesser": [[594, 597], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_color_count_lesser", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "colors", ")", "<", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_count_lesser_equals": [[598, 601], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_color_count_lesser_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "colors", ")", "<=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_count_equals": [[602, 605], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_shape_count_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "shapes", ")", "==", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_count_not_equals": [[606, 609], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_shape_count_not_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "shapes", ")", "!=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_count_greater": [[610, 613], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_shape_count_greater", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "shapes", ")", ">", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_count_greater_equals": [[614, 617], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_shape_count_greater_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "shapes", ")", ">=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_count_lesser": [[618, 621], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_shape_count_lesser", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "shapes", ")", "<", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_count_lesser_equals": [[622, 625], ["len"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "member_shape_count_lesser_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "count", ":", "int", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "len", "(", "box", ".", "shapes", ")", "<=", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_all_equals": [[626, 629], ["nlvr_language.NlvrLanguage.object_color_all_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_all_equals"], ["", "@", "predicate", "\n", "def", "member_color_all_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "color", ":", "Color", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_color_all_equals", "(", "box", ".", "objects", ",", "color", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_any_equals": [[630, 633], ["nlvr_language.NlvrLanguage.object_color_any_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_any_equals"], ["", "@", "predicate", "\n", "def", "member_color_any_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "color", ":", "Color", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_color_any_equals", "(", "box", ".", "objects", ",", "color", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_none_equals": [[634, 637], ["nlvr_language.NlvrLanguage.object_color_none_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_none_equals"], ["", "@", "predicate", "\n", "def", "member_color_none_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "color", ":", "Color", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_color_none_equals", "(", "box", ".", "objects", ",", "color", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_all_equals": [[638, 641], ["nlvr_language.NlvrLanguage.object_shape_all_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_all_equals"], ["", "@", "predicate", "\n", "def", "member_shape_all_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "shape", ":", "Shape", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_shape_all_equals", "(", "box", ".", "objects", ",", "shape", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_any_equals": [[642, 645], ["nlvr_language.NlvrLanguage.object_shape_any_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_any_equals"], ["", "@", "predicate", "\n", "def", "member_shape_any_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "shape", ":", "Shape", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_shape_any_equals", "(", "box", ".", "objects", ",", "shape", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_none_equals": [[646, 649], ["nlvr_language.NlvrLanguage.object_shape_none_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_none_equals"], ["", "@", "predicate", "\n", "def", "member_shape_none_equals", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ",", "shape", ":", "Shape", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_shape_none_equals", "(", "box", ".", "objects", ",", "shape", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_same": [[650, 653], ["nlvr_language.NlvrLanguage.object_shape_count_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_equals"], ["", "@", "predicate", "\n", "def", "member_shape_same", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_shape_count_equals", "(", "box", ".", "objects", ",", "1", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_same": [[654, 657], ["nlvr_language.NlvrLanguage.object_color_count_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_equals"], ["", "@", "predicate", "\n", "def", "member_color_same", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_color_count_equals", "(", "box", ".", "objects", ",", "1", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_shape_different": [[658, 661], ["nlvr_language.NlvrLanguage.object_shape_count_not_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_shape_count_not_equals"], ["", "@", "predicate", "\n", "def", "member_shape_different", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_shape_count_not_equals", "(", "box", ".", "objects", ",", "1", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.member_color_different": [[662, 665], ["nlvr_language.NlvrLanguage.object_color_count_not_equals"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.object_color_count_not_equals"], ["", "@", "predicate", "\n", "def", "member_color_different", "(", "self", ",", "boxes", ":", "Set", "[", "Box", "]", ")", "->", "Set", "[", "Box", "]", ":", "\n", "        ", "return", "{", "box", "for", "box", "in", "boxes", "if", "self", ".", "object_color_count_not_equals", "(", "box", ".", "objects", ",", "1", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.negate_filter": [[666, 674], ["objects.difference", "filter_function"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "negate_filter", "(", "\n", "self", ",", "filter_function", ":", "Callable", "[", "[", "Set", "[", "Object", "]", "]", ",", "Set", "[", "Object", "]", "]", "\n", ")", "->", "Callable", "[", "[", "Set", "[", "Object", "]", "]", ",", "Set", "[", "Object", "]", "]", ":", "\n", "        ", "def", "negated_filter", "(", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "            ", "return", "objects", ".", "difference", "(", "filter_function", "(", "objects", ")", ")", "\n", "\n", "", "return", "negated_filter", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._objects_touch_each_other": [[675, 696], ["None"], "methods", ["None"], ["", "def", "_objects_touch_each_other", "(", "self", ",", "object1", ":", "Object", ",", "object2", ":", "Object", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Returns true iff the objects touch each other.\n        \"\"\"", "\n", "in_vertical_range", "=", "(", "\n", "object1", ".", "y_loc", "<=", "object2", ".", "y_loc", "+", "object2", ".", "size", "\n", "and", "object1", ".", "y_loc", "+", "object1", ".", "size", ">=", "object2", ".", "y_loc", "\n", ")", "\n", "in_horizantal_range", "=", "(", "\n", "object1", ".", "x_loc", "<=", "object2", ".", "x_loc", "+", "object2", ".", "size", "\n", "and", "object1", ".", "x_loc", "+", "object1", ".", "size", ">=", "object2", ".", "x_loc", "\n", ")", "\n", "touch_side", "=", "(", "\n", "object1", ".", "x_loc", "+", "object1", ".", "size", "==", "object2", ".", "x_loc", "\n", "or", "object2", ".", "x_loc", "+", "object2", ".", "size", "==", "object1", ".", "x_loc", "\n", ")", "\n", "touch_top_or_bottom", "=", "(", "\n", "object1", ".", "y_loc", "+", "object1", ".", "size", "==", "object2", ".", "y_loc", "\n", "or", "object2", ".", "y_loc", "+", "object2", ".", "size", "==", "object1", ".", "y_loc", "\n", ")", "\n", "return", "(", "in_vertical_range", "and", "touch_side", ")", "or", "(", "in_horizantal_range", "and", "touch_top_or_bottom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._separate_objects_by_boxes": [[697, 707], ["collections.defaultdict", "objects_per_box[].append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_separate_objects_by_boxes", "(", "self", ",", "objects", ":", "Set", "[", "Object", "]", ")", "->", "Dict", "[", "Box", ",", "List", "[", "Object", "]", "]", ":", "\n", "        ", "\"\"\"\n        Given a set of objects, separate them by the boxes they belong to and return a dict.\n        \"\"\"", "\n", "objects_per_box", ":", "Dict", "[", "Box", ",", "List", "[", "Object", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "box", "in", "self", ".", "boxes", ":", "\n", "            ", "for", "object_", "in", "objects", ":", "\n", "                ", "if", "object_", "in", "box", ".", "objects", ":", "\n", "                    ", "objects_per_box", "[", "box", "]", ".", "append", "(", "object_", ")", "\n", "", "", "", "return", "objects_per_box", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage._get_objects_with_same_attribute": [[708, 727], ["collections.defaultdict", "max", "objects_of_attribute[].add", "set", "len", "set", "len", "attribute_function"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "_get_objects_with_same_attribute", "(", "\n", "self", ",", "objects", ":", "Set", "[", "Object", "]", ",", "attribute_function", ":", "Callable", "[", "[", "Object", "]", ",", "str", "]", "\n", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "\"\"\"\n        Returns the set of objects for which the attribute function returns an attribute value that\n        is most frequent in the initial set, if the frequency is greater than 1. If not, all\n        objects have different attribute values, and this method returns an empty set.\n        \"\"\"", "\n", "objects_of_attribute", ":", "Dict", "[", "str", ",", "Set", "[", "Object", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "for", "entity", "in", "objects", ":", "\n", "            ", "objects_of_attribute", "[", "attribute_function", "(", "entity", ")", "]", ".", "add", "(", "entity", ")", "\n", "", "if", "not", "objects_of_attribute", ":", "\n", "            ", "return", "set", "(", ")", "\n", "", "most_frequent_attribute", "=", "max", "(", "\n", "objects_of_attribute", ",", "key", "=", "lambda", "x", ":", "len", "(", "objects_of_attribute", "[", "x", "]", ")", "\n", ")", "\n", "if", "len", "(", "objects_of_attribute", "[", "most_frequent_attribute", "]", ")", "<=", "1", ":", "\n", "            ", "return", "set", "(", ")", "\n", "", "return", "objects_of_attribute", "[", "most_frequent_attribute", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type": [[76, 100], ["domain_language.is_callable", "domain_language.BasicType", "domain_language.PredicateType.get_type", "domain_language.FunctionType", "domain_language.is_generic", "domain_language.PredicateType.get_type", "domain_language.get_generic_name"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.is_callable", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.is_generic", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.get_generic_name"], ["@", "staticmethod", "\n", "def", "get_type", "(", "type_", ":", "Type", ")", "->", "\"PredicateType\"", ":", "\n", "        ", "\"\"\"\n        Converts a python ``Type`` (as you might get from a type annotation) into a\n        ``PredicateType``.  If the ``Type`` is callable, this will return a ``FunctionType``;\n        otherwise, it will return a ``BasicType``.\n\n        ``BasicTypes`` have a single ``name`` parameter - we typically get this from\n        ``type_.__name__``.  This doesn't work for generic types (like ``List[str]``), so we handle\n        those specially, so that the ``name`` for the ``BasicType`` remains ``List[str]``, as you\n        would expect.\n        \"\"\"", "\n", "if", "is_callable", "(", "type_", ")", ":", "\n", "            ", "callable_args", "=", "type_", ".", "__args__", "\n", "argument_types", "=", "[", "PredicateType", ".", "get_type", "(", "t", ")", "for", "t", "in", "callable_args", "[", ":", "-", "1", "]", "]", "\n", "return_type", "=", "PredicateType", ".", "get_type", "(", "callable_args", "[", "-", "1", "]", ")", "\n", "return", "FunctionType", "(", "argument_types", ",", "return_type", ")", "\n", "", "elif", "is_generic", "(", "type_", ")", ":", "\n", "# This is something like List[int].  type_.__name__ doesn't do the right thing (and", "\n", "# crashes in python 3.7), so we need to do some magic here.", "\n", "            ", "name", "=", "get_generic_name", "(", "type_", ")", "\n", "", "else", ":", "\n", "            ", "name", "=", "type_", ".", "__name__", "\n", "", "return", "BasicType", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type": [[101, 116], ["domain_language.FunctionType"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_function_type", "(", "\n", "arg_types", ":", "Sequence", "[", "\"PredicateType\"", "]", ",", "return_type", ":", "\"PredicateType\"", "\n", ")", "->", "\"PredicateType\"", ":", "\n", "        ", "\"\"\"\n        Constructs an NLTK ``ComplexType`` representing a function with the given argument and\n        return types.\n        \"\"\"", "\n", "# TODO(mattg): We might need to generalize this to just `get_type`, so we can handle", "\n", "# functions as arguments correctly in the logic below.", "\n", "if", "not", "arg_types", ":", "\n", "# Functions with no arguments are basically constants whose type match their return", "\n", "# type.", "\n", "            ", "return", "return_type", "\n", "", "return", "FunctionType", "(", "arg_types", ",", "return_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.BasicType.__init__": [[124, 126], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ":", "str", ")", "->", "None", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.BasicType.__repr__": [[127, 129], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.BasicType.__hash__": [[130, 132], ["hash"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.BasicType.__eq__": [[133, 137], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "name", "==", "other", ".", "name", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.FunctionType.__init__": [[147, 151], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["def", "__init__", "(", "self", ",", "argument_types", ":", "Sequence", "[", "PredicateType", "]", ",", "return_type", ":", "PredicateType", ")", "->", "None", ":", "\n", "        ", "self", ".", "argument_types", "=", "argument_types", "\n", "self", ".", "return_type", "=", "return_type", "\n", "self", ".", "name", "=", "f'<{\",\".join(str(arg) for arg in argument_types)}:{return_type}>'", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.FunctionType.__repr__": [[152, 154], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.FunctionType.__hash__": [[155, 157], ["hash"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.FunctionType.__eq__": [[158, 162], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "name", "==", "other", ".", "name", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.__init__": [[337, 362], ["collections.defaultdict", "dir", "domain_language.PredicateType.get_type", "isinstance", "allowed_constants.items", "getattr", "getattr", "getattr", "domain_language.DomainLanguage.add_constant", "getattr", "domain_language.DomainLanguage.add_predicate"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate"], ["def", "__init__", "(", "\n", "self", ",", "\n", "allowed_constants", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "start_types", ":", "Set", "[", "Type", "]", "=", "None", ",", "\n", "allow_function_currying", ":", "bool", "=", "False", ",", "\n", "allow_function_composition", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_allow_currying", "=", "allow_function_currying", "\n", "self", ".", "_allow_composition", "=", "allow_function_composition", "\n", "self", ".", "_functions", ":", "Dict", "[", "str", ",", "Callable", "]", "=", "{", "}", "\n", "self", ".", "_function_types", ":", "Dict", "[", "str", ",", "List", "[", "PredicateType", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "_start_types", ":", "Set", "[", "PredicateType", "]", "=", "{", "\n", "PredicateType", ".", "get_type", "(", "type_", ")", "for", "type_", "in", "start_types", "\n", "}", "\n", "for", "name", "in", "dir", "(", "self", ")", ":", "\n", "            ", "if", "isinstance", "(", "getattr", "(", "self", ",", "name", ")", ",", "types", ".", "MethodType", ")", ":", "\n", "                ", "function", "=", "getattr", "(", "self", ",", "name", ")", "\n", "if", "getattr", "(", "function", ",", "\"_is_predicate\"", ",", "False", ")", ":", "\n", "                    ", "side_arguments", "=", "getattr", "(", "function", ",", "\"_side_arguments\"", ",", "None", ")", "\n", "self", ".", "add_predicate", "(", "name", ",", "function", ",", "side_arguments", ")", "\n", "", "", "", "if", "allowed_constants", ":", "\n", "            ", "for", "name", ",", "value", "in", "allowed_constants", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "add_constant", "(", "name", ",", "value", ")", "\n", "# Caching this to avoid recomputing it every time `get_nonterminal_productions` is called.", "\n", "", "", "self", ".", "_nonterminal_productions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute": [[363, 370], ["logical_form.replace.replace.replace", "allennlp_semparse.common.util.lisp_to_nested_expression", "domain_language.DomainLanguage._execute_expression", "hasattr", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util.lisp_to_nested_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_expression"], ["", "def", "execute", "(", "self", ",", "logical_form", ":", "str", ")", ":", "\n", "        ", "\"\"\"Executes a logical form, using whatever predicates you have defined.\"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "\"_functions\"", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"You must call super().__init__() in your Language constructor\"", ")", "\n", "", "logical_form", "=", "logical_form", ".", "replace", "(", "\",\"", ",", "\" \"", ")", "\n", "expression", "=", "util", ".", "lisp_to_nested_expression", "(", "logical_form", ")", "\n", "return", "self", ".", "_execute_expression", "(", "expression", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence": [[371, 393], ["first_action.split", "allennlp_semparse.common.ExecutionError", "domain_language.DomainLanguage._execute_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_sequence"], ["", "def", "execute_action_sequence", "(", "\n", "self", ",", "action_sequence", ":", "List", "[", "str", "]", ",", "side_arguments", ":", "List", "[", "Dict", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Executes the program defined by an action sequence directly, without needing the overhead\n        of translating to a logical form first.  For any given program, :func:`execute` and this\n        function are equivalent, they just take different representations of the program, so you\n        can use whichever is more efficient.\n\n        Also, if you have state or side arguments associated with particular production rules\n        (e.g., the decoder's attention on an input utterance when a predicate was predicted), you\n        `must` use this function to execute the logical form, instead of :func:`execute`, so that\n        we can match the side arguments with the right functions.\n        \"\"\"", "\n", "# We'll strip off the first action, because it doesn't matter for execution.", "\n", "first_action", "=", "action_sequence", "[", "0", "]", "\n", "left_side", "=", "first_action", ".", "split", "(", "\" -> \"", ")", "[", "0", "]", "\n", "if", "left_side", "!=", "\"@start@\"", ":", "\n", "            ", "raise", "ExecutionError", "(", "\"invalid action sequence\"", ")", "\n", "", "remaining_actions", "=", "action_sequence", "[", "1", ":", "]", "\n", "remaining_side_args", "=", "side_arguments", "[", "1", ":", "]", "if", "side_arguments", "else", "None", "\n", "return", "self", ".", "_execute_sequence", "(", "remaining_actions", ",", "remaining_side_args", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions": [[394, 463], ["collections.defaultdict", "domain_language.DomainLanguage._function_types.items", "set", "domain_language.DomainLanguage._function_types.values", "actions[].add", "str", "sorted", "set.update", "actions[].add", "isinstance", "actions.items", "actions[].add", "isinstance", "len", "list", "isinstance", "domain_language.PredicateType.get_function_type", "actions[].add", "set", "list", "list.remove", "list.reverse", "domain_language.PredicateType.get_function_type", "actions[].add", "len", "reversed", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "get_nonterminal_productions", "(", "self", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"\n        Induces a grammar from the defined collection of predicates in this language and returns\n        all productions in that grammar, keyed by the non-terminal they are expanding.\n\n        This includes terminal productions implied by each predicate as well as productions for the\n        `return type` of each defined predicate.  For example, defining a \"multiply\" predicate adds\n        a \"<int,int:int> -> multiply\" terminal production to the grammar, and `also` a \"int ->\n        [<int,int:int>, int, int]\" non-terminal production, because I can use the \"multiply\"\n        predicate to produce an int.\n        \"\"\"", "\n", "if", "not", "self", ".", "_nonterminal_productions", ":", "\n", "            ", "actions", ":", "Dict", "[", "Union", "[", "str", ",", "PredicateType", "]", ",", "Set", "[", "str", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "# If you didn't give us a set of valid start types, we'll assume all types we know", "\n", "# about (including functional types) are valid start types.", "\n", "if", "self", ".", "_start_types", ":", "\n", "                ", "start_types", "=", "self", ".", "_start_types", "\n", "", "else", ":", "\n", "                ", "start_types", "=", "set", "(", ")", "\n", "for", "type_list", "in", "self", ".", "_function_types", ".", "values", "(", ")", ":", "\n", "                    ", "start_types", ".", "update", "(", "type_list", ")", "\n", "", "", "for", "start_type", "in", "start_types", ":", "\n", "                ", "actions", "[", "START_SYMBOL", "]", ".", "add", "(", "f\"{START_SYMBOL} -> {start_type}\"", ")", "\n", "", "for", "name", ",", "function_type_list", "in", "self", ".", "_function_types", ".", "items", "(", ")", ":", "\n", "                ", "for", "function_type", "in", "function_type_list", ":", "\n", "                    ", "actions", "[", "function_type", "]", ".", "add", "(", "f\"{function_type} -> {name}\"", ")", "\n", "if", "isinstance", "(", "function_type", ",", "FunctionType", ")", ":", "\n", "                        ", "return_type", "=", "function_type", ".", "return_type", "\n", "arg_types", "=", "function_type", ".", "argument_types", "\n", "right_side", "=", "f\"[{function_type}, {', '.join(str(arg_type) for arg_type in arg_types)}]\"", "\n", "actions", "[", "return_type", "]", ".", "add", "(", "f\"{return_type} -> {right_side}\"", ")", "\n", "\n", "", "", "", "if", "self", ".", "_allow_currying", ":", "\n", "                ", "function_types", "=", "[", "t", "for", "t", "in", "actions", "if", "isinstance", "(", "t", ",", "FunctionType", ")", "]", "\n", "for", "function_type", "in", "function_types", ":", "\n", "                    ", "if", "len", "(", "function_type", ".", "argument_types", ")", ">", "1", ":", "\n", "                        ", "argument_types", "=", "list", "(", "set", "(", "function_type", ".", "argument_types", ")", ")", "\n", "for", "uncurried_arg_type", "in", "argument_types", ":", "\n", "                            ", "curried_arg_types", "=", "list", "(", "\n", "reversed", "(", "[", "t", "for", "t", "in", "function_type", ".", "argument_types", "]", ")", "\n", ")", "\n", "curried_arg_types", ".", "remove", "(", "uncurried_arg_type", ")", "\n", "curried_arg_types", ".", "reverse", "(", ")", "\n", "curried_function_type", "=", "PredicateType", ".", "get_function_type", "(", "\n", "[", "uncurried_arg_type", "]", ",", "function_type", ".", "return_type", "\n", ")", "\n", "right_side", "=", "f'[{function_type}, {\", \".join(str(arg) for arg in curried_arg_types)}]'", "\n", "actions", "[", "curried_function_type", "]", ".", "add", "(", "\n", "f\"{curried_function_type} -> {right_side}\"", "\n", ")", "\n", "\n", "", "", "", "", "if", "self", ".", "_allow_composition", ":", "\n", "                ", "function_types", "=", "[", "t", "for", "t", "in", "actions", "if", "isinstance", "(", "t", ",", "FunctionType", ")", "]", "\n", "for", "type1", "in", "function_types", ":", "\n", "                    ", "for", "type2", "in", "function_types", ":", "\n", "                        ", "if", "len", "(", "type1", ".", "argument_types", ")", "!=", "1", ":", "\n", "                            ", "continue", "\n", "", "if", "type1", ".", "argument_types", "[", "0", "]", "!=", "type2", ".", "return_type", ":", "\n", "                            ", "continue", "\n", "", "composed_type", "=", "PredicateType", ".", "get_function_type", "(", "\n", "type2", ".", "argument_types", ",", "type1", ".", "return_type", "\n", ")", "\n", "right_side", "=", "f\"[*, {type1}, {type2}]\"", "\n", "actions", "[", "composed_type", "]", ".", "add", "(", "f\"{composed_type} -> {right_side}\"", ")", "\n", "\n", "", "", "", "self", ".", "_nonterminal_productions", "=", "{", "\n", "str", "(", "key", ")", ":", "sorted", "(", "value", ")", "for", "key", ",", "value", "in", "actions", ".", "items", "(", ")", "\n", "}", "\n", "", "return", "self", ".", "_nonterminal_productions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.all_possible_productions": [[464, 473], ["set", "domain_language.DomainLanguage.get_nonterminal_productions().values", "sorted", "set.update", "domain_language.DomainLanguage.get_nonterminal_productions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions"], ["", "def", "all_possible_productions", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Returns a sorted list of all production rules in the grammar induced by\n        :func:`get_nonterminal_productions`.\n        \"\"\"", "\n", "all_actions", "=", "set", "(", ")", "\n", "for", "action_set", "in", "self", ".", "get_nonterminal_productions", "(", ")", ".", "values", "(", ")", ":", "\n", "            ", "all_actions", ".", "update", "(", "action_set", ")", "\n", "", "return", "sorted", "(", "all_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence": [[474, 507], ["allennlp_semparse.common.util.lisp_to_nested_expression", "transitions.insert", "domain_language.DomainLanguage._get_transitions", "allennlp_semparse.common.ParsingError", "logger.error"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util.lisp_to_nested_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_transitions"], ["", "def", "logical_form_to_action_sequence", "(", "self", ",", "logical_form", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Converts a logical form into a linearization of the production rules from its abstract\n        syntax tree.  The linearization is top-down, depth-first.\n\n        Each production rule is formatted as \"LHS -> RHS\", where \"LHS\" is a single non-terminal\n        type, and RHS is either a terminal or a list of non-terminals (other possible values for\n        RHS in a more general context-free grammar are not produced by our grammar induction\n        logic).\n\n        Non-terminals are `types` in the grammar, either basic types (like ``int``, ``str``, or\n        some class that you define), or functional types, represented with angle brackets with a\n        colon separating arguments from the return type.  Multi-argument functions have commas\n        separating their argument types.  For example, ``<int:int>`` is a function that takes an\n        integer and returns an integer, and ``<int,int:int>`` is a function that takes two integer\n        arguments and returns an integer.\n\n        As an example translation from logical form to complete action sequence, the logical form\n        ``(add 2 3)`` would be translated to ``['@start@ -> int', 'int -> [<int,int:int>, int, int]',\n        '<int,int:int> -> add', 'int -> 2', 'int -> 3']``.\n        \"\"\"", "\n", "expression", "=", "util", ".", "lisp_to_nested_expression", "(", "logical_form", ")", "\n", "try", ":", "\n", "            ", "transitions", ",", "start_type", "=", "self", ".", "_get_transitions", "(", "expression", ",", "expected_type", "=", "None", ")", "\n", "if", "self", ".", "_start_types", "and", "start_type", "not", "in", "self", ".", "_start_types", ":", "\n", "                ", "raise", "ParsingError", "(", "\n", "f\"Expression had unallowed start type of {start_type}: {expression}\"", "\n", ")", "\n", "", "", "except", "ParsingError", "as", "error", ":", "\n", "            ", "logger", ".", "error", "(", "f\"Error parsing logical form: {logical_form}: {error}\"", ")", "\n", "raise", "\n", "", "transitions", ".", "insert", "(", "0", ",", "f\"@start@ -> {start_type}\"", ")", "\n", "return", "transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form": [[508, 534], ["nltk.Tree", "domain_language.nltk_tree_to_logical_form", "action.split", "domain_language.DomainLanguage._construct_node_from_actions", "logger.error", "logger.error", "allennlp_semparse.common.ParsingError", "logger.error"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.nltk_tree_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._construct_node_from_actions"], ["", "def", "action_sequence_to_logical_form", "(", "self", ",", "action_sequence", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Takes an action sequence as produced by :func:`logical_form_to_action_sequence`, which is a\n        linearization of an abstract syntax tree, and reconstructs the logical form defined by that\n        abstract syntax tree.\n        \"\"\"", "\n", "# Basic outline: we assume that the bracketing that we get in the RHS of each action is the", "\n", "# correct bracketing for reconstructing the logical form.  This is true when there is no", "\n", "# currying in the action sequence.  Given this assumption, we just need to construct a tree", "\n", "# from the action sequence, then output all of the leaves in the tree, with brackets around", "\n", "# the children of all non-terminal nodes.", "\n", "\n", "remaining_actions", "=", "[", "action", ".", "split", "(", "\" -> \"", ")", "for", "action", "in", "action_sequence", "]", "\n", "tree", "=", "Tree", "(", "remaining_actions", "[", "0", "]", "[", "1", "]", ",", "[", "]", ")", "\n", "\n", "try", ":", "\n", "            ", "remaining_actions", "=", "self", ".", "_construct_node_from_actions", "(", "tree", ",", "remaining_actions", "[", "1", ":", "]", ")", "\n", "", "except", "ParsingError", ":", "\n", "            ", "logger", ".", "error", "(", "\"Error parsing action sequence: %s\"", ",", "action_sequence", ")", "\n", "raise", "\n", "\n", "", "if", "remaining_actions", ":", "\n", "            ", "logger", ".", "error", "(", "\"Error parsing action sequence: %s\"", ",", "action_sequence", ")", "\n", "logger", ".", "error", "(", "\"Remaining actions were: %s\"", ",", "remaining_actions", ")", "\n", "raise", "ParsingError", "(", "\"Extra actions in action sequence\"", ")", "\n", "", "return", "nltk_tree_to_logical_form", "(", "tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_predicate": [[535, 572], ["inspect.signature", "domain_language.PredicateType.get_type", "domain_language.PredicateType.get_function_type", "domain_language.DomainLanguage._function_types[].append", "domain_language.PredicateType.get_type", "inspect.signature.parameters.items"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type"], ["", "def", "add_predicate", "(", "self", ",", "name", ":", "str", ",", "function", ":", "Callable", ",", "side_arguments", ":", "List", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Adds a predicate to this domain language.  Typically you do this with the ``@predicate``\n        decorator on the methods in your class.  But, if you need to for whatever reason, you can\n        also call this function yourself with a (type-annotated) function to add it to your\n        language.\n\n        Parameters\n        ----------\n        name : ``str``\n            The name that we will use in the induced language for this function.\n        function : ``Callable``\n            The function that gets called when executing a predicate with the given name.\n        side_arguments : ``List[str]``, optional\n            If given, we will ignore these arguments for the purposes of grammar induction.  This\n            is to allow passing extra arguments from the decoder state that are not explicitly part\n            of the language the decoder produces, such as the decoder's attention over the question\n            when a terminal was predicted.  If you use this functionality, you also `must` use\n            ``language.execute_action_sequence()`` instead of ``language.execute()``, and you must\n            pass the additional side arguments needed to that function.  See\n            :func:`execute_action_sequence` for more information.\n        \"\"\"", "\n", "side_arguments", "=", "side_arguments", "or", "[", "]", "\n", "signature", "=", "inspect", ".", "signature", "(", "function", ")", "\n", "argument_types", "=", "[", "\n", "param", ".", "annotation", "\n", "for", "name", ",", "param", "in", "signature", ".", "parameters", ".", "items", "(", ")", "\n", "if", "name", "not", "in", "side_arguments", "\n", "]", "\n", "return_type", "=", "signature", ".", "return_annotation", "\n", "argument_nltk_types", ":", "List", "[", "PredicateType", "]", "=", "[", "\n", "PredicateType", ".", "get_type", "(", "arg_type", ")", "for", "arg_type", "in", "argument_types", "\n", "]", "\n", "return_nltk_type", "=", "PredicateType", ".", "get_type", "(", "return_type", ")", "\n", "function_nltk_type", "=", "PredicateType", ".", "get_function_type", "(", "argument_nltk_types", ",", "return_nltk_type", ")", "\n", "self", ".", "_functions", "[", "name", "]", "=", "function", "\n", "self", ".", "_function_types", "[", "name", "]", ".", "append", "(", "function_nltk_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.add_constant": [[573, 588], ["domain_language.PredicateType.get_type", "domain_language.DomainLanguage._function_types[].append", "type"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type"], ["", "def", "add_constant", "(", "self", ",", "name", ":", "str", ",", "value", ":", "Any", ",", "type_", ":", "Type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Adds a constant to this domain language.  You would typically just pass in a list of\n        constants to the ``super().__init__()`` call in your constructor, but you can also call\n        this method to add constants if it is more convenient.\n\n        Because we construct a grammar over this language for you, in order for the grammar to be\n        finite we cannot allow arbitrary constants.  Having a finite grammar is important when\n        you're doing semantic parsing - we need to be able to search over this space, and compute\n        normalized probability distributions.\n        \"\"\"", "\n", "value_type", "=", "type_", "if", "type_", "else", "type", "(", "value", ")", "\n", "constant_type", "=", "PredicateType", ".", "get_type", "(", "value_type", ")", "\n", "self", ".", "_functions", "[", "name", "]", "=", "lambda", ":", "value", "\n", "self", ".", "_function_types", "[", "name", "]", ".", "append", "(", "constant_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.is_nonterminal": [[589, 595], ["domain_language.DomainLanguage.get_nonterminal_productions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions"], ["", "def", "is_nonterminal", "(", "self", ",", "symbol", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Determines whether an input symbol is a valid non-terminal in the grammar.\n        \"\"\"", "\n", "nonterminal_productions", "=", "self", ".", "get_nonterminal_productions", "(", ")", "\n", "return", "symbol", "in", "nonterminal_productions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_expression": [[596, 652], ["isinstance", "isinstance", "isinstance", "domain_language.DomainLanguage._execute_expression", "domain_language.DomainLanguage._execute_expression", "domain_language.DomainLanguage.", "isinstance", "allennlp_semparse.common.ExecutionError", "domain_language.DomainLanguage._create_composed_function", "traceback.print_exc", "allennlp_semparse.common.ExecutionError", "allennlp_semparse.common.ExecutionError", "isinstance", "domain_language.DomainLanguage._get_curried_function", "allennlp_semparse.common.ExecutionError", "allennlp_semparse.common.ExecutionError"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._create_composed_function", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_curried_function"], ["", "def", "_execute_expression", "(", "self", ",", "expression", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        This does the bulk of the work of executing a logical form, recursively executing a single\n        expression.  Basically, if the expression is a function we know about, we evaluate its\n        arguments then call the function.  If it's a list, we evaluate all elements of the list.\n        If it's a constant (or a zero-argument function), we evaluate the constant.\n        \"\"\"", "\n", "if", "isinstance", "(", "expression", ",", "list", ")", ":", "\n", "            ", "if", "isinstance", "(", "expression", "[", "0", "]", ",", "list", ")", ":", "\n", "                ", "function", "=", "self", ".", "_execute_expression", "(", "expression", "[", "0", "]", ")", "\n", "", "elif", "expression", "[", "0", "]", "in", "self", ".", "_functions", ":", "\n", "                ", "function", "=", "self", ".", "_functions", "[", "expression", "[", "0", "]", "]", "\n", "", "elif", "self", ".", "_allow_composition", "and", "expression", "[", "0", "]", "==", "\"*\"", ":", "\n", "                ", "function", "=", "\"*\"", "\n", "", "else", ":", "\n", "                ", "if", "isinstance", "(", "expression", "[", "0", "]", ",", "str", ")", ":", "\n", "                    ", "raise", "ExecutionError", "(", "f\"Unrecognized function: {expression[0]}\"", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ExecutionError", "(", "f\"Unsupported expression type: {expression}\"", ")", "\n", "", "", "arguments", "=", "[", "self", ".", "_execute_expression", "(", "arg", ")", "for", "arg", "in", "expression", "[", "1", ":", "]", "]", "\n", "try", ":", "\n", "                ", "if", "self", ".", "_allow_composition", "and", "function", "==", "\"*\"", ":", "\n", "                    ", "return", "self", ".", "_create_composed_function", "(", "arguments", "[", "0", "]", ",", "arguments", "[", "1", "]", ")", "\n", "", "return", "function", "(", "*", "arguments", ")", "\n", "", "except", "(", "TypeError", ",", "ValueError", ")", ":", "\n", "                ", "if", "self", ".", "_allow_currying", ":", "\n", "# If we got here, then maybe the error is because this should be a curried", "\n", "# function.  We'll check for that and return the curried function if possible.", "\n", "                    ", "curried_function", "=", "self", ".", "_get_curried_function", "(", "function", ",", "arguments", ")", "\n", "if", "curried_function", ":", "\n", "                        ", "return", "curried_function", "\n", "", "", "traceback", ".", "print_exc", "(", ")", "\n", "raise", "ExecutionError", "(", "\n", "f\"Error executing expression {expression} (see stderr for stack trace)\"", "\n", ")", "\n", "", "", "elif", "isinstance", "(", "expression", ",", "str", ")", ":", "\n", "            ", "if", "expression", "not", "in", "self", ".", "_functions", ":", "\n", "                ", "raise", "ExecutionError", "(", "f\"Unrecognized constant: {expression}\"", ")", "\n", "# This is a bit of a quirk in how we represent constants and zero-argument functions.", "\n", "# For consistency, constants are wrapped in a zero-argument lambda.  So both constants", "\n", "# and zero-argument functions are callable in `self._functions`, and are `BasicTypes`", "\n", "# in `self._function_types`.  For these, we want to return", "\n", "# `self._functions[expression]()` _calling_ the zero-argument function.  If we get a", "\n", "# `FunctionType` in here, that means we're referring to the function as a first-class", "\n", "# object, instead of calling it (maybe as an argument to a higher-order function).  In", "\n", "# that case, we return the function _without_ calling it.", "\n", "# Also, we just check the first function type here, because we assume you haven't", "\n", "# registered the same function with both a constant type and a `FunctionType`.", "\n", "", "if", "isinstance", "(", "self", ".", "_function_types", "[", "expression", "]", "[", "0", "]", ",", "FunctionType", ")", ":", "\n", "                ", "return", "self", ".", "_functions", "[", "expression", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_functions", "[", "expression", "]", "(", ")", "\n", "", "return", "self", ".", "_functions", "[", "expression", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ExecutionError", "(", "\n", "\"Not sure how you got here. Please open a github issue with details.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_sequence": [[654, 760], ["allennlp_semparse.common.ExecutionError", "first_action.split", "isinstance", "right_side.split", "domain_language.DomainLanguage._execute_function", "domain_language.DomainLanguage._execute_sequence", "domain_language.DomainLanguage._execute_sequence", "arguments.append", "inspect.signature", "function", "domain_language.DomainLanguage._execute_function", "list", "inspect.signature", "domain_language.DomainLanguage._execute_function", "inspect.signature", "non_kwargs.append", "function", "function", "list", "function_argument", "inspect.signature.parameters.values"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_function", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_function", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_function", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "def", "_execute_sequence", "(", "\n", "self", ",", "action_sequence", ":", "List", "[", "str", "]", ",", "side_arguments", ":", "List", "[", "Dict", "]", "\n", ")", "->", "Tuple", "[", "Any", ",", "List", "[", "str", "]", ",", "List", "[", "Dict", "]", "]", ":", "\n", "        ", "\"\"\"\n        This does the bulk of the work of :func:`execute_action_sequence`, recursively executing\n        the functions it finds and trimming actions off of the action sequence.  The return value\n        is a tuple of (execution, remaining_actions), where the second value is necessary to handle\n        the recursion.\n        \"\"\"", "\n", "if", "not", "action_sequence", ":", "\n", "            ", "raise", "ExecutionError", "(", "\"invalid action sequence\"", ")", "\n", "", "first_action", "=", "action_sequence", "[", "0", "]", "\n", "remaining_actions", "=", "action_sequence", "[", "1", ":", "]", "\n", "remaining_side_args", "=", "side_arguments", "[", "1", ":", "]", "if", "side_arguments", "else", "None", "\n", "right_side", "=", "first_action", ".", "split", "(", "\" -> \"", ")", "[", "1", "]", "\n", "if", "right_side", "in", "self", ".", "_functions", ":", "\n", "            ", "function", "=", "self", ".", "_functions", "[", "right_side", "]", "\n", "# mypy doesn't like this check, saying that Callable isn't a reasonable thing to pass", "\n", "# here.  But it works just fine; I'm not sure why mypy complains about it.", "\n", "if", "isinstance", "(", "function", ",", "Callable", ")", ":", "# type: ignore", "\n", "                ", "function_arguments", "=", "inspect", ".", "signature", "(", "function", ")", ".", "parameters", "\n", "if", "not", "function_arguments", ":", "\n", "# This was a zero-argument function / constant that was registered as a lambda", "\n", "# function, for consistency of execution in `execute()`.", "\n", "                    ", "execution_value", "=", "function", "(", ")", "\n", "", "elif", "side_arguments", ":", "\n", "                    ", "kwargs", "=", "{", "}", "\n", "non_kwargs", "=", "[", "]", "\n", "for", "argument_name", "in", "function_arguments", ":", "\n", "                        ", "if", "argument_name", "in", "side_arguments", "[", "0", "]", ":", "\n", "                            ", "kwargs", "[", "argument_name", "]", "=", "side_arguments", "[", "0", "]", "[", "argument_name", "]", "\n", "", "else", ":", "\n", "                            ", "non_kwargs", ".", "append", "(", "argument_name", ")", "\n", "", "", "if", "kwargs", "and", "non_kwargs", ":", "\n", "# This is a function that has both side arguments and logical form", "\n", "# arguments - we curry the function so only the logical form arguments are", "\n", "# left.", "\n", "                        ", "def", "curried_function", "(", "*", "args", ")", ":", "\n", "                            ", "return", "function", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "execution_value", "=", "curried_function", "\n", "", "elif", "kwargs", ":", "\n", "# This is a function that _only_ has side arguments - we just call the", "\n", "# function and return a value.", "\n", "                        ", "execution_value", "=", "function", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# This is a function that has logical form arguments, but no side arguments", "\n", "# that match what we were given - just return the function itself.", "\n", "                        ", "execution_value", "=", "function", "\n", "", "", "else", ":", "\n", "                    ", "execution_value", "=", "function", "\n", "", "", "return", "execution_value", ",", "remaining_actions", ",", "remaining_side_args", "\n", "", "else", ":", "\n", "# This is a non-terminal expansion, like 'int -> [<int:int>, int, int]'.  We need to", "\n", "# get the function and its arguments, then call the function with its arguments.", "\n", "# Because we linearize the abstract syntax tree depth first, left-to-right, we can just", "\n", "# recursively call `_execute_sequence` for the function and all of its arguments, and", "\n", "# things will just work.", "\n", "            ", "right_side_parts", "=", "right_side", ".", "split", "(", "\", \"", ")", "\n", "\n", "if", "right_side_parts", "[", "0", "]", "==", "\"[*\"", "and", "self", ".", "_allow_composition", ":", "\n", "# This one we need to handle differently, because the \"function\" is a function", "\n", "# composition which doesn't show up in the action sequence.", "\n", "                ", "function", "=", "\"*\"", "# type: ignore", "\n", "", "else", ":", "\n", "# Otherwise, we grab the function itself by executing the next self-contained action", "\n", "# sequence (if this is a simple function call, that will be exactly one action; if", "\n", "# it's a higher-order function, it could be many actions).", "\n", "                ", "function", ",", "remaining_actions", ",", "remaining_side_args", "=", "self", ".", "_execute_sequence", "(", "\n", "remaining_actions", ",", "remaining_side_args", "\n", ")", "\n", "# We don't really need to know what the types of the arguments are, just how many of them", "\n", "# there are, so we recurse the right number of times.", "\n", "", "arguments", "=", "[", "]", "\n", "for", "_", "in", "right_side_parts", "[", "1", ":", "]", ":", "\n", "                ", "argument", ",", "remaining_actions", ",", "remaining_side_args", "=", "self", ".", "_execute_sequence", "(", "\n", "remaining_actions", ",", "remaining_side_args", "\n", ")", "\n", "arguments", ".", "append", "(", "argument", ")", "\n", "", "if", "self", ".", "_allow_composition", "and", "function", "==", "\"*\"", ":", "\n", "# In this case, both arguments should be functions, and we want to compose them, by", "\n", "# calling the second argument first, and passing the result to the first argument.", "\n", "                ", "def", "composed_function", "(", "*", "args", ")", ":", "\n", "                    ", "function_argument", ",", "is_curried", "=", "self", ".", "_execute_function", "(", "arguments", "[", "1", "]", ",", "list", "(", "args", ")", ")", "\n", "if", "is_curried", ":", "\n", "# If the inner function ended up curried, we have to curry the outer", "\n", "# function too.", "\n", "                        ", "return_type", "=", "inspect", ".", "signature", "(", "arguments", "[", "0", "]", ")", ".", "return_annotation", "\n", "inner_signature", "=", "inspect", ".", "signature", "(", "function_argument", ")", "\n", "arg_type", "=", "list", "(", "inner_signature", ".", "parameters", ".", "values", "(", ")", ")", "[", "0", "]", ".", "annotation", "\n", "\n", "# Pretty cool that you can give runtime types to a function defined at", "\n", "# runtime, but mypy has no idea what to do with this.", "\n", "def", "curried_function", "(", "x", ":", "arg_type", ")", "->", "return_type", ":", "# type: ignore", "\n", "                            ", "return", "arguments", "[", "0", "]", "(", "function_argument", "(", "x", ")", ")", "\n", "\n", "", "function_value", "=", "curried_function", "\n", "", "else", ":", "\n", "                        ", "function_value", ",", "_", "=", "self", ".", "_execute_function", "(", "\n", "arguments", "[", "0", "]", ",", "[", "function_argument", "]", "\n", ")", "\n", "", "return", "function_value", "\n", "\n", "", "return", "composed_function", ",", "remaining_actions", ",", "remaining_side_args", "\n", "", "function_value", ",", "_", "=", "self", ".", "_execute_function", "(", "function", ",", "arguments", ")", "\n", "return", "function_value", ",", "remaining_actions", ",", "remaining_side_args", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_function": [[761, 781], ["function", "domain_language.DomainLanguage._get_curried_function"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_curried_function"], ["", "", "def", "_execute_function", "(", "self", ",", "function", ":", "Callable", ",", "arguments", ":", "List", "[", "Any", "]", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Calls `function` with the given `arguments`, allowing for the possibility of currying the\n        `function`.\n        \"\"\"", "\n", "is_curried", "=", "False", "\n", "try", ":", "\n", "            ", "function_value", "=", "function", "(", "*", "arguments", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "if", "not", "self", ".", "_allow_currying", ":", "\n", "                ", "raise", "\n", "# If we got here, then maybe the error is because this should be a curried", "\n", "# function.  We'll check for that and return the curried function if possible.", "\n", "", "curried_function", "=", "self", ".", "_get_curried_function", "(", "function", ",", "arguments", ")", "\n", "if", "curried_function", ":", "\n", "                ", "function_value", "=", "curried_function", "\n", "is_curried", "=", "True", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "", "", "return", "function_value", ",", "is_curried", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_transitions": [[782, 829], ["isinstance", "domain_language.DomainLanguage._get_function_transitions", "zip", "isinstance", "len", "len", "allennlp_semparse.common.ParsingError", "argument_transitions.extend", "allennlp_semparse.common.ParsingError", "allennlp_semparse.common.ParsingError", "len", "domain_language.DomainLanguage._get_transitions", "allennlp_semparse.common.ParsingError", "allennlp_semparse.common.ParsingError", "allennlp_semparse.common.ParsingError"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_function_transitions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_transitions"], ["", "def", "_get_transitions", "(", "\n", "self", ",", "expression", ":", "Any", ",", "expected_type", ":", "PredicateType", "\n", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "PredicateType", "]", ":", "\n", "        ", "\"\"\"\n        This is used when converting a logical form into an action sequence.  This piece\n        recursively translates a lisp expression into an action sequence, making sure we match the\n        expected type (or using the expected type to get the right type for constant expressions).\n        \"\"\"", "\n", "if", "isinstance", "(", "expression", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "function_transitions", ",", "return_type", ",", "argument_types", "=", "self", ".", "_get_function_transitions", "(", "\n", "expression", ",", "expected_type", "\n", ")", "\n", "if", "len", "(", "argument_types", ")", "!=", "len", "(", "expression", "[", "1", ":", "]", ")", ":", "\n", "                ", "raise", "ParsingError", "(", "f\"Wrong number of arguments for function in {expression}\"", ")", "\n", "", "argument_transitions", "=", "[", "]", "\n", "for", "argument_type", ",", "subexpression", "in", "zip", "(", "argument_types", ",", "expression", "[", "1", ":", "]", ")", ":", "\n", "                ", "argument_transitions", ".", "extend", "(", "self", ".", "_get_transitions", "(", "subexpression", ",", "argument_type", ")", "[", "0", "]", ")", "\n", "", "return", "function_transitions", "+", "argument_transitions", ",", "return_type", "\n", "", "elif", "isinstance", "(", "expression", ",", "str", ")", ":", "\n", "            ", "if", "expression", "not", "in", "self", ".", "_functions", ":", "\n", "                ", "raise", "ParsingError", "(", "f\"Unrecognized constant: {expression}\"", ")", "\n", "", "constant_types", "=", "self", ".", "_function_types", "[", "expression", "]", "\n", "if", "len", "(", "constant_types", ")", "==", "1", ":", "\n", "                ", "constant_type", "=", "constant_types", "[", "0", "]", "\n", "# This constant had only one type; that's the easy case.", "\n", "if", "expected_type", "and", "expected_type", "!=", "constant_type", ":", "\n", "                    ", "raise", "ParsingError", "(", "\n", "f\"{expression} did not have expected type {expected_type} \"", "\n", "f\"(found {constant_type})\"", "\n", ")", "\n", "", "return", "[", "f\"{constant_type} -> {expression}\"", "]", ",", "constant_type", "\n", "", "else", ":", "\n", "                ", "if", "not", "expected_type", ":", "\n", "                    ", "raise", "ParsingError", "(", "\n", "\"With no expected type and multiple types to pick from \"", "\n", "f\"I don't know what type to use (constant was {expression})\"", "\n", ")", "\n", "", "if", "expected_type", "not", "in", "constant_types", ":", "\n", "                    ", "raise", "ParsingError", "(", "\n", "f\"{expression} did not have expected type {expected_type} \"", "\n", "f\"(found these options: {constant_types}; none matched)\"", "\n", ")", "\n", "", "return", "[", "f\"{expected_type} -> {expression}\"", "]", ",", "expected_type", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ParsingError", "(", "\n", "\"Not sure how you got here. Please open an issue on github with details.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_function_transitions": [[831, 974], ["isinstance", "transitions.insert", "domain_language.DomainLanguage._get_transitions", "isinstance", "allennlp_semparse.common.ParsingError", "domain_language.DomainLanguage._get_curried_function", "inspect.signature", "domain_language.PredicateType.get_type", "domain_language.PredicateType.get_type", "domain_language.PredicateType.get_function_type", "list", "list.remove", "list.reverse", "transitions.insert", "allennlp_semparse.common.ParsingError", "len", "domain_language.DomainLanguage._execute_expression", "domain_language.DomainLanguage._execute_expression", "reversed", "len", "allennlp_semparse.common.ParsingError", "domain_language.DomainLanguage._get_function_transitions", "isinstance", "domain_language.DomainLanguage._get_function_transitions", "isinstance", "domain_language.PredicateType.get_function_type", "isinstance", "len", "len", "isinstance", "isinstance", "domain_language.PredicateType.get_function_type", "domain_language.PredicateType.get_function_type", "allennlp_semparse.common.ParsingError", "allennlp_semparse.common.ParsingError", "list", "str", "inspect.signature.parameters.values", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_transitions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_curried_function", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._execute_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_function_transitions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_function_transitions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.PredicateType.get_function_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "", "def", "_get_function_transitions", "(", "\n", "self", ",", "expression", ":", "Sequence", ",", "expected_type", ":", "PredicateType", "\n", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "PredicateType", ",", "Sequence", "[", "PredicateType", "]", "]", ":", "\n", "        ", "\"\"\"\n        A helper method for ``_get_transitions``.  This gets the transitions for the predicate\n        itself in a function call.  If we only had simple functions (e.g., \"(add 2 3)\"), this would\n        be pretty straightforward and we wouldn't need a separate method to handle it.  We split it\n        out into its own method because handling higher-order functions and currying is complicated\n        (e.g., something like \"((negate add) 2 3)\" or \"((multiply 3) 2)\").\n        \"\"\"", "\n", "function_expression", "=", "expression", "[", "0", "]", "\n", "# This first block handles getting the transitions and function type (and some error", "\n", "# checking) _just for the function itself_.  If this is a simple function, this is easy; if", "\n", "# it's a higher-order function, it involves some recursion.", "\n", "if", "isinstance", "(", "function_expression", ",", "list", ")", ":", "\n", "# This is a higher-order function.  TODO(mattg): we'll just ignore type checking on", "\n", "# higher-order functions, for now.", "\n", "# Some annoying redirection here to make mypy happy; need to specify the type of", "\n", "# function_type.", "\n", "            ", "result", "=", "self", ".", "_get_transitions", "(", "function_expression", ",", "None", ")", "\n", "transitions", "=", "result", "[", "0", "]", "\n", "function_type", ":", "FunctionType", "=", "result", "[", "1", "]", "# type: ignore", "\n", "# This is a bit of an unfortunate hack. In order to handle currying, we currently rely", "\n", "# on executing the function, for which we need actual function code (see the class", "\n", "# docstring).  I want to avoid executing the function prematurely, though, so this still", "\n", "# works in cases where you don't need to handle currying higher-order functions.  So,", "\n", "# we'll leave this as `None` and handle it below, if indeed you are currying this", "\n", "# function.", "\n", "function", "=", "None", "\n", "", "elif", "function_expression", "in", "self", ".", "_functions", ":", "\n", "            ", "name", "=", "function_expression", "\n", "function_types", "=", "self", ".", "_function_types", "[", "function_expression", "]", "\n", "if", "len", "(", "function_types", ")", "!=", "1", ":", "\n", "                ", "raise", "ParsingError", "(", "\n", "f\"{function_expression} had multiple types; this is not yet supported for functions\"", "\n", ")", "\n", "", "function_type", "=", "function_types", "[", "0", "]", "# type: ignore", "\n", "\n", "transitions", "=", "[", "f\"{function_type} -> {name}\"", "]", "\n", "function", "=", "self", ".", "_functions", "[", "function_expression", "]", "\n", "\n", "", "elif", "self", ".", "_allow_composition", "and", "function_expression", "==", "\"*\"", ":", "\n", "            ", "outer_function_expression", "=", "expression", "[", "1", "]", "\n", "if", "not", "isinstance", "(", "outer_function_expression", ",", "list", ")", ":", "\n", "                ", "outer_function_expression", "=", "[", "outer_function_expression", "]", "\n", "", "inner_function_expression", "=", "expression", "[", "2", "]", "\n", "if", "not", "isinstance", "(", "inner_function_expression", ",", "list", ")", ":", "\n", "                ", "inner_function_expression", "=", "[", "inner_function_expression", "]", "\n", "\n", "# This is unfortunately a bit complex.  What we really what is the _type_ of these", "\n", "# expressions.  We don't have a function that will give us that.  Instead, we have a", "\n", "# function that will give us return types and argument types.  If we have a bare", "\n", "# function name, like \"sum\", this works fine.  But if it's a higher-order function", "\n", "# (including a curried function), then the return types and argument types from", "\n", "# _get_function_transitions aren't what we're looking for here, because that function is", "\n", "# designed for something else.  We need to hack our way around that a bit, by grabbing", "\n", "# the return type from the inner return type (confusing, I know).", "\n", "", "_", ",", "outer_return_type", ",", "outer_arg_types", "=", "self", ".", "_get_function_transitions", "(", "\n", "outer_function_expression", ",", "None", "\n", ")", "\n", "if", "isinstance", "(", "expression", "[", "1", "]", ",", "list", ")", ":", "\n", "                ", "outer_function_type", ":", "FunctionType", "=", "outer_return_type", "# type: ignore", "\n", "", "else", ":", "\n", "                ", "outer_function_type", "=", "PredicateType", ".", "get_function_type", "(", "# type: ignore", "\n", "outer_arg_types", ",", "outer_return_type", "\n", ")", "\n", "\n", "", "_", ",", "inner_return_type", ",", "inner_arg_types", "=", "self", ".", "_get_function_transitions", "(", "\n", "inner_function_expression", ",", "None", "\n", ")", "\n", "if", "isinstance", "(", "expression", "[", "2", "]", ",", "list", ")", ":", "\n", "                ", "inner_function_type", ":", "FunctionType", "=", "inner_return_type", "# type: ignore", "\n", "", "else", ":", "\n", "                ", "inner_function_type", "=", "PredicateType", ".", "get_function_type", "(", "# type: ignore", "\n", "inner_arg_types", ",", "inner_return_type", "\n", ")", "\n", "\n", "", "composition_argument_types", "=", "[", "outer_function_type", ",", "inner_function_type", "]", "\n", "composition_type", "=", "PredicateType", ".", "get_function_type", "(", "\n", "inner_function_type", ".", "argument_types", ",", "outer_function_type", ".", "return_type", "\n", ")", "\n", "right_side", "=", "f'[*, {\", \".join(str(arg) for arg in composition_argument_types)}]'", "\n", "composition_transition", "=", "f\"{composition_type} -> {right_side}\"", "\n", "return", "[", "composition_transition", "]", ",", "composition_type", ",", "composition_argument_types", "\n", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "function_expression", ",", "str", ")", ":", "\n", "                ", "raise", "ParsingError", "(", "f\"Unrecognized function: {function_expression[0]}\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ParsingError", "(", "f\"Unsupported function_expression type: {function_expression}\"", ")", "\n", "\n", "", "", "if", "not", "isinstance", "(", "function_type", ",", "FunctionType", ")", ":", "\n", "            ", "raise", "ParsingError", "(", "f\"Zero-arg function or constant called with arguments: {name}\"", ")", "\n", "\n", "# Now that we have the transitions for the function itself, and the function's type, we can", "\n", "# get argument types and do the rest of the transitions.  The first thing we need to do is", "\n", "# check if we need to curry this function, because we're missing an argument.", "\n", "", "if", "(", "\n", "self", ".", "_allow_currying", "\n", "# This check means we're missing an argument to the function.", "\n", "and", "len", "(", "expression", ")", ">", "1", "\n", "and", "len", "(", "function_type", ".", "argument_types", ")", "-", "1", "==", "len", "(", "expression", ")", "-", "1", "\n", ")", ":", "\n", "# If we're currying this function, we need to add a transition that encodes the", "\n", "# currying, and change the function_type accordingly.", "\n", "            ", "arguments", "=", "[", "self", ".", "_execute_expression", "(", "e", ")", "for", "e", "in", "expression", "[", "1", ":", "]", "]", "\n", "if", "function", "is", "None", ":", "\n", "                ", "function", "=", "self", ".", "_execute_expression", "(", "function_expression", ")", "\n", "", "curried_function", "=", "self", ".", "_get_curried_function", "(", "function", ",", "arguments", ")", "\n", "\n", "# Here we get the FunctionType corresponding to the new, curried function.", "\n", "signature", "=", "inspect", ".", "signature", "(", "curried_function", ")", "\n", "return_type", "=", "PredicateType", ".", "get_type", "(", "signature", ".", "return_annotation", ")", "\n", "uncurried_arg_type", "=", "PredicateType", ".", "get_type", "(", "\n", "list", "(", "signature", ".", "parameters", ".", "values", "(", ")", ")", "[", "0", "]", ".", "annotation", "\n", ")", "\n", "curried_function_type", "=", "PredicateType", ".", "get_function_type", "(", "\n", "[", "uncurried_arg_type", "]", ",", "return_type", "\n", ")", "\n", "\n", "# To fit in with the logic below, we need to basically make a fake `curry`", "\n", "# FunctionType, with the arguments being the function we're currying and all of the", "\n", "# curried arguments, and the return type being the one-argument function.  Then we", "\n", "# can re-use all of the existing logic without modification.", "\n", "curried_arg_types", "=", "list", "(", "reversed", "(", "[", "t", "for", "t", "in", "function_type", ".", "argument_types", "]", ")", ")", "\n", "curried_arg_types", ".", "remove", "(", "uncurried_arg_type", ")", "\n", "curried_arg_types", ".", "reverse", "(", ")", "\n", "right_side", "=", "f'[{function_type}, {\", \".join(str(arg) for arg in curried_arg_types)}]'", "\n", "curry_transition", "=", "f\"{curried_function_type} -> {right_side}\"", "\n", "transitions", ".", "insert", "(", "0", ",", "curry_transition", ")", "\n", "return", "transitions", ",", "curried_function_type", ",", "curried_arg_types", "\n", "\n", "", "argument_types", "=", "function_type", ".", "argument_types", "\n", "return_type", "=", "function_type", ".", "return_type", "\n", "right_side", "=", "f'[{function_type}, {\", \".join(str(arg) for arg in argument_types)}]'", "\n", "first_transition", "=", "f\"{return_type} -> {right_side}\"", "\n", "transitions", ".", "insert", "(", "0", ",", "first_transition", ")", "\n", "if", "expected_type", "and", "expected_type", "!=", "return_type", ":", "\n", "            ", "raise", "ParsingError", "(", "\n", "f\"{function_expression} did not have expected type {expected_type} \"", "\n", "f\"(found {return_type})\"", "\n", ")", "\n", "", "return", "transitions", ",", "return_type", ",", "argument_types", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._construct_node_from_actions": [[975, 1023], ["domain_language.DomainLanguage.pop", "logger.error", "allennlp_semparse.common.ParsingError", "current_node.label", "logger.error", "logger.error", "logger.error", "allennlp_semparse.common.ParsingError", "right_side[].split", "current_node.append", "nltk.Tree", "current_node.append", "domain_language.DomainLanguage._construct_node_from_actions", "nltk.Tree"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._construct_node_from_actions"], ["", "def", "_construct_node_from_actions", "(", "\n", "self", ",", "current_node", ":", "Tree", ",", "remaining_actions", ":", "List", "[", "List", "[", "str", "]", "]", "\n", ")", "->", "List", "[", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"\n        Given a current node in the logical form tree, and a list of actions in an action sequence,\n        this method fills in the children of the current node from the action sequence, then\n        returns whatever actions are left.\n\n        For example, we could get a node with type ``c``, and an action sequence that begins with\n        ``c -> [<r,c>, r]``.  This method will add two children to the input node, consuming\n        actions from the action sequence for nodes of type ``<r,c>`` (and all of its children,\n        recursively) and ``r`` (and all of its children, recursively).  This method assumes that\n        action sequences are produced `depth-first`, so all actions for the subtree under ``<r,c>``\n        appear before actions for the subtree under ``r``.  If there are any actions in the action\n        sequence after the ``<r,c>`` and ``r`` subtrees have terminated in leaf nodes, they will be\n        returned.\n        \"\"\"", "\n", "if", "not", "remaining_actions", ":", "\n", "            ", "logger", ".", "error", "(", "\"No actions left to construct current node: %s\"", ",", "current_node", ")", "\n", "raise", "ParsingError", "(", "\"Incomplete action sequence\"", ")", "\n", "", "left_side", ",", "right_side", "=", "remaining_actions", ".", "pop", "(", "0", ")", "\n", "if", "left_side", "!=", "current_node", ".", "label", "(", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Current node: %s\"", ",", "current_node", ")", "\n", "logger", ".", "error", "(", "\"Next action: %s -> %s\"", ",", "left_side", ",", "right_side", ")", "\n", "logger", ".", "error", "(", "\"Remaining actions were: %s\"", ",", "remaining_actions", ")", "\n", "raise", "ParsingError", "(", "\"Current node does not match next action\"", ")", "\n", "", "if", "right_side", "[", "0", "]", "==", "\"[\"", ":", "\n", "# This is a non-terminal expansion, with more than one child node.", "\n", "            ", "for", "child_type", "in", "right_side", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", ":", "\n", "                ", "child_node", "=", "Tree", "(", "child_type", ",", "[", "]", ")", "\n", "current_node", ".", "append", "(", "child_node", ")", "# you add a child to an nltk.Tree with `append`", "\n", "# For now, we assume that all children in a list like this are non-terminals, so we", "\n", "# recurse on them.  I'm pretty sure that will always be true for the way our", "\n", "# grammar induction works.  We can revisit this later if we need to.", "\n", "if", "self", ".", "_allow_composition", "and", "child_type", "==", "\"*\"", ":", "\n", "# One exception to the comment above is when we are doing function composition.", "\n", "# The function composition operator * does not have a corresponding action, so", "\n", "# the recursion on constructing that node doesn't work.", "\n", "                    ", "continue", "\n", "", "remaining_actions", "=", "self", ".", "_construct_node_from_actions", "(", "child_node", ",", "remaining_actions", ")", "\n", "", "", "else", ":", "\n", "# The current node is a pre-terminal; we'll add a single terminal child.  By", "\n", "# construction, the right-hand side of our production rules are only ever terminal", "\n", "# productions or lists of non-terminals.", "\n", "            ", "current_node", ".", "append", "(", "\n", "Tree", "(", "right_side", ",", "[", "]", ")", "\n", ")", "# you add a child to an nltk.Tree with `append`", "\n", "", "return", "remaining_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._get_curried_function": [[1024, 1061], ["inspect.signature", "list", "len", "parameters.values", "isinstance", "function", "len", "domain_language.infer_collection_type", "type", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.infer_collection_type", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type"], ["", "def", "_get_curried_function", "(", "self", ",", "function", ":", "Callable", ",", "arguments", ":", "List", "[", "Any", "]", ")", "->", "Optional", "[", "Callable", "]", ":", "\n", "        ", "signature", "=", "inspect", ".", "signature", "(", "function", ")", "\n", "parameters", "=", "signature", ".", "parameters", "\n", "if", "len", "(", "parameters", ")", "!=", "len", "(", "arguments", ")", "+", "1", ":", "\n", "# We only allow currying that makes a function into a one-argument function.  This is to", "\n", "# simplify both the complexity of the `DomainLanguage` code and the complexity of", "\n", "# whatever model might use the resulting grammar.  For all currently-envisioned uses of", "\n", "# currying, we only need to make one-argument functions.  These are predominantly for", "\n", "# replacing lambda functions in argmaxes and the like.", "\n", "            ", "return", "None", "\n", "# Now we have to decide where the missing argument goes in the list of arguments.  We will", "\n", "# look at types to figure that out, and arbitrarily say that if there are multiple matching", "\n", "# types, the missing one comes last.", "\n", "", "missing_arg_index", "=", "0", "\n", "parameter_types", "=", "list", "(", "parameters", ".", "values", "(", ")", ")", "\n", "for", "parameter", "in", "parameter_types", ":", "\n", "            ", "argument", "=", "arguments", "[", "missing_arg_index", "]", "\n", "if", "isinstance", "(", "argument", ",", "(", "list", ",", "set", ")", ")", ":", "\n", "                ", "arg_type", "=", "infer_collection_type", "(", "argument", ")", "\n", "", "else", ":", "\n", "                ", "arg_type", "=", "type", "(", "argument", ")", "\n", "", "if", "parameter", ".", "annotation", "==", "arg_type", ":", "\n", "                ", "missing_arg_index", "+=", "1", "\n", "if", "missing_arg_index", "==", "len", "(", "parameters", ")", "-", "1", ":", "\n", "                    ", "break", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "arg_type", "=", "parameter_types", "[", "missing_arg_index", "]", ".", "annotation", "\n", "\n", "# Pretty cool that you can give runtime types to a function defined at runtime, but mypy has", "\n", "# no idea what to do with this.", "\n", "def", "curried_function", "(", "x", ":", "arg_type", ")", "->", "signature", ".", "return_annotation", ":", "# type: ignore", "\n", "            ", "new_arguments", "=", "arguments", "[", ":", "missing_arg_index", "]", "+", "[", "x", "]", "+", "arguments", "[", "missing_arg_index", ":", "]", "\n", "return", "function", "(", "*", "new_arguments", ")", "\n", "\n", "", "return", "curried_function", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage._create_composed_function": [[1062, 1118], ["inspect.signature", "inspect.signature", "len", "inspect.signature.parameters.values", "outer_function", "len", "inner_function", "outer_function", "len", "inner_function", "outer_function", "len", "ValueError", "inner_function", "outer_function", "inner_function"], "methods", ["None"], ["", "def", "_create_composed_function", "(", "\n", "self", ",", "outer_function", ":", "Callable", ",", "inner_function", ":", "Callable", "\n", ")", "->", "Callable", ":", "\n", "        ", "\"\"\"\n        Creating a composed function is easy; just do a `def` and call the functions in order.  This\n        function exists because we need the composed function to have _correct type annotations_,\n        which is harder.  We can't use `*args` for the lambda function that we construct, so we need\n        to switch on how many arguments the inner function takes, and create functions with the\n        right argument type annotations.\n\n        And, as in other places where we assign types at runtime, mypy has no idea what's going on,\n        so we tell it to ignore this code.  `inspect` will do the right thing, even if mypy can't\n        analyze it.\n        \"\"\"", "\n", "inner_signature", "=", "inspect", ".", "signature", "(", "inner_function", ")", "\n", "outer_signature", "=", "inspect", ".", "signature", "(", "outer_function", ")", "\n", "argument_types", "=", "[", "arg", ".", "annotation", "for", "arg", "in", "inner_signature", ".", "parameters", ".", "values", "(", ")", "]", "\n", "return_type", "=", "outer_signature", ".", "return_annotation", "\n", "\n", "if", "len", "(", "argument_types", ")", "==", "1", ":", "\n", "\n", "            ", "def", "composed_function", "(", "arg1", ":", "argument_types", "[", "0", "]", ")", "->", "return_type", ":", "# type: ignore", "\n", "                ", "return", "outer_function", "(", "inner_function", "(", "arg1", ")", ")", "\n", "\n", "", "", "elif", "len", "(", "argument_types", ")", "==", "2", ":", "\n", "\n", "            ", "def", "composed_function", "(", "# type: ignore", "\n", "arg1", ":", "argument_types", "[", "0", "]", ",", "arg2", ":", "argument_types", "[", "1", "]", "# type:ignore", "\n", ")", "->", "return_type", ":", "# type: ignore", "\n", "                ", "return", "outer_function", "(", "inner_function", "(", "arg1", ",", "arg2", ")", ")", "\n", "\n", "", "", "elif", "len", "(", "argument_types", ")", "==", "3", ":", "\n", "\n", "            ", "def", "composed_function", "(", "# type:ignore", "\n", "arg1", ":", "argument_types", "[", "0", "]", ",", "# type: ignore", "\n", "arg2", ":", "argument_types", "[", "1", "]", ",", "# type: ignore", "\n", "arg3", ":", "argument_types", "[", "2", "]", ",", "# type:ignore", "\n", ")", "->", "return_type", ":", "# type: ignore", "\n", "                ", "return", "outer_function", "(", "inner_function", "(", "arg1", ",", "arg2", ",", "arg3", ")", ")", "\n", "\n", "", "", "elif", "len", "(", "argument_types", ")", "==", "4", ":", "\n", "\n", "            ", "def", "composed_function", "(", "# type:ignore", "\n", "arg1", ":", "argument_types", "[", "0", "]", ",", "# type:ignore", "\n", "arg2", ":", "argument_types", "[", "1", "]", ",", "# type:ignore", "\n", "arg3", ":", "argument_types", "[", "2", "]", ",", "# type:ignore", "\n", "arg4", ":", "argument_types", "[", "3", "]", ",", "# type:ignore", "\n", ")", "->", "return_type", ":", "# type: ignore", "\n", "                ", "return", "outer_function", "(", "inner_function", "(", "arg1", ",", "arg2", ",", "arg3", ",", "arg4", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Inner function has a type signature that's not currently handled: {inner_function}\"", "\n", ")", "\n", "\n", "", "return", "composed_function", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.__len__": [[1119, 1123], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# This method exists just to make it easier to use this in a MetadataField.  Kind of", "\n", "# annoying, but oh well.", "\n", "        ", "return", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.is_callable": [[24, 31], ["isinstance", "getattr"], "function", ["None"], ["def", "is_callable", "(", "type_", ":", "Type", ")", "->", "bool", ":", "\n", "    ", "if", "sys", ".", "version_info", "<", "(", "3", ",", "7", ")", ":", "\n", "        ", "from", "typing", "import", "CallableMeta", "# type: ignore", "\n", "\n", "return", "isinstance", "(", "type_", ",", "CallableMeta", ")", "# type: ignore", "\n", "", "else", ":", "\n", "        ", "return", "getattr", "(", "type_", ",", "\"_name\"", ",", "None", ")", "==", "\"Callable\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.is_generic": [[33, 42], ["isinstance", "isinstance"], "function", ["None"], ["", "", "def", "is_generic", "(", "type_", ":", "Type", ")", "->", "bool", ":", "\n", "    ", "if", "sys", ".", "version_info", "<", "(", "3", ",", "7", ")", ":", "\n", "        ", "from", "typing", "import", "GenericMeta", "# type: ignore", "\n", "\n", "return", "isinstance", "(", "type_", ",", "GenericMeta", ")", "# type: ignore", "\n", "", "else", ":", "\n", "        ", "from", "typing", "import", "_GenericAlias", "# type: ignore", "\n", "\n", "return", "isinstance", "(", "type_", ",", "_GenericAlias", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.get_generic_name": [[44, 53], ["None"], "function", ["None"], ["", "", "def", "get_generic_name", "(", "type_", ":", "Type", ")", "->", "str", ":", "\n", "    ", "if", "sys", ".", "version_info", "<", "(", "3", ",", "7", ")", ":", "\n", "        ", "origin", "=", "type_", ".", "__origin__", ".", "__name__", "\n", "", "else", ":", "\n", "# In python 3.7, type_.__origin__ switched to the built-in class, instead of the typing", "\n", "# class.", "\n", "        ", "origin", "=", "type_", ".", "_name", "\n", "", "args", "=", "type_", ".", "__args__", "\n", "return", "f'{origin}[{\",\".join(arg.__name__ for arg in args)}]'", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.infer_collection_type": [[55, 66], ["set", "isinstance", "len", "ValueError", "list", "isinstance", "type", "ValueError"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.DynamicTypeApplicationExpression.type"], ["", "def", "infer_collection_type", "(", "collection", ":", "Any", ")", "->", "Type", ":", "\n", "    ", "instance_types", "=", "set", "(", "[", "type", "(", "instance", ")", "for", "instance", "in", "collection", "]", ")", "\n", "if", "len", "(", "instance_types", ")", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Inconsistent types in collection: {instance_types}, {collection}\"", ")", "\n", "", "subtype", "=", "list", "(", "instance_types", ")", "[", "0", "]", "\n", "if", "isinstance", "(", "collection", ",", "list", ")", ":", "\n", "        ", "return", "List", "[", "subtype", "]", "# type: ignore", "\n", "", "elif", "isinstance", "(", "collection", ",", "set", ")", ":", "\n", "        ", "return", "Set", "[", "subtype", "]", "# type: ignore", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unsupported top-level generic type: {collection}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.predicate": [[164, 173], ["setattr"], "function", ["None"], ["", "", "def", "predicate", "(", "function", ":", "Callable", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"\n    This is intended to be used as a decorator when you are implementing your ``DomainLanguage``.\n    This marks a function on a ``DomainLanguage`` subclass as a predicate that can be used in the\n    language.  See the :class:`DomainLanguage` docstring for an example usage, and for what using\n    this does.\n    \"\"\"", "\n", "setattr", "(", "function", ",", "\"_is_predicate\"", ",", "True", ")", "\n", "return", "function", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.predicate_with_side_args": [[175, 194], ["setattr", "domain_language.predicate"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.predicate"], ["", "def", "predicate_with_side_args", "(", "side_arguments", ":", "List", "[", "str", "]", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"\n    Like :func:`predicate`, but used when some of the arguments to the function are meant to be\n    provided by the decoder or other state, instead of from the language.  For example, you might\n    want to have a function use the decoder's attention over some input text when a terminal was\n    predicted.  That attention won't show up in the language productions.  Use this decorator, and\n    pass in the required state to :func:`DomainLanguage.execute_action_sequence`, if you need to\n    ignore some arguments when doing grammar induction.\n\n    In order for this to work out, the side arguments `must` be after any non-side arguments.  This\n    is because we use ``*args`` to pass the non-side arguments, and ``**kwargs`` to pass the side\n    arguments, and python requires that ``*args`` be before ``**kwargs``.\n    \"\"\"", "\n", "\n", "def", "decorator", "(", "function", ":", "Callable", ")", "->", "Callable", ":", "\n", "        ", "setattr", "(", "function", ",", "\"_side_arguments\"", ",", "side_arguments", ")", "\n", "return", "predicate", "(", "function", ")", "\n", "\n", "", "return", "decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.nltk_tree_to_logical_form": [[196, 214], ["len", "tree.label", "len", "tree[].label", "domain_language.nltk_tree_to_logical_form"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.nltk_tree_to_logical_form"], ["", "def", "nltk_tree_to_logical_form", "(", "tree", ":", "Tree", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Given an ``nltk.Tree`` representing the syntax tree that generates a logical form, this method\n    produces the actual (lisp-like) logical form, with all of the non-terminal symbols converted\n    into the correct number of parentheses.\n\n    This is used in the logic that converts action sequences back into logical forms.  It's very\n    unlikely that you will need this anywhere else.\n    \"\"\"", "\n", "# nltk.Tree actually inherits from `list`, so you use `len()` to get the number of children.", "\n", "# We're going to be explicit about checking length, instead of using `if tree:`, just to avoid", "\n", "# any funny business nltk might have done (e.g., it's really odd if `if tree:` evaluates to", "\n", "# `False` if there's a single leaf node with no children).", "\n", "if", "len", "(", "tree", ")", "==", "0", ":", "\n", "        ", "return", "tree", ".", "label", "(", ")", "\n", "", "if", "len", "(", "tree", ")", "==", "1", ":", "\n", "        ", "return", "tree", "[", "0", "]", ".", "label", "(", ")", "\n", "", "return", "\"(\"", "+", "\" \"", ".", "join", "(", "nltk_tree_to_logical_form", "(", "child", ")", "for", "child", "in", "tree", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.__init__": [[12, 40], ["allennlp_semparse.DomainLanguage.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "allow_function_currying", ":", "bool", "=", "False", ",", "allow_function_composition", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "start_types", "=", "{", "int", "}", ",", "\n", "allowed_constants", "=", "{", "\n", "# We unfortunately have to explicitly enumerate all allowed constants in the", "\n", "# grammar.  Because we'll be inducing a grammar for this language for use with a", "\n", "# semantic parser, we need the grammar to be finite, which means we can't allow", "\n", "# arbitrary constants (you can't parameterize an infinite categorical", "\n", "# distribution).  So our Arithmetic language will have to only operate on simple", "\n", "# numbers.", "\n", "\"1\"", ":", "1", ",", "\n", "\"2\"", ":", "2", ",", "\n", "\"3\"", ":", "3", ",", "\n", "\"4\"", ":", "4", ",", "\n", "\"5\"", ":", "5", ",", "\n", "\"6\"", ":", "6", ",", "\n", "\"7\"", ":", "7", ",", "\n", "\"8\"", ":", "8", ",", "\n", "\"9\"", ":", "9", ",", "\n", "\"10\"", ":", "10", ",", "\n", "\"20\"", ":", "20", ",", "\n", "\"-5\"", ":", "-", "5", ",", "\n", "\"-2\"", ":", "-", "2", ",", "\n", "}", ",", "\n", "allow_function_currying", "=", "allow_function_currying", ",", "\n", "allow_function_composition", "=", "allow_function_composition", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add": [[42, 45], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "add", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "        ", "return", "num1", "+", "num2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum": [[46, 49], ["domain_language_test.Arithmetic.sum"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum"], ["", "@", "predicate", "\n", "def", "sum", "(", "self", ",", "numbers", ":", "List", "[", "int", "]", ")", "->", "int", ":", "\n", "        ", "return", "sum", "(", "numbers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.list1": [[53, 56], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "list1", "(", "self", ",", "num1", ":", "int", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "num1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.list2": [[57, 60], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "list2", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "num1", ",", "num2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.list3": [[61, 64], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "list3", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ",", "num3", ":", "int", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "num1", ",", "num2", ",", "num3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.list4": [[65, 68], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "list4", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ",", "num3", ":", "int", ",", "num4", ":", "int", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "num1", ",", "num2", ",", "num3", ",", "num4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.subtract": [[69, 72], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "subtract", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "        ", "return", "num1", "-", "num2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.power": [[73, 76], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "power", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "        ", "return", "num1", "**", "num2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.multiply": [[77, 80], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "multiply", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "        ", "return", "num1", "*", "num2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.divide": [[81, 84], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "divide", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "        ", "return", "num1", "//", "num2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.halve": [[85, 88], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "halve", "(", "self", ",", "num1", ":", "int", ")", "->", "int", ":", "\n", "        ", "return", "num1", "//", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.three": [[89, 92], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "three", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.three_less": [[93, 105], ["function"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "three_less", "(", "self", ",", "function", ":", "Callable", "[", "[", "int", ",", "int", "]", ",", "int", "]", ")", "->", "Callable", "[", "[", "int", ",", "int", "]", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Wraps a function into a new function that always returns three less than what the original\n        function would.  Totally senseless function that's just here to test higher-order\n        functions.\n        \"\"\"", "\n", "\n", "def", "new_function", "(", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "            ", "return", "function", "(", "num1", ",", "num2", ")", "-", "3", "\n", "\n", "", "return", "new_function", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append": [[106, 109], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "append", "(", "self", ",", "list_", ":", "List", "[", "int", "]", ",", "num", ":", "int", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "list_", "+", "[", "num", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.not_a_predicate": [[110, 112], ["None"], "methods", ["None"], ["", "def", "not_a_predicate", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.setup_method": [[120, 125], ["super().setup_method", "domain_language_test.Arithmetic", "domain_language_test.Arithmetic"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "language", "=", "Arithmetic", "(", ")", "\n", "self", ".", "curried_language", "=", "Arithmetic", "(", "\n", "allow_function_currying", "=", "True", ",", "allow_function_composition", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_constant_logical_form": [[127, 134], ["domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "pytest.raises", "domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_constant_logical_form", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "language", ".", "execute", "(", "\"5\"", ")", "==", "5", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"2\"", ")", "==", "2", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"20\"", ")", "==", "20", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"3\"", ")", "==", "3", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ",", "match", "=", "\"Unrecognized constant\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "'\"add\"'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_error_message_with_wrong_arguments": [[135, 140], ["pytest.raises", "domain_language_test.TestDomainLanguage.language.execute", "pytest.raises", "domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_error_message_with_wrong_arguments", "(", "self", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "\"(add)\"", ")", "\n", "", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "\"(add 2)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_not_all_functions_are_predicates": [[141, 145], ["pytest.raises", "domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_not_all_functions_are_predicates", "(", "self", ")", ":", "\n", "# This should not execute to 5, but instead be treated as a constant.", "\n", "        ", "with", "pytest", ".", "raises", "(", "ExecutionError", ",", "match", "=", "\"Unrecognized constant\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "\"not_a_predicate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_basic_logical_form": [[146, 151], ["domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_basic_logical_form", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "language", ".", "execute", "(", "\"three\"", ")", "==", "3", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(add 2 3)\"", ")", "==", "5", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(subtract 2 3)\"", ")", "==", "-", "1", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(halve 20)\"", ")", "==", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_list_types": [[152, 157], ["domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_list_types", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "language", ".", "execute", "(", "\"(sum (list1 2))\"", ")", "==", "2", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(sum (list2 2 3))\"", ")", "==", "5", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(sum (list4 2 10 -2 -5))\"", ")", "==", "5", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(sum (list4 2 three (halve 4) (add -5 -2)))\"", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_nested_logical_form": [[158, 161], ["domain_language_test.TestDomainLanguage.language.execute", "domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_nested_logical_form", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "language", ".", "execute", "(", "\"(add 2 (subtract 4 2))\"", ")", "==", "4", "\n", "assert", "self", ".", "language", ".", "execute", "(", "\"(halve (multiply (divide 9 3) (power 2 3)))\"", ")", "==", "12", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_higher_order_logical_form": [[162, 164], ["domain_language_test.TestDomainLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_higher_order_logical_form", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "language", ".", "execute", "(", "\"((three_less add) 2 (subtract 4 2))\"", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_execute_action_sequence": [[165, 179], ["domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.execute_action_sequence", "domain_language_test.TestDomainLanguage.language.execute_action_sequence", "domain_language_test.TestDomainLanguage.language.execute_action_sequence", "domain_language_test.TestDomainLanguage.language.execute_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence"], ["", "def", "test_execute_action_sequence", "(", "self", ")", ":", "\n", "# Repeats tests from above, but using `execute_action_sequence` instead of `execute`.", "\n", "        ", "logical_form", "=", "\"(add 2 (subtract 4 2))\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "4", "\n", "logical_form", "=", "\"(halve (multiply (divide 9 3) (power 2 3)))\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "12", "\n", "logical_form", "=", "\"((three_less add) 2 (subtract 4 2))\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "1", "\n", "logical_form", "=", "\"((three_less add) three (subtract 4 2))\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_execute_function_composition": [[180, 186], ["domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_function_composition", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((* halve halve) 8)\"", ")", "==", "2", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((* sum list1) 8)\"", ")", "==", "8", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"(multiply 4 ((* sum list1) 6))\"", ")", "==", "24", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"(halve ((* halve halve) 8))\"", ")", "==", "1", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((* (* halve halve) (three_less multiply)) 2 4)\"", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_execute_function_currying": [[187, 193], ["domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_function_currying", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((multiply 3) 6)\"", ")", "==", "18", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"(sum ((list2 1) 7))\"", ")", "==", "8", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((append 3) (list1 2))\"", ")", "==", "[", "2", ",", "3", "]", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((append (list1 4)) 6)\"", ")", "==", "[", "4", ",", "6", "]", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "\"((list3 1 2) 3)\"", ")", "==", "[", "1", ",", "2", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_execute_action_sequence_function_composition": [[194, 208], ["domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence"], ["", "def", "test_execute_action_sequence_function_composition", "(", "self", ")", ":", "\n", "# Repeats tests from above, but using `execute_action_sequence` instead of `execute`.", "\n", "        ", "logical_form", "=", "\"((* halve halve) 8)\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "2", "\n", "logical_form", "=", "\"((* sum list1) 8)\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "8", "\n", "logical_form", "=", "\"(multiply 4 ((* sum list1) 6))\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "24", "\n", "logical_form", "=", "\"(halve ((* halve halve) 8))\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_execute_action_sequence_function_currying": [[209, 217], ["domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence"], ["", "def", "test_execute_action_sequence_function_currying", "(", "self", ")", ":", "\n", "# Repeats tests from above, but using `execute_action_sequence` instead of `execute`.", "\n", "        ", "logical_form", "=", "\"((multiply 3) 6)\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "18", "\n", "logical_form", "=", "\"(sum ((list3 1 2) 7))\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_currying_composed_functions": [[218, 244], ["domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.execute", "domain_language_test.TestDomainLanguage.curried_language.execute_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence"], ["", "def", "test_currying_composed_functions", "(", "self", ")", ":", "\n", "# Testing all of our operations (conversion and execution) for currying composed functions.", "\n", "        ", "logical_form", "=", "\"(((* sum list3) 1 2) 7)\"", "\n", "action_sequence", "=", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> [<int,int,int:int>, int, int]\"", ",", "\n", "\"<int,int,int:int> -> [*, <List[int]:int>, <int,int,int:List[int]>]\"", ",", "\n", "\"<List[int]:int> -> sum\"", ",", "\n", "\"<int,int,int:List[int]> -> list3\"", ",", "\n", "\"int -> 1\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 7\"", ",", "\n", "]", "\n", "generated_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "generated_logical_form", "==", "logical_form", "\n", "\n", "generated_action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\n", "logical_form", "\n", ")", "\n", "assert", "generated_action_sequence", "==", "action_sequence", "\n", "\n", "assert", "self", ".", "curried_language", ".", "execute", "(", "logical_form", ")", "==", "10", "\n", "assert", "self", ".", "curried_language", ".", "execute_action_sequence", "(", "action_sequence", ")", "==", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_get_nonterminal_productions": [[245, 313], ["domain_language_test.TestDomainLanguage.language.get_nonterminal_productions", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "set", "domain_language_test.TestDomainLanguage.keys"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match"], ["", "def", "test_get_nonterminal_productions", "(", "self", ")", ":", "\n", "        ", "valid_actions", "=", "self", ".", "language", ".", "get_nonterminal_productions", "(", ")", "\n", "assert", "set", "(", "valid_actions", ".", "keys", "(", ")", ")", "==", "{", "\n", "\"@start@\"", ",", "\n", "\"int\"", ",", "\n", "\"List[int]\"", ",", "\n", "\"<int:int>\"", ",", "\n", "\"<int,int:int>\"", ",", "\n", "\"<List[int]:int>\"", ",", "\n", "\"<List[int],int:List[int]>\"", ",", "\n", "\"<int:List[int]>\"", ",", "\n", "\"<int,int:List[int]>\"", ",", "\n", "\"<int,int,int:List[int]>\"", ",", "\n", "\"<int,int,int,int:List[int]>\"", ",", "\n", "\"<<int,int:int>:<int,int:int>>\"", ",", "\n", "}", "\n", "check_productions_match", "(", "valid_actions", "[", "\"@start@\"", "]", ",", "[", "\"int\"", "]", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"int\"", "]", ",", "\n", "[", "\n", "\"[<int,int:int>, int, int]\"", ",", "\n", "\"[<int:int>, int]\"", ",", "\n", "\"[<List[int]:int>, List[int]]\"", ",", "\n", "\"three\"", ",", "\n", "\"1\"", ",", "\n", "\"2\"", ",", "\n", "\"3\"", ",", "\n", "\"4\"", ",", "\n", "\"5\"", ",", "\n", "\"6\"", ",", "\n", "\"7\"", ",", "\n", "\"8\"", ",", "\n", "\"9\"", ",", "\n", "\"10\"", ",", "\n", "\"20\"", ",", "\n", "\"-5\"", ",", "\n", "\"-2\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"List[int]\"", "]", ",", "\n", "[", "\n", "\"[<int:List[int]>, int]\"", ",", "\n", "\"[<int,int:List[int]>, int, int]\"", ",", "\n", "\"[<int,int,int:List[int]>, int, int, int]\"", ",", "\n", "\"[<int,int,int,int:List[int]>, int, int, int, int]\"", ",", "\n", "\"[<List[int],int:List[int]>, List[int], int]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<int:int>\"", "]", ",", "[", "\"halve\"", "]", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int:int>\"", "]", ",", "\n", "[", "\n", "\"[<<int,int:int>:<int,int:int>>, <int,int:int>]\"", ",", "\n", "\"add\"", ",", "\n", "\"subtract\"", ",", "\n", "\"multiply\"", ",", "\n", "\"divide\"", ",", "\n", "\"power\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<List[int],int:List[int]>\"", "]", ",", "[", "\"append\"", "]", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<List[int]:int>\"", "]", ",", "[", "\"sum\"", "]", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<int:List[int]>\"", "]", ",", "[", "\"list1\"", "]", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<int,int:List[int]>\"", "]", ",", "[", "\"list2\"", "]", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<int,int,int:List[int]>\"", "]", ",", "[", "\"list3\"", "]", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<int,int,int,int:List[int]>\"", "]", ",", "[", "\"list4\"", "]", ")", "\n", "check_productions_match", "(", "valid_actions", "[", "\"<<int,int:int>:<int,int:int>>\"", "]", ",", "[", "\"three_less\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_get_nonterminal_productions_curried_language_and_function_composition": [[314, 465], ["domain_language_test.TestDomainLanguage.curried_language.get_nonterminal_productions", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "set", "domain_language_test.TestDomainLanguage.keys"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match"], ["", "def", "test_get_nonterminal_productions_curried_language_and_function_composition", "(", "self", ")", ":", "\n", "        ", "valid_actions", "=", "self", ".", "curried_language", ".", "get_nonterminal_productions", "(", ")", "\n", "assert", "set", "(", "valid_actions", ".", "keys", "(", ")", ")", "==", "{", "\n", "\"@start@\"", ",", "\n", "\"int\"", ",", "\n", "\"List[int]\"", ",", "\n", "\"<int:int>\"", ",", "\n", "\"<int,int:int>\"", ",", "\n", "\"<List[int]:int>\"", ",", "\n", "\"<int:List[int]>\"", ",", "\n", "\"<int,int:List[int]>\"", ",", "\n", "\"<int,int,int:List[int]>\"", ",", "\n", "\"<int,int,int,int:List[int]>\"", ",", "\n", "\"<List[int],int:List[int]>\"", ",", "\n", "\"<<int,int:int>:<int,int:int>>\"", ",", "\n", "# Types induced by allowing function composition", "\n", "\"<List[int]:List[int]>\"", ",", "# also induced from currying", "\n", "\"<int,int,int,int:int>\"", ",", "\n", "\"<int,int,int:int>\"", ",", "\n", "\"<List[int],int:int>\"", ",", "\n", "}", "\n", "check_productions_match", "(", "valid_actions", "[", "\"@start@\"", "]", ",", "[", "\"int\"", "]", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"int\"", "]", ",", "\n", "[", "\n", "\"[<int,int:int>, int, int]\"", ",", "\n", "\"[<int:int>, int]\"", ",", "\n", "\"[<List[int]:int>, List[int]]\"", ",", "\n", "\"three\"", ",", "\n", "\"1\"", ",", "\n", "\"2\"", ",", "\n", "\"3\"", ",", "\n", "\"4\"", ",", "\n", "\"5\"", ",", "\n", "\"6\"", ",", "\n", "\"7\"", ",", "\n", "\"8\"", ",", "\n", "\"9\"", ",", "\n", "\"10\"", ",", "\n", "\"20\"", ",", "\n", "\"-5\"", ",", "\n", "\"-2\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"List[int]\"", "]", ",", "\n", "[", "\n", "\"[<int:List[int]>, int]\"", ",", "\n", "\"[<int,int:List[int]>, int, int]\"", ",", "\n", "\"[<int,int,int:List[int]>, int, int, int]\"", ",", "\n", "\"[<int,int,int,int:List[int]>, int, int, int, int]\"", ",", "\n", "\"[<List[int],int:List[int]>, List[int], int]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int:int>\"", "]", ",", "\n", "[", "\n", "\"halve\"", ",", "\n", "# Production due to function composition", "\n", "\"[*, <int:int>, <int:int>]\"", ",", "\n", "\"[*, <List[int]:int>, <int:List[int]>]\"", ",", "\n", "# Production due to function currying", "\n", "\"[<int,int:int>, int]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int:int>\"", "]", ",", "\n", "[", "\n", "\"[<<int,int:int>:<int,int:int>>, <int,int:int>]\"", ",", "\n", "\"add\"", ",", "\n", "\"subtract\"", ",", "\n", "\"multiply\"", ",", "\n", "\"divide\"", ",", "\n", "\"power\"", ",", "\n", "# Production due to function composition", "\n", "\"[*, <int:int>, <int,int:int>]\"", ",", "\n", "\"[*, <List[int]:int>, <int,int:List[int]>]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<List[int]:int>\"", "]", ",", "\n", "[", "\n", "\"sum\"", ",", "\n", "# Production due to function composition", "\n", "\"[*, <int:int>, <List[int]:int>]\"", ",", "\n", "\"[*, <List[int]:int>, <List[int]:List[int]>]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int:List[int]>\"", "]", ",", "\n", "[", "\n", "\"list1\"", ",", "\n", "# Production due to function composition", "\n", "\"[*, <int:List[int]>, <int:int>]\"", ",", "\n", "\"[*, <List[int]:List[int]>, <int:List[int]>]\"", ",", "\n", "# Production due to function currying", "\n", "\"[<List[int],int:List[int]>, List[int]]\"", ",", "\n", "\"[<int,int:List[int]>, int]\"", ",", "\n", "\"[<int,int,int:List[int]>, int, int]\"", ",", "\n", "\"[<int,int,int,int:List[int]>, int, int, int]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<List[int],int:List[int]>\"", "]", ",", "\n", "[", "\"append\"", ",", "\"[*, <List[int]:List[int]>, <List[int],int:List[int]>]\"", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int:List[int]>\"", "]", ",", "\n", "[", "\n", "\"list2\"", ",", "\n", "\"[*, <int:List[int]>, <int,int:int>]\"", ",", "\n", "\"[*, <List[int]:List[int]>, <int,int:List[int]>]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int,int:List[int]>\"", "]", ",", "\n", "[", "\"list3\"", ",", "\"[*, <List[int]:List[int]>, <int,int,int:List[int]>]\"", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int,int,int:List[int]>\"", "]", ",", "\n", "[", "\"list4\"", ",", "\"[*, <List[int]:List[int]>, <int,int,int,int:List[int]>]\"", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<<int,int:int>:<int,int:int>>\"", "]", ",", "\n", "[", "\"three_less\"", ",", "\"[*, <<int,int:int>:<int,int:int>>, <<int,int:int>:<int,int:int>>]\"", "]", ",", "\n", ")", "\n", "# Production due to function composition", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<List[int]:List[int]>\"", "]", ",", "\n", "[", "\n", "\"[*, <int:List[int]>, <List[int]:int>]\"", ",", "\n", "\"[*, <List[int]:List[int]>, <List[int]:List[int]>]\"", ",", "\n", "\"[<List[int],int:List[int]>, int]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int,int,int:int>\"", "]", ",", "\n", "[", "\n", "\"[*, <List[int]:int>, <int,int,int,int:List[int]>]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<int,int,int:int>\"", "]", ",", "\n", "[", "\n", "\"[*, <List[int]:int>, <int,int,int:List[int]>]\"", ",", "\n", "]", ",", "\n", ")", "\n", "check_productions_match", "(", "\n", "valid_actions", "[", "\"<List[int],int:int>\"", "]", ",", "\n", "[", "\n", "\"[*, <List[int]:int>, <List[int],int:List[int]>]\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_logical_form_to_action_sequence": [[468, 507], ["domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_to_action_sequence", "(", "self", ")", ":", "\n", "        ", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"(add 2 3)\"", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> add\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 3\"", ",", "\n", "]", "\n", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\n", "\"(halve (subtract 8 three))\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> subtract\"", ",", "\n", "\"int -> 8\"", ",", "\n", "\"int -> three\"", ",", "\n", "]", "\n", "\n", "logical_form", "=", "\"(halve (multiply (divide 9 three) (power 2 3)))\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> multiply\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> divide\"", ",", "\n", "\"int -> 9\"", ",", "\n", "\"int -> three\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> power\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 3\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_logical_form_to_action_sequence_with_higher_order_functions": [[509, 519], ["domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_to_action_sequence_with_higher_order_functions", "(", "self", ")", ":", "\n", "        ", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"((three_less add) 2 3)\"", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> [<<int,int:int>:<int,int:int>>, <int,int:int>]\"", ",", "\n", "\"<<int,int:int>:<int,int:int>> -> three_less\"", ",", "\n", "\"<int,int:int> -> add\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 3\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_logical_form_to_action_sequence_with_function_composition": [[521, 594], ["domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_to_action_sequence_with_function_composition", "(", "self", ")", ":", "\n", "        ", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\n", "\"((* halve halve) 8)\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> [*, <int:int>, <int:int>]\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"int -> 8\"", ",", "\n", "]", "\n", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\"((* sum list1) 8)\"", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> [*, <List[int]:int>, <int:List[int]>]\"", ",", "\n", "\"<List[int]:int> -> sum\"", ",", "\n", "\"<int:List[int]> -> list1\"", ",", "\n", "\"int -> 8\"", ",", "\n", "]", "\n", "\n", "# Trying a mix of regular composition and function-composition", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\n", "\"(halve ((* halve halve) 8))\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> [*, <int:int>, <int:int>]\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"int -> 8\"", ",", "\n", "]", "\n", "\n", "# Idea is to execute multiply(4, sum(list3(2, 4))(6)) where list3 is curried and then", "\n", "# composed with sum", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\n", "\"(multiply 4 ((* sum (list3 2 4)) 6))\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> multiply\"", ",", "\n", "\"int -> 4\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> [*, <List[int]:int>, <int:List[int]>]\"", ",", "\n", "\"<List[int]:int> -> sum\"", ",", "\n", "\"<int:List[int]> -> [<int,int,int:List[int]>, int, int]\"", ",", "\n", "\"<int,int,int:List[int]> -> list3\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 4\"", ",", "\n", "\"int -> 6\"", ",", "\n", "]", "\n", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\n", "\"((* (* halve halve) (three_less multiply)) 2 4)\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int,int:int>, int, int]\"", ",", "\n", "\"<int,int:int> -> [*, <int:int>, <int,int:int>]\"", ",", "\n", "\"<int:int> -> [*, <int:int>, <int:int>]\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"<int:int> -> halve\"", ",", "\n", "\"<int,int:int> -> [<<int,int:int>:<int,int:int>>, <int,int:int>]\"", ",", "\n", "\"<<int,int:int>:<int,int:int>> -> three_less\"", ",", "\n", "\"<int,int:int> -> multiply\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 4\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_logical_form_to_action_sequence_with_function_currying": [[596, 620], ["domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_to_action_sequence_with_function_currying", "(", "self", ")", ":", "\n", "        ", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\"((multiply 3) 6)\"", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> [<int,int:int>, int]\"", ",", "\n", "\"<int,int:int> -> multiply\"", ",", "\n", "\"int -> 3\"", ",", "\n", "\"int -> 6\"", ",", "\n", "]", "\n", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "\n", "\"(sum ((list3 1 2) 7))\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<List[int]:int>, List[int]]\"", ",", "\n", "\"<List[int]:int> -> sum\"", ",", "\n", "\"List[int] -> [<int:List[int]>, int]\"", ",", "\n", "\"<int:List[int]> -> [<int,int,int:List[int]>, int, int]\"", ",", "\n", "\"<int,int,int:List[int]> -> list3\"", ",", "\n", "\"int -> 1\"", ",", "\n", "\"int -> 2\"", ",", "\n", "\"int -> 7\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_action_sequence_to_logical_form": [[622, 637], ["domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_action_sequence_to_logical_form", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(add 2 3)\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n", "logical_form", "=", "\"(halve (multiply (divide 9 three) (power 2 3)))\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n", "logical_form", "=", "\"((three_less add) 2 3)\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_action_sequence_to_logical_form_with_function_composition": [[638, 666], ["domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_action_sequence_to_logical_form_with_function_composition", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"((* halve halve) 8)\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n", "logical_form", "=", "\"((* sum list1) 8)\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n", "logical_form", "=", "\"(multiply 4 ((* sum list1) 6))\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n", "logical_form", "=", "\"(halve ((* halve halve) 8))\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_action_sequence_to_logical_form_with_function_currying": [[667, 681], ["domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form", "domain_language_test.TestDomainLanguage.curried_language.logical_form_to_action_sequence", "domain_language_test.TestDomainLanguage.curried_language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_action_sequence_to_logical_form_with_function_currying", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"((multiply 3) 6)\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n", "logical_form", "=", "\"(sum ((list3 1 2) 7))\"", "\n", "action_sequence", "=", "self", ".", "curried_language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "recovered_logical_form", "=", "self", ".", "curried_language", ".", "action_sequence_to_logical_form", "(", "\n", "action_sequence", "\n", ")", "\n", "assert", "recovered_logical_form", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_logical_form_parsing_fails_on_bad_inputs": [[682, 695], ["pytest.raises", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "pytest.raises", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "pytest.raises", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "pytest.raises", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence", "pytest.raises", "domain_language_test.TestDomainLanguage.language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_parsing_fails_on_bad_inputs", "(", "self", ")", ":", "\n", "# We don't catch all type inconsistencies in the code, but we _do_ catch some.  If we add", "\n", "# more that we catch, this is a good place to test for them.", "\n", "        ", "with", "pytest", ".", "raises", "(", "ParsingError", ",", "match", "=", "\"Wrong number of arguments\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"(halve 2 3)\"", ")", "\n", "", "with", "pytest", ".", "raises", "(", "ParsingError", ",", "match", "=", "\"Wrong number of arguments\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"(add 3)\"", ")", "\n", "", "with", "pytest", ".", "raises", "(", "ParsingError", ",", "match", "=", "\"unallowed start type\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"add\"", ")", "\n", "", "with", "pytest", ".", "raises", "(", "ParsingError", ",", "match", "=", "\"Zero-arg function or constant\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"(sum (3 2))\"", ")", "\n", "", "with", "pytest", ".", "raises", "(", "ParsingError", ",", "match", "=", "\"did not have expected type\"", ")", ":", "\n", "            ", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "\"(sum (add 2 3))\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.TestDomainLanguage.test_execution_with_side_arguments": [[696, 738], ["SideArgumentLanguage", "allennlp_semparse.predicate_with_side_args", "allennlp_semparse.predicate_with_side_args", "SideArgumentLanguage.execute_action_sequence", "SideArgumentLanguage.execute_action_sequence", "SemparseTestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.predicate_with_side_args", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.predicate_with_side_args", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["", "", "def", "test_execution_with_side_arguments", "(", "self", ")", ":", "\n", "        ", "class", "SideArgumentLanguage", "(", "DomainLanguage", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "                ", "super", "(", ")", ".", "__init__", "(", "start_types", "=", "{", "int", "}", ",", "allowed_constants", "=", "{", "\"1\"", ":", "1", ",", "\"2\"", ":", "2", ",", "\"3\"", ":", "3", "}", ")", "\n", "\n", "", "@", "predicate_with_side_args", "(", "[", "\"num2\"", "]", ")", "\n", "def", "add", "(", "self", ",", "num1", ":", "int", ",", "num2", ":", "int", ")", "->", "int", ":", "\n", "                ", "return", "num1", "+", "num2", "\n", "\n", "", "@", "predicate_with_side_args", "(", "[", "\"num\"", "]", ")", "\n", "def", "current_number", "(", "self", ",", "num", ":", "int", ")", "->", "int", ":", "\n", "                ", "return", "num", "\n", "\n", "", "", "language", "=", "SideArgumentLanguage", "(", ")", "\n", "\n", "# (add 1)", "\n", "action_sequence", "=", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> add\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", "# For each action in the action sequence, we pass state.  We only actually _use_ the state", "\n", "# when the action we've predicted at that step needs the state.  In this case, the third", "\n", "# action will get {'num2': 3} passed to the `add()` function.", "\n", "state", "=", "[", "{", "\"num2\"", ":", "1", "}", ",", "{", "\"num2\"", ":", "2", "}", ",", "{", "\"num2\"", ":", "3", "}", ",", "{", "\"num2\"", ":", "4", "}", "]", "\n", "assert", "language", ".", "execute_action_sequence", "(", "action_sequence", ",", "state", ")", "==", "4", "\n", "\n", "# (add current_number)", "\n", "action_sequence", "=", "[", "\n", "\"@start@ -> int\"", ",", "\n", "\"int -> [<int:int>, int]\"", ",", "\n", "\"<int:int> -> add\"", ",", "\n", "\"int -> current_number\"", ",", "\n", "]", "\n", "state", "=", "[", "\n", "{", "\"num2\"", ":", "1", ",", "\"num\"", ":", "5", "}", ",", "\n", "{", "\"num2\"", ":", "2", ",", "\"num\"", ":", "6", "}", ",", "\n", "{", "\"num2\"", ":", "3", ",", "\"num\"", ":", "7", "}", ",", "\n", "{", "\"num2\"", ":", "4", ",", "\"num\"", ":", "8", "}", ",", "\n", "]", "\n", "assert", "language", ".", "execute_action_sequence", "(", "action_sequence", ",", "state", ")", "==", "11", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match": [[114, 117], ["set", "set", "rule.split"], "function", ["None"], ["", "", "def", "check_productions_match", "(", "actual_rules", ":", "List", "[", "str", "]", ",", "expected_right_sides", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "actual_right_sides", "=", "[", "rule", ".", "split", "(", "\" -> \"", ")", "[", "1", "]", "for", "rule", "in", "actual_rules", "]", "\n", "assert", "set", "(", "actual_right_sides", ")", "==", "set", "(", "expected_right_sides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.setup_method": [[10, 33], ["super().setup_method", "allennlp_semparse.domain_languages.NlvrLanguage", "allennlp_semparse.domain_languages.NlvrLanguage", "json.loads", "open().readlines", "allennlp_semparse.domain_languages.nlvr_language.Box", "allennlp_semparse.domain_languages.nlvr_language.Box", "enumerate", "enumerate", "open"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "test_filename", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"nlvr\"", "/", "\"sample_ungrouped_data.jsonl\"", "\n", "data", "=", "[", "json", ".", "loads", "(", "line", ")", "[", "\"structured_rep\"", "]", "for", "line", "in", "open", "(", "test_filename", ")", ".", "readlines", "(", ")", "]", "\n", "box_lists", "=", "[", "\n", "[", "Box", "(", "object_reps", ",", "i", ")", "for", "i", ",", "object_reps", "in", "enumerate", "(", "box_rep", ")", "]", "for", "box_rep", "in", "data", "\n", "]", "\n", "self", ".", "languages", "=", "[", "NlvrLanguage", "(", "boxes", ")", "for", "boxes", "in", "box_lists", "]", "\n", "# y_loc increases as we go down from top to bottom, and x_loc from left to right. That is,", "\n", "# the origin is at the top-left corner.", "\n", "custom_rep", "=", "[", "\n", "[", "\n", "{", "\"y_loc\"", ":", "79", ",", "\"size\"", ":", "20", ",", "\"type\"", ":", "\"triangle\"", ",", "\"x_loc\"", ":", "27", ",", "\"color\"", ":", "\"Yellow\"", "}", ",", "\n", "{", "\"y_loc\"", ":", "55", ",", "\"size\"", ":", "10", ",", "\"type\"", ":", "\"circle\"", ",", "\"x_loc\"", ":", "47", ",", "\"color\"", ":", "\"Black\"", "}", ",", "\n", "]", ",", "\n", "[", "\n", "{", "\"y_loc\"", ":", "44", ",", "\"size\"", ":", "30", ",", "\"type\"", ":", "\"square\"", ",", "\"x_loc\"", ":", "10", ",", "\"color\"", ":", "\"#0099ff\"", "}", ",", "\n", "{", "\"y_loc\"", ":", "74", ",", "\"size\"", ":", "30", ",", "\"type\"", ":", "\"square\"", ",", "\"x_loc\"", ":", "40", ",", "\"color\"", ":", "\"Yellow\"", "}", ",", "\n", "]", ",", "\n", "[", "{", "\"y_loc\"", ":", "60", ",", "\"size\"", ":", "10", ",", "\"type\"", ":", "\"triangle\"", ",", "\"x_loc\"", ":", "12", ",", "\"color\"", ":", "\"#0099ff\"", "}", "]", ",", "\n", "]", "\n", "self", ".", "custom_language", "=", "NlvrLanguage", "(", "\n", "[", "Box", "(", "object_rep", ",", "i", ")", "for", "i", ",", "object_rep", "in", "enumerate", "(", "custom_rep", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_assert_executes_correctly": [[35, 42], ["executor.execute", "executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_assert_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "0", "]", "\n", "# Utterance is \"There is a circle closely touching a corner of a box.\" and label is \"True\".", "\n", "logical_form_true", "=", "\"(object_count_greater_equals (touch_corner (circle (all_objects))) 1)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form_true", ")", "is", "True", "\n", "logical_form_false", "=", "\"(object_count_equals (touch_corner (circle (all_objects))) 9)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form_false", ")", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_box_filter_executes_correctly": [[43, 48], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_box_filter_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "2", "]", "\n", "# Utterance is \"There is a box without a blue item.\" and label is \"False\".", "\n", "logical_form", "=", "\"(box_exists (member_color_none_equals all_boxes color_blue))\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_box_filter_within_object_filter_executes_correctly": [[49, 56], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_box_filter_within_object_filter_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "2", "]", "\n", "# Utterance is \"There are at least three blue items in boxes with blue items\" and label", "\n", "# is \"True\".", "\n", "logical_form", "=", "\"(object_count_greater_equals \\\n                            (object_in_box (member_color_any_equals all_boxes color_blue)) 3)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_same_color_executes_correctly": [[57, 62], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_same_color_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "1", "]", "\n", "# Utterance is \"There are exactly two blocks of the same color.\" and label is \"True\".", "\n", "logical_form", "=", "\"(object_count_equals (same_color all_objects) 2)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_same_shape_executes_correctly": [[63, 68], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_same_shape_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "0", "]", "\n", "# Utterance is \"There are less than three black objects of the same shape\" and label is \"False\".", "\n", "logical_form", "=", "\"(object_count_lesser (same_shape (black (all_objects))) 3)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_touch_wall_executes_correctly": [[69, 74], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_touch_wall_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "0", "]", "\n", "# Utterance is \"There are two black circles touching a wall\" and label is \"False\".", "\n", "logical_form", "=", "\"(object_count_greater_equals (touch_wall (black (circle (all_objects)))) 2)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_not_executes_correctly": [[75, 83], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_not_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "2", "]", "\n", "# Utterance is \"There are at most two medium triangles not touching a wall.\" and label is \"True\".", "\n", "logical_form", "=", "(", "\n", "\"(object_count_lesser_equals ((negate_filter touch_wall) \"", "\n", "\"(medium (triangle (all_objects)))) 2)\"", "\n", ")", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_color_comparison_executes_correctly": [[84, 89], ["executor.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_logical_form_with_color_comparison_executes_correctly", "(", "self", ")", ":", "\n", "        ", "executor", "=", "self", ".", "languages", "[", "0", "]", "\n", "# Utterance is \"The color of the circle touching the wall is black.\" and label is \"True\".", "\n", "logical_form", "=", "\"(object_color_all_equals (circle (touch_wall (all_objects))) color_black)\"", "\n", "assert", "executor", ".", "execute", "(", "logical_form", ")", "is", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_spatial_relations_return_objects_in_the_same_box": [[90, 121], ["nlvr_language_test.TestNlvrLanguage.custom_language.execute", "nlvr_language_test.TestNlvrLanguage.custom_language.execute", "nlvr_language_test.TestNlvrLanguage.custom_language.execute", "nlvr_language_test.TestNlvrLanguage.custom_language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_spatial_relations_return_objects_in_the_same_box", "(", "self", ")", ":", "\n", "# \"above\", \"below\", \"top\", \"bottom\" are relations defined only for objects within the same", "\n", "# box. So they should not return objects from other boxes.", "\n", "# Asserting that the color of the objects above the yellow triangle is only black (it is not", "\n", "# yellow or blue, which are colors of objects from other boxes)", "\n", "        ", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_color_all_equals (above (yellow (triangle all_objects)))\"", "\" color_black)\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n", "# Asserting that the only shape below the blue square is a square.", "\n", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_shape_all_equals (below (blue (square all_objects)))\"", "\" shape_square)\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n", "# Asserting the shape of the object at the bottom in the box with a circle is triangle.", "\n", "logical_form", "=", "(", "\n", "\"(object_shape_all_equals (bottom (object_in_box\"", "\n", "\" (member_shape_any_equals all_boxes shape_circle))) shape_triangle)\"", "\n", ")", "\n", "assert", "self", ".", "custom_language", ".", "execute", "(", "logical_form", ")", "is", "True", "\n", "\n", "# Asserting the shape of the object at the top of the box with all squares is a square (!).", "\n", "logical_form", "=", "(", "\n", "\"(object_shape_all_equals (top (object_in_box\"", "\n", "\" (member_shape_all_equals all_boxes shape_square))) shape_square)\"", "\n", ")", "\n", "assert", "self", ".", "custom_language", ".", "execute", "(", "logical_form", ")", "is", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_touch_object_executes_correctly": [[122, 136], ["nlvr_language_test.TestNlvrLanguage.custom_language.execute", "nlvr_language_test.TestNlvrLanguage.custom_language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_touch_object_executes_correctly", "(", "self", ")", ":", "\n", "# Assert that there is a yellow square touching a blue square.", "\n", "        ", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_exists (yellow (square (touch_object (blue \"", "\"(square all_objects))))))\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n", "# Assert that the triangle does not touch the circle (they are out of vertical range).", "\n", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_shape_none_equals (touch_object (triangle all_objects))\"", "\" shape_circle)\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_spatial_relations_with_objects_from_different_boxes": [[138, 148], ["nlvr_language_test.TestNlvrLanguage.custom_language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_spatial_relations_with_objects_from_different_boxes", "(", "self", ")", ":", "\n", "# When the objects are from different boxes, top and bottom should return objects from", "\n", "# respective boxes.", "\n", "# There are triangles in two boxes, so top should return the top objects from both boxes.", "\n", "        ", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_count_equals (top (object_in_box (member_shape_any_equals \"", "\n", "\"all_boxes shape_triangle))) 2)\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_same_and_different_execute_correctly": [[150, 167], ["nlvr_language_test.TestNlvrLanguage.custom_language.execute", "nlvr_language_test.TestNlvrLanguage.custom_language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_same_and_different_execute_correctly", "(", "self", ")", ":", "\n", "# All the objects in the box with two objects of the same shape are squares.", "\n", "        ", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_shape_all_equals \"", "\n", "\"(object_in_box (member_shape_same (member_count_equals all_boxes 2)))\"", "\n", "\" shape_square)\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n", "# There is a circle in the box with objects of different shapes.", "\n", "assert", "(", "\n", "self", ".", "custom_language", ".", "execute", "(", "\n", "\"(object_shape_any_equals (object_in_box \"", "\n", "\"(member_shape_different all_boxes)) shape_circle)\"", "\n", ")", "\n", "is", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_get_action_sequence_handles_multi_arg_functions": [[169, 205], ["language.logical_form_to_action_sequence", "language.logical_form_to_action_sequence", "language.logical_form_to_action_sequence", "language.logical_form_to_action_sequence", "language.logical_form_to_action_sequence", "language.logical_form_to_action_sequence", "language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_get_action_sequence_handles_multi_arg_functions", "(", "self", ")", ":", "\n", "        ", "language", "=", "self", ".", "languages", "[", "0", "]", "\n", "# box_color_filter", "\n", "logical_form", "=", "\"(box_exists (member_color_all_equals all_boxes color_blue))\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"Set[Box] -> [<Set[Box],Color:Set[Box]>, Set[Box], Color]\"", "in", "action_sequence", "\n", "\n", "# box_shape_filter", "\n", "logical_form", "=", "\"(box_exists (member_shape_all_equals all_boxes shape_square))\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"Set[Box] -> [<Set[Box],Shape:Set[Box]>, Set[Box], Shape]\"", "in", "action_sequence", "\n", "\n", "# box_count_filter", "\n", "logical_form", "=", "\"(box_exists (member_count_equals all_boxes 3))\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"Set[Box] -> [<Set[Box],int:Set[Box]>, Set[Box], int]\"", "in", "action_sequence", "\n", "\n", "# assert_color", "\n", "logical_form", "=", "\"(object_color_all_equals all_objects color_blue)\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"bool -> [<Set[Object],Color:bool>, Set[Object], Color]\"", "in", "action_sequence", "\n", "\n", "# assert_shape", "\n", "logical_form", "=", "\"(object_shape_all_equals all_objects shape_square)\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"bool -> [<Set[Object],Shape:bool>, Set[Object], Shape]\"", "in", "action_sequence", "\n", "\n", "# assert_box_count", "\n", "logical_form", "=", "\"(box_count_equals all_boxes 1)\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"bool -> [<Set[Box],int:bool>, Set[Box], int]\"", "in", "action_sequence", "\n", "\n", "# assert_object_count", "\n", "logical_form", "=", "\"(object_count_equals all_objects 1)\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "\"bool -> [<Set[Object],int:bool>, Set[Object], int]\"", "in", "action_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_object_filter_returns_correct_action_sequence": [[206, 220], ["language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_with_object_filter_returns_correct_action_sequence", "(", "self", ")", ":", "\n", "        ", "language", "=", "self", ".", "languages", "[", "0", "]", "\n", "logical_form", "=", "\"(object_color_all_equals (circle (touch_wall all_objects)) color_black)\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> bool\"", ",", "\n", "\"bool -> [<Set[Object],Color:bool>, Set[Object], Color]\"", ",", "\n", "\"<Set[Object],Color:bool> -> object_color_all_equals\"", ",", "\n", "\"Set[Object] -> [<Set[Object]:Set[Object]>, Set[Object]]\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> circle\"", ",", "\n", "\"Set[Object] -> [<Set[Object]:Set[Object]>, Set[Object]]\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "\"Set[Object] -> all_objects\"", ",", "\n", "\"Color -> color_black\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_negate_filter_returns_correct_action_sequence": [[222, 240], ["language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_with_negate_filter_returns_correct_action_sequence", "(", "self", ")", ":", "\n", "        ", "language", "=", "self", ".", "languages", "[", "0", "]", "\n", "logical_form", "=", "\"(object_exists ((negate_filter touch_wall) all_objects))\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "negate_filter_production", "=", "(", "\n", "\"<Set[Object]:Set[Object]> -> \"", "\n", "\"[<<Set[Object]:Set[Object]>:<Set[Object]:Set[Object]>>, \"", "\n", "\"<Set[Object]:Set[Object]>]\"", "\n", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> bool\"", ",", "\n", "\"bool -> [<Set[Object]:bool>, Set[Object]]\"", ",", "\n", "\"<Set[Object]:bool> -> object_exists\"", ",", "\n", "\"Set[Object] -> [<Set[Object]:Set[Object]>, Set[Object]]\"", ",", "\n", "negate_filter_production", ",", "\n", "\"<<Set[Object]:Set[Object]>:<Set[Object]:Set[Object]>> -> negate_filter\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "\"Set[Object] -> all_objects\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_logical_form_with_box_filter_returns_correct_action_sequence": [[242, 254], ["language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_logical_form_with_box_filter_returns_correct_action_sequence", "(", "self", ")", ":", "\n", "        ", "language", "=", "self", ".", "languages", "[", "0", "]", "\n", "logical_form", "=", "\"(box_exists (member_color_none_equals all_boxes color_blue))\"", "\n", "action_sequence", "=", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "action_sequence", "==", "[", "\n", "\"@start@ -> bool\"", ",", "\n", "\"bool -> [<Set[Box]:bool>, Set[Box]]\"", ",", "\n", "\"<Set[Box]:bool> -> box_exists\"", ",", "\n", "\"Set[Box] -> [<Set[Box],Color:Set[Box]>, Set[Box], Color]\"", ",", "\n", "\"<Set[Box],Color:Set[Box]> -> member_color_none_equals\"", ",", "\n", "\"Set[Box] -> all_boxes\"", ",", "\n", "\"Color -> color_blue\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_get_agenda_for_sentence": [[256, 354], ["language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "language.get_agenda_for_sentence", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence"], ["", "def", "test_get_agenda_for_sentence", "(", "self", ")", ":", "\n", "        ", "language", "=", "self", ".", "languages", "[", "0", "]", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\"there is a tower with exactly two yellow blocks\"", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\"Color -> color_yellow\"", ",", "\"<Set[Box]:bool> -> box_exists\"", ",", "\"int -> 2\"", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is at most one yellow item closely touching \"", "\"the bottom of a box.\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> yellow\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_bottom\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is at most one yellow item closely touching \"", "\"the right wall of a box.\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> yellow\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_right\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is at most one yellow item closely touching \"", "\"the left wall of a box.\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> yellow\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_left\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is at most one yellow item closely touching \"", "\"a wall of a box.\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> yellow\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\"There is exactly one square touching any edge\"", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> square\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is exactly one square not touching any edge\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> square\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "\"int -> 1\"", ",", "\n", "\"<<Set[Object]:Set[Object]>:<Set[Object]:Set[Object]>> -> negate_filter\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is only 1 tower with 1 blue block at the base\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> blue\"", ",", "\n", "\"int -> 1\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> bottom\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is only 1 tower that has 1 blue block at the top\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> blue\"", ",", "\n", "\"int -> 1\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> top\"", ",", "\n", "\"int -> 1\"", ",", "\n", "\"Set[Box] -> all_boxes\"", ",", "\n", "]", "\n", ")", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"There is exactly one square touching the blue \"", "\"triangle\"", "\n", ")", "\n", "assert", "set", "(", "agenda", ")", "==", "set", "(", "\n", "[", "\n", "\"<Set[Object]:Set[Object]> -> square\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> blue\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> triangle\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_object\"", ",", "\n", "\"int -> 1\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language_test.TestNlvrLanguage.test_get_agenda_for_sentence_correctly_adds_object_filters": [[357, 378], ["language.get_agenda_for_sentence", "language.get_agenda_for_sentence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.nlvr_language.NlvrLanguage.get_agenda_for_sentence"], ["", "def", "test_get_agenda_for_sentence_correctly_adds_object_filters", "(", "self", ")", ":", "\n", "# In logical forms that contain \"box_exists\" at the top, there can never be object filtering", "\n", "# operations like \"blue\", \"square\" etc. In those cases, strings like \"blue\" and \"square\" in", "\n", "# sentences should map to \"color_blue\" and \"shape_square\" respectively.", "\n", "        ", "language", "=", "self", ".", "languages", "[", "0", "]", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"there is a box with exactly two yellow triangles \"", "\"touching the top edge\"", "\n", ")", "\n", "assert", "\"<Set[Object]:Set[Object]> -> yellow\"", "not", "in", "agenda", "\n", "assert", "\"Color -> color_yellow\"", "in", "agenda", "\n", "assert", "\"<Set[Object]:Set[Object]> -> triangle\"", "not", "in", "agenda", "\n", "assert", "\"Shape -> shape_triangle\"", "in", "agenda", "\n", "assert", "\"<Set[Object]:Set[Object]> -> touch_top\"", "not", "in", "agenda", "\n", "agenda", "=", "language", ".", "get_agenda_for_sentence", "(", "\n", "\"there are exactly two yellow triangles touching the\"", "\" top edge\"", "\n", ")", "\n", "assert", "\"<Set[Object]:Set[Object]> -> yellow\"", "in", "agenda", "\n", "assert", "\"Color -> color_yellow\"", "not", "in", "agenda", "\n", "assert", "\"<Set[Object]:Set[Object]> -> triangle\"", "in", "agenda", "\n", "assert", "\"Shape -> shape_triangle\"", "not", "in", "agenda", "\n", "assert", "\"<Set[Object]:Set[Object]> -> touch_top\"", "in", "agenda", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.setup_method": [[17, 48], ["super().setup_method", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.domain_languages.wikitables_language.WikiTablesLanguage", "allennlp.data.tokenizers.Token"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "# Adding a bunch of random tokens in here so we get them as constants in the language.", "\n", "question_tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"last\"", ",", "\n", "\"year\"", ",", "\n", "\"2013\"", ",", "\n", "\"?\"", ",", "\n", "\"quarterfinals\"", ",", "\n", "\"a_league\"", ",", "\n", "\"2010\"", ",", "\n", "\"8000\"", ",", "\n", "\"did_not_qualify\"", ",", "\n", "\"2001\"", ",", "\n", "\"2\"", ",", "\n", "\"23\"", ",", "\n", "\"2005\"", ",", "\n", "\"1\"", ",", "\n", "\"2002\"", ",", "\n", "\"usl_a_league\"", ",", "\n", "\"usl_first_division\"", ",", "\n", "]", "\n", "]", "\n", "self", ".", "table_file", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"sample_table.tagged\"", "\n", "self", ".", "table_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "self", ".", "table_file", ",", "question_tokens", ")", "\n", "self", ".", "language", "=", "WikiTablesLanguage", "(", "self", ".", "table_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens": [[49, 53], ["allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.domain_languages.wikitables_language.WikiTablesLanguage"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "_get_world_with_question_tokens", "(", "self", ",", "tokens", ":", "List", "[", "Token", "]", ")", "->", "WikiTablesLanguage", ":", "\n", "        ", "table_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "self", ".", "table_file", ",", "tokens", ")", "\n", "world", "=", "WikiTablesLanguage", "(", "table_context", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens_and_table_file": [[54, 60], ["allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file", "allennlp_semparse.domain_languages.wikitables_language.WikiTablesLanguage"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["", "def", "_get_world_with_question_tokens_and_table_file", "(", "\n", "self", ",", "tokens", ":", "List", "[", "Token", "]", ",", "table_file", ":", "str", "\n", ")", "->", "WikiTablesLanguage", ":", "\n", "        ", "table_context", "=", "TableQuestionContext", ".", "read_from_file", "(", "table_file", ",", "tokens", ")", "\n", "world", "=", "WikiTablesLanguage", "(", "table_context", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_fails_with_unknown_function": [[61, 65], ["pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_fails_with_unknown_function", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(unknown_function all_rows string_column:league)\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_select": [[66, 70], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_select", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(select_string all_rows string_column:league)\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "set", "(", "cell_list", ")", "==", "{", "\"usl_a_league\"", ",", "\"usl_first_division\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_select_number": [[71, 75], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_select_number", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(select_number all_rows number_column:division)\"", "\n", "selected_number", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "selected_number", "==", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_argmax": [[76, 82], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_argmax", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "(", "\n", "\"(select_string (argmax all_rows number_column:avg_attendance) string_column:league)\"", "\n", ")", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"usl_a_league\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_argmax_on_dates": [[83, 87], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_argmax_on_dates", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(select_string (argmax all_rows date_column:year) string_column:league)\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"usl_first_division\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_argmin": [[88, 94], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "allennlp_semparse.common.Date"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_argmin", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "(", "\n", "\"(select_date (argmin all_rows number_column:avg_attendance) date_column:year)\"", "\n", ")", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "Date", "(", "2005", ",", "3", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_argmin_on_dates": [[95, 99], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_argmin_on_dates", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(select_string (argmin all_rows date_column:year) string_column:league)\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"usl_a_league\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_number_greater": [[100, 117], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_filter_number_greater", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have attendance greater than the min value of", "\n", "# attendance.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_number_greater all_rows number_column:avg_attendance\n                                   (min_number all_rows number_column:avg_attendance)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_a_league\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_number_greater all_rows number_column:avg_attendance\n                                   all_rows) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "# Replacing the filter value with an invalid value.", "\n", "", "logical_form", "=", "\"\"\"(select_string (filter_number_greater all_rows number_column:avg_attendance\n                            string:usl_first_division) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_date_greater": [[118, 129], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_date_greater", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date greater than 2002.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_date_greater all_rows date_column:year\n                                   (date 2002 -1 -1)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_first_division\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_date_greater all_rows date_column:year\n                                   2005) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_number_greater_equals": [[130, 147], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_number_greater_equals", "(", "self", ")", ":", "\n", "# Counting rows that have attendance greater than or equal to the min value of attendance.", "\n", "        ", "logical_form", "=", "\"\"\"(count (filter_number_greater_equals all_rows number_column:avg_attendance\n                                  (min_number all_rows number_column:avg_attendance)))\"\"\"", "\n", "count_result", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "count_result", "==", "2", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "(", "\n", "\"\"\"(count (filter_number_greater all_rows number_column:avg_attendance all_rows))\"\"\"", "\n", ")", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "# Replacing the filter value with an invalid value.", "\n", "", "logical_form", "=", "\"\"\"(count (filter_number_greater all_rows number_column:avg_attendance\n                                  string:usl_a_league))\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_date_greater_equals": [[148, 160], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_date_greater_equals", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date greater than or equal to 2005 February", "\n", "# 1st.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_date_greater_equals all_rows date_column:year\n                                   (date 2005 2 1)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_first_division\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_date_greater_equals all_rows date_column:year\n                                   2005) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_number_lesser": [[161, 167], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_number_lesser", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date lesser than 2005.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_number_lesser all_rows number_column:avg_attendance\n                                    (max_number all_rows number_column:avg_attendance)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_first_division\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_date_lesser": [[168, 179], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_filter_date_lesser", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date less that 2005 January", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_date_lesser all_rows date_column:year\n                                   (date 2005 1 -1)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_a_league\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_date_lesser all_rows date_column:year\n                                   2005) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_number_lesser_equals": [[180, 187], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_number_lesser_equals", "(", "self", ")", ":", "\n", "# Counting rows that have year lesser than or equal to 2005.", "\n", "        ", "logical_form", "=", "(", "\n", "\"\"\"(count (filter_number_lesser_equals all_rows number_column:avg_attendance 8000))\"\"\"", "\n", ")", "\n", "count_result", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "count_result", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_date_lesser_equals": [[188, 199], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_filter_date_lesser_equals", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date less that or equal to 2001 February 23", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_date_lesser_equals all_rows date_column:year\n                                   (date 2001 2 23)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_a_league\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_date_lesser_equals all_rows date_column:year\n                                   2005) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_number_equals": [[200, 207], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_number_equals", "(", "self", ")", ":", "\n", "# Counting rows that have year equal to 2010.", "\n", "        ", "logical_form", "=", "(", "\n", "\"\"\"(count (filter_number_equals all_rows number_column:avg_attendance 8000))\"\"\"", "\n", ")", "\n", "count_result", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "count_result", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_date_equals": [[208, 219], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_filter_date_equals", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date not equal to 2001", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_date_equals all_rows date_column:year\n                                   (date 2001 -1 -1)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_a_league\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_date_equals all_rows date_column:year\n                                   2005) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_number_not_equals": [[220, 227], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_number_not_equals", "(", "self", ")", ":", "\n", "# Counting rows that have year not equal to 2010.", "\n", "        ", "logical_form", "=", "(", "\n", "\"\"\"(count (filter_number_not_equals all_rows number_column:avg_attendance 8000))\"\"\"", "\n", ")", "\n", "count_result", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "count_result", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_date_not_equals": [[228, 239], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_filter_date_not_equals", "(", "self", ")", ":", "\n", "# Selecting cell values from all rows that have date not equal to 2001", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_date_not_equals all_rows date_column:year\n                                   (date 2001 -1 -1)) string_column:league)\"\"\"", "\n", "cell_value_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_value_list", "==", "[", "\"usl_first_division\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_date_not_equals all_rows date_column:year\n                                   2005) string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_in": [[240, 246], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_filter_in", "(", "self", ")", ":", "\n", "# Selecting \"regular season\" from rows that have \"did not qualify\" in \"open cup\" column.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_in all_rows string_column:open_cup string:did_not_qualify)\n                                  string_column:regular_season)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"4th_western\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_select_nested_in_filter_in": [[247, 252], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_select_nested_in_filter_in", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(filter_in all_rows string_column:regular_season (select_string (first all_rows)\n                           string_column:regular_season))\"\"\"", "\n", "row_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "row_list", "==", "self", ".", "language", ".", "execute", "(", "\"(first all_rows)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_filter_not_in": [[253, 264], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_filter_not_in", "(", "self", ")", ":", "\n", "# Selecting \"regular season\" from rows that do not have \"did not qualify\" in \"open cup\" column.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (filter_not_in all_rows string_column:open_cup string:did_not_qualify)\n                                   string_column:regular_season)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"5th\"", "]", "\n", "# Replacing the filter value with an invalid value.", "\n", "logical_form", "=", "\"\"\"(select_string (filter_not_in all_rows string_column:open_cup 2000)\n                                   string_column:regular_season)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_first": [[265, 270], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_execute_works_with_first", "(", "self", ")", ":", "\n", "# Selecting \"regular season\" from the first row.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (first all_rows) string_column:regular_season)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"4th_western\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_logs_warning_with_first_on_empty_list": [[271, 278], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_logs_warning_with_first_on_empty_list", "(", "self", ",", "caplog", ")", ":", "\n", "# Selecting \"regular season\" from the first row where year is greater than 2010.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (first (filter_date_greater all_rows date_column:year\n                                            (date 2010 -1 -1)))\n                                  string_column:regular_season)\"\"\"", "\n", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "\"Trying to get first row from an empty list\"", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_last": [[279, 286], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_last", "(", "self", ")", ":", "\n", "# Selecting \"regular season\" from the last row where year is not equal to 2010.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (last (filter_date_not_equals all_rows date_column:year\n                                         (date 2010 -1 -1)))\n                                  string_column:regular_season)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"5th\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_logs_warning_with_last_on_empty_list": [[287, 294], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_logs_warning_with_last_on_empty_list", "(", "self", ",", "caplog", ")", ":", "\n", "# Selecting \"regular season\" from the last row where year is greater than 2010.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (last (filter_date_greater all_rows date_column:year\n                                            (date 2010 -1 -1)))\n                                  string_column:regular_season)\"\"\"", "\n", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "\"Trying to get last row from an empty list\"", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_previous": [[295, 302], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_previous", "(", "self", ")", ":", "\n", "# Selecting \"regular season\" from the row before last where year is not equal to 2010.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (previous (last (filter_date_not_equals\n                                                    all_rows date_column:year (date 2010 -1 -1))))\n                                  string_column:regular_season)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"4th_western\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_next": [[303, 310], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_next", "(", "self", ")", ":", "\n", "# Selecting \"regular season\" from the row after first where year is not equal to 2010.", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (next (first (filter_date_not_equals\n                                                all_rows date_column:year (date 2010 -1 -1))))\n                                  string_column:regular_season)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"5th\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_max_date": [[311, 315], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_execute_works_with_max_date", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(max_date all_rows date_column:year)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "str", "(", "cell_list", ")", "==", "\"2005\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_min_date": [[316, 320], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_execute_works_with_min_date", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(min_date all_rows date_column:year)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "str", "(", "cell_list", ")", "==", "\"2001\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_mode_number": [[321, 331], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_mode_number", "(", "self", ")", ":", "\n", "# Most frequent division value.", "\n", "        ", "logical_form", "=", "\"\"\"(mode_number all_rows number_column:division)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "2.0", "\n", "logical_form", "=", "\"\"\"(mode_number\n                            (filter_in all_rows string_column:league string:a_league)\n                           number_column:division)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_mode_string": [[332, 337], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_mode_string", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(mode_string all_rows string_column:league)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "# Returns the string values with frequency 1 (which is the max frequency)", "\n", "assert", "cell_list", "==", "[", "\"usl_a_league\"", ",", "\"usl_first_division\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_mode_date": [[338, 342], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_execute_works_with_mode_date", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(mode_date all_rows date_column:year)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "str", "(", "cell_list", ")", "==", "\"2001\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_same_as": [[343, 351], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_same_as", "(", "self", ")", ":", "\n", "# Select the \"league\" from all the rows that have the same value under \"playoffs\" as the", "\n", "# row that has the string \"a league\" under \"league\".", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (same_as (filter_in all_rows string_column:league string:a_league)\n                                   string_column:playoffs)\n                           string_column:league)\"\"\"", "\n", "cell_list", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "cell_list", "==", "[", "\"usl_a_league\"", ",", "\"usl_first_division\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_sum": [[352, 362], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_sum", "(", "self", ")", ":", "\n", "# Get total \"avg attendance\".", "\n", "        ", "logical_form", "=", "\"\"\"(sum all_rows number_column:avg_attendance)\"\"\"", "\n", "sum_value", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "sum_value", "==", "13197", "\n", "# Total \"avg attendance\" where \"playoffs\" has \"quarterfinals\"", "\n", "logical_form", "=", "\"\"\"(sum (filter_in all_rows string_column:playoffs string:quarterfinals)\n                                number_column:avg_attendance)\"\"\"", "\n", "sum_value", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "sum_value", "==", "13197", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_average": [[363, 373], ["wikitables_language_test.TestWikiTablesLanguage.language.execute", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_average", "(", "self", ")", ":", "\n", "# Get average \"avg attendance\".", "\n", "        ", "logical_form", "=", "\"\"\"(average all_rows number_column:avg_attendance)\"\"\"", "\n", "avg_value", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "avg_value", "==", "6598.5", "\n", "# Average \"avg attendance\" where \"playoffs\" has \"quarterfinals\"", "\n", "logical_form", "=", "\"\"\"(average (filter_in all_rows string_column:playoffs string:quarterfinals)\n                                number_column:avg_attendance)\"\"\"", "\n", "avg_value", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "avg_value", "==", "6598.5", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_works_with_diff": [[374, 382], ["wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_works_with_diff", "(", "self", ")", ":", "\n", "# Difference in \"avg attendance\" between rows with \"usl_a_league\" and \"usl_first_division\"", "\n", "# in \"league\" columns.", "\n", "        ", "logical_form", "=", "\"\"\"(diff (filter_in all_rows string_column:league string:usl_a_league)\n                                (filter_in all_rows string_column:league string:usl_first_division)\n                                number_column:avg_attendance)\"\"\"", "\n", "avg_value", "=", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "assert", "avg_value", "==", "1141", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_execute_fails_with_diff_on_non_numerical_columns": [[383, 389], ["pytest.raises", "wikitables_language_test.TestWikiTablesLanguage.language.execute"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "def", "test_execute_fails_with_diff_on_non_numerical_columns", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(diff (filter_in all_rows string_column:league string:usl_a_league)\n                                (filter_in all_rows string_column:league string:usl_first_division)\n                                string_column:league)\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ")", ":", "\n", "            ", "self", ".", "language", ".", "execute", "(", "logical_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_number_comparison_works": [[390, 400], ["allennlp.data.tokenizers.SpacyTokenizer().tokenize", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens_and_table_file", "wikitables_language_test.TestWikiTablesLanguage.execute", "allennlp_semparse.common.Date", "allennlp.data.tokenizers.SpacyTokenizer"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens_and_table_file", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.execute"], ["", "", "def", "test_number_comparison_works", "(", "self", ")", ":", "\n", "# TableQuestionContext normlaizes all strings according to some rules. We want to ensure", "\n", "# that the original numerical values of number cells is being correctly processed here.", "\n", "        ", "tokens", "=", "SpacyTokenizer", "(", ")", ".", "tokenize", "(", "\"when was the attendance the highest?\"", ")", "\n", "tagged_file", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"corenlp_processed_tables\"", "/", "\"TEST-2.table\"", "\n", "language", "=", "self", ".", "_get_world_with_question_tokens_and_table_file", "(", "tokens", ",", "tagged_file", ")", "\n", "result", "=", "language", ".", "execute", "(", "\n", "\"(select_date (argmax all_rows number_column:attendance) date_column:date)\"", "\n", ")", "\n", "assert", "result", "==", "Date", "(", "-", "1", ",", "11", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_evaluate_logical_form": [[401, 407], ["wikitables_language_test.TestWikiTablesLanguage.language.evaluate_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_logical_form"], ["", "def", "test_evaluate_logical_form", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (same_as (filter_in all_rows string_column:league string:a_league)\n                                   string_column:playoffs)\n                           string_column:league)\"\"\"", "\n", "assert", "self", ".", "language", ".", "evaluate_logical_form", "(", "\n", "logical_form", ",", "[", "\"USL A-League\"", ",", "\"USL First Division\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_evaluate_logical_form_with_invalid_logical_form": [[409, 415], ["wikitables_language_test.TestWikiTablesLanguage.language.evaluate_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.evaluate_logical_form"], ["", "def", "test_evaluate_logical_form_with_invalid_logical_form", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(select_string (same_as (filter_in all_rows string_column:league INVALID_CONSTANT)\n                                   string_column:playoffs)\n                           string_column:league)\"\"\"", "\n", "assert", "not", "self", ".", "language", ".", "evaluate_logical_form", "(", "\n", "logical_form", ",", "[", "\"USL A-League\"", ",", "\"USL First Division\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_get_nonterminal_productions_all_column_types": [[417, 624], ["wikitables_language_test.TestWikiTablesLanguage.language.get_nonterminal_productions", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "domain_language_test.check_productions_match", "set", "wikitables_language_test.TestWikiTablesLanguage.keys"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.check_productions_match"], ["", "def", "test_get_nonterminal_productions_all_column_types", "(", "self", ")", ":", "\n", "# This test is long, but worth it.  These are all of the valid actions in the grammar, and", "\n", "# we want to be sure they are what we expect.", "\n", "        ", "productions", "=", "self", ".", "language", ".", "get_nonterminal_productions", "(", ")", "\n", "assert", "set", "(", "productions", ".", "keys", "(", ")", ")", "==", "{", "\n", "\"@start@\"", ",", "\n", "\"<List[Row],StringColumn:List[str]>\"", ",", "\n", "\"<List[Row],DateColumn:Date>\"", ",", "\n", "\"<List[Row],NumberColumn,Number:List[Row]>\"", ",", "\n", "\"<List[Row],ComparableColumn:List[Row]>\"", ",", "\n", "\"<List[Row],Column:List[Row]>\"", ",", "\n", "\"<List[Row],List[Row],NumberColumn:Number>\"", ",", "\n", "\"<List[Row],StringColumn,List[str]:List[Row]>\"", ",", "\n", "\"<Number,Number,Number:Date>\"", ",", "\n", "\"<List[Row],DateColumn,Date:List[Row]>\"", ",", "\n", "\"<List[Row],NumberColumn:Number>\"", ",", "\n", "\"<List[Row]:List[Row]>\"", ",", "\n", "\"<List[Row],StringColumn:List[str]>\"", ",", "\n", "\"<List[Row]:Number>\"", ",", "\n", "\"List[str]\"", ",", "\n", "\"List[Row]\"", ",", "\n", "\"Date\"", ",", "\n", "\"Number\"", ",", "\n", "\"StringColumn\"", ",", "\n", "\"NumberColumn\"", ",", "\n", "\"ComparableColumn\"", ",", "\n", "\"Column\"", ",", "\n", "\"DateColumn\"", ",", "\n", "\"List[str]\"", ",", "\n", "}", "\n", "\n", "check_productions_match", "(", "productions", "[", "\"@start@\"", "]", ",", "[", "\"Date\"", ",", "\"Number\"", ",", "\"List[str]\"", "]", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],StringColumn:List[str]>\"", "]", ",", "[", "\"select_string\"", ",", "\"mode_string\"", "]", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],DateColumn:Date>\"", "]", ",", "\n", "[", "\"select_date\"", ",", "\"max_date\"", ",", "\"min_date\"", ",", "\"mode_date\"", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],NumberColumn,Number:List[Row]>\"", "]", ",", "\n", "[", "\n", "\"filter_number_equals\"", ",", "\n", "\"filter_number_greater\"", ",", "\n", "\"filter_number_greater_equals\"", ",", "\n", "\"filter_number_lesser\"", ",", "\n", "\"filter_number_lesser_equals\"", ",", "\n", "\"filter_number_not_equals\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],ComparableColumn:List[Row]>\"", "]", ",", "[", "\"argmax\"", ",", "\"argmin\"", "]", "\n", ")", "\n", "\n", "check_productions_match", "(", "productions", "[", "\"<List[Row],Column:List[Row]>\"", "]", ",", "[", "\"same_as\"", "]", ")", "\n", "\n", "check_productions_match", "(", "productions", "[", "\"<List[Row],List[Row],NumberColumn:Number>\"", "]", ",", "[", "\"diff\"", "]", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],StringColumn,List[str]:List[Row]>\"", "]", ",", "\n", "[", "\"filter_in\"", ",", "\"filter_not_in\"", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "productions", "[", "\"<Number,Number,Number:Date>\"", "]", ",", "[", "\"date\"", "]", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],DateColumn,Date:List[Row]>\"", "]", ",", "\n", "[", "\n", "\"filter_date_equals\"", ",", "\n", "\"filter_date_greater\"", ",", "\n", "\"filter_date_greater_equals\"", ",", "\n", "\"filter_date_lesser\"", ",", "\n", "\"filter_date_lesser_equals\"", ",", "\n", "\"filter_date_not_equals\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row],NumberColumn:Number>\"", "]", ",", "\n", "[", "\"average\"", ",", "\"max_number\"", ",", "\"min_number\"", ",", "\"sum\"", ",", "\"select_number\"", ",", "\"mode_number\"", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"<List[Row]:List[Row]>\"", "]", ",", "[", "\"first\"", ",", "\"last\"", ",", "\"next\"", ",", "\"previous\"", "]", "\n", ")", "\n", "\n", "check_productions_match", "(", "productions", "[", "\"<List[Row]:Number>\"", "]", ",", "[", "\"count\"", "]", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"List[Row]\"", "]", ",", "\n", "[", "\n", "\"all_rows\"", ",", "\n", "\"[<List[Row],Column:List[Row]>, List[Row], Column]\"", ",", "\n", "\"[<List[Row],DateColumn,Date:List[Row]>, List[Row], DateColumn, Date]\"", ",", "\n", "\"[<List[Row],ComparableColumn:List[Row]>, List[Row], ComparableColumn]\"", ",", "\n", "\"[<List[Row],NumberColumn,Number:List[Row]>, List[Row], NumberColumn, Number]\"", ",", "\n", "\"[<List[Row],StringColumn,List[str]:List[Row]>, List[Row], StringColumn, List[str]]\"", ",", "\n", "\"[<List[Row]:List[Row]>, List[Row]]\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"Date\"", "]", ",", "\n", "[", "\n", "\"[<Number,Number,Number:Date>, Number, Number, Number]\"", ",", "\n", "\"[<List[Row],DateColumn:Date>, List[Row], DateColumn]\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "# Some of the number productions are instance-specific, and some of them are from the", "\n", "# grammar.", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"Number\"", "]", ",", "\n", "[", "\n", "\"2001\"", ",", "\n", "\"2002\"", ",", "\n", "\"2005\"", ",", "\n", "\"2010\"", ",", "\n", "\"2013\"", ",", "\n", "\"-1\"", ",", "\n", "\"1\"", ",", "\n", "\"2\"", ",", "\n", "\"23\"", ",", "\n", "\"8000\"", ",", "\n", "\"[<List[Row],NumberColumn:Number>, List[Row], NumberColumn]\"", ",", "\n", "\"[<List[Row],List[Row],NumberColumn:Number>, List[Row], List[Row], NumberColumn]\"", ",", "\n", "\"[<List[Row]:Number>, List[Row]]\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "# These are the columns in table, and are instance specific.", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"StringColumn\"", "]", ",", "\n", "[", "\n", "\"string_column:league\"", ",", "\n", "\"string_column:playoffs\"", ",", "\n", "\"string_column:open_cup\"", ",", "\n", "\"string_column:year\"", ",", "\n", "\"string_column:division\"", ",", "\n", "\"string_column:avg_attendance\"", ",", "\n", "\"string_column:regular_season\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "productions", "[", "\"DateColumn\"", "]", ",", "[", "\"date_column:year\"", "]", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"NumberColumn\"", "]", ",", "\n", "[", "\n", "\"number_column:avg_attendance\"", ",", "\n", "\"number_column:open_cup\"", ",", "\n", "\"number_column:regular_season\"", ",", "\n", "\"number_column:division\"", ",", "\n", "\"number_column:year\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"ComparableColumn\"", "]", ",", "\n", "[", "\n", "\"date_column:year\"", ",", "\n", "\"number_column:avg_attendance\"", ",", "\n", "\"number_column:open_cup\"", ",", "\n", "\"number_column:regular_season\"", ",", "\n", "\"number_column:division\"", ",", "\n", "\"number_column:year\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"Column\"", "]", ",", "\n", "[", "\n", "\"string_column:league\"", ",", "\n", "\"string_column:playoffs\"", ",", "\n", "\"string_column:open_cup\"", ",", "\n", "\"string_column:year\"", ",", "\n", "\"string_column:division\"", ",", "\n", "\"string_column:avg_attendance\"", ",", "\n", "\"string_column:regular_season\"", ",", "\n", "\"date_column:year\"", ",", "\n", "\"number_column:avg_attendance\"", ",", "\n", "\"number_column:open_cup\"", ",", "\n", "\"number_column:regular_season\"", ",", "\n", "\"number_column:division\"", ",", "\n", "\"number_column:year\"", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "# Strings come from the question - any span in the question that shows up as a cell in the", "\n", "# table is a valid string production.", "\n", "check_productions_match", "(", "\n", "productions", "[", "\"List[str]\"", "]", ",", "\n", "[", "\n", "\"string:quarterfinals\"", ",", "\n", "\"string:did_not_qualify\"", ",", "\n", "\"string:a_league\"", ",", "\n", "\"string:usl_first_division\"", ",", "\n", "\"string:usl_a_league\"", ",", "\n", "\"string:1\"", ",", "\n", "\"string:2\"", ",", "\n", "\"string:2005\"", ",", "\n", "\"string:2001\"", ",", "\n", "\"[<List[Row],StringColumn:List[str]>, List[Row], StringColumn]\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_world_processes_logical_forms_correctly": [[627, 634], ["wikitables_language_test.TestWikiTablesLanguage.language.logical_form_to_action_sequence", "wikitables_language_test.TestWikiTablesLanguage.language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_world_processes_logical_forms_correctly", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "(", "\n", "\"(select_date (filter_in all_rows string_column:league string:usl_a_league)\"", "\n", "\" date_column:year)\"", "\n", ")", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_world_gets_correct_actions": [[635, 650], ["wikitables_language_test.TestWikiTablesLanguage.language.logical_form_to_action_sequence"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence"], ["", "def", "test_world_gets_correct_actions", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"\"\"(select_date (filter_in all_rows string_column:league string:usl_a_league)\n                           date_column:year)\"\"\"", "\n", "expected_sequence", "=", "[", "\n", "\"@start@ -> Date\"", ",", "\n", "\"Date -> [<List[Row],DateColumn:Date>, List[Row], DateColumn]\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"List[Row] -> [<List[Row],StringColumn,List[str]:List[Row]>, List[Row], StringColumn, List[str]]\"", ",", "\n", "\"<List[Row],StringColumn,List[str]:List[Row]> -> filter_in\"", ",", "\n", "\"List[Row] -> all_rows\"", ",", "\n", "\"StringColumn -> string_column:league\"", ",", "\n", "\"List[str] -> string:usl_a_league\"", ",", "\n", "\"DateColumn -> date_column:year\"", ",", "\n", "]", "\n", "assert", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "==", "expected_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_world_processes_logical_forms_with_number_correctly": [[651, 658], ["wikitables_language_test.TestWikiTablesLanguage.language.logical_form_to_action_sequence", "wikitables_language_test.TestWikiTablesLanguage.language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_world_processes_logical_forms_with_number_correctly", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "(", "\n", "\"(select_date (filter_number_greater all_rows number_column:avg_attendance 8000) \"", "\n", "\"date_column:year)\"", "\n", ")", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_world_processes_logical_forms_with_date_correctly": [[659, 666], ["wikitables_language_test.TestWikiTablesLanguage.language.logical_form_to_action_sequence", "wikitables_language_test.TestWikiTablesLanguage.language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_world_processes_logical_forms_with_date_correctly", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "(", "\n", "\"(select_date (filter_date_greater all_rows date_column:year (date 2013 -1 -1)) \"", "\n", "\"date_column:year)\"", "\n", ")", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_world_processes_logical_forms_with_generic_function_correctly": [[667, 671], ["wikitables_language_test.TestWikiTablesLanguage.language.logical_form_to_action_sequence", "wikitables_language_test.TestWikiTablesLanguage.language.action_sequence_to_logical_form"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.logical_form_to_action_sequence", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "test_world_processes_logical_forms_with_generic_function_correctly", "(", "self", ")", ":", "\n", "        ", "logical_form", "=", "\"(select_string (argmax all_rows date_column:year) string_column:league)\"", "\n", "action_sequence", "=", "self", ".", "language", ".", "logical_form_to_action_sequence", "(", "logical_form", ")", "\n", "assert", "self", ".", "language", ".", "action_sequence_to_logical_form", "(", "action_sequence", ")", "==", "logical_form", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage.test_get_agenda": [[672, 1045], ["wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "allennlp.data.tokenizers.Token", "set", "set", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda", "wikitables_language_test.TestWikiTablesLanguage.get_agenda"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language_test.TestWikiTablesLanguage._get_world_with_question_tokens", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.wikitables_language.WikiTablesLanguage.get_agenda"], ["", "def", "test_get_agenda", "(", "self", ")", ":", "\n", "        ", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"difference\"", ",", "\n", "\"in\"", ",", "\n", "\"attendance\"", ",", "\n", "\"between\"", ",", "\n", "\"years\"", ",", "\n", "\"2001\"", ",", "\n", "\"and\"", ",", "\n", "\"2005\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "# \"year\" column does not match because \"years\" occurs in the question.", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"Number -> 2001\"", ",", "\n", "\"Number -> 2005\"", ",", "\n", "\"List[str] -> string:2005\"", ",", "\n", "\"List[str] -> string:2001\"", ",", "\n", "\"<List[Row],DateColumn,Date:List[Row]> -> filter_date_equals\"", ",", "\n", "\"<List[Row],List[Row],NumberColumn:Number> -> diff\"", ",", "\n", "}", "\n", "# Conservative agenda does not have strings and numbers because they have multiple types.", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],List[Row],NumberColumn:Number> -> diff\"", ",", "\n", "\"<List[Row],DateColumn,Date:List[Row]> -> filter_date_equals\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"total\"", ",", "\n", "\"avg.\"", ",", "\n", "\"attendance\"", ",", "\n", "\"in\"", ",", "\n", "\"years\"", ",", "\n", "\"2001\"", ",", "\n", "\"and\"", ",", "\n", "\"2005\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"Number -> 2001\"", ",", "\n", "\"Number -> 2005\"", ",", "\n", "\"List[str] -> string:2005\"", ",", "\n", "\"List[str] -> string:2001\"", ",", "\n", "\"<List[Row],NumberColumn:Number> -> sum\"", ",", "\n", "\"<List[Row],DateColumn,Date:List[Row]> -> filter_date_equals\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "# Conservative disallows \"sum\" for the question word \"total\" too.", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],DateColumn,Date:List[Row]> -> filter_date_equals\"", "\n", "}", "\n", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "[", "\"what\"", ",", "\"was\"", ",", "\"the\"", ",", "\"average\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"?\"", "]", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn:Number> -> average\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn:Number> -> average\"", "\n", "}", "\n", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "[", "\"what\"", ",", "\"was\"", ",", "\"the\"", ",", "\"largest\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"?\"", "]", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmax\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmax\"", "\n", "}", "\n", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "[", "\"when\"", ",", "\"was\"", ",", "\"the\"", ",", "\"least\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"?\"", "]", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"attendance\"", ",", "\n", "\"after\"", ",", "\n", "\"the\"", ",", "\n", "\"time\"", ",", "\n", "\"with\"", ",", "\n", "\"the\"", ",", "\n", "\"least\"", ",", "\n", "\"avg.\"", ",", "\n", "\"attendance\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"<List[Row]:List[Row]> -> next\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "# conservative disallows \"after\" mapping to \"next\"", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"attendance\"", ",", "\n", "\"below\"", ",", "\n", "\"the\"", ",", "\n", "\"row\"", ",", "\n", "\"with\"", ",", "\n", "\"the\"", ",", "\n", "\"least\"", ",", "\n", "\"avg.\"", ",", "\n", "\"attendance\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"<List[Row]:List[Row]> -> next\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"<List[Row]:List[Row]> -> next\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"attendance\"", ",", "\n", "\"before\"", ",", "\n", "\"the\"", ",", "\n", "\"time\"", ",", "\n", "\"with\"", ",", "\n", "\"the\"", ",", "\n", "\"least\"", ",", "\n", "\"avg.\"", ",", "\n", "\"attendance\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"<List[Row]:List[Row]> -> previous\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "# conservative disallows \"before\" mapping to \"previous\"", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"what\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"attendance\"", ",", "\n", "\"above\"", ",", "\n", "\"the\"", ",", "\n", "\"row\"", ",", "\n", "\"with\"", ",", "\n", "\"the\"", ",", "\n", "\"least\"", ",", "\n", "\"avg.\"", ",", "\n", "\"attendance\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"<List[Row]:List[Row]> -> previous\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],ComparableColumn:List[Row]> -> argmin\"", ",", "\n", "\"<List[Row]:List[Row]> -> previous\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\n", "\"when\"", ",", "\n", "\"was\"", ",", "\n", "\"the\"", ",", "\n", "\"avg.\"", ",", "\n", "\"attendance\"", ",", "\n", "\"same\"", ",", "\n", "\"as\"", ",", "\n", "\"when\"", ",", "\n", "\"the\"", ",", "\n", "\"league\"", ",", "\n", "\"was\"", ",", "\n", "\"usl\"", ",", "\n", "\"a\"", ",", "\n", "\"league\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "\"StringColumn -> string_column:league\"", ",", "\n", "\"List[str] -> string:usl_a_league\"", ",", "\n", "\"<List[Row],Column:List[Row]> -> same_as\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"StringColumn -> string_column:league\"", ",", "\n", "\"List[str] -> string:usl_a_league\"", ",", "\n", "\"<List[Row],Column:List[Row]> -> same_as\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "[", "\"what\"", ",", "\"is\"", ",", "\"the\"", ",", "\"least\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"?\"", "]", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn:Number> -> min_number\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn:Number> -> min_number\"", "\n", "}", "\n", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "[", "\"when\"", ",", "\"did\"", ",", "\"the\"", ",", "\"team\"", ",", "\"not\"", ",", "\"qualify\"", ",", "\"?\"", "]", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"List[str] -> string:qualify\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"List[str] -> string:qualify\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\"when\"", ",", "\"was\"", ",", "\"the\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"at\"", ",", "\"least\"", ",", "\"7000\"", ",", "\"?\"", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_greater_equals\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_greater_equals\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\"when\"", ",", "\"was\"", ",", "\"the\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"more\"", ",", "\"than\"", ",", "\"7000\"", ",", "\"?\"", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_greater\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_greater\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\"when\"", ",", "\"was\"", ",", "\"the\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"at\"", ",", "\"most\"", ",", "\"7000\"", ",", "\"?\"", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_lesser_equals\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_lesser_equals\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "\n", "for", "x", "in", "[", "\"when\"", ",", "\"was\"", ",", "\"the\"", ",", "\"avg.\"", ",", "\"attendance\"", ",", "\"no\"", ",", "\"more\"", ",", "\"than\"", ",", "\"7000\"", ",", "\"?\"", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_lesser_equals\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"NumberColumn -> number_column:avg_attendance\"", ",", "\n", "\"StringColumn -> string_column:avg_attendance\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\n", "\"<List[Row],NumberColumn,Number:List[Row]> -> filter_number_lesser_equals\"", ",", "\n", "\"<List[Row],DateColumn:Date> -> select_date\"", ",", "\n", "\"Number -> 7000\"", ",", "\n", "}", "\n", "\n", "tokens", "=", "[", "Token", "(", "x", ")", "for", "x", "in", "[", "\"what\"", ",", "\"was\"", ",", "\"the\"", ",", "\"top\"", ",", "\"year\"", ",", "\"?\"", "]", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row]:List[Row]> -> first\"", ",", "\n", "\"StringColumn -> string_column:year\"", ",", "\n", "\"NumberColumn -> number_column:year\"", ",", "\n", "\"DateColumn -> date_column:year\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\"<List[Row]:List[Row]> -> first\"", "}", "\n", "\n", "tokens", "=", "[", "\n", "Token", "(", "x", ")", "for", "x", "in", "[", "\"what\"", ",", "\"was\"", ",", "\"the\"", ",", "\"year\"", ",", "\"in\"", ",", "\"the\"", ",", "\"bottom\"", ",", "\"row\"", ",", "\"?\"", "]", "\n", "]", "\n", "world", "=", "self", ".", "_get_world_with_question_tokens", "(", "tokens", ")", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", ")", ")", "==", "{", "\n", "\"<List[Row]:List[Row]> -> last\"", ",", "\n", "\"StringColumn -> string_column:year\"", ",", "\n", "\"NumberColumn -> number_column:year\"", ",", "\n", "\"DateColumn -> date_column:year\"", ",", "\n", "}", "\n", "assert", "set", "(", "world", ".", "get_agenda", "(", "conservative", "=", "True", ")", ")", "==", "{", "\"<List[Row]:List[Row]> -> last\"", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.beam_search.BeamSearch.__init__": [[49, 75], ["allennlp_semparse.state_machines.util.construct_prefix_tree", "initial_sequence.view"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.util.construct_prefix_tree"], ["def", "__init__", "(", "\n", "self", ",", "\n", "beam_size", ":", "int", ",", "\n", "per_node_beam_size", ":", "int", "=", "None", ",", "\n", "initial_sequence", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "keep_beam_details", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_beam_size", "=", "beam_size", "\n", "self", ".", "_per_node_beam_size", "=", "per_node_beam_size", "or", "beam_size", "\n", "\n", "if", "initial_sequence", "is", "not", "None", ":", "\n", "# construct_prefix_tree wants a tensor of shape (batch_size, num_sequences, sequence_length)", "\n", "# so we need to add the first two dimensions in. This returns a list, but we're assuming", "\n", "# batch size 1, so we extract the first element.", "\n", "            ", "self", ".", "_allowed_transitions", "=", "util", ".", "construct_prefix_tree", "(", "initial_sequence", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", ")", "[", "\n", "0", "\n", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_allowed_transitions", "=", "None", "\n", "\n", "", "if", "keep_beam_details", ":", "\n", "# mapping from batch_index to a list (timesteps) of lists (beam elements)", "\n", "# of pairs (score, action_history)", "\n", "            ", "self", ".", "beam_snapshots", ":", "Dict", "[", "int", ",", "List", "[", "List", "[", "Tuple", "[", "float", ",", "List", "[", "int", "]", "]", "]", "]", "]", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "beam_snapshots", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.beam_search.BeamSearch.constrained_to": [[76, 84], ["beam_search.BeamSearch"], "methods", ["None"], ["", "", "def", "constrained_to", "(", "\n", "self", ",", "initial_sequence", ":", "torch", ".", "Tensor", ",", "keep_beam_details", ":", "bool", "=", "True", "\n", ")", "->", "\"BeamSearch\"", ":", "\n", "        ", "\"\"\"\n        Return a new BeamSearch instance that's like this one but with the specified constraint.\n        \"\"\"", "\n", "return", "BeamSearch", "(", "\n", "self", ".", "_beam_size", ",", "self", ".", "_per_node_beam_size", ",", "initial_sequence", ",", "keep_beam_details", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.beam_search.BeamSearch.search": [[86, 189], ["collections.defaultdict", "finished_states.items", "collections.defaultdict", "collections.defaultdict", "states[].combine_states", "transition_function.take_step", "next_states.items", "finished_states.items", "finished_to_sort.sort", "tuple", "next_state.is_finished", "states.extend", "finished_states[].append", "next_states[].append", "beam_search.BeamSearch.beam_snapshots[].append", "state.score[].item", "[].append", "finished_states[].append", "len", "len", "beam_search.BeamSearch.beam_snapshots[].append", "state.score[].item", "state.score[].item", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.combine_states", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.take_step", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "search", "(", "\n", "self", ",", "\n", "num_steps", ":", "int", ",", "\n", "initial_state", ":", "StateType", ",", "\n", "transition_function", ":", "TransitionFunction", ",", "\n", "keep_final_unfinished_states", ":", "bool", "=", "True", ",", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        num_steps : ``int``\n            How many steps should we take in our search?  This is an upper bound, as it's possible\n            for the search to run out of valid actions before hitting this number, or for all\n            states on the beam to finish.\n        initial_state : ``StateType``\n            The starting state of our search.  This is assumed to be `batched`, and our beam search\n            is batch-aware - we'll keep ``beam_size`` states around for each instance in the batch.\n        transition_function : ``TransitionFunction``\n            The ``TransitionFunction`` object that defines and scores transitions from one state to the\n            next.\n        keep_final_unfinished_states : ``bool``, optional (default=True)\n            If we run out of steps before a state is \"finished\", should we return that state in our\n            search results?\n\n        Returns\n        -------\n        best_states : ``Dict[int, List[StateType]]``\n            This is a mapping from batch index to the top states for that instance.\n        \"\"\"", "\n", "finished_states", ":", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "states", "=", "[", "initial_state", "]", "\n", "step_num", "=", "1", "\n", "\n", "# Erase stored beams, if we're tracking them.", "\n", "if", "self", ".", "beam_snapshots", "is", "not", "None", ":", "\n", "            ", "self", ".", "beam_snapshots", "=", "defaultdict", "(", "list", ")", "\n", "\n", "", "while", "states", "and", "step_num", "<=", "num_steps", ":", "\n", "            ", "next_states", ":", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "grouped_state", "=", "states", "[", "0", "]", ".", "combine_states", "(", "states", ")", "\n", "\n", "if", "self", ".", "_allowed_transitions", ":", "\n", "# We were provided an initial sequence, so we need to check", "\n", "# if the current sequence is still constrained.", "\n", "                ", "key", "=", "tuple", "(", "grouped_state", ".", "action_history", "[", "0", "]", ")", "\n", "if", "key", "in", "self", ".", "_allowed_transitions", ":", "\n", "# We're still in the initial_sequence, so our hand is forced.", "\n", "                    ", "allowed_actions", "=", "[", "self", ".", "_allowed_transitions", "[", "key", "]", "]", "\n", "", "else", ":", "\n", "# We've gone past the end of the initial sequence, so no constraint.", "\n", "                    ", "allowed_actions", "=", "None", "\n", "", "", "else", ":", "\n", "# No initial sequence was provided, so all actions are allowed.", "\n", "                ", "allowed_actions", "=", "None", "\n", "\n", "", "for", "next_state", "in", "transition_function", ".", "take_step", "(", "\n", "grouped_state", ",", "max_actions", "=", "self", ".", "_per_node_beam_size", ",", "allowed_actions", "=", "allowed_actions", "\n", ")", ":", "\n", "# NOTE: we're doing state.batch_indices[0] here (and similar things below),", "\n", "# hard-coding a group size of 1.  But, our use of `next_state.is_finished()`", "\n", "# already checks for that, as it crashes if the group size is not 1.", "\n", "                ", "batch_index", "=", "next_state", ".", "batch_indices", "[", "0", "]", "\n", "if", "next_state", ".", "is_finished", "(", ")", ":", "\n", "                    ", "finished_states", "[", "batch_index", "]", ".", "append", "(", "next_state", ")", "\n", "", "else", ":", "\n", "                    ", "if", "step_num", "==", "num_steps", "and", "keep_final_unfinished_states", ":", "\n", "                        ", "finished_states", "[", "batch_index", "]", ".", "append", "(", "next_state", ")", "\n", "", "next_states", "[", "batch_index", "]", ".", "append", "(", "next_state", ")", "\n", "", "", "states", "=", "[", "]", "\n", "for", "batch_index", ",", "batch_states", "in", "next_states", ".", "items", "(", ")", ":", "\n", "# The states from the generator are already sorted, so we can just take the first", "\n", "# ones here, without an additional sort.", "\n", "                ", "states", ".", "extend", "(", "batch_states", "[", ":", "self", ".", "_beam_size", "]", ")", "\n", "\n", "if", "self", ".", "beam_snapshots", "is", "not", "None", ":", "\n", "# Add to beams", "\n", "                    ", "self", ".", "beam_snapshots", "[", "batch_index", "]", ".", "append", "(", "\n", "[", "(", "state", ".", "score", "[", "0", "]", ".", "item", "(", ")", ",", "state", ".", "action_history", "[", "0", "]", ")", "for", "state", "in", "batch_states", "]", "\n", ")", "\n", "", "", "step_num", "+=", "1", "\n", "\n", "# Add finished states to the stored beams as well.", "\n", "", "if", "self", ".", "beam_snapshots", "is", "not", "None", ":", "\n", "            ", "for", "batch_index", ",", "states", "in", "finished_states", ".", "items", "(", ")", ":", "\n", "                ", "for", "state", "in", "states", ":", "\n", "                    ", "score", "=", "state", ".", "score", "[", "0", "]", ".", "item", "(", ")", "\n", "action_history", "=", "state", ".", "action_history", "[", "0", "]", "\n", "\n", "while", "len", "(", "self", ".", "beam_snapshots", "[", "batch_index", "]", ")", "<", "len", "(", "action_history", ")", ":", "\n", "                        ", "self", ".", "beam_snapshots", "[", "batch_index", "]", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "self", ".", "beam_snapshots", "[", "batch_index", "]", "[", "len", "(", "action_history", ")", "-", "1", "]", ".", "append", "(", "\n", "(", "score", ",", "action_history", ")", "\n", ")", "\n", "\n", "", "", "", "best_states", ":", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_states", "in", "finished_states", ".", "items", "(", ")", ":", "\n", "# The time this sort takes is pretty negligible, no particular need to optimize this", "\n", "# yet.  Maybe with a larger beam size...", "\n", "            ", "finished_to_sort", "=", "[", "(", "-", "state", ".", "score", "[", "0", "]", ".", "item", "(", ")", ",", "state", ")", "for", "state", "in", "batch_states", "]", "\n", "finished_to_sort", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "best_states", "[", "batch_index", "]", "=", "[", "state", "[", "1", "]", "for", "state", "in", "finished_to_sort", "[", ":", "self", ".", "_beam_size", "]", "]", "\n", "", "return", "best_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.__init__": [[52, 63], ["allennlp_semparse.state_machines.util.construct_prefix_tree"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.util.construct_prefix_tree"], ["def", "__init__", "(", "\n", "self", ",", "\n", "beam_size", ":", "Optional", "[", "int", "]", ",", "\n", "allowed_sequences", ":", "torch", ".", "Tensor", ",", "\n", "allowed_sequence_mask", ":", "torch", ".", "Tensor", ",", "\n", "per_node_beam_size", ":", "int", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_beam_size", "=", "beam_size", "\n", "self", ".", "_per_node_beam_size", "=", "per_node_beam_size", "or", "beam_size", "\n", "self", ".", "_allowed_transitions", "=", "util", ".", "construct_prefix_tree", "(", "\n", "allowed_sequences", ",", "allowed_sequence_mask", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search": [[65, 123], ["collections.defaultdict", "finished_states.items", "collections.defaultdict", "states[].combine_states", "zip", "transition_function.take_step", "next_states.items", "finished_to_sort.sort", "allowed_actions.append", "next_state.is_finished", "states.extend", "finished_states[].append", "next_states[].append", "state.score[].item", "tuple"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.combine_states", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.take_step", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "search", "(", "\n", "self", ",", "initial_state", ":", "State", ",", "transition_function", ":", "TransitionFunction", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "State", "]", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        initial_state : ``State``\n            The starting state of our search.  This is assumed to be `batched`, and our beam search\n            is batch-aware - we'll keep ``beam_size`` states around for each instance in the batch.\n        transition_function : ``TransitionFunction``\n            The ``TransitionFunction`` object that defines and scores transitions from one state to the\n            next.\n\n        Returns\n        -------\n        best_states : ``Dict[int, List[State]]``\n            This is a mapping from batch index to the top states for that instance.\n        \"\"\"", "\n", "finished_states", ":", "Dict", "[", "int", ",", "List", "[", "State", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "states", "=", "[", "initial_state", "]", "\n", "step_num", "=", "0", "\n", "while", "states", ":", "\n", "            ", "step_num", "+=", "1", "\n", "next_states", ":", "Dict", "[", "int", ",", "List", "[", "State", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "grouped_state", "=", "states", "[", "0", "]", ".", "combine_states", "(", "states", ")", "\n", "allowed_actions", "=", "[", "]", "\n", "for", "batch_index", ",", "action_history", "in", "zip", "(", "\n", "grouped_state", ".", "batch_indices", ",", "grouped_state", ".", "action_history", "\n", ")", ":", "\n", "                ", "allowed_actions", ".", "append", "(", "\n", "self", ".", "_allowed_transitions", "[", "batch_index", "]", "[", "tuple", "(", "action_history", ")", "]", "\n", ")", "\n", "", "for", "next_state", "in", "transition_function", ".", "take_step", "(", "\n", "grouped_state", ",", "max_actions", "=", "self", ".", "_per_node_beam_size", ",", "allowed_actions", "=", "allowed_actions", "\n", ")", ":", "\n", "# NOTE: we're doing state.batch_indices[0] here (and similar things below),", "\n", "# hard-coding a group size of 1.  But, our use of `next_state.is_finished()`", "\n", "# already checks for that, as it crashes if the group size is not 1.", "\n", "                ", "batch_index", "=", "next_state", ".", "batch_indices", "[", "0", "]", "\n", "if", "next_state", ".", "is_finished", "(", ")", ":", "\n", "                    ", "finished_states", "[", "batch_index", "]", ".", "append", "(", "next_state", ")", "\n", "", "else", ":", "\n", "                    ", "next_states", "[", "batch_index", "]", ".", "append", "(", "next_state", ")", "\n", "", "", "states", "=", "[", "]", "\n", "for", "batch_index", ",", "batch_states", "in", "next_states", ".", "items", "(", ")", ":", "\n", "# The states from the generator are already sorted, so we can just take the first", "\n", "# ones here, without an additional sort.", "\n", "                ", "if", "self", ".", "_beam_size", ":", "\n", "                    ", "batch_states", "=", "batch_states", "[", ":", "self", ".", "_beam_size", "]", "\n", "", "states", ".", "extend", "(", "batch_states", ")", "\n", "", "", "best_states", ":", "Dict", "[", "int", ",", "List", "[", "State", "]", "]", "=", "{", "}", "\n", "for", "batch_index", ",", "batch_states", "in", "finished_states", ".", "items", "(", ")", ":", "\n", "# The time this sort takes is pretty negligible, no particular need to optimize this", "\n", "# yet.  Maybe with a larger beam size...", "\n", "            ", "finished_to_sort", "=", "[", "(", "-", "state", ".", "score", "[", "0", "]", ".", "item", "(", ")", ",", "state", ")", "for", "state", "in", "batch_states", "]", "\n", "finished_to_sort", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "best_states", "[", "batch_index", "]", "=", "[", "state", "[", "1", "]", "for", "state", "in", "finished_to_sort", "[", ":", "self", ".", "_beam_size", "]", "]", "\n", "", "return", "best_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.util.construct_prefix_tree": [[7, 51], ["zip", "isinstance", "targets.detach().cpu().numpy().tolist.detach().cpu().numpy().tolist", "collections.defaultdict", "enumerate", "batched_allowed_transitions.append", "targets.detach().cpu().numpy().tolist.dim", "isinstance", "target_mask.detach().cpu().numpy().tolist.detach().cpu().numpy().tolist", "enumerate", "targets.detach().cpu().numpy().tolist.detach().cpu().numpy", "allowed_transitions[].add", "target_mask.detach().cpu().numpy().tolist.detach().cpu().numpy", "targets.detach().cpu().numpy().tolist.detach().cpu", "target_mask.detach().cpu().numpy().tolist.detach().cpu", "targets.detach().cpu().numpy().tolist.detach", "target_mask.detach().cpu().numpy().tolist.detach"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["def", "construct_prefix_tree", "(", "\n", "targets", ":", "Union", "[", "torch", ".", "Tensor", ",", "List", "[", "List", "[", "List", "[", "int", "]", "]", "]", "]", ",", "\n", "target_mask", ":", "Optional", "[", "Union", "[", "torch", ".", "Tensor", ",", "List", "[", "List", "[", "List", "[", "int", "]", "]", "]", "]", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "Dict", "[", "Tuple", "[", "int", ",", "...", "]", ",", "Set", "[", "int", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    Takes a list of valid target action sequences and creates a mapping from all possible\n    (valid) action prefixes to allowed actions given that prefix.  While the method is called\n    ``construct_prefix_tree``, we're actually returning a map that has as keys the paths to\n    `all internal nodes of the trie`, and as values all of the outgoing edges from that node.\n\n    ``targets`` is assumed to be a tensor of shape ``(batch_size, num_valid_sequences,\n    sequence_length)``.  If the mask is not ``None``, it is assumed to have the same shape, and\n    we will ignore any value in ``targets`` that has a value of ``0`` in the corresponding\n    position in the mask.  We assume that the mask has the format 1*0* for each item in\n    ``targets`` - that is, once we see our first zero, we stop processing that target.\n\n    For example, if ``targets`` is the following tensor: ``[[1, 2, 3], [1, 4, 5]]``, the return\n    value will be: ``{(): set([1]), (1,): set([2, 4]), (1, 2): set([3]), (1, 4): set([5])}``.\n\n    This could be used, e.g., to do an efficient constrained beam search, or to efficiently\n    evaluate the probability of all of the target sequences.\n    \"\"\"", "\n", "batched_allowed_transitions", ":", "List", "[", "Dict", "[", "Tuple", "[", "int", ",", "...", "]", ",", "Set", "[", "int", "]", "]", "]", "=", "[", "]", "\n", "\n", "if", "not", "isinstance", "(", "targets", ",", "list", ")", ":", "\n", "        ", "assert", "targets", ".", "dim", "(", ")", "==", "3", ",", "\"targets tensor needs to be batched!\"", "\n", "targets", "=", "targets", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "", "if", "target_mask", "is", "not", "None", ":", "\n", "        ", "if", "not", "isinstance", "(", "target_mask", ",", "list", ")", ":", "\n", "            ", "target_mask", "=", "target_mask", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "target_mask", "=", "[", "None", "for", "_", "in", "targets", "]", "\n", "\n", "", "for", "instance_targets", ",", "instance_mask", "in", "zip", "(", "targets", ",", "target_mask", ")", ":", "\n", "        ", "allowed_transitions", ":", "Dict", "[", "Tuple", "[", "int", ",", "...", "]", ",", "Set", "[", "int", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "for", "i", ",", "target_sequence", "in", "enumerate", "(", "instance_targets", ")", ":", "\n", "            ", "history", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", ")", "\n", "for", "j", ",", "action", "in", "enumerate", "(", "target_sequence", ")", ":", "\n", "                ", "if", "instance_mask", "and", "instance_mask", "[", "i", "]", "[", "j", "]", "==", "0", ":", "\n", "                    ", "break", "\n", "", "allowed_transitions", "[", "history", "]", ".", "add", "(", "action", ")", "\n", "history", "=", "history", "+", "(", "action", ",", ")", "\n", "", "", "batched_allowed_transitions", ".", "append", "(", "allowed_transitions", ")", "\n", "", "return", "batched_allowed_transitions", "\n", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.util_test.TestStateMachinesUtil.test_create_allowed_transitions": [[9, 36], ["torch.Tensor", "torch.Tensor", "allennlp_semparse.state_machines.util.construct_prefix_tree", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.util.construct_prefix_tree"], ["    ", "def", "test_create_allowed_transitions", "(", "self", ")", ":", "\n", "        ", "targets", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "2", ",", "3", ",", "4", "]", ",", "[", "1", ",", "3", ",", "4", "]", ",", "[", "1", ",", "2", ",", "4", "]", "]", ",", "[", "[", "3", ",", "4", ",", "0", "]", ",", "[", "2", ",", "3", ",", "4", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", "]", "\n", ")", "\n", "target_mask", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ",", "[", "[", "1", ",", "1", ",", "0", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", "]", "\n", ")", "\n", "prefix_tree", "=", "util", ".", "construct_prefix_tree", "(", "targets", ",", "target_mask", ")", "\n", "\n", "# There were two instances in this batch.", "\n", "assert", "len", "(", "prefix_tree", ")", "==", "2", "\n", "\n", "# The first instance had six valid action sequence prefixes.", "\n", "assert", "len", "(", "prefix_tree", "[", "0", "]", ")", "==", "6", "\n", "assert", "prefix_tree", "[", "0", "]", "[", "(", ")", "]", "==", "{", "1", ",", "2", "}", "\n", "assert", "prefix_tree", "[", "0", "]", "[", "(", "1", ",", ")", "]", "==", "{", "2", ",", "3", "}", "\n", "assert", "prefix_tree", "[", "0", "]", "[", "(", "1", ",", "2", ")", "]", "==", "{", "4", "}", "\n", "assert", "prefix_tree", "[", "0", "]", "[", "(", "1", ",", "3", ")", "]", "==", "{", "4", "}", "\n", "assert", "prefix_tree", "[", "0", "]", "[", "(", "2", ",", ")", "]", "==", "{", "3", "}", "\n", "assert", "prefix_tree", "[", "0", "]", "[", "(", "2", ",", "3", ")", "]", "==", "{", "4", "}", "\n", "\n", "# The second instance had four valid action sequence prefixes.", "\n", "assert", "len", "(", "prefix_tree", "[", "1", "]", ")", "==", "4", "\n", "assert", "prefix_tree", "[", "1", "]", "[", "(", ")", "]", "==", "{", "2", ",", "3", "}", "\n", "assert", "prefix_tree", "[", "1", "]", "[", "(", "2", ",", ")", "]", "==", "{", "3", "}", "\n", "assert", "prefix_tree", "[", "1", "]", "[", "(", "2", ",", "3", ")", "]", "==", "{", "4", "}", "\n", "assert", "prefix_tree", "[", "1", "]", "[", "(", "3", ",", ")", "]", "==", "{", "4", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.beam_search_test.TestBeamSearch.test_search": [[11, 44], ["allennlp_semparse.state_machines.BeamSearch.from_params", "simple_transition_system.SimpleState", "simple_transition_system.SimpleTransitionFunction", "allennlp_semparse.state_machines.BeamSearch.from_params.search", "allennlp_semparse.state_machines.BeamSearch.from_params.search", "allennlp.common.Params", "len", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search"], ["    ", "def", "test_search", "(", "self", ")", ":", "\n", "        ", "beam_search", "=", "BeamSearch", ".", "from_params", "(", "Params", "(", "{", "\"beam_size\"", ":", "4", "}", ")", ")", "\n", "initial_state", "=", "SimpleState", "(", "\n", "[", "0", ",", "1", ",", "2", ",", "3", "]", ",", "\n", "[", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "]", ",", "\n", "[", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "]", ",", "\n", "[", "-", "3", ",", "1", ",", "-", "20", ",", "5", "]", ",", "\n", ")", "\n", "decoder_step", "=", "SimpleTransitionFunction", "(", "include_value_in_score", "=", "True", ")", "\n", "best_states", "=", "beam_search", ".", "search", "(", "\n", "5", ",", "initial_state", ",", "decoder_step", ",", "keep_final_unfinished_states", "=", "False", "\n", ")", "\n", "\n", "# Instance with batch index 2 needed too many steps to finish, and batch index 3 had no", "\n", "# path to get to a finished state.  (See the simple transition system definition; goal is", "\n", "# to end up at 4, actions are either add one or two to starting value.)", "\n", "assert", "len", "(", "best_states", ")", "==", "2", "\n", "assert", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "1", ",", "1", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "1", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "3", ",", "4", "]", "\n", "\n", "best_states", "=", "beam_search", ".", "search", "(", "\n", "5", ",", "initial_state", ",", "decoder_step", ",", "keep_final_unfinished_states", "=", "True", "\n", ")", "\n", "\n", "# Now we're keeping final unfinished states, which allows a \"best state\" for the instances", "\n", "# that didn't have one before.  Our previous best states for the instances that finish", "\n", "# doesn't change, because the score for taking another step is always negative at these", "\n", "# values.", "\n", "assert", "len", "(", "best_states", ")", "==", "4", "\n", "assert", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "1", ",", "1", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "1", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "2", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "18", ",", "-", "16", ",", "-", "14", ",", "-", "12", ",", "-", "10", "]", "\n", "assert", "best_states", "[", "3", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "7", ",", "9", ",", "11", ",", "13", ",", "15", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.beam_search_test.TestBeamSearch.test_constraints": [[45, 99], ["simple_transition_system.SimpleState", "torch.Tensor", "allennlp_semparse.state_machines.BeamSearch", "simple_transition_system.SimpleTransitionFunction", "allennlp_semparse.state_machines.BeamSearch.search", "allennlp_semparse.state_machines.BeamSearch", "simple_transition_system.SimpleTransitionFunction", "allennlp_semparse.state_machines.BeamSearch.search", "beam_snapshots.get", "enumerate", "len", "len", "len", "len", "all", "torch.Tensor", "len", "any", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search"], ["", "def", "test_constraints", "(", "self", ")", ":", "\n", "# The simple transition system starts at some number, adds one or two at each state, and", "\n", "# tries to get to 4.  The highest scoring path has the shortest length and the highest", "\n", "# numbers (so always add two, unless you're at 3).  From -3, there are lots of possible", "\n", "# sequences: [-2, -1, 0, 1, 2, 3, 4], [-1, 1, 3, 4], ...  We'll specify a few of those up", "\n", "# front as \"allowed\", and use that to test the constrained beam search implementation.", "\n", "        ", "initial_state", "=", "SimpleState", "(", "[", "0", "]", ",", "[", "[", "]", "]", ",", "[", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "]", ",", "[", "-", "3", "]", ")", "\n", "beam_size", "=", "3", "\n", "initial_sequence", "=", "torch", ".", "Tensor", "(", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", "]", ")", "\n", "beam_search", "=", "BeamSearch", "(", "beam_size", ",", "initial_sequence", "=", "initial_sequence", ")", "\n", "\n", "decoder_step", "=", "SimpleTransitionFunction", "(", "include_value_in_score", "=", "True", ")", "\n", "best_states", "=", "beam_search", ".", "search", "(", "7", ",", "initial_state", ",", "decoder_step", ")", "\n", "\n", "assert", "len", "(", "best_states", ")", "==", "1", "\n", "\n", "# After the constraint runs out, we generate [3], [2],", "\n", "# then we generate [3, 5], [3, 4], [2, 4], the latter two of which are finished,", "\n", "# then we generate [3, 5, 7], [3, 5, 6], and we're out of steps, so we keep the former", "\n", "assert", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "1", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "2", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "3", ",", "5", ",", "7", "]", "\n", "\n", "# Now set the beam size to 6, we generate [3], [2]", "\n", "# then [3, 5], [2, 3], [3, 4], [2, 4] (the latter two of which are finished)", "\n", "# then [3, 5, 6], [3, 5, 7], [2, 3, 5], [2, 3, 4] (the last is finished)", "\n", "beam_size", "=", "6", "\n", "beam_search", "=", "BeamSearch", "(", "\n", "beam_size", ",", "initial_sequence", "=", "initial_sequence", ",", "keep_beam_details", "=", "True", "\n", ")", "\n", "decoder_step", "=", "SimpleTransitionFunction", "(", "include_value_in_score", "=", "True", ")", "\n", "best_states", "=", "beam_search", ".", "search", "(", "\n", "7", ",", "initial_state", ",", "decoder_step", ",", "keep_final_unfinished_states", "=", "False", "\n", ")", "\n", "\n", "assert", "len", "(", "best_states", ")", "==", "1", "\n", "assert", "len", "(", "best_states", "[", "0", "]", ")", "==", "3", "\n", "assert", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "1", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "2", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "\n", "# Check that beams are correct", "\n", "best_action_sequence", "=", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "\n", "\n", "beam_snapshots", "=", "beam_search", ".", "beam_snapshots", "\n", "assert", "len", "(", "beam_snapshots", ")", "==", "1", "\n", "\n", "beam_snapshots0", "=", "beam_snapshots", ".", "get", "(", "0", ")", "\n", "assert", "beam_snapshots0", "is", "not", "None", "\n", "\n", "for", "i", ",", "beam", "in", "enumerate", "(", "beam_snapshots0", ")", ":", "\n", "            ", "assert", "all", "(", "len", "(", "sequence", ")", "==", "i", "+", "1", "for", "_", ",", "sequence", "in", "beam", ")", "\n", "if", "i", "<", "len", "(", "best_action_sequence", ")", ":", "\n", "                ", "assert", "any", "(", "sequence", "[", "-", "1", "]", "==", "best_action_sequence", "[", "i", "]", "for", "_", ",", "sequence", "in", "beam", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.simple_transition_system.SimpleState.__init__": [[19, 28], ["super().__init__", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "batch_indices", ":", "List", "[", "int", "]", ",", "\n", "action_history", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "score", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "start_values", ":", "List", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "batch_indices", ",", "action_history", ",", "score", ")", "\n", "self", ".", "start_values", "=", "start_values", "or", "[", "0", "]", "*", "len", "(", "batch_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.simple_transition_system.SimpleState.is_finished": [[29, 31], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "action_history", "[", "0", "]", "[", "-", "1", "]", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.simple_transition_system.SimpleState.combine_states": [[32, 41], ["simple_transition_system.SimpleState"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "combine_states", "(", "cls", ",", "states", ")", "->", "\"SimpleState\"", ":", "\n", "        ", "batch_indices", "=", "[", "batch_index", "for", "state", "in", "states", "for", "batch_index", "in", "state", ".", "batch_indices", "]", "\n", "action_histories", "=", "[", "\n", "action_history", "for", "state", "in", "states", "for", "action_history", "in", "state", ".", "action_history", "\n", "]", "\n", "scores", "=", "[", "score", "for", "state", "in", "states", "for", "score", "in", "state", ".", "score", "]", "\n", "start_values", "=", "[", "start_value", "for", "state", "in", "states", "for", "start_value", "in", "state", ".", "start_values", "]", "\n", "return", "SimpleState", "(", "batch_indices", ",", "action_histories", ",", "scores", ",", "start_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.simple_transition_system.SimpleState.__repr__": [[42, 44], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.action_history}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.simple_transition_system.SimpleTransitionFunction.__init__": [[47, 55], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "valid_actions", ":", "Set", "[", "int", "]", "=", "None", ",", "include_value_in_score", ":", "bool", "=", "False", "\n", ")", "->", "None", ":", "\n", "# The default allowed actions are adding 1 or 2 to the last element.", "\n", "        ", "self", ".", "_valid_actions", "=", "valid_actions", "or", "{", "1", ",", "2", "}", "\n", "# If True, we will add a small multiple of the action take to the score, to encourage", "\n", "# getting higher numbers first (and to differentiate action sequences).", "\n", "self", ".", "_include_value_in_score", "=", "include_value_in_score", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.simple_transition_system.SimpleTransitionFunction.take_step": [[56, 91], ["collections.defaultdict", "zip", "indexed_next_states.values", "sorted_next_states.sort", "next_states.extend", "len", "int", "simple_transition_system.SimpleState", "indexed_next_states[].append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "take_step", "(", "\n", "self", ",", "state", ":", "SimpleState", ",", "max_actions", ":", "int", "=", "None", ",", "allowed_actions", ":", "List", "[", "Set", "]", "=", "None", "\n", ")", "->", "List", "[", "SimpleState", "]", ":", "\n", "        ", "indexed_next_states", ":", "Dict", "[", "int", ",", "List", "[", "SimpleState", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "if", "not", "allowed_actions", ":", "\n", "            ", "allowed_actions", "=", "[", "None", "]", "*", "len", "(", "state", ".", "batch_indices", ")", "\n", "", "for", "batch_index", ",", "action_history", ",", "score", ",", "start_value", ",", "actions", "in", "zip", "(", "\n", "state", ".", "batch_indices", ",", "\n", "state", ".", "action_history", ",", "\n", "state", ".", "score", ",", "\n", "state", ".", "start_values", ",", "\n", "allowed_actions", ",", "\n", ")", ":", "\n", "\n", "            ", "prev_action", "=", "action_history", "[", "-", "1", "]", "if", "action_history", "else", "start_value", "\n", "for", "action", "in", "self", ".", "_valid_actions", ":", "\n", "                ", "next_item", "=", "int", "(", "prev_action", "+", "action", ")", "\n", "if", "actions", "and", "next_item", "not", "in", "actions", ":", "\n", "                    ", "continue", "\n", "", "new_history", "=", "action_history", "+", "[", "next_item", "]", "\n", "# For every action taken, we reduce the score by 1.", "\n", "new_score", "=", "score", "-", "1", "\n", "if", "self", ".", "_include_value_in_score", ":", "\n", "                    ", "new_score", "+=", "0.01", "*", "next_item", "\n", "", "new_state", "=", "SimpleState", "(", "[", "batch_index", "]", ",", "[", "new_history", "]", ",", "[", "new_score", "]", ")", "\n", "indexed_next_states", "[", "batch_index", "]", ".", "append", "(", "new_state", ")", "\n", "", "", "next_states", ":", "List", "[", "SimpleState", "]", "=", "[", "]", "\n", "for", "batch_next_states", "in", "indexed_next_states", ".", "values", "(", ")", ":", "\n", "            ", "sorted_next_states", "=", "[", "(", "-", "state", ".", "score", "[", "0", "]", ".", "data", "[", "0", "]", ",", "state", ")", "for", "state", "in", "batch_next_states", "]", "\n", "sorted_next_states", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "if", "max_actions", "is", "not", "None", ":", "\n", "                ", "sorted_next_states", "=", "sorted_next_states", "[", ":", "max_actions", "]", "\n", "", "next_states", ".", "extend", "(", "state", "[", "1", "]", "for", "state", "in", "sorted_next_states", ")", "\n", "", "return", "next_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search_test.TestConstrainedBeamSearch.test_search": [[10, 67], ["simple_transition_system.SimpleState", "torch.Tensor", "torch.Tensor", "allennlp_semparse.state_machines.ConstrainedBeamSearch", "simple_transition_system.SimpleTransitionFunction", "allennlp_semparse.state_machines.ConstrainedBeamSearch.search", "allennlp_semparse.state_machines.ConstrainedBeamSearch", "simple_transition_system.SimpleTransitionFunction", "allennlp_semparse.state_machines.ConstrainedBeamSearch.search", "len", "len", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search"], ["    ", "def", "test_search", "(", "self", ")", ":", "\n", "# The simple transition system starts at some number, adds one or two at each state, and", "\n", "# tries to get to 4.  The highest scoring path has the shortest length and the highest", "\n", "# numbers (so always add two, unless you're at 3).  From -3, there are lots of possible", "\n", "# sequences: [-2, -1, 0, 1, 2, 3, 4], [-1, 1, 3, 4], ...  We'll specify a few of those up", "\n", "# front as \"allowed\", and use that to test the constrained beam search implementation.", "\n", "        ", "initial_state", "=", "SimpleState", "(", "[", "0", "]", ",", "[", "[", "]", "]", ",", "[", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "]", ",", "[", "-", "3", "]", ")", "\n", "beam_size", "=", "3", "\n", "allowed_sequences", "=", "torch", ".", "Tensor", "(", "\n", "[", "\n", "[", "\n", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "\n", "[", "-", "2", ",", "0", ",", "2", ",", "4", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "1", ",", "3", ",", "4", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "4", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "1", ",", "2", ",", "3", ",", "4", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "]", "\n", "]", "\n", ")", "\n", "mask", "=", "torch", ".", "Tensor", "(", "\n", "[", "\n", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "]", "\n", "]", "\n", ")", "\n", "\n", "beam_search", "=", "ConstrainedBeamSearch", "(", "beam_size", ",", "allowed_sequences", ",", "mask", ")", "\n", "\n", "# Including the value in the score will make us pick states that have higher numbers first.", "\n", "# So with a beam size of 3, we'll get all of the states that start with `-1` after the", "\n", "# first step, even though in the end one of the states that starts with `-2` is better than", "\n", "# two of the states that start with `-1`.", "\n", "decoder_step", "=", "SimpleTransitionFunction", "(", "include_value_in_score", "=", "True", ")", "\n", "best_states", "=", "beam_search", ".", "search", "(", "initial_state", ",", "decoder_step", ")", "\n", "\n", "assert", "len", "(", "best_states", ")", "==", "1", "\n", "assert", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "1", ",", "1", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "1", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "1", ",", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "2", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "\n", "# With a beam size of 6, we should get the other allowed path of length 4 as the second", "\n", "# best result.", "\n", "beam_size", "=", "6", "\n", "beam_search", "=", "ConstrainedBeamSearch", "(", "beam_size", ",", "allowed_sequences", ",", "mask", ")", "\n", "decoder_step", "=", "SimpleTransitionFunction", "(", "include_value_in_score", "=", "True", ")", "\n", "best_states", "=", "beam_search", ".", "search", "(", "initial_state", ",", "decoder_step", ")", "\n", "\n", "assert", "len", "(", "best_states", ")", "==", "1", "\n", "assert", "best_states", "[", "0", "]", "[", "0", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "1", ",", "1", ",", "3", ",", "4", "]", "\n", "assert", "best_states", "[", "0", "]", "[", "1", "]", ".", "action_history", "[", "0", "]", "==", "[", "-", "2", ",", "0", ",", "2", ",", "4", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.transition_function.TransitionFunction.forward": [[24, 26], ["RuntimeError"], "methods", ["None"], ["def", "forward", "(", "self", ",", "*", "inputs", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"call .take_step() instead of .forward()\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.transition_function.TransitionFunction.take_step": [[27, 86], ["None"], "methods", ["None"], ["", "def", "take_step", "(", "\n", "self", ",", "state", ":", "StateType", ",", "max_actions", ":", "int", "=", "None", ",", "allowed_actions", ":", "List", "[", "Set", "]", "=", "None", "\n", ")", "->", "List", "[", "StateType", "]", ":", "\n", "        ", "\"\"\"\n        The main method in the ``TransitionFunction`` API.  This function defines the computation\n        done at each step of decoding and returns a ranked list of next states.\n\n        The input state is `grouped`, to allow for efficient computation, but the output states\n        should all have a ``group_size`` of 1, to make things easier on the decoding algorithm.\n        They will get regrouped later as needed.\n\n        Because of the way we handle grouping in the decoder states, constructing a new state is\n        actually a relatively expensive operation.  If you know a priori that only some of the\n        states will be needed (either because you have a set of gold action sequences, or you have\n        a fixed beam size), passing that information into this function will keep us from\n        constructing more states than we need, which will greatly speed up your computation.\n\n        IMPORTANT: This method `must` returns states already sorted by their score, otherwise\n        ``BeamSearch`` and other methods will break.  For efficiency, we do not perform an\n        additional sort in those methods.\n\n        ALSO IMPORTANT: When ``allowed_actions`` is given and ``max_actions`` is not, we assume you\n        want to evaluate all possible states and do not need any sorting (e.g., this is true for\n        maximum marginal likelihood training that does not use a beam search).  In this case, we\n        may skip the sorting step for efficiency reasons.\n\n        Parameters\n        ----------\n        state : ``State``\n            The current state of the decoder, which we will take a step `from`.  We may be grouping\n            together computation for several states here.  Because we can have several states for\n            each instance in the original batch being evaluated at the same time, we use\n            ``group_size`` for this kind of batching, and ``batch_size`` for the `original` batch\n            in ``model.forward.``\n        max_actions : ``int``, optional\n            If you know that you will only need a certain number of states out of this (e.g., in a\n            beam search), you can pass in the max number of actions that you need, and we will only\n            construct that many states (for each `batch` instance - `not` for each `group`\n            instance!).  This can save a whole lot of computation if you have an action space\n            that's much larger than your beam size.\n        allowed_actions : ``List[Set]``, optional\n            If the ``DecoderTrainer`` has constraints on which actions need to be evaluated (e.g.,\n            maximum marginal likelihood only needs to evaluate action sequences in a given set),\n            you can pass those constraints here, to avoid constructing state objects unnecessarily.\n            If there are no constraints from the trainer, passing a value of ``None`` here will\n            allow all actions to be considered.\n\n            This is a list because it is `batched` - every instance in the batch has a set of\n            allowed actions.  Note that the size of this list is the ``group_size`` in the\n            ``State``, `not` the ``batch_size`` of ``model.forward``.  The training algorithm needs\n            to convert from the `batched` allowed action sequences that it has to a `grouped`\n            allowed action sequence list.\n\n        Returns\n        -------\n        next_states : ``List[State]``\n            A list of next states, ordered by score.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.coverage_transition_function.CoverageTransitionFunction.__init__": [[44, 63], ["allennlp_semparse.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction.__init__", "torch.nn.Parameter", "allennlp.nn.Activation.by_name", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "encoder_output_dim", ":", "int", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "input_attention", ":", "Attention", ",", "\n", "activation", ":", "Activation", "=", "Activation", ".", "by_name", "(", "\"relu\"", ")", "(", ")", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "encoder_output_dim", "=", "encoder_output_dim", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "input_attention", ",", "\n", "activation", "=", "activation", ",", "\n", "add_action_bias", "=", "add_action_bias", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "# See the class docstring for a description of what this does.", "\n", "self", ".", "_checklist_multiplier", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "[", "1.0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.coverage_transition_function.CoverageTransitionFunction._compute_action_probabilities": [[64, 111], ["len", "state.get_valid_actions", "collections.defaultdict", "range", "coverage_transition_function.CoverageTransitionFunction._get_predicted_embedding_addition", "action_embeddings.mm().squeeze", "torch.nn.functional.log_softmax", "batch_results[].append", "action_embeddings.mm", "predicted_action_embedding.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.coverage_transition_function.CoverageTransitionFunction._get_predicted_embedding_addition", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "_compute_action_probabilities", "(", "# type: ignore", "\n", "self", ",", "\n", "state", ":", "CoverageState", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", ",", "\n", "attention_weights", ":", "torch", ".", "Tensor", ",", "\n", "predicted_action_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", ":", "\n", "# In this section we take our predicted action embedding and compare it to the available", "\n", "# actions in our current state (which might be different for each group element).  For", "\n", "# computing action scores, we'll forget about doing batched / grouped computation, as it", "\n", "# adds too much complexity and doesn't speed things up, anyway, with the operations we're", "\n", "# doing here.  This means we don't need any action masks, as we'll only get the right", "\n", "# lengths for what we're computing.", "\n", "\n", "        ", "group_size", "=", "len", "(", "state", ".", "batch_indices", ")", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "\n", "batch_results", ":", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "group_index", "in", "range", "(", "group_size", ")", ":", "\n", "            ", "instance_actions", "=", "actions", "[", "group_index", "]", "\n", "predicted_action_embedding", "=", "predicted_action_embeddings", "[", "group_index", "]", "\n", "action_embeddings", ",", "output_action_embeddings", ",", "action_ids", "=", "instance_actions", "[", "\"global\"", "]", "\n", "\n", "# This embedding addition the only difference between the logic here and the", "\n", "# corresponding logic in the super class.", "\n", "embedding_addition", "=", "self", ".", "_get_predicted_embedding_addition", "(", "\n", "state", ".", "checklist_state", "[", "group_index", "]", ",", "action_ids", ",", "action_embeddings", "\n", ")", "\n", "addition", "=", "embedding_addition", "*", "self", ".", "_checklist_multiplier", "\n", "predicted_action_embedding", "=", "predicted_action_embedding", "+", "addition", "\n", "\n", "# This is just a matrix product between a (num_actions, embedding_dim) matrix and an", "\n", "# (embedding_dim, 1) matrix.", "\n", "action_logits", "=", "action_embeddings", ".", "mm", "(", "predicted_action_embedding", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "\n", "-", "1", "\n", ")", "\n", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "action_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# This is now the total score for each state after taking each action.  We're going to", "\n", "# sort by this later, so it's important that this is the total score, not just the", "\n", "# score for the current action.", "\n", "log_probs", "=", "state", ".", "score", "[", "group_index", "]", "+", "current_log_probs", "\n", "batch_results", "[", "state", ".", "batch_indices", "[", "group_index", "]", "]", ".", "append", "(", "\n", "(", "group_index", ",", "log_probs", ",", "current_log_probs", ",", "output_action_embeddings", ",", "action_ids", ")", "\n", ")", "\n", "", "return", "batch_results", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.coverage_transition_function.CoverageTransitionFunction._get_predicted_embedding_addition": [[112, 160], ["checklist_state.get_balance().clamp", "checklist_state.get_balance().clamp.new().long().unsqueeze", "torch.sum", "torch.sum", "checklist_state.get_balance", "checklist_state.get_balance().clamp.new().long", "torch.sum.unsqueeze", "checklist_state.get_balance().clamp.new"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.get_balance"], ["", "def", "_get_predicted_embedding_addition", "(", "\n", "self", ",", "\n", "checklist_state", ":", "ChecklistStatelet", ",", "\n", "action_ids", ":", "List", "[", "int", "]", ",", "\n", "action_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Gets the embeddings of desired terminal actions yet to be produced by the decoder, and\n        returns their sum for the decoder to add it to the predicted embedding to bias the\n        prediction towards missing actions.\n        \"\"\"", "\n", "# Our basic approach here will be to figure out which actions we want to bias, by doing", "\n", "# some fancy indexing work, then multiply the action embeddings by a mask for those", "\n", "# actions, and return the sum of the result.", "\n", "\n", "# Shape: (num_terminal_actions, 1).  This is 1 if we still want to predict something on the", "\n", "# checklist, and 0 otherwise.", "\n", "checklist_balance", "=", "checklist_state", ".", "get_balance", "(", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "\n", "# (num_terminal_actions, 1)", "\n", "actions_in_agenda", "=", "checklist_state", ".", "terminal_actions", "\n", "# (1, num_current_actions)", "\n", "action_id_tensor", "=", "checklist_balance", ".", "new", "(", "action_ids", ")", ".", "long", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# Shape: (num_terminal_actions, num_current_actions).  Will have a value of 1 if the", "\n", "# terminal action i is our current action j, and a value of 0 otherwise.  Because both sets", "\n", "# of actions are free of duplicates, there will be at most one non-zero value per current", "\n", "# action, and per terminal action.", "\n", "current_agenda_actions", "=", "(", "actions_in_agenda", "==", "action_id_tensor", ")", ".", "float", "(", ")", "\n", "\n", "# Shape: (num_current_actions,).  With the inner multiplication, we remove any current", "\n", "# agenda actions that are not in our checklist balance, then we sum over the terminal", "\n", "# action dimension, which will have a sum of at most one.  So this will be a 0/1 tensor,", "\n", "# where a 1 means to encourage the current action in that position.", "\n", "actions_to_encourage", "=", "torch", ".", "sum", "(", "current_agenda_actions", "*", "checklist_balance", ",", "dim", "=", "0", ")", "\n", "\n", "# Shape: (action_embedding_dim,).  This is the sum of the action embeddings that we want", "\n", "# the model to prefer.", "\n", "embedding_addition", "=", "torch", ".", "sum", "(", "\n", "action_embeddings", "*", "actions_to_encourage", ".", "unsqueeze", "(", "1", ")", ",", "dim", "=", "0", ",", "keepdim", "=", "False", "\n", ")", "\n", "\n", "if", "self", ".", "_add_action_bias", ":", "\n", "# If we're adding an action bias, the last dimension of the action embedding is a bias", "\n", "# weight.  We don't want this addition to affect the bias (TODO(mattg): or do we?), so", "\n", "# we zero out that dimension here.", "\n", "            ", "embedding_addition", "[", "-", "1", "]", "=", "0", "\n", "\n", "", "return", "embedding_addition", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.linking_coverage_transition_function.LinkingCoverageTransitionFunction.__init__": [[46, 79], ["allennlp_semparse.state_machines.transition_functions.coverage_transition_function.CoverageTransitionFunction.__init__", "torch.nn.Parameter", "allennlp.nn.Activation.by_name", "torch.FloatTensor", "allennlp.common.checks.check_dimensions_match", "allennlp.common.checks.check_dimensions_match", "mixture_feedforward.get_input_dim", "mixture_feedforward.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "encoder_output_dim", ":", "int", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "input_attention", ":", "Attention", ",", "\n", "activation", ":", "Activation", "=", "Activation", ".", "by_name", "(", "\"relu\"", ")", "(", ")", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "mixture_feedforward", ":", "FeedForward", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "encoder_output_dim", "=", "encoder_output_dim", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "input_attention", ",", "\n", "activation", "=", "activation", ",", "\n", "add_action_bias", "=", "add_action_bias", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "_linked_checklist_multiplier", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "[", "1.0", "]", ")", ")", "\n", "self", ".", "_mixture_feedforward", "=", "mixture_feedforward", "\n", "\n", "if", "mixture_feedforward", "is", "not", "None", ":", "\n", "            ", "check_dimensions_match", "(", "\n", "encoder_output_dim", ",", "\n", "mixture_feedforward", ".", "get_input_dim", "(", ")", ",", "\n", "\"hidden state embedding dim\"", ",", "\n", "\"mixture feedforward input dim\"", ",", "\n", ")", "\n", "check_dimensions_match", "(", "\n", "mixture_feedforward", ".", "get_output_dim", "(", ")", ",", "\n", "1", ",", "\n", "\"mixture feedforward output dim\"", ",", "\n", "\"dimension for scalar value\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.linking_coverage_transition_function.LinkingCoverageTransitionFunction._compute_action_probabilities": [[81, 193], ["len", "state.get_valid_actions", "collections.defaultdict", "range", "batch_results[].append", "linking_coverage_transition_function.LinkingCoverageTransitionFunction._get_predicted_embedding_addition", "action_embeddings.mm().squeeze", "linking_scores.mm().squeeze", "linking_coverage_transition_function.LinkingCoverageTransitionFunction._get_linked_logits_addition", "torch.nn.functional.log_softmax", "torch.cat", "linking_coverage_transition_function.LinkingCoverageTransitionFunction._mixture_feedforward", "torch.log", "torch.log", "action_embeddings.mm", "linking_scores.mm", "torch.nn.functional.log_softmax", "torch.cat", "torch.nn.functional.log_softmax", "torch.cat", "torch.nn.functional.log_softmax", "predicted_action_embedding.unsqueeze", "attention_weights[].unsqueeze", "torch.nn.functional.log_softmax"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.coverage_transition_function.CoverageTransitionFunction._get_predicted_embedding_addition", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.linking_coverage_transition_function.LinkingCoverageTransitionFunction._get_linked_logits_addition"], ["", "", "@", "overrides", "\n", "def", "_compute_action_probabilities", "(", "# type: ignore", "\n", "self", ",", "\n", "state", ":", "CoverageState", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", ",", "\n", "attention_weights", ":", "torch", ".", "Tensor", ",", "\n", "predicted_action_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", ":", "\n", "# In this section we take our predicted action embedding and compare it to the available", "\n", "# actions in our current state (which might be different for each group element).  For", "\n", "# computing action scores, we'll forget about doing batched / grouped computation, as it", "\n", "# adds too much complexity and doesn't speed things up, anyway, with the operations we're", "\n", "# doing here.  This means we don't need any action masks, as we'll only get the right", "\n", "# lengths for what we're computing.", "\n", "\n", "        ", "group_size", "=", "len", "(", "state", ".", "batch_indices", ")", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "\n", "batch_results", ":", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "group_index", "in", "range", "(", "group_size", ")", ":", "\n", "            ", "instance_actions", "=", "actions", "[", "group_index", "]", "\n", "predicted_action_embedding", "=", "predicted_action_embeddings", "[", "group_index", "]", "\n", "action_ids", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "if", "\"global\"", "in", "instance_actions", ":", "\n", "                ", "action_embeddings", ",", "output_action_embeddings", ",", "embedded_actions", "=", "instance_actions", "[", "\n", "\"global\"", "\n", "]", "\n", "\n", "# This embedding addition the only difference between the logic here and the", "\n", "# corresponding logic in the super class.", "\n", "embedding_addition", "=", "self", ".", "_get_predicted_embedding_addition", "(", "\n", "state", ".", "checklist_state", "[", "group_index", "]", ",", "embedded_actions", ",", "action_embeddings", "\n", ")", "\n", "addition", "=", "embedding_addition", "*", "self", ".", "_checklist_multiplier", "\n", "predicted_action_embedding", "=", "predicted_action_embedding", "+", "addition", "\n", "\n", "# This is just a matrix product between a (num_actions, embedding_dim) matrix and an", "\n", "# (embedding_dim, 1) matrix.", "\n", "embedded_action_logits", "=", "action_embeddings", ".", "mm", "(", "\n", "predicted_action_embedding", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "action_ids", "+=", "embedded_actions", "\n", "", "else", ":", "\n", "                ", "embedded_action_logits", "=", "None", "\n", "output_action_embeddings", "=", "None", "\n", "\n", "", "if", "\"linked\"", "in", "instance_actions", ":", "\n", "                ", "linking_scores", ",", "type_embeddings", ",", "linked_actions", "=", "instance_actions", "[", "\"linked\"", "]", "\n", "action_ids", "+=", "linked_actions", "\n", "# (num_question_tokens, 1)", "\n", "linked_action_logits", "=", "linking_scores", ".", "mm", "(", "\n", "attention_weights", "[", "group_index", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "linked_logits_addition", "=", "self", ".", "_get_linked_logits_addition", "(", "\n", "state", ".", "checklist_state", "[", "group_index", "]", ",", "linked_actions", ",", "linked_action_logits", "\n", ")", "\n", "\n", "addition", "=", "linked_logits_addition", "*", "self", ".", "_linked_checklist_multiplier", "\n", "linked_action_logits", "=", "linked_action_logits", "+", "addition", "\n", "\n", "# The `output_action_embeddings` tensor gets used later as the input to the next", "\n", "# decoder step.  For linked actions, we don't have any action embedding, so we use", "\n", "# the entity type instead.", "\n", "if", "output_action_embeddings", "is", "None", ":", "\n", "                    ", "output_action_embeddings", "=", "type_embeddings", "\n", "", "else", ":", "\n", "                    ", "output_action_embeddings", "=", "torch", ".", "cat", "(", "\n", "[", "output_action_embeddings", ",", "type_embeddings", "]", ",", "dim", "=", "0", "\n", ")", "\n", "\n", "", "if", "self", ".", "_mixture_feedforward", "is", "not", "None", ":", "\n", "# The linked and global logits are combined with a mixture weight to prevent the", "\n", "# linked_action_logits from dominating the embedded_action_logits if a softmax", "\n", "# was applied on both together.", "\n", "                    ", "mixture_weight", "=", "self", ".", "_mixture_feedforward", "(", "hidden_state", "[", "group_index", "]", ")", "\n", "mix1", "=", "torch", ".", "log", "(", "mixture_weight", ")", "\n", "mix2", "=", "torch", ".", "log", "(", "1", "-", "mixture_weight", ")", "\n", "\n", "entity_action_probs", "=", "(", "\n", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "linked_action_logits", ",", "dim", "=", "-", "1", ")", "+", "mix1", "\n", ")", "\n", "if", "embedded_action_logits", "is", "None", ":", "\n", "                        ", "current_log_probs", "=", "entity_action_probs", "\n", "", "else", ":", "\n", "                        ", "embedded_action_probs", "=", "(", "\n", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "embedded_action_logits", ",", "dim", "=", "-", "1", ")", "+", "mix2", "\n", ")", "\n", "current_log_probs", "=", "torch", ".", "cat", "(", "\n", "[", "embedded_action_probs", ",", "entity_action_probs", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "if", "embedded_action_logits", "is", "None", ":", "\n", "                        ", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "\n", "linked_action_logits", ",", "dim", "=", "-", "1", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "action_logits", "=", "torch", ".", "cat", "(", "\n", "[", "embedded_action_logits", ",", "linked_action_logits", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "action_logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "", "else", ":", "\n", "                ", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "embedded_action_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# This is now the total score for each state after taking each action.  We're going to", "\n", "# sort by this later, so it's important that this is the total score, not just the", "\n", "# score for the current action.", "\n", "", "log_probs", "=", "state", ".", "score", "[", "group_index", "]", "+", "current_log_probs", "\n", "batch_results", "[", "state", ".", "batch_indices", "[", "group_index", "]", "]", ".", "append", "(", "\n", "(", "group_index", ",", "log_probs", ",", "current_log_probs", ",", "output_action_embeddings", ",", "action_ids", ")", "\n", ")", "\n", "", "return", "batch_results", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.linking_coverage_transition_function.LinkingCoverageTransitionFunction._get_linked_logits_addition": [[194, 231], ["checklist_state.get_balance().clamp", "checklist_state.get_balance().clamp.new().long().unsqueeze", "torch.sum", "checklist_state.get_balance", "checklist_state.get_balance().clamp.new().long", "checklist_state.get_balance().clamp.new"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.get_balance"], ["", "@", "staticmethod", "\n", "def", "_get_linked_logits_addition", "(", "\n", "checklist_state", ":", "ChecklistStatelet", ",", "action_ids", ":", "List", "[", "int", "]", ",", "action_logits", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Gets the logits of desired terminal actions yet to be produced by the decoder, and\n        returns them for the decoder to add to the prior action logits, biasing the model towards\n        predicting missing linked actions.\n        \"\"\"", "\n", "# Our basic approach here will be to figure out which actions we want to bias, by doing", "\n", "# some fancy indexing work, then multiply the action embeddings by a mask for those", "\n", "# actions, and return the sum of the result.", "\n", "\n", "# Shape: (num_terminal_actions, 1).  This is 1 if we still want to predict something on the", "\n", "# checklist, and 0 otherwise.", "\n", "checklist_balance", "=", "checklist_state", ".", "get_balance", "(", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "\n", "# (num_terminal_actions, 1)", "\n", "actions_in_agenda", "=", "checklist_state", ".", "terminal_actions", "\n", "# (1, num_current_actions)", "\n", "action_id_tensor", "=", "checklist_balance", ".", "new", "(", "action_ids", ")", ".", "long", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# Shape: (num_terminal_actions, num_current_actions).  Will have a value of 1 if the", "\n", "# terminal action i is our current action j, and a value of 0 otherwise.  Because both sets", "\n", "# of actions are free of duplicates, there will be at most one non-zero value per current", "\n", "# action, and per terminal action.", "\n", "current_agenda_actions", "=", "(", "actions_in_agenda", "==", "action_id_tensor", ")", ".", "float", "(", ")", "\n", "\n", "# Shape: (num_current_actions,).  With the inner multiplication, we remove any current", "\n", "# agenda actions that are not in our checklist balance, then we sum over the terminal", "\n", "# action dimension, which will have a sum of at most one.  So this will be a 0/1 tensor,", "\n", "# where a 1 means to encourage the current action in that position.", "\n", "actions_to_encourage", "=", "torch", ".", "sum", "(", "current_agenda_actions", "*", "checklist_balance", ",", "dim", "=", "0", ")", "\n", "\n", "# Shape: (num_current_actions,).  This is the sum of the action embeddings that we want", "\n", "# the model to prefer.", "\n", "logit_addition", "=", "action_logits", "*", "actions_to_encourage", "\n", "return", "logit_addition", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.linking_transition_function.LinkingTransitionFunction.__init__": [[53, 87], ["allennlp_semparse.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction.__init__", "allennlp.nn.Activation.by_name", "allennlp.common.checks.check_dimensions_match", "allennlp.common.checks.check_dimensions_match", "mixture_feedforward.get_input_dim", "mixture_feedforward.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "encoder_output_dim", ":", "int", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "input_attention", ":", "Attention", ",", "\n", "activation", ":", "Activation", "=", "Activation", ".", "by_name", "(", "\"relu\"", ")", "(", ")", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "mixture_feedforward", ":", "FeedForward", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "num_layers", ":", "int", "=", "1", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "encoder_output_dim", "=", "encoder_output_dim", ",", "\n", "action_embedding_dim", "=", "action_embedding_dim", ",", "\n", "input_attention", "=", "input_attention", ",", "\n", "activation", "=", "activation", ",", "\n", "add_action_bias", "=", "add_action_bias", ",", "\n", "dropout", "=", "dropout", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", ")", "\n", "self", ".", "_mixture_feedforward", "=", "mixture_feedforward", "\n", "\n", "if", "mixture_feedforward", "is", "not", "None", ":", "\n", "            ", "check_dimensions_match", "(", "\n", "encoder_output_dim", ",", "\n", "mixture_feedforward", ".", "get_input_dim", "(", ")", ",", "\n", "\"hidden state embedding dim\"", ",", "\n", "\"mixture feedforward input dim\"", ",", "\n", ")", "\n", "check_dimensions_match", "(", "\n", "mixture_feedforward", ".", "get_output_dim", "(", ")", ",", "\n", "1", ",", "\n", "\"mixture feedforward output dim\"", ",", "\n", "\"dimension for scalar value\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.linking_transition_function.LinkingTransitionFunction._compute_action_probabilities": [[89, 187], ["len", "state.get_valid_actions", "collections.defaultdict", "range", "batch_results[].append", "action_embeddings.mm().squeeze", "linking_scores.mm().squeeze", "torch.nn.functional.log_softmax", "torch.cat", "linking_transition_function.LinkingTransitionFunction._mixture_feedforward", "torch.log", "torch.log", "torch.nn.functional.log_softmax", "action_embeddings.mm", "linking_scores.mm", "torch.nn.functional.log_softmax", "torch.cat", "torch.cat", "predicted_action_embedding.unsqueeze", "attention_weights[].unsqueeze", "torch.nn.functional.log_softmax"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "", "@", "overrides", "\n", "def", "_compute_action_probabilities", "(", "\n", "self", ",", "\n", "state", ":", "GrammarBasedState", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", ",", "\n", "attention_weights", ":", "torch", ".", "Tensor", ",", "\n", "predicted_action_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", ":", "\n", "# In this section we take our predicted action embedding and compare it to the available", "\n", "# actions in our current state (which might be different for each group element).  For", "\n", "# computing action scores, we'll forget about doing batched / grouped computation, as it", "\n", "# adds too much complexity and doesn't speed things up, anyway, with the operations we're", "\n", "# doing here.  This means we don't need any action masks, as we'll only get the right", "\n", "# lengths for what we're computing.", "\n", "\n", "        ", "group_size", "=", "len", "(", "state", ".", "batch_indices", ")", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "\n", "batch_results", ":", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "group_index", "in", "range", "(", "group_size", ")", ":", "\n", "            ", "instance_actions", "=", "actions", "[", "group_index", "]", "\n", "predicted_action_embedding", "=", "predicted_action_embeddings", "[", "group_index", "]", "\n", "embedded_actions", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\n", "output_action_embeddings", "=", "None", "\n", "embedded_action_logits", "=", "None", "\n", "current_log_probs", "=", "None", "\n", "\n", "if", "\"global\"", "in", "instance_actions", ":", "\n", "                ", "action_embeddings", ",", "output_action_embeddings", ",", "embedded_actions", "=", "instance_actions", "[", "\n", "\"global\"", "\n", "]", "\n", "# This is just a matrix product between a (num_actions, embedding_dim) matrix and an", "\n", "# (embedding_dim, 1) matrix.", "\n", "embedded_action_logits", "=", "action_embeddings", ".", "mm", "(", "\n", "predicted_action_embedding", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "action_ids", "=", "embedded_actions", "\n", "\n", "", "if", "\"linked\"", "in", "instance_actions", ":", "\n", "                ", "linking_scores", ",", "type_embeddings", ",", "linked_actions", "=", "instance_actions", "[", "\"linked\"", "]", "\n", "action_ids", "=", "embedded_actions", "+", "linked_actions", "\n", "# linking_scores: (num_entities, num_question_tokens)", "\n", "# linked_action_logits: (num_entities, 1)", "\n", "linked_action_logits", "=", "linking_scores", ".", "mm", "(", "\n", "attention_weights", "[", "group_index", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# The `output_action_embeddings` tensor gets used later as the input to the next", "\n", "# decoder step.  For linked actions, we don't have any action embedding, so we use", "\n", "# the entity type instead.", "\n", "if", "output_action_embeddings", "is", "not", "None", ":", "\n", "                    ", "output_action_embeddings", "=", "torch", ".", "cat", "(", "\n", "[", "output_action_embeddings", ",", "type_embeddings", "]", ",", "dim", "=", "0", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "output_action_embeddings", "=", "type_embeddings", "\n", "\n", "", "if", "self", ".", "_mixture_feedforward", "is", "not", "None", ":", "\n", "# The linked and global logits are combined with a mixture weight to prevent the", "\n", "# linked_action_logits from dominating the embedded_action_logits if a softmax", "\n", "# was applied on both together.", "\n", "                    ", "mixture_weight", "=", "self", ".", "_mixture_feedforward", "(", "hidden_state", "[", "group_index", "]", ")", "\n", "mix1", "=", "torch", ".", "log", "(", "mixture_weight", ")", "\n", "mix2", "=", "torch", ".", "log", "(", "1", "-", "mixture_weight", ")", "\n", "\n", "entity_action_probs", "=", "(", "\n", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "linked_action_logits", ",", "dim", "=", "-", "1", ")", "+", "mix1", "\n", ")", "\n", "if", "embedded_action_logits", "is", "not", "None", ":", "\n", "                        ", "embedded_action_probs", "=", "(", "\n", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "embedded_action_logits", ",", "dim", "=", "-", "1", ")", "+", "mix2", "\n", ")", "\n", "current_log_probs", "=", "torch", ".", "cat", "(", "\n", "[", "embedded_action_probs", ",", "entity_action_probs", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "current_log_probs", "=", "entity_action_probs", "\n", "", "", "else", ":", "\n", "                    ", "if", "embedded_action_logits", "is", "not", "None", ":", "\n", "                        ", "action_logits", "=", "torch", ".", "cat", "(", "\n", "[", "embedded_action_logits", ",", "linked_action_logits", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "action_logits", "=", "linked_action_logits", "\n", "", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "action_logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "action_logits", "=", "embedded_action_logits", "\n", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "action_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# This is now the total score for each state after taking each action.  We're going to", "\n", "# sort by this later, so it's important that this is the total score, not just the", "\n", "# score for the current action.", "\n", "", "log_probs", "=", "state", ".", "score", "[", "group_index", "]", "+", "current_log_probs", "\n", "batch_results", "[", "state", ".", "batch_indices", "[", "group_index", "]", "]", ".", "append", "(", "\n", "(", "group_index", ",", "log_probs", ",", "current_log_probs", ",", "output_action_embeddings", ",", "action_ids", ")", "\n", ")", "\n", "", "return", "batch_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.__init__": [[49, 91], ["super().__init__", "torch.nn.modules.linear.Linear", "torch.nn.modules.linear.Linear", "allennlp.nn.Activation.by_name", "torch.nn.modules.rnn.LSTM", "torch.nn.modules.rnn.LSTMCell", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "encoder_output_dim", ":", "int", ",", "\n", "action_embedding_dim", ":", "int", ",", "\n", "input_attention", ":", "Attention", ",", "\n", "activation", ":", "Activation", "=", "Activation", ".", "by_name", "(", "\"relu\"", ")", "(", ")", ",", "\n", "add_action_bias", ":", "bool", "=", "True", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "num_layers", ":", "int", "=", "1", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_input_attention", "=", "input_attention", "\n", "self", ".", "_add_action_bias", "=", "add_action_bias", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_num_layers", "=", "num_layers", "\n", "\n", "# Decoder output dim needs to be the same as the encoder output dim since we initialize the", "\n", "# hidden state of the decoder with the final hidden state of the encoder.", "\n", "output_dim", "=", "encoder_output_dim", "\n", "input_dim", "=", "output_dim", "\n", "# Our decoder input will be the concatenation of the attended encoder hidden state (i.e.,", "\n", "# the attended question encoding) and the previous action embedding, and we'll project that", "\n", "# down to the decoder's `input_dim`, which we arbitrarily set to be the same as", "\n", "# `output_dim`.", "\n", "self", ".", "_input_projection_layer", "=", "Linear", "(", "encoder_output_dim", "+", "action_embedding_dim", ",", "input_dim", ")", "\n", "# Before making a prediction, we'll compute an attention over the input given our updated", "\n", "# hidden state. Then we concatenate those with the decoder state and project to", "\n", "# `action_embedding_dim` to make a prediction.", "\n", "self", ".", "_output_projection_layer", "=", "Linear", "(", "\n", "output_dim", "+", "encoder_output_dim", ",", "action_embedding_dim", "\n", ")", "\n", "if", "self", ".", "_num_layers", ">", "1", ":", "\n", "            ", "self", ".", "_decoder_cell", "=", "LSTM", "(", "input_dim", ",", "output_dim", ",", "self", ".", "_num_layers", ")", "\n", "", "else", ":", "\n", "# We use a ``LSTMCell`` if we just have one layer because it is slightly faster since we are", "\n", "# just running the LSTM for one step each time.", "\n", "            ", "self", ".", "_decoder_cell", "=", "LSTMCell", "(", "input_dim", ",", "output_dim", ")", "\n", "\n", "", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dropout", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.take_step": [[92, 118], ["basic_transition_function.BasicTransitionFunction._update_decoder_state", "basic_transition_function.BasicTransitionFunction._compute_action_probabilities", "basic_transition_function.BasicTransitionFunction._construct_next_states"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction._update_decoder_state", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction._compute_action_probabilities", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction._construct_next_states"], ["", "", "@", "overrides", "\n", "def", "take_step", "(", "\n", "self", ",", "\n", "state", ":", "GrammarBasedState", ",", "\n", "max_actions", ":", "int", "=", "None", ",", "\n", "allowed_actions", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "GrammarBasedState", "]", ":", "\n", "# Taking a step in the decoder consists of three main parts.  First, we'll construct the", "\n", "# input to the decoder and update the decoder's hidden state.  Second, we'll use this new", "\n", "# hidden state (and maybe other information) to predict an action.  Finally, we will", "\n", "# construct new states for the next step.  Each new state corresponds to one valid action", "\n", "# that can be taken from the current state, and they are ordered by their probability of", "\n", "# being selected.", "\n", "\n", "        ", "updated_state", "=", "self", ".", "_update_decoder_state", "(", "state", ")", "\n", "batch_results", "=", "self", ".", "_compute_action_probabilities", "(", "\n", "state", ",", "\n", "updated_state", "[", "\"hidden_state\"", "]", ",", "\n", "updated_state", "[", "\"attention_weights\"", "]", ",", "\n", "updated_state", "[", "\"predicted_action_embeddings\"", "]", ",", "\n", ")", "\n", "new_states", "=", "self", ".", "_construct_next_states", "(", "\n", "state", ",", "updated_state", ",", "batch_results", ",", "max_actions", ",", "allowed_actions", "\n", ")", "\n", "\n", "return", "new_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction._update_decoder_state": [[119, 186], ["len", "torch.stack", "torch.stack", "basic_transition_function.BasicTransitionFunction._input_projection_layer", "basic_transition_function.BasicTransitionFunction._activation", "basic_transition_function.BasicTransitionFunction._dropout", "torch.stack", "torch.stack", "basic_transition_function.BasicTransitionFunction._activation", "basic_transition_function.BasicTransitionFunction._dropout", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "basic_transition_function.BasicTransitionFunction._decoder_cell", "basic_transition_function.BasicTransitionFunction._decoder_cell", "basic_transition_function.BasicTransitionFunction.attend_on_question", "torch.cat", "basic_transition_function.BasicTransitionFunction.attend_on_question", "torch.cat", "basic_transition_function.BasicTransitionFunction._output_projection_layer", "torch.cat.new", "torch.cat", "basic_transition_function.BasicTransitionFunction.unsqueeze", "range"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.attend_on_question", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.attend_on_question"], ["", "def", "_update_decoder_state", "(", "self", ",", "state", ":", "GrammarBasedState", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# For updating the decoder, we're doing a bunch of tensor operations that can be batched", "\n", "# without much difficulty.  So, we take all group elements and batch their tensors together", "\n", "# before doing these decoder operations.", "\n", "\n", "        ", "group_size", "=", "len", "(", "state", ".", "batch_indices", ")", "\n", "attended_question", "=", "torch", ".", "stack", "(", "[", "rnn_state", ".", "attended_input", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", ")", "\n", "if", "self", ".", "_num_layers", ">", "1", ":", "\n", "            ", "hidden_state", "=", "torch", ".", "stack", "(", "[", "rnn_state", ".", "hidden_state", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", ",", "1", ")", "\n", "memory_cell", "=", "torch", ".", "stack", "(", "[", "rnn_state", ".", "memory_cell", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "hidden_state", "=", "torch", ".", "stack", "(", "[", "rnn_state", ".", "hidden_state", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", ")", "\n", "memory_cell", "=", "torch", ".", "stack", "(", "[", "rnn_state", ".", "memory_cell", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", ")", "\n", "\n", "", "previous_action_embedding", "=", "torch", ".", "stack", "(", "\n", "[", "rnn_state", ".", "previous_action_embedding", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", "\n", ")", "\n", "\n", "# (group_size, decoder_input_dim)", "\n", "projected_input", "=", "self", ".", "_input_projection_layer", "(", "\n", "torch", ".", "cat", "(", "[", "attended_question", ",", "previous_action_embedding", "]", ",", "-", "1", ")", "\n", ")", "\n", "decoder_input", "=", "self", ".", "_activation", "(", "projected_input", ")", "\n", "if", "self", ".", "_num_layers", ">", "1", ":", "\n", "            ", "_", ",", "(", "hidden_state", ",", "memory_cell", ")", "=", "self", ".", "_decoder_cell", "(", "\n", "decoder_input", ".", "unsqueeze", "(", "0", ")", ",", "(", "hidden_state", ",", "memory_cell", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "hidden_state", ",", "memory_cell", "=", "self", ".", "_decoder_cell", "(", "\n", "decoder_input", ",", "(", "hidden_state", ",", "memory_cell", ")", "\n", ")", "\n", "", "hidden_state", "=", "self", ".", "_dropout", "(", "hidden_state", ")", "\n", "\n", "# (group_size, encoder_output_dim)", "\n", "encoder_outputs", "=", "torch", ".", "stack", "(", "\n", "[", "state", ".", "rnn_state", "[", "0", "]", ".", "encoder_outputs", "[", "i", "]", "for", "i", "in", "state", ".", "batch_indices", "]", "\n", ")", "\n", "encoder_output_mask", "=", "torch", ".", "stack", "(", "\n", "[", "state", ".", "rnn_state", "[", "0", "]", ".", "encoder_output_mask", "[", "i", "]", "for", "i", "in", "state", ".", "batch_indices", "]", "\n", ")", "\n", "\n", "if", "self", ".", "_num_layers", ">", "1", ":", "\n", "            ", "attended_question", ",", "attention_weights", "=", "self", ".", "attend_on_question", "(", "\n", "hidden_state", "[", "-", "1", "]", ",", "encoder_outputs", ",", "encoder_output_mask", "\n", ")", "\n", "action_query", "=", "torch", ".", "cat", "(", "[", "hidden_state", "[", "-", "1", "]", ",", "attended_question", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "attended_question", ",", "attention_weights", "=", "self", ".", "attend_on_question", "(", "\n", "hidden_state", ",", "encoder_outputs", ",", "encoder_output_mask", "\n", ")", "\n", "action_query", "=", "torch", ".", "cat", "(", "[", "hidden_state", ",", "attended_question", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# (group_size, action_embedding_dim)", "\n", "", "projected_query", "=", "self", ".", "_activation", "(", "self", ".", "_output_projection_layer", "(", "action_query", ")", ")", "\n", "predicted_action_embeddings", "=", "self", ".", "_dropout", "(", "projected_query", ")", "\n", "if", "self", ".", "_add_action_bias", ":", "\n", "# NOTE: It's important that this happens right before the dot product with the action", "\n", "# embeddings.  Otherwise this isn't a proper bias.  We do it here instead of right next", "\n", "# to the `.mm` below just so we only do it once for the whole group.", "\n", "            ", "ones", "=", "predicted_action_embeddings", ".", "new", "(", "[", "[", "1", "]", "for", "_", "in", "range", "(", "group_size", ")", "]", ")", "\n", "predicted_action_embeddings", "=", "torch", ".", "cat", "(", "[", "predicted_action_embeddings", ",", "ones", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "{", "\n", "\"hidden_state\"", ":", "hidden_state", ",", "\n", "\"memory_cell\"", ":", "memory_cell", ",", "\n", "\"attended_question\"", ":", "attended_question", ",", "\n", "\"attention_weights\"", ":", "attention_weights", ",", "\n", "\"predicted_action_embeddings\"", ":", "predicted_action_embeddings", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction._compute_action_probabilities": [[188, 227], ["len", "state.get_valid_actions", "collections.defaultdict", "range", "action_embeddings.mm().squeeze", "torch.nn.functional.log_softmax", "batch_results[].append", "action_embeddings.mm", "predicted_action_embedding.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_compute_action_probabilities", "(", "\n", "self", ",", "\n", "state", ":", "GrammarBasedState", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", ",", "\n", "attention_weights", ":", "torch", ".", "Tensor", ",", "\n", "predicted_action_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", ":", "\n", "# We take a couple of extra arguments here because subclasses might use them.", "\n", "\n", "# In this section we take our predicted action embedding and compare it to the available", "\n", "# actions in our current state (which might be different for each group element).  For", "\n", "# computing action scores, we'll forget about doing batched / grouped computation, as it", "\n", "# adds too much complexity and doesn't speed things up, anyway, with the operations we're", "\n", "# doing here.  This means we don't need any action masks, as we'll only get the right", "\n", "# lengths for what we're computing.", "\n", "\n", "        ", "group_size", "=", "len", "(", "state", ".", "batch_indices", ")", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "\n", "batch_results", ":", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "group_index", "in", "range", "(", "group_size", ")", ":", "\n", "            ", "instance_actions", "=", "actions", "[", "group_index", "]", "\n", "predicted_action_embedding", "=", "predicted_action_embeddings", "[", "group_index", "]", "\n", "action_embeddings", ",", "output_action_embeddings", ",", "action_ids", "=", "instance_actions", "[", "\"global\"", "]", "\n", "# This is just a matrix product between a (num_actions, embedding_dim) matrix and an", "\n", "# (embedding_dim, 1) matrix.", "\n", "action_logits", "=", "action_embeddings", ".", "mm", "(", "predicted_action_embedding", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "\n", "-", "1", "\n", ")", "\n", "current_log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "action_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# This is now the total score for each state after taking each action.  We're going to", "\n", "# sort by this later, so it's important that this is the total score, not just the", "\n", "# score for the current action.", "\n", "log_probs", "=", "state", ".", "score", "[", "group_index", "]", "+", "current_log_probs", "\n", "batch_results", "[", "state", ".", "batch_indices", "[", "group_index", "]", "]", ".", "append", "(", "\n", "(", "group_index", ",", "log_probs", ",", "current_log_probs", ",", "output_action_embeddings", ",", "action_ids", ")", "\n", ")", "\n", "", "return", "batch_results", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction._construct_next_states": [[228, 340], ["len", "batch_action_probs.items", "x.squeeze", "x.squeeze", "x.squeeze", "allennlp_semparse.state_machines.states.RnnStatelet", "state.new_state_from_group_index", "updated_rnn_state[].chunk", "updated_rnn_state[].chunk", "updated_rnn_state[].chunk", "torch.cat", "torch.cat", "torch.cat.data.cpu().numpy().tolist", "batch_states.sort", "current_log_probs.exp().cpu", "zip", "group_indices.extend", "group_log_probs.append", "group_action_embeddings.append", "group_actions.extend", "new_states.append", "torch.cat.data.cpu().numpy", "range", "basic_transition_function.BasicTransitionFunction._construct_next_states.make_state"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.new_state_from_group_index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_construct_next_states", "(", "\n", "self", ",", "\n", "state", ":", "GrammarBasedState", ",", "\n", "updated_rnn_state", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "batch_action_probs", ":", "Dict", "[", "int", ",", "List", "[", "Tuple", "[", "int", ",", "Any", ",", "Any", ",", "Any", ",", "List", "[", "int", "]", "]", "]", "]", ",", "\n", "max_actions", ":", "int", ",", "\n", "allowed_actions", ":", "List", "[", "Set", "[", "int", "]", "]", ",", "\n", ")", ":", "\n", "\n", "# We'll yield a bunch of states here that all have a `group_size` of 1, so that the", "\n", "# learning algorithm can decide how many of these it wants to keep, and it can just regroup", "\n", "# them later, as that's a really easy operation.", "\n", "#", "\n", "# We first define a `make_state` method, as in the logic that follows we want to create", "\n", "# states in a couple of different branches, and we don't want to duplicate the", "\n", "# state-creation logic.  This method creates a closure using variables from the method, so", "\n", "# it doesn't make sense to pull it out of here.", "\n", "\n", "# Each group index here might get accessed multiple times, and doing the slicing operation", "\n", "# each time is more expensive than doing it once upfront.  These three lines give about a", "\n", "# 10% speedup in training time.", "\n", "        ", "group_size", "=", "len", "(", "state", ".", "batch_indices", ")", "\n", "\n", "chunk_index", "=", "1", "if", "self", ".", "_num_layers", ">", "1", "else", "0", "\n", "hidden_state", "=", "[", "\n", "x", ".", "squeeze", "(", "chunk_index", ")", "\n", "for", "x", "in", "updated_rnn_state", "[", "\"hidden_state\"", "]", ".", "chunk", "(", "group_size", ",", "chunk_index", ")", "\n", "]", "\n", "memory_cell", "=", "[", "\n", "x", ".", "squeeze", "(", "chunk_index", ")", "\n", "for", "x", "in", "updated_rnn_state", "[", "\"memory_cell\"", "]", ".", "chunk", "(", "group_size", ",", "chunk_index", ")", "\n", "]", "\n", "\n", "attended_question", "=", "[", "\n", "x", ".", "squeeze", "(", "0", ")", "for", "x", "in", "updated_rnn_state", "[", "\"attended_question\"", "]", ".", "chunk", "(", "group_size", ",", "0", ")", "\n", "]", "\n", "\n", "def", "make_state", "(", "\n", "group_index", ":", "int", ",", "action", ":", "int", ",", "new_score", ":", "torch", ".", "Tensor", ",", "action_embedding", ":", "torch", ".", "Tensor", "\n", ")", "->", "GrammarBasedState", ":", "\n", "            ", "new_rnn_state", "=", "RnnStatelet", "(", "\n", "hidden_state", "[", "group_index", "]", ",", "\n", "memory_cell", "[", "group_index", "]", ",", "\n", "action_embedding", ",", "\n", "attended_question", "[", "group_index", "]", ",", "\n", "state", ".", "rnn_state", "[", "group_index", "]", ".", "encoder_outputs", ",", "\n", "state", ".", "rnn_state", "[", "group_index", "]", ".", "encoder_output_mask", ",", "\n", ")", "\n", "batch_index", "=", "state", ".", "batch_indices", "[", "group_index", "]", "\n", "for", "i", ",", "_", ",", "current_log_probs", ",", "_", ",", "actions", "in", "batch_action_probs", "[", "batch_index", "]", ":", "\n", "                ", "if", "i", "==", "group_index", ":", "\n", "                    ", "considered_actions", "=", "actions", "\n", "probabilities", "=", "current_log_probs", ".", "exp", "(", ")", ".", "cpu", "(", ")", "\n", "break", "\n", "", "", "return", "state", ".", "new_state_from_group_index", "(", "\n", "group_index", ",", "\n", "action", ",", "\n", "new_score", ",", "\n", "new_rnn_state", ",", "\n", "considered_actions", ",", "\n", "probabilities", ",", "\n", "updated_rnn_state", "[", "\"attention_weights\"", "]", ",", "\n", ")", "\n", "\n", "", "new_states", "=", "[", "]", "\n", "for", "_", ",", "results", "in", "batch_action_probs", ".", "items", "(", ")", ":", "\n", "            ", "if", "allowed_actions", "and", "not", "max_actions", ":", "\n", "# If we're given a set of allowed actions, and we're not just keeping the top k of", "\n", "# them, we don't need to do any sorting, so we can speed things up quite a bit.", "\n", "                ", "for", "group_index", ",", "log_probs", ",", "_", ",", "action_embeddings", ",", "actions", "in", "results", ":", "\n", "                    ", "for", "log_prob", ",", "action_embedding", ",", "action", "in", "zip", "(", "\n", "log_probs", ",", "action_embeddings", ",", "actions", "\n", ")", ":", "\n", "                        ", "if", "action", "in", "allowed_actions", "[", "group_index", "]", ":", "\n", "                            ", "new_states", ".", "append", "(", "\n", "make_state", "(", "group_index", ",", "action", ",", "log_prob", ",", "action_embedding", ")", "\n", ")", "\n", "", "", "", "", "else", ":", "\n", "# In this case, we need to sort the actions.  We'll do that on CPU, as it's easier,", "\n", "# and our action list is on the CPU, anyway.", "\n", "                ", "group_indices", "=", "[", "]", "\n", "group_log_probs", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "group_action_embeddings", "=", "[", "]", "\n", "group_actions", "=", "[", "]", "\n", "for", "group_index", ",", "log_probs", ",", "_", ",", "action_embeddings", ",", "actions", "in", "results", ":", "\n", "                    ", "group_indices", ".", "extend", "(", "[", "group_index", "]", "*", "len", "(", "actions", ")", ")", "\n", "group_log_probs", ".", "append", "(", "log_probs", ")", "\n", "group_action_embeddings", ".", "append", "(", "action_embeddings", ")", "\n", "group_actions", ".", "extend", "(", "actions", ")", "\n", "", "log_probs", "=", "torch", ".", "cat", "(", "group_log_probs", ",", "dim", "=", "0", ")", "\n", "action_embeddings", "=", "torch", ".", "cat", "(", "group_action_embeddings", ",", "dim", "=", "0", ")", "\n", "log_probs_cpu", "=", "log_probs", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "batch_states", "=", "[", "\n", "(", "\n", "log_probs_cpu", "[", "i", "]", ",", "\n", "group_indices", "[", "i", "]", ",", "\n", "log_probs", "[", "i", "]", ",", "\n", "action_embeddings", "[", "i", "]", ",", "\n", "group_actions", "[", "i", "]", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "group_actions", ")", ")", "\n", "if", "(", "\n", "not", "allowed_actions", "or", "group_actions", "[", "i", "]", "in", "allowed_actions", "[", "group_indices", "[", "i", "]", "]", "\n", ")", "\n", "]", "\n", "# We use a key here to make sure we're not trying to compare anything on the GPU.", "\n", "batch_states", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "if", "max_actions", ":", "\n", "                    ", "batch_states", "=", "batch_states", "[", ":", "max_actions", "]", "\n", "", "for", "_", ",", "group_index", ",", "log_prob", ",", "action_embedding", ",", "action", "in", "batch_states", ":", "\n", "                    ", "new_states", ".", "append", "(", "make_state", "(", "group_index", ",", "action", ",", "log_prob", ",", "action_embedding", ")", ")", "\n", "", "", "", "return", "new_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.attend_on_question": [[341, 360], ["basic_transition_function.BasicTransitionFunction._input_attention", "allennlp.nn.util.weighted_sum"], "methods", ["None"], ["", "def", "attend_on_question", "(", "\n", "self", ",", "query", ":", "torch", ".", "Tensor", ",", "encoder_outputs", ":", "torch", ".", "Tensor", ",", "encoder_output_mask", ":", "torch", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Given a query (which is typically the decoder hidden state), compute an attention over the\n        output of the question encoder, and return a weighted sum of the question representations\n        given this attention.  We also return the attention weights themselves.\n\n        This is a simple computation, but we have it as a separate method so that the ``forward``\n        method on the main parser module can call it on the initial hidden state, to simplify the\n        logic in ``take_step``.\n        \"\"\"", "\n", "# (group_size, question_length)", "\n", "question_attention_weights", "=", "self", ".", "_input_attention", "(", "\n", "query", ",", "encoder_outputs", ",", "encoder_output_mask", "\n", ")", "\n", "# (group_size, encoder_output_dim)", "\n", "attended_question", "=", "util", ".", "weighted_sum", "(", "encoder_outputs", ",", "question_attention_weights", ")", "\n", "return", "attended_question", ",", "question_attention_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function_test.TestBasicTransitionFunction.setup_method": [[13, 98], ["super().setup_method", "allennlp_semparse.state_machines.transition_functions.BasicTransitionFunction", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "allennlp_semparse.state_machines.states.GrammarBasedState", "torch.FloatTensor", "allennlp_semparse.state_machines.states.GrammarStatelet", "len", "rnn_state.append", "zip", "allennlp_semparse.state_machines.states.RnnStatelet", "allennlp.modules.Attention.by_name", "range", "range", "range", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "decoder_step", "=", "BasicTransitionFunction", "(", "\n", "encoder_output_dim", "=", "2", ",", "\n", "action_embedding_dim", "=", "2", ",", "\n", "input_attention", "=", "Attention", ".", "by_name", "(", "\"dot_product\"", ")", "(", ")", ",", "\n", "add_action_bias", "=", "False", ",", "\n", ")", "\n", "\n", "batch_indices", "=", "[", "0", ",", "1", ",", "0", "]", "\n", "action_history", "=", "[", "[", "1", "]", ",", "[", "3", ",", "4", "]", ",", "[", "]", "]", "\n", "score", "=", "[", "torch", ".", "FloatTensor", "(", "[", "x", "]", ")", "for", "x", "in", "[", "0.1", ",", "1.1", ",", "2.2", "]", "]", "\n", "hidden_state", "=", "torch", ".", "FloatTensor", "(", "[", "[", "i", ",", "i", "]", "for", "i", "in", "range", "(", "len", "(", "batch_indices", ")", ")", "]", ")", "\n", "memory_cell", "=", "torch", ".", "FloatTensor", "(", "[", "[", "i", ",", "i", "]", "for", "i", "in", "range", "(", "len", "(", "batch_indices", ")", ")", "]", ")", "\n", "previous_action_embedding", "=", "torch", ".", "FloatTensor", "(", "[", "[", "i", ",", "i", "]", "for", "i", "in", "range", "(", "len", "(", "batch_indices", ")", ")", "]", ")", "\n", "attended_question", "=", "torch", ".", "FloatTensor", "(", "[", "[", "i", ",", "i", "]", "for", "i", "in", "range", "(", "len", "(", "batch_indices", ")", ")", "]", ")", "\n", "# This maps non-terminals to valid actions, where the valid actions are grouped by _type_.", "\n", "# We have \"global\" actions, which are from the global grammar, and \"linked\" actions, which", "\n", "# are instance-specific and are generated based on question attention.  Each action type", "\n", "# has a tuple which is (input representation, output representation, action ids).", "\n", "valid_actions", "=", "{", "\n", "\"e\"", ":", "{", "\n", "\"global\"", ":", "(", "\n", "torch", ".", "FloatTensor", "(", "[", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "-", "1", "]", ",", "[", "-", "2", ",", "-", "2", "]", "]", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "[", "[", "-", "1", ",", "-", "1", "]", ",", "[", "-", "2", ",", "-", "2", "]", ",", "[", "-", "3", ",", "-", "3", "]", "]", ")", ",", "\n", "[", "0", ",", "1", ",", "2", "]", ",", "\n", ")", ",", "\n", "\"linked\"", ":", "(", "\n", "torch", ".", "FloatTensor", "(", "[", "[", "0.1", ",", "0.2", ",", "0.3", "]", ",", "[", "0.4", ",", "0.5", ",", "0.6", "]", "]", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "4", "]", "]", ")", ",", "\n", "[", "3", ",", "4", "]", ",", "\n", ")", ",", "\n", "}", ",", "\n", "\"d\"", ":", "{", "\n", "\"global\"", ":", "(", "torch", ".", "FloatTensor", "(", "[", "[", "0", ",", "0", "]", "]", ")", ",", "torch", ".", "FloatTensor", "(", "[", "[", "-", "1", ",", "-", "1", "]", "]", ")", ",", "[", "0", "]", ")", ",", "\n", "\"linked\"", ":", "(", "\n", "torch", ".", "FloatTensor", "(", "[", "[", "-", "0.1", ",", "-", "0.2", ",", "-", "0.3", "]", ",", "[", "-", "0.4", ",", "-", "0.5", ",", "-", "0.6", "]", ",", "[", "-", "0.7", ",", "-", "0.8", ",", "-", "0.9", "]", "]", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "[", "[", "5", ",", "5", "]", ",", "[", "6", ",", "6", "]", ",", "[", "7", ",", "7", "]", "]", ")", ",", "\n", "[", "1", ",", "2", ",", "3", "]", ",", "\n", ")", ",", "\n", "}", ",", "\n", "}", "\n", "grammar_state", "=", "[", "\n", "GrammarStatelet", "(", "[", "nonterminal", "]", ",", "valid_actions", ",", "is_nonterminal", ")", "\n", "for", "_", ",", "nonterminal", "in", "zip", "(", "batch_indices", ",", "[", "\"e\"", ",", "\"d\"", ",", "\"e\"", "]", ")", "\n", "]", "\n", "self", ".", "encoder_outputs", "=", "torch", ".", "FloatTensor", "(", "\n", "[", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", ",", "[", "5", ",", "6", "]", "]", ",", "[", "[", "10", ",", "11", "]", ",", "[", "12", ",", "13", "]", ",", "[", "14", ",", "15", "]", "]", "]", "\n", ")", "\n", "self", ".", "encoder_output_mask", "=", "torch", ".", "FloatTensor", "(", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "0", "]", "]", ")", "\n", "self", ".", "possible_actions", "=", "[", "\n", "[", "\n", "(", "\"e -> f\"", ",", "False", ",", "None", ")", ",", "\n", "(", "\"e -> g\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"e -> h\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"e -> i\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"e -> j\"", ",", "True", ",", "None", ")", ",", "\n", "]", ",", "\n", "[", "\n", "(", "\"d -> q\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"d -> g\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"d -> h\"", ",", "True", ",", "None", ")", ",", "\n", "(", "\"d -> i\"", ",", "True", ",", "None", ")", ",", "\n", "]", ",", "\n", "]", "\n", "\n", "rnn_state", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "batch_indices", ")", ")", ":", "\n", "            ", "rnn_state", ".", "append", "(", "\n", "RnnStatelet", "(", "\n", "hidden_state", "[", "i", "]", ",", "\n", "memory_cell", "[", "i", "]", ",", "\n", "previous_action_embedding", "[", "i", "]", ",", "\n", "attended_question", "[", "i", "]", ",", "\n", "self", ".", "encoder_outputs", ",", "\n", "self", ".", "encoder_output_mask", ",", "\n", ")", "\n", ")", "\n", "", "self", ".", "state", "=", "GrammarBasedState", "(", "\n", "batch_indices", "=", "batch_indices", ",", "\n", "action_history", "=", "action_history", ",", "\n", "score", "=", "score", ",", "\n", "rnn_state", "=", "rnn_state", ",", "\n", "grammar_state", "=", "grammar_state", ",", "\n", "possible_actions", "=", "self", ".", "possible_actions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function_test.TestBasicTransitionFunction.test_take_step": [[100, 146], ["basic_transition_function_test.TestBasicTransitionFunction.decoder_step.take_step", "set", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "len", "tuple", "tuple", "new_state.rnn_state[].encoder_outputs.cpu().numpy", "basic_transition_function_test.TestBasicTransitionFunction.encoder_outputs.cpu().numpy", "new_state.rnn_state[].encoder_output_mask.cpu().numpy", "basic_transition_function_test.TestBasicTransitionFunction.encoder_output_mask.cpu().numpy", "new_state.rnn_state[].encoder_outputs.cpu().numpy", "basic_transition_function_test.TestBasicTransitionFunction.encoder_outputs.cpu().numpy", "new_state.rnn_state[].encoder_output_mask.cpu().numpy", "basic_transition_function_test.TestBasicTransitionFunction.encoder_output_mask.cpu().numpy", "new_state.rnn_state[].encoder_outputs.cpu", "basic_transition_function_test.TestBasicTransitionFunction.encoder_outputs.cpu", "new_state.rnn_state[].encoder_output_mask.cpu", "basic_transition_function_test.TestBasicTransitionFunction.encoder_output_mask.cpu", "new_state.rnn_state[].encoder_outputs.cpu", "basic_transition_function_test.TestBasicTransitionFunction.encoder_outputs.cpu", "new_state.rnn_state[].encoder_output_mask.cpu", "basic_transition_function_test.TestBasicTransitionFunction.encoder_output_mask.cpu"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.take_step"], ["", "def", "test_take_step", "(", "self", ")", ":", "\n", "        ", "new_states", "=", "self", ".", "decoder_step", ".", "take_step", "(", "\n", "self", ".", "state", ",", "max_actions", "=", "1", ",", "allowed_actions", "=", "[", "{", "2", ",", "3", "}", ",", "{", "0", "}", ",", "{", "4", "}", "]", "\n", ")", "\n", "\n", "assert", "len", "(", "new_states", ")", "==", "2", "\n", "new_state", "=", "new_states", "[", "0", "]", "\n", "assert", "new_state", ".", "batch_indices", "==", "[", "0", "]", "\n", "\n", "# We're not going to try to guess which action was taken (or set model weights so that we", "\n", "# know which action will be taken); we'll just check that we got one of the actions we were", "\n", "# expecting.", "\n", "expected_possibilities", "=", "set", "(", "[", "(", "(", "4", ",", ")", ",", "(", "\"j\"", ",", ")", ")", ",", "(", "(", "1", ",", "2", ")", ",", "(", "\"h\"", ",", ")", ")", ",", "(", "(", "1", ",", "3", ")", ",", "(", "\"i\"", ",", ")", ")", "]", ")", "\n", "actual", "=", "(", "\n", "tuple", "(", "new_state", ".", "action_history", "[", "0", "]", ")", ",", "\n", "tuple", "(", "new_state", ".", "grammar_state", "[", "0", "]", ".", "_nonterminal_stack", ")", ",", "\n", ")", "\n", "assert", "actual", "in", "expected_possibilities", "\n", "\n", "# These should just be copied from the prior state, no matter which action we took.", "\n", "assert_almost_equal", "(", "\n", "new_state", ".", "rnn_state", "[", "0", "]", ".", "encoder_outputs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "self", ".", "encoder_outputs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "assert_almost_equal", "(", "\n", "new_state", ".", "rnn_state", "[", "0", "]", ".", "encoder_output_mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "self", ".", "encoder_output_mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", ")", "\n", "assert", "new_state", ".", "possible_actions", "==", "self", ".", "possible_actions", "\n", "\n", "new_state", "=", "new_states", "[", "1", "]", "\n", "# For batch instance 1, we should have selected action 0 from group index 1 - there was", "\n", "# only one allowed action.", "\n", "assert", "new_state", ".", "batch_indices", "==", "[", "1", "]", "\n", "# These two have values taken from what's defined in setup_method() - the prior action", "\n", "# history ([3, 4]) and the nonterminals corresponding to the action we picked ('q').", "\n", "assert", "new_state", ".", "action_history", "==", "[", "[", "3", ",", "4", ",", "0", "]", "]", "\n", "assert", "new_state", ".", "grammar_state", "[", "0", "]", ".", "_nonterminal_stack", "==", "[", "\"q\"", "]", "\n", "# And these should just be copied from the prior state.", "\n", "assert_almost_equal", "(", "\n", "new_state", ".", "rnn_state", "[", "0", "]", ".", "encoder_outputs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "self", ".", "encoder_outputs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "assert_almost_equal", "(", "\n", "new_state", ".", "rnn_state", "[", "0", "]", ".", "encoder_output_mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "self", ".", "encoder_output_mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", ")", "\n", "assert", "new_state", ".", "possible_actions", "==", "self", ".", "possible_actions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization.__init__": [[39, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "beam_size", ":", "int", ",", "\n", "normalize_by_length", ":", "bool", ",", "\n", "max_decoding_steps", ":", "int", ",", "\n", "max_num_decoded_sequences", ":", "int", "=", "1", ",", "\n", "max_num_finished_states", ":", "int", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_beam_size", "=", "beam_size", "\n", "self", ".", "_normalize_by_length", "=", "normalize_by_length", "\n", "self", ".", "_max_decoding_steps", "=", "max_decoding_steps", "\n", "self", ".", "_max_num_decoded_sequences", "=", "max_num_decoded_sequences", "\n", "self", ".", "_max_num_finished_states", "=", "max_num_finished_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization.decode": [[53, 79], ["expected_risk_minimization.ExpectedRiskMinimization._get_finished_states", "initial_state.score[].new_zeros", "expected_risk_minimization.ExpectedRiskMinimization._get_model_scores_by_batch", "expected_risk_minimization.ExpectedRiskMinimization._get_costs_by_batch", "torch.cat", "torch.cat", "allennlp.nn.util.masked_softmax", "allennlp.nn.util.masked_softmax.dot", "len", "expected_risk_minimization.ExpectedRiskMinimization._get_best_final_states", "tensor.view", "tensor.view"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_finished_states", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_model_scores_by_batch", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_costs_by_batch", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_best_final_states"], ["", "def", "decode", "(", "\n", "self", ",", "\n", "initial_state", ":", "State", ",", "\n", "transition_function", ":", "TransitionFunction", ",", "\n", "supervision", ":", "Callable", "[", "[", "StateType", "]", ",", "torch", ".", "Tensor", "]", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "cost_function", "=", "supervision", "\n", "finished_states", "=", "self", ".", "_get_finished_states", "(", "initial_state", ",", "transition_function", ")", "\n", "loss", "=", "initial_state", ".", "score", "[", "0", "]", ".", "new_zeros", "(", "1", ")", "\n", "finished_model_scores", "=", "self", ".", "_get_model_scores_by_batch", "(", "finished_states", ")", "\n", "finished_costs", "=", "self", ".", "_get_costs_by_batch", "(", "finished_states", ",", "cost_function", ")", "\n", "for", "batch_index", "in", "finished_model_scores", ":", "\n", "# Finished model scores are log-probabilities of the predicted sequences. We convert", "\n", "# log probabilities into probabilities and re-normalize them to compute expected cost under", "\n", "# the distribution approximated by the beam search.", "\n", "\n", "            ", "costs", "=", "torch", ".", "cat", "(", "[", "tensor", ".", "view", "(", "-", "1", ")", "for", "tensor", "in", "finished_costs", "[", "batch_index", "]", "]", ")", "\n", "logprobs", "=", "torch", ".", "cat", "(", "[", "tensor", ".", "view", "(", "-", "1", ")", "for", "tensor", "in", "finished_model_scores", "[", "batch_index", "]", "]", ")", "\n", "# Unmasked softmax of log probabilities will convert them into probabilities and", "\n", "# renormalize them.", "\n", "renormalized_probs", "=", "nn_util", ".", "masked_softmax", "(", "logprobs", ",", "None", ")", "\n", "loss", "+=", "renormalized_probs", ".", "dot", "(", "costs", ")", "\n", "", "mean_loss", "=", "loss", "/", "len", "(", "finished_model_scores", ")", "\n", "return", "{", "\n", "\"loss\"", ":", "mean_loss", ",", "\n", "\"best_final_states\"", ":", "self", ".", "_get_best_final_states", "(", "finished_states", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_finished_states": [[81, 106], ["states[].combine_states", "transition_function.take_step", "expected_risk_minimization.ExpectedRiskMinimization._prune_beam", "expected_risk_minimization.ExpectedRiskMinimization._prune_beam", "next_state.is_finished", "expected_risk_minimization.ExpectedRiskMinimization.append", "next_states.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.combine_states", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.transition_functions.basic_transition_function.BasicTransitionFunction.take_step", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._prune_beam", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._prune_beam", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_finished_states", "(", "\n", "self", ",", "initial_state", ":", "State", ",", "transition_function", ":", "TransitionFunction", "\n", ")", "->", "List", "[", "StateType", "]", ":", "\n", "        ", "finished_states", "=", "[", "]", "\n", "states", "=", "[", "initial_state", "]", "\n", "num_steps", "=", "0", "\n", "while", "states", "and", "num_steps", "<", "self", ".", "_max_decoding_steps", ":", "\n", "            ", "next_states", "=", "[", "]", "\n", "grouped_state", "=", "states", "[", "0", "]", ".", "combine_states", "(", "states", ")", "\n", "# These states already come sorted.", "\n", "for", "next_state", "in", "transition_function", ".", "take_step", "(", "grouped_state", ")", ":", "\n", "                ", "if", "next_state", ".", "is_finished", "(", ")", ":", "\n", "                    ", "finished_states", ".", "append", "(", "next_state", ")", "\n", "", "else", ":", "\n", "                    ", "next_states", ".", "append", "(", "next_state", ")", "\n", "\n", "", "", "states", "=", "self", ".", "_prune_beam", "(", "\n", "states", "=", "next_states", ",", "beam_size", "=", "self", ".", "_beam_size", ",", "sort_states", "=", "False", "\n", ")", "\n", "num_steps", "+=", "1", "\n", "", "if", "self", ".", "_max_num_finished_states", "is", "not", "None", ":", "\n", "            ", "finished_states", "=", "self", ".", "_prune_beam", "(", "\n", "states", "=", "finished_states", ",", "beam_size", "=", "self", ".", "_max_num_finished_states", ",", "sort_states", "=", "True", "\n", ")", "\n", "", "return", "finished_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._prune_beam": [[108, 132], ["collections.defaultdict", "states_by_batch_index.items", "states_by_batch_index[].append", "len", "torch.cat", "torch.cat.sort", "pruned_states.append", "state.score[].view", "sorted_indices.detach().cpu().numpy", "sorted_indices.detach().cpu", "sorted_indices.detach"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_prune_beam", "(", "states", ":", "List", "[", "State", "]", ",", "beam_size", ":", "int", ",", "sort_states", ":", "bool", "=", "False", ")", "->", "List", "[", "State", "]", ":", "\n", "        ", "\"\"\"\n        This method can be used to prune the set of unfinished states on a beam or finished states\n        at the end of search. In the former case, the states need not be sorted because the all come\n        from the same decoding step, which does the sorting. However, if the states are finished and\n        this method is called at the end of the search, they need to be sorted because they come\n        from different decoding steps.\n        \"\"\"", "\n", "states_by_batch_index", ":", "Dict", "[", "int", ",", "List", "[", "State", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "state", "in", "states", ":", "\n", "            ", "assert", "len", "(", "state", ".", "batch_indices", ")", "==", "1", "\n", "batch_index", "=", "state", ".", "batch_indices", "[", "0", "]", "\n", "states_by_batch_index", "[", "batch_index", "]", ".", "append", "(", "state", ")", "\n", "", "pruned_states", "=", "[", "]", "\n", "for", "_", ",", "instance_states", "in", "states_by_batch_index", ".", "items", "(", ")", ":", "\n", "            ", "if", "sort_states", ":", "\n", "                ", "scores", "=", "torch", ".", "cat", "(", "[", "state", ".", "score", "[", "0", "]", ".", "view", "(", "-", "1", ")", "for", "state", "in", "instance_states", "]", ")", "\n", "_", ",", "sorted_indices", "=", "scores", ".", "sort", "(", "-", "1", ",", "descending", "=", "True", ")", "\n", "sorted_states", "=", "[", "instance_states", "[", "i", "]", "for", "i", "in", "sorted_indices", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "instance_states", "=", "sorted_states", "\n", "", "for", "state", "in", "instance_states", "[", ":", "beam_size", "]", ":", "\n", "                ", "pruned_states", ".", "append", "(", "state", ")", "\n", "", "", "return", "pruned_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_model_scores_by_batch": [[133, 144], ["collections.defaultdict", "zip", "batch_scores[].append", "model_score.new_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_model_scores_by_batch", "(", "self", ",", "states", ":", "List", "[", "StateType", "]", ")", "->", "Dict", "[", "int", ",", "List", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "batch_scores", ":", "Dict", "[", "int", ",", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "state", "in", "states", ":", "\n", "            ", "for", "batch_index", ",", "model_score", ",", "history", "in", "zip", "(", "\n", "state", ".", "batch_indices", ",", "state", ".", "score", ",", "state", ".", "action_history", "\n", ")", ":", "\n", "                ", "if", "self", ".", "_normalize_by_length", ":", "\n", "                    ", "path_length", "=", "model_score", ".", "new_tensor", "(", "[", "len", "(", "history", ")", "]", ")", "\n", "model_score", "=", "model_score", "/", "path_length", "\n", "", "batch_scores", "[", "batch_index", "]", ".", "append", "(", "model_score", ")", "\n", "", "", "return", "batch_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_costs_by_batch": [[145, 157], ["collections.defaultdict", "cost_function", "batch_costs[].append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "staticmethod", "\n", "def", "_get_costs_by_batch", "(", "\n", "states", ":", "List", "[", "StateType", "]", ",", "cost_function", ":", "Callable", "[", "[", "StateType", "]", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "batch_costs", ":", "Dict", "[", "int", ",", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "state", "in", "states", ":", "\n", "            ", "cost", "=", "cost_function", "(", "state", ")", "\n", "# Since this is a finished state, its group size is 1, and we just take the only batch", "\n", "# index.", "\n", "batch_index", "=", "state", ".", "batch_indices", "[", "0", "]", "\n", "batch_costs", "[", "batch_index", "]", ".", "append", "(", "cost", ")", "\n", "", "return", "batch_costs", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_best_final_states": [[158, 176], ["collections.defaultdict", "batch_states.items", "batch_states[].append", "finished_to_sort.sort", "state.score[].item"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_get_best_final_states", "(", "\n", "self", ",", "finished_states", ":", "List", "[", "StateType", "]", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns the best finished states for each batch instance based on model scores. We return\n        at most ``self._max_num_decoded_sequences`` number of sequences per instance.\n        \"\"\"", "\n", "batch_states", ":", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "state", "in", "finished_states", ":", "\n", "            ", "batch_states", "[", "state", ".", "batch_indices", "[", "0", "]", "]", ".", "append", "(", "state", ")", "\n", "", "best_states", ":", "Dict", "[", "int", ",", "List", "[", "StateType", "]", "]", "=", "{", "}", "\n", "for", "batch_index", ",", "states", "in", "batch_states", ".", "items", "(", ")", ":", "\n", "# The time this sort takes is pretty negligible, no particular need to optimize this", "\n", "# yet.  Maybe with a larger beam size...", "\n", "            ", "finished_to_sort", "=", "[", "(", "-", "state", ".", "score", "[", "0", "]", ".", "item", "(", ")", ",", "state", ")", "for", "state", "in", "states", "]", "\n", "finished_to_sort", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "best_states", "[", "batch_index", "]", "=", "[", "state", "[", "1", "]", "for", "state", "in", "finished_to_sort", "[", ":", "self", ".", "_beam_size", "]", "]", "\n", "", "return", "best_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.maximum_marginal_likelihood.MaximumMarginalLikelihood.__init__": [[42, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beam_size", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "_beam_size", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.maximum_marginal_likelihood.MaximumMarginalLikelihood.decode": [[45, 62], ["allennlp_semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch", "allennlp_semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search", "finished_states.values", "state.score[].view", "allennlp.nn.util.logsumexp", "len", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.state_machines.constrained_beam_search.ConstrainedBeamSearch.search"], ["", "def", "decode", "(", "\n", "self", ",", "\n", "initial_state", ":", "State", ",", "\n", "transition_function", ":", "TransitionFunction", ",", "\n", "supervision", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "targets", ",", "target_mask", "=", "supervision", "\n", "beam_search", "=", "ConstrainedBeamSearch", "(", "self", ".", "_beam_size", ",", "targets", ",", "target_mask", ")", "\n", "finished_states", ":", "Dict", "[", "int", ",", "List", "[", "State", "]", "]", "=", "beam_search", ".", "search", "(", "\n", "initial_state", ",", "transition_function", "\n", ")", "\n", "\n", "loss", "=", "0", "\n", "for", "instance_states", "in", "finished_states", ".", "values", "(", ")", ":", "\n", "            ", "scores", "=", "[", "state", ".", "score", "[", "0", "]", ".", "view", "(", "-", "1", ")", "for", "state", "in", "instance_states", "]", "\n", "loss", "+=", "-", "util", ".", "logsumexp", "(", "torch", ".", "cat", "(", "scores", ")", ")", "\n", "", "return", "{", "\"loss\"", ":", "loss", "/", "len", "(", "finished_states", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode": [[26, 57], ["None"], "methods", ["None"], ["def", "decode", "(", "\n", "self", ",", "\n", "initial_state", ":", "State", ",", "\n", "transition_function", ":", "TransitionFunction", ",", "\n", "supervision", ":", "SupervisionType", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Takes an initial state object, a means of transitioning from state to state, and a\n        supervision signal, and uses the supervision to train the transition function to pick\n        \"good\" states.\n\n        This function should typically return a ``loss`` key during training, which the ``Model``\n        will use as its loss.\n\n        Parameters\n        ----------\n        initial_state : ``State``\n            This is the initial state for decoding, typically initialized after running some kind\n            of encoder on some inputs.\n        transition_function : ``TransitionFunction``\n            This is the transition function that scores all possible actions that can be taken in a\n            given state, and returns a ranked list of next states at each step of decoding.\n        supervision : ``SupervisionType``\n            This is the supervision that is used to train the ``transition_function`` function to\n            pick \"good\" states.  You can use whatever kind of supervision you want (e.g., a single\n            \"gold\" action sequence, a set of possible \"gold\" action sequences, a reward function,\n            etc.).  We use ``typing.Generics`` to make sure that our static type checker is happy\n            with how you've matched the supervision that you provide in the model to the\n            ``DecoderTrainer`` that you want to use.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.maximum_marginal_likelihood_test.TestMaximumMarginalLikelihood.setup_method": [[13, 29], ["super().setup_method", "simple_transition_system.SimpleState", "simple_transition_system.SimpleTransitionFunction", "torch.Tensor", "torch.Tensor", "allennlp_semparse.state_machines.trainers.MaximumMarginalLikelihood", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "initial_state", "=", "SimpleState", "(", "\n", "[", "0", ",", "1", "]", ",", "[", "[", "]", ",", "[", "]", "]", ",", "[", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "]", ",", "[", "0", ",", "1", "]", "\n", ")", "\n", "self", ".", "decoder_step", "=", "SimpleTransitionFunction", "(", ")", "\n", "self", ".", "targets", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "2", ",", "3", ",", "4", "]", ",", "[", "1", ",", "3", ",", "4", "]", ",", "[", "1", ",", "2", ",", "4", "]", "]", ",", "[", "[", "3", ",", "4", ",", "0", "]", ",", "[", "2", ",", "3", ",", "4", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", "]", "\n", ")", "\n", "self", ".", "target_mask", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ",", "[", "[", "1", ",", "1", ",", "0", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", "]", "\n", ")", "\n", "\n", "self", ".", "supervision", "=", "(", "self", ".", "targets", ",", "self", ".", "target_mask", ")", "\n", "# High beam size ensures exhaustive search.", "\n", "self", ".", "trainer", "=", "MaximumMarginalLikelihood", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.maximum_marginal_likelihood_test.TestMaximumMarginalLikelihood.test_decode": [[30, 39], ["maximum_marginal_likelihood_test.TestMaximumMarginalLikelihood.trainer.decode", "math.log", "math.log", "numpy.testing.assert_almost_equal", "decoded_info[].data.numpy", "math.exp", "math.exp", "math.exp"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode"], ["", "def", "test_decode", "(", "self", ")", ":", "\n", "        ", "decoded_info", "=", "self", ".", "trainer", ".", "decode", "(", "self", ".", "initial_state", ",", "self", ".", "decoder_step", ",", "self", ".", "supervision", ")", "\n", "\n", "# Our loss is the negative log sum of the scores from each target sequence.  The score for", "\n", "# each sequence in our simple transition system is just `-sequence_length`.", "\n", "instance0_loss", "=", "math", ".", "log", "(", "math", ".", "exp", "(", "-", "3", ")", "*", "3", ")", "# all three sequences have length 3", "\n", "instance1_loss", "=", "math", ".", "log", "(", "math", ".", "exp", "(", "-", "2", ")", "+", "math", ".", "exp", "(", "-", "3", ")", ")", "# one has length 2, one has length 3", "\n", "expected_loss", "=", "-", "(", "instance0_loss", "+", "instance1_loss", ")", "/", "2", "\n", "assert_almost_equal", "(", "decoded_info", "[", "\"loss\"", "]", ".", "data", ".", "numpy", "(", ")", ",", "expected_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization_test.TestExpectedRiskMinimization.setup_method": [[12, 23], ["super().setup_method", "simple_transition_system.SimpleState", "simple_transition_system.SimpleTransitionFunction", "allennlp_semparse.state_machines.trainers.ExpectedRiskMinimization", "torch.Tensor", "torch.Tensor", "sum"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.sum"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "initial_state", "=", "SimpleState", "(", "[", "0", "]", ",", "[", "[", "0", "]", "]", ",", "[", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "]", ")", "\n", "self", ".", "decoder_step", "=", "SimpleTransitionFunction", "(", ")", "\n", "# Cost is the number of odd elements in the action history.", "\n", "self", ".", "supervision", "=", "lambda", "state", ":", "torch", ".", "Tensor", "(", "\n", "[", "sum", "(", "[", "x", "%", "2", "!=", "0", "for", "x", "in", "state", ".", "action_history", "[", "0", "]", "]", ")", "]", "\n", ")", "\n", "# High beam size ensures exhaustive search.", "\n", "self", ".", "trainer", "=", "ExpectedRiskMinimization", "(", "\n", "beam_size", "=", "100", ",", "normalize_by_length", "=", "False", ",", "max_decoding_steps", "=", "10", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization_test.TestExpectedRiskMinimization.test_get_finished_states": [[25, 36], ["expected_risk_minimization_test.TestExpectedRiskMinimization.trainer._get_finished_states", "len", "state.score[].item"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization.ExpectedRiskMinimization._get_finished_states"], ["", "def", "test_get_finished_states", "(", "self", ")", ":", "\n", "        ", "finished_states", "=", "self", ".", "trainer", ".", "_get_finished_states", "(", "self", ".", "initial_state", ",", "self", ".", "decoder_step", ")", "\n", "state_info", "=", "[", "(", "state", ".", "action_history", "[", "0", "]", ",", "state", ".", "score", "[", "0", "]", ".", "item", "(", ")", ")", "for", "state", "in", "finished_states", "]", "\n", "# There will be exactly five finished states with the following paths. Each score is the", "\n", "# negative of one less than the number of elements in the action history.", "\n", "assert", "len", "(", "finished_states", ")", "==", "5", "\n", "assert", "(", "[", "0", ",", "2", ",", "4", "]", ",", "-", "2", ")", "in", "state_info", "\n", "assert", "(", "[", "0", ",", "1", ",", "2", ",", "4", "]", ",", "-", "3", ")", "in", "state_info", "\n", "assert", "(", "[", "0", ",", "1", ",", "3", ",", "4", "]", ",", "-", "3", ")", "in", "state_info", "\n", "assert", "(", "[", "0", ",", "2", ",", "3", ",", "4", "]", ",", "-", "3", ")", "in", "state_info", "\n", "assert", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "-", "4", ")", "in", "state_info", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.expected_risk_minimization_test.TestExpectedRiskMinimization.test_decode": [[37, 59], ["expected_risk_minimization_test.TestExpectedRiskMinimization.trainer.decode", "numpy.testing.assert_almost_equal", "numpy.exp", "decoded_info[].data.numpy", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.trainers.decoder_trainer.DecoderTrainer.decode"], ["", "def", "test_decode", "(", "self", ")", ":", "\n", "        ", "decoded_info", "=", "self", ".", "trainer", ".", "decode", "(", "self", ".", "initial_state", ",", "self", ".", "decoder_step", ",", "self", ".", "supervision", ")", "\n", "# The best state corresponds to the shortest path.", "\n", "best_state", "=", "decoded_info", "[", "\"best_final_states\"", "]", "[", "0", "]", "[", "0", "]", "\n", "assert", "best_state", ".", "action_history", "[", "0", "]", "==", "[", "0", ",", "2", ",", "4", "]", "\n", "# The scores and costs corresponding to the finished states will be", "\n", "# [0, 2, 4] : -2, 0", "\n", "# [0, 1, 2, 4] : -3, 1", "\n", "# [0, 1, 3, 4] : -3, 2", "\n", "# [0, 2, 3, 4] : -3, 1", "\n", "# [0, 1, 2, 3, 4] : -4, 2", "\n", "\n", "# This is the normalization factor while re-normalizing probabilities on the beam", "\n", "partition", "=", "np", ".", "exp", "(", "-", "2", ")", "+", "np", ".", "exp", "(", "-", "3", ")", "+", "np", ".", "exp", "(", "-", "3", ")", "+", "np", ".", "exp", "(", "-", "3", ")", "+", "np", ".", "exp", "(", "-", "4", ")", "\n", "expected_loss", "=", "(", "\n", "(", "np", ".", "exp", "(", "-", "2", ")", "*", "0", ")", "\n", "+", "(", "np", ".", "exp", "(", "-", "3", ")", "*", "1", ")", "\n", "+", "(", "np", ".", "exp", "(", "-", "3", ")", "*", "2", ")", "\n", "+", "(", "np", ".", "exp", "(", "-", "3", ")", "*", "1", ")", "\n", "+", "(", "np", ".", "exp", "(", "-", "4", ")", "*", "2", ")", "\n", ")", "/", "partition", "\n", "assert_almost_equal", "(", "decoded_info", "[", "\"loss\"", "]", ".", "data", ".", "numpy", "(", ")", ",", "expected_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.state.State.__init__": [[48, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "batch_indices", ":", "List", "[", "int", "]", ",", "action_history", ":", "List", "[", "List", "[", "int", "]", "]", ",", "score", ":", "List", "[", "torch", ".", "Tensor", "]", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "batch_indices", "=", "batch_indices", "\n", "self", ".", "action_history", "=", "action_history", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.state.State.is_finished": [[55, 62], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        If this state has a ``group_size`` of 1, this returns whether the single action sequence in\n        this state is finished or not.  If this state has a ``group_size`` other than 1, this\n        method raises an error.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.state.State.combine_states": [[63, 69], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "combine_states", "(", "cls", ",", "states", ":", "List", "[", "T", "]", ")", "->", "T", ":", "\n", "        ", "\"\"\"\n        Combines a list of states, each with their own group size, into a single state.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.state.State.__eq__": [[70, 74], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.coverage_state.CoverageState.__init__": [[39, 62], ["allennlp_semparse.state_machines.states.grammar_based_state.GrammarBasedState.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_indices", ":", "List", "[", "int", "]", ",", "\n", "action_history", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "score", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "rnn_state", ":", "List", "[", "RnnStatelet", "]", ",", "\n", "grammar_state", ":", "List", "[", "GrammarStatelet", "]", ",", "\n", "checklist_state", ":", "List", "[", "ChecklistStatelet", "]", ",", "\n", "possible_actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "extras", ":", "List", "[", "Any", "]", "=", "None", ",", "\n", "debug_info", ":", "List", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "batch_indices", "=", "batch_indices", ",", "\n", "action_history", "=", "action_history", ",", "\n", "score", "=", "score", ",", "\n", "rnn_state", "=", "rnn_state", ",", "\n", "grammar_state", "=", "grammar_state", ",", "\n", "possible_actions", "=", "possible_actions", ",", "\n", "extras", "=", "extras", ",", "\n", "debug_info", "=", "debug_info", ",", "\n", ")", "\n", "self", ".", "checklist_state", "=", "checklist_state", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.coverage_state.CoverageState.new_state_from_group_index": [[63, 93], ["super().new_state_from_group_index", "coverage_state.CoverageState.checklist_state[].update", "coverage_state.CoverageState"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.new_state_from_group_index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update"], ["", "def", "new_state_from_group_index", "(", "\n", "self", ",", "\n", "group_index", ":", "int", ",", "\n", "action", ":", "int", ",", "\n", "new_score", ":", "torch", ".", "Tensor", ",", "\n", "new_rnn_state", ":", "RnnStatelet", ",", "\n", "considered_actions", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "action_probabilities", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attention_weights", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", "->", "\"CoverageState\"", ":", "\n", "        ", "super_class_state", "=", "super", "(", ")", ".", "new_state_from_group_index", "(", "\n", "group_index", "=", "group_index", ",", "\n", "action", "=", "action", ",", "\n", "new_score", "=", "new_score", ",", "\n", "new_rnn_state", "=", "new_rnn_state", ",", "\n", "considered_actions", "=", "considered_actions", ",", "\n", "action_probabilities", "=", "action_probabilities", ",", "\n", "attention_weights", "=", "attention_weights", ",", "\n", ")", "\n", "new_checklist", "=", "self", ".", "checklist_state", "[", "group_index", "]", ".", "update", "(", "action", ")", "\n", "return", "CoverageState", "(", "\n", "batch_indices", "=", "super_class_state", ".", "batch_indices", ",", "\n", "action_history", "=", "super_class_state", ".", "action_history", ",", "\n", "score", "=", "super_class_state", ".", "score", ",", "\n", "rnn_state", "=", "super_class_state", ".", "rnn_state", ",", "\n", "grammar_state", "=", "super_class_state", ".", "grammar_state", ",", "\n", "checklist_state", "=", "[", "new_checklist", "]", ",", "\n", "possible_actions", "=", "super_class_state", ".", "possible_actions", ",", "\n", "extras", "=", "super_class_state", ".", "extras", ",", "\n", "debug_info", "=", "super_class_state", ".", "debug_info", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.coverage_state.CoverageState.combine_states": [[95, 111], ["super().combine_states", "coverage_state.CoverageState"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.combine_states"], ["", "@", "classmethod", "\n", "def", "combine_states", "(", "cls", ",", "states", ":", "Sequence", "[", "\"CoverageState\"", "]", ")", "->", "\"CoverageState\"", ":", "# type: ignore", "\n", "        ", "super_class_state", "=", "super", "(", ")", ".", "combine_states", "(", "states", ")", "\n", "checklist_states", "=", "[", "\n", "checklist_state", "for", "state", "in", "states", "for", "checklist_state", "in", "state", ".", "checklist_state", "\n", "]", "\n", "return", "CoverageState", "(", "\n", "batch_indices", "=", "super_class_state", ".", "batch_indices", ",", "\n", "action_history", "=", "super_class_state", ".", "action_history", ",", "\n", "score", "=", "super_class_state", ".", "score", ",", "\n", "rnn_state", "=", "super_class_state", ".", "rnn_state", ",", "\n", "grammar_state", "=", "super_class_state", ".", "grammar_state", ",", "\n", "checklist_state", "=", "checklist_states", ",", "\n", "possible_actions", "=", "super_class_state", ".", "possible_actions", ",", "\n", "extras", "=", "super_class_state", ".", "extras", ",", "\n", "debug_info", "=", "super_class_state", ".", "debug_info", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.coverage_state.CoverageState.__eq__": [[113, 129], ["isinstance", "all", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "all", "(", "\n", "[", "\n", "self", ".", "batch_indices", "==", "other", ".", "batch_indices", ",", "\n", "self", ".", "action_history", "==", "other", ".", "action_history", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "score", ",", "other", ".", "score", ",", "tolerance", "=", "1e-3", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "rnn_state", ",", "other", ".", "rnn_state", ",", "tolerance", "=", "1e-4", ")", ",", "\n", "self", ".", "grammar_state", "==", "other", ".", "grammar_state", ",", "\n", "self", ".", "checklist_state", "==", "other", ".", "checklist_state", ",", "\n", "self", ".", "possible_actions", "==", "other", ".", "possible_actions", ",", "\n", "self", ".", "extras", "==", "other", ".", "extras", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "debug_info", ",", "other", ".", "debug_info", ",", "tolerance", "=", "1e-6", ")", ",", "\n", "]", "\n", ")", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.__init__": [[57, 74], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_indices", ":", "List", "[", "int", "]", ",", "\n", "action_history", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "score", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "rnn_state", ":", "List", "[", "RnnStatelet", "]", ",", "\n", "grammar_state", ":", "List", "[", "GrammarStatelet", "]", ",", "\n", "possible_actions", ":", "List", "[", "List", "[", "ProductionRule", "]", "]", ",", "\n", "extras", ":", "List", "[", "Any", "]", "=", "None", ",", "\n", "debug_info", ":", "List", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "batch_indices", ",", "action_history", ",", "score", ")", "\n", "self", ".", "rnn_state", "=", "rnn_state", "\n", "self", ".", "grammar_state", "=", "grammar_state", "\n", "self", ".", "possible_actions", "=", "possible_actions", "\n", "self", ".", "extras", "=", "extras", "\n", "self", ".", "debug_info", "=", "debug_info", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.new_state_from_group_index": [[75, 108], ["grammar_based_state.GrammarBasedState.grammar_state[].take_action", "grammar_based_state.GrammarBasedState"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["", "def", "new_state_from_group_index", "(", "\n", "self", ",", "\n", "group_index", ":", "int", ",", "\n", "action", ":", "int", ",", "\n", "new_score", ":", "torch", ".", "Tensor", ",", "\n", "new_rnn_state", ":", "RnnStatelet", ",", "\n", "considered_actions", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "action_probabilities", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attention_weights", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", "->", "\"GrammarBasedState\"", ":", "\n", "        ", "batch_index", "=", "self", ".", "batch_indices", "[", "group_index", "]", "\n", "new_action_history", "=", "self", ".", "action_history", "[", "group_index", "]", "+", "[", "action", "]", "\n", "production_rule", "=", "self", ".", "possible_actions", "[", "batch_index", "]", "[", "action", "]", "[", "0", "]", "\n", "new_grammar_state", "=", "self", ".", "grammar_state", "[", "group_index", "]", ".", "take_action", "(", "production_rule", ")", "\n", "if", "self", ".", "debug_info", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention_weights", "[", "group_index", "]", "if", "attention_weights", "is", "not", "None", "else", "None", "\n", "debug_info", "=", "{", "\n", "\"considered_actions\"", ":", "considered_actions", ",", "\n", "\"question_attention\"", ":", "attention", ",", "\n", "\"probabilities\"", ":", "action_probabilities", ",", "\n", "}", "\n", "new_debug_info", "=", "[", "self", ".", "debug_info", "[", "group_index", "]", "+", "[", "debug_info", "]", "]", "\n", "", "else", ":", "\n", "            ", "new_debug_info", "=", "None", "\n", "", "return", "GrammarBasedState", "(", "\n", "batch_indices", "=", "[", "batch_index", "]", ",", "\n", "action_history", "=", "[", "new_action_history", "]", ",", "\n", "score", "=", "[", "new_score", "]", ",", "\n", "rnn_state", "=", "[", "new_rnn_state", "]", ",", "\n", "grammar_state", "=", "[", "new_grammar_state", "]", ",", "\n", "possible_actions", "=", "self", ".", "possible_actions", ",", "\n", "extras", "=", "self", ".", "extras", ",", "\n", "debug_info", "=", "new_debug_info", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.print_action_history": [[110, 123], ["zip", "print", "score.detach().cpu().numpy", "score.detach().cpu", "score.detach"], "methods", ["None"], ["", "def", "print_action_history", "(", "self", ",", "group_index", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "scores", "=", "self", ".", "score", "if", "group_index", "is", "None", "else", "[", "self", ".", "score", "[", "group_index", "]", "]", "\n", "batch_indices", "=", "(", "\n", "self", ".", "batch_indices", "if", "group_index", "is", "None", "else", "[", "self", ".", "batch_indices", "[", "group_index", "]", "]", "\n", ")", "\n", "histories", "=", "(", "\n", "self", ".", "action_history", "if", "group_index", "is", "None", "else", "[", "self", ".", "action_history", "[", "group_index", "]", "]", "\n", ")", "\n", "for", "score", ",", "batch_index", ",", "action_history", "in", "zip", "(", "scores", ",", "batch_indices", ",", "histories", ")", ":", "\n", "            ", "print", "(", "\n", "\"  \"", ",", "\n", "score", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", ",", "\n", "[", "self", ".", "possible_actions", "[", "batch_index", "]", "[", "action", "]", "[", "0", "]", "for", "action", "in", "action_history", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.get_valid_actions": [[125, 130], ["state.get_valid_actions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "", "def", "get_valid_actions", "(", "self", ")", "->", "List", "[", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns a list of valid actions for each element of the group.\n        \"\"\"", "\n", "return", "[", "state", ".", "get_valid_actions", "(", ")", "for", "state", "in", "self", ".", "grammar_state", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.is_finished": [[131, 135], ["grammar_based_state.GrammarBasedState.grammar_state[].is_finished", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished"], ["", "def", "is_finished", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "len", "(", "self", ".", "batch_indices", ")", "!=", "1", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"is_finished() is only defined with a group_size of 1\"", ")", "\n", "", "return", "self", ".", "grammar_state", "[", "0", "]", ".", "is_finished", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_based_state.GrammarBasedState.combine_states": [[136, 160], ["grammar_based_state.GrammarBasedState"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "combine_states", "(", "cls", ",", "states", ":", "Sequence", "[", "\"GrammarBasedState\"", "]", ")", "->", "\"GrammarBasedState\"", ":", "\n", "        ", "batch_indices", "=", "[", "batch_index", "for", "state", "in", "states", "for", "batch_index", "in", "state", ".", "batch_indices", "]", "\n", "action_histories", "=", "[", "\n", "action_history", "for", "state", "in", "states", "for", "action_history", "in", "state", ".", "action_history", "\n", "]", "\n", "scores", "=", "[", "score", "for", "state", "in", "states", "for", "score", "in", "state", ".", "score", "]", "\n", "rnn_states", "=", "[", "rnn_state", "for", "state", "in", "states", "for", "rnn_state", "in", "state", ".", "rnn_state", "]", "\n", "grammar_states", "=", "[", "\n", "grammar_state", "for", "state", "in", "states", "for", "grammar_state", "in", "state", ".", "grammar_state", "\n", "]", "\n", "if", "states", "[", "0", "]", ".", "debug_info", "is", "not", "None", ":", "\n", "            ", "debug_info", "=", "[", "debug_info", "for", "state", "in", "states", "for", "debug_info", "in", "state", ".", "debug_info", "]", "\n", "", "else", ":", "\n", "            ", "debug_info", "=", "None", "\n", "", "return", "GrammarBasedState", "(", "\n", "batch_indices", "=", "batch_indices", ",", "\n", "action_history", "=", "action_histories", ",", "\n", "score", "=", "scores", ",", "\n", "rnn_state", "=", "rnn_states", ",", "\n", "grammar_state", "=", "grammar_states", ",", "\n", "possible_actions", "=", "states", "[", "0", "]", ".", "possible_actions", ",", "\n", "extras", "=", "states", "[", "0", "]", ".", "extras", ",", "\n", "debug_info", "=", "debug_info", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet.LambdaGrammarStatelet.__init__": [[59, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nonterminal_stack", ":", "List", "[", "str", "]", ",", "\n", "lambda_stacks", ":", "Dict", "[", "Tuple", "[", "str", ",", "str", "]", ",", "List", "[", "str", "]", "]", ",", "\n", "valid_actions", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", "]", ",", "\n", "context_actions", ":", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "int", "]", "]", ",", "\n", "is_nonterminal", ":", "Callable", "[", "[", "str", "]", ",", "bool", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_nonterminal_stack", "=", "nonterminal_stack", "\n", "self", ".", "_lambda_stacks", "=", "lambda_stacks", "\n", "self", ".", "_valid_actions", "=", "valid_actions", "\n", "self", ".", "_context_actions", "=", "context_actions", "\n", "self", ".", "_is_nonterminal", "=", "is_nonterminal", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet.LambdaGrammarStatelet.is_finished": [[73, 79], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Have we finished producing our logical form?  We have finished producing the logical form\n        if and only if there are no more non-terminals on the stack.\n        \"\"\"", "\n", "return", "not", "self", ".", "_nonterminal_stack", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet.LambdaGrammarStatelet.get_valid_actions": [[80, 104], ["torch.cat", "torch.cat", "context_actions.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_valid_actions", "(", "self", ")", "->", "Dict", "[", "str", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns the valid actions in the current grammar state.  See the class docstring for a\n        description of what we're returning here.\n        \"\"\"", "\n", "actions", "=", "self", ".", "_valid_actions", "[", "self", ".", "_nonterminal_stack", "[", "-", "1", "]", "]", "\n", "context_actions", "=", "[", "]", "\n", "for", "type_", ",", "variable", "in", "self", ".", "_lambda_stacks", ":", "\n", "            ", "if", "self", ".", "_nonterminal_stack", "[", "-", "1", "]", "==", "type_", ":", "\n", "                ", "production_string", "=", "f\"{type_} -> {variable}\"", "\n", "context_actions", ".", "append", "(", "self", ".", "_context_actions", "[", "production_string", "]", ")", "\n", "", "", "if", "context_actions", ":", "\n", "            ", "input_tensor", ",", "output_tensor", ",", "action_ids", "=", "actions", "[", "\"global\"", "]", "\n", "new_inputs", "=", "[", "input_tensor", "]", "+", "[", "x", "[", "0", "]", "for", "x", "in", "context_actions", "]", "\n", "input_tensor", "=", "torch", ".", "cat", "(", "new_inputs", ",", "dim", "=", "0", ")", "\n", "new_outputs", "=", "[", "output_tensor", "]", "+", "[", "x", "[", "1", "]", "for", "x", "in", "context_actions", "]", "\n", "output_tensor", "=", "torch", ".", "cat", "(", "new_outputs", ",", "dim", "=", "0", ")", "\n", "new_action_ids", "=", "action_ids", "+", "[", "x", "[", "2", "]", "for", "x", "in", "context_actions", "]", "\n", "# We can't just reassign to actions['global'], because that would modify the state of", "\n", "# self._valid_actions.  Instead, we need to construct a new actions dictionary.", "\n", "new_actions", "=", "{", "**", "actions", "}", "\n", "new_actions", "[", "\"global\"", "]", "=", "(", "input_tensor", ",", "output_tensor", ",", "new_action_ids", ")", "\n", "actions", "=", "new_actions", "\n", "", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet.LambdaGrammarStatelet.take_action": [[105, 166], ["production_rule.split", "all", "lambda_grammar_statelet.LambdaGrammarStatelet._get_productions_from_string", "reversed", "lambda_grammar_statelet.LambdaGrammarStatelet", "lambda_grammar_statelet.LambdaGrammarStatelet._is_nonterminal", "production.split", "len", "NotImplementedError", "new_stack.append", "new_lambda_stacks.values", "lambda_stack.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet._get_productions_from_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "take_action", "(", "self", ",", "production_rule", ":", "str", ")", "->", "\"LambdaGrammarStatelet\"", ":", "\n", "        ", "\"\"\"\n        Takes an action in the current grammar state, returning a new grammar state with whatever\n        updates are necessary.  The production rule is assumed to be formatted as \"LHS -> RHS\".\n\n        This will update the non-terminal stack and the context-dependent actions.  Updating the\n        non-terminal stack involves popping the non-terminal that was expanded off of the stack,\n        then pushing on any non-terminals in the production rule back on the stack.  We push the\n        non-terminals on in `reverse` order, so that the first non-terminal in the production rule\n        gets popped off the stack first.\n\n        For example, if our current ``nonterminal_stack`` is ``[\"r\", \"<e,r>\", \"d\"]``, and\n        ``action`` is ``d -> [<e,d>, e]``, the resulting stack will be ``[\"r\", \"<e,r>\", \"e\",\n        \"<e,d>\"]``.\n        \"\"\"", "\n", "left_side", ",", "right_side", "=", "production_rule", ".", "split", "(", "\" -> \"", ")", "\n", "assert", "self", ".", "_nonterminal_stack", "[", "-", "1", "]", "==", "left_side", ",", "(", "\n", "f\"Tried to expand {self._nonterminal_stack[-1]}\"", "\n", "f\"but got rule {left_side} -> {right_side}\"", "\n", ")", "\n", "assert", "all", "(", "self", ".", "_lambda_stacks", "[", "key", "]", "[", "-", "1", "]", "==", "left_side", "for", "key", "in", "self", ".", "_lambda_stacks", ")", "\n", "\n", "new_stack", "=", "self", ".", "_nonterminal_stack", "[", ":", "-", "1", "]", "\n", "new_lambda_stacks", "=", "{", "key", ":", "self", ".", "_lambda_stacks", "[", "key", "]", "[", ":", "-", "1", "]", "for", "key", "in", "self", ".", "_lambda_stacks", "}", "\n", "\n", "productions", "=", "self", ".", "_get_productions_from_string", "(", "right_side", ")", "\n", "# Looking for lambda productions, but not for cells or columns with the word \"lambda\" in", "\n", "# them.", "\n", "if", "\"lambda\"", "in", "productions", "[", "0", "]", "and", "\"fb:\"", "not", "in", "productions", "[", "0", "]", ":", "\n", "            ", "production", "=", "productions", "[", "0", "]", "\n", "if", "production", "[", "0", "]", "==", "\"'\"", "and", "production", "[", "-", "1", "]", "==", "\"'\"", ":", "\n", "# The production rule with a lambda is typically \"<t,d> -> ['lambda x', d]\".  We", "\n", "# need to strip the quotes.", "\n", "                ", "production", "=", "production", "[", "1", ":", "-", "1", "]", "\n", "", "lambda_variable", "=", "production", ".", "split", "(", "\" \"", ")", "[", "1", "]", "\n", "# The left side must be formatted as \"<t,d>\", where \"t\" is the type of the lambda", "\n", "# variable, and \"d\" is the return type of the lambda function.  We need to pull out the", "\n", "# \"t\" here.  TODO(mattg): this is pretty limiting, but I'm not sure how general we", "\n", "# should make this.", "\n", "if", "len", "(", "left_side", ")", "!=", "5", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Can't handle this type yet:\"", ",", "left_side", ")", "\n", "", "lambda_type", "=", "left_side", "[", "1", "]", "\n", "new_lambda_stacks", "[", "(", "lambda_type", ",", "lambda_variable", ")", "]", "=", "[", "]", "\n", "\n", "", "for", "production", "in", "reversed", "(", "productions", ")", ":", "\n", "            ", "if", "self", ".", "_is_nonterminal", "(", "production", ")", ":", "\n", "                ", "new_stack", ".", "append", "(", "production", ")", "\n", "for", "lambda_stack", "in", "new_lambda_stacks", ".", "values", "(", ")", ":", "\n", "                    ", "lambda_stack", ".", "append", "(", "production", ")", "\n", "\n", "# If any of the lambda stacks have now become empty, we remove them from our dictionary.", "\n", "", "", "", "new_lambda_stacks", "=", "{", "\n", "key", ":", "new_lambda_stacks", "[", "key", "]", "for", "key", "in", "new_lambda_stacks", "if", "new_lambda_stacks", "[", "key", "]", "\n", "}", "\n", "\n", "return", "LambdaGrammarStatelet", "(", "\n", "nonterminal_stack", "=", "new_stack", ",", "\n", "lambda_stacks", "=", "new_lambda_stacks", ",", "\n", "valid_actions", "=", "self", ".", "_valid_actions", ",", "\n", "context_actions", "=", "self", ".", "_context_actions", ",", "\n", "is_nonterminal", "=", "self", ".", "_is_nonterminal", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet.LambdaGrammarStatelet._get_productions_from_string": [[168, 179], ["production_string[].split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_productions_from_string", "(", "production_string", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Takes a string like '[<d,d>, d]' and parses it into a list like ['<d,d>', 'd'].  For\n        production strings that are not lists, like '<e,d>', we return a single-element list:\n        ['<e,d>'].\n        \"\"\"", "\n", "if", "production_string", "[", "0", "]", "==", "\"[\"", ":", "\n", "            ", "return", "production_string", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "production_string", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet.LambdaGrammarStatelet.__eq__": [[180, 192], ["isinstance", "all", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal"], "methods", ["None"], ["", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "all", "(", "\n", "[", "\n", "self", ".", "_nonterminal_stack", "==", "other", ".", "_nonterminal_stack", ",", "\n", "self", ".", "_lambda_stacks", "==", "other", ".", "_lambda_stacks", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "_valid_actions", ",", "other", ".", "_valid_actions", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "_context_actions", ",", "other", ".", "_context_actions", ")", ",", "\n", "self", ".", "_is_nonterminal", "==", "other", ".", "_is_nonterminal", ",", "\n", "]", "\n", ")", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.rnn_statelet.RnnStatelet.__init__": [[49, 64], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", ",", "\n", "memory_cell", ":", "torch", ".", "Tensor", ",", "\n", "previous_action_embedding", ":", "torch", ".", "Tensor", ",", "\n", "attended_input", ":", "torch", ".", "Tensor", ",", "\n", "encoder_outputs", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "encoder_output_mask", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "hidden_state", "=", "hidden_state", "\n", "self", ".", "memory_cell", "=", "memory_cell", "\n", "self", ".", "previous_action_embedding", "=", "previous_action_embedding", "\n", "self", ".", "attended_input", "=", "attended_input", "\n", "self", ".", "encoder_outputs", "=", "encoder_outputs", "\n", "self", ".", "encoder_output_mask", "=", "encoder_output_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.rnn_statelet.RnnStatelet.__eq__": [[65, 84], ["isinstance", "all", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "all", "(", "\n", "[", "\n", "util", ".", "tensors_equal", "(", "self", ".", "hidden_state", ",", "other", ".", "hidden_state", ",", "tolerance", "=", "1e-5", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "memory_cell", ",", "other", ".", "memory_cell", ",", "tolerance", "=", "1e-5", ")", ",", "\n", "util", ".", "tensors_equal", "(", "\n", "self", ".", "previous_action_embedding", ",", "\n", "other", ".", "previous_action_embedding", ",", "\n", "tolerance", "=", "1e-5", ",", "\n", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "attended_input", ",", "other", ".", "attended_input", ",", "tolerance", "=", "1e-5", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "encoder_outputs", ",", "other", ".", "encoder_outputs", ",", "tolerance", "=", "1e-5", ")", ",", "\n", "util", ".", "tensors_equal", "(", "\n", "self", ".", "encoder_output_mask", ",", "other", ".", "encoder_output_mask", ",", "tolerance", "=", "1e-5", "\n", ")", ",", "\n", "]", "\n", ")", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.__init__": [[47, 58], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nonterminal_stack", ":", "List", "[", "str", "]", ",", "\n", "valid_actions", ":", "Dict", "[", "str", ",", "ActionRepresentation", "]", ",", "\n", "is_nonterminal", ":", "Callable", "[", "[", "str", "]", ",", "bool", "]", ",", "\n", "reverse_productions", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "_nonterminal_stack", "=", "nonterminal_stack", "\n", "self", ".", "_valid_actions", "=", "valid_actions", "\n", "self", ".", "_is_nonterminal", "=", "is_nonterminal", "\n", "self", ".", "_reverse_productions", "=", "reverse_productions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished": [[59, 65], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Have we finished producing our logical form?  We have finished producing the logical form\n        if and only if there are no more non-terminals on the stack.\n        \"\"\"", "\n", "return", "not", "self", ".", "_nonterminal_stack", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions": [[66, 72], ["None"], "methods", ["None"], ["", "def", "get_valid_actions", "(", "self", ")", "->", "ActionRepresentation", ":", "\n", "        ", "\"\"\"\n        Returns the valid actions in the current grammar state.  The `Model` determines what\n        exactly this looks like when it constructs the `valid_actions` dictionary.\n        \"\"\"", "\n", "return", "self", ".", "_valid_actions", "[", "self", ".", "_nonterminal_stack", "[", "-", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action": [[73, 111], ["production_rule.split", "grammar_statelet.GrammarStatelet._get_productions_from_string", "grammar_statelet.GrammarStatelet", "list", "grammar_statelet.GrammarStatelet._is_nonterminal", "reversed", "new_stack.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet._get_productions_from_string", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "take_action", "(", "self", ",", "production_rule", ":", "str", ")", "->", "\"GrammarStatelet\"", ":", "\n", "        ", "\"\"\"\n        Takes an action in the current grammar state, returning a new grammar state with whatever\n        updates are necessary.  The production rule is assumed to be formatted as \"LHS -> RHS\".\n\n        This will update the non-terminal stack.  Updating the non-terminal stack involves popping\n        the non-terminal that was expanded off of the stack, then pushing on any non-terminals in\n        the production rule back on the stack.\n\n        For example, if our current ``nonterminal_stack`` is ``[\"r\", \"<e,r>\", \"d\"]``, and\n        ``action`` is ``d -> [<e,d>, e]``, the resulting stack will be ``[\"r\", \"<e,r>\", \"e\",\n        \"<e,d>\"]``.\n\n        If ``self._reverse_productions`` is set to ``False`` then we push the non-terminals on in\n        in their given order, which means that the first non-terminal in the production rule gets\n        popped off the stack `last`.\n        \"\"\"", "\n", "left_side", ",", "right_side", "=", "production_rule", ".", "split", "(", "\" -> \"", ")", "\n", "assert", "self", ".", "_nonterminal_stack", "[", "-", "1", "]", "==", "left_side", ",", "(", "\n", "f\"Tried to expand {self._nonterminal_stack[-1]}\"", "\n", "f\"but got rule {left_side} -> {right_side}\"", "\n", ")", "\n", "\n", "new_stack", "=", "self", ".", "_nonterminal_stack", "[", ":", "-", "1", "]", "\n", "\n", "productions", "=", "self", ".", "_get_productions_from_string", "(", "right_side", ")", "\n", "if", "self", ".", "_reverse_productions", ":", "\n", "            ", "productions", "=", "list", "(", "reversed", "(", "productions", ")", ")", "\n", "\n", "", "for", "production", "in", "productions", ":", "\n", "            ", "if", "self", ".", "_is_nonterminal", "(", "production", ")", ":", "\n", "                ", "new_stack", ".", "append", "(", "production", ")", "\n", "\n", "", "", "return", "GrammarStatelet", "(", "\n", "nonterminal_stack", "=", "new_stack", ",", "\n", "valid_actions", "=", "self", ".", "_valid_actions", ",", "\n", "is_nonterminal", "=", "self", ".", "_is_nonterminal", ",", "\n", "reverse_productions", "=", "self", ".", "_reverse_productions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet._get_productions_from_string": [[113, 124], ["production_string[].split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_productions_from_string", "(", "production_string", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Takes a string like '[<d,d>, d]' and parses it into a list like ['<d,d>', 'd'].  For\n        production strings that are not lists, like '<e,d>', we return a single-element list:\n        ['<e,d>'].\n        \"\"\"", "\n", "if", "production_string", "[", "0", "]", "==", "\"[\"", ":", "\n", "            ", "return", "production_string", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "production_string", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.__eq__": [[125, 136], ["isinstance", "all", "allennlp.nn.util.tensors_equal"], "methods", ["None"], ["", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "all", "(", "\n", "[", "\n", "self", ".", "_nonterminal_stack", "==", "other", ".", "_nonterminal_stack", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "_valid_actions", ",", "other", ".", "_valid_actions", ")", ",", "\n", "self", ".", "_is_nonterminal", ".", "__code__", "==", "other", ".", "_is_nonterminal", ".", "__code__", ",", "\n", "self", ".", "_reverse_productions", "==", "other", ".", "_reverse_productions", ",", "\n", "]", "\n", ")", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.__init__": [[38, 59], ["enumerate", "terminal_actions.detach().cpu", "int", "terminal_actions.detach"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "terminal_actions", ":", "torch", ".", "Tensor", ",", "\n", "checklist_target", ":", "torch", ".", "Tensor", ",", "\n", "checklist_mask", ":", "torch", ".", "Tensor", ",", "\n", "checklist", ":", "torch", ".", "Tensor", ",", "\n", "terminal_indices_dict", ":", "Dict", "[", "int", ",", "int", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "terminal_actions", "=", "terminal_actions", "\n", "self", ".", "checklist_target", "=", "checklist_target", "\n", "self", ".", "checklist_mask", "=", "checklist_mask", "\n", "self", ".", "checklist", "=", "checklist", "\n", "if", "terminal_indices_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "terminal_indices_dict", "=", "terminal_indices_dict", "\n", "", "else", ":", "\n", "            ", "self", ".", "terminal_indices_dict", "=", "{", "}", "\n", "for", "checklist_index", ",", "batch_action_index", "in", "enumerate", "(", "terminal_actions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ":", "\n", "                ", "action_index", "=", "int", "(", "batch_action_index", "[", "0", "]", ")", "\n", "if", "action_index", "==", "-", "1", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "terminal_indices_dict", "[", "action_index", "]", "=", "checklist_index", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update": [[60, 74], ["checklist_statelet.ChecklistStatelet"], "methods", ["None"], ["", "", "", "def", "update", "(", "self", ",", "action", ":", "torch", ".", "Tensor", ")", "->", "\"ChecklistStatelet\"", ":", "\n", "        ", "\"\"\"\n        Takes an action index, updates checklist and returns an updated state.\n        \"\"\"", "\n", "checklist_addition", "=", "(", "self", ".", "terminal_actions", "==", "action", ")", ".", "float", "(", ")", "\n", "new_checklist", "=", "self", ".", "checklist", "+", "checklist_addition", "\n", "new_checklist_state", "=", "ChecklistStatelet", "(", "\n", "terminal_actions", "=", "self", ".", "terminal_actions", ",", "\n", "checklist_target", "=", "self", ".", "checklist_target", ",", "\n", "checklist_mask", "=", "self", ".", "checklist_mask", ",", "\n", "checklist", "=", "new_checklist", ",", "\n", "terminal_indices_dict", "=", "self", ".", "terminal_indices_dict", ",", "\n", ")", "\n", "return", "new_checklist_state", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.get_balance": [[75, 77], ["None"], "methods", ["None"], ["", "def", "get_balance", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "checklist_mask", "*", "(", "self", ".", "checklist_target", "-", "self", ".", "checklist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.__eq__": [[78, 90], ["isinstance", "all", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal", "allennlp.nn.util.tensors_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "all", "(", "\n", "[", "\n", "util", ".", "tensors_equal", "(", "self", ".", "terminal_actions", ",", "other", ".", "terminal_actions", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "checklist_target", ",", "other", ".", "checklist_target", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "checklist_mask", ",", "other", ".", "checklist_mask", ")", ",", "\n", "util", ".", "tensors_equal", "(", "self", ".", "checklist", ",", "other", ".", "checklist", ")", ",", "\n", "self", ".", "terminal_indices_dict", "==", "other", ".", "terminal_indices_dict", ",", "\n", "]", "\n", ")", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet_test.TestGrammarStatelet.test_is_finished_just_uses_nonterminal_stack": [[19, 24], ["allennlp_semparse.state_machines.states.GrammarStatelet", "allennlp_semparse.state_machines.states.GrammarStatelet", "allennlp_semparse.state_machines.states.GrammarStatelet.is_finished", "allennlp_semparse.state_machines.states.GrammarStatelet.is_finished"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished"], ["    ", "def", "test_is_finished_just_uses_nonterminal_stack", "(", "self", ")", ":", "\n", "        ", "state", "=", "GrammarStatelet", "(", "[", "\"s\"", "]", ",", "{", "}", ",", "is_nonterminal", ")", "\n", "assert", "not", "state", ".", "is_finished", "(", ")", "\n", "state", "=", "GrammarStatelet", "(", "[", "]", ",", "{", "}", ",", "is_nonterminal", ")", "\n", "assert", "state", ".", "is_finished", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet_test.TestGrammarStatelet.test_get_valid_actions_uses_top_of_stack": [[25, 37], ["object", "object", "object", "allennlp_semparse.state_machines.states.GrammarStatelet", "allennlp_semparse.state_machines.states.GrammarStatelet", "allennlp_semparse.state_machines.states.GrammarStatelet", "allennlp_semparse.state_machines.states.GrammarStatelet.get_valid_actions", "allennlp_semparse.state_machines.states.GrammarStatelet.get_valid_actions", "allennlp_semparse.state_machines.states.GrammarStatelet.get_valid_actions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions_uses_top_of_stack", "(", "self", ")", ":", "\n", "        ", "s_actions", "=", "object", "(", ")", "\n", "t_actions", "=", "object", "(", ")", "\n", "e_actions", "=", "object", "(", ")", "\n", "state", "=", "GrammarStatelet", "(", "[", "\"s\"", "]", ",", "{", "\"s\"", ":", "s_actions", ",", "\"t\"", ":", "t_actions", "}", ",", "is_nonterminal", ")", "\n", "assert", "state", ".", "get_valid_actions", "(", ")", "==", "s_actions", "\n", "state", "=", "GrammarStatelet", "(", "[", "\"t\"", "]", ",", "{", "\"s\"", ":", "s_actions", ",", "\"t\"", ":", "t_actions", "}", ",", "is_nonterminal", ")", "\n", "assert", "state", ".", "get_valid_actions", "(", ")", "==", "t_actions", "\n", "state", "=", "GrammarStatelet", "(", "\n", "[", "\"e\"", "]", ",", "{", "\"s\"", ":", "s_actions", ",", "\"t\"", ":", "t_actions", ",", "\"e\"", ":", "e_actions", "}", ",", "is_nonterminal", "\n", ")", "\n", "assert", "state", ".", "get_valid_actions", "(", ")", "==", "e_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet_test.TestGrammarStatelet.test_take_action_crashes_with_mismatched_types": [[38, 42], ["pytest.raises", "allennlp_semparse.state_machines.states.GrammarStatelet", "allennlp_semparse.state_machines.states.GrammarStatelet.take_action"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["", "def", "test_take_action_crashes_with_mismatched_types", "(", "self", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "state", "=", "GrammarStatelet", "(", "[", "\"s\"", "]", ",", "{", "}", ",", "is_nonterminal", ")", "\n", "state", ".", "take_action", "(", "\"t -> identity\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet_test.is_nonterminal": [[8, 16], ["None"], "function", ["None"], ["def", "is_nonterminal", "(", "symbol", ":", "str", ")", "->", "bool", ":", "\n", "    ", "if", "symbol", "==", "\"identity\"", ":", "\n", "        ", "return", "False", "\n", "", "if", "\"lambda \"", "in", "symbol", ":", "\n", "        ", "return", "False", "\n", "", "if", "symbol", "in", "{", "\"x\"", ",", "\"y\"", ",", "\"z\"", "}", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_is_finished_just_uses_nonterminal_stack": [[21, 26], ["allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.is_finished", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.is_finished"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.is_finished"], ["    ", "def", "test_is_finished_just_uses_nonterminal_stack", "(", "self", ")", ":", "\n", "        ", "state", "=", "LambdaGrammarStatelet", "(", "[", "\"s\"", "]", ",", "{", "}", ",", "{", "}", ",", "{", "}", ",", "is_nonterminal", ")", "\n", "assert", "not", "state", ".", "is_finished", "(", ")", "\n", "state", "=", "LambdaGrammarStatelet", "(", "[", "]", ",", "{", "}", ",", "{", "}", ",", "{", "}", ",", "is_nonterminal", ")", "\n", "assert", "state", ".", "is_finished", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_get_valid_actions_uses_top_of_stack": [[27, 43], ["object", "object", "object", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions_uses_top_of_stack", "(", "self", ")", ":", "\n", "        ", "s_actions", "=", "object", "(", ")", "\n", "t_actions", "=", "object", "(", ")", "\n", "e_actions", "=", "object", "(", ")", "\n", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"s\"", "]", ",", "{", "}", ",", "{", "\"s\"", ":", "s_actions", ",", "\"t\"", ":", "t_actions", "}", ",", "{", "}", ",", "is_nonterminal", "\n", ")", "\n", "assert", "state", ".", "get_valid_actions", "(", ")", "==", "s_actions", "\n", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", "]", ",", "{", "}", ",", "{", "\"s\"", ":", "s_actions", ",", "\"t\"", ":", "t_actions", "}", ",", "{", "}", ",", "is_nonterminal", "\n", ")", "\n", "assert", "state", ".", "get_valid_actions", "(", ")", "==", "t_actions", "\n", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"e\"", "]", ",", "{", "}", ",", "{", "\"s\"", ":", "s_actions", ",", "\"t\"", ":", "t_actions", ",", "\"e\"", ":", "e_actions", "}", ",", "{", "}", ",", "is_nonterminal", "\n", ")", "\n", "assert", "state", ".", "get_valid_actions", "(", ")", "==", "e_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_get_valid_actions_adds_lambda_productions": [[44, 61], ["allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "[].cpu().numpy", "[].cpu().numpy", "[].cpu().numpy", "[].cpu().numpy", "torch.Tensor", "torch.Tensor", "[].cpu", "[].cpu", "[].cpu", "[].cpu", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions_adds_lambda_productions", "(", "self", ")", ":", "\n", "        ", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"s\"", "]", ",", "\n", "{", "(", "\"s\"", ",", "\"x\"", ")", ":", "[", "\"s\"", "]", "}", ",", "\n", "{", "\"s\"", ":", "{", "\"global\"", ":", "(", "torch", ".", "Tensor", "(", "[", "1", ",", "1", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "2", ",", "2", "]", ")", ",", "[", "1", ",", "2", "]", ")", "}", "}", ",", "\n", "{", "\"s -> x\"", ":", "(", "torch", ".", "Tensor", "(", "[", "5", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "6", "]", ")", ",", "5", ")", "}", ",", "\n", "is_nonterminal", ",", "\n", ")", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "1", ",", "1", ",", "5", "]", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "2", ",", "2", ",", "6", "]", ")", "\n", "assert", "actions", "[", "\"global\"", "]", "[", "2", "]", "==", "[", "1", ",", "2", ",", "5", "]", "\n", "# We're doing this assert twice to make sure we haven't accidentally modified the state.", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "1", ",", "1", ",", "5", "]", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "2", ",", "2", ",", "6", "]", ")", "\n", "assert", "actions", "[", "\"global\"", "]", "[", "2", "]", "==", "[", "1", ",", "2", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_get_valid_actions_adds_lambda_productions_only_for_correct_type": [[62, 82], ["allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.get_valid_actions", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "[].cpu().numpy", "[].cpu().numpy", "[].cpu().numpy", "[].cpu().numpy", "torch.Tensor", "torch.Tensor", "[].cpu", "[].cpu", "[].cpu", "[].cpu", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.get_valid_actions"], ["", "def", "test_get_valid_actions_adds_lambda_productions_only_for_correct_type", "(", "self", ")", ":", "\n", "        ", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", "]", ",", "\n", "{", "(", "\"s\"", ",", "\"x\"", ")", ":", "[", "\"t\"", "]", "}", ",", "\n", "{", "\n", "\"s\"", ":", "{", "\"global\"", ":", "(", "torch", ".", "Tensor", "(", "[", "1", ",", "1", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "2", ",", "2", "]", ")", ",", "[", "1", ",", "2", "]", ")", "}", ",", "\n", "\"t\"", ":", "{", "\"global\"", ":", "(", "torch", ".", "Tensor", "(", "[", "3", ",", "3", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "4", ",", "4", "]", ")", ",", "[", "3", ",", "4", "]", ")", "}", ",", "\n", "}", ",", "\n", "{", "\"s -> x\"", ":", "(", "torch", ".", "Tensor", "(", "[", "5", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "6", "]", ")", ",", "5", ")", "}", ",", "\n", "is_nonterminal", ",", "\n", ")", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "3", ",", "3", "]", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "4", ",", "4", "]", ")", "\n", "assert", "actions", "[", "\"global\"", "]", "[", "2", "]", "==", "[", "3", ",", "4", "]", "\n", "# We're doing this assert twice to make sure we haven't accidentally modified the state.", "\n", "actions", "=", "state", ".", "get_valid_actions", "(", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "3", ",", "3", "]", ")", "\n", "assert_almost_equal", "(", "actions", "[", "\"global\"", "]", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "4", ",", "4", "]", ")", "\n", "assert", "actions", "[", "\"global\"", "]", "[", "2", "]", "==", "[", "3", ",", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_take_action_gives_correct_next_states_with_non_lambda_productions": [[83, 104], ["object", "object", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["", "def", "test_take_action_gives_correct_next_states_with_non_lambda_productions", "(", "self", ")", ":", "\n", "# state.take_action() doesn't read or change these objects, it just passes them through, so", "\n", "# we'll use some sentinels to be sure of that.", "\n", "        ", "valid_actions", "=", "object", "(", ")", "\n", "context_actions", "=", "object", "(", ")", "\n", "\n", "state", "=", "LambdaGrammarStatelet", "(", "[", "\"s\"", "]", ",", "{", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", ")", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"s -> [t, r]\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"r\"", ",", "\"t\"", "]", ",", "{", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "\n", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"r\"", ",", "\"t\"", "]", ",", "{", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"t -> identity\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"r\"", "]", ",", "{", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_take_action_crashes_with_mismatched_types": [[105, 109], ["pytest.raises", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["", "def", "test_take_action_crashes_with_mismatched_types", "(", "self", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "state", "=", "LambdaGrammarStatelet", "(", "[", "\"s\"", "]", ",", "{", "}", ",", "{", "}", ",", "{", "}", ",", "is_nonterminal", ")", "\n", "state", ".", "take_action", "(", "\"t -> identity\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.TestLambdaGrammarStatelet.test_take_action_gives_correct_next_states_with_lambda_productions": [[110, 160], ["object", "object", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet.take_action", "allennlp_semparse.state_machines.states.LambdaGrammarStatelet"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.grammar_statelet.GrammarStatelet.take_action"], ["", "", "def", "test_take_action_gives_correct_next_states_with_lambda_productions", "(", "self", ")", ":", "\n", "# state.take_action() doesn't read or change these objects, it just passes them through, so", "\n", "# we'll use some sentinels to be sure of that.", "\n", "        ", "valid_actions", "=", "object", "(", ")", "\n", "context_actions", "=", "object", "(", ")", "\n", "\n", "state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", ",", "\"<s,d>\"", "]", ",", "{", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"<s,d> -> [lambda x, d]\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", ",", "\"d\"", "]", ",", "{", "(", "\"s\"", ",", "\"x\"", ")", ":", "[", "\"d\"", "]", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "\n", "state", "=", "expected_next_state", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"d -> [<s,r>, d]\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", ",", "\"d\"", ",", "\"<s,r>\"", "]", ",", "\n", "{", "(", "\"s\"", ",", "\"x\"", ")", ":", "[", "\"d\"", ",", "\"<s,r>\"", "]", "}", ",", "\n", "valid_actions", ",", "\n", "context_actions", ",", "\n", "is_nonterminal", ",", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "\n", "state", "=", "expected_next_state", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"<s,r> -> [lambda y, r]\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", ",", "\"d\"", ",", "\"r\"", "]", ",", "\n", "{", "(", "\"s\"", ",", "\"x\"", ")", ":", "[", "\"d\"", ",", "\"r\"", "]", ",", "(", "\"s\"", ",", "\"y\"", ")", ":", "[", "\"r\"", "]", "}", ",", "\n", "valid_actions", ",", "\n", "context_actions", ",", "\n", "is_nonterminal", ",", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "\n", "state", "=", "expected_next_state", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"r -> identity\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", ",", "\"d\"", "]", ",", "{", "(", "\"s\"", ",", "\"x\"", ")", ":", "[", "\"d\"", "]", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "\n", "state", "=", "expected_next_state", "\n", "next_state", "=", "state", ".", "take_action", "(", "\"d -> x\"", ")", "\n", "expected_next_state", "=", "LambdaGrammarStatelet", "(", "\n", "[", "\"t\"", "]", ",", "{", "}", ",", "valid_actions", ",", "context_actions", ",", "is_nonterminal", "\n", ")", "\n", "assert", "next_state", ".", "__dict__", "==", "expected_next_state", ".", "__dict__", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.is_nonterminal": [[10, 18], ["None"], "function", ["None"], ["def", "is_nonterminal", "(", "symbol", ":", "str", ")", "->", "bool", ":", "\n", "    ", "if", "symbol", "==", "\"identity\"", ":", "\n", "        ", "return", "False", "\n", "", "if", "\"lambda \"", "in", "symbol", ":", "\n", "        ", "return", "False", "\n", "", "if", "symbol", "in", "{", "\"x\"", ",", "\"y\"", ",", "\"z\"", "}", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.__init__": [[83, 178], ["allennlp.data.tokenizers.SpacyTokenizer", "knowledge_graph_field.KnowledgeGraphField._tokenizer.batch_tokenize", "len", "max", "entity_text_fields.append", "allennlp.data.fields.ListField", "allennlp.data.fields.TextField().empty_field", "allennlp.data.fields.ListField().empty_field", "getattr", "knowledge_graph_field.KnowledgeGraphField._feature_extractors.append", "zip", "zip", "zip", "knowledge_graph_field.KnowledgeGraphField._compute_linking_features", "knowledge_graph.entity_text[].lower", "int", "allennlp.data.fields.TextField", "allennlp.common.checks.ConfigurationError", "set", "set", "len", "allennlp.data.fields.TextField", "allennlp.data.fields.ListField"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.empty_field", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.empty_field", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._compute_linking_features"], ["def", "__init__", "(", "\n", "self", ",", "\n", "knowledge_graph", ":", "KnowledgeGraph", ",", "\n", "utterance_tokens", ":", "List", "[", "Token", "]", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "feature_extractors", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "entity_tokens", ":", "List", "[", "List", "[", "Token", "]", "]", "=", "None", ",", "\n", "linking_features", ":", "List", "[", "List", "[", "List", "[", "float", "]", "]", "]", "=", "None", ",", "\n", "include_in_vocab", ":", "bool", "=", "True", ",", "\n", "max_table_tokens", ":", "int", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "knowledge_graph", "=", "knowledge_graph", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "SpacyTokenizer", "(", "pos_tags", "=", "True", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "if", "not", "entity_tokens", ":", "\n", "            ", "entity_texts", "=", "[", "\n", "knowledge_graph", ".", "entity_text", "[", "entity", "]", ".", "lower", "(", ")", "for", "entity", "in", "knowledge_graph", ".", "entities", "\n", "]", "\n", "# TODO(mattg): Because we do tagging on each of these entities in addition to just", "\n", "# tokenizations, this is quite slow, and about half of our data processing time just", "\n", "# goes to this (~15 minutes when there are 7k instances).  The reason we do tagging is", "\n", "# so that we can add lemma features.  If we can remove the need for lemma / other", "\n", "# hand-written features, like with a CNN, we can cut down our data processing time by a", "\n", "# factor of 2.", "\n", "self", ".", "entity_texts", "=", "self", ".", "_tokenizer", ".", "batch_tokenize", "(", "entity_texts", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "entity_texts", "=", "entity_tokens", "\n", "", "entity_text_fields", "=", "[", "]", "\n", "max_entity_tokens", "=", "None", "\n", "if", "max_table_tokens", ":", "\n", "            ", "num_entities", "=", "len", "(", "self", ".", "entity_texts", ")", "\n", "num_entity_tokens", "=", "max", "(", "len", "(", "entity_text", ")", "for", "entity_text", "in", "self", ".", "entity_texts", ")", "\n", "# This truncates the number of entity tokens used, enabling larger tables (either in", "\n", "# the number of entities in the table, or the number of tokens per entity) to fit in", "\n", "# memory, particularly when using ELMo.", "\n", "if", "num_entities", "*", "num_entity_tokens", ">", "max_table_tokens", ":", "\n", "                ", "max_entity_tokens", "=", "int", "(", "max_table_tokens", "/", "num_entities", ")", "\n", "", "", "for", "entity_text", "in", "self", ".", "entity_texts", ":", "\n", "            ", "if", "max_entity_tokens", ":", "\n", "                ", "entity_text", "=", "entity_text", "[", ":", "max_entity_tokens", "]", "\n", "", "entity_text_fields", ".", "append", "(", "TextField", "(", "entity_text", ",", "token_indexers", ")", ")", "\n", "", "if", "self", ".", "entity_texts", ":", "\n", "            ", "self", ".", "_entity_text_field", "=", "ListField", "(", "entity_text_fields", ")", "\n", "", "else", ":", "\n", "            ", "empty_text_field", "=", "TextField", "(", "[", "]", ",", "self", ".", "_token_indexers", ")", ".", "empty_field", "(", ")", "\n", "self", ".", "_entity_text_field", "=", "ListField", "(", "[", "empty_text_field", "]", ")", ".", "empty_field", "(", ")", "\n", "", "self", ".", "utterance_tokens", "=", "utterance_tokens", "\n", "self", ".", "_include_in_vocab", "=", "include_in_vocab", "\n", "\n", "feature_extractors", "=", "(", "\n", "feature_extractors", "\n", "if", "feature_extractors", "is", "not", "None", "\n", "else", "[", "\n", "\"number_token_match\"", ",", "\n", "\"exact_token_match\"", ",", "\n", "\"contains_exact_token_match\"", ",", "\n", "\"lemma_match\"", ",", "\n", "\"contains_lemma_match\"", ",", "\n", "\"edit_distance\"", ",", "\n", "\"related_column\"", ",", "\n", "\"related_column_lemma\"", ",", "\n", "\"span_overlap_fraction\"", ",", "\n", "\"span_lemma_overlap_fraction\"", ",", "\n", "]", "\n", ")", "\n", "self", ".", "_feature_extractors", ":", "List", "[", "\n", "Callable", "[", "[", "str", ",", "List", "[", "Token", "]", ",", "Token", ",", "int", ",", "List", "[", "Token", "]", "]", ",", "float", "]", "\n", "]", "=", "[", "]", "\n", "for", "feature_extractor_name", "in", "feature_extractors", ":", "\n", "            ", "extractor", "=", "getattr", "(", "self", ",", "\"_\"", "+", "feature_extractor_name", ",", "None", ")", "\n", "if", "not", "extractor", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "f\"Invalid feature extractor name: {feature_extractor_name}\"", "\n", ")", "\n", "", "self", ".", "_feature_extractors", ".", "append", "(", "extractor", ")", "\n", "\n", "", "if", "not", "linking_features", ":", "\n", "# For quicker lookups in our feature functions, we'll additionally store some", "\n", "# dictionaries that map entity strings to useful information about the entity.", "\n", "            ", "self", ".", "_entity_text_map", ":", "Dict", "[", "str", ",", "List", "[", "Token", "]", "]", "=", "{", "}", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "                ", "self", ".", "_entity_text_map", "[", "entity", "]", "=", "entity_text", "\n", "\n", "", "self", ".", "_entity_text_exact_text", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "{", "}", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "                ", "self", ".", "_entity_text_exact_text", "[", "entity", "]", "=", "set", "(", "e", ".", "text", "for", "e", "in", "entity_text", ")", "\n", "\n", "", "self", ".", "_entity_text_lemmas", ":", "Dict", "[", "str", ",", "Set", "[", "str", "]", "]", "=", "{", "}", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "                ", "self", ".", "_entity_text_lemmas", "[", "entity", "]", "=", "set", "(", "e", ".", "lemma_", "for", "e", "in", "entity_text", ")", "\n", "", "self", ".", "linking_features", "=", "self", ".", "_compute_linking_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linking_features", "=", "linking_features", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.count_vocab_items": [[179, 183], ["knowledge_graph_field.KnowledgeGraphField._entity_text_field.count_vocab_items"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.count_vocab_items"], ["", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_include_in_vocab", ":", "\n", "            ", "self", ".", "_entity_text_field", ".", "count_vocab_items", "(", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.index": [[184, 187], ["knowledge_graph_field.KnowledgeGraphField._entity_text_field.index"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index"], ["", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "self", ".", "_entity_text_field", ".", "index", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.__len__": [[188, 190], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "utterance_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.get_padding_lengths": [[191, 199], ["padding_lengths.update", "len", "len", "knowledge_graph_field.KnowledgeGraphField._entity_text_field.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.checklist_statelet.ChecklistStatelet.update", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "padding_lengths", "=", "{", "\n", "\"num_entities\"", ":", "len", "(", "self", ".", "entity_texts", ")", ",", "\n", "\"num_utterance_tokens\"", ":", "len", "(", "self", ".", "utterance_tokens", ")", ",", "\n", "}", "\n", "padding_lengths", ".", "update", "(", "self", ".", "_entity_text_field", ".", "get_padding_lengths", "(", ")", ")", "\n", "return", "padding_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.as_tensor": [[200, 220], ["knowledge_graph_field.KnowledgeGraphField._entity_text_field.as_tensor", "allennlp.common.util.pad_sequence_to_length", "torch.FloatTensor", "allennlp.common.util.pad_sequence_to_length", "padded_linking_arrays.append", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "text_tensors", "=", "self", ".", "_entity_text_field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "padded_linking_features", "=", "util", ".", "pad_sequence_to_length", "(", "\n", "self", ".", "linking_features", ",", "padding_lengths", "[", "\"num_entities\"", "]", ",", "default_value", "=", "lambda", ":", "[", "]", "\n", ")", "\n", "padded_linking_arrays", "=", "[", "]", "\n", "\n", "def", "default_feature_value", "(", ")", ":", "\n", "            ", "return", "[", "0.0", "]", "*", "len", "(", "self", ".", "_feature_extractors", ")", "\n", "\n", "", "for", "linking_features", "in", "padded_linking_features", ":", "\n", "            ", "padded_features", "=", "util", ".", "pad_sequence_to_length", "(", "\n", "linking_features", ",", "\n", "padding_lengths", "[", "\"num_utterance_tokens\"", "]", ",", "\n", "default_value", "=", "default_feature_value", ",", "\n", ")", "\n", "padded_linking_arrays", ".", "append", "(", "padded_features", ")", "\n", "", "linking_features_tensor", "=", "torch", ".", "FloatTensor", "(", "padded_linking_arrays", ")", "\n", "return", "{", "\"text\"", ":", "text_tensors", ",", "\"linking\"", ":", "linking_features_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._compute_linking_features": [[221, 236], ["zip", "enumerate", "linking_features.append", "entity_features.append", "token_features.append", "feature_extractor"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "_compute_linking_features", "(", "self", ")", "->", "List", "[", "List", "[", "List", "[", "float", "]", "]", "]", ":", "\n", "        ", "linking_features", "=", "[", "]", "\n", "for", "entity", ",", "entity_text", "in", "zip", "(", "self", ".", "knowledge_graph", ".", "entities", ",", "self", ".", "entity_texts", ")", ":", "\n", "            ", "entity_features", "=", "[", "]", "\n", "for", "token_index", ",", "token", "in", "enumerate", "(", "self", ".", "utterance_tokens", ")", ":", "\n", "                ", "token_features", "=", "[", "]", "\n", "for", "feature_extractor", "in", "self", ".", "_feature_extractors", ":", "\n", "                    ", "token_features", ".", "append", "(", "\n", "feature_extractor", "(", "\n", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "self", ".", "utterance_tokens", "\n", ")", "\n", ")", "\n", "", "entity_features", ".", "append", "(", "token_features", ")", "\n", "", "linking_features", ".", "append", "(", "entity_features", ")", "\n", "", "return", "linking_features", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.empty_field": [[237, 240], ["knowledge_graph_field.KnowledgeGraphField", "allennlp_semparse.common.knowledge_graph.KnowledgeGraph", "set"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", "->", "\"KnowledgeGraphField\"", ":", "\n", "        ", "return", "KnowledgeGraphField", "(", "KnowledgeGraph", "(", "set", "(", ")", ",", "{", "}", ")", ",", "[", "]", ",", "self", ".", "_token_indexers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField.batch_tensors": [[241, 247], ["knowledge_graph_field.KnowledgeGraphField._entity_text_field.batch_tensors", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.batch_tensors"], ["", "@", "overrides", "\n", "def", "batch_tensors", "(", "self", ",", "tensor_list", ":", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "text_tensors", "=", "[", "tensor", "[", "\"text\"", "]", "for", "tensor", "in", "tensor_list", "]", "\n", "batched_text", "=", "self", ".", "_entity_text_field", ".", "batch_tensors", "(", "text_tensors", ")", "\n", "batched_linking", "=", "torch", ".", "stack", "(", "[", "tensor", "[", "\"linking\"", "]", "for", "tensor", "in", "tensor_list", "]", ")", "\n", "return", "{", "\"text\"", ":", "batched_text", ",", "\"linking\"", ":", "batched_linking", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._number_token_match": [[270, 294], ["knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match"], ["", "def", "_number_token_match", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "# PNP had a \"spanFeatures\" function that said whether an entity was a-priori known to link", "\n", "# to a token or set of tokens in the question.  This was only used for numbers, and it's", "\n", "# not totally clear to me how this number feature overlapped with the token match features", "\n", "# in the original implementation (I think in most cases it was the same, except for things", "\n", "# like \"four million\", because the token match is derived from the entity name, which would", "\n", "# be 4000000, and wouldn't match \"four million\").", "\n", "#", "\n", "# Our implementation basically just adds a duplicate token match feature that's specific to", "\n", "# numbers.  It'll break in some rare cases (e.g., \"Which four had four million ...\"), but", "\n", "# those shouldn't be a big deal.", "\n", "        ", "if", "\":\"", "in", "entity", ":", "\n", "# This check works because numbers are the only entities that don't contain \":\". All", "\n", "# others in both WikiTables languages do (e.g.: fb:row.row.column_name,", "\n", "# date_column:year, string:usl_a_league etc.).", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_contains_exact_token_match", "(", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._exact_token_match": [[295, 306], ["knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match"], ["", "def", "_exact_token_match", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "if", "len", "(", "entity_text", ")", "!=", "1", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_contains_exact_token_match", "(", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._contains_exact_token_match": [[307, 318], ["None"], "methods", ["None"], ["", "def", "_contains_exact_token_match", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "entity", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._lemma_match": [[319, 330], ["knowledge_graph_field.KnowledgeGraphField._contains_lemma_match", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._contains_lemma_match"], ["", "def", "_lemma_match", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "if", "len", "(", "entity_text", ")", "!=", "1", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_contains_lemma_match", "(", "entity", ",", "entity_text", ",", "token", ",", "token_index", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._contains_lemma_match": [[331, 344], ["None"], "methods", ["None"], ["", "def", "_contains_lemma_match", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "entity", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "if", "token", ".", "lemma_", "in", "self", ".", "_entity_text_lemmas", "[", "entity", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._edit_distance": [[345, 355], ["float", "editdistance.eval", "len"], "methods", ["None"], ["", "def", "_edit_distance", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "edit_distance", "=", "float", "(", "editdistance", ".", "eval", "(", "\" \"", ".", "join", "(", "e", ".", "text", "for", "e", "in", "entity_text", ")", ",", "token", ".", "text", ")", ")", "\n", "return", "1.0", "-", "edit_distance", "/", "len", "(", "token", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._related_column": [[356, 371], ["entity.startswith"], "methods", ["None"], ["", "def", "_related_column", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "# Check if the entity is a column name in one of the two WikiTables languages.", "\n", "        ", "if", "not", "entity", ".", "startswith", "(", "\"fb:row.row\"", ")", "and", "\"_column:\"", "not", "in", "entity", ":", "\n", "            ", "return", "0.0", "\n", "", "for", "neighbor", "in", "self", ".", "knowledge_graph", ".", "neighbors", "[", "entity", "]", ":", "\n", "            ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "neighbor", "]", ":", "\n", "                ", "return", "1.0", "\n", "", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._related_column_lemma": [[372, 389], ["entity.startswith"], "methods", ["None"], ["", "def", "_related_column_lemma", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "# Check if the entity is a column name in one of the two WikiTables languages.", "\n", "        ", "if", "not", "entity", ".", "startswith", "(", "\"fb:row.row\"", ")", "and", "\"_column:\"", "not", "in", "entity", ":", "\n", "            ", "return", "0.0", "\n", "", "for", "neighbor", "in", "self", ".", "knowledge_graph", ".", "neighbors", "[", "entity", "]", ":", "\n", "            ", "if", "token", ".", "text", "in", "self", ".", "_entity_text_exact_text", "[", "neighbor", "]", ":", "\n", "                ", "return", "1.0", "\n", "", "if", "token", ".", "lemma_", "in", "self", ".", "_entity_text_lemmas", "[", "neighbor", "]", ":", "\n", "                ", "return", "1.0", "\n", "", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._span_overlap_fraction": [[390, 411], ["set", "set", "set.add", "set.add", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "_span_overlap_fraction", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "entity_words", "=", "set", "(", "entity_token", ".", "text", "for", "entity_token", "in", "entity_text", ")", "\n", "if", "not", "entity_words", ":", "\n", "# Some tables have empty cells.", "\n", "            ", "return", "0", "\n", "", "seen_entity_words", "=", "set", "(", ")", "\n", "token_index_left", "=", "token_index", "\n", "while", "token_index", "<", "len", "(", "tokens", ")", "and", "tokens", "[", "token_index", "]", ".", "text", "in", "entity_words", ":", "\n", "            ", "seen_entity_words", ".", "add", "(", "tokens", "[", "token_index", "]", ".", "text", ")", "\n", "token_index", "+=", "1", "\n", "", "while", "token_index_left", ">=", "0", "and", "tokens", "[", "token_index_left", "]", ".", "text", "in", "entity_words", ":", "\n", "            ", "seen_entity_words", ".", "add", "(", "tokens", "[", "token_index_left", "]", ".", "text", ")", "\n", "token_index_left", "-=", "1", "\n", "", "return", "len", "(", "seen_entity_words", ")", "/", "len", "(", "entity_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._span_lemma_overlap_fraction": [[412, 433], ["set", "set", "set.add", "set.add", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "_span_lemma_overlap_fraction", "(", "\n", "self", ",", "\n", "entity", ":", "str", ",", "\n", "entity_text", ":", "List", "[", "Token", "]", ",", "\n", "token", ":", "Token", ",", "\n", "token_index", ":", "int", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", ")", "->", "float", ":", "\n", "        ", "entity_lemmas", "=", "set", "(", "entity_token", ".", "lemma_", "for", "entity_token", "in", "entity_text", ")", "\n", "if", "not", "entity_lemmas", ":", "\n", "# Some tables have empty cells.", "\n", "            ", "return", "0", "\n", "", "seen_entity_lemmas", "=", "set", "(", ")", "\n", "token_index_left", "=", "token_index", "\n", "while", "token_index", "<", "len", "(", "tokens", ")", "and", "tokens", "[", "token_index", "]", ".", "lemma_", "in", "entity_lemmas", ":", "\n", "            ", "seen_entity_lemmas", ".", "add", "(", "tokens", "[", "token_index", "]", ".", "lemma_", ")", "\n", "token_index", "+=", "1", "\n", "", "while", "token_index_left", ">=", "0", "and", "tokens", "[", "token_index_left", "]", ".", "lemma_", "in", "entity_lemmas", ":", "\n", "            ", "seen_entity_lemmas", ".", "add", "(", "tokens", "[", "token_index_left", "]", ".", "lemma_", ")", "\n", "token_index_left", "-=", "1", "\n", "", "return", "len", "(", "seen_entity_lemmas", ")", "/", "len", "(", "entity_lemmas", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.__init__": [[77, 89], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "rule", ":", "str", ",", "\n", "is_global_rule", ":", "bool", ",", "\n", "vocab_namespace", ":", "str", "=", "\"rule_labels\"", ",", "\n", "nonterminal", ":", "str", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "rule", "=", "rule", "\n", "self", ".", "nonterminal", "=", "nonterminal", "\n", "self", ".", "is_global_rule", "=", "is_global_rule", "\n", "self", ".", "_vocab_namespace", "=", "vocab_namespace", "\n", "self", ".", "_rule_id", ":", "int", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.count_vocab_items": [[90, 94], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "is_global_rule", ":", "\n", "            ", "counter", "[", "self", ".", "_vocab_namespace", "]", "[", "self", ".", "rule", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index": [[95, 99], ["vocab.get_token_index"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "is_global_rule", "and", "self", ".", "_rule_id", "is", "None", ":", "\n", "            ", "self", ".", "_rule_id", "=", "vocab", ".", "get_token_index", "(", "self", ".", "rule", ",", "self", ".", "_vocab_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths": [[100, 103], ["None"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor": [[104, 111], ["production_rule_field.ProductionRule", "torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "ProductionRule", ":", "\n", "        ", "if", "self", ".", "is_global_rule", ":", "\n", "            ", "tensor", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "_rule_id", "]", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "None", "\n", "", "return", "ProductionRule", "(", "self", ".", "rule", ",", "self", ".", "is_global_rule", ",", "tensor", ",", "self", ".", "nonterminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.empty_field": [[112, 118], ["production_rule_field.ProductionRuleField"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "\n", "# This _does_ get called, because we don't want to bother with modifying the ListField to", "\n", "# ignore padding for these.  We just make sure the rule is the empty string, which the", "\n", "# model will use to know that this rule is just padding.", "\n", "        ", "return", "ProductionRuleField", "(", "rule", "=", "\"\"", ",", "is_global_rule", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.batch_tensors": [[119, 124], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "batch_tensors", "(", "\n", "self", ",", "tensor_list", ":", "List", "[", "ProductionRule", "]", "\n", ")", "->", "List", "[", "ProductionRule", "]", ":", "# type: ignore", "\n", "        ", "return", "tensor_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.__str__": [[125, 128], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "(", "\n", "f\"ProductionRuleField with rule: {self.rule} (is_global_rule: \"", "\n", "f\"{self.is_global_rule}) in namespace: '{self._vocab_namespace}'.'\"", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.setup_method": [[18, 41], ["allennlp.data.tokenizers.SpacyTokenizer", "knowledge_graph_field_test.TestKnowledgeGraphField.tokenizer.tokenize", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file().get_table_knowledge_graph", "allennlp.data.Vocabulary", "knowledge_graph_field_test.TestKnowledgeGraphField.vocab.add_token_to_namespace", "knowledge_graph_field_test.TestKnowledgeGraphField.vocab.add_token_to_namespace", "knowledge_graph_field_test.TestKnowledgeGraphField.vocab.add_token_to_namespace", "knowledge_graph_field_test.TestKnowledgeGraphField.vocab.add_token_to_namespace", "knowledge_graph_field_test.TestKnowledgeGraphField.vocab.add_token_to_namespace", "knowledge_graph_field_test.TestKnowledgeGraphField.vocab.get_token_index", "allennlp_semparse.fields.KnowledgeGraphField", "super().setup_method", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp_semparse.common.wikitables.TableQuestionContext.read_from_file"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.get_table_knowledge_graph", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.wikitables.table_question_context.TableQuestionContext.read_from_file"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "SpacyTokenizer", "(", "pos_tags", "=", "True", ")", "\n", "self", ".", "utterance", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"where is mersin?\"", ")", "\n", "self", ".", "token_indexers", "=", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "\"tokens\"", ")", "}", "\n", "\n", "table_file", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"wikitables\"", "/", "\"tables\"", "/", "\"341.tagged\"", "\n", "self", ".", "graph", "=", "TableQuestionContext", ".", "read_from_file", "(", "\n", "table_file", ",", "self", ".", "utterance", "\n", ")", ".", "get_table_knowledge_graph", "(", ")", "\n", "self", ".", "vocab", "=", "Vocabulary", "(", ")", "\n", "self", ".", "name_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\"name\"", ",", "namespace", "=", "\"tokens\"", ")", "\n", "self", ".", "in_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\"in\"", ",", "namespace", "=", "\"tokens\"", ")", "\n", "self", ".", "english_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\"english\"", ",", "namespace", "=", "\"tokens\"", ")", "\n", "self", ".", "location_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\"location\"", ",", "namespace", "=", "\"tokens\"", ")", "\n", "self", ".", "mersin_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\"mersin\"", ",", "namespace", "=", "\"tokens\"", ")", "\n", "\n", "self", ".", "oov_index", "=", "self", ".", "vocab", ".", "get_token_index", "(", "\"random OOV string\"", ",", "namespace", "=", "\"tokens\"", ")", "\n", "self", ".", "edirne_index", "=", "self", ".", "oov_index", "\n", "self", ".", "field", "=", "KnowledgeGraphField", "(", "\n", "self", ".", "graph", ",", "self", ".", "utterance", ",", "self", ".", "token_indexers", ",", "self", ".", "tokenizer", "\n", ")", "\n", "\n", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_count_vocab_items": [[42, 52], ["collections.defaultdict", "knowledge_graph_field_test.TestKnowledgeGraphField.field.count_vocab_items", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.count_vocab_items"], ["", "def", "test_count_vocab_items", "(", "self", ")", ":", "\n", "        ", "namespace_token_counts", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "self", ".", "field", ".", "count_vocab_items", "(", "namespace_token_counts", ")", "\n", "\n", "assert", "namespace_token_counts", "[", "\"tokens\"", "]", "==", "{", "\n", "\"name\"", ":", "1", ",", "\n", "\"in\"", ":", "2", ",", "\n", "\"english\"", ":", "2", ",", "\n", "\"location\"", ":", "1", ",", "\n", "\"mersin\"", ":", "1", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_get_padding_lengths_raises_if_not_indexed": [[54, 57], ["pytest.raises", "knowledge_graph_field_test.TestKnowledgeGraphField.field.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths"], ["", "def", "test_get_padding_lengths_raises_if_not_indexed", "(", "self", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ConfigurationError", ")", ":", "\n", "            ", "self", ".", "field", ".", "get_padding_lengths", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_padding_lengths_are_computed_correctly": [[58, 77], ["knowledge_graph_field_test.TestKnowledgeGraphField.field.index", "allennlp.data.token_indexers.TokenCharactersIndexer", "knowledge_graph_field_test.TestKnowledgeGraphField.field.index", "knowledge_graph_field_test.TestKnowledgeGraphField.field.get_padding_lengths", "knowledge_graph_field_test.TestKnowledgeGraphField.field.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths"], ["", "", "def", "test_padding_lengths_are_computed_correctly", "(", "self", ")", ":", "\n", "        ", "self", ".", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "assert", "self", ".", "field", ".", "get_padding_lengths", "(", ")", "==", "{", "\n", "\"num_entities\"", ":", "3", ",", "\n", "\"num_utterance_tokens\"", ":", "4", ",", "\n", "\"num_fields\"", ":", "3", ",", "\n", "\"list_tokens___tokens\"", ":", "3", ",", "\n", "}", "\n", "self", ".", "field", ".", "_token_indexers", "[", "\"token_characters\"", "]", "=", "TokenCharactersIndexer", "(", "\n", "min_padding_length", "=", "1", "\n", ")", "\n", "self", ".", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "assert", "self", ".", "field", ".", "get_padding_lengths", "(", ")", "==", "{", "\n", "\"num_entities\"", ":", "3", ",", "\n", "\"num_utterance_tokens\"", ":", "4", ",", "\n", "\"num_fields\"", ":", "3", ",", "\n", "\"list_tokens___tokens\"", ":", "3", ",", "\n", "\"list_token_characters___token_characters\"", ":", "3", ",", "\n", "\"list_token_characters___num_token_characters\"", ":", "8", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_as_tensor_produces_correct_output": [[79, 135], ["knowledge_graph_field_test.TestKnowledgeGraphField.field.index", "knowledge_graph_field_test.TestKnowledgeGraphField.field.get_padding_lengths", "knowledge_graph_field_test.TestKnowledgeGraphField.field.as_tensor", "numpy.testing.assert_almost_equal", "tensor_dict[].detach().cpu().numpy", "enumerate", "knowledge_graph_field_test.TestKnowledgeGraphField.keys", "[].detach().cpu().numpy", "enumerate", "tensor_dict[].detach().cpu", "numpy.testing.assert_almost_equal", "[].detach().cpu", "tensor_dict[].detach", "[].detach"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor"], ["", "def", "test_as_tensor_produces_correct_output", "(", "self", ")", ":", "\n", "        ", "self", ".", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "padding_lengths", "=", "self", ".", "field", ".", "get_padding_lengths", "(", ")", "\n", "padding_lengths", "[", "\"num_utterance_tokens\"", "]", "+=", "1", "\n", "padding_lengths", "[", "\"num_entities\"", "]", "+=", "1", "\n", "padding_lengths", "[", "\"num_fields\"", "]", "+=", "1", "\n", "tensor_dict", "=", "self", ".", "field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "assert", "tensor_dict", ".", "keys", "(", ")", "==", "{", "\"text\"", ",", "\"linking\"", "}", "\n", "expected_text_tensor", "=", "[", "\n", "[", "self", ".", "mersin_index", ",", "0", ",", "0", "]", ",", "\n", "[", "self", ".", "location_index", ",", "self", ".", "in_index", ",", "self", ".", "english_index", "]", ",", "\n", "[", "self", ".", "name_index", ",", "self", ".", "in_index", ",", "self", ".", "english_index", "]", ",", "\n", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "]", "\n", "assert_almost_equal", "(", "\n", "tensor_dict", "[", "\"text\"", "]", "[", "\"tokens\"", "]", "[", "\"tokens\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "expected_text_tensor", "\n", ")", "\n", "\n", "linking_tensor", "=", "tensor_dict", "[", "\"linking\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "expected_linking_tensor", "=", "[", "\n", "[", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string:mersin, \"where\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "1.5", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string:mersin, \"is\"", "\n", "[", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", ",", "# string:mersin, \"mersin\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "5", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string:mersin, \"?\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "]", ",", "# string:mersin, padding", "\n", "[", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "2.6", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_column:name_in_english, \"where\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "7.5", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_column:name_in_english, \"is\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "1.8333", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "# string_column:..in_english, \"mersin\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "18", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_column:name_in_english, \"?\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "]", ",", "# string_column:name_in_english, padding", "\n", "[", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "1.6", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_..:location_in_english, \"where\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "5.5", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_column:location_in_english, \"is\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_column:location_in_english, \"mersin\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "-", "14", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# string_column:location_in_english, \"?\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "]", ",", "# string_column:location_in_english, padding", "\n", "[", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# padding, \"where\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# padding, \"is\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# padding, \"mersin\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# padding, \"?\"", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "]", ",", "\n", "]", "# padding, padding", "\n", "for", "entity_index", ",", "entity_features", "in", "enumerate", "(", "expected_linking_tensor", ")", ":", "\n", "            ", "for", "question_index", ",", "feature_vector", "in", "enumerate", "(", "entity_features", ")", ":", "\n", "                ", "assert_almost_equal", "(", "\n", "linking_tensor", "[", "entity_index", ",", "question_index", "]", ",", "\n", "feature_vector", ",", "\n", "decimal", "=", "4", ",", "\n", "err_msg", "=", "f\"{entity_index} {question_index}\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_lemma_feature_extractor": [[137, 145], ["knowledge_graph_field_test.TestKnowledgeGraphField.tokenizer.tokenize", "allennlp_semparse.fields.KnowledgeGraphField", "allennlp_semparse.fields.KnowledgeGraphField._contains_lemma_match"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._contains_lemma_match"], ["", "", "", "def", "test_lemma_feature_extractor", "(", "self", ")", ":", "\n", "        ", "utterance", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Names in English\"", ")", "\n", "field", "=", "KnowledgeGraphField", "(", "self", ".", "graph", ",", "self", ".", "utterance", ",", "self", ".", "token_indexers", ",", "self", ".", "tokenizer", ")", "\n", "entity", "=", "\"string_column:name_in_english\"", "\n", "lemma_feature", "=", "field", ".", "_contains_lemma_match", "(", "\n", "entity", ",", "field", ".", "_entity_text_map", "[", "entity", "]", ",", "utterance", "[", "0", "]", ",", "0", ",", "utterance", "\n", ")", "\n", "assert", "lemma_feature", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_span_overlap_fraction": [[146, 156], ["knowledge_graph_field_test.TestKnowledgeGraphField.tokenizer.tokenize", "allennlp_semparse.fields.KnowledgeGraphField", "allennlp_semparse.fields.KnowledgeGraphField._span_overlap_fraction", "enumerate"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field.KnowledgeGraphField._span_overlap_fraction"], ["", "def", "test_span_overlap_fraction", "(", "self", ")", ":", "\n", "        ", "utterance", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"what is the name in english of mersin?\"", ")", "\n", "field", "=", "KnowledgeGraphField", "(", "self", ".", "graph", ",", "self", ".", "utterance", ",", "self", ".", "token_indexers", ",", "self", ".", "tokenizer", ")", "\n", "entity", "=", "\"string_column:name_in_english\"", "\n", "entity_text", "=", "field", ".", "_entity_text_map", "[", "entity", "]", "\n", "feature_values", "=", "[", "\n", "field", ".", "_span_overlap_fraction", "(", "entity", ",", "entity_text", ",", "token", ",", "i", ",", "utterance", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "utterance", ")", "\n", "]", "\n", "assert", "feature_values", "==", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_batch_tensors": [[157, 178], ["knowledge_graph_field_test.TestKnowledgeGraphField.field.index", "knowledge_graph_field_test.TestKnowledgeGraphField.field.get_padding_lengths", "knowledge_graph_field_test.TestKnowledgeGraphField.field.as_tensor", "knowledge_graph_field_test.TestKnowledgeGraphField.field.as_tensor", "knowledge_graph_field_test.TestKnowledgeGraphField.field.batch_tensors", "numpy.testing.assert_almost_equal", "torch.stack", "numpy.testing.assert_almost_equal", "knowledge_graph_field_test.TestKnowledgeGraphField.keys", "[].detach().cpu().numpy", "batched_tensor_dict[].detach().cpu().numpy", "torch.stack.detach().cpu().numpy", "[].detach().cpu", "batched_tensor_dict[].detach().cpu", "torch.stack.detach().cpu", "[].detach", "batched_tensor_dict[].detach", "torch.stack.detach"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.batch_tensors"], ["", "def", "test_batch_tensors", "(", "self", ")", ":", "\n", "        ", "self", ".", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "padding_lengths", "=", "self", ".", "field", ".", "get_padding_lengths", "(", ")", "\n", "tensor_dict1", "=", "self", ".", "field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "tensor_dict2", "=", "self", ".", "field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "batched_tensor_dict", "=", "self", ".", "field", ".", "batch_tensors", "(", "[", "tensor_dict1", ",", "tensor_dict2", "]", ")", "\n", "assert", "batched_tensor_dict", ".", "keys", "(", ")", "==", "{", "\"text\"", ",", "\"linking\"", "}", "\n", "expected_single_tensor", "=", "[", "\n", "[", "self", ".", "mersin_index", ",", "0", ",", "0", "]", ",", "\n", "[", "self", ".", "location_index", ",", "self", ".", "in_index", ",", "self", ".", "english_index", "]", ",", "\n", "[", "self", ".", "name_index", ",", "self", ".", "in_index", ",", "self", ".", "english_index", "]", ",", "\n", "]", "\n", "expected_batched_tensor", "=", "[", "expected_single_tensor", ",", "expected_single_tensor", "]", "\n", "assert_almost_equal", "(", "\n", "batched_tensor_dict", "[", "\"text\"", "]", "[", "\"tokens\"", "]", "[", "\"tokens\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "expected_batched_tensor", ",", "\n", ")", "\n", "expected_linking_tensor", "=", "torch", ".", "stack", "(", "[", "tensor_dict1", "[", "\"linking\"", "]", ",", "tensor_dict2", "[", "\"linking\"", "]", "]", ")", "\n", "assert_almost_equal", "(", "\n", "batched_tensor_dict", "[", "\"linking\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "expected_linking_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.knowledge_graph_field_test.TestKnowledgeGraphField.test_field_initialized_with_empty_constructor": [[180, 185], ["knowledge_graph_field_test.TestKnowledgeGraphField.field.empty_field", "pytest.fail", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.empty_field", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_field_initialized_with_empty_constructor", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "field", ".", "empty_field", "(", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "pytest", ".", "fail", "(", "str", "(", "e", ")", ",", "pytrace", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.setup_method": [[13, 20], ["super().setup_method", "allennlp.data.Vocabulary", "production_rule_field_test.TestProductionRuleField.vocab.add_token_to_namespace", "production_rule_field_test.TestProductionRuleField.vocab.add_token_to_namespace"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", "TestProductionRuleField", ",", "self", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "vocab", "=", "Vocabulary", "(", ")", "\n", "self", ".", "s_rule_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\n", "\"S -> [NP, VP]\"", ",", "namespace", "=", "\"rule_labels\"", "\n", ")", "\n", "self", ".", "np_index", "=", "self", ".", "vocab", ".", "add_token_to_namespace", "(", "\"NP -> test\"", ",", "namespace", "=", "\"rule_labels\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_field_counts_vocab_items_correctly": [[21, 31], ["allennlp_semparse.fields.ProductionRuleField", "collections.defaultdict", "allennlp_semparse.fields.ProductionRuleField.count_vocab_items", "allennlp_semparse.fields.ProductionRuleField", "collections.defaultdict", "allennlp_semparse.fields.ProductionRuleField.count_vocab_items", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.count_vocab_items", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.count_vocab_items"], ["", "def", "test_field_counts_vocab_items_correctly", "(", "self", ")", ":", "\n", "        ", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "namespace_token_counts", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "field", ".", "count_vocab_items", "(", "namespace_token_counts", ")", "\n", "assert", "namespace_token_counts", "[", "\"rule_labels\"", "]", "[", "\"S -> [NP, VP]\"", "]", "==", "1", "\n", "\n", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "False", ")", "\n", "namespace_token_counts", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "field", ".", "count_vocab_items", "(", "namespace_token_counts", ")", "\n", "assert", "namespace_token_counts", "[", "\"rule_labels\"", "]", "[", "\"S -> [NP, VP]\"", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_index_converts_field_correctly": [[32, 36], ["allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField.index"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index"], ["", "def", "test_index_converts_field_correctly", "(", "self", ")", ":", "\n", "        ", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "assert", "field", ".", "_rule_id", "==", "self", ".", "s_rule_index", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_padding_lengths_are_computed_correctly": [[37, 41], ["allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField.index", "allennlp_semparse.fields.ProductionRuleField.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths"], ["", "def", "test_padding_lengths_are_computed_correctly", "(", "self", ")", ":", "\n", "        ", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "assert", "field", ".", "get_padding_lengths", "(", ")", "==", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_as_tensor_produces_correct_output": [[42, 60], ["allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField.index", "allennlp_semparse.fields.ProductionRuleField.as_tensor", "isinstance", "numpy.testing.assert_almost_equal", "allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField.index", "allennlp_semparse.fields.ProductionRuleField.as_tensor", "isinstance", "allennlp_semparse.fields.ProductionRuleField.get_padding_lengths", "len", "tensor_tuple[].detach().cpu().numpy", "allennlp_semparse.fields.ProductionRuleField.get_padding_lengths", "len", "tensor_tuple[].detach().cpu", "tensor_tuple[].detach"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths"], ["", "def", "test_as_tensor_produces_correct_output", "(", "self", ")", ":", "\n", "        ", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "tensor_tuple", "=", "field", ".", "as_tensor", "(", "field", ".", "get_padding_lengths", "(", ")", ")", "\n", "assert", "isinstance", "(", "tensor_tuple", ",", "tuple", ")", "\n", "assert", "len", "(", "tensor_tuple", ")", "==", "4", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"S -> [NP, VP]\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "True", "\n", "assert_almost_equal", "(", "tensor_tuple", "[", "2", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "self", ".", "s_rule_index", "]", ")", "\n", "\n", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "False", ")", "\n", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "tensor_tuple", "=", "field", ".", "as_tensor", "(", "field", ".", "get_padding_lengths", "(", ")", ")", "\n", "assert", "isinstance", "(", "tensor_tuple", ",", "tuple", ")", "\n", "assert", "len", "(", "tensor_tuple", ")", "==", "4", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"S -> [NP, VP]\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "False", "\n", "assert", "tensor_tuple", "[", "2", "]", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_batch_tensors_does_not_modify_list": [[61, 73], ["allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField.index", "allennlp_semparse.fields.ProductionRuleField.get_padding_lengths", "allennlp_semparse.fields.ProductionRuleField.as_tensor", "allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField.index", "allennlp_semparse.fields.ProductionRuleField.get_padding_lengths", "allennlp_semparse.fields.ProductionRuleField.as_tensor", "allennlp_semparse.fields.ProductionRuleField.batch_tensors"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.batch_tensors"], ["", "def", "test_batch_tensors_does_not_modify_list", "(", "self", ")", ":", "\n", "        ", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "padding_lengths", "=", "field", ".", "get_padding_lengths", "(", ")", "\n", "tensor_dict1", "=", "field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "\n", "field", "=", "ProductionRuleField", "(", "\"NP -> test\"", ",", "is_global_rule", "=", "True", ")", "\n", "field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "padding_lengths", "=", "field", ".", "get_padding_lengths", "(", ")", "\n", "tensor_dict2", "=", "field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "tensor_list", "=", "[", "tensor_dict1", ",", "tensor_dict2", "]", "\n", "assert", "field", ".", "batch_tensors", "(", "tensor_list", ")", "==", "tensor_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_doubly_nested_field_works": [[74, 119], ["allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField", "allennlp_semparse.fields.ProductionRuleField", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField.index", "allennlp.data.fields.ListField.get_padding_lengths", "allennlp.data.fields.ListField.as_tensor", "isinstance", "isinstance", "isinstance", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "numpy.testing.assert_almost_equal", "len", "len", "len", "tensor_tuple[].detach().cpu().numpy", "tensor_tuple[].detach().cpu().numpy", "tensor_tuple[].detach().cpu().numpy", "tensor_tuple[].detach().cpu().numpy", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "tensor_tuple[].detach().cpu", "tensor_tuple[].detach().cpu", "tensor_tuple[].detach().cpu", "tensor_tuple[].detach().cpu", "tensor_tuple[].detach", "tensor_tuple[].detach", "tensor_tuple[].detach", "tensor_tuple[].detach"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.index", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.get_padding_lengths", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field.ProductionRuleField.as_tensor"], ["", "def", "test_doubly_nested_field_works", "(", "self", ")", ":", "\n", "        ", "field1", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "field2", "=", "ProductionRuleField", "(", "\"NP -> test\"", ",", "is_global_rule", "=", "True", ")", "\n", "field3", "=", "ProductionRuleField", "(", "\"VP -> eat\"", ",", "is_global_rule", "=", "False", ")", "\n", "list_field", "=", "ListField", "(", "[", "ListField", "(", "[", "field1", ",", "field2", ",", "field3", "]", ")", ",", "ListField", "(", "[", "field1", ",", "field2", "]", ")", "]", ")", "\n", "list_field", ".", "index", "(", "self", ".", "vocab", ")", "\n", "padding_lengths", "=", "list_field", ".", "get_padding_lengths", "(", ")", "\n", "tensors", "=", "list_field", ".", "as_tensor", "(", "padding_lengths", ")", "\n", "assert", "isinstance", "(", "tensors", ",", "list", ")", "\n", "assert", "len", "(", "tensors", ")", "==", "2", "\n", "assert", "isinstance", "(", "tensors", "[", "0", "]", ",", "list", ")", "\n", "assert", "len", "(", "tensors", "[", "0", "]", ")", "==", "3", "\n", "assert", "isinstance", "(", "tensors", "[", "1", "]", ",", "list", ")", "\n", "assert", "len", "(", "tensors", "[", "1", "]", ")", "==", "3", "\n", "\n", "tensor_tuple", "=", "tensors", "[", "0", "]", "[", "0", "]", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"S -> [NP, VP]\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "True", "\n", "assert_almost_equal", "(", "tensor_tuple", "[", "2", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "self", ".", "s_rule_index", "]", ")", "\n", "\n", "tensor_tuple", "=", "tensors", "[", "0", "]", "[", "1", "]", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"NP -> test\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "True", "\n", "assert_almost_equal", "(", "tensor_tuple", "[", "2", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "self", ".", "np_index", "]", ")", "\n", "\n", "tensor_tuple", "=", "tensors", "[", "0", "]", "[", "2", "]", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"VP -> eat\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "False", "\n", "assert", "tensor_tuple", "[", "2", "]", "is", "None", "\n", "\n", "tensor_tuple", "=", "tensors", "[", "1", "]", "[", "0", "]", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"S -> [NP, VP]\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "True", "\n", "assert_almost_equal", "(", "tensor_tuple", "[", "2", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "self", ".", "s_rule_index", "]", ")", "\n", "\n", "tensor_tuple", "=", "tensors", "[", "1", "]", "[", "1", "]", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"NP -> test\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "True", "\n", "assert_almost_equal", "(", "tensor_tuple", "[", "2", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "self", ".", "np_index", "]", ")", "\n", "\n", "# This item was just padding.", "\n", "tensor_tuple", "=", "tensors", "[", "1", "]", "[", "2", "]", "\n", "assert", "tensor_tuple", "[", "0", "]", "==", "\"\"", "\n", "assert", "tensor_tuple", "[", "1", "]", "is", "False", "\n", "assert", "tensor_tuple", "[", "2", "]", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.fields.production_rule_field_test.TestProductionRuleField.test_production_rule_field_can_print": [[120, 123], ["allennlp_semparse.fields.ProductionRuleField", "print"], "methods", ["None"], ["", "def", "test_production_rule_field_can_print", "(", "self", ")", ":", "\n", "        ", "field", "=", "ProductionRuleField", "(", "\"S -> [NP, VP]\"", ",", "is_global_rule", "=", "True", ")", "\n", "print", "(", "field", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.knowledge_graph.KnowledgeGraph.__init__": [[37, 46], ["sorted"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "entities", ":", "Set", "[", "str", "]", ",", "\n", "neighbors", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "entity_text", ":", "Dict", "[", "str", ",", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "entities", "=", "sorted", "(", "entities", ")", "\n", "self", ".", "neighbors", "=", "neighbors", "\n", "self", ".", "entity_text", "=", "entity_text", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.knowledge_graph.KnowledgeGraph.__eq__": [[47, 51], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.__init__": [[29, 35], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "world", ":", "DomainLanguage", ",", "max_path_length", ":", "int", ")", "->", "None", ":", "\n", "        ", "self", ".", "_world", "=", "world", "\n", "self", ".", "_max_path_length", "=", "max_path_length", "\n", "self", ".", "_completed_paths", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "self", ".", "_terminal_path_index", ":", "Dict", "[", "str", ",", "Set", "[", "int", "]", "]", "=", "defaultdict", "(", "set", ")", "\n", "self", ".", "_length_sorted_paths", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker._walk": [[36, 99], ["action_space_walker.ActionSpaceWalker._world.get_nonterminal_productions", "nonterminal_buffer.pop", "next_actions.extend", "reversed", "next_paths.append", "len", "action_space_walker.ActionSpaceWalker._completed_paths.append", "start_production.split", "action_space_walker.ActionSpaceWalker._get_right_side_parts", "action_space_walker.ActionSpaceWalker._world.is_nonterminal", "action_space_walker.ActionSpaceWalker._get_right_side_parts", "len", "incomplete_paths.append", "new_nonterminal_buffer.append", "action_space_walker.ActionSpaceWalker._world.is_nonterminal", "action_space_walker.ActionSpaceWalker._terminal_path_index[].add"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.get_nonterminal_productions", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker._get_right_side_parts", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.is_nonterminal", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker._get_right_side_parts", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.states.lambda_grammar_statelet_test.is_nonterminal", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "_walk", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Walk over action space to collect completed paths of at most ``self._max_path_length`` steps.\n        \"\"\"", "\n", "actions", "=", "self", ".", "_world", ".", "get_nonterminal_productions", "(", ")", "\n", "start_productions", "=", "actions", "[", "START_SYMBOL", "]", "\n", "# Buffer of NTs to expand, previous actions", "\n", "incomplete_paths", "=", "[", "\n", "(", "[", "start_production", ".", "split", "(", "\" -> \"", ")", "[", "-", "1", "]", "]", ",", "[", "start_production", "]", ")", "\n", "for", "start_production", "in", "start_productions", "\n", "]", "\n", "self", ".", "_completed_paths", "=", "[", "]", "\n", "# Overview: We keep track of the buffer of non-terminals to expand, and the action history", "\n", "# for each incomplete path. At every iteration in the while loop below, we iterate over all", "\n", "# incomplete paths, expand one non-terminal from the buffer in a depth-first fashion, get", "\n", "# all possible next actions triggered by that non-terminal and add to the paths. Then, we", "\n", "# check the expanded paths, to see if they are 1) complete, in which case they are", "\n", "# added to completed_paths, 2) longer than max_path_length, in which case they are", "\n", "# discarded, or 3) neither, in which case they are used to form the incomplete_paths for the", "\n", "# next iteration of this while loop.", "\n", "# While the non-terminal expansion is done in a depth-first fashion, note that the search over", "\n", "# the action space itself is breadth-first.", "\n", "while", "incomplete_paths", ":", "\n", "            ", "next_paths", "=", "[", "]", "\n", "for", "nonterminal_buffer", ",", "history", "in", "incomplete_paths", ":", "\n", "# Taking the last non-terminal added to the buffer. We're going depth-first.", "\n", "                ", "nonterminal", "=", "nonterminal_buffer", ".", "pop", "(", ")", "\n", "next_actions", "=", "[", "]", "\n", "if", "nonterminal", "not", "in", "actions", ":", "\n", "# This happens when the nonterminal corresponds to a type that does not exist in", "\n", "# the context. For example, in the variable free variant of the WikiTables", "\n", "# world, there are nonterminals for specific column types (like date). Say we", "\n", "# produced a path containing \"filter_date_greater\" already, and we do not have", "\n", "# an columns of type \"date\", then this condition would be triggered. We should", "\n", "# just discard those paths.", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "next_actions", ".", "extend", "(", "actions", "[", "nonterminal", "]", ")", "\n", "# Iterating over all possible next actions.", "\n", "", "for", "action", "in", "next_actions", ":", "\n", "                    ", "new_history", "=", "history", "+", "[", "action", "]", "\n", "new_nonterminal_buffer", "=", "nonterminal_buffer", "[", ":", "]", "\n", "# Since we expand the last action added to the buffer, the left child should be", "\n", "# added after the right child.", "\n", "for", "right_side_part", "in", "reversed", "(", "self", ".", "_get_right_side_parts", "(", "action", ")", ")", ":", "\n", "                        ", "if", "self", ".", "_world", ".", "is_nonterminal", "(", "right_side_part", ")", ":", "\n", "                            ", "new_nonterminal_buffer", ".", "append", "(", "right_side_part", ")", "\n", "", "", "next_paths", ".", "append", "(", "(", "new_nonterminal_buffer", ",", "new_history", ")", ")", "\n", "", "", "incomplete_paths", "=", "[", "]", "\n", "for", "nonterminal_buffer", ",", "path", "in", "next_paths", ":", "\n", "# An empty buffer means that we've completed this path.", "\n", "                ", "if", "not", "nonterminal_buffer", ":", "\n", "# Indexing completed paths by the nonterminals they contain.", "\n", "                    ", "next_path_index", "=", "len", "(", "self", ".", "_completed_paths", ")", "\n", "for", "action", "in", "path", ":", "\n", "                        ", "for", "value", "in", "self", ".", "_get_right_side_parts", "(", "action", ")", ":", "\n", "                            ", "if", "not", "self", ".", "_world", ".", "is_nonterminal", "(", "value", ")", ":", "\n", "                                ", "self", ".", "_terminal_path_index", "[", "action", "]", ".", "add", "(", "next_path_index", ")", "\n", "", "", "", "self", ".", "_completed_paths", ".", "append", "(", "path", ")", "\n", "# We're adding to incomplete_paths for the next iteration, only those paths that are", "\n", "# shorter than the max_path_length. The remaining paths will be discarded.", "\n", "", "elif", "len", "(", "path", ")", "<=", "self", ".", "_max_path_length", ":", "\n", "                    ", "incomplete_paths", ".", "append", "(", "(", "nonterminal_buffer", ",", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker._get_right_side_parts": [[100, 108], ["action.split", "right_side.startswith", "right_side[].split"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "_get_right_side_parts", "(", "action", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "_", ",", "right_side", "=", "action", ".", "split", "(", "\" -> \"", ")", "\n", "if", "right_side", ".", "startswith", "(", "\"[\"", ")", ":", "\n", "            ", "right_side_parts", "=", "right_side", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\", \"", ")", "\n", "", "else", ":", "\n", "            ", "right_side_parts", "=", "[", "right_side", "]", "\n", "", "return", "right_side_parts", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda": [[109, 182], ["all", "zip", "collections.defaultdict", "action_space_walker.ActionSpaceWalker._walk", "filtered_path_indices.append", "collections.defaultdict", "index_to_num_items.items", "sorted", "index_to_num_items.items", "sorted", "action_space_walker.ActionSpaceWalker._world.action_sequence_to_logical_form", "logger.warning", "action_space_walker.ActionSpaceWalker.get_all_logical_forms", "logger.warning", "action_space_walker.ActionSpaceWalker.get_all_logical_forms", "logger.warning", "num_items_grouped_paths[].append", "num_items_grouped_paths.items", "sorted.extend", "sorted", "len", "indices_to_return.append"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker._walk", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_all_logical_forms", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_all_logical_forms", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "get_logical_forms_with_agenda", "(", "\n", "self", ",", "\n", "agenda", ":", "List", "[", "str", "]", ",", "\n", "max_num_logical_forms", ":", "int", "=", "None", ",", "\n", "allow_partial_match", ":", "bool", "=", "False", ",", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        agenda : ``List[str]``\n        max_num_logical_forms : ``int`` (optional)\n        allow_partial_match : ``bool`` (optional, defaul=False)\n            If set, this method will return logical forms which contain not necessarily all the\n            items on the agenda. The returned list will be sorted by how many items the logical\n            forms match.\n        \"\"\"", "\n", "if", "not", "agenda", ":", "\n", "            ", "if", "allow_partial_match", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Agenda is empty! Returning all paths instead.\"", ")", "\n", "return", "self", ".", "get_all_logical_forms", "(", "max_num_logical_forms", ")", "\n", "", "return", "[", "]", "\n", "", "if", "self", ".", "_completed_paths", "is", "None", ":", "\n", "            ", "self", ".", "_walk", "(", ")", "\n", "", "agenda_path_indices", "=", "[", "self", ".", "_terminal_path_index", "[", "action", "]", "for", "action", "in", "agenda", "]", "\n", "if", "all", "(", "[", "not", "path_indices", "for", "path_indices", "in", "agenda_path_indices", "]", ")", ":", "\n", "            ", "if", "allow_partial_match", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"\"\"Agenda items not in any of the paths found. Returning all paths.\"\"\"", "\n", ")", "\n", "return", "self", ".", "get_all_logical_forms", "(", "max_num_logical_forms", ")", "\n", "", "return", "[", "]", "\n", "# TODO (pradeep): Sort the indices and do intersections in order, so that we can return the", "\n", "# set with maximal coverage if the full intersection is null.", "\n", "\n", "# This list contains for each agenda item the list of indices of paths that contain that agenda item. Note", "\n", "# that we omit agenda items that are not in any paths to avoid the final intersection being null. So there", "\n", "# will not be any empty sub-lists in the list below.", "\n", "", "filtered_path_indices", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "for", "agenda_item", ",", "path_indices", "in", "zip", "(", "agenda", ",", "agenda_path_indices", ")", ":", "\n", "            ", "if", "not", "path_indices", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"{agenda_item} is not in any of the paths found! Ignoring it.\"", ")", "\n", "continue", "\n", "", "filtered_path_indices", ".", "append", "(", "path_indices", ")", "\n", "\n", "# This mapping is from a path index to the number of items in the agenda that the path contains.", "\n", "", "index_to_num_items", ":", "Dict", "[", "int", ",", "int", "]", "=", "defaultdict", "(", "int", ")", "\n", "for", "indices", "in", "filtered_path_indices", ":", "\n", "            ", "for", "index", "in", "indices", ":", "\n", "                ", "index_to_num_items", "[", "index", "]", "+=", "1", "\n", "", "", "if", "allow_partial_match", ":", "\n", "# We group the paths based on how many agenda items they contain, and output them in a sorted order.", "\n", "            ", "num_items_grouped_paths", ":", "Dict", "[", "int", ",", "List", "[", "List", "[", "str", "]", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "index", ",", "num_items", "in", "index_to_num_items", ".", "items", "(", ")", ":", "\n", "                ", "num_items_grouped_paths", "[", "num_items", "]", ".", "append", "(", "self", ".", "_completed_paths", "[", "index", "]", ")", "\n", "", "paths", "=", "[", "]", "\n", "# Sort by number of agenda items present in the paths.", "\n", "for", "num_items", ",", "corresponding_paths", "in", "sorted", "(", "\n", "num_items_grouped_paths", ".", "items", "(", ")", ",", "reverse", "=", "True", "\n", ")", ":", "\n", "# Given those paths, sort them by length, so that the first path in ``paths`` will", "\n", "# be the shortest path with the most agenda items.", "\n", "                ", "paths", ".", "extend", "(", "sorted", "(", "corresponding_paths", ",", "key", "=", "len", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "indices_to_return", "=", "[", "]", "\n", "for", "index", ",", "num_items", "in", "index_to_num_items", ".", "items", "(", ")", ":", "\n", "                ", "if", "num_items", "==", "len", "(", "filtered_path_indices", ")", ":", "\n", "                    ", "indices_to_return", ".", "append", "(", "index", ")", "\n", "# Sort all the paths by length", "\n", "", "", "paths", "=", "sorted", "(", "[", "self", ".", "_completed_paths", "[", "index", "]", "for", "index", "in", "indices_to_return", "]", ",", "key", "=", "len", ")", "\n", "", "if", "max_num_logical_forms", "is", "not", "None", ":", "\n", "            ", "paths", "=", "paths", "[", ":", "max_num_logical_forms", "]", "\n", "", "logical_forms", "=", "[", "self", ".", "_world", ".", "action_sequence_to_logical_form", "(", "path", ")", "for", "path", "in", "paths", "]", "\n", "return", "logical_forms", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_all_logical_forms": [[183, 193], ["action_space_walker.ActionSpaceWalker._walk", "action_space_walker.ActionSpaceWalker._world.action_sequence_to_logical_form", "sorted"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker._walk", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language.DomainLanguage.action_sequence_to_logical_form"], ["", "def", "get_all_logical_forms", "(", "self", ",", "max_num_logical_forms", ":", "int", "=", "None", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "self", ".", "_completed_paths", "is", "None", ":", "\n", "            ", "self", ".", "_walk", "(", ")", "\n", "", "paths", "=", "self", ".", "_completed_paths", "\n", "if", "max_num_logical_forms", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "_length_sorted_paths", "is", "None", ":", "\n", "                ", "self", ".", "_length_sorted_paths", "=", "sorted", "(", "self", ".", "_completed_paths", ",", "key", "=", "len", ")", "\n", "", "paths", "=", "self", ".", "_length_sorted_paths", "[", ":", "max_num_logical_forms", "]", "\n", "", "logical_forms", "=", "[", "self", ".", "_world", ".", "action_sequence_to_logical_form", "(", "path", ")", "for", "path", "in", "paths", "]", "\n", "return", "logical_forms", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.errors.ParsingError.__init__": [[9, 12], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "self", ",", "message", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message", "=", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.errors.ParsingError.__str__": [[13, 15], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.errors.ExecutionError.__init__": [[24, 27], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__"], ["def", "__init__", "(", "self", ",", "message", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message", "=", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.errors.ExecutionError.__str__": [[28, 30], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "message", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util.lisp_to_nested_expression": [[57, 77], ["lisp_string.split", "stack.pop.append", "stack.pop.append", "stack.append", "token.replace", "stack.pop"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], []], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__init__": [[5, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "year", ":", "int", ",", "month", ":", "int", ",", "day", ":", "int", ")", "->", "None", ":", "\n", "        ", "self", ".", "year", "=", "year", "\n", "self", ".", "month", "=", "month", "\n", "self", ".", "day", "=", "day", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__eq__": [[10, 20], ["isinstance", "allennlp_semparse.common.errors.ExecutionError"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", "->", "bool", ":", "\n", "# Note that the logic below renders equality to be non-transitive. That is,", "\n", "# Date(2018, -1, -1) == Date(2018, 2, 3) and Date(2018, -1, -1) == Date(2018, 4, 5)", "\n", "# but Date(2018, 2, 3) != Date(2018, 4, 5).", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "Date", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "\"only compare Dates with Dates\"", ")", "\n", "", "year_is_same", "=", "self", ".", "year", "==", "-", "1", "or", "other", ".", "year", "==", "-", "1", "or", "self", ".", "year", "==", "other", ".", "year", "\n", "month_is_same", "=", "self", ".", "month", "==", "-", "1", "or", "other", ".", "month", "==", "-", "1", "or", "self", ".", "month", "==", "other", ".", "month", "\n", "day_is_same", "=", "self", ".", "day", "==", "-", "1", "or", "other", ".", "day", "==", "-", "1", "or", "self", ".", "day", "==", "other", ".", "day", "\n", "return", "year_is_same", "and", "month_is_same", "and", "day_is_same", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__gt__": [[21, 46], ["isinstance", "allennlp_semparse.common.errors.ExecutionError"], "methods", ["None"], ["", "def", "__gt__", "(", "self", ",", "other", ")", "->", "bool", ":", "\n", "# The logic below is tricky, and is based on some assumptions we make about date comparison.", "\n", "# Year, month or day being -1 means that we do not know its value. In those cases, the", "\n", "# we consider the comparison to be undefined, and return False if all the fields that are", "\n", "# more significant than the field being compared are equal. However, when year is -1 for both", "\n", "# dates being compared, it is safe to assume that the year is not specified because it is", "\n", "# the same. So we make an exception just in that case. That is, we deem the comparison", "\n", "# undefined only when one of the year values is -1, but not both.", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "Date", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "\"only compare Dates with Dates\"", ")", "\n", "# We're doing an exclusive or below.", "\n", "", "if", "(", "self", ".", "year", "==", "-", "1", ")", "!=", "(", "other", ".", "year", "==", "-", "1", ")", ":", "\n", "            ", "return", "False", "# comparison undefined", "\n", "# If both years are -1, we proceed.", "\n", "", "if", "self", ".", "year", "!=", "other", ".", "year", ":", "\n", "            ", "return", "self", ".", "year", ">", "other", ".", "year", "\n", "# The years are equal and not -1, or both are -1.", "\n", "", "if", "self", ".", "month", "==", "-", "1", "or", "other", ".", "month", "==", "-", "1", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "month", "!=", "other", ".", "month", ":", "\n", "            ", "return", "self", ".", "month", ">", "other", ".", "month", "\n", "# The months and years are equal and not -1", "\n", "", "if", "self", ".", "day", "==", "-", "1", "or", "other", ".", "day", "==", "-", "1", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "day", ">", "other", ".", "day", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__ge__": [[47, 51], ["isinstance", "allennlp_semparse.common.errors.ExecutionError"], "methods", ["None"], ["", "def", "__ge__", "(", "self", ",", "other", ")", "->", "bool", ":", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "Date", ")", ":", "\n", "            ", "raise", "ExecutionError", "(", "\"only compare Dates with Dates\"", ")", "\n", "", "return", "self", ">", "other", "or", "self", "==", "other", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__str__": [[52, 58], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "(", "self", ".", "month", ",", "self", ".", "day", ")", "==", "(", "-", "1", ",", "-", "1", ")", ":", "\n", "# If we have only the year, return just that so that the official evaluator does the", "\n", "# comparison against the target as if both are numbers.", "\n", "            ", "return", "str", "(", "self", ".", "year", ")", "\n", "", "return", "f\"{self.year}-{self.month}-{self.day}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.__hash__": [[59, 61], ["hash", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "str", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.to_json": [[62, 64], ["str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date.Date.make_date": [[65, 84], ["string.split", "date.Date", "int", "int", "int"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "make_date", "(", "cls", ",", "string", ":", "str", ")", "->", "\"Date\"", ":", "\n", "        ", "year_string", ",", "month_string", ",", "day_string", "=", "string", ".", "split", "(", "\"-\"", ")", "\n", "year", "=", "-", "1", "\n", "month", "=", "-", "1", "\n", "day", "=", "-", "1", "\n", "try", ":", "\n", "            ", "year", "=", "int", "(", "year_string", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "", "try", ":", "\n", "            ", "month", "=", "int", "(", "month_string", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "", "try", ":", "\n", "            ", "day", "=", "int", "(", "day_string", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "", "return", "Date", "(", "year", ",", "month", ",", "day", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util_test.TestSemparseUtil.test_lisp_to_nested_expression": [[7, 17], ["allennlp_semparse.common.util.lisp_to_nested_expression", "allennlp_semparse.common.util.lisp_to_nested_expression"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util.lisp_to_nested_expression", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.util.lisp_to_nested_expression"], ["\n", "class", "TestStateMachinesUtil", "(", "SemparseTestCase", ")", ":", "\n", "    ", "def", "test_create_allowed_transitions", "(", "self", ")", ":", "\n", "        ", "targets", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "2", ",", "3", ",", "4", "]", ",", "[", "1", ",", "3", ",", "4", "]", ",", "[", "1", ",", "2", ",", "4", "]", "]", ",", "[", "[", "3", ",", "4", ",", "0", "]", ",", "[", "2", ",", "3", ",", "4", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", "]", "\n", ")", "\n", "target_mask", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ",", "[", "[", "1", ",", "1", ",", "0", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", "]", "\n", ")", "\n", "prefix_tree", "=", "util", ".", "construct_prefix_tree", "(", "targets", ",", "target_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.FakeLanguageWithAssertions.object_exists": [[13, 16], ["None"], "methods", ["None"], ["    ", "@", "predicate", "\n", "def", "object_exists", "(", "self", ",", "items", ":", "Set", "[", "Object", "]", ")", "->", "bool", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.FakeLanguageWithAssertions.black": [[17, 20], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "black", "(", "self", ",", "items", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.FakeLanguageWithAssertions.triangle": [[21, 24], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "triangle", "(", "self", ",", "items", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.FakeLanguageWithAssertions.touch_wall": [[25, 28], ["None"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "touch_wall", "(", "self", ",", "items", ":", "Set", "[", "Object", "]", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.FakeLanguageWithAssertions.all_objects": [[29, 32], ["set"], "methods", ["None"], ["", "@", "predicate", "\n", "def", "all_objects", "(", "self", ")", "->", "Set", "[", "Object", "]", ":", "\n", "        ", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.setup_method": [[35, 39], ["super().setup_method", "action_space_walker_test.FakeLanguageWithAssertions", "allennlp_semparse.ActionSpaceWalker"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "world", "=", "FakeLanguageWithAssertions", "(", "start_types", "=", "{", "bool", "}", ")", "\n", "self", ".", "walker", "=", "ActionSpaceWalker", "(", "self", ".", "world", ",", "max_path_length", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.test_get_logical_forms_with_agenda": [[40, 67], ["action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "len", "action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "set", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda"], ["", "def", "test_get_logical_forms_with_agenda", "(", "self", ")", ":", "\n", "        ", "black_logical_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "[", "\"<Set[Object]:Set[Object]> -> black\"", "]", "\n", ")", "\n", "# These are all the possible logical forms with black", "\n", "assert", "len", "(", "black_logical_forms", ")", "==", "25", "\n", "shortest_logical_form", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "[", "\"<Set[Object]:Set[Object]> -> black\"", "]", ",", "1", "\n", ")", "[", "0", "]", "\n", "# This is the shortest complete logical form with black", "\n", "assert", "shortest_logical_form", "==", "\"(object_exists (black all_objects))\"", "\n", "agenda", "=", "[", "\n", "\"<Set[Object]:Set[Object]> -> black\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> triangle\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "]", "\n", "black_triangle_touch_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "agenda", ")", "\n", "# Permutations of the three functions. There will not be repetitions of any functions", "\n", "# because we limit the length of paths to 10 above.", "\n", "assert", "set", "(", "black_triangle_touch_forms", ")", "==", "set", "(", "\n", "[", "\n", "\"(object_exists (black (triangle (touch_wall all_objects))))\"", ",", "\n", "\"(object_exists (black (touch_wall (triangle all_objects))))\"", ",", "\n", "\"(object_exists (triangle (black (touch_wall all_objects))))\"", ",", "\n", "\"(object_exists (triangle (touch_wall (black all_objects))))\"", ",", "\n", "\"(object_exists (touch_wall (black (triangle all_objects))))\"", ",", "\n", "\"(object_exists (touch_wall (triangle (black all_objects))))\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.test_get_logical_forms_with_agenda_and_partial_match": [[70, 120], ["action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "len", "action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "set", "set", "set", "set", "set", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda"], ["", "def", "test_get_logical_forms_with_agenda_and_partial_match", "(", "self", ")", ":", "\n", "        ", "black_logical_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "[", "\"<Set[Object]:Set[Object]> -> black\"", "]", "\n", ")", "\n", "# These are all the possible logical forms with black", "\n", "assert", "len", "(", "black_logical_forms", ")", "==", "25", "\n", "shortest_logical_form", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "[", "\"<Set[Object]:Set[Object]> -> black\"", "]", ",", "1", "\n", ")", "[", "0", "]", "\n", "# This is the shortest complete logical form with black", "\n", "assert", "shortest_logical_form", "==", "\"(object_exists (black all_objects))\"", "\n", "agenda", "=", "[", "\n", "\"<Set[Object]:Set[Object]> -> black\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> triangle\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "]", "\n", "black_triangle_touch_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "agenda", ",", "allow_partial_match", "=", "True", "\n", ")", "\n", "# The first six logical forms will contain permutations of all three functions.", "\n", "assert", "set", "(", "black_triangle_touch_forms", "[", ":", "6", "]", ")", "==", "set", "(", "\n", "[", "\n", "\"(object_exists (black (triangle (touch_wall all_objects))))\"", ",", "\n", "\"(object_exists (black (touch_wall (triangle all_objects))))\"", ",", "\n", "\"(object_exists (triangle (black (touch_wall all_objects))))\"", ",", "\n", "\"(object_exists (triangle (touch_wall (black all_objects))))\"", ",", "\n", "\"(object_exists (touch_wall (black (triangle all_objects))))\"", ",", "\n", "\"(object_exists (touch_wall (triangle (black all_objects))))\"", ",", "\n", "]", "\n", ")", "\n", "\n", "# The next six will be the shortest six with two agenda items.", "\n", "assert", "set", "(", "black_triangle_touch_forms", "[", "6", ":", "12", "]", ")", "==", "set", "(", "\n", "[", "\n", "\"(object_exists (black (triangle all_objects)))\"", ",", "\n", "\"(object_exists (black (touch_wall all_objects)))\"", ",", "\n", "\"(object_exists (triangle (black all_objects)))\"", ",", "\n", "\"(object_exists (triangle (touch_wall all_objects)))\"", ",", "\n", "\"(object_exists (touch_wall (black all_objects)))\"", ",", "\n", "\"(object_exists (touch_wall (triangle all_objects)))\"", ",", "\n", "]", "\n", ")", "\n", "\n", "# After a bunch of longer logical forms with two agenda items, we have the shortest three", "\n", "# with one agenda item.", "\n", "assert", "set", "(", "black_triangle_touch_forms", "[", "30", ":", "33", "]", ")", "==", "set", "(", "\n", "[", "\n", "\"(object_exists (black all_objects))\"", ",", "\n", "\"(object_exists (triangle all_objects))\"", ",", "\n", "\"(object_exists (touch_wall all_objects))\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.test_get_logical_forms_with_empty_agenda_returns_all_logical_forms": [[123, 135], ["action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda"], ["", "def", "test_get_logical_forms_with_empty_agenda_returns_all_logical_forms", "(", "self", ",", "caplog", ")", ":", "\n", "        ", "empty_agenda_logical_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "[", "]", ",", "allow_partial_match", "=", "True", "\n", ")", "\n", "first_four_logical_forms", "=", "empty_agenda_logical_forms", "[", ":", "4", "]", "\n", "assert", "set", "(", "first_four_logical_forms", ")", "==", "{", "\n", "\"(object_exists all_objects)\"", ",", "\n", "\"(object_exists (black all_objects))\"", ",", "\n", "\"(object_exists (touch_wall all_objects))\"", ",", "\n", "\"(object_exists (triangle all_objects))\"", ",", "\n", "}", "\n", "assert", "\"Agenda is empty! Returning all paths instead.\"", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.test_get_logical_forms_with_unmatched_agenda_returns_all_logical_forms": [[136, 151], ["action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda"], ["", "def", "test_get_logical_forms_with_unmatched_agenda_returns_all_logical_forms", "(", "self", ",", "caplog", ")", ":", "\n", "        ", "agenda", "=", "[", "\"<Set[Object]:Set[Object]> -> purple\"", "]", "\n", "empty_agenda_logical_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "\n", "agenda", ",", "allow_partial_match", "=", "True", "\n", ")", "\n", "first_four_logical_forms", "=", "empty_agenda_logical_forms", "[", ":", "4", "]", "\n", "assert", "set", "(", "first_four_logical_forms", ")", "==", "{", "\n", "\"(object_exists all_objects)\"", ",", "\n", "\"(object_exists (black all_objects))\"", ",", "\n", "\"(object_exists (touch_wall all_objects))\"", ",", "\n", "\"(object_exists (triangle all_objects))\"", ",", "\n", "}", "\n", "assert", "\"Agenda items not in any of the paths found. Returning all paths.\"", "in", "caplog", ".", "text", "\n", "empty_set", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "agenda", ",", "allow_partial_match", "=", "False", ")", "\n", "assert", "empty_set", "==", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.test_get_logical_forms_with_agenda_ignores_null_set_item": [[152, 174], ["action_space_walker_test.TestActionSpaceWalker.walker.get_logical_forms_with_agenda", "set", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_logical_forms_with_agenda"], ["", "def", "test_get_logical_forms_with_agenda_ignores_null_set_item", "(", "self", ",", "caplog", ")", ":", "\n", "        ", "agenda", "=", "[", "\n", "\"<Set[Object]:Set[Object]> -> yellow\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> black\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> triangle\"", ",", "\n", "\"<Set[Object]:Set[Object]> -> touch_wall\"", ",", "\n", "]", "\n", "yellow_black_triangle_touch_forms", "=", "self", ".", "walker", ".", "get_logical_forms_with_agenda", "(", "agenda", ")", "\n", "# Permutations of the three functions, after ignoring yellow. There will not be repetitions", "\n", "# of any functions because we limit the length of paths to 10 above.", "\n", "assert", "set", "(", "yellow_black_triangle_touch_forms", ")", "==", "set", "(", "\n", "[", "\n", "\"(object_exists (black (triangle (touch_wall all_objects))))\"", ",", "\n", "\"(object_exists (black (touch_wall (triangle all_objects))))\"", ",", "\n", "\"(object_exists (triangle (black (touch_wall all_objects))))\"", ",", "\n", "\"(object_exists (triangle (touch_wall (black all_objects))))\"", ",", "\n", "\"(object_exists (touch_wall (black (triangle all_objects))))\"", ",", "\n", "\"(object_exists (touch_wall (triangle (black all_objects))))\"", ",", "\n", "]", "\n", ")", "\n", "log", "=", "\"<Set[Object]:Set[Object]> -> yellow is not in any of the paths found! Ignoring it.\"", "\n", "assert", "log", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker_test.TestActionSpaceWalker.test_get_all_logical_forms": [[175, 185], ["action_space_walker_test.TestActionSpaceWalker.walker.get_all_logical_forms", "set"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.action_space_walker.ActionSpaceWalker.get_all_logical_forms"], ["", "def", "test_get_all_logical_forms", "(", "self", ")", ":", "\n", "# get_all_logical_forms should sort logical forms by length.", "\n", "        ", "ten_shortest_logical_forms", "=", "self", ".", "walker", ".", "get_all_logical_forms", "(", "max_num_logical_forms", "=", "10", ")", "\n", "shortest_logical_form", "=", "ten_shortest_logical_forms", "[", "0", "]", "\n", "assert", "shortest_logical_form", "==", "\"(object_exists all_objects)\"", "\n", "length_three_logical_forms", "=", "ten_shortest_logical_forms", "[", "1", ":", "4", "]", "\n", "assert", "set", "(", "length_three_logical_forms", ")", "==", "{", "\n", "\"(object_exists (black all_objects))\"", ",", "\n", "\"(object_exists (touch_wall all_objects))\"", ",", "\n", "\"(object_exists (triangle all_objects))\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.common.date_test.TestDate.test_date_comparison_works": [[9, 31], ["allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "pytest.raises", "pytest.raises", "pytest.raises", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date", "allennlp_semparse.common.Date"], "methods", ["None"], ["    ", "def", "test_date_comparison_works", "(", "self", ")", ":", "\n", "        ", "assert", "Date", "(", "2013", ",", "12", ",", "31", ")", ">", "Date", "(", "2013", ",", "12", ",", "30", ")", "\n", "assert", "Date", "(", "2013", ",", "12", ",", "31", ")", "==", "Date", "(", "2013", ",", "12", ",", "-", "1", ")", "\n", "assert", "Date", "(", "2013", ",", "-", "1", ",", "-", "1", ")", ">=", "Date", "(", "2013", ",", "12", ",", "31", ")", "\n", "assert", "(", "Date", "(", "2013", ",", "12", ",", "-", "1", ")", ">", "Date", "(", "2013", ",", "12", ",", "31", ")", ")", "is", "False", "\n", "with", "pytest", ".", "raises", "(", "ExecutionError", ",", "match", "=", "\"only compare Dates with Dates\"", ")", ":", "\n", "            ", "assert", "(", "Date", "(", "2013", ",", "12", ",", "31", ")", ">", "2013", ")", "is", "False", "\n", "", "with", "pytest", ".", "raises", "(", "ExecutionError", ",", "match", "=", "\"only compare Dates with Dates\"", ")", ":", "\n", "            ", "assert", "(", "Date", "(", "2013", ",", "12", ",", "31", ")", ">=", "2013", ")", "is", "False", "\n", "", "with", "pytest", ".", "raises", "(", "ExecutionError", ",", "match", "=", "\"only compare Dates with Dates\"", ")", ":", "\n", "            ", "assert", "Date", "(", "2013", ",", "12", ",", "31", ")", "!=", "2013", "\n", "", "assert", "(", "Date", "(", "2018", ",", "1", ",", "1", ")", ">=", "Date", "(", "-", "1", ",", "2", ",", "1", ")", ")", "is", "False", "\n", "assert", "(", "Date", "(", "2018", ",", "1", ",", "1", ")", "<", "Date", "(", "-", "1", ",", "2", ",", "1", ")", ")", "is", "False", "\n", "# When year is unknown in both cases, we can compare months and days.", "\n", "assert", "Date", "(", "-", "1", ",", "2", ",", "1", ")", "<", "Date", "(", "-", "1", ",", "2", ",", "3", ")", "\n", "# If both year and month are not know in both cases, the comparison is undefined, and both", "\n", "# < and >= return False.", "\n", "assert", "(", "Date", "(", "-", "1", ",", "-", "1", ",", "1", ")", "<", "Date", "(", "-", "1", ",", "-", "1", ",", "3", ")", ")", "is", "False", "\n", "assert", "(", "Date", "(", "-", "1", ",", "-", "1", ",", "1", ")", ">=", "Date", "(", "-", "1", ",", "-", "1", ",", "3", ")", ")", "is", "False", "\n", "# Same when year is known, but months are not.", "\n", "assert", "(", "Date", "(", "2018", ",", "-", "1", ",", "1", ")", "<", "Date", "(", "2018", ",", "-", "1", ",", "3", ")", ")", "is", "False", "\n", "assert", "(", "Date", "(", "2018", ",", "-", "1", ",", "1", ")", ">=", "Date", "(", "2018", ",", "-", "1", ",", "3", ")", ")", "is", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.column_has_string_type": [[48, 57], ["None"], "function", ["None"], ["", "def", "column_has_string_type", "(", "column", ":", "TableColumn", ")", "->", "bool", ":", "\n", "    ", "if", "\"varchar\"", "in", "column", ".", "column_type", ":", "\n", "        ", "return", "True", "\n", "", "elif", "column", ".", "column_type", "==", "\"text\"", ":", "\n", "        ", "return", "True", "\n", "", "elif", "column", ".", "column_type", "==", "\"longtext\"", ":", "\n", "        ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.column_has_numeric_type": [[59, 67], ["None"], "function", ["None"], ["", "def", "column_has_numeric_type", "(", "column", ":", "TableColumn", ")", "->", "bool", ":", "\n", "    ", "if", "\"int\"", "in", "column", ".", "column_type", ":", "\n", "        ", "return", "True", "\n", "", "elif", "\"float\"", "in", "column", ".", "column_type", ":", "\n", "        ", "return", "True", "\n", "", "elif", "\"double\"", "in", "column", ".", "column_type", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.replace_variables": [[69, 86], ["tokens.append", "tags.append", "sentence_variables[].split", "tokens.append", "tags.append"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "replace_variables", "(", "\n", "sentence", ":", "List", "[", "str", "]", ",", "sentence_variables", ":", "Dict", "[", "str", ",", "str", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    Replaces abstract variables in text with their concrete counterparts.\n    \"\"\"", "\n", "tokens", "=", "[", "]", "\n", "tags", "=", "[", "]", "\n", "for", "token", "in", "sentence", ":", "\n", "        ", "if", "token", "not", "in", "sentence_variables", ":", "\n", "            ", "tokens", ".", "append", "(", "token", ")", "\n", "tags", ".", "append", "(", "\"O\"", ")", "\n", "", "else", ":", "\n", "            ", "for", "word", "in", "sentence_variables", "[", "token", "]", ".", "split", "(", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "word", ")", "\n", "tags", ".", "append", "(", "token", ")", "\n", "", "", "", "return", "tokens", ",", "tags", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.split_table_and_column_names": [[88, 94], ["partitioned[].isnumeric", "partitioned[].isnumeric", "table.partition"], "function", ["None"], ["", "def", "split_table_and_column_names", "(", "table", ":", "str", ")", "->", "Iterable", "[", "str", "]", ":", "\n", "    ", "partitioned", "=", "[", "x", "for", "x", "in", "table", ".", "partition", "(", "\".\"", ")", "if", "x", "!=", "\"\"", "]", "\n", "# Avoid splitting decimal strings.", "\n", "if", "partitioned", "[", "0", "]", ".", "isnumeric", "(", ")", "and", "partitioned", "[", "-", "1", "]", ".", "isnumeric", "(", ")", ":", "\n", "        ", "return", "[", "table", "]", "\n", "", "return", "partitioned", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_and_split_sql": [[96, 110], ["sql.strip().split", "token.replace().replace.replace().replace", "sql.strip", "token.replace().replace.endswith", "sql_tokens.extend", "sql_tokens.extend", "sql_tokens.extend", "token.replace().replace.replace", "len", "text2sql_utils.split_table_and_column_names", "text2sql_utils.split_table_and_column_names", "text2sql_utils.split_table_and_column_names"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.split_table_and_column_names", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.split_table_and_column_names", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.split_table_and_column_names"], ["", "def", "clean_and_split_sql", "(", "sql", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Cleans up and unifies a SQL query. This involves unifying quoted strings\n    and splitting brackets which aren't formatted consistently in the data.\n    \"\"\"", "\n", "sql_tokens", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "for", "token", "in", "sql", ".", "strip", "(", ")", ".", "split", "(", ")", ":", "\n", "        ", "token", "=", "token", ".", "replace", "(", "'\"'", ",", "\"'\"", ")", ".", "replace", "(", "\"%\"", ",", "\"\"", ")", "\n", "if", "token", ".", "endswith", "(", "\"(\"", ")", "and", "len", "(", "token", ")", ">", "1", ":", "\n", "            ", "sql_tokens", ".", "extend", "(", "split_table_and_column_names", "(", "token", "[", ":", "-", "1", "]", ")", ")", "\n", "sql_tokens", ".", "extend", "(", "split_table_and_column_names", "(", "token", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "sql_tokens", ".", "extend", "(", "split_table_and_column_names", "(", "token", ")", ")", "\n", "", "", "return", "sql_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.resolve_primary_keys_in_schema": [[112, 132], ["enumerate", "resolved_tokens.append", "max", "schema.items", "primary_keys_for_tables.keys"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "resolve_primary_keys_in_schema", "(", "\n", "sql_tokens", ":", "List", "[", "str", "]", ",", "schema", ":", "Dict", "[", "str", ",", "List", "[", "TableColumn", "]", "]", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Some examples in the text2sql datasets use ID as a column reference to the\n    column of a table which has a primary key. This causes problems if you are trying\n    to constrain a grammar to only produce the column names directly, because you don't\n    know what ID refers to. So instead of dealing with that, we just replace it.\n    \"\"\"", "\n", "primary_keys_for_tables", "=", "{", "\n", "name", ":", "max", "(", "columns", ",", "key", "=", "lambda", "x", ":", "x", ".", "is_primary_key", ")", ".", "name", "for", "name", ",", "columns", "in", "schema", ".", "items", "(", ")", "\n", "}", "\n", "resolved_tokens", "=", "[", "]", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "sql_tokens", ")", ":", "\n", "        ", "if", "i", ">", "2", ":", "\n", "            ", "table_name", "=", "sql_tokens", "[", "i", "-", "2", "]", "\n", "if", "token", "==", "\"ID\"", "and", "table_name", "in", "primary_keys_for_tables", ".", "keys", "(", ")", ":", "\n", "                ", "token", "=", "primary_keys_for_tables", "[", "table_name", "]", "\n", "", "", "resolved_tokens", ".", "append", "(", "token", ")", "\n", "", "return", "resolved_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_unneeded_aliases": [[134, 162], ["zip", "unneeded_aliases.get", "dealiased_tokens.append", "dealiased_tokens.pop"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "clean_unneeded_aliases", "(", "sql_tokens", ":", "List", "[", "str", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "\n", "    ", "unneeded_aliases", "=", "{", "}", "\n", "previous_token", "=", "sql_tokens", "[", "0", "]", "\n", "for", "(", "token", ",", "next_token", ")", "in", "zip", "(", "sql_tokens", "[", "1", ":", "-", "1", "]", ",", "sql_tokens", "[", "2", ":", "]", ")", ":", "\n", "        ", "if", "token", "==", "\"AS\"", "and", "previous_token", "is", "not", "None", ":", "\n", "# Check to see if the table name without the alias", "\n", "# is the same.", "\n", "            ", "table_name", "=", "next_token", "[", ":", "-", "6", "]", "\n", "if", "table_name", "==", "previous_token", ":", "\n", "# If so, store the mapping as a replacement.", "\n", "                ", "unneeded_aliases", "[", "next_token", "]", "=", "previous_token", "\n", "\n", "", "", "previous_token", "=", "token", "\n", "\n", "", "dealiased_tokens", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "for", "token", "in", "sql_tokens", ":", "\n", "        ", "new_token", "=", "unneeded_aliases", ".", "get", "(", "token", ",", "None", ")", "\n", "\n", "if", "new_token", "is", "not", "None", "and", "dealiased_tokens", "[", "-", "1", "]", "==", "\"AS\"", ":", "\n", "            ", "dealiased_tokens", ".", "pop", "(", ")", "\n", "continue", "\n", "", "elif", "new_token", "is", "None", ":", "\n", "            ", "new_token", "=", "token", "\n", "\n", "", "dealiased_tokens", ".", "append", "(", "new_token", ")", "\n", "\n", "", "return", "dealiased_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.read_dataset_schema": [[164, 197], ["collections.defaultdict", "enumerate", "open", "x.strip", "schema[].append", "line.split", "data.get", "data.get", "data.get", "data.get", "data.get", "text2sql_utils.TableColumn", "zip", "column.upper", "x.strip", "table.upper", "line.split"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.append"], ["", "def", "read_dataset_schema", "(", "schema_path", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "TableColumn", "]", "]", ":", "\n", "    ", "\"\"\"\n    Reads a schema from the text2sql data, returning a dictionary\n    mapping table names to their columns and respective types.\n    This handles columns in an arbitrary order and also allows\n    either ``{Table, Field}`` or ``{Table, Field} Name`` as headers,\n    because both appear in the data. It also uppercases table and\n    column names if they are not already uppercase.\n\n    Parameters\n    ----------\n    schema_path : ``str``, required.\n        The path to the csv schema.\n\n    Returns\n    -------\n    A dictionary mapping table names to typed columns.\n    \"\"\"", "\n", "schema", ":", "Dict", "[", "str", ",", "List", "[", "TableColumn", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "schema_path", ",", "\"r\"", ")", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "header", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "line", ".", "split", "(", "\",\"", ")", "]", "\n", "", "elif", "line", "[", "0", "]", "==", "\"-\"", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "data", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "zip", "(", "header", ",", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "line", ".", "split", "(", "\",\"", ")", "]", ")", "}", "\n", "\n", "table", "=", "data", ".", "get", "(", "\"Table Name\"", ",", "None", ")", "or", "data", ".", "get", "(", "\"Table\"", ")", "\n", "column", "=", "data", ".", "get", "(", "\"Field Name\"", ",", "None", ")", "or", "data", ".", "get", "(", "\"Field\"", ")", "\n", "is_primary_key", "=", "data", ".", "get", "(", "\"Primary Key\"", ")", "==", "\"y\"", "\n", "schema", "[", "table", ".", "upper", "(", ")", "]", ".", "append", "(", "TableColumn", "(", "column", ".", "upper", "(", ")", ",", "data", "[", "\"Type\"", "]", ",", "is_primary_key", ")", ")", "\n", "\n", "", "", "return", "{", "**", "schema", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data": [[199, 278], ["set", "sent_info[].strip().split", "text2sql_utils.replace_variables", "text2sql_utils.clean_and_split_sql", "text2sql_utils.SqlData", "text2sql_utils.clean_unneeded_aliases", "text2sql_utils.resolve_primary_keys_in_schema", "sent_info[].strip", "seen_sentences.add"], "function", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.replace_variables", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_and_split_sql", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_unneeded_aliases", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.resolve_primary_keys_in_schema", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.domain_languages.domain_language_test.Arithmetic.add"], ["", "def", "process_sql_data", "(", "\n", "data", ":", "List", "[", "JsonDict", "]", ",", "\n", "use_all_sql", ":", "bool", "=", "False", ",", "\n", "use_all_queries", ":", "bool", "=", "False", ",", "\n", "remove_unneeded_aliases", ":", "bool", "=", "False", ",", "\n", "schema", ":", "Dict", "[", "str", ",", "List", "[", "TableColumn", "]", "]", "=", "None", ",", "\n", ")", "->", "Iterable", "[", "SqlData", "]", ":", "\n", "    ", "\"\"\"\n    A utility function for reading in text2sql data. The blob is\n    the result of loading the json from a file produced by the script\n    ``scripts/reformat_text2sql_data.py``.\n\n    Parameters\n    ----------\n    data : ``JsonDict``\n    use_all_sql : ``bool``, optional (default = False)\n        Whether to use all of the sql queries which have identical semantics,\n        or whether to just use the first one.\n    use_all_queries : ``bool``, (default = False)\n        Whether or not to enforce query sentence uniqueness. If false,\n        duplicated queries will occur in the dataset as separate instances,\n        as for a given SQL query, not only are there multiple queries with\n        the same template, but there are also duplicate queries.\n    remove_unneeded_aliases : ``bool``, (default = False)\n        The text2sql data by default creates alias names for `all` tables,\n        regardless of whether the table is derived or if it is identical to\n        the original (e.g SELECT TABLEalias0.COLUMN FROM TABLE AS TABLEalias0).\n        This is not necessary and makes the action sequence and grammar manipulation\n        much harder in a grammar based decoder. Note that this does not\n        remove aliases which are legitimately required, such as when a new\n        table is formed by performing operations on the original table.\n    schema : ``Dict[str, List[TableColumn]]``, optional, (default = None)\n        A schema to resolve primary keys against. Converts 'ID' column names\n        to their actual name with respect to the Primary Key for the table\n        in the schema.\n    \"\"\"", "\n", "for", "example", "in", "data", ":", "\n", "        ", "seen_sentences", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "for", "sent_info", "in", "example", "[", "\"sentences\"", "]", ":", "\n", "# Loop over the different sql statements with \"equivalent\" semantics", "\n", "            ", "for", "sql", "in", "example", "[", "\"sql\"", "]", ":", "\n", "                ", "text_with_variables", "=", "sent_info", "[", "\"text\"", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "text_vars", "=", "sent_info", "[", "\"variables\"", "]", "\n", "\n", "query_tokens", ",", "tags", "=", "replace_variables", "(", "text_with_variables", ",", "text_vars", ")", "\n", "if", "not", "use_all_queries", ":", "\n", "                    ", "key", "=", "\" \"", ".", "join", "(", "query_tokens", ")", "\n", "if", "key", "in", "seen_sentences", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "seen_sentences", ".", "add", "(", "key", ")", "\n", "\n", "", "", "sql_tokens", "=", "clean_and_split_sql", "(", "sql", ")", "\n", "if", "remove_unneeded_aliases", ":", "\n", "                    ", "sql_tokens", "=", "clean_unneeded_aliases", "(", "sql_tokens", ")", "\n", "", "if", "schema", "is", "not", "None", ":", "\n", "                    ", "sql_tokens", "=", "resolve_primary_keys_in_schema", "(", "sql_tokens", ",", "schema", ")", "\n", "\n", "", "sql_variables", "=", "{", "}", "\n", "for", "variable", "in", "example", "[", "\"variables\"", "]", ":", "\n", "                    ", "sql_variables", "[", "variable", "[", "\"name\"", "]", "]", "=", "{", "\n", "\"text\"", ":", "variable", "[", "\"example\"", "]", ",", "\n", "\"type\"", ":", "variable", "[", "\"type\"", "]", ",", "\n", "}", "\n", "\n", "", "sql_data", "=", "SqlData", "(", "\n", "text", "=", "query_tokens", ",", "\n", "text_with_variables", "=", "text_with_variables", ",", "\n", "variable_tags", "=", "tags", ",", "\n", "sql", "=", "sql_tokens", ",", "\n", "text_variables", "=", "text_vars", ",", "\n", "sql_variables", "=", "sql_variables", ",", "\n", ")", "\n", "yield", "sql_data", "\n", "\n", "# Some questions might have multiple equivalent SQL statements.", "\n", "# By default, we just use the first one. TODO(Mark): Use the shortest?", "\n", "if", "not", "use_all_sql", ":", "\n", "                    ", "break", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method": [[8, 11], ["super().setup_method"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.setup_method"], ["    ", "def", "setup_method", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup_method", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants_tiny.json\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_process_sql_data_blob": [[12, 251], ["json.load", "allennlp_semparse.common.sql.text2sql_utils.process_sql_data", "list", "allennlp_semparse.common.sql.text2sql_utils.process_sql_data", "enumerate", "open", "len", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "def", "test_process_sql_data_blob", "(", "self", ")", ":", "\n", "\n", "        ", "data", "=", "json", ".", "load", "(", "open", "(", "str", "(", "self", ".", "data", ")", ")", ")", "\n", "dataset", "=", "text2sql_utils", ".", "process_sql_data", "(", "[", "data", "[", "0", "]", "]", ")", "\n", "dataset", "=", "list", "(", "dataset", ")", "\n", "sql_data", "=", "dataset", "[", "0", "]", "\n", "# Check that question de-duplication happens by default", "\n", "# (otherwise there would be more than 1 dataset element).", "\n", "assert", "len", "(", "dataset", ")", "==", "1", "\n", "assert", "sql_data", ".", "text", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"buttercup\"", ",", "\n", "\"kitchen\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"san\"", ",", "\n", "\"francisco\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "sql_data", ".", "text_with_variables", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"name0\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"city_name0\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "sql_data", ".", "sql", "==", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"AS\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"ID\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "assert", "sql_data", ".", "text_variables", "==", "{", "\n", "\"city_name0\"", ":", "\"san francisco\"", ",", "\n", "\"name0\"", ":", "\"buttercup kitchen\"", ",", "\n", "}", "\n", "assert", "sql_data", ".", "sql_variables", "==", "{", "\n", "\"city_name0\"", ":", "{", "\"text\"", ":", "\"san francisco\"", ",", "\"type\"", ":", "\"city_name\"", "}", ",", "\n", "\"name0\"", ":", "{", "\"text\"", ":", "\"buttercup kitchen\"", ",", "\"type\"", ":", "\"name\"", "}", ",", "\n", "}", "\n", "\n", "dataset", "=", "text2sql_utils", ".", "process_sql_data", "(", "[", "data", "[", "1", "]", "]", ")", "\n", "correct_text", "=", "[", "\n", "[", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"chinese\"", ",", "\n", "\"restaurants\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"food_type0\"", ",", "\n", "\"restaurants\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"region0\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "]", ",", "\n", "[", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"places\"", ",", "\n", "\"for\"", ",", "\n", "\"chinese\"", ",", "\n", "\"food\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"places\"", ",", "\n", "\"for\"", ",", "\n", "\"food_type0\"", ",", "\n", "\"food\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"region0\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "]", ",", "\n", "[", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"chinese\"", ",", "\n", "\"places\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"food_type0\"", ",", "\n", "\"places\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"region0\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "]", ",", "\n", "[", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"places\"", ",", "\n", "\"for\"", ",", "\n", "\"chinese\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"bay\"", ",", "\n", "\"area\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"places\"", ",", "\n", "\"for\"", ",", "\n", "\"food_type0\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"the\"", ",", "\n", "\"region0\"", ",", "\n", "\"?\"", ",", "\n", "]", ",", "\n", "]", ",", "\n", "]", "\n", "\n", "for", "i", ",", "sql_data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "assert", "sql_data", ".", "sql", "==", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"GEOGRAPHIC\"", ",", "\n", "\"AS\"", ",", "\n", "\"GEOGRAPHICalias0\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"AS\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"GEOGRAPHICalias0\"", ",", "\n", "\".\"", ",", "\n", "\"REGION\"", ",", "\n", "\"=\"", ",", "\n", "\"'region0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"GEOGRAPHICalias0\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"FOOD_TYPE\"", ",", "\n", "\"=\"", ",", "\n", "\"'food_type0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "assert", "sql_data", ".", "text_variables", "==", "{", "\"region0\"", ":", "\"bay area\"", ",", "\"food_type0\"", ":", "\"chinese\"", "}", "\n", "assert", "sql_data", ".", "sql_variables", "==", "{", "\n", "\"region0\"", ":", "{", "\"text\"", ":", "\"bay area\"", ",", "\"type\"", ":", "\"region\"", "}", ",", "\n", "\"food_type0\"", ":", "{", "\"text\"", ":", "\"chinese\"", ",", "\"type\"", ":", "\"food_type\"", "}", ",", "\n", "}", "\n", "assert", "sql_data", ".", "text", "==", "correct_text", "[", "i", "]", "[", "0", "]", "\n", "assert", "sql_data", ".", "text_with_variables", "==", "correct_text", "[", "i", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_process_sql_data_can_yield_all_queries": [[252, 257], ["json.load", "allennlp_semparse.common.sql.text2sql_utils.process_sql_data", "list", "open", "len", "str"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.process_sql_data", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.type_declarations.type_declaration.PlaceholderType.str"], ["", "", "def", "test_process_sql_data_can_yield_all_queries", "(", "self", ")", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "open", "(", "str", "(", "self", ".", "data", ")", ")", ")", "\n", "dataset", "=", "text2sql_utils", ".", "process_sql_data", "(", "[", "data", "[", "0", "]", "]", ",", "use_all_queries", "=", "True", ")", "\n", "dataset", "=", "list", "(", "dataset", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_replace_variables": [[258, 275], ["allennlp_semparse.common.sql.text2sql_utils.replace_variables"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.replace_variables"], ["", "def", "test_replace_variables", "(", "self", ")", ":", "\n", "        ", "sentence", "=", "[", "\"how\"", ",", "\"many\"", ",", "\"name0\"", ",", "\"are\"", ",", "\"there\"", ",", "\"in\"", ",", "\"city_name0\"", ",", "\"?\"", "]", "\n", "sentence_variables", "=", "{", "\"city_name0\"", ":", "\"san francisco\"", ",", "\"name0\"", ":", "\"buttercup kitchen\"", "}", "\n", "tokens", ",", "tags", "=", "text2sql_utils", ".", "replace_variables", "(", "sentence", ",", "sentence_variables", ")", "\n", "assert", "tokens", "==", "[", "\n", "\"how\"", ",", "\n", "\"many\"", ",", "\n", "\"buttercup\"", ",", "\n", "\"kitchen\"", ",", "\n", "\"are\"", ",", "\n", "\"there\"", ",", "\n", "\"in\"", ",", "\n", "\"san\"", ",", "\n", "\"francisco\"", ",", "\n", "\"?\"", ",", "\n", "]", "\n", "assert", "tags", "==", "[", "\"O\"", ",", "\"O\"", ",", "\"name0\"", ",", "\"name0\"", ",", "\"O\"", ",", "\"O\"", ",", "\"O\"", ",", "\"city_name0\"", ",", "\"city_name0\"", ",", "\"O\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_clean_and_split_sql": [[276, 319], ["allennlp_semparse.common.sql.text2sql_utils.clean_and_split_sql"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_and_split_sql"], ["", "def", "test_clean_and_split_sql", "(", "self", ")", ":", "\n", "        ", "sql", "=", "(", "\n", "\"SELECT COUNT( * ) FROM LOCATION AS LOCATIONalias0 , RESTAURANT AS RESTAURANTalias0 \"", "\n", "'WHERE LOCATIONalias0.CITY_NAME = \"city_name0\" AND RESTAURANTalias0.ID = '", "\n", "'LOCATIONalias0.RESTAURANT_ID AND RESTAURANTalias0.NAME = \"name0\" ;'", "\n", ")", "\n", "\n", "cleaned", "=", "text2sql_utils", ".", "clean_and_split_sql", "(", "sql", ")", "\n", "assert", "cleaned", "==", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"AS\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"ID\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_clean_unneeded_aliases": [[321, 415], ["allennlp_semparse.common.sql.text2sql_utils.clean_unneeded_aliases", "allennlp_semparse.common.sql.text2sql_utils.clean_unneeded_aliases", "allennlp_semparse.common.sql.text2sql_utils.clean_unneeded_aliases"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_unneeded_aliases", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_unneeded_aliases", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.clean_unneeded_aliases"], ["", "def", "test_clean_unneeded_aliases", "(", "self", ")", ":", "\n", "        ", "sql", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"AS\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"ID\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANTalias0\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "cleaned", "=", "text2sql_utils", ".", "clean_unneeded_aliases", "(", "sql", ")", "\n", "assert", "cleaned", "==", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\",\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\"WHERE\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"CITY_NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'city_name0'\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"ID\"", ",", "\n", "\"=\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\"AND\"", ",", "\n", "\"RESTAURANT\"", ",", "\n", "\".\"", ",", "\n", "\"NAME\"", ",", "\n", "\"=\"", ",", "\n", "\"'name0'\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "# Check we don't mangle decimal numbers:", "\n", "assert", "text2sql_utils", ".", "clean_unneeded_aliases", "(", "[", "\"2.5\"", "]", ")", "==", "[", "\"2.5\"", "]", "\n", "\n", "# Check we don't remove non-trivial aliases:", "\n", "sql", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"MAX\"", ",", "\n", "\"(\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"ID\"", ",", "\n", "\")\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "assert", "text2sql_utils", ".", "clean_unneeded_aliases", "(", "sql", ")", "==", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_read_database_schema": [[416, 442], ["allennlp_semparse.common.sql.text2sql_utils.read_dataset_schema", "allennlp_semparse.common.sql.text2sql_utils.read_dataset_schema.items"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.read_dataset_schema"], ["", "def", "test_read_database_schema", "(", "self", ")", ":", "\n", "        ", "schema", "=", "text2sql_utils", ".", "read_dataset_schema", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants-schema.csv\"", "\n", ")", "\n", "# Make it easier to compare:", "\n", "schema", "=", "{", "\n", "k", ":", "[", "(", "x", ".", "name", ",", "x", ".", "column_type", ",", "x", ".", "is_primary_key", ")", "for", "x", "in", "v", "]", "for", "k", ",", "v", "in", "schema", ".", "items", "(", ")", "\n", "}", "\n", "assert", "schema", "==", "{", "\n", "\"RESTAURANT\"", ":", "[", "\n", "(", "\"RESTAURANT_ID\"", ",", "\"int(11)\"", ",", "True", ")", ",", "\n", "(", "\"NAME\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "(", "\"FOOD_TYPE\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "(", "\"CITY_NAME\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "(", "\"RATING\"", ",", "'\"decimal(1'", ",", "False", ")", ",", "\n", "]", ",", "\n", "\"LOCATION\"", ":", "[", "\n", "(", "\"RESTAURANT_ID\"", ",", "\"int(11)\"", ",", "True", ")", ",", "\n", "(", "\"HOUSE_NUMBER\"", ",", "\"int(11)\"", ",", "False", ")", ",", "\n", "(", "\"STREET_NAME\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "(", "\"CITY_NAME\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "]", ",", "\n", "\"GEOGRAPHIC\"", ":", "[", "\n", "(", "\"CITY_NAME\"", ",", "\"varchar(255)\"", ",", "True", ")", ",", "\n", "(", "\"COUNTY\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "(", "\"REGION\"", ",", "\"varchar(255)\"", ",", "False", ")", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils_test.TestText2SqlUtils.test_resolve_primary_keys_in_schema": [[445, 484], ["allennlp_semparse.common.sql.text2sql_utils.read_dataset_schema", "allennlp_semparse.common.sql.text2sql_utils.resolve_primary_keys_in_schema"], "methods", ["home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.read_dataset_schema", "home.repos.pwc.inspect_result.nitishgupta_allennlp-semparse.sql.text2sql_utils.resolve_primary_keys_in_schema"], ["", "def", "test_resolve_primary_keys_in_schema", "(", "self", ")", ":", "\n", "        ", "schema", "=", "text2sql_utils", ".", "read_dataset_schema", "(", "\n", "self", ".", "FIXTURES_ROOT", "/", "\"data\"", "/", "\"text2sql\"", "/", "\"restaurants-schema.csv\"", "\n", ")", "\n", "sql", "=", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"MAX\"", ",", "\n", "\"(\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"ID\"", ",", "\n", "\")\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\";\"", ",", "\n", "]", "\n", "\n", "resolved", "=", "text2sql_utils", ".", "resolve_primary_keys_in_schema", "(", "sql", ",", "schema", ")", "\n", "assert", "resolved", "==", "[", "\n", "\"SELECT\"", ",", "\n", "\"COUNT\"", ",", "\n", "\"(\"", ",", "\n", "\"*\"", ",", "\n", "\")\"", ",", "\n", "\"FROM\"", ",", "\n", "\"MAX\"", ",", "\n", "\"(\"", ",", "\n", "\"LOCATION\"", ",", "\n", "\".\"", ",", "\n", "\"RESTAURANT_ID\"", ",", "\n", "\")\"", ",", "\n", "\"AS\"", ",", "\n", "\"LOCATIONalias0\"", ",", "\n", "\";\"", ",", "\n", "]", "\n"]]}