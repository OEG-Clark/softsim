{"home.repos.pwc.inspect_result.bzantium_bert-AAD.None.main.parse_arguments": [[17, 82], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_arguments", "(", ")", ":", "\n", "# argument parsing", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Specify Params for Experimental Setting\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--src'", ",", "type", "=", "str", ",", "default", "=", "\"books\"", ",", "\n", "choices", "=", "[", "\"books\"", ",", "\"dvd\"", ",", "\"electronics\"", ",", "\"kitchen\"", ",", "\"blog\"", ",", "\"airline\"", ",", "\"imdb\"", "]", ",", "\n", "help", "=", "\"Specify src dataset\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--tgt'", ",", "type", "=", "str", ",", "default", "=", "\"dvd\"", ",", "\n", "choices", "=", "[", "\"books\"", ",", "\"dvd\"", ",", "\"electronics\"", ",", "\"kitchen\"", ",", "\"blog\"", ",", "\"airline\"", ",", "\"imdb\"", "]", ",", "\n", "help", "=", "\"Specify tgt dataset\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--pretrain'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Force to pretrain source encoder/classifier'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--adapt'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Force to adapt target encoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"Specify random state\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--train_seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"Specify random state\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--load'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Load saved model\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "\"bert\"", ",", "\n", "choices", "=", "[", "\"bert\"", ",", "\"distilbert\"", ",", "\"roberta\"", ",", "\"distilroberta\"", "]", ",", "\n", "help", "=", "\"Specify model type\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--max_seq_length'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"Specify maximum sequence length\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Specify adversarial weight\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--beta'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Specify KD loss weight\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "\"Specify temperature\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--clip_value\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "\"lower and upper clip value for disc. weights\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"Specify batch size\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--pre_epochs'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Specify the number of epochs for pretrain\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--pre_log_step'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Specify log step size for pretrain\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Specify the number of epochs for adaptation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--log_step'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Specify log step size for adaptation\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.main.set_seed": [[84, 89], ["random.seed", "torch.manual_seed", "torch.cuda.device_count", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.main.main": [[91, 217], ["main.parse_arguments", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "main.set_seed", "print", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "utils.get_data_loader", "utils.get_data_loader", "utils.get_data_loader", "utils.get_data_loader", "model.Discriminator", "print", "print", "train.evaluate", "train.evaluate", "train.evaluate", "model.DistilRobertaEncoder.parameters", "model.RobertaClassifier.parameters", "print", "print", "print", "train.evaluate", "print", "train.evaluate", "transformers.RobertaTokenizer.from_pretrained", "transformers.BertTokenizer.from_pretrained", "utils.CSV2Array", "utils.XML2Array", "utils.CSV2Array", "utils.XML2Array", "utils.roberta_convert_examples_to_features", "utils.roberta_convert_examples_to_features", "utils.roberta_convert_examples_to_features", "utils.roberta_convert_examples_to_features", "utils.convert_examples_to_features", "utils.convert_examples_to_features", "utils.convert_examples_to_features", "utils.convert_examples_to_features", "model.BertEncoder", "model.BertEncoder", "model.BertClassifier", "utils.init_model", "utils.init_model", "utils.init_model", "utils.init_model", "utils.init_model", "utils.init_model", "utils.init_model", "utils.init_model", "train.pretrain", "model.DistilRobertaEncoder.load_state_dict", "train.adapt", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "model.DistilBertEncoder", "model.DistilBertEncoder", "model.BertClassifier", "model.DistilRobertaEncoder.state_dict", "model.RobertaEncoder", "model.RobertaEncoder", "model.RobertaClassifier", "model.DistilRobertaEncoder", "model.DistilRobertaEncoder", "model.RobertaClassifier"], "function", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.main.parse_arguments", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.main.set_seed", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.get_data_loader", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.get_data_loader", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.get_data_loader", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.get_data_loader", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.CSV2Array", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.XML2Array", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.CSV2Array", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.XML2Array", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.roberta_convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.roberta_convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.roberta_convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.roberta_convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.pretrain", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.adapt"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_arguments", "(", ")", "\n", "# argument setting", "\n", "print", "(", "\"=== Argument Setting ===\"", ")", "\n", "print", "(", "\"src: \"", "+", "args", ".", "src", ")", "\n", "print", "(", "\"tgt: \"", "+", "args", ".", "tgt", ")", "\n", "print", "(", "\"seed: \"", "+", "str", "(", "args", ".", "seed", ")", ")", "\n", "print", "(", "\"train_seed: \"", "+", "str", "(", "args", ".", "train_seed", ")", ")", "\n", "print", "(", "\"model_type: \"", "+", "str", "(", "args", ".", "model", ")", ")", "\n", "print", "(", "\"max_seq_length: \"", "+", "str", "(", "args", ".", "max_seq_length", ")", ")", "\n", "print", "(", "\"batch_size: \"", "+", "str", "(", "args", ".", "batch_size", ")", ")", "\n", "print", "(", "\"pre_epochs: \"", "+", "str", "(", "args", ".", "pre_epochs", ")", ")", "\n", "print", "(", "\"num_epochs: \"", "+", "str", "(", "args", ".", "num_epochs", ")", ")", "\n", "print", "(", "\"AD weight: \"", "+", "str", "(", "args", ".", "alpha", ")", ")", "\n", "print", "(", "\"KD weight: \"", "+", "str", "(", "args", ".", "beta", ")", ")", "\n", "print", "(", "\"temperature: \"", "+", "str", "(", "args", ".", "temperature", ")", ")", "\n", "set_seed", "(", "args", ".", "train_seed", ")", "\n", "\n", "if", "args", ".", "model", "in", "[", "'roberta'", ",", "'distilroberta'", "]", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "\n", "# preprocess data", "\n", "", "print", "(", "\"=== Processing datasets ===\"", ")", "\n", "if", "args", ".", "src", "in", "[", "'blog'", ",", "'airline'", ",", "'imdb'", "]", ":", "\n", "        ", "src_x", ",", "src_y", "=", "CSV2Array", "(", "os", ".", "path", ".", "join", "(", "'data'", ",", "args", ".", "src", ",", "args", ".", "src", "+", "'.csv'", ")", ")", "\n", "", "else", ":", "\n", "        ", "src_x", ",", "src_y", "=", "XML2Array", "(", "os", ".", "path", ".", "join", "(", "'data'", ",", "args", ".", "src", ",", "'negative.review'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "args", ".", "src", ",", "'positive.review'", ")", ")", "\n", "\n", "", "src_x", ",", "src_test_x", ",", "src_y", ",", "src_test_y", "=", "train_test_split", "(", "src_x", ",", "src_y", ",", "\n", "test_size", "=", "0.2", ",", "\n", "stratify", "=", "src_y", ",", "\n", "random_state", "=", "args", ".", "seed", ")", "\n", "\n", "if", "args", ".", "tgt", "in", "[", "'blog'", ",", "'airline'", ",", "'imdb'", "]", ":", "\n", "        ", "tgt_x", ",", "tgt_y", "=", "CSV2Array", "(", "os", ".", "path", ".", "join", "(", "'data'", ",", "args", ".", "tgt", ",", "args", ".", "tgt", "+", "'.csv'", ")", ")", "\n", "", "else", ":", "\n", "        ", "tgt_x", ",", "tgt_y", "=", "XML2Array", "(", "os", ".", "path", ".", "join", "(", "'data'", ",", "args", ".", "tgt", ",", "'negative.review'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "args", ".", "tgt", ",", "'positive.review'", ")", ")", "\n", "\n", "", "tgt_train_x", ",", "tgt_test_y", ",", "tgt_train_y", ",", "tgt_test_y", "=", "train_test_split", "(", "tgt_x", ",", "tgt_y", ",", "\n", "test_size", "=", "0.2", ",", "\n", "stratify", "=", "tgt_y", ",", "\n", "random_state", "=", "args", ".", "seed", ")", "\n", "\n", "if", "args", ".", "model", "in", "[", "'roberta'", ",", "'distilroberta'", "]", ":", "\n", "        ", "src_features", "=", "roberta_convert_examples_to_features", "(", "src_x", ",", "src_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "src_test_features", "=", "roberta_convert_examples_to_features", "(", "src_test_x", ",", "src_test_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "tgt_features", "=", "roberta_convert_examples_to_features", "(", "tgt_x", ",", "tgt_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "tgt_train_features", "=", "roberta_convert_examples_to_features", "(", "tgt_train_x", ",", "tgt_train_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "", "else", ":", "\n", "        ", "src_features", "=", "convert_examples_to_features", "(", "src_x", ",", "src_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "src_test_features", "=", "convert_examples_to_features", "(", "src_test_x", ",", "src_test_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "tgt_features", "=", "convert_examples_to_features", "(", "tgt_x", ",", "tgt_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "tgt_train_features", "=", "convert_examples_to_features", "(", "tgt_train_x", ",", "tgt_train_y", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "\n", "# load dataset", "\n", "\n", "", "src_data_loader", "=", "get_data_loader", "(", "src_features", ",", "args", ".", "batch_size", ")", "\n", "src_data_eval_loader", "=", "get_data_loader", "(", "src_test_features", ",", "args", ".", "batch_size", ")", "\n", "tgt_data_train_loader", "=", "get_data_loader", "(", "tgt_train_features", ",", "args", ".", "batch_size", ")", "\n", "tgt_data_all_loader", "=", "get_data_loader", "(", "tgt_features", ",", "args", ".", "batch_size", ")", "\n", "\n", "# load models", "\n", "if", "args", ".", "model", "==", "'bert'", ":", "\n", "        ", "src_encoder", "=", "BertEncoder", "(", ")", "\n", "tgt_encoder", "=", "BertEncoder", "(", ")", "\n", "src_classifier", "=", "BertClassifier", "(", ")", "\n", "", "elif", "args", ".", "model", "==", "'distilbert'", ":", "\n", "        ", "src_encoder", "=", "DistilBertEncoder", "(", ")", "\n", "tgt_encoder", "=", "DistilBertEncoder", "(", ")", "\n", "src_classifier", "=", "BertClassifier", "(", ")", "\n", "", "elif", "args", ".", "model", "==", "'roberta'", ":", "\n", "        ", "src_encoder", "=", "RobertaEncoder", "(", ")", "\n", "tgt_encoder", "=", "RobertaEncoder", "(", ")", "\n", "src_classifier", "=", "RobertaClassifier", "(", ")", "\n", "", "else", ":", "\n", "        ", "src_encoder", "=", "DistilRobertaEncoder", "(", ")", "\n", "tgt_encoder", "=", "DistilRobertaEncoder", "(", ")", "\n", "src_classifier", "=", "RobertaClassifier", "(", ")", "\n", "", "discriminator", "=", "Discriminator", "(", ")", "\n", "\n", "if", "args", ".", "load", ":", "\n", "        ", "src_encoder", "=", "init_model", "(", "args", ",", "src_encoder", ",", "restore", "=", "param", ".", "src_encoder_path", ")", "\n", "src_classifier", "=", "init_model", "(", "args", ",", "src_classifier", ",", "restore", "=", "param", ".", "src_classifier_path", ")", "\n", "tgt_encoder", "=", "init_model", "(", "args", ",", "tgt_encoder", ",", "restore", "=", "param", ".", "tgt_encoder_path", ")", "\n", "discriminator", "=", "init_model", "(", "args", ",", "discriminator", ",", "restore", "=", "param", ".", "d_model_path", ")", "\n", "", "else", ":", "\n", "        ", "src_encoder", "=", "init_model", "(", "args", ",", "src_encoder", ")", "\n", "src_classifier", "=", "init_model", "(", "args", ",", "src_classifier", ")", "\n", "tgt_encoder", "=", "init_model", "(", "args", ",", "tgt_encoder", ")", "\n", "discriminator", "=", "init_model", "(", "args", ",", "discriminator", ")", "\n", "\n", "# train source model", "\n", "", "print", "(", "\"=== Training classifier for source domain ===\"", ")", "\n", "if", "args", ".", "pretrain", ":", "\n", "        ", "src_encoder", ",", "src_classifier", "=", "pretrain", "(", "\n", "args", ",", "src_encoder", ",", "src_classifier", ",", "src_data_loader", ")", "\n", "\n", "# eval source model", "\n", "", "print", "(", "\"=== Evaluating classifier for source domain ===\"", ")", "\n", "evaluate", "(", "src_encoder", ",", "src_classifier", ",", "src_data_loader", ")", "\n", "evaluate", "(", "src_encoder", ",", "src_classifier", ",", "src_data_eval_loader", ")", "\n", "evaluate", "(", "src_encoder", ",", "src_classifier", ",", "tgt_data_all_loader", ")", "\n", "\n", "for", "params", "in", "src_encoder", ".", "parameters", "(", ")", ":", "\n", "        ", "params", ".", "requires_grad", "=", "False", "\n", "\n", "", "for", "params", "in", "src_classifier", ".", "parameters", "(", ")", ":", "\n", "        ", "params", ".", "requires_grad", "=", "False", "\n", "\n", "# train target encoder by GAN", "\n", "", "print", "(", "\"=== Training encoder for target domain ===\"", ")", "\n", "if", "args", ".", "adapt", ":", "\n", "        ", "tgt_encoder", ".", "load_state_dict", "(", "src_encoder", ".", "state_dict", "(", ")", ")", "\n", "tgt_encoder", "=", "adapt", "(", "args", ",", "src_encoder", ",", "tgt_encoder", ",", "discriminator", ",", "\n", "src_classifier", ",", "src_data_loader", ",", "tgt_data_train_loader", ",", "tgt_data_all_loader", ")", "\n", "\n", "# eval target encoder on lambda0.1 set of target dataset", "\n", "", "print", "(", "\"=== Evaluating classifier for encoded target domain ===\"", ")", "\n", "print", "(", "\">>> source only <<<\"", ")", "\n", "evaluate", "(", "src_encoder", ",", "src_classifier", ",", "tgt_data_all_loader", ")", "\n", "print", "(", "\">>> domain adaption <<<\"", ")", "\n", "evaluate", "(", "tgt_encoder", ",", "src_classifier", ",", "tgt_data_all_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.pretrain": [[12, 56], ["torch.Adam", "torch.CrossEntropyLoss", "encoder.train", "classifier.train", "range", "utils.save_model", "utils.save_model", "enumerate", "list", "list", "utils.make_cuda", "utils.make_cuda", "utils.make_cuda", "optim.Adam.zero_grad", "encoder", "classifier", "nn.CrossEntropyLoss.", "CELoss.backward", "optim.Adam.step", "encoder.parameters", "classifier.parameters", "print", "len", "CELoss.item"], "function", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.save_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.save_model", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda"], ["def", "pretrain", "(", "args", ",", "encoder", ",", "classifier", ",", "data_loader", ")", ":", "\n", "    ", "\"\"\"Train classifier for source domain.\"\"\"", "\n", "\n", "# setup criterion and optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "list", "(", "encoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "classifier", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "param", ".", "c_learning_rate", ")", "\n", "CELoss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "# set train state for Dropout and BN layers", "\n", "encoder", ".", "train", "(", ")", "\n", "classifier", ".", "train", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "pre_epochs", ")", ":", "\n", "        ", "for", "step", ",", "(", "reviews", ",", "mask", ",", "labels", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "reviews", "=", "make_cuda", "(", "reviews", ")", "\n", "mask", "=", "make_cuda", "(", "mask", ")", "\n", "labels", "=", "make_cuda", "(", "labels", ")", "\n", "\n", "# zero gradients for optimizer", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# compute loss for discriminator", "\n", "feat", "=", "encoder", "(", "reviews", ",", "mask", ")", "\n", "preds", "=", "classifier", "(", "feat", ")", "\n", "cls_loss", "=", "CELoss", "(", "preds", ",", "labels", ")", "\n", "\n", "# optimize source classifier", "\n", "cls_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# print step info", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "pre_log_step", "==", "0", ":", "\n", "                ", "print", "(", "\"Epoch [%.2d/%.2d] Step [%.3d/%.3d]: cls_loss=%.4f\"", "\n", "%", "(", "epoch", "+", "1", ",", "\n", "args", ".", "pre_epochs", ",", "\n", "step", "+", "1", ",", "\n", "len", "(", "data_loader", ")", ",", "\n", "cls_loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "# save final model", "\n", "", "", "", "save_model", "(", "args", ",", "encoder", ",", "param", ".", "src_encoder_path", ")", "\n", "save_model", "(", "args", ",", "classifier", ",", "param", ".", "src_classifier_path", ")", "\n", "\n", "return", "encoder", ",", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.adapt": [[58, 151], ["src_encoder.eval", "src_classifier.eval", "tgt_encoder.train", "discriminator.train", "torch.BCELoss", "torch.KLDivLoss", "torch.Adam", "torch.Adam", "min", "range", "tgt_encoder.parameters", "discriminator.parameters", "len", "len", "enumerate", "train.evaluate", "zip", "utils.make_cuda", "utils.make_cuda", "utils.make_cuda", "utils.make_cuda", "optim.Adam.zero_grad", "tgt_encoder", "tgt_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "utils.make_cuda().unsqueeze", "utils.make_cuda().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nn.BCELoss.", "BCELoss.backward", "discriminator.parameters", "optim.Adam.step", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "optim.Adam.zero_grad", "discriminator", "torch.log_softmax", "nn.BCELoss.", "loss_tgt.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optim.Adam.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src_encoder", "torch.cat.detach", "p.data.clamp_", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.softmax", "tgt_encoder.parameters", "print", "utils.make_cuda", "utils.make_cuda", "discriminator.max", "src_classifier", "nn.KLDivLoss.", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "src_classifier", "F.softmax.detach", "tgt_encoder.size", "tgt_encoder.size", "acc.item", "BCELoss.item", "BCELoss.item", "kd_loss.item"], "function", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda"], ["", "def", "adapt", "(", "args", ",", "src_encoder", ",", "tgt_encoder", ",", "discriminator", ",", "\n", "src_classifier", ",", "src_data_loader", ",", "tgt_data_train_loader", ",", "tgt_data_all_loader", ")", ":", "\n", "    ", "\"\"\"Train encoder for target domain.\"\"\"", "\n", "\n", "# set train state for Dropout and BN layers", "\n", "src_encoder", ".", "eval", "(", ")", "\n", "src_classifier", ".", "eval", "(", ")", "\n", "tgt_encoder", ".", "train", "(", ")", "\n", "discriminator", ".", "train", "(", ")", "\n", "\n", "# setup criterion and optimizer", "\n", "BCELoss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "KLDivLoss", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'batchmean'", ")", "\n", "optimizer_G", "=", "optim", ".", "Adam", "(", "tgt_encoder", ".", "parameters", "(", ")", ",", "lr", "=", "param", ".", "d_learning_rate", ")", "\n", "optimizer_D", "=", "optim", ".", "Adam", "(", "discriminator", ".", "parameters", "(", ")", ",", "lr", "=", "param", ".", "d_learning_rate", ")", "\n", "len_data_loader", "=", "min", "(", "len", "(", "src_data_loader", ")", ",", "len", "(", "tgt_data_train_loader", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "# zip source and target data pair", "\n", "        ", "data_zip", "=", "enumerate", "(", "zip", "(", "src_data_loader", ",", "tgt_data_train_loader", ")", ")", "\n", "for", "step", ",", "(", "(", "reviews_src", ",", "src_mask", ",", "_", ")", ",", "(", "reviews_tgt", ",", "tgt_mask", ",", "_", ")", ")", "in", "data_zip", ":", "\n", "            ", "reviews_src", "=", "make_cuda", "(", "reviews_src", ")", "\n", "src_mask", "=", "make_cuda", "(", "src_mask", ")", "\n", "\n", "reviews_tgt", "=", "make_cuda", "(", "reviews_tgt", ")", "\n", "tgt_mask", "=", "make_cuda", "(", "tgt_mask", ")", "\n", "\n", "# zero gradients for optimizer", "\n", "optimizer_D", ".", "zero_grad", "(", ")", "\n", "\n", "# extract and concat features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "feat_src", "=", "src_encoder", "(", "reviews_src", ",", "src_mask", ")", "\n", "", "feat_src_tgt", "=", "tgt_encoder", "(", "reviews_src", ",", "src_mask", ")", "\n", "feat_tgt", "=", "tgt_encoder", "(", "reviews_tgt", ",", "tgt_mask", ")", "\n", "feat_concat", "=", "torch", ".", "cat", "(", "(", "feat_src_tgt", ",", "feat_tgt", ")", ",", "0", ")", "\n", "\n", "# predict on discriminator", "\n", "pred_concat", "=", "discriminator", "(", "feat_concat", ".", "detach", "(", ")", ")", "\n", "\n", "# prepare real and fake label", "\n", "label_src", "=", "make_cuda", "(", "torch", ".", "ones", "(", "feat_src_tgt", ".", "size", "(", "0", ")", ")", ")", ".", "unsqueeze", "(", "1", ")", "\n", "label_tgt", "=", "make_cuda", "(", "torch", ".", "zeros", "(", "feat_tgt", ".", "size", "(", "0", ")", ")", ")", ".", "unsqueeze", "(", "1", ")", "\n", "label_concat", "=", "torch", ".", "cat", "(", "(", "label_src", ",", "label_tgt", ")", ",", "0", ")", "\n", "\n", "# compute loss for discriminator", "\n", "dis_loss", "=", "BCELoss", "(", "pred_concat", ",", "label_concat", ")", "\n", "dis_loss", ".", "backward", "(", ")", "\n", "\n", "for", "p", "in", "discriminator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "clamp_", "(", "-", "args", ".", "clip_value", ",", "args", ".", "clip_value", ")", "\n", "# optimize discriminator", "\n", "", "optimizer_D", ".", "step", "(", ")", "\n", "\n", "pred_cls", "=", "torch", ".", "squeeze", "(", "pred_concat", ".", "max", "(", "1", ")", "[", "1", "]", ")", "\n", "acc", "=", "(", "pred_cls", "==", "label_concat", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "\n", "# zero gradients for optimizer", "\n", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "T", "=", "args", ".", "temperature", "\n", "\n", "# predict on discriminator", "\n", "pred_tgt", "=", "discriminator", "(", "feat_tgt", ")", "\n", "\n", "# logits for KL-divergence", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "src_prob", "=", "F", ".", "softmax", "(", "src_classifier", "(", "feat_src", ")", "/", "T", ",", "dim", "=", "-", "1", ")", "\n", "", "tgt_prob", "=", "F", ".", "log_softmax", "(", "src_classifier", "(", "feat_src_tgt", ")", "/", "T", ",", "dim", "=", "-", "1", ")", "\n", "kd_loss", "=", "KLDivLoss", "(", "tgt_prob", ",", "src_prob", ".", "detach", "(", ")", ")", "*", "T", "*", "T", "\n", "\n", "# compute loss for target encoder", "\n", "gen_loss", "=", "BCELoss", "(", "pred_tgt", ",", "label_src", ")", "\n", "loss_tgt", "=", "args", ".", "alpha", "*", "gen_loss", "+", "args", ".", "beta", "*", "kd_loss", "\n", "loss_tgt", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "tgt_encoder", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "# optimize target encoder", "\n", "optimizer_G", ".", "step", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "log_step", "==", "0", ":", "\n", "                ", "print", "(", "\"Epoch [%.2d/%.2d] Step [%.3d/%.3d]: \"", "\n", "\"acc=%.4f g_loss=%.4f d_loss=%.4f kd_loss=%.4f\"", "\n", "%", "(", "epoch", "+", "1", ",", "\n", "args", ".", "num_epochs", ",", "\n", "step", "+", "1", ",", "\n", "len_data_loader", ",", "\n", "acc", ".", "item", "(", ")", ",", "\n", "gen_loss", ".", "item", "(", ")", ",", "\n", "dis_loss", ".", "item", "(", ")", ",", "\n", "kd_loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "", "", "evaluate", "(", "tgt_encoder", ",", "src_classifier", ",", "tgt_data_all_loader", ")", "\n", "\n", "", "return", "tgt_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.train.evaluate": [[153, 185], ["encoder.eval", "classifier.eval", "torch.CrossEntropyLoss", "len", "len", "print", "utils.make_cuda", "utils.make_cuda", "utils.make_cuda", "nn.CrossEntropyLoss.item", "pred_cls.eq().cpu().sum().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "encoder", "classifier", "classifier.data.max", "nn.CrossEntropyLoss.", "pred_cls.eq().cpu().sum", "pred_cls.eq().cpu", "pred_cls.eq"], "function", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda", "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda"], ["", "def", "evaluate", "(", "encoder", ",", "classifier", ",", "data_loader", ")", ":", "\n", "    ", "\"\"\"Evaluation for target encoder by source classifier on target dataset.\"\"\"", "\n", "# set eval state for Dropout and BN layers", "\n", "encoder", ".", "eval", "(", ")", "\n", "classifier", ".", "eval", "(", ")", "\n", "\n", "# init loss and accuracy", "\n", "loss", "=", "0", "\n", "acc", "=", "0", "\n", "\n", "# set loss function", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "# evaluate network", "\n", "for", "(", "reviews", ",", "mask", ",", "labels", ")", "in", "data_loader", ":", "\n", "        ", "reviews", "=", "make_cuda", "(", "reviews", ")", "\n", "mask", "=", "make_cuda", "(", "mask", ")", "\n", "labels", "=", "make_cuda", "(", "labels", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "feat", "=", "encoder", "(", "reviews", ",", "mask", ")", "\n", "preds", "=", "classifier", "(", "feat", ")", "\n", "", "loss", "+=", "criterion", "(", "preds", ",", "labels", ")", ".", "item", "(", ")", "\n", "pred_cls", "=", "preds", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "acc", "+=", "pred_cls", ".", "eq", "(", "labels", ".", "data", ")", ".", "cpu", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "loss", "/=", "len", "(", "data_loader", ")", "\n", "acc", "/=", "len", "(", "data_loader", ".", "dataset", ")", "\n", "\n", "print", "(", "\"Avg Loss = %.4f, Avg Accuracy = %.4f\"", "%", "(", "loss", ",", "acc", ")", ")", "\n", "\n", "return", "acc", "\n", "", ""]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.BertEncoder.__init__": [[8, 11], ["torch.Module.__init__", "transformers.BertModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.BertEncoder.forward": [[12, 16], ["model.BertEncoder.encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "encoder", "(", "x", ",", "attention_mask", "=", "mask", ")", "\n", "feat", "=", "outputs", "[", "1", "]", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.DistilBertEncoder.__init__": [[19, 23], ["torch.Module.__init__", "transformers.DistilBertModel.from_pretrained", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DistilBertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "DistilBertModel", ".", "from_pretrained", "(", "'distilbert-base-uncased'", ")", "\n", "self", ".", "pooler", "=", "nn", ".", "Linear", "(", "param", ".", "hidden_size", ",", "param", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.DistilBertEncoder.forward": [[24, 30], ["model.DistilBertEncoder.encoder", "model.DistilBertEncoder.pooler"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "encoder", "(", "x", ",", "attention_mask", "=", "mask", ")", "\n", "hidden_state", "=", "outputs", "[", "0", "]", "\n", "pooled_output", "=", "hidden_state", "[", ":", ",", "0", "]", "\n", "feat", "=", "self", ".", "pooler", "(", "pooled_output", ")", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.RobertaEncoder.__init__": [[33, 36], ["torch.Module.__init__", "transformers.RobertaModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "RobertaEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "RobertaModel", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.RobertaEncoder.forward": [[37, 42], ["model.RobertaEncoder.encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "encoder", "(", "x", ",", "attention_mask", "=", "mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "feat", "=", "sequence_output", "[", ":", ",", "0", ",", ":", "]", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.DistilRobertaEncoder.__init__": [[45, 49], ["torch.Module.__init__", "transformers.RobertaModel.from_pretrained", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DistilRobertaEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "RobertaModel", ".", "from_pretrained", "(", "'distilroberta-base'", ")", "\n", "self", ".", "pooler", "=", "nn", ".", "Linear", "(", "param", ".", "hidden_size", ",", "param", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.DistilRobertaEncoder.forward": [[50, 55], ["model.DistilRobertaEncoder.encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "encoder", "(", "x", ",", "attention_mask", "=", "mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "feat", "=", "sequence_output", "[", ":", ",", "0", ",", ":", "]", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.BertClassifier.__init__": [[58, 63], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "model.BertClassifier.apply"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "BertClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "param", ".", "hidden_size", ",", "param", ".", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.BertClassifier.forward": [[64, 68], ["model.BertClassifier.dropout", "model.BertClassifier.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "out", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.BertClassifier.init_bert_weights": [[69, 76], ["isinstance", "module.weight.data.normal_", "isinstance", "module.bias.data.zero_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.RobertaClassifier.__init__": [[81, 86], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "RobertaClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pooler", "=", "nn", ".", "Linear", "(", "param", ".", "hidden_size", ",", "param", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "param", ".", "hidden_size", ",", "param", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.RobertaClassifier.forward": [[87, 94], ["model.RobertaClassifier.dropout", "model.RobertaClassifier.pooler", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "model.RobertaClassifier.dropout", "model.RobertaClassifier.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "pooler", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "out", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.Discriminator.__init__": [[99, 109], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Init discriminator.\"\"\"", "\n", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "param", ".", "hidden_size", ",", "param", ".", "intermediate_size", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "param", ".", "intermediate_size", ",", "param", ".", "intermediate_size", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "param", ".", "intermediate_size", ",", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.model.Discriminator.forward": [[111, 115], ["model.Discriminator.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward the discriminator.\"\"\"", "\n", "out", "=", "self", ".", "layer", "(", "x", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.InputFeatures.__init__": [[17, 21], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "label_id", "=", "label_id", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.XML2Array": [[23, 53], ["lxml.etree.XMLParser", "re.compile", "xml.parse", "ET.parse.getroot", "neg_tree.getroot.iter", "np.array.extend", "xml.parse", "ET.parse.getroot", "pos_tree.getroot.iter", "np.array.extend", "numpy.array", "numpy.array", "re.compile.sub", "np.array.append", "numpy.zeros", "re.compile.sub", "np.array.append", "numpy.ones"], "function", ["None"], ["", "", "def", "XML2Array", "(", "neg_path", ",", "pos_path", ")", ":", "\n", "    ", "parser", "=", "etree", ".", "XMLParser", "(", "recover", "=", "True", ")", "\n", "reviews", "=", "[", "]", "\n", "negCount", "=", "0", "\n", "posCount", "=", "0", "\n", "labels", "=", "[", "]", "\n", "regex", "=", "re", ".", "compile", "(", "r'[\\n\\r\\t+]'", ")", "\n", "\n", "neg_tree", "=", "ET", ".", "parse", "(", "neg_path", ",", "parser", "=", "parser", ")", "\n", "neg_root", "=", "neg_tree", ".", "getroot", "(", ")", "\n", "\n", "for", "rev", "in", "neg_root", ".", "iter", "(", "'review_text'", ")", ":", "\n", "        ", "text", "=", "regex", ".", "sub", "(", "\" \"", ",", "rev", ".", "text", ")", "\n", "reviews", ".", "append", "(", "text", ")", "\n", "negCount", "+=", "1", "\n", "", "labels", ".", "extend", "(", "np", ".", "zeros", "(", "negCount", ",", "dtype", "=", "int", ")", ")", "\n", "\n", "pos_tree", "=", "ET", ".", "parse", "(", "pos_path", ",", "parser", "=", "parser", ")", "\n", "pos_root", "=", "pos_tree", ".", "getroot", "(", ")", "\n", "\n", "for", "rev", "in", "pos_root", ".", "iter", "(", "'review_text'", ")", ":", "\n", "        ", "text", "=", "regex", ".", "sub", "(", "\" \"", ",", "rev", ".", "text", ")", "\n", "reviews", ".", "append", "(", "text", ")", "\n", "posCount", "+=", "1", "\n", "", "labels", ".", "extend", "(", "np", ".", "ones", "(", "posCount", ",", "dtype", "=", "int", ")", ")", "\n", "\n", "reviews", "=", "np", ".", "array", "(", "reviews", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "return", "reviews", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.CSV2Array": [[55, 59], ["pandas.read_csv", "pd.read_csv.reviews.values.tolist", "pd.read_csv.labels.values.tolist"], "function", ["None"], ["", "def", "CSV2Array", "(", "path", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "path", ",", "encoding", "=", "'latin'", ")", "\n", "reviews", ",", "labels", "=", "data", ".", "reviews", ".", "values", ".", "tolist", "(", ")", ",", "data", ".", "labels", ".", "values", ".", "tolist", "(", ")", "\n", "return", "reviews", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.make_cuda": [[61, 66], ["torch.cuda.is_available", "torch.cuda.is_available", "tensor.cuda.cuda"], "function", ["None"], ["", "def", "make_cuda", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Use CUDA if it's available.\"\"\"", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "tensor", "=", "tensor", ".", "cuda", "(", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_random_seed": [[68, 79], ["print", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "random.randint", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "init_random_seed", "(", "manual_seed", ")", ":", "\n", "    ", "\"\"\"Init random seed.\"\"\"", "\n", "if", "manual_seed", "is", "None", ":", "\n", "        ", "seed", "=", "random", ".", "randint", "(", "1", ",", "10000", ")", "\n", "", "else", ":", "\n", "        ", "seed", "=", "manual_seed", "\n", "", "print", "(", "\"use random seed: {}\"", ".", "format", "(", "seed", ")", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.init_model": [[81, 94], ["torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.path.exists", "net.cuda", "str", "net.load_state_dict", "print", "torch.load", "torch.load", "os.path.abspath"], "function", ["None"], ["", "", "def", "init_model", "(", "args", ",", "net", ",", "restore", "=", "None", ")", ":", "\n", "# restore model weights", "\n", "    ", "if", "restore", "is", "not", "None", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "param", ".", "model_root", ",", "args", ".", "src", ",", "args", ".", "model", ",", "str", "(", "args", ".", "seed", ")", ",", "restore", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ")", "\n", "print", "(", "\"Restore model from: {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "path", ")", ")", ")", "\n", "\n", "# check if cuda is available", "\n", "", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cudnn", ".", "benchmark", "=", "True", "\n", "net", ".", "cuda", "(", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.save_model": [[96, 104], ["os.path.join", "os.path.join", "torch.save", "torch.save", "print", "str", "os.path.exists", "os.makedirs", "net.state_dict"], "function", ["None"], ["", "def", "save_model", "(", "args", ",", "net", ",", "name", ")", ":", "\n", "    ", "\"\"\"Save trained model.\"\"\"", "\n", "folder", "=", "os", ".", "path", ".", "join", "(", "param", ".", "model_root", ",", "args", ".", "src", ",", "args", ".", "model", ",", "str", "(", "args", ".", "seed", ")", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "folder", ")", "\n", "", "torch", ".", "save", "(", "net", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "print", "(", "\"save pretrained model to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.convert_examples_to_features": [[106, 131], ["enumerate", "zip", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "features.append", "print", "len", "len", "len", "len", "len", "utils.InputFeatures", "len"], "function", ["None"], ["", "def", "convert_examples_to_features", "(", "reviews", ",", "labels", ",", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "\n", "pad_token", "=", "0", ")", ":", "\n", "    ", "features", "=", "[", "]", "\n", "for", "ex_index", ",", "(", "review", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "reviews", ",", "labels", ")", ")", ":", "\n", "        ", "if", "(", "ex_index", "+", "1", ")", "%", "200", "==", "0", ":", "\n", "            ", "print", "(", "\"writing example %d of %d\"", "%", "(", "ex_index", "+", "1", ",", "len", "(", "reviews", ")", ")", ")", "\n", "", "tokens", "=", "tokenizer", ".", "tokenize", "(", "review", ")", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "+", "[", "sep_token", "]", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "]", "*", "padding_length", ")", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "label_id", "=", "label", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.roberta_convert_examples_to_features": [[133, 158], ["enumerate", "zip", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "features.append", "print", "len", "len", "len", "len", "len", "utils.InputFeatures", "len"], "function", ["None"], ["", "def", "roberta_convert_examples_to_features", "(", "reviews", ",", "labels", ",", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token", "=", "'<s>'", ",", "sep_token", "=", "'</s>'", ",", "\n", "pad_token", "=", "1", ")", ":", "\n", "    ", "features", "=", "[", "]", "\n", "for", "ex_index", ",", "(", "review", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "reviews", ",", "labels", ")", ")", ":", "\n", "        ", "if", "(", "ex_index", "+", "1", ")", "%", "200", "==", "0", ":", "\n", "            ", "print", "(", "\"writing example %d of %d\"", "%", "(", "ex_index", "+", "1", ",", "len", "(", "reviews", ")", ")", ")", "\n", "", "tokens", "=", "tokenizer", ".", "tokenize", "(", "review", ")", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "+", "[", "sep_token", "]", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "]", "*", "padding_length", ")", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "label_id", "=", "label", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.get_data_loader": [[160, 168], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "get_data_loader", "(", "features", ",", "batch_size", ")", ":", "\n", "    ", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_label_ids", ")", "\n", "sampler", "=", "RandomSampler", "(", "dataset", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.bzantium_bert-AAD.None.utils.MMD": [[170, 173], ["torch.exp", "torch.exp", "source.mean", "target.mean"], "function", ["None"], ["", "def", "MMD", "(", "source", ",", "target", ")", ":", "\n", "    ", "mmd_loss", "=", "torch", ".", "exp", "(", "-", "1", "/", "(", "source", ".", "mean", "(", "dim", "=", "0", ")", "-", "target", ".", "mean", "(", "dim", "=", "0", ")", ")", ".", "norm", "(", ")", ")", "\n", "return", "mmd_loss", "\n", "", ""]]}