{"home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.is_master": [[17, 19], ["None"], "function", ["None"], ["def", "is_master", "(", "gpu_ranks", ",", "device_id", ")", ":", "\n", "    ", "return", "gpu_ranks", "[", "device_id", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.multi_init": [[21, 34], ["print", "torch.distributed.init_process_group", "torch.distributed.get_rank", "distributed.is_master"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.is_master"], ["", "def", "multi_init", "(", "device_id", ",", "world_size", ",", "gpu_ranks", ")", ":", "\n", "    ", "print", "(", "gpu_ranks", ")", "\n", "dist_init_method", "=", "'tcp://localhost:10000'", "\n", "dist_world_size", "=", "world_size", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "init_method", "=", "dist_init_method", ",", "\n", "world_size", "=", "dist_world_size", ",", "rank", "=", "gpu_ranks", "[", "device_id", "]", ")", "\n", "gpu_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "if", "not", "is_master", "(", "gpu_ranks", ",", "device_id", ")", ":", "\n", "#     print('not master')", "\n", "        ", "logger", ".", "disabled", "=", "True", "\n", "\n", "", "return", "gpu_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_reduce_and_rescale_tensors": [[37, 89], ["tensors[].new().zero_", "torch.distributed.all_reduce", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors.all_reduce_buffer"], "function", ["None"], ["", "def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_gather_list": [[91, 125], ["torch.distributed.get_world_size", "pickle.dumps", "len", "torch.ByteTensor", "torch.distributed.all_gather", "range", "torch.cuda.ByteTensor", "ValueError", "list", "in_buffer.cuda", "bytes", "pickle.loads", "results.append", "hasattr", "all_gather_list._in_buffer.size", "torch.cuda.ByteTensor", "out_buffer[].item", "out_buffer[].tolist", "range", "out_buffer[].item"], "function", ["None"], ["", "", "def", "all_gather_list", "(", "data", ",", "max_size", "=", "4096", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_in_buffer'", ")", "or", "max_size", "!=", "all_gather_list", ".", "_in_buffer", ".", "size", "(", ")", ":", "\n", "        ", "all_gather_list", ".", "_in_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "all_gather_list", ".", "_out_buffers", "=", "[", "\n", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "", "in_buffer", "=", "all_gather_list", ".", "_in_buffer", "\n", "out_buffers", "=", "all_gather_list", ".", "_out_buffers", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "in_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "in_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "in_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "out_buffers", ",", "in_buffer", ".", "cuda", "(", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "out_buffer", "=", "out_buffers", "[", "i", "]", "\n", "size", "=", "(", "255", "*", "out_buffer", "[", "0", "]", ".", "item", "(", ")", ")", "+", "out_buffer", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "bytes_list", "=", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.ErrorHandler.__init__": [[74, 84], ["threading.Thread", "train_extractive.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.ErrorHandler.add_child": [[85, 88], ["train_extractive.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.ErrorHandler.error_listener": [[89, 94], ["train_extractive.ErrorHandler.error_queue.get", "train_extractive.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.ErrorHandler.signal_handler": [[95, 104], ["train_extractive.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n", "", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "msg", "=", "\"\"\"\\n\\n-- Tracebacks above this line can probably\n                 be ignored --\\n\\n\"\"\"", "\n", "msg", "+=", "original_trace", "\n", "raise", "Exception", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.train_multi_ext": [[26, 48], ["others.logging.init_logger", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train_extractive.ErrorHandler", "range", "procs.append", "procs[].start", "others.logging.logger.info", "train_extractive.ErrorHandler.add_child", "p.join", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.logging.init_logger", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.ErrorHandler.add_child"], ["def", "train_multi_ext", "(", "args", ")", ":", "\n", "    ", "\"\"\" Spawns 1 process per GPU \"\"\"", "\n", "init_logger", "(", ")", "\n", "\n", "nb_gpu", "=", "args", ".", "world_size", "\n", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_gpu", ")", ":", "\n", "        ", "device_id", "=", "i", "\n", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "args", ",", "\n", "device_id", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "i", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "i", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "i", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.run": [[50, 68], ["setattr", "distributed.multi_init", "print", "train_extractive.train_single_ext", "int", "AssertionError", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.multi_init", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.train_single_ext"], ["", "", "def", "run", "(", "args", ",", "device_id", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "setattr", "(", "args", ",", "'gpu_ranks'", ",", "[", "int", "(", "i", ")", "for", "i", "in", "args", ".", "gpu_ranks", "]", ")", "\n", "\n", "try", ":", "\n", "        ", "gpu_rank", "=", "distributed", ".", "multi_init", "(", "device_id", ",", "args", ".", "world_size", ",", "args", ".", "gpu_ranks", ")", "\n", "print", "(", "'gpu_rank %d'", "%", "gpu_rank", ")", "\n", "if", "gpu_rank", "!=", "args", ".", "gpu_ranks", "[", "device_id", "]", ":", "\n", "            ", "raise", "AssertionError", "(", "\"An error occurred in \\\n                  Distributed initialization\"", ")", "\n", "\n", "", "train_single_ext", "(", "args", ",", "device_id", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# killed by parent, do nothing", "\n", "", "except", "Exception", ":", "\n", "# propagate exception to parent process, keeping original traceback", "\n", "        ", "import", "traceback", "\n", "error_queue", ".", "put", "(", "(", "args", ".", "gpu_ranks", "[", "device_id", "]", ",", "traceback", ".", "format_exc", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.validate_ext": [[106, 149], ["sorted", "sorted.sort", "enumerate", "others.logging.logger.info", "glob.glob", "int", "train_extractive.validate", "xent_lst.append", "xent_lst.index", "sorted", "int", "train_extractive.test_ext", "sorted", "sorted.sort", "sorted", "sorted.sort", "os.path.join", "min", "str", "glob.glob", "os.path.getmtime", "glob.glob", "os.path.getmtime", "time.sleep", "[].split", "[].split", "os.path.join", "time.sleep", "int", "train_extractive.validate", "train_extractive.test_ext", "os.path.join", "os.path.getsize", "[].split", "cp.split", "cp.split", "cp.split"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.test_ext", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.test_ext"], ["", "", "def", "validate_ext", "(", "args", ",", "device_id", ")", ":", "\n", "    ", "timestep", "=", "0", "\n", "if", "(", "args", ".", "test_all", ")", ":", "\n", "        ", "cp_files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'model_step_*.pt'", ")", ")", ")", "\n", "cp_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "xent_lst", "=", "[", "]", "\n", "for", "i", ",", "cp", "in", "enumerate", "(", "cp_files", ")", ":", "\n", "            ", "step", "=", "int", "(", "cp", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "xent", "=", "validate", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "xent_lst", ".", "append", "(", "(", "xent", ",", "cp", ")", ")", "\n", "max_step", "=", "xent_lst", ".", "index", "(", "min", "(", "xent_lst", ")", ")", "\n", "if", "(", "i", "-", "max_step", ">", "10", ")", ":", "\n", "                ", "break", "\n", "", "", "xent_lst", "=", "sorted", "(", "xent_lst", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", ":", "3", "]", "\n", "logger", ".", "info", "(", "'PPL %s'", "%", "str", "(", "xent_lst", ")", ")", "\n", "for", "xent", ",", "cp", "in", "xent_lst", ":", "\n", "            ", "step", "=", "int", "(", "cp", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "test_ext", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "", "", "else", ":", "\n", "        ", "while", "(", "True", ")", ":", "\n", "            ", "cp_files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'model_step_*.pt'", ")", ")", ")", "\n", "cp_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "if", "(", "cp_files", ")", ":", "\n", "                ", "cp", "=", "cp_files", "[", "-", "1", "]", "\n", "time_of_cp", "=", "os", ".", "path", ".", "getmtime", "(", "cp", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "getsize", "(", "cp", ")", ">", "0", ")", ":", "\n", "                    ", "time", ".", "sleep", "(", "60", ")", "\n", "continue", "\n", "", "if", "(", "time_of_cp", ">", "timestep", ")", ":", "\n", "                    ", "timestep", "=", "time_of_cp", "\n", "step", "=", "int", "(", "cp", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "validate", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "test_ext", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "\n", "", "", "cp_files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'model_step_*.pt'", ")", ")", ")", "\n", "cp_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "if", "(", "cp_files", ")", ":", "\n", "                ", "cp", "=", "cp_files", "[", "-", "1", "]", "\n", "time_of_cp", "=", "os", ".", "path", ".", "getmtime", "(", "cp", ")", "\n", "if", "(", "time_of_cp", ">", "timestep", ")", ":", "\n", "                    ", "continue", "\n", "", "", "else", ":", "\n", "                ", "time", ".", "sleep", "(", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.validate": [[151, 174], ["others.logging.logger.info", "torch.load", "vars", "vars.keys", "print", "models.model_builder.ExtSummarizer", "models.model_builder.ExtSummarizer.eval", "models.data_loader.Dataloader", "models.trainer_ext.build_trainer", "models.trainer_ext.build_trainer.validate", "trainer.validate.xent", "models.data_loader.load_dataset", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset"], ["", "", "", "", "def", "validate", "(", "args", ",", "device_id", ",", "pt", ",", "step", ")", ":", "\n", "    ", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "if", "(", "pt", "!=", "''", ")", ":", "\n", "        ", "test_from", "=", "pt", "\n", "", "else", ":", "\n", "        ", "test_from", "=", "args", ".", "test_from", "\n", "", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "test_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "test_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "        ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "print", "(", "args", ")", "\n", "\n", "model", "=", "ExtSummarizer", "(", "args", ",", "device", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "valid_iter", "=", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'valid'", ",", "shuffle", "=", "False", ")", ",", "\n", "args", ".", "batch_size", ",", "device", ",", "\n", "shuffle", "=", "False", ",", "is_test", "=", "False", ")", "\n", "trainer", "=", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "None", ")", "\n", "stats", "=", "trainer", ".", "validate", "(", "valid_iter", ",", "step", ")", "\n", "return", "stats", ".", "xent", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.test_ext": [[176, 198], ["others.logging.logger.info", "torch.load", "vars", "vars.keys", "print", "models.model_builder.ExtSummarizer", "models.model_builder.ExtSummarizer.eval", "models.data_loader.Dataloader", "models.trainer_ext.build_trainer", "models.trainer_ext.build_trainer.test", "models.data_loader.load_dataset", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.test", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset"], ["", "def", "test_ext", "(", "args", ",", "device_id", ",", "pt", ",", "step", ")", ":", "\n", "    ", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "if", "(", "pt", "!=", "''", ")", ":", "\n", "        ", "test_from", "=", "pt", "\n", "", "else", ":", "\n", "        ", "test_from", "=", "args", ".", "test_from", "\n", "", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "test_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "test_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "        ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "print", "(", "args", ")", "\n", "\n", "model", "=", "ExtSummarizer", "(", "args", ",", "device", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "test_iter", "=", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'test'", ",", "shuffle", "=", "False", ")", ",", "\n", "args", ".", "test_batch_size", ",", "device", ",", "\n", "shuffle", "=", "False", ",", "is_test", "=", "True", ")", "\n", "trainer", "=", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "None", ")", "\n", "trainer", ".", "test", "(", "test_iter", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.train_ext": [[199, 204], ["train_extractive.train_multi_ext", "train_extractive.train_single_ext"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.train_multi_ext", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.train_single_ext"], ["", "def", "train_ext", "(", "args", ",", "device_id", ")", ":", "\n", "    ", "if", "(", "args", ".", "world_size", ">", "1", ")", ":", "\n", "        ", "train_multi_ext", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "train_single_ext", "(", "args", ",", "device_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_extractive.train_single_ext": [[206, 246], ["others.logging.init_logger", "others.logging.logger.info", "others.logging.logger.info", "torch.manual_seed", "random.seed", "torch.manual_seed", "random.seed", "models.model_builder.ExtSummarizer", "models.model_builder.build_optim", "others.logging.logger.info", "models.trainer_ext.build_trainer", "models.trainer_ext.build_trainer.train", "torch.cuda.set_device", "torch.cuda.manual_seed", "others.logging.logger.info", "torch.load", "vars", "vars.keys", "models.data_loader.Dataloader", "models.data_loader.load_dataset", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.logging.init_logger", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.build_optim", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.train", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset"], ["", "", "def", "train_single_ext", "(", "args", ",", "device_id", ")", ":", "\n", "    ", "init_logger", "(", "args", ".", "log_file", ")", "\n", "\n", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "logger", ".", "info", "(", "'Device ID %d'", "%", "device_id", ")", "\n", "logger", ".", "info", "(", "'Device %s'", "%", "device", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "if", "args", ".", "train_from", "!=", "''", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "args", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "            ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "                ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "\n", "", "def", "train_iter_fct", "(", ")", ":", "\n", "        ", "return", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'train'", ",", "shuffle", "=", "True", ")", ",", "args", ".", "batch_size", ",", "device", ",", "\n", "shuffle", "=", "True", ",", "is_test", "=", "False", ")", "\n", "\n", "", "model", "=", "ExtSummarizer", "(", "args", ",", "device", ",", "checkpoint", ")", "\n", "optim", "=", "model_builder", ".", "build_optim", "(", "args", ",", "model", ",", "checkpoint", ")", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "optim", ")", "\n", "trainer", ".", "train", "(", "train_iter_fct", ",", "args", ".", "train_steps", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.str2bool": [[6, 13], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.n_grams": [[16, 19], ["len", "tuple", "range"], "function", ["None"], ["", "", "def", "n_grams", "(", "tokens", ",", "n", ")", ":", "\n", "    ", "l", "=", "len", "(", "tokens", ")", "\n", "return", "[", "tuple", "(", "tokens", "[", "i", ":", "i", "+", "n", "]", ")", "for", "i", "in", "range", "(", "l", ")", "if", "i", "+", "n", "<", "l", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.has_repeat": [[20, 23], ["set", "len", "len"], "function", ["None"], ["", "def", "has_repeat", "(", "elements", ")", ":", "\n", "    ", "d", "=", "set", "(", "elements", ")", "\n", "return", "len", "(", "d", ")", "<", "len", "(", "elements", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.cal_self_repeat": [[24, 32], ["summary.split", "ngram_repeats.keys", "functools.reduce", "post_stats.has_repeat", "post_stats.n_grams", "sent.split"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.has_repeat", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.n_grams"], ["", "def", "cal_self_repeat", "(", "summary", ")", ":", "\n", "    ", "ngram_repeats", "=", "{", "2", ":", "0", ",", "4", ":", "0", ",", "8", ":", "0", "}", "\n", "sents", "=", "summary", ".", "split", "(", "'<q>'", ")", "\n", "for", "n", "in", "ngram_repeats", ".", "keys", "(", ")", ":", "\n", "# Respect sentence boundary", "\n", "        ", "grams", "=", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "[", "n_grams", "(", "sent", ".", "split", "(", ")", ",", "n", ")", "for", "sent", "in", "sents", "]", ",", "[", "]", ")", "\n", "ngram_repeats", "[", "n", "]", "+=", "has_repeat", "(", "grams", ")", "\n", "", "return", "ngram_repeats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.cal_novel": [[33, 57], ["re.sub().strip.replace", "re.sub().strip", "re.sub().strip.replace", "re.sub().strip", "re.sub().strip.replace", "re.sub().strip.replace().replace().replace", "re.sub().strip", "summary_ngram_novel.keys", "set", "set", "set", "set.intersection", "len", "set.intersection", "len", "re.sub", "re.sub", "re.sub().strip.replace().replace", "re.sub", "post_stats.n_grams", "post_stats.n_grams", "post_stats.n_grams", "len", "len", "re.sub().strip.split", "re.sub().strip.split", "re.sub().strip.split", "len", "len", "len", "len", "re.sub().strip.replace", "re.sub().strip.split", "re.sub().strip.split"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.n_grams", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.n_grams", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.n_grams"], ["", "def", "cal_novel", "(", "summary", ",", "gold", ",", "source", ",", "summary_ngram_novel", ",", "gold_ngram_novel", ")", ":", "\n", "    ", "summary", "=", "summary", ".", "replace", "(", "'<q>'", ",", "' '", ")", "\n", "summary", "=", "re", ".", "sub", "(", "r' +'", ",", "' '", ",", "summary", ")", ".", "strip", "(", ")", "\n", "gold", "=", "gold", ".", "replace", "(", "'<q>'", ",", "' '", ")", "\n", "gold", "=", "re", ".", "sub", "(", "r' +'", ",", "' '", ",", "gold", ")", ".", "strip", "(", ")", "\n", "source", "=", "source", ".", "replace", "(", "' ##'", ",", "''", ")", "\n", "source", "=", "source", ".", "replace", "(", "'[CLS]'", ",", "' '", ")", ".", "replace", "(", "'[SEP]'", ",", "' '", ")", ".", "replace", "(", "'[PAD]'", ",", "' '", ")", "\n", "source", "=", "re", ".", "sub", "(", "r' +'", ",", "' '", ",", "source", ")", ".", "strip", "(", ")", "\n", "\n", "\n", "for", "n", "in", "summary_ngram_novel", ".", "keys", "(", ")", ":", "\n", "        ", "summary_grams", "=", "set", "(", "n_grams", "(", "summary", ".", "split", "(", ")", ",", "n", ")", ")", "\n", "gold_grams", "=", "set", "(", "n_grams", "(", "gold", ".", "split", "(", ")", ",", "n", ")", ")", "\n", "source_grams", "=", "set", "(", "n_grams", "(", "source", ".", "split", "(", ")", ",", "n", ")", ")", "\n", "joint", "=", "summary_grams", ".", "intersection", "(", "source_grams", ")", "\n", "novel", "=", "summary_grams", "-", "joint", "\n", "summary_ngram_novel", "[", "n", "]", "[", "0", "]", "+=", "1.0", "*", "len", "(", "novel", ")", "\n", "summary_ngram_novel", "[", "n", "]", "[", "1", "]", "+=", "len", "(", "summary_grams", ")", "\n", "summary_ngram_novel", "[", "n", "]", "[", "2", "]", "+=", "1.0", "*", "len", "(", "novel", ")", "/", "(", "len", "(", "summary", ".", "split", "(", ")", ")", "+", "1e-6", ")", "\n", "joint", "=", "gold_grams", ".", "intersection", "(", "source_grams", ")", "\n", "novel", "=", "gold_grams", "-", "joint", "\n", "gold_ngram_novel", "[", "n", "]", "[", "0", "]", "+=", "1.0", "*", "len", "(", "novel", ")", "\n", "gold_ngram_novel", "[", "n", "]", "[", "1", "]", "+=", "len", "(", "gold_grams", ")", "\n", "gold_ngram_novel", "[", "n", "]", "[", "2", "]", "+=", "1.0", "*", "len", "(", "novel", ")", "/", "(", "len", "(", "gold", ".", "split", "(", ")", ")", "+", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.cal_repeat": [[59, 79], ["open().read().strip().split", "open().read().strip().split", "open().read().strip().split", "zip", "print", "summary_ngram_novel.keys", "print", "post_stats.cal_novel", "open().read().strip", "open().read().strip", "open().read().strip", "open().read", "open().read", "open().read", "open", "open", "open"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.post_stats.cal_novel"], ["", "", "def", "cal_repeat", "(", "args", ")", ":", "\n", "    ", "candidate_lines", "=", "open", "(", "args", ".", "result_path", "+", "'.candidate'", ")", ".", "read", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "gold_lines", "=", "open", "(", "args", ".", "result_path", "+", "'.gold'", ")", ".", "read", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "src_lines", "=", "open", "(", "args", ".", "result_path", "+", "'.raw_src'", ")", ".", "read", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "lines", "=", "zip", "(", "candidate_lines", ",", "gold_lines", ",", "src_lines", ")", "\n", "\n", "summary_ngram_novel", "=", "{", "1", ":", "[", "0", ",", "0", ",", "0", "]", ",", "2", ":", "[", "0", ",", "0", ",", "0", "]", ",", "4", ":", "[", "0", ",", "0", ",", "0", "]", "}", "\n", "gold_ngram_novel", "=", "{", "1", ":", "[", "0", ",", "0", ",", "0", "]", ",", "2", ":", "[", "0", ",", "0", ",", "0", "]", ",", "4", ":", "[", "0", ",", "0", ",", "0", "]", "}", "\n", "\n", "for", "c", ",", "g", ",", "s", "in", "lines", ":", "\n", "# self_repeats = cal_self_repeat(c)", "\n", "        ", "cal_novel", "(", "c", ",", "g", ",", "s", ",", "summary_ngram_novel", ",", "gold_ngram_novel", ")", "\n", "", "print", "(", "summary_ngram_novel", ",", "gold_ngram_novel", ")", "\n", "\n", "for", "n", "in", "summary_ngram_novel", ".", "keys", "(", ")", ":", "\n", "# summary_ngram_novel[n] = summary_ngram_novel[n][2]/len(src_lines)", "\n", "# gold_ngram_novel[n] = gold_ngram_novel[n][2]/len(src_lines)", "\n", "        ", "summary_ngram_novel", "[", "n", "]", "=", "summary_ngram_novel", "[", "n", "]", "[", "0", "]", "/", "summary_ngram_novel", "[", "n", "]", "[", "1", "]", "\n", "gold_ngram_novel", "[", "n", "]", "=", "gold_ngram_novel", "[", "n", "]", "[", "0", "]", "/", "gold_ngram_novel", "[", "n", "]", "[", "1", "]", "\n", "", "print", "(", "summary_ngram_novel", ",", "gold_ngram_novel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train.str2bool": [[17, 24], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.preprocess.do_format_to_lines": [[11, 15], ["print", "prepro.data_builder.format_to_lines", "print", "time.clock", "time.clock"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.format_to_lines"], ["def", "do_format_to_lines", "(", "args", ")", ":", "\n", "    ", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "data_builder", ".", "format_to_lines", "(", "args", ")", "\n", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.preprocess.do_format_to_bert": [[16, 20], ["print", "prepro.data_builder.format_to_bert", "print", "time.clock", "time.clock"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.format_to_bert"], ["", "def", "do_format_to_bert", "(", "args", ")", ":", "\n", "    ", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "data_builder", ".", "format_to_bert", "(", "args", ")", "\n", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.preprocess.do_format_xsum_to_lines": [[23, 27], ["print", "prepro.data_builder.format_xsum_to_lines", "print", "time.clock", "time.clock"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.format_xsum_to_lines"], ["", "def", "do_format_xsum_to_lines", "(", "args", ")", ":", "\n", "    ", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "data_builder", ".", "format_xsum_to_lines", "(", "args", ")", "\n", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.preprocess.do_tokenize": [[28, 32], ["print", "prepro.data_builder.tokenize", "print", "time.clock", "time.clock"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.tokenize"], ["", "def", "do_tokenize", "(", "args", ")", ":", "\n", "    ", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "data_builder", ".", "tokenize", "(", "args", ")", "\n", "print", "(", "time", ".", "clock", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.preprocess.str2bool": [[34, 41], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.cal_rouge.process": [[15, 48], ["len", "time.strftime", "time.localtime", "os.path.isdir", "os.mkdir", "os.mkdir", "os.mkdir", "range", "others.pyrouge.Rouge155", "pyrouge.Rouge155.convert_and_evaluate", "print", "pyrouge.Rouge155.output_to_dict", "os.path.isdir", "shutil.rmtree", "len", "open", "f.write", "open", "f.write"], "function", ["None"], ["def", "process", "(", "data", ")", ":", "\n", "    ", "candidates", ",", "references", ",", "pool_id", "=", "data", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "tmp_dir", "=", "\"rouge-tmp-{}-{}\"", ".", "format", "(", "current_time", ",", "pool_id", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "try", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/reference/ref.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "references", "[", "i", "]", ")", "\n", "", "", "r", "=", "pyrouge", ".", "Rouge155", "(", ")", "\n", "r", ".", "model_dir", "=", "tmp_dir", "+", "\"/reference/\"", "\n", "r", ".", "system_dir", "=", "tmp_dir", "+", "\"/candidate/\"", "\n", "r", ".", "model_filename_pattern", "=", "'ref.#ID#.txt'", "\n", "r", ".", "system_filename_pattern", "=", "r'cand.(\\d+).txt'", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "print", "(", "rouge_results", ")", "\n", "results_dict", "=", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "", "finally", ":", "\n", "        ", "pass", "\n", "if", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "", "", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.cal_rouge.chunks": [[52, 56], ["range", "len"], "function", ["None"], ["", "def", "chunks", "(", "l", ",", "n", ")", ":", "\n", "    ", "\"\"\"Yield successive n-sized chunks from l.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "        ", "yield", "l", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.cal_rouge.test_rouge": [[57, 85], ["print", "print", "list", "list", "len", "range", "multiprocessing.Pool", "multiprocessing.Pool.map", "enumerate", "line.strip", "line.strip", "len", "len", "len", "len", "cal_rouge.chunks", "cal_rouge.chunks", "arg_lst.append", "int", "int", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.cal_rouge.chunks", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.cal_rouge.chunks"], ["", "", "def", "test_rouge", "(", "cand", ",", "ref", ",", "num_processes", ")", ":", "\n", "    ", "\"\"\"Calculate ROUGE scores of sequences passed as an iterator\n       e.g. a list of str, an open file, StringIO or even sys.stdin\n    \"\"\"", "\n", "candidates", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "cand", "]", "\n", "references", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "ref", "]", "\n", "\n", "print", "(", "len", "(", "candidates", ")", ")", "\n", "print", "(", "len", "(", "references", ")", ")", "\n", "assert", "len", "(", "candidates", ")", "==", "len", "(", "references", ")", "\n", "candidates_chunks", "=", "list", "(", "chunks", "(", "candidates", ",", "int", "(", "len", "(", "candidates", ")", "/", "num_processes", ")", ")", ")", "\n", "references_chunks", "=", "list", "(", "chunks", "(", "references", ",", "int", "(", "len", "(", "references", ")", "/", "num_processes", ")", ")", ")", "\n", "n_pool", "=", "len", "(", "candidates_chunks", ")", "\n", "arg_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_pool", ")", ":", "\n", "        ", "arg_lst", ".", "append", "(", "(", "candidates_chunks", "[", "i", "]", ",", "references_chunks", "[", "i", "]", ",", "i", ")", ")", "\n", "", "pool", "=", "Pool", "(", "n_pool", ")", "\n", "results", "=", "pool", ".", "map", "(", "process", ",", "arg_lst", ")", "\n", "final_results", "=", "{", "}", "\n", "for", "i", ",", "r", "in", "enumerate", "(", "results", ")", ":", "\n", "        ", "for", "k", "in", "r", ":", "\n", "            ", "if", "(", "k", "not", "in", "final_results", ")", ":", "\n", "                ", "final_results", "[", "k", "]", "=", "r", "[", "k", "]", "*", "len", "(", "candidates_chunks", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "final_results", "[", "k", "]", "+=", "r", "[", "k", "]", "*", "len", "(", "candidates_chunks", "[", "i", "]", ")", "\n", "", "", "", "for", "k", "in", "final_results", ":", "\n", "        ", "final_results", "[", "k", "]", "=", "final_results", "[", "k", "]", "/", "len", "(", "candidates", ")", "\n", "", "return", "final_results", "\n", "", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.cal_rouge.rouge_results_to_str": [[85, 95], ["None"], "function", ["None"], ["", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n", "    ", "return", "\">> ROUGE-F(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\nROUGE-R(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\n\"", ".", "format", "(", "\n", "results_dict", "[", "\"rouge_1_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_f_score\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_1_recall\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_recall\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_recall\"", "]", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.ErrorHandler.__init__": [[88, 98], ["threading.Thread", "train_abstractive.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.ErrorHandler.add_child": [[99, 102], ["train_abstractive.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.ErrorHandler.error_listener": [[103, 108], ["train_abstractive.ErrorHandler.error_queue.get", "train_abstractive.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.ErrorHandler.signal_handler": [[109, 118], ["train_abstractive.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n", "", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "msg", "=", "\"\"\"\\n\\n-- Tracebacks above this line can probably\n                 be ignored --\\n\\n\"\"\"", "\n", "msg", "+=", "original_trace", "\n", "raise", "Exception", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.str2bool": [[30, 37], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.train_abs_multi": [[39, 61], ["others.logging.init_logger", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train_abstractive.ErrorHandler", "range", "procs.append", "procs[].start", "others.logging.logger.info", "train_abstractive.ErrorHandler.add_child", "p.join", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.logging.init_logger", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.ErrorHandler.add_child"], ["", "", "def", "train_abs_multi", "(", "args", ")", ":", "\n", "    ", "\"\"\" Spawns 1 process per GPU \"\"\"", "\n", "init_logger", "(", ")", "\n", "\n", "nb_gpu", "=", "args", ".", "world_size", "\n", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_gpu", ")", ":", "\n", "        ", "device_id", "=", "i", "\n", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "args", ",", "\n", "device_id", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "i", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "i", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "i", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.run": [[63, 82], ["setattr", "distributed.multi_init", "print", "train_abstractive.train_abs_single", "int", "AssertionError", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.multi_init", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.train_abs_single"], ["", "", "def", "run", "(", "args", ",", "device_id", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "\n", "setattr", "(", "args", ",", "'gpu_ranks'", ",", "[", "int", "(", "i", ")", "for", "i", "in", "args", ".", "gpu_ranks", "]", ")", "\n", "\n", "try", ":", "\n", "        ", "gpu_rank", "=", "distributed", ".", "multi_init", "(", "device_id", ",", "args", ".", "world_size", ",", "args", ".", "gpu_ranks", ")", "\n", "print", "(", "'gpu_rank %d'", "%", "gpu_rank", ")", "\n", "if", "gpu_rank", "!=", "args", ".", "gpu_ranks", "[", "device_id", "]", ":", "\n", "            ", "raise", "AssertionError", "(", "\"An error occurred in \\\n                  Distributed initialization\"", ")", "\n", "\n", "", "train_abs_single", "(", "args", ",", "device_id", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# killed by parent, do nothing", "\n", "", "except", "Exception", ":", "\n", "# propagate exception to parent process, keeping original traceback", "\n", "        ", "import", "traceback", "\n", "error_queue", ".", "put", "(", "(", "args", ".", "gpu_ranks", "[", "device_id", "]", ",", "traceback", ".", "format_exc", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.validate_abs": [[120, 166], ["sorted", "sorted.sort", "enumerate", "others.logging.logger.info", "glob.glob", "int", "train_abstractive.validate", "xent_lst.append", "xent_lst.index", "sorted", "int", "train_abstractive.test_abs", "sorted", "sorted.sort", "sorted", "sorted.sort", "os.path.join", "xent_lst.append", "min", "str", "glob.glob", "os.path.getmtime", "glob.glob", "os.path.getmtime", "time.sleep", "[].split", "[].split", "os.path.join", "time.sleep", "int", "train_abstractive.validate", "train_abstractive.test_abs", "os.path.join", "os.path.getsize", "[].split", "cp.split", "cp.split", "cp.split"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.test_abs", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.test_abs"], ["", "", "def", "validate_abs", "(", "args", ",", "device_id", ")", ":", "\n", "    ", "timestep", "=", "0", "\n", "if", "(", "args", ".", "test_all", ")", ":", "\n", "        ", "cp_files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'model_step_*.pt'", ")", ")", ")", "\n", "cp_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "xent_lst", "=", "[", "]", "\n", "for", "i", ",", "cp", "in", "enumerate", "(", "cp_files", ")", ":", "\n", "            ", "step", "=", "int", "(", "cp", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "if", "(", "args", ".", "test_start_from", "!=", "-", "1", "and", "step", "<", "args", ".", "test_start_from", ")", ":", "\n", "                ", "xent_lst", ".", "append", "(", "(", "1e6", ",", "cp", ")", ")", "\n", "continue", "\n", "", "xent", "=", "validate", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "xent_lst", ".", "append", "(", "(", "xent", ",", "cp", ")", ")", "\n", "max_step", "=", "xent_lst", ".", "index", "(", "min", "(", "xent_lst", ")", ")", "\n", "if", "(", "i", "-", "max_step", ">", "10", ")", ":", "\n", "                ", "break", "\n", "", "", "xent_lst", "=", "sorted", "(", "xent_lst", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", ":", "5", "]", "\n", "logger", ".", "info", "(", "'PPL %s'", "%", "str", "(", "xent_lst", ")", ")", "\n", "for", "xent", ",", "cp", "in", "xent_lst", ":", "\n", "            ", "step", "=", "int", "(", "cp", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "test_abs", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "", "", "else", ":", "\n", "        ", "while", "(", "True", ")", ":", "\n", "            ", "cp_files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'model_step_*.pt'", ")", ")", ")", "\n", "cp_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "if", "(", "cp_files", ")", ":", "\n", "                ", "cp", "=", "cp_files", "[", "-", "1", "]", "\n", "time_of_cp", "=", "os", ".", "path", ".", "getmtime", "(", "cp", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "getsize", "(", "cp", ")", ">", "0", ")", ":", "\n", "                    ", "time", ".", "sleep", "(", "60", ")", "\n", "continue", "\n", "", "if", "(", "time_of_cp", ">", "timestep", ")", ":", "\n", "                    ", "timestep", "=", "time_of_cp", "\n", "step", "=", "int", "(", "cp", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "validate", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "test_abs", "(", "args", ",", "device_id", ",", "cp", ",", "step", ")", "\n", "\n", "", "", "cp_files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'model_step_*.pt'", ")", ")", ")", "\n", "cp_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "if", "(", "cp_files", ")", ":", "\n", "                ", "cp", "=", "cp_files", "[", "-", "1", "]", "\n", "time_of_cp", "=", "os", ".", "path", ".", "getmtime", "(", "cp", ")", "\n", "if", "(", "time_of_cp", ">", "timestep", ")", ":", "\n", "                    ", "continue", "\n", "", "", "else", ":", "\n", "                ", "time", ".", "sleep", "(", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.validate": [[168, 198], ["others.logging.logger.info", "torch.load", "vars", "vars.keys", "print", "models.model_builder.AbsSummarizer", "models.model_builder.AbsSummarizer.eval", "models.data_loader.Dataloader", "pytorch_transformers.BertTokenizer.from_pretrained", "models.loss.abs_loss", "models.trainer.build_trainer", "models.trainer.build_trainer.validate", "trainer.validate.xent", "models.data_loader.load_dataset", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.abs_loss", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset"], ["", "", "", "", "def", "validate", "(", "args", ",", "device_id", ",", "pt", ",", "step", ")", ":", "\n", "    ", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "if", "(", "pt", "!=", "''", ")", ":", "\n", "        ", "test_from", "=", "pt", "\n", "", "else", ":", "\n", "        ", "test_from", "=", "args", ".", "test_from", "\n", "", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "test_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "test_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "        ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "print", "(", "args", ")", "\n", "\n", "model", "=", "AbsSummarizer", "(", "args", ",", "device", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "valid_iter", "=", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'valid'", ",", "shuffle", "=", "False", ")", ",", "\n", "args", ".", "batch_size", ",", "device", ",", "\n", "shuffle", "=", "False", ",", "is_test", "=", "False", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "do_lower_case", "=", "True", ",", "cache_dir", "=", "args", ".", "temp_dir", ")", "\n", "symbols", "=", "{", "'BOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused0]'", "]", ",", "'EOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused1]'", "]", ",", "\n", "'PAD'", ":", "tokenizer", ".", "vocab", "[", "'[PAD]'", "]", ",", "'EOQ'", ":", "tokenizer", ".", "vocab", "[", "'[unused2]'", "]", "}", "\n", "\n", "valid_loss", "=", "abs_loss", "(", "model", ".", "generator", ",", "symbols", ",", "model", ".", "vocab_size", ",", "train", "=", "False", ",", "device", "=", "device", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "None", ",", "valid_loss", ")", "\n", "stats", "=", "trainer", ".", "validate", "(", "valid_iter", ",", "step", ")", "\n", "return", "stats", ".", "xent", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.test_abs": [[200, 226], ["others.logging.logger.info", "torch.load", "vars", "vars.keys", "print", "models.model_builder.AbsSummarizer", "models.model_builder.AbsSummarizer.eval", "models.data_loader.Dataloader", "pytorch_transformers.BertTokenizer.from_pretrained", "models.predictor.build_predictor", "models.predictor.build_predictor.translate", "models.data_loader.load_dataset", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.build_predictor", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.translate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset"], ["", "def", "test_abs", "(", "args", ",", "device_id", ",", "pt", ",", "step", ")", ":", "\n", "    ", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "if", "(", "pt", "!=", "''", ")", ":", "\n", "        ", "test_from", "=", "pt", "\n", "", "else", ":", "\n", "        ", "test_from", "=", "args", ".", "test_from", "\n", "", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "test_from", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "test_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "        ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "print", "(", "args", ")", "\n", "\n", "model", "=", "AbsSummarizer", "(", "args", ",", "device", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "test_iter", "=", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'test'", ",", "shuffle", "=", "False", ")", ",", "\n", "args", ".", "test_batch_size", ",", "device", ",", "\n", "shuffle", "=", "False", ",", "is_test", "=", "True", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "do_lower_case", "=", "True", ",", "cache_dir", "=", "args", ".", "temp_dir", ")", "\n", "symbols", "=", "{", "'BOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused0]'", "]", ",", "'EOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused1]'", "]", ",", "\n", "'PAD'", ":", "tokenizer", ".", "vocab", "[", "'[PAD]'", "]", ",", "'EOQ'", ":", "tokenizer", ".", "vocab", "[", "'[unused2]'", "]", "}", "\n", "predictor", "=", "build_predictor", "(", "args", ",", "tokenizer", ",", "symbols", ",", "model", ",", "logger", ")", "\n", "predictor", ".", "translate", "(", "test_iter", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.test_text_abs": [[228, 254], ["others.logging.logger.info", "torch.load", "vars", "vars.keys", "print", "models.model_builder.AbsSummarizer", "models.model_builder.AbsSummarizer.eval", "models.data_loader.Dataloader", "pytorch_transformers.BertTokenizer.from_pretrained", "models.predictor.build_predictor", "models.predictor.build_predictor.translate", "models.data_loader.load_dataset", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.build_predictor", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.translate", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset"], ["", "def", "test_text_abs", "(", "args", ",", "device_id", ",", "pt", ",", "step", ")", ":", "\n", "    ", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "if", "(", "pt", "!=", "''", ")", ":", "\n", "        ", "test_from", "=", "pt", "\n", "", "else", ":", "\n", "        ", "test_from", "=", "args", ".", "test_from", "\n", "", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "test_from", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "test_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "        ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "print", "(", "args", ")", "\n", "\n", "model", "=", "AbsSummarizer", "(", "args", ",", "device", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "test_iter", "=", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'test'", ",", "shuffle", "=", "False", ")", ",", "\n", "args", ".", "test_batch_size", ",", "device", ",", "\n", "shuffle", "=", "False", ",", "is_test", "=", "True", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "do_lower_case", "=", "True", ",", "cache_dir", "=", "args", ".", "temp_dir", ")", "\n", "symbols", "=", "{", "'BOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused0]'", "]", ",", "'EOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused1]'", "]", ",", "\n", "'PAD'", ":", "tokenizer", ".", "vocab", "[", "'[PAD]'", "]", ",", "'EOQ'", ":", "tokenizer", ".", "vocab", "[", "'[unused2]'", "]", "}", "\n", "predictor", "=", "build_predictor", "(", "args", ",", "tokenizer", ",", "symbols", ",", "model", ",", "logger", ")", "\n", "predictor", ".", "translate", "(", "test_iter", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.baseline": [[256, 267], ["models.data_loader.Dataloader", "models.trainer.build_trainer", "models.data_loader.load_dataset", "models.trainer.build_trainer.test", "models.trainer.build_trainer.test"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.test", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.test"], ["", "def", "baseline", "(", "args", ",", "cal_lead", "=", "False", ",", "cal_oracle", "=", "False", ")", ":", "\n", "    ", "test_iter", "=", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'test'", ",", "shuffle", "=", "False", ")", ",", "\n", "args", ".", "batch_size", ",", "'cpu'", ",", "\n", "shuffle", "=", "False", ",", "is_test", "=", "True", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "args", ",", "'-1'", ",", "None", ",", "None", ",", "None", ")", "\n", "#", "\n", "if", "(", "cal_lead", ")", ":", "\n", "        ", "trainer", ".", "test", "(", "test_iter", ",", "0", ",", "cal_lead", "=", "True", ")", "\n", "", "elif", "(", "cal_oracle", ")", ":", "\n", "        ", "trainer", ".", "test", "(", "test_iter", ",", "0", ",", "cal_oracle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.train_abs": [[269, 274], ["train_abstractive.train_abs_multi", "train_abstractive.train_abs_single"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.train_abs_multi", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.train_abs_single"], ["", "", "def", "train_abs", "(", "args", ",", "device_id", ")", ":", "\n", "    ", "if", "(", "args", ".", "world_size", ">", "1", ")", ":", "\n", "        ", "train_abs_multi", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "train_abs_single", "(", "args", ",", "device_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.train_abstractive.train_abs_single": [[276, 335], ["others.logging.init_logger", "others.logging.logger.info", "others.logging.logger.info", "others.logging.logger.info", "torch.manual_seed", "random.seed", "torch.manual_seed", "random.seed", "models.model_builder.AbsSummarizer", "others.logging.logger.info", "pytorch_transformers.BertTokenizer.from_pretrained", "models.loss.abs_loss", "models.trainer.build_trainer", "models.trainer.build_trainer.train", "str", "torch.cuda.set_device", "torch.cuda.manual_seed", "others.logging.logger.info", "torch.load", "vars", "vars.keys", "others.logging.logger.info", "torch.load", "models.data_loader.Dataloader", "models.model_builder.build_optim_bert", "models.model_builder.build_optim_dec", "models.data_loader.load_dataset", "models.model_builder.build_optim", "setattr"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.logging.init_logger", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.abs_loss", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.train", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.build_optim_bert", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.build_optim_dec", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.build_optim"], ["", "", "def", "train_abs_single", "(", "args", ",", "device_id", ")", ":", "\n", "    ", "init_logger", "(", "args", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "str", "(", "args", ")", ")", "\n", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "logger", ".", "info", "(", "'Device ID %d'", "%", "device_id", ")", "\n", "logger", ".", "info", "(", "'Device %s'", "%", "device", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "args", ".", "train_from", "!=", "''", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "args", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "opt", "=", "vars", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "for", "k", "in", "opt", ".", "keys", "(", ")", ":", "\n", "            ", "if", "(", "k", "in", "model_flags", ")", ":", "\n", "                ", "setattr", "(", "args", ",", "k", ",", "opt", "[", "k", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "\n", "", "if", "(", "args", ".", "load_from_extractive", "!=", "''", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading bert from extractive model %s'", "%", "args", ".", "load_from_extractive", ")", "\n", "bert_from_extractive", "=", "torch", ".", "load", "(", "args", ".", "load_from_extractive", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "bert_from_extractive", "=", "bert_from_extractive", "[", "'model'", "]", "\n", "", "else", ":", "\n", "        ", "bert_from_extractive", "=", "None", "\n", "", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "def", "train_iter_fct", "(", ")", ":", "\n", "        ", "return", "data_loader", ".", "Dataloader", "(", "args", ",", "load_dataset", "(", "args", ",", "'train'", ",", "shuffle", "=", "True", ")", ",", "args", ".", "batch_size", ",", "device", ",", "\n", "shuffle", "=", "True", ",", "is_test", "=", "False", ")", "\n", "\n", "", "model", "=", "AbsSummarizer", "(", "args", ",", "device", ",", "checkpoint", ",", "bert_from_extractive", ")", "\n", "if", "(", "args", ".", "sep_optim", ")", ":", "\n", "        ", "optim_bert", "=", "model_builder", ".", "build_optim_bert", "(", "args", ",", "model", ",", "checkpoint", ")", "\n", "optim_dec", "=", "model_builder", ".", "build_optim_dec", "(", "args", ",", "model", ",", "checkpoint", ")", "\n", "optim", "=", "[", "optim_bert", ",", "optim_dec", "]", "\n", "", "else", ":", "\n", "        ", "optim", "=", "[", "model_builder", ".", "build_optim", "(", "args", ",", "model", ",", "checkpoint", ")", "]", "\n", "\n", "", "logger", ".", "info", "(", "model", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "do_lower_case", "=", "True", ",", "cache_dir", "=", "args", ".", "temp_dir", ")", "\n", "symbols", "=", "{", "'BOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused0]'", "]", ",", "'EOS'", ":", "tokenizer", ".", "vocab", "[", "'[unused1]'", "]", ",", "\n", "'PAD'", ":", "tokenizer", ".", "vocab", "[", "'[PAD]'", "]", ",", "'EOQ'", ":", "tokenizer", ".", "vocab", "[", "'[unused2]'", "]", "}", "\n", "\n", "train_loss", "=", "abs_loss", "(", "model", ".", "generator", ",", "symbols", ",", "model", ".", "vocab_size", ",", "device", ",", "train", "=", "True", ",", "\n", "label_smoothing", "=", "args", ".", "label_smoothing", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "optim", ",", "train_loss", ")", "\n", "\n", "trainer", ".", "train", "(", "train_iter_fct", ",", "args", ".", "train_steps", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.logging.init_logger": [[9, 25], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "log_file", "=", "None", ",", "log_file_level", "=", "logging", ".", "NOTSET", ")", ":", "\n", "    ", "log_format", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s %(levelname)s] %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setLevel", "(", "log_file_level", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.__init__": [[77, 92], ["tokenization.load_vocab", "collections.OrderedDict", "tokenization.BasicTokenizer", "tokenization.WordpieceTokenizer", "os.path.isfile", "ValueError", "int", "tokenization.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "max_len", "=", "None", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ",", "\"[unused0]\"", ",", "\"[unused1]\"", ",", "\"[unused2]\"", ",", "\"[unused3]\"", ",", "\"[unused4]\"", ",", "\"[unused5]\"", ",", "\"[unused6]\"", ")", ")", ":", "\n", "\n", "        ", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "\n", "never_split", "=", "never_split", ")", "\n", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.tokenize": [[93, 107], ["tokenization.BertTokenizer.basic_tokenizer.tokenize", "list", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "enumerate", "split_tokens.append", "text.split"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.tokenize", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "use_bert_basic_tokenizer", "=", "False", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "if", "(", "use_bert_basic_tokenizer", ")", ":", "\n", "            ", "pretokens", "=", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pretokens", "=", "list", "(", "enumerate", "(", "text", ".", "split", "(", ")", ")", ")", "\n", "\n", "", "for", "i", ",", "token", "in", "pretokens", ":", "\n", "# if(self.do_lower_case):", "\n", "#     token = token.lower()", "\n", "            ", "subtokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "subtokens", ":", "\n", "                ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.convert_tokens_to_ids": [[108, 120], ["ids.append"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"", "\n", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "token", "]", ")", "\n", "# if len(ids) > self.max_len:", "\n", "#     raise ValueError(", "\n", "#         \"Token indices sequence length is longer than the specified maximum \"", "\n", "#         \" sequence length for this BERT model ({} > {}). Running this\"", "\n", "#         \" sequence through BERT will result in indexing errors\".format(len(ids), self.max_len)", "\n", "#     )", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.convert_ids_to_tokens": [[121, 127], ["tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "ids_to_tokens", "[", "i", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained": [[128, 165], ["os.path.isdir", "cls", "os.path.join", "pytorch_transformers.cached_path", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "pretrained_model_name_or_path", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "vocab_file", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_file", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer.__init__": [[170, 180], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "\"\"\"Constructs a BasicTokenizer.\n\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer.tokenize": [[181, 202], ["tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "enumerate", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "orig_tokens", ")", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "self", ".", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "# split_tokens.append(token)", "\n", "", "split_tokens", ".", "extend", "(", "[", "(", "i", ",", "t", ")", "for", "t", "in", "self", ".", "_run_split_on_punc", "(", "token", ")", "]", ")", "\n", "\n", "# output_tokens = whitespace_tokenize(\" \".join(split_tokens))", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._run_strip_accents": [[203, 213], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._run_split_on_punc": [[214, 235], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "text", "in", "self", ".", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._tokenize_chinese_chars": [[236, 248], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._is_chinese_char": [[249, 270], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BasicTokenizer._clean_text": [[271, 283], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization._is_whitespace", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.WordpieceTokenizer.__init__": [[288, 292], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.WordpieceTokenizer.tokenize": [[293, 343], ["tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.load_vocab": [[50, 63], ["collections.OrderedDict", "io.open", "reader.readline", "token.strip.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "token", "=", "reader", ".", "readline", "(", ")", "\n", "if", "not", "token", ":", "\n", "                ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.whitespace_tokenize": [[65, 72], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization._is_whitespace": [[345, 355], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization._is_control": [[357, 367], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization._is_punctuation": [[369, 383], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.clean": [[12, 16], ["re.sub", "REMAP.get", "m.group"], "function", ["None"], ["def", "clean", "(", "x", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "\n", "r\"-lrb-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|``|''\"", ",", "\n", "lambda", "m", ":", "REMAP", ".", "get", "(", "m", ".", "group", "(", ")", ")", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.process": [[18, 52], ["len", "time.strftime", "os.path.join", "time.localtime", "os.path.isdir", "os.mkdir", "os.mkdir", "os.mkdir", "range", "others.pyrouge.Rouge155", "pyrouge.Rouge155.convert_and_evaluate", "print", "pyrouge.Rouge155.output_to_dict", "os.path.isdir", "shutil.rmtree", "len", "open", "f.write", "open", "f.write"], "function", ["None"], ["", "def", "process", "(", "params", ")", ":", "\n", "    ", "temp_dir", ",", "data", "=", "params", "\n", "candidates", ",", "references", ",", "pool_id", "=", "data", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "temp_dir", ",", "\"rouge-tmp-{}-{}\"", ".", "format", "(", "current_time", ",", "pool_id", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "try", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/reference/ref.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "references", "[", "i", "]", ")", "\n", "", "", "r", "=", "pyrouge", ".", "Rouge155", "(", "temp_dir", "=", "temp_dir", ")", "\n", "r", ".", "model_dir", "=", "tmp_dir", "+", "\"/reference/\"", "\n", "r", ".", "system_dir", "=", "tmp_dir", "+", "\"/candidate/\"", "\n", "r", ".", "model_filename_pattern", "=", "'ref.#ID#.txt'", "\n", "r", ".", "system_filename_pattern", "=", "r'cand.(\\d+).txt'", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "print", "(", "rouge_results", ")", "\n", "results_dict", "=", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "", "finally", ":", "\n", "        ", "pass", "\n", "if", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "", "", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.test_rouge": [[54, 92], ["print", "print", "len", "time.strftime", "os.path.join", "line.strip", "line.strip", "len", "len", "len", "len", "time.localtime", "os.path.isdir", "os.mkdir", "os.mkdir", "os.mkdir", "range", "others.pyrouge.Rouge155", "pyrouge.Rouge155.convert_and_evaluate", "print", "pyrouge.Rouge155.output_to_dict", "os.path.isdir", "open", "open", "shutil.rmtree", "len", "open", "f.write", "open", "f.write"], "function", ["None"], ["", "def", "test_rouge", "(", "temp_dir", ",", "cand", ",", "ref", ")", ":", "\n", "    ", "candidates", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "cand", ",", "encoding", "=", "'utf-8'", ")", "]", "\n", "references", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "ref", ",", "encoding", "=", "'utf-8'", ")", "]", "\n", "print", "(", "len", "(", "candidates", ")", ")", "\n", "print", "(", "len", "(", "references", ")", ")", "\n", "assert", "len", "(", "candidates", ")", "==", "len", "(", "references", ")", "\n", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "temp_dir", ",", "\"rouge-tmp-{}\"", ".", "format", "(", "current_time", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "try", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/reference/ref.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "references", "[", "i", "]", ")", "\n", "", "", "r", "=", "pyrouge", ".", "Rouge155", "(", "temp_dir", "=", "temp_dir", ")", "\n", "r", ".", "model_dir", "=", "tmp_dir", "+", "\"/reference/\"", "\n", "r", ".", "system_dir", "=", "tmp_dir", "+", "\"/candidate/\"", "\n", "r", ".", "model_filename_pattern", "=", "'ref.#ID#.txt'", "\n", "r", ".", "system_filename_pattern", "=", "r'cand.(\\d+).txt'", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "print", "(", "rouge_results", ")", "\n", "results_dict", "=", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "", "finally", ":", "\n", "        ", "pass", "\n", "if", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "", "", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.tile": [[94, 114], ["list", "list", "x.permute().contiguous.size", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous().view", "range", "x.permute().contiguous.permute().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute().contiguous", "len", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute", "x.permute().contiguous.permute", "x.permute().contiguous.view().transpose().repeat().transpose", "x.permute().contiguous.view().transpose().repeat", "x.permute().contiguous.view().transpose", "x.permute().contiguous.view"], "function", ["None"], ["", "def", "tile", "(", "x", ",", "count", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Tiles x on dimension dim count times.\n    \"\"\"", "\n", "perm", "=", "list", "(", "range", "(", "len", "(", "x", ".", "size", "(", ")", ")", ")", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "perm", "[", "0", "]", ",", "perm", "[", "dim", "]", "=", "perm", "[", "dim", "]", ",", "perm", "[", "0", "]", "\n", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "out_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "out_size", "[", "0", "]", "*=", "count", "\n", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "batch", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "repeat", "(", "count", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "out_size", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.rouge_results_to_str": [[115, 125], ["None"], "function", ["None"], ["", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n", "    ", "return", "\">> ROUGE-F(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\nROUGE-R(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\n\"", ".", "format", "(", "\n", "results_dict", "[", "\"rouge_1_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_f_score\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_1_recall\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_recall\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_recall\"", "]", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.__init__": [[20, 65], ["set", "beam.Beam.tt.FloatTensor().zero_", "beam.Beam.tt.LongTensor().fill_", "beam.Beam.tt.FloatTensor", "beam.Beam.tt.LongTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "pad", ",", "bos", ",", "eos", ",", "\n", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "pad", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "bos", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "eos", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "global_state", "=", "{", "}", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n", "# Apply Penalty at every step", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.get_current_state": [[66, 69], ["None"], "methods", ["None"], ["", "def", "get_current_state", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.get_current_origin": [[70, 73], ["None"], "methods", ["None"], ["", "def", "get_current_origin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.advance": [[74, 151], ["word_probs.size", "len", "beam_scores.view", "beam_scores.view.topk", "beam.Beam.all_scores.append", "beam.Beam.prev_ks.append", "beam.Beam.next_ys.append", "beam.Beam.attn.append", "beam.Beam.global_scorer.update_global_state", "range", "beam.Beam.global_scorer.update_score", "range", "len", "range", "attn_out.index_select", "beam.Beam.next_ys[].size", "beam.Beam.all_scores.append", "len", "beam.Beam.scores.unsqueeze().expand_as", "beam.Beam.next_ys[].size", "len", "range", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "beam.Beam.next_ys[].size", "beam.Beam.get_hyp", "set", "range", "beam.Beam.scores.unsqueeze", "set.add", "set", "tuple", "tuple", "len", "hyp[].item"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.GlobalAttention.score", "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.get_hyp"], ["", "def", "advance", "(", "self", ",", "word_probs", ",", "attn_out", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attn_out`: Compute and update the beam search.\n\n        Parameters:\n\n        * `word_probs`- probs of advancing from the last step (K x words)\n        * `attn_out`- attention at the last step\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "stepwise_penalty", ":", "\n", "            ", "self", ".", "global_scorer", ".", "update_score", "(", "self", ",", "attn_out", ")", "\n", "# force the output to be longer than self.min_length", "\n", "", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "if", "cur_len", "<", "self", ".", "min_length", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "word_probs", ")", ")", ":", "\n", "                ", "word_probs", "[", "k", "]", "[", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "# Sum the previous scores.", "\n", "", "", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "word_probs", ")", "\n", "# Don't let EOS have children.", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "beam_scores", "[", "i", "]", "=", "-", "1e20", "\n", "\n", "# Block ngram repeats", "\n", "", "", "if", "self", ".", "block_ngram_repeat", ">", "0", ":", "\n", "                ", "ngrams", "=", "[", "]", "\n", "le", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "hyp", ",", "_", "=", "self", ".", "get_hyp", "(", "le", "-", "1", ",", "j", ")", "\n", "ngrams", "=", "set", "(", ")", "\n", "fail", "=", "False", "\n", "gram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "le", "-", "1", ")", ":", "\n", "# Last n tokens, n = block_ngram_repeat", "\n", "                        ", "gram", "=", "(", "gram", "+", "\n", "[", "hyp", "[", "i", "]", ".", "item", "(", ")", "]", ")", "[", "-", "self", ".", "block_ngram_repeat", ":", "]", "\n", "# Skip the blocking if it is in the exclusion list", "\n", "if", "set", "(", "gram", ")", "&", "self", ".", "exclusion_tokens", ":", "\n", "                            ", "continue", "\n", "", "if", "tuple", "(", "gram", ")", "in", "ngrams", ":", "\n", "                            ", "fail", "=", "True", "\n", "", "ngrams", ".", "add", "(", "tuple", "(", "gram", ")", ")", "\n", "", "if", "fail", ":", "\n", "                        ", "beam_scores", "[", "j", "]", "=", "-", "10e20", "\n", "", "", "", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "\n", "True", ",", "True", ")", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "self", ".", "attn", ".", "append", "(", "attn_out", ".", "index_select", "(", "0", ",", "prev_k", ")", ")", "\n", "self", ".", "global_scorer", ".", "update_global_state", "(", "self", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "            ", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "eos_top", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.done": [[152, 154], ["len"], "methods", ["None"], ["", "", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.sort_finished": [[155, 169], ["beam.Beam.finished.sort", "len", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.GlobalAttention.score"], ["", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.Beam.get_hyp": [[170, 180], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Walk back to construct the full hypothesis.\n        \"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.GNMTGlobalScorer.__init__": [[192, 198], ["translate.penalties.PenaltyBuilder", "translate.penalties.PenaltyBuilder.length_penalty"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.length_penalty"], ["def", "__init__", "(", "self", ",", "alpha", ",", "length_penalty", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "penalty_builder", "=", "penalties", ".", "PenaltyBuilder", "(", "length_penalty", ")", "\n", "# Term will be subtracted from probability", "\n", "# Probability will be divided by this", "\n", "self", ".", "length_penalty", "=", "penalty_builder", ".", "length_penalty", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.beam.GNMTGlobalScorer.score": [[199, 208], ["beam.GNMTGlobalScorer.length_penalty"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.length_penalty"], ["", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Rescores a prediction based on penalty functions\n        \"\"\"", "\n", "normalized_probs", "=", "self", ".", "length_penalty", "(", "beam", ",", "\n", "logprobs", ",", "\n", "self", ".", "alpha", ")", "\n", "\n", "return", "normalized_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.__init__": [[14, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "length_pen", ")", ":", "\n", "        ", "self", ".", "length_pen", "=", "length_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.length_penalty": [[17, 24], ["None"], "methods", ["None"], ["", "def", "length_penalty", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "length_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "length_wu", "\n", "", "elif", "self", ".", "length_pen", "==", "\"avg\"", ":", "\n", "            ", "return", "self", ".", "length_average", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "length_none", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.length_wu": [[30, 39], ["len"], "methods", ["None"], ["def", "length_wu", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        NMT length re-ranking score from\n        \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "\n", "modifier", "=", "(", "(", "(", "5", "+", "len", "(", "beam", ".", "next_ys", ")", ")", "**", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "modifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.length_average": [[40, 45], ["len"], "methods", ["None"], ["", "def", "length_average", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns the average probability of tokens in a sequence.\n        \"\"\"", "\n", "return", "logprobs", "/", "len", "(", "beam", ".", "next_ys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.translate.penalties.PenaltyBuilder.length_none": [[46, 51], ["None"], "methods", ["None"], ["", "def", "length_none", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns unmodified scores.\n        \"\"\"", "\n", "return", "logprobs", "", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.Classifier.__init__": [[10, 14], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "Classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.Classifier.forward": [[15, 19], ["encoder.Classifier.linear1().squeeze", "encoder.Classifier.sigmoid", "mask_cls.float", "encoder.Classifier.linear1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask_cls", ")", ":", "\n", "        ", "h", "=", "self", ".", "linear1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "sent_scores", "=", "self", ".", "sigmoid", "(", "h", ")", "*", "mask_cls", ".", "float", "(", ")", "\n", "return", "sent_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.PositionalEncoding.__init__": [[23, 35], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "encoder.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "math.log"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ",", "dtype", "=", "torch", ".", "float", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.PositionalEncoding.forward": [[36, 45], ["encoder.PositionalEncoding.dropout", "math.sqrt", "encoder.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ")", ":", "\n", "        ", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "if", "(", "step", ")", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", ",", "step", "]", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", ",", ":", "emb", ".", "size", "(", "1", ")", "]", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.PositionalEncoding.get_emb": [[46, 48], ["emb.size"], "methods", ["None"], ["", "def", "get_emb", "(", "self", ",", "emb", ")", ":", "\n", "        ", "return", "self", ".", "pe", "[", ":", ",", ":", "emb", ".", "size", "(", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.TransformerEncoderLayer.__init__": [[51, 59], ["torch.Module.__init__", "models.neural.MultiHeadedAttention", "models.neural.PositionwiseFeedForward", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "TransformerEncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.TransformerEncoderLayer.forward": [[60, 71], ["mask.unsqueeze.unsqueeze.unsqueeze", "encoder.TransformerEncoderLayer.self_attn", "encoder.TransformerEncoderLayer.feed_forward", "encoder.TransformerEncoderLayer.layer_norm", "encoder.TransformerEncoderLayer.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "iter", ",", "query", ",", "inputs", ",", "mask", ")", ":", "\n", "        ", "if", "(", "iter", "!=", "0", ")", ":", "\n", "            ", "input_norm", "=", "self", ".", "layer_norm", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "input_norm", "=", "inputs", "\n", "\n", "", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "context", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "\n", "mask", "=", "mask", ")", "\n", "out", "=", "self", ".", "dropout", "(", "context", ")", "+", "inputs", "\n", "return", "self", ".", "feed_forward", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.ExtTransformerEncoder.__init__": [[74, 86], ["torch.Module.__init__", "encoder.PositionalEncoding", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "encoder.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "heads", ",", "dropout", ",", "num_inter_layers", "=", "0", ")", ":", "\n", "        ", "super", "(", "ExtTransformerEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "num_inter_layers", "=", "num_inter_layers", "\n", "self", ".", "pos_emb", "=", "PositionalEncoding", "(", "dropout", ",", "d_model", ")", "\n", "self", ".", "transformer_inter", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerEncoderLayer", "(", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ")", "\n", "for", "_", "in", "range", "(", "num_inter_layers", ")", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "wo", "=", "nn", ".", "Linear", "(", "d_model", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.encoder.ExtTransformerEncoder.forward": [[87, 103], ["range", "encoder.ExtTransformerEncoder.layer_norm", "encoder.ExtTransformerEncoder.sigmoid", "top_vecs.size", "top_vecs.size", "mask[].float", "encoder.ExtTransformerEncoder.wo", "encoder.ExtTransformerEncoder.squeeze", "mask.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "top_vecs", ",", "mask", ")", ":", "\n", "        ", "\"\"\" See :obj:`EncoderBase.forward()`\"\"\"", "\n", "\n", "batch_size", ",", "n_sents", "=", "top_vecs", ".", "size", "(", "0", ")", ",", "top_vecs", ".", "size", "(", "1", ")", "\n", "pos_emb", "=", "self", ".", "pos_emb", ".", "pe", "[", ":", ",", ":", "n_sents", "]", "\n", "x", "=", "top_vecs", "*", "mask", "[", ":", ",", ":", ",", "None", "]", ".", "float", "(", ")", "\n", "x", "=", "x", "+", "pos_emb", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_inter_layers", ")", ":", "\n", "            ", "x", "=", "self", ".", "transformer_inter", "[", "i", "]", "(", "i", ",", "x", ",", "x", ",", "1", "-", "mask", ")", "# all_sents * max_tokens * dim", "\n", "\n", "", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "sent_scores", "=", "self", ".", "sigmoid", "(", "self", ".", "wo", "(", "x", ")", ")", "\n", "sent_scores", "=", "sent_scores", ".", "squeeze", "(", "-", "1", ")", "*", "mask", ".", "float", "(", ")", "\n", "\n", "return", "sent_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.__init__": [[43, 83], ["tensorboardX.SummaryWriter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "args", ",", "\n", "model", ",", "\n", "vocab", ",", "\n", "symbols", ",", "\n", "global_scorer", "=", "None", ",", "\n", "logger", "=", "None", ",", "\n", "dump_beam", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "self", ".", "cuda", "=", "args", ".", "visible_gpus", "!=", "'-1'", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "generator", "=", "self", ".", "model", ".", "generator", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "symbols", "=", "symbols", "\n", "self", ".", "start_token", "=", "symbols", "[", "'BOS'", "]", "\n", "self", ".", "end_token", "=", "symbols", "[", "'EOS'", "]", "\n", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "beam_size", "=", "args", ".", "beam_size", "\n", "self", ".", "min_length", "=", "args", ".", "min_length", "\n", "self", ".", "max_length", "=", "args", ".", "max_length", "\n", "\n", "self", ".", "dump_beam", "=", "dump_beam", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_trace", "=", "self", ".", "dump_beam", "!=", "\"\"", "\n", "self", ".", "beam_accum", "=", "None", "\n", "\n", "tensorboard_log_dir", "=", "args", ".", "model_path", "\n", "\n", "self", ".", "tensorboard_writer", "=", "SummaryWriter", "(", "tensorboard_log_dir", ",", "comment", "=", "\"Unmt\"", ")", "\n", "\n", "if", "self", ".", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator._build_target_tokens": [[84, 96], ["predictor.Translator.vocab.DecodeIds().split", "int", "predictor.Translator.append", "predictor.Translator.vocab.DecodeIds", "len"], "methods", ["None"], ["", "", "def", "_build_target_tokens", "(", "self", ",", "pred", ")", ":", "\n", "# vocab = self.fields[\"tgt\"].vocab", "\n", "        ", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "tok", "=", "int", "(", "tok", ")", "\n", "tokens", ".", "append", "(", "tok", ")", "\n", "if", "tokens", "[", "-", "1", "]", "==", "self", ".", "end_token", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "tokens", "=", "[", "t", "for", "t", "in", "tokens", "if", "t", "<", "len", "(", "self", ".", "vocab", ")", "]", "\n", "tokens", "=", "self", ".", "vocab", ".", "DecodeIds", "(", "tokens", ")", ".", "split", "(", "' '", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.from_batch": [[97, 122], ["range", "len", "len", "predictor.Translator.vocab.convert_ids_to_tokens", "translations.append", "tgt_str[].split", "int", "int"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.convert_ids_to_tokens"], ["", "def", "from_batch", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "assert", "(", "len", "(", "translation_batch", "[", "\"gold_score\"", "]", ")", "==", "\n", "len", "(", "translation_batch", "[", "\"predictions\"", "]", ")", ")", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "preds", ",", "pred_score", ",", "gold_score", ",", "tgt_str", ",", "src", "=", "translation_batch", "[", "\"predictions\"", "]", ",", "translation_batch", "[", "\"scores\"", "]", ",", "translation_batch", "[", "\"gold_score\"", "]", ",", "batch", ".", "tgt_str", ",", "batch", ".", "src", "\n", "\n", "translations", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "pred_sents", "=", "self", ".", "vocab", ".", "convert_ids_to_tokens", "(", "[", "int", "(", "n", ")", "for", "n", "in", "preds", "[", "b", "]", "[", "0", "]", "]", ")", "\n", "pred_sents", "=", "' '", ".", "join", "(", "pred_sents", ")", ".", "replace", "(", "' ##'", ",", "''", ")", "\n", "gold_sent", "=", "' '", ".", "join", "(", "tgt_str", "[", "b", "]", ".", "split", "(", ")", ")", "\n", "# translation = Translation(fname[b],src[:, b] if src is not None else None,", "\n", "#                           src_raw, pred_sents,", "\n", "#                           attn[b], pred_score[b], gold_sent,", "\n", "#                           gold_score[b])", "\n", "# src = self.spm.DecodeIds([int(t) for t in translation_batch['batch'].src[0][5] if int(t) != len(self.spm)])", "\n", "raw_src", "=", "[", "self", ".", "vocab", ".", "ids_to_tokens", "[", "int", "(", "t", ")", "]", "for", "t", "in", "src", "[", "b", "]", "]", "[", ":", "500", "]", "\n", "raw_src", "=", "' '", ".", "join", "(", "raw_src", ")", "\n", "translation", "=", "(", "pred_sents", ",", "gold_sent", ",", "raw_src", ")", "\n", "# translation = (pred_sents[0], gold_sent)", "\n", "translations", ".", "append", "(", "translation", ")", "\n", "\n", "", "return", "translations", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.translate": [[123, 194], ["predictor.Translator.model.eval", "codecs.open", "codecs.open", "codecs.open", "codecs.open", "codecs.open", "predictor.Translator.can_out_file.close", "predictor.Translator.gold_out_file.close", "predictor.Translator.src_out_file.close", "torch.no_grad", "predictor.Translator._report_rouge", "predictor.Translator.logger.info", "predictor.Translator.translate_batch", "predictor.Translator.from_batch", "predictor.Translator.can_out_file.flush", "predictor.Translator.gold_out_file.flush", "predictor.Translator.src_out_file.flush", "predictor.Translator.tensorboard_writer.add_scalar", "predictor.Translator.tensorboard_writer.add_scalar", "predictor.Translator.tensorboard_writer.add_scalar", "batch.tgt.size", "pred.replace().replace().replace().replace().replace().replace().replace().strip", "gold.strip", "predictor.Translator.can_out_file.write", "predictor.Translator.gold_out_file.write", "predictor.Translator.src_out_file.write", "pred.replace().replace().replace().replace().replace().replace().replace().strip.split", "others.utils.rouge_results_to_str", "pred.replace().replace().replace().replace().replace().replace().replace", "math.fabs", "src.strip", "sent.strip", "len", "pred.replace().replace().replace().replace().replace().replace", "len", "len", "can_pred_str.split", "len", "_pred_str.split", "gold.strip.split", "gold.strip.split", "pred.replace().replace().replace().replace().replace", "pred.replace().replace().replace().replace", "pred.replace().replace().replace", "pred.replace().replace", "pred.replace"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator._report_rouge", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.translate_batch", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.from_batch", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.rouge_results_to_str"], ["", "def", "translate", "(", "self", ",", "\n", "data_iter", ",", "step", ",", "\n", "attn_debug", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "gold_path", "=", "self", ".", "args", ".", "result_path", "+", "'.%d.gold'", "%", "step", "\n", "can_path", "=", "self", ".", "args", ".", "result_path", "+", "'.%d.candidate'", "%", "step", "\n", "self", ".", "gold_out_file", "=", "codecs", ".", "open", "(", "gold_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "self", ".", "can_out_file", "=", "codecs", ".", "open", "(", "can_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "\n", "# raw_gold_path = self.args.result_path + '.%d.raw_gold' % step", "\n", "# raw_can_path = self.args.result_path + '.%d.raw_candidate' % step", "\n", "self", ".", "gold_out_file", "=", "codecs", ".", "open", "(", "gold_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "self", ".", "can_out_file", "=", "codecs", ".", "open", "(", "can_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "\n", "raw_src_path", "=", "self", ".", "args", ".", "result_path", "+", "'.%d.raw_src'", "%", "step", "\n", "self", ".", "src_out_file", "=", "codecs", ".", "open", "(", "raw_src_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "\n", "# pred_results, gold_results = [], []", "\n", "ct", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch", "in", "data_iter", ":", "\n", "                ", "if", "(", "self", ".", "args", ".", "recall_eval", ")", ":", "\n", "                    ", "gold_tgt_len", "=", "batch", ".", "tgt", ".", "size", "(", "1", ")", "\n", "self", ".", "min_length", "=", "gold_tgt_len", "+", "20", "\n", "self", ".", "max_length", "=", "gold_tgt_len", "+", "60", "\n", "", "batch_data", "=", "self", ".", "translate_batch", "(", "batch", ")", "\n", "translations", "=", "self", ".", "from_batch", "(", "batch_data", ")", "\n", "\n", "for", "trans", "in", "translations", ":", "\n", "                    ", "pred", ",", "gold", ",", "src", "=", "trans", "\n", "pred_str", "=", "pred", ".", "replace", "(", "'[unused0]'", ",", "''", ")", ".", "replace", "(", "'[unused3]'", ",", "''", ")", ".", "replace", "(", "'[PAD]'", ",", "''", ")", ".", "replace", "(", "'[unused1]'", ",", "''", ")", ".", "replace", "(", "r' +'", ",", "' '", ")", ".", "replace", "(", "' [unused2] '", ",", "'<q>'", ")", ".", "replace", "(", "'[unused2]'", ",", "''", ")", ".", "strip", "(", ")", "\n", "gold_str", "=", "gold", ".", "strip", "(", ")", "\n", "if", "(", "self", ".", "args", ".", "recall_eval", ")", ":", "\n", "                        ", "_pred_str", "=", "''", "\n", "gap", "=", "1e3", "\n", "for", "sent", "in", "pred_str", ".", "split", "(", "'<q>'", ")", ":", "\n", "                            ", "can_pred_str", "=", "_pred_str", "+", "'<q>'", "+", "sent", ".", "strip", "(", ")", "\n", "can_gap", "=", "math", ".", "fabs", "(", "len", "(", "_pred_str", ".", "split", "(", ")", ")", "-", "len", "(", "gold_str", ".", "split", "(", ")", ")", ")", "\n", "# if(can_gap>=gap):", "\n", "if", "(", "len", "(", "can_pred_str", ".", "split", "(", ")", ")", ">=", "len", "(", "gold_str", ".", "split", "(", ")", ")", "+", "10", ")", ":", "\n", "                                ", "pred_str", "=", "_pred_str", "\n", "break", "\n", "", "else", ":", "\n", "                                ", "gap", "=", "can_gap", "\n", "_pred_str", "=", "can_pred_str", "\n", "\n", "\n", "\n", "# pred_str = ' '.join(pred_str.split()[:len(gold_str.split())])", "\n", "# self.raw_can_out_file.write(' '.join(pred).strip() + '\\n')", "\n", "# self.raw_gold_out_file.write(' '.join(gold).strip() + '\\n')", "\n", "", "", "", "self", ".", "can_out_file", ".", "write", "(", "pred_str", "+", "'\\n'", ")", "\n", "self", ".", "gold_out_file", ".", "write", "(", "gold_str", "+", "'\\n'", ")", "\n", "self", ".", "src_out_file", ".", "write", "(", "src", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "ct", "+=", "1", "\n", "", "self", ".", "can_out_file", ".", "flush", "(", ")", "\n", "self", ".", "gold_out_file", ".", "flush", "(", ")", "\n", "self", ".", "src_out_file", ".", "flush", "(", ")", "\n", "\n", "", "", "self", ".", "can_out_file", ".", "close", "(", ")", "\n", "self", ".", "gold_out_file", ".", "close", "(", ")", "\n", "self", ".", "src_out_file", ".", "close", "(", ")", "\n", "\n", "if", "(", "step", "!=", "-", "1", ")", ":", "\n", "            ", "rouges", "=", "self", ".", "_report_rouge", "(", "gold_path", ",", "can_path", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Rouges at step %d \\n%s'", "%", "(", "step", ",", "rouge_results_to_str", "(", "rouges", ")", ")", ")", "\n", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "                ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'test/rouge1-F'", ",", "rouges", "[", "'rouge_1_f_score'", "]", ",", "step", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'test/rouge2-F'", ",", "rouges", "[", "'rouge_2_f_score'", "]", ",", "step", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'test/rougeL-F'", ",", "rouges", "[", "'rouge_l_f_score'", "]", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator._report_rouge": [[195, 199], ["predictor.Translator.logger.info", "others.utils.test_rouge"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.test_rouge"], ["", "", "", "def", "_report_rouge", "(", "self", ",", "gold_path", ",", "can_path", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Calculating Rouge\"", ")", "\n", "results_dict", "=", "test_rouge", "(", "self", ".", "args", ".", "temp_dir", ",", "can_path", ",", "gold_path", ")", "\n", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator.translate_batch": [[200, 219], ["torch.no_grad", "predictor.Translator._fast_translate_batch"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator._fast_translate_batch"], ["", "def", "translate_batch", "(", "self", ",", "batch", ",", "fast", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Translate a batch of sentences.\n\n        Mostly a wrapper around :obj:`Beam`.\n\n        Args:\n           batch (:obj:`Batch`): a batch from a dataset object\n           data (:obj:`Dataset`): the dataset object\n           fast (bool): enables fast beam search (may not support all features)\n\n        Todo:\n           Shouldn't need the original dataset.\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "_fast_translate_batch", "(", "\n", "batch", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translator._fast_translate_batch": [[220, 377], ["predictor.Translator.model.bert", "predictor.Translator.model.decoder.init_decoder_state", "predictor.Translator.map_batch_fn", "others.utils.tile", "torch.arange", "torch.arange", "torch.full", "torch.tensor().repeat", "range", "alive_seq[].view", "decoder_input.transpose.transpose.transpose", "predictor.Translator.model.decoder", "predictor.Translator.generator.forward", "predictor.Translator.size", "topk_log_probs.index_select.index_select.view().unsqueeze", "curr_scores.reshape.reshape.reshape", "curr_scores.reshape.reshape.topk", "topk_ids.fmod.fmod.div", "topk_ids.fmod.fmod.fmod", "batch_index.index_select.index_select.view", "torch.cat", "topk_ids.fmod.fmod.eq", "is_finished[].eq", "topk_ids.fmod.eq.any", "batch_index.index_select.index_select.view", "src_features.index_select.index_select.index_select", "predictor.Translator.map_batch_fn", "others.utils.tile", "torch.tensor", "range", "range", "range", "dec_out.transpose().squeeze", "alive_seq.view.index_select().view.size", "beam_offset[].unsqueeze", "topk_ids.fmod.eq.fill_", "alive_seq.view.index_select().view.view", "range", "is_finished[].eq.eq().nonzero().view", "topk_log_probs.index_select.index_select.index_select", "batch_index.index_select.index_select.index_select", "batch_offset.index_select.index_select.index_select", "predictions.index_select().view.view.index_select().view", "topk_log_probs.index_select.index_select.view", "range", "alive_seq.view.index_select().view.index_select", "topk_ids.fmod.fmod.view", "alive_seq.view.index_select().view.size", "topk_ids.fmod.eq.size", "is_finished[].nonzero().view", "len", "alive_seq.view.index_select().view.size", "state.index_select", "dec_out.transpose", "alive_seq.view.index_select().view.size", "tuple", "is_finished[].fill_", "hypotheses[].append", "sorted", "[].append", "[].append", "is_finished[].eq.eq().nonzero", "predictions.index_select().view.view.index_select", "int", "len", "is_finished[].nonzero", "float", "range", "topk_ids.fmod.div.size", "is_finished[].eq.eq", "len"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoder.init_decoder_state", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.map_batch_fn", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.tile", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.AbsSummarizer.forward", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.map_batch_fn", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.tile"], ["", "", "def", "_fast_translate_batch", "(", "self", ",", "\n", "batch", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ")", ":", "\n", "# TODO: faster code path for beam_size == 1.", "\n", "\n", "# TODO: support these blacklisted features.", "\n", "        ", "assert", "not", "self", ".", "dump_beam", "\n", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "src", "=", "batch", ".", "src", "\n", "segs", "=", "batch", ".", "segs", "\n", "mask_src", "=", "batch", ".", "mask_src", "\n", "\n", "src_features", "=", "self", ".", "model", ".", "bert", "(", "src", ",", "segs", ",", "mask_src", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "src_features", ",", "with_cache", "=", "True", ")", "\n", "device", "=", "src_features", ".", "device", "\n", "\n", "# Tile states and memory beam_size times.", "\n", "dec_states", ".", "map_batch_fn", "(", "\n", "lambda", "state", ",", "dim", ":", "tile", "(", "state", ",", "beam_size", ",", "dim", "=", "dim", ")", ")", "\n", "src_features", "=", "tile", "(", "src_features", ",", "beam_size", ",", "dim", "=", "0", ")", "\n", "batch_offset", "=", "torch", ".", "arange", "(", "\n", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "\n", "batch_size", "*", "beam_size", ",", "\n", "step", "=", "beam_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "device", ")", "\n", "alive_seq", "=", "torch", ".", "full", "(", "\n", "[", "batch_size", "*", "beam_size", ",", "1", "]", ",", "\n", "self", ".", "start_token", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "device", ")", "\n", "\n", "# Give full probability to the first beam on the first step.", "\n", "topk_log_probs", "=", "(", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", "+", "[", "float", "(", "\"-inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", ",", "\n", "device", "=", "device", ")", ".", "repeat", "(", "batch_size", ")", ")", "\n", "\n", "# Structure that holds finished hypotheses.", "\n", "hypotheses", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "\n", "results", "=", "{", "}", "\n", "results", "[", "\"predictions\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"scores\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"gold_score\"", "]", "=", "[", "0", "]", "*", "batch_size", "\n", "results", "[", "\"batch\"", "]", "=", "batch", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "            ", "decoder_input", "=", "alive_seq", "[", ":", ",", "-", "1", "]", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "# Decoder forward.", "\n", "decoder_input", "=", "decoder_input", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "dec_out", ",", "dec_states", "=", "self", ".", "model", ".", "decoder", "(", "decoder_input", ",", "src_features", ",", "dec_states", ",", "\n", "step", "=", "step", ")", "\n", "\n", "# Generator forward.", "\n", "log_probs", "=", "self", ".", "generator", ".", "forward", "(", "dec_out", ".", "transpose", "(", "0", ",", "1", ")", ".", "squeeze", "(", "0", ")", ")", "\n", "vocab_size", "=", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "step", "<", "min_length", ":", "\n", "                ", "log_probs", "[", ":", ",", "self", ".", "end_token", "]", "=", "-", "1e20", "\n", "\n", "# Multiply probs by the beam probability.", "\n", "", "log_probs", "+=", "topk_log_probs", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "alpha", "=", "self", ".", "global_scorer", ".", "alpha", "\n", "length_penalty", "=", "(", "(", "5.0", "+", "(", "step", "+", "1", ")", ")", "/", "6.0", ")", "**", "alpha", "\n", "\n", "# Flatten probs into a list of possibilities.", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "\n", "if", "(", "self", ".", "args", ".", "block_trigram", ")", ":", "\n", "                ", "cur_len", "=", "alive_seq", ".", "size", "(", "1", ")", "\n", "if", "(", "cur_len", ">", "3", ")", ":", "\n", "                    ", "for", "i", "in", "range", "(", "alive_seq", ".", "size", "(", "0", ")", ")", ":", "\n", "                        ", "fail", "=", "False", "\n", "words", "=", "[", "int", "(", "w", ")", "for", "w", "in", "alive_seq", "[", "i", "]", "]", "\n", "words", "=", "[", "self", ".", "vocab", ".", "ids_to_tokens", "[", "w", "]", "for", "w", "in", "words", "]", "\n", "words", "=", "' '", ".", "join", "(", "words", ")", ".", "replace", "(", "' ##'", ",", "''", ")", ".", "split", "(", ")", "\n", "if", "(", "len", "(", "words", ")", "<=", "3", ")", ":", "\n", "                            ", "continue", "\n", "", "trigrams", "=", "[", "(", "words", "[", "i", "-", "1", "]", ",", "words", "[", "i", "]", ",", "words", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "words", ")", "-", "1", ")", "]", "\n", "trigram", "=", "tuple", "(", "trigrams", "[", "-", "1", "]", ")", "\n", "if", "trigram", "in", "trigrams", "[", ":", "-", "1", "]", ":", "\n", "                            ", "fail", "=", "True", "\n", "", "if", "fail", ":", "\n", "                            ", "curr_scores", "[", "i", "]", "=", "-", "10e20", "\n", "\n", "", "", "", "", "curr_scores", "=", "curr_scores", ".", "reshape", "(", "-", "1", ",", "beam_size", "*", "vocab_size", ")", "\n", "topk_scores", ",", "topk_ids", "=", "curr_scores", ".", "topk", "(", "beam_size", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Recover log probs.", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Resolve beam origin and true word ids.", "\n", "topk_beam_index", "=", "topk_ids", ".", "div", "(", "vocab_size", ")", "\n", "topk_ids", "=", "topk_ids", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# Map beam_index to batch_index in the flat representation.", "\n", "batch_index", "=", "(", "\n", "topk_beam_index", "\n", "+", "beam_offset", "[", ":", "topk_beam_index", ".", "size", "(", "0", ")", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "select_indices", "=", "batch_index", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Append last prediction.", "\n", "alive_seq", "=", "torch", ".", "cat", "(", "\n", "[", "alive_seq", ".", "index_select", "(", "0", ",", "select_indices", ")", ",", "\n", "topk_ids", ".", "view", "(", "-", "1", ",", "1", ")", "]", ",", "-", "1", ")", "\n", "\n", "is_finished", "=", "topk_ids", ".", "eq", "(", "self", ".", "end_token", ")", "\n", "if", "step", "+", "1", "==", "max_length", ":", "\n", "                ", "is_finished", ".", "fill_", "(", "1", ")", "\n", "# End condition is top beam is finished.", "\n", "", "end_condition", "=", "is_finished", "[", ":", ",", "0", "]", ".", "eq", "(", "1", ")", "\n", "# Save finished hypotheses.", "\n", "if", "is_finished", ".", "any", "(", ")", ":", "\n", "                ", "predictions", "=", "alive_seq", ".", "view", "(", "-", "1", ",", "beam_size", ",", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "is_finished", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "b", "=", "batch_offset", "[", "i", "]", "\n", "if", "end_condition", "[", "i", "]", ":", "\n", "                        ", "is_finished", "[", "i", "]", ".", "fill_", "(", "1", ")", "\n", "", "finished_hyp", "=", "is_finished", "[", "i", "]", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# Store finished hypotheses for this batch.", "\n", "for", "j", "in", "finished_hyp", ":", "\n", "                        ", "hypotheses", "[", "b", "]", ".", "append", "(", "(", "\n", "topk_scores", "[", "i", ",", "j", "]", ",", "\n", "predictions", "[", "i", ",", "j", ",", "1", ":", "]", ")", ")", "\n", "# If the batch reached the end, save the n_best hypotheses.", "\n", "", "if", "end_condition", "[", "i", "]", ":", "\n", "                        ", "best_hyp", "=", "sorted", "(", "\n", "hypotheses", "[", "b", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "score", ",", "pred", "=", "best_hyp", "[", "0", "]", "\n", "\n", "results", "[", "\"scores\"", "]", "[", "b", "]", ".", "append", "(", "score", ")", "\n", "results", "[", "\"predictions\"", "]", "[", "b", "]", ".", "append", "(", "pred", ")", "\n", "", "", "non_finished", "=", "end_condition", ".", "eq", "(", "0", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# If all sentences are translated, no need to go further.", "\n", "if", "len", "(", "non_finished", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "# Remove finished batches for the next step.", "\n", "", "topk_log_probs", "=", "topk_log_probs", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "batch_index", "=", "batch_index", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "batch_offset", "=", "batch_offset", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "alive_seq", "=", "predictions", ".", "index_select", "(", "0", ",", "non_finished", ")", ".", "view", "(", "-", "1", ",", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n", "# Reorder states.", "\n", "", "select_indices", "=", "batch_index", ".", "view", "(", "-", "1", ")", "\n", "src_features", "=", "src_features", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "dec_states", ".", "map_batch_fn", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translation.__init__": [[395, 405], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fname", ",", "src", ",", "src_raw", ",", "pred_sents", ",", "\n", "attn", ",", "pred_scores", ",", "tgt_sent", ",", "gold_score", ")", ":", "\n", "        ", "self", ".", "fname", "=", "fname", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "src_raw", "=", "src_raw", "\n", "self", ".", "pred_sents", "=", "pred_sents", "\n", "self", ".", "attns", "=", "attn", "\n", "self", ".", "pred_scores", "=", "pred_scores", "\n", "self", ".", "gold_sent", "=", "tgt_sent", "\n", "self", ".", "gold_score", "=", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.Translation.log": [[406, 429], ["len", "zip"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "sent_number", ")", ":", "\n", "        ", "\"\"\"\n        Log translation.\n        \"\"\"", "\n", "\n", "output", "=", "'\\nSENT {}: {}\\n'", ".", "format", "(", "sent_number", ",", "self", ".", "src_raw", ")", "\n", "\n", "best_pred", "=", "self", ".", "pred_sents", "[", "0", "]", "\n", "best_score", "=", "self", ".", "pred_scores", "[", "0", "]", "\n", "pred_sent", "=", "' '", ".", "join", "(", "best_pred", ")", "\n", "output", "+=", "'PRED {}: {}\\n'", ".", "format", "(", "sent_number", ",", "pred_sent", ")", "\n", "output", "+=", "\"PRED SCORE: {:.4f}\\n\"", ".", "format", "(", "best_score", ")", "\n", "\n", "if", "self", ".", "gold_sent", "is", "not", "None", ":", "\n", "            ", "tgt_sent", "=", "' '", ".", "join", "(", "self", ".", "gold_sent", ")", "\n", "output", "+=", "'GOLD {}: {}\\n'", ".", "format", "(", "sent_number", ",", "tgt_sent", ")", "\n", "output", "+=", "(", "\"GOLD SCORE: {:.4f}\\n\"", ".", "format", "(", "self", ".", "gold_score", ")", ")", "\n", "", "if", "len", "(", "self", ".", "pred_sents", ")", ">", "1", ":", "\n", "            ", "output", "+=", "'\\nBEST HYP:\\n'", "\n", "for", "score", ",", "sent", "in", "zip", "(", "self", ".", "pred_scores", ",", "self", ".", "pred_sents", ")", ":", "\n", "                ", "output", "+=", "\"[{:.4f}] {}\\n\"", ".", "format", "(", "score", ",", "sent", ")", "\n", "\n", "", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.predictor.build_predictor": [[16, 21], ["translate.beam.GNMTGlobalScorer", "predictor.Translator"], "function", ["None"], ["def", "build_predictor", "(", "args", ",", "tokenizer", ",", "symbols", ",", "model", ",", "logger", "=", "None", ")", ":", "\n", "    ", "scorer", "=", "GNMTGlobalScorer", "(", "args", ".", "alpha", ",", "length_penalty", "=", "'wu'", ")", "\n", "\n", "translator", "=", "Translator", "(", "args", ",", "model", ",", "tokenizer", ",", "symbols", ",", "global_scorer", "=", "scorer", ",", "logger", "=", "logger", ")", "\n", "return", "translator", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch._pad": [[13, 18], ["max", "len", "len"], "methods", ["None"], ["    ", "def", "_pad", "(", "self", ",", "data", ",", "pad_id", ",", "width", "=", "-", "1", ")", ":", "\n", "        ", "if", "(", "width", "==", "-", "1", ")", ":", "\n", "            ", "width", "=", "max", "(", "len", "(", "d", ")", "for", "d", "in", "data", ")", "\n", "", "rtn_data", "=", "[", "d", "+", "[", "pad_id", "]", "*", "(", "width", "-", "len", "(", "d", ")", ")", "for", "d", "in", "data", "]", "\n", "return", "rtn_data", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch.__init__": [[19, 58], ["len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "data_loader.Batch._pad", "data_loader.Batch._pad", "data_loader.Batch._pad", "data_loader.Batch._pad", "data_loader.Batch._pad", "torch.tensor.to", "mask_cls.to", "torch.tensor.to", "torch.tensor.to", "torch.tensor.to", "torch.tensor.to", "mask_src.to", "mask_tgt.to", "setattr", "setattr"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch._pad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch._pad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch._pad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch._pad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch._pad"], ["", "def", "__init__", "(", "self", ",", "data", "=", "None", ",", "device", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "        ", "\"\"\"Create a Batch from a list of examples.\"\"\"", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "self", ".", "batch_size", "=", "len", "(", "data", ")", "\n", "pre_src", "=", "[", "x", "[", "0", "]", "for", "x", "in", "data", "]", "\n", "pre_tgt", "=", "[", "x", "[", "1", "]", "for", "x", "in", "data", "]", "\n", "pre_segs", "=", "[", "x", "[", "2", "]", "for", "x", "in", "data", "]", "\n", "pre_clss", "=", "[", "x", "[", "3", "]", "for", "x", "in", "data", "]", "\n", "pre_src_sent_labels", "=", "[", "x", "[", "4", "]", "for", "x", "in", "data", "]", "\n", "\n", "src", "=", "torch", ".", "tensor", "(", "self", ".", "_pad", "(", "pre_src", ",", "0", ")", ")", "\n", "tgt", "=", "torch", ".", "tensor", "(", "self", ".", "_pad", "(", "pre_tgt", ",", "0", ")", ")", "\n", "\n", "segs", "=", "torch", ".", "tensor", "(", "self", ".", "_pad", "(", "pre_segs", ",", "0", ")", ")", "\n", "mask_src", "=", "1", "-", "(", "src", "==", "0", ")", "\n", "mask_tgt", "=", "1", "-", "(", "tgt", "==", "0", ")", "\n", "\n", "\n", "clss", "=", "torch", ".", "tensor", "(", "self", ".", "_pad", "(", "pre_clss", ",", "-", "1", ")", ")", "\n", "src_sent_labels", "=", "torch", ".", "tensor", "(", "self", ".", "_pad", "(", "pre_src_sent_labels", ",", "0", ")", ")", "\n", "mask_cls", "=", "1", "-", "(", "clss", "==", "-", "1", ")", "\n", "clss", "[", "clss", "==", "-", "1", "]", "=", "0", "\n", "setattr", "(", "self", ",", "'clss'", ",", "clss", ".", "to", "(", "device", ")", ")", "\n", "setattr", "(", "self", ",", "'mask_cls'", ",", "mask_cls", ".", "to", "(", "device", ")", ")", "\n", "setattr", "(", "self", ",", "'src_sent_labels'", ",", "src_sent_labels", ".", "to", "(", "device", ")", ")", "\n", "\n", "\n", "setattr", "(", "self", ",", "'src'", ",", "src", ".", "to", "(", "device", ")", ")", "\n", "setattr", "(", "self", ",", "'tgt'", ",", "tgt", ".", "to", "(", "device", ")", ")", "\n", "setattr", "(", "self", ",", "'segs'", ",", "segs", ".", "to", "(", "device", ")", ")", "\n", "setattr", "(", "self", ",", "'mask_src'", ",", "mask_src", ".", "to", "(", "device", ")", ")", "\n", "setattr", "(", "self", ",", "'mask_tgt'", ",", "mask_tgt", ".", "to", "(", "device", ")", ")", "\n", "\n", "\n", "if", "(", "is_test", ")", ":", "\n", "                ", "src_str", "=", "[", "x", "[", "-", "2", "]", "for", "x", "in", "data", "]", "\n", "setattr", "(", "self", ",", "'src_str'", ",", "src_str", ")", "\n", "tgt_str", "=", "[", "x", "[", "-", "1", "]", "for", "x", "in", "data", "]", "\n", "setattr", "(", "self", ",", "'tgt_str'", ",", "tgt_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Batch.__len__": [[59, 61], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Dataloader.__init__": [[128, 138], ["data_loader.Dataloader._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Dataloader._next_dataset_iterator"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "datasets", ",", "batch_size", ",", "\n", "device", ",", "shuffle", ",", "is_test", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "is_test", "=", "is_test", "\n", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Dataloader.__iter__": [[139, 145], ["data_loader.Dataloader._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Dataloader._next_dataset_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n", "while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.Dataloader._next_dataset_iterator": [[147, 163], ["data_loader.DataIterator", "hasattr", "next", "gc.collect", "gc.collect"], "methods", ["None"], ["", "", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "try", ":", "\n", "# Drop the current dataset for decreasing memory", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"cur_dataset\"", ")", ":", "\n", "                ", "self", ".", "cur_dataset", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "self", ".", "cur_dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "DataIterator", "(", "args", "=", "self", ".", "args", ",", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "device", "=", "self", ".", "device", ",", "shuffle", "=", "self", ".", "shuffle", ",", "is_test", "=", "self", ".", "is_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.__init__": [[166, 181], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dataset", ",", "batch_size", ",", "device", "=", "None", ",", "is_test", "=", "False", ",", "\n", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "batch_size", ",", "self", ".", "is_test", ",", "self", ".", "dataset", "=", "batch_size", ",", "is_test", ",", "dataset", "\n", "self", ".", "iterations", "=", "0", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", "\n", "\n", "self", ".", "_iterations_this_epoch", "=", "0", "\n", "if", "(", "self", ".", "args", ".", "task", "==", "'abs'", ")", ":", "\n", "            ", "self", ".", "batch_size_fn", "=", "abs_batch_size_fn", "\n", "", "else", ":", "\n", "            ", "self", ".", "batch_size_fn", "=", "ext_batch_size_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.data": [[182, 187], ["random.shuffle"], "methods", ["None"], ["", "", "def", "data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "random", ".", "shuffle", "(", "self", ".", "dataset", ")", "\n", "", "xs", "=", "self", ".", "dataset", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.preprocess": [[193, 218], ["bisect.bisect_left", "len"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "ex", ",", "is_test", ")", ":", "\n", "        ", "src", "=", "ex", "[", "'src'", "]", "\n", "tgt", "=", "ex", "[", "'tgt'", "]", "[", ":", "self", ".", "args", ".", "max_tgt_len", "]", "[", ":", "-", "1", "]", "+", "[", "2", "]", "\n", "src_sent_labels", "=", "ex", "[", "'src_sent_labels'", "]", "\n", "segs", "=", "ex", "[", "'segs'", "]", "\n", "if", "(", "not", "self", ".", "args", ".", "use_interval", ")", ":", "\n", "            ", "segs", "=", "[", "0", "]", "*", "len", "(", "segs", ")", "\n", "", "clss", "=", "ex", "[", "'clss'", "]", "\n", "src_txt", "=", "ex", "[", "'src_txt'", "]", "\n", "tgt_txt", "=", "ex", "[", "'tgt_txt'", "]", "\n", "\n", "end_id", "=", "[", "src", "[", "-", "1", "]", "]", "\n", "src", "=", "src", "[", ":", "-", "1", "]", "[", ":", "self", ".", "args", ".", "max_pos", "-", "1", "]", "+", "end_id", "\n", "segs", "=", "segs", "[", ":", "self", ".", "args", ".", "max_pos", "]", "\n", "max_sent_id", "=", "bisect", ".", "bisect_left", "(", "clss", ",", "self", ".", "args", ".", "max_pos", ")", "\n", "src_sent_labels", "=", "src_sent_labels", "[", ":", "max_sent_id", "]", "\n", "clss", "=", "clss", "[", ":", "max_sent_id", "]", "\n", "# src_txt = src_txt[:max_sent_id]", "\n", "\n", "\n", "\n", "if", "(", "is_test", ")", ":", "\n", "            ", "return", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "src_sent_labels", ",", "src_txt", ",", "tgt_txt", "\n", "", "else", ":", "\n", "            ", "return", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "src_sent_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.batch_buffer": [[219, 237], ["data_loader.DataIterator.preprocess", "minibatch.append", "data_loader.DataIterator.batch_size_fn", "len", "len", "data_loader.DataIterator.batch_size_fn"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.preprocess"], ["", "", "def", "batch_buffer", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "for", "ex", "in", "data", ":", "\n", "            ", "if", "(", "len", "(", "ex", "[", "'src'", "]", ")", "==", "0", ")", ":", "\n", "                ", "continue", "\n", "", "ex", "=", "self", ".", "preprocess", "(", "ex", ",", "self", ".", "is_test", ")", "\n", "if", "(", "ex", "is", "None", ")", ":", "\n", "                ", "continue", "\n", "", "minibatch", ".", "append", "(", "ex", ")", "\n", "size_so_far", "=", "self", ".", "batch_size_fn", "(", "ex", ",", "len", "(", "minibatch", ")", ")", "\n", "if", "size_so_far", "==", "batch_size", ":", "\n", "                ", "yield", "minibatch", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "", "elif", "size_so_far", ">", "batch_size", ":", "\n", "                ", "yield", "minibatch", "[", ":", "-", "1", "]", "\n", "minibatch", ",", "size_so_far", "=", "minibatch", "[", "-", "1", ":", "]", ",", "self", ".", "batch_size_fn", "(", "ex", ",", "1", ")", "\n", "", "", "if", "minibatch", ":", "\n", "            ", "yield", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.batch": [[238, 252], ["minibatch.append", "data_loader.DataIterator.batch_size_fn", "len", "data_loader.DataIterator.batch_size_fn"], "methods", ["None"], ["", "", "def", "batch", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Yield elements from data in chunks of batch_size.\"\"\"", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "for", "ex", "in", "data", ":", "\n", "            ", "minibatch", ".", "append", "(", "ex", ")", "\n", "size_so_far", "=", "self", ".", "batch_size_fn", "(", "ex", ",", "len", "(", "minibatch", ")", ")", "\n", "if", "size_so_far", "==", "batch_size", ":", "\n", "                ", "yield", "minibatch", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "", "elif", "size_so_far", ">", "batch_size", ":", "\n", "                ", "yield", "minibatch", "[", ":", "-", "1", "]", "\n", "minibatch", ",", "size_so_far", "=", "minibatch", "[", "-", "1", ":", "]", ",", "self", ".", "batch_size_fn", "(", "ex", ",", "1", ")", "\n", "", "", "if", "minibatch", ":", "\n", "            ", "yield", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.create_batches": [[253, 274], ["data_loader.DataIterator.data", "data_loader.DataIterator.batch_buffer", "data_loader.DataIterator.batch", "list", "sorted", "sorted", "sorted", "random.shuffle", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.data", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.batch_buffer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.batch"], ["", "", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "\"\"\" Create batches \"\"\"", "\n", "data", "=", "self", ".", "data", "(", ")", "\n", "for", "buffer", "in", "self", ".", "batch_buffer", "(", "data", ",", "self", ".", "batch_size", "*", "300", ")", ":", "\n", "\n", "            ", "if", "(", "self", ".", "args", ".", "task", "==", "'abs'", ")", ":", "\n", "                ", "p_batch", "=", "sorted", "(", "buffer", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "2", "]", ")", ")", "\n", "p_batch", "=", "sorted", "(", "p_batch", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "p_batch", "=", "sorted", "(", "buffer", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "2", "]", ")", ")", "\n", "\n", "", "p_batch", "=", "self", ".", "batch", "(", "p_batch", ",", "self", ".", "batch_size", ")", "\n", "\n", "\n", "p_batch", "=", "list", "(", "p_batch", ")", "\n", "if", "(", "self", ".", "shuffle", ")", ":", "\n", "                ", "random", ".", "shuffle", "(", "p_batch", ")", "\n", "", "for", "b", "in", "p_batch", ":", "\n", "                ", "if", "(", "len", "(", "b", ")", "==", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "yield", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.__iter__": [[275, 288], ["data_loader.DataIterator.create_batches", "enumerate", "data_loader.Batch"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.create_batches"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "self", ".", "batches", "=", "self", ".", "create_batches", "(", ")", "\n", "for", "idx", ",", "minibatch", "in", "enumerate", "(", "self", ".", "batches", ")", ":", "\n", "# fast-forward if loaded from state", "\n", "                ", "if", "self", ".", "_iterations_this_epoch", ">", "idx", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "iterations", "+=", "1", "\n", "self", ".", "_iterations_this_epoch", "+=", "1", "\n", "batch", "=", "Batch", "(", "minibatch", ",", "self", ".", "device", ",", "self", ".", "is_test", ")", "\n", "\n", "yield", "batch", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.__init__": [[291, 296], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "datasets", ",", "batch_size", ",", "\n", "device", ",", "shuffle", ",", "is_test", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.data": [[297, 302], ["random.shuffle"], "methods", ["None"], ["", "def", "data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "random", ".", "shuffle", "(", "self", ".", "dataset", ")", "\n", "", "xs", "=", "self", ".", "dataset", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.preprocess": [[303, 326], ["bisect.bisect_left", "len"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "ex", ",", "is_test", ")", ":", "\n", "        ", "src", "=", "ex", "[", "'src'", "]", "\n", "tgt", "=", "ex", "[", "'tgt'", "]", "[", ":", "self", ".", "args", ".", "max_tgt_len", "]", "[", ":", "-", "1", "]", "+", "[", "2", "]", "\n", "src_sent_labels", "=", "ex", "[", "'src_sent_labels'", "]", "\n", "segs", "=", "ex", "[", "'segs'", "]", "\n", "if", "(", "not", "self", ".", "args", ".", "use_interval", ")", ":", "\n", "            ", "segs", "=", "[", "0", "]", "*", "len", "(", "segs", ")", "\n", "", "clss", "=", "ex", "[", "'clss'", "]", "\n", "src_txt", "=", "ex", "[", "'src_txt'", "]", "\n", "tgt_txt", "=", "ex", "[", "'tgt_txt'", "]", "\n", "\n", "end_id", "=", "[", "src", "[", "-", "1", "]", "]", "\n", "src", "=", "src", "[", ":", "-", "1", "]", "[", ":", "self", ".", "args", ".", "max_pos", "-", "1", "]", "+", "end_id", "\n", "segs", "=", "segs", "[", ":", "self", ".", "args", ".", "max_pos", "]", "\n", "max_sent_id", "=", "bisect", ".", "bisect_left", "(", "clss", ",", "self", ".", "args", ".", "max_pos", ")", "\n", "src_sent_labels", "=", "src_sent_labels", "[", ":", "max_sent_id", "]", "\n", "clss", "=", "clss", "[", ":", "max_sent_id", "]", "\n", "# src_txt = src_txt[:max_sent_id]", "\n", "\n", "if", "(", "is_test", ")", ":", "\n", "            ", "return", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "src_sent_labels", ",", "src_txt", ",", "tgt_txt", "\n", "", "else", ":", "\n", "            ", "return", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "src_sent_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.batch_buffer": [[327, 345], ["data_loader.TextDataloader.preprocess", "minibatch.append", "simple_batch_size_fn", "len", "len", "simple_batch_size_fn"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.preprocess"], ["", "", "def", "batch_buffer", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "for", "ex", "in", "data", ":", "\n", "            ", "if", "(", "len", "(", "ex", "[", "'src'", "]", ")", "==", "0", ")", ":", "\n", "                ", "continue", "\n", "", "ex", "=", "self", ".", "preprocess", "(", "ex", ",", "self", ".", "is_test", ")", "\n", "if", "(", "ex", "is", "None", ")", ":", "\n", "                ", "continue", "\n", "", "minibatch", ".", "append", "(", "ex", ")", "\n", "size_so_far", "=", "simple_batch_size_fn", "(", "ex", ",", "len", "(", "minibatch", ")", ")", "\n", "if", "size_so_far", "==", "batch_size", ":", "\n", "                ", "yield", "minibatch", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "", "elif", "size_so_far", ">", "batch_size", ":", "\n", "                ", "yield", "minibatch", "[", ":", "-", "1", "]", "\n", "minibatch", ",", "size_so_far", "=", "minibatch", "[", "-", "1", ":", "]", ",", "simple_batch_size_fn", "(", "ex", ",", "1", ")", "\n", "", "", "if", "minibatch", ":", "\n", "            ", "yield", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.create_batches": [[346, 366], ["data_loader.TextDataloader.data", "data_loader.TextDataloader.batch_buffer", "batch", "list", "sorted", "sorted", "sorted", "batch", "random.shuffle", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.data", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.batch_buffer", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.batch", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.DataIterator.batch"], ["", "", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "\"\"\" Create batches \"\"\"", "\n", "data", "=", "self", ".", "data", "(", ")", "\n", "for", "buffer", "in", "self", ".", "batch_buffer", "(", "data", ",", "self", ".", "batch_size", "*", "300", ")", ":", "\n", "            ", "if", "(", "self", ".", "args", ".", "task", "==", "'abs'", ")", ":", "\n", "                ", "p_batch", "=", "sorted", "(", "buffer", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "2", "]", ")", ")", "\n", "p_batch", "=", "sorted", "(", "p_batch", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "p_batch", "=", "sorted", "(", "buffer", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "2", "]", ")", ")", "\n", "p_batch", "=", "batch", "(", "p_batch", ",", "self", ".", "batch_size", ")", "\n", "\n", "", "p_batch", "=", "batch", "(", "p_batch", ",", "self", ".", "batch_size", ")", "\n", "\n", "p_batch", "=", "list", "(", "p_batch", ")", "\n", "if", "(", "self", ".", "shuffle", ")", ":", "\n", "                ", "random", ".", "shuffle", "(", "p_batch", ")", "\n", "", "for", "b", "in", "p_batch", ":", "\n", "                ", "if", "(", "len", "(", "b", ")", "==", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "yield", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.__iter__": [[367, 380], ["data_loader.TextDataloader.create_batches", "enumerate", "data_loader.Batch"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.TextDataloader.create_batches"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "self", ".", "batches", "=", "self", ".", "create_batches", "(", ")", "\n", "for", "idx", ",", "minibatch", "in", "enumerate", "(", "self", ".", "batches", ")", ":", "\n", "# fast-forward if loaded from state", "\n", "                ", "if", "self", ".", "_iterations_this_epoch", ">", "idx", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "iterations", "+=", "1", "\n", "self", ".", "_iterations_this_epoch", "+=", "1", "\n", "batch", "=", "Batch", "(", "minibatch", ",", "self", ".", "device", ",", "self", ".", "is_test", ")", "\n", "\n", "yield", "batch", "\n", "", "return", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.load_dataset": [[65, 95], ["sorted", "torch.load", "others.logging.logger.info", "glob.glob", "random.shuffle", "data_loader.load_dataset._lazy_dataset_loader"], "function", ["None"], ["", "", "def", "load_dataset", "(", "args", ",", "corpus_type", ",", "shuffle", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", "\n", "\n", "def", "_lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "pt_file", ")", "\n", "logger", ".", "info", "(", "'Loading %s dataset from %s, number of examples: %d'", "%", "\n", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n", "return", "dataset", "\n", "\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "bert_data_path", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "if", "(", "shuffle", ")", ":", "\n", "            ", "random", ".", "shuffle", "(", "pts", ")", "\n", "\n", "", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "_lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one inputters.*Dataset, simple!", "\n", "        ", "pt", "=", "args", ".", "bert_data_path", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "_lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.abs_batch_size_fn": [[97, 110], ["max", "max", "len"], "function", ["None"], ["", "", "def", "abs_batch_size_fn", "(", "new", ",", "count", ")", ":", "\n", "    ", "src", ",", "tgt", "=", "new", "[", "0", "]", ",", "new", "[", "1", "]", "\n", "global", "max_n_sents", ",", "max_n_tokens", ",", "max_size", "\n", "if", "count", "==", "1", ":", "\n", "        ", "max_size", "=", "0", "\n", "max_n_sents", "=", "0", "\n", "max_n_tokens", "=", "0", "\n", "", "max_n_sents", "=", "max", "(", "max_n_sents", ",", "len", "(", "tgt", ")", ")", "\n", "max_size", "=", "max", "(", "max_size", ",", "max_n_sents", ")", "\n", "src_elements", "=", "count", "*", "max_size", "\n", "if", "(", "count", ">", "6", ")", ":", "\n", "        ", "return", "src_elements", "+", "1e3", "\n", "", "return", "src_elements", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.data_loader.ext_batch_size_fn": [[112, 125], ["max", "max", "len", "len"], "function", ["None"], ["", "def", "ext_batch_size_fn", "(", "new", ",", "count", ")", ":", "\n", "    ", "if", "(", "len", "(", "new", ")", "==", "4", ")", ":", "\n", "        ", "pass", "\n", "", "src", ",", "labels", "=", "new", "[", "0", "]", ",", "new", "[", "4", "]", "\n", "global", "max_n_sents", ",", "max_n_tokens", ",", "max_size", "\n", "if", "count", "==", "1", ":", "\n", "        ", "max_size", "=", "0", "\n", "max_n_sents", "=", "0", "\n", "max_n_tokens", "=", "0", "\n", "", "max_n_sents", "=", "max", "(", "max_n_sents", ",", "len", "(", "src", ")", ")", "\n", "max_size", "=", "max", "(", "max_size", ",", "max_n_sents", ")", "\n", "src_elements", "=", "count", "*", "max_size", "\n", "return", "src_elements", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.GlobalAttention.__init__": [[93, 110], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "attn_type", "=", "\"dot\"", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "assert", "attn_type", "in", "[", "\"dot\"", ",", "\"general\"", ",", "\"mlp\"", "]", ",", "(", "\n", "\"Please select a valid attention type.\"", ")", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.GlobalAttention.score": [[112, 151], ["h_s.size", "neural.GlobalAttention.view.size", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "neural.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "neural.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "neural.GlobalAttention.v().view", "neural.GlobalAttention.view.view", "neural.GlobalAttention.linear_in", "neural.GlobalAttention.view", "neural.GlobalAttention.view.view", "h_s.contiguous().view", "neural.GlobalAttention.v", "h_s.contiguous", "torch.tanh.view", "torch.tanh.view", "torch.tanh.view", "torch.tanh.view", "torch.tanh.view"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (`FloatTensor`): sequence of queries `[batch x tgt_len x dim]`\n          h_s (`FloatTensor`): sequence of sources `[batch x src_len x dim]`\n\n        Returns:\n          :obj:`FloatTensor`:\n           raw attention scores (unnormalized) for each src index\n          `[batch x tgt_len x src_len]`\n\n        \"\"\"", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "torch", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.GlobalAttention.forward": [[152, 213], ["memory_bank.size", "source.unsqueeze.unsqueeze.size", "neural.GlobalAttention.score", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "align_vectors.transpose().contiguous.transpose().contiguous.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "neural.GlobalAttention.linear_out().view", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "memory_masks.transpose.transpose.transpose", "memory_masks.transpose.transpose.transpose", "neural.GlobalAttention.masked_fill_", "neural.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "neural.GlobalAttention.masked_fill_", "neural.GlobalAttention.view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "neural.GlobalAttention.linear_out", "memory_masks.transpose.transpose.byte", "float", "neural.GlobalAttention.size", "float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.GlobalAttention.score", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.sequence_mask"], ["", "", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "memory_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          source (`FloatTensor`): query vectors `[batch x tgt_len x dim]`\n          memory_bank (`FloatTensor`): source vectors `[batch x src_len x dim]`\n          memory_lengths (`LongTensor`): the source context lengths `[batch]`\n          coverage (`FloatTensor`): None (not supported yet)\n\n        Returns:\n          (`FloatTensor`, `FloatTensor`):\n\n          * Computed vector `[tgt_len x batch x dim]`\n          * Attention distribtutions for each query\n             `[tgt_len x batch x src_len]`\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "source_l", ",", "dim", "=", "memory_bank", ".", "size", "(", ")", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "align", "=", "self", ".", "score", "(", "source", ",", "memory_bank", ")", "\n", "\n", "if", "memory_masks", "is", "not", "None", ":", "\n", "            ", "memory_masks", "=", "memory_masks", ".", "transpose", "(", "0", ",", "1", ")", "\n", "memory_masks", "=", "memory_masks", ".", "transpose", "(", "1", ",", "2", ")", "\n", "align", ".", "masked_fill_", "(", "1", "-", "memory_masks", ".", "byte", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "if", "memory_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "memory_lengths", ",", "max_len", "=", "align", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "align_vectors", "=", "F", ".", "softmax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "target_l", ",", "source_l", ")", "\n", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "memory_bank", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "source", "]", ",", "2", ")", ".", "view", "(", "batch", "*", "target_l", ",", "dim", "*", "2", ")", "\n", "attn_h", "=", "self", ".", "linear_out", "(", "concat_c", ")", ".", "view", "(", "batch", ",", "target_l", ",", "dim", ")", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "attn_h", "=", "torch", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "align_vectors", "=", "align_vectors", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.PositionwiseFeedForward.__init__": [[225, 233], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "actv", "=", "gelu", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.PositionwiseFeedForward.forward": [[234, 238], ["neural.PositionwiseFeedForward.dropout_1", "neural.PositionwiseFeedForward.dropout_2", "neural.PositionwiseFeedForward.actv", "neural.PositionwiseFeedForward.w_2", "neural.PositionwiseFeedForward.w_1", "neural.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "inter", "=", "self", ".", "dropout_1", "(", "self", ".", "actv", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout_2", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.MultiHeadedAttention.__init__": [[282, 301], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ",", "use_final_linear", "=", "True", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "use_final_linear", "=", "use_final_linear", "\n", "if", "(", "self", ".", "use_final_linear", ")", ":", "\n", "            ", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.MultiHeadedAttention.forward": [[302, 434], ["shape.size", "shape.size", "neural.MultiHeadedAttention.size", "neural.MultiHeadedAttention.forward.shape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ",", "\n", "layer_cache", "=", "None", ",", "type", "=", "None", ",", "predefined_graph_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           key (`FloatTensor`): set of `key_len`\n                key vectors `[batch, key_len, dim]`\n           value (`FloatTensor`): set of `key_len`\n                value vectors `[batch, key_len, dim]`\n           query (`FloatTensor`): set of `query_len`\n                 query vectors  `[batch, query_len, dim]`\n           mask: binary mask indicating which keys have\n                 non-zero attention `[batch, query_len, key_len]`\n        Returns:\n           (`FloatTensor`, `FloatTensor`) :\n\n           * output context vectors `[batch, query_len, dim]`\n           * one of the attention vectors `[batch, query_len, key_len]`\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "head_count", "=", "self", ".", "head_count", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim_per_head", ")", "\n", "\n", "# 1) Project key, value, and query.", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "if", "type", "==", "\"self\"", ":", "\n", "                ", "query", ",", "key", ",", "value", "=", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "linear_keys", "(", "query", ")", ",", "self", ".", "linear_values", "(", "query", ")", "\n", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "device", "=", "key", ".", "device", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                        ", "key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "key", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                        ", "value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "value", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "value", "\n", "", "", "elif", "type", "==", "\"context\"", ":", "\n", "                ", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                        ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "else", ":", "\n", "                        ", "key", ",", "value", "=", "layer_cache", "[", "\"memory_keys\"", "]", ",", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "layer_cache", "[", "\"memory_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "linear_keys", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_values", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "scores", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", "\n", "\n", "if", "(", "not", "predefined_graph_1", "is", "None", ")", ":", "\n", "            ", "attn_masked", "=", "attn", "[", ":", ",", "-", "1", "]", "*", "predefined_graph_1", "\n", "attn_masked", "=", "attn_masked", "/", "(", "torch", ".", "sum", "(", "attn_masked", ",", "2", ")", ".", "unsqueeze", "(", "2", ")", "+", "1e-9", ")", "\n", "\n", "attn", "=", "torch", ".", "cat", "(", "[", "attn", "[", ":", ",", ":", "-", "1", "]", ",", "attn_masked", ".", "unsqueeze", "(", "1", ")", "]", ",", "1", ")", "\n", "\n", "", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "if", "(", "self", ".", "use_final_linear", ")", ":", "\n", "            ", "context", "=", "unshape", "(", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", ")", "\n", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "return", "output", "\n", "", "else", ":", "\n", "            ", "context", "=", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.DecoderState.detach": [[453, 457], ["tuple", "neural.DecoderState.input_feed.detach", "_.detach"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.detach", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.detach"], ["def", "detach", "(", "self", ")", ":", "\n", "        ", "\"\"\" Need to document this \"\"\"", "\n", "self", ".", "hidden", "=", "tuple", "(", "[", "_", ".", "detach", "(", ")", "for", "_", "in", "self", ".", "hidden", "]", ")", "\n", "self", ".", "input_feed", "=", "self", ".", "input_feed", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.DecoderState.beam_update": [[458, 474], ["e.size", "sent_states.data.copy_", "len", "sent_states.data.index_select", "e.view", "e.view"], "methods", ["None"], ["", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Need to document this \"\"\"", "\n", "for", "e", "in", "self", ".", "_all", ":", "\n", "            ", "sizes", "=", "e", ".", "size", "(", ")", "\n", "br", "=", "sizes", "[", "1", "]", "\n", "if", "len", "(", "sizes", ")", "==", "3", ":", "\n", "                ", "sent_states", "=", "e", ".", "view", "(", "sizes", "[", "0", "]", ",", "beam_size", ",", "br", "//", "beam_size", ",", "\n", "sizes", "[", "2", "]", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "", "else", ":", "\n", "                ", "sent_states", "=", "e", ".", "view", "(", "sizes", "[", "0", "]", ",", "beam_size", ",", "\n", "br", "//", "beam_size", ",", "\n", "sizes", "[", "2", "]", ",", "\n", "sizes", "[", "3", "]", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "\n", "", "sent_states", ".", "data", ".", "copy_", "(", "\n", "sent_states", ".", "data", ".", "index_select", "(", "1", ",", "positions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.DecoderState.map_batch_fn": [[475, 477], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.aeq": [[6, 14], ["next", "all", "str"], "function", ["None"], ["def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.sequence_mask": [[16, 26], ["lengths.numel", "torch.arange().type_as().repeat().lt", "torch.arange().type_as().repeat().lt", "torch.arange().type_as().repeat().lt", "torch.arange().type_as().repeat().lt", "torch.arange().type_as().repeat().lt", "lengths.max", "lengths.unsqueeze", "torch.arange().type_as().repeat", "torch.arange().type_as().repeat", "torch.arange().type_as().repeat", "torch.arange().type_as().repeat", "torch.arange().type_as().repeat", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "sequence_mask", "(", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean mask from sequence lengths.\n    \"\"\"", "\n", "batch_size", "=", "lengths", ".", "numel", "(", ")", "\n", "max_len", "=", "max_len", "or", "lengths", ".", "max", "(", ")", "\n", "return", "(", "torch", ".", "arange", "(", "0", ",", "max_len", ")", "\n", ".", "type_as", "(", "lengths", ")", "\n", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", ".", "lt", "(", "lengths", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.neural.gelu": [[28, 30], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer.__init__": [[87, 106], ["trainer.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.train"], ["def", "__init__", "(", "self", ",", "args", ",", "model", ",", "optims", ",", "loss", ",", "\n", "grad_accum_count", "=", "1", ",", "n_gpu", "=", "1", ",", "gpu_rank", "=", "1", ",", "\n", "report_manager", "=", "None", ")", ":", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "save_checkpoint_steps", "=", "args", ".", "save_checkpoint_steps", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "optims", "=", "optims", "\n", "self", ".", "grad_accum_count", "=", "grad_accum_count", "\n", "self", ".", "n_gpu", "=", "n_gpu", "\n", "self", ".", "gpu_rank", "=", "gpu_rank", "\n", "self", ".", "report_manager", "=", "report_manager", "\n", "\n", "self", ".", "loss", "=", "loss", "\n", "\n", "assert", "grad_accum_count", ">", "0", "\n", "# Set model in training mode.", "\n", "if", "(", "model", ")", ":", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer.train": [[107, 177], ["others.logging.logger.info", "train_iter_fct", "models.reporter.Statistics", "models.reporter.Statistics", "trainer.Trainer._start_report_manager", "enumerate", "train_iter_fct", "true_batchs.append", "batch.tgt[].ne().sum", "batch.tgt[].ne().sum.item", "trainer.Trainer._gradient_accumulation", "trainer.Trainer._maybe_report_training", "batch.tgt[].ne", "sum", "trainer.Trainer._save", "distributed.all_gather_list"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._start_report_manager", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._gradient_accumulation", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._maybe_report_training", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._save", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_gather_list"], ["", "", "def", "train", "(", "self", ",", "train_iter_fct", ",", "train_steps", ",", "valid_iter_fct", "=", "None", ",", "valid_steps", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        The main training loops.\n        by iterating over training data (i.e. `train_iter_fct`)\n        and running validation (i.e. iterating over `valid_iter_fct`\n\n        Args:\n            train_iter_fct(function): a function that returns the train\n                iterator. e.g. something like\n                train_iter_fct = lambda: generator(*args, **kwargs)\n            valid_iter_fct(function): same as train_iter_fct, for valid data\n            train_steps(int):\n            valid_steps(int):\n            save_checkpoint_steps(int):\n\n        Return:\n            None\n        \"\"\"", "\n", "logger", ".", "info", "(", "'Start training...'", ")", "\n", "\n", "# step =  self.optim._step + 1", "\n", "step", "=", "self", ".", "optims", "[", "0", "]", ".", "_step", "+", "1", "\n", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "total_stats", "=", "Statistics", "(", ")", "\n", "report_stats", "=", "Statistics", "(", ")", "\n", "self", ".", "_start_report_manager", "(", "start_time", "=", "total_stats", ".", "start_time", ")", "\n", "\n", "while", "step", "<=", "train_steps", ":", "\n", "\n", "            ", "reduce_counter", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "                ", "if", "self", ".", "n_gpu", "==", "0", "or", "(", "i", "%", "self", ".", "n_gpu", "==", "self", ".", "gpu_rank", ")", ":", "\n", "\n", "                    ", "true_batchs", ".", "append", "(", "batch", ")", "\n", "num_tokens", "=", "batch", ".", "tgt", "[", ":", ",", "1", ":", "]", ".", "ne", "(", "self", ".", "loss", ".", "padding_idx", ")", ".", "sum", "(", ")", "\n", "normalization", "+=", "num_tokens", ".", "item", "(", ")", "\n", "accum", "+=", "1", "\n", "if", "accum", "==", "self", ".", "grad_accum_count", ":", "\n", "                        ", "reduce_counter", "+=", "1", "\n", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                            ", "normalization", "=", "sum", "(", "distributed", "\n", ".", "all_gather_list", "\n", "(", "normalization", ")", ")", "\n", "\n", "", "self", ".", "_gradient_accumulation", "(", "\n", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", "\n", "\n", "report_stats", "=", "self", ".", "_maybe_report_training", "(", "\n", "step", ",", "train_steps", ",", "\n", "self", ".", "optims", "[", "0", "]", ".", "learning_rate", ",", "\n", "report_stats", ")", "\n", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "if", "(", "step", "%", "self", ".", "save_checkpoint_steps", "==", "0", "and", "self", ".", "gpu_rank", "==", "0", ")", ":", "\n", "                            ", "self", ".", "_save", "(", "step", ")", "\n", "\n", "", "step", "+=", "1", "\n", "if", "step", ">", "train_steps", ":", "\n", "                            ", "break", "\n", "", "", "", "", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "", "return", "total_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer.validate": [[178, 204], ["trainer.Trainer.model.eval", "models.reporter.Statistics", "torch.no_grad", "trainer.Trainer._report_step", "trainer.Trainer.model", "trainer.Trainer.loss.monolithic_compute_loss", "models.reporter.Statistics.update"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase.monolithic_compute_loss", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update"], ["", "def", "validate", "(", "self", ",", "valid_iter", ",", "step", "=", "0", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "# Set model in validating mode.", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "stats", "=", "Statistics", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch", "in", "valid_iter", ":", "\n", "                ", "src", "=", "batch", ".", "src", "\n", "tgt", "=", "batch", ".", "tgt", "\n", "segs", "=", "batch", ".", "segs", "\n", "clss", "=", "batch", ".", "clss", "\n", "mask_src", "=", "batch", ".", "mask_src", "\n", "mask_tgt", "=", "batch", ".", "mask_tgt", "\n", "mask_cls", "=", "batch", ".", "mask_cls", "\n", "\n", "outputs", ",", "_", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "mask_src", ",", "mask_tgt", ",", "mask_cls", ")", "\n", "\n", "batch_stats", "=", "self", ".", "loss", ".", "monolithic_compute_loss", "(", "batch", ",", "outputs", ")", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "", "self", ".", "_report_step", "(", "0", ",", "step", ",", "valid_stats", "=", "stats", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._gradient_accumulation": [[206, 255], ["trainer.Trainer.model.zero_grad", "trainer.Trainer.model", "trainer.Trainer.loss.sharded_compute_loss", "int", "total_stats.update", "report_stats.update", "trainer.Trainer.model.zero_grad", "src.size", "distributed.all_reduce_and_rescale_tensors", "o.step", "distributed.all_reduce_and_rescale_tensors", "o.step", "float", "float", "trainer.Trainer.model.parameters", "trainer.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase.sharded_compute_loss", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step"], ["", "", "def", "_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "            ", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "src", "=", "batch", ".", "src", "\n", "tgt", "=", "batch", ".", "tgt", "\n", "segs", "=", "batch", ".", "segs", "\n", "clss", "=", "batch", ".", "clss", "\n", "mask_src", "=", "batch", ".", "mask_src", "\n", "mask_tgt", "=", "batch", ".", "mask_tgt", "\n", "mask_cls", "=", "batch", ".", "mask_cls", "\n", "\n", "outputs", ",", "scores", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "mask_src", ",", "mask_tgt", ",", "mask_cls", ")", "\n", "batch_stats", "=", "self", ".", "loss", ".", "sharded_compute_loss", "(", "batch", ",", "outputs", ",", "self", ".", "args", ".", "generator_shard_size", ",", "normalization", ")", "\n", "\n", "batch_stats", ".", "n_docs", "=", "int", "(", "src", ".", "size", "(", "0", ")", ")", "\n", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# 4. Update the parameters and statistics.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "# Multi GPU gradient gather", "\n", "                ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "for", "o", "in", "self", ".", "optims", ":", "\n", "                    ", "o", ".", "step", "(", ")", "\n", "\n", "# in case of multi step gradient accumulation,", "\n", "# update only after accum batches", "\n", "", "", "", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "for", "o", "in", "self", ".", "optims", ":", "\n", "                ", "o", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer.test": [[257, 324], ["models.reporter.Statistics", "trainer.Trainer._report_step", "set", "len", "range", "trainer.Trainer.test._get_ngrams"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_ngrams"], ["", "", "", "def", "test", "(", "self", ",", "test_iter", ",", "step", ",", "cal_lead", "=", "False", ",", "cal_oracle", "=", "False", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "# Set model in validating mode.", "\n", "def", "_get_ngrams", "(", "n", ",", "text", ")", ":", "\n", "            ", "ngram_set", "=", "set", "(", ")", "\n", "text_length", "=", "len", "(", "text", ")", "\n", "max_index_ngram_start", "=", "text_length", "-", "n", "\n", "for", "i", "in", "range", "(", "max_index_ngram_start", "+", "1", ")", ":", "\n", "                ", "ngram_set", ".", "add", "(", "tuple", "(", "text", "[", "i", ":", "i", "+", "n", "]", ")", ")", "\n", "", "return", "ngram_set", "\n", "\n", "", "def", "_block_tri", "(", "c", ",", "p", ")", ":", "\n", "            ", "tri_c", "=", "_get_ngrams", "(", "3", ",", "c", ".", "split", "(", ")", ")", "\n", "for", "s", "in", "p", ":", "\n", "                ", "tri_s", "=", "_get_ngrams", "(", "3", ",", "s", ".", "split", "(", ")", ")", "\n", "if", "len", "(", "tri_c", ".", "intersection", "(", "tri_s", ")", ")", ">", "0", ":", "\n", "                    ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "if", "(", "not", "cal_lead", "and", "not", "cal_oracle", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "", "stats", "=", "Statistics", "(", ")", "\n", "\n", "can_path", "=", "'%s_step%d.candidate'", "%", "(", "self", ".", "args", ".", "result_path", ",", "step", ")", "\n", "gold_path", "=", "'%s_step%d.gold'", "%", "(", "self", ".", "args", ".", "result_path", ",", "step", ")", "\n", "with", "open", "(", "can_path", ",", "'w'", ")", "as", "save_pred", ":", "\n", "            ", "with", "open", "(", "gold_path", ",", "'w'", ")", "as", "save_gold", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "batch", "in", "test_iter", ":", "\n", "                        ", "gold", "=", "[", "]", "\n", "pred", "=", "[", "]", "\n", "if", "(", "cal_lead", ")", ":", "\n", "                            ", "selected_ids", "=", "[", "list", "(", "range", "(", "batch", ".", "clss", ".", "size", "(", "1", ")", ")", ")", "]", "*", "batch", ".", "batch_size", "\n", "", "for", "i", ",", "idx", "in", "enumerate", "(", "selected_ids", ")", ":", "\n", "                            ", "_pred", "=", "[", "]", "\n", "if", "(", "len", "(", "batch", ".", "src_str", "[", "i", "]", ")", "==", "0", ")", ":", "\n", "                                ", "continue", "\n", "", "for", "j", "in", "selected_ids", "[", "i", "]", "[", ":", "len", "(", "batch", ".", "src_str", "[", "i", "]", ")", "]", ":", "\n", "                                ", "if", "(", "j", ">=", "len", "(", "batch", ".", "src_str", "[", "i", "]", ")", ")", ":", "\n", "                                    ", "continue", "\n", "", "candidate", "=", "batch", ".", "src_str", "[", "i", "]", "[", "j", "]", ".", "strip", "(", ")", "\n", "_pred", ".", "append", "(", "candidate", ")", "\n", "\n", "if", "(", "(", "not", "cal_oracle", ")", "and", "(", "not", "self", ".", "args", ".", "recall_eval", ")", "and", "len", "(", "_pred", ")", "==", "3", ")", ":", "\n", "                                    ", "break", "\n", "\n", "", "", "_pred", "=", "'<q>'", ".", "join", "(", "_pred", ")", "\n", "if", "(", "self", ".", "args", ".", "recall_eval", ")", ":", "\n", "                                ", "_pred", "=", "' '", ".", "join", "(", "_pred", ".", "split", "(", ")", "[", ":", "len", "(", "batch", ".", "tgt_str", "[", "i", "]", ".", "split", "(", ")", ")", "]", ")", "\n", "\n", "", "pred", ".", "append", "(", "_pred", ")", "\n", "gold", ".", "append", "(", "batch", ".", "tgt_str", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "gold", ")", ")", ":", "\n", "                            ", "save_gold", ".", "write", "(", "gold", "[", "i", "]", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "pred", ")", ")", ":", "\n", "                            ", "save_pred", ".", "write", "(", "pred", "[", "i", "]", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "", "", "", "", "", "if", "(", "step", "!=", "-", "1", "and", "self", ".", "args", ".", "report_rouge", ")", ":", "\n", "            ", "rouges", "=", "test_rouge", "(", "self", ".", "args", ".", "temp_dir", ",", "can_path", ",", "gold_path", ")", "\n", "logger", ".", "info", "(", "'Rouges at step %d \\n%s'", "%", "(", "step", ",", "rouge_results_to_str", "(", "rouges", ")", ")", ")", "\n", "", "self", ".", "_report_step", "(", "0", ",", "step", ",", "valid_stats", "=", "stats", ")", "\n", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._save": [[325, 345], ["real_model.state_dict", "os.path.join", "others.logging.logger.info", "os.path.exists", "torch.save"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict"], ["", "def", "_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "real_model", "=", "self", ".", "model", "\n", "# real_generator = (self.generator.module", "\n", "#                   if isinstance(self.generator, torch.nn.DataParallel)", "\n", "#                   else self.generator)", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "# generator_state_dict = real_generator.state_dict()", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "# 'generator': generator_state_dict,", "\n", "'opt'", ":", "self", ".", "args", ",", "\n", "'optims'", ":", "self", ".", "optims", ",", "\n", "}", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "model_path", ",", "'model_step_%d.pt'", "%", "step", ")", "\n", "logger", ".", "info", "(", "\"Saving checkpoint %s\"", "%", "checkpoint_path", ")", "\n", "# checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)", "\n", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_path", ")", ")", ":", "\n", "            ", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._start_report_manager": [[346, 355], ["trainer.Trainer.report_manager.start"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start"], ["", "", "def", "_start_report_manager", "(", "self", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to start report manager (if any)\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "if", "start_time", "is", "None", ":", "\n", "                ", "self", ".", "report_manager", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "report_manager", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._maybe_gather_stats": [[356, 370], ["models.reporter.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats"], ["", "", "", "def", "_maybe_gather_stats", "(", "self", ",", "stat", ")", ":", "\n", "        ", "\"\"\"\n        Gather statistics in multi-processes cases\n\n        Args:\n            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n                or None (it returns None in this case)\n\n        Returns:\n            stat: the updated (or unchanged) stat object\n        \"\"\"", "\n", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "return", "Statistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._maybe_report_training": [[371, 381], ["trainer.Trainer.report_manager.report_training"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.report_training"], ["", "def", "_maybe_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report training stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_training` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ",", "\n", "multigpu", "=", "self", ".", "n_gpu", ">", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._report_step": [[382, 392], ["trainer.Trainer.report_manager.report_step"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.report_step"], ["", "", "def", "_report_step", "(", "self", ",", "learning_rate", ",", "step", ",", "train_stats", "=", "None", ",", "\n", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_step` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_step", "(", "\n", "learning_rate", ",", "step", ",", "train_stats", "=", "train_stats", ",", "\n", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.Trainer._maybe_save": [[393, 399], ["trainer.Trainer.model_saver.maybe_save"], "methods", ["None"], ["", "", "def", "_maybe_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"\n        Save the model if a model saver is set\n        \"\"\"", "\n", "if", "self", ".", "model_saver", "is", "not", "None", ":", "\n", "            ", "self", ".", "model_saver", ".", "maybe_save", "(", "step", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer._tally_parameters": [[13, 16], ["sum", "p.nelement", "model.parameters"], "function", ["None"], ["def", "_tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "return", "n_params", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer.build_trainer": [[18, 60], ["print", "tensorboardX.SummaryWriter", "models.reporter.ReportMgr", "trainer.Trainer", "int", "trainer._tally_parameters", "others.logging.logger.info"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext._tally_parameters"], ["", "def", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "optims", ",", "loss", ")", ":", "\n", "    ", "\"\"\"\n    Simplify `Trainer` creation based on user `opt`s*\n    Args:\n        opt (:obj:`Namespace`): user options (usually from argument parsing)\n        model (:obj:`onmt.models.NMTModel`): the model to train\n        fields (dict): dict of fields\n        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n        data_type (str): string describing the type of data\n            e.g. \"text\", \"img\", \"audio\"\n        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n            used to save the model\n    \"\"\"", "\n", "device", "=", "\"cpu\"", "if", "args", ".", "visible_gpus", "==", "'-1'", "else", "\"cuda\"", "\n", "\n", "\n", "grad_accum_count", "=", "args", ".", "accum_count", "\n", "n_gpu", "=", "args", ".", "world_size", "\n", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "gpu_rank", "=", "int", "(", "args", ".", "gpu_ranks", "[", "device_id", "]", ")", "\n", "", "else", ":", "\n", "        ", "gpu_rank", "=", "0", "\n", "n_gpu", "=", "0", "\n", "\n", "", "print", "(", "'gpu_rank %d'", "%", "gpu_rank", ")", "\n", "\n", "tensorboard_log_dir", "=", "args", ".", "model_path", "\n", "\n", "writer", "=", "SummaryWriter", "(", "tensorboard_log_dir", ",", "comment", "=", "\"Unmt\"", ")", "\n", "\n", "report_manager", "=", "ReportMgr", "(", "args", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "tensorboard_writer", "=", "writer", ")", "\n", "\n", "\n", "trainer", "=", "Trainer", "(", "args", ",", "model", ",", "optims", ",", "loss", ",", "grad_accum_count", ",", "n_gpu", ",", "gpu_rank", ",", "report_manager", ")", "\n", "\n", "# print(tr)", "\n", "if", "(", "model", ")", ":", "\n", "        ", "n_params", "=", "_tally_parameters", "(", "model", ")", "\n", "logger", ".", "info", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "\n", "", "return", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase.__init__": [[35, 45], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            report_every(int): Report status every this many sentences\n            start_time(float): manually set report start time. Negative values\n                means that you will need to set it later or use `start()`\n        \"\"\"", "\n", "self", ".", "report_every", "=", "report_every", "\n", "self", ".", "progress_step", "=", "0", "\n", "self", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase.start": [[46, 48], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase.log": [[49, 51], ["others.logging.logger.info"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase.report_training": [[52, 78], ["reporter.Statistics", "ValueError", "reporter.Statistics.all_gather_stats", "reporter.ReportMgrBase._report_training"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_training"], ["", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(Statistics): old Statistics instance.\n        Returns:\n            report_stats(Statistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "multigpu", ":", "\n", "            ", "report_stats", "=", "Statistics", ".", "all_gather_stats", "(", "report_stats", ")", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "", "return", "Statistics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase._report_training": [[79, 82], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" To be overridden \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase.report_step": [[83, 94], ["reporter.ReportMgrBase._report_step"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step"], ["", "def", "report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report stats of a step\n\n        Args:\n            train_stats(Statistics): training stats\n            valid_stats(Statistics): validation stats\n            lr(float): current learning rate\n        \"\"\"", "\n", "self", ".", "_report_step", "(", "\n", "lr", ",", "step", ",", "train_stats", "=", "train_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgrBase._report_step": [[95, 97], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgr.__init__": [[100, 112], ["reporter.ReportMgrBase.__init__"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["    ", "def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ",", "tensorboard_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A report manager that writes statistics on standard output as well as\n        (optionally) TensorBoard\n\n        Args:\n            report_every(int): Report status every this many sentences\n            tensorboard_writer(:obj:`tensorboard.SummaryWriter`):\n                The TensorBoard Summary writer to use or None\n        \"\"\"", "\n", "super", "(", "ReportMgr", ",", "self", ")", ".", "__init__", "(", "report_every", ",", "start_time", ")", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgr.maybe_log_tensorboard": [[113, 117], ["stats.log_tensorboard"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.log_tensorboard"], ["", "def", "maybe_log_tensorboard", "(", "self", ",", "stats", ",", "prefix", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "            ", "stats", ".", "log_tensorboard", "(", "\n", "prefix", ",", "self", ".", "tensorboard_writer", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgr._report_training": [[118, 134], ["reporter.Statistics.output", "reporter.ReportMgr.maybe_log_tensorboard", "reporter.Statistics"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.output", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard"], ["", "", "def", "_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_training`.\n        \"\"\"", "\n", "report_stats", ".", "output", "(", "step", ",", "num_steps", ",", "\n", "learning_rate", ",", "self", ".", "start_time", ")", "\n", "\n", "# Log the progress using the number of batches on the x-axis.", "\n", "self", ".", "maybe_log_tensorboard", "(", "report_stats", ",", "\n", "\"progress\"", ",", "\n", "learning_rate", ",", "\n", "step", ")", "\n", "report_stats", "=", "Statistics", "(", ")", "\n", "\n", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.ReportMgr._report_step": [[135, 156], ["reporter.ReportMgr.log", "reporter.ReportMgr.log", "reporter.ReportMgr.maybe_log_tensorboard", "reporter.ReportMgr.log", "reporter.ReportMgr.log", "reporter.ReportMgr.maybe_log_tensorboard", "train_stats.ppl", "train_stats.accuracy", "valid_stats.ppl", "valid_stats.accuracy"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.ppl", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.accuracy", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.ppl", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.accuracy"], ["", "def", "_report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_step`.\n        \"\"\"", "\n", "if", "train_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "train_stats", ",", "\n", "\"train\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n", "", "if", "valid_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "valid_stats", ",", "\n", "\"valid\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.__init__": [[168, 175], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_words", "=", "0", ",", "n_correct", "=", "0", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "n_docs", "=", "0", "\n", "self", ".", "n_correct", "=", "n_correct", "\n", "self", ".", "n_src_words", "=", "0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.all_gather_stats": [[176, 191], ["reporter.Statistics.all_gather_stats_list"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats_list"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats", "(", "stat", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` object accross multiple process/nodes\n\n        Args:\n            stat(:obj:Statistics): the statistics object to gather\n                accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            `Statistics`, the update stats object\n        \"\"\"", "\n", "stats", "=", "Statistics", ".", "all_gather_stats_list", "(", "[", "stat", "]", ",", "max_size", "=", "max_size", ")", "\n", "return", "stats", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.all_gather_stats_list": [[192, 218], ["distributed.all_gather_list", "get_rank", "enumerate", "enumerate", "our_stats[].update"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_gather_list", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats_list", "(", "stat_list", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "from", "torch", ".", "distributed", "import", "get_rank", "\n", "\n", "\"\"\"\n        Gather a `Statistics` list accross all processes/nodes\n\n        Args:\n            stat_list(list([`Statistics`])): list of statistics objects to\n                gather accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            our_stats(list([`Statistics`])): list of updated stats\n        \"\"\"", "\n", "# Get a list of world_size lists with len(stat_list) Statistics objects", "\n", "all_stats", "=", "all_gather_list", "(", "stat_list", ",", "max_size", "=", "max_size", ")", "\n", "\n", "our_rank", "=", "get_rank", "(", ")", "\n", "our_stats", "=", "all_stats", "[", "our_rank", "]", "\n", "for", "other_rank", ",", "stats", "in", "enumerate", "(", "all_stats", ")", ":", "\n", "            ", "if", "other_rank", "==", "our_rank", ":", "\n", "                ", "continue", "\n", "", "for", "i", ",", "stat", "in", "enumerate", "(", "stats", ")", ":", "\n", "                ", "our_stats", "[", "i", "]", ".", "update", "(", "stat", ",", "update_n_src_words", "=", "True", ")", "\n", "", "", "return", "our_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.update": [[219, 236], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "stat", ",", "update_n_src_words", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update statistics by suming values with another `Statistics` object\n\n        Args:\n            stat: another statistic object\n            update_n_src_words(bool): whether to update (sum) `n_src_words`\n                or not\n\n        \"\"\"", "\n", "self", ".", "loss", "+=", "stat", ".", "loss", "\n", "self", ".", "n_words", "+=", "stat", ".", "n_words", "\n", "self", ".", "n_correct", "+=", "stat", ".", "n_correct", "\n", "self", ".", "n_docs", "+=", "stat", ".", "n_docs", "\n", "\n", "if", "update_n_src_words", ":", "\n", "            ", "self", ".", "n_src_words", "+=", "stat", ".", "n_src_words", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.accuracy": [[237, 240], ["None"], "methods", ["None"], ["", "", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute accuracy \"\"\"", "\n", "return", "100", "*", "(", "self", ".", "n_correct", "/", "self", ".", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.xent": [[241, 244], ["None"], "methods", ["None"], ["", "def", "xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n", "return", "self", ".", "loss", "/", "self", ".", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.ppl": [[245, 248], ["math.exp", "min"], "methods", ["None"], ["", "def", "ppl", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute perplexity \"\"\"", "\n", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "loss", "/", "self", ".", "n_words", ",", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.elapsed_time": [[249, 252], ["time.time"], "methods", ["None"], ["", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute elapsed time \"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.output": [[253, 274], ["reporter.Statistics.elapsed_time", "others.logging.logger.info", "sys.stdout.flush", "reporter.Statistics.accuracy", "reporter.Statistics.ppl", "reporter.Statistics.xent", "time.time"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.elapsed_time", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.accuracy", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.ppl", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent"], ["", "def", "output", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           step (int): current step\n           n_batch (int): total batches\n           start (int): start time of step.\n        \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "logger", ".", "info", "(", "\n", "(", "\"Step %2d/%5d; acc: %6.2f; ppl: %5.2f; xent: %4.2f; \"", "+", "\n", "\"lr: %7.8f; %3.0f/%3.0f tok/s; %6.0f sec\"", ")", "\n", "%", "(", "step", ",", "num_steps", ",", "\n", "self", ".", "accuracy", "(", ")", ",", "\n", "self", ".", "ppl", "(", ")", ",", "\n", "self", ".", "xent", "(", ")", ",", "\n", "learning_rate", ",", "\n", "self", ".", "n_src_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "self", ".", "n_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.log_tensorboard": [[275, 283], ["reporter.Statistics.elapsed_time", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "reporter.Statistics.xent", "reporter.Statistics.ppl", "reporter.Statistics.accuracy"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.elapsed_time", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.ppl", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.Statistics.accuracy"], ["", "def", "log_tensorboard", "(", "self", ",", "prefix", ",", "writer", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "\"\"\" display statistics to tensorboard \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/xent\"", ",", "self", ".", "xent", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/ppl\"", ",", "self", ".", "ppl", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/accuracy\"", ",", "self", ".", "accuracy", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/tgtper\"", ",", "self", ".", "n_words", "/", "t", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/lr\"", ",", "learning_rate", ",", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter.build_report_manager": [[13, 25], ["reporter.ReportMgr", "SummaryWriter", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "build_report_manager", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "writer", "=", "SummaryWriter", "(", "opt", ".", "tensorboard_log_dir", "\n", "+", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"/%b-%d_%H-%M-%S\"", ")", ",", "\n", "comment", "=", "\"Unmt\"", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "report_mgr", "=", "ReportMgr", "(", "opt", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "\n", "tensorboard_writer", "=", "writer", ")", "\n", "return", "report_mgr", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.__init__": [[84, 102], ["torch.nn.BCELoss", "trainer_ext.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.train"], ["def", "__init__", "(", "self", ",", "args", ",", "model", ",", "optim", ",", "\n", "grad_accum_count", "=", "1", ",", "n_gpu", "=", "1", ",", "gpu_rank", "=", "1", ",", "\n", "report_manager", "=", "None", ")", ":", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "save_checkpoint_steps", "=", "args", ".", "save_checkpoint_steps", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "grad_accum_count", "=", "grad_accum_count", "\n", "self", ".", "n_gpu", "=", "n_gpu", "\n", "self", ".", "gpu_rank", "=", "gpu_rank", "\n", "self", ".", "report_manager", "=", "report_manager", "\n", "\n", "self", ".", "loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "assert", "grad_accum_count", ">", "0", "\n", "# Set model in training mode.", "\n", "if", "(", "model", ")", ":", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.train": [[103, 171], ["others.logging.logger.info", "train_iter_fct", "models.reporter_ext.Statistics", "models.reporter_ext.Statistics", "trainer_ext.Trainer._start_report_manager", "enumerate", "train_iter_fct", "true_batchs.append", "trainer_ext.Trainer._gradient_accumulation", "trainer_ext.Trainer._maybe_report_training", "sum", "trainer_ext.Trainer._save", "distributed.all_gather_list"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._start_report_manager", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._gradient_accumulation", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._maybe_report_training", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._save", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_gather_list"], ["", "", "def", "train", "(", "self", ",", "train_iter_fct", ",", "train_steps", ",", "valid_iter_fct", "=", "None", ",", "valid_steps", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        The main training loops.\n        by iterating over training data (i.e. `train_iter_fct`)\n        and running validation (i.e. iterating over `valid_iter_fct`\n\n        Args:\n            train_iter_fct(function): a function that returns the train\n                iterator. e.g. something like\n                train_iter_fct = lambda: generator(*args, **kwargs)\n            valid_iter_fct(function): same as train_iter_fct, for valid data\n            train_steps(int):\n            valid_steps(int):\n            save_checkpoint_steps(int):\n\n        Return:\n            None\n        \"\"\"", "\n", "logger", ".", "info", "(", "'Start training...'", ")", "\n", "\n", "# step =  self.optim._step + 1", "\n", "step", "=", "self", ".", "optim", ".", "_step", "+", "1", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "total_stats", "=", "Statistics", "(", ")", "\n", "report_stats", "=", "Statistics", "(", ")", "\n", "self", ".", "_start_report_manager", "(", "start_time", "=", "total_stats", ".", "start_time", ")", "\n", "\n", "while", "step", "<=", "train_steps", ":", "\n", "\n", "            ", "reduce_counter", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "                ", "if", "self", ".", "n_gpu", "==", "0", "or", "(", "i", "%", "self", ".", "n_gpu", "==", "self", ".", "gpu_rank", ")", ":", "\n", "\n", "                    ", "true_batchs", ".", "append", "(", "batch", ")", "\n", "normalization", "+=", "batch", ".", "batch_size", "\n", "accum", "+=", "1", "\n", "if", "accum", "==", "self", ".", "grad_accum_count", ":", "\n", "                        ", "reduce_counter", "+=", "1", "\n", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                            ", "normalization", "=", "sum", "(", "distributed", "\n", ".", "all_gather_list", "\n", "(", "normalization", ")", ")", "\n", "\n", "", "self", ".", "_gradient_accumulation", "(", "\n", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", "\n", "\n", "report_stats", "=", "self", ".", "_maybe_report_training", "(", "\n", "step", ",", "train_steps", ",", "\n", "self", ".", "optim", ".", "learning_rate", ",", "\n", "report_stats", ")", "\n", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "if", "(", "step", "%", "self", ".", "save_checkpoint_steps", "==", "0", "and", "self", ".", "gpu_rank", "==", "0", ")", ":", "\n", "                            ", "self", ".", "_save", "(", "step", ")", "\n", "\n", "", "step", "+=", "1", "\n", "if", "step", ">", "train_steps", ":", "\n", "                            ", "break", "\n", "", "", "", "", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "", "return", "total_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.validate": [[172, 199], ["trainer_ext.Trainer.model.eval", "models.reporter_ext.Statistics", "torch.no_grad", "trainer_ext.Trainer._report_step", "trainer_ext.Trainer.model", "trainer_ext.Trainer.loss", "models.reporter_ext.Statistics", "models.reporter_ext.Statistics.update", "labels.float", "float", "len", "trainer_ext.Trainer.cpu().data.numpy", "mask.float", "trainer_ext.Trainer.cpu"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update"], ["", "def", "validate", "(", "self", ",", "valid_iter", ",", "step", "=", "0", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "# Set model in validating mode.", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "stats", "=", "Statistics", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch", "in", "valid_iter", ":", "\n", "                ", "src", "=", "batch", ".", "src", "\n", "labels", "=", "batch", ".", "src_sent_labels", "\n", "segs", "=", "batch", ".", "segs", "\n", "clss", "=", "batch", ".", "clss", "\n", "mask", "=", "batch", ".", "mask_src", "\n", "mask_cls", "=", "batch", ".", "mask_cls", "\n", "\n", "sent_scores", ",", "mask", "=", "self", ".", "model", "(", "src", ",", "segs", ",", "clss", ",", "mask", ",", "mask_cls", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "sent_scores", ",", "labels", ".", "float", "(", ")", ")", "\n", "loss", "=", "(", "loss", "*", "mask", ".", "float", "(", ")", ")", ".", "sum", "(", ")", "\n", "batch_stats", "=", "Statistics", "(", "float", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", ",", "len", "(", "labels", ")", ")", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "", "self", ".", "_report_step", "(", "0", ",", "step", ",", "valid_stats", "=", "stats", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer.test": [[200, 295], ["models.reporter_ext.Statistics", "trainer_ext.Trainer._report_step", "set", "len", "range", "trainer_ext.Trainer.test._get_ngrams"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_ngrams"], ["", "", "def", "test", "(", "self", ",", "test_iter", ",", "step", ",", "cal_lead", "=", "False", ",", "cal_oracle", "=", "False", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "\n", "# Set model in validating mode.", "\n", "def", "_get_ngrams", "(", "n", ",", "text", ")", ":", "\n", "            ", "ngram_set", "=", "set", "(", ")", "\n", "text_length", "=", "len", "(", "text", ")", "\n", "max_index_ngram_start", "=", "text_length", "-", "n", "\n", "for", "i", "in", "range", "(", "max_index_ngram_start", "+", "1", ")", ":", "\n", "                ", "ngram_set", ".", "add", "(", "tuple", "(", "text", "[", "i", ":", "i", "+", "n", "]", ")", ")", "\n", "", "return", "ngram_set", "\n", "\n", "", "def", "_block_tri", "(", "c", ",", "p", ")", ":", "\n", "            ", "tri_c", "=", "_get_ngrams", "(", "3", ",", "c", ".", "split", "(", ")", ")", "\n", "for", "s", "in", "p", ":", "\n", "                ", "tri_s", "=", "_get_ngrams", "(", "3", ",", "s", ".", "split", "(", ")", ")", "\n", "if", "len", "(", "tri_c", ".", "intersection", "(", "tri_s", ")", ")", ">", "0", ":", "\n", "                    ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "if", "(", "not", "cal_lead", "and", "not", "cal_oracle", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "", "stats", "=", "Statistics", "(", ")", "\n", "\n", "can_path", "=", "'%s_step%d.candidate'", "%", "(", "self", ".", "args", ".", "result_path", ",", "step", ")", "\n", "gold_path", "=", "'%s_step%d.gold'", "%", "(", "self", ".", "args", ".", "result_path", ",", "step", ")", "\n", "with", "open", "(", "can_path", ",", "'w'", ")", "as", "save_pred", ":", "\n", "            ", "with", "open", "(", "gold_path", ",", "'w'", ")", "as", "save_gold", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "batch", "in", "test_iter", ":", "\n", "                        ", "src", "=", "batch", ".", "src", "\n", "labels", "=", "batch", ".", "src_sent_labels", "\n", "segs", "=", "batch", ".", "segs", "\n", "clss", "=", "batch", ".", "clss", "\n", "mask", "=", "batch", ".", "mask_src", "\n", "mask_cls", "=", "batch", ".", "mask_cls", "\n", "\n", "gold", "=", "[", "]", "\n", "pred", "=", "[", "]", "\n", "\n", "if", "(", "cal_lead", ")", ":", "\n", "                            ", "selected_ids", "=", "[", "list", "(", "range", "(", "batch", ".", "clss", ".", "size", "(", "1", ")", ")", ")", "]", "*", "batch", ".", "batch_size", "\n", "", "elif", "(", "cal_oracle", ")", ":", "\n", "                            ", "selected_ids", "=", "[", "[", "j", "for", "j", "in", "range", "(", "batch", ".", "clss", ".", "size", "(", "1", ")", ")", "if", "labels", "[", "i", "]", "[", "j", "]", "==", "1", "]", "for", "i", "in", "\n", "range", "(", "batch", ".", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "                            ", "sent_scores", ",", "mask", "=", "self", ".", "model", "(", "src", ",", "segs", ",", "clss", ",", "mask", ",", "mask_cls", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "sent_scores", ",", "labels", ".", "float", "(", ")", ")", "\n", "loss", "=", "(", "loss", "*", "mask", ".", "float", "(", ")", ")", ".", "sum", "(", ")", "\n", "batch_stats", "=", "Statistics", "(", "float", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", ",", "len", "(", "labels", ")", ")", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "sent_scores", "=", "sent_scores", "+", "mask", ".", "float", "(", ")", "\n", "sent_scores", "=", "sent_scores", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "selected_ids", "=", "np", ".", "argsort", "(", "-", "sent_scores", ",", "1", ")", "\n", "# selected_ids = np.sort(selected_ids,1)", "\n", "", "for", "i", ",", "idx", "in", "enumerate", "(", "selected_ids", ")", ":", "\n", "                            ", "_pred", "=", "[", "]", "\n", "if", "(", "len", "(", "batch", ".", "src_str", "[", "i", "]", ")", "==", "0", ")", ":", "\n", "                                ", "continue", "\n", "", "for", "j", "in", "selected_ids", "[", "i", "]", "[", ":", "len", "(", "batch", ".", "src_str", "[", "i", "]", ")", "]", ":", "\n", "                                ", "if", "(", "j", ">=", "len", "(", "batch", ".", "src_str", "[", "i", "]", ")", ")", ":", "\n", "                                    ", "continue", "\n", "", "candidate", "=", "batch", ".", "src_str", "[", "i", "]", "[", "j", "]", ".", "strip", "(", ")", "\n", "if", "(", "self", ".", "args", ".", "block_trigram", ")", ":", "\n", "                                    ", "if", "(", "not", "_block_tri", "(", "candidate", ",", "_pred", ")", ")", ":", "\n", "                                        ", "_pred", ".", "append", "(", "candidate", ")", "\n", "", "", "else", ":", "\n", "                                    ", "_pred", ".", "append", "(", "candidate", ")", "\n", "\n", "", "if", "(", "(", "not", "cal_oracle", ")", "and", "(", "not", "self", ".", "args", ".", "recall_eval", ")", "and", "len", "(", "_pred", ")", "==", "3", ")", ":", "\n", "                                    ", "break", "\n", "\n", "", "", "_pred", "=", "'<q>'", ".", "join", "(", "_pred", ")", "\n", "if", "(", "self", ".", "args", ".", "recall_eval", ")", ":", "\n", "                                ", "_pred", "=", "' '", ".", "join", "(", "_pred", ".", "split", "(", ")", "[", ":", "len", "(", "batch", ".", "tgt_str", "[", "i", "]", ".", "split", "(", ")", ")", "]", ")", "\n", "\n", "", "pred", ".", "append", "(", "_pred", ")", "\n", "gold", ".", "append", "(", "batch", ".", "tgt_str", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "gold", ")", ")", ":", "\n", "                            ", "save_gold", ".", "write", "(", "gold", "[", "i", "]", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "pred", ")", ")", ":", "\n", "                            ", "save_pred", ".", "write", "(", "pred", "[", "i", "]", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "", "", "", "", "", "if", "(", "step", "!=", "-", "1", "and", "self", ".", "args", ".", "report_rouge", ")", ":", "\n", "            ", "rouges", "=", "test_rouge", "(", "self", ".", "args", ".", "temp_dir", ",", "can_path", ",", "gold_path", ")", "\n", "logger", ".", "info", "(", "'Rouges at step %d \\n%s'", "%", "(", "step", ",", "rouge_results_to_str", "(", "rouges", ")", ")", ")", "\n", "", "self", ".", "_report_step", "(", "0", ",", "step", ",", "valid_stats", "=", "stats", ")", "\n", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._gradient_accumulation": [[296, 345], ["trainer_ext.Trainer.model.zero_grad", "trainer_ext.Trainer.model", "trainer_ext.Trainer.loss", "models.reporter_ext.Statistics", "total_stats.update", "report_stats.update", "trainer_ext.Trainer.optim.step", "trainer_ext.Trainer.model.zero_grad", "labels.float", "float", "trainer_ext.Trainer.optim.step", "distributed.all_reduce_and_rescale_tensors", "trainer_ext.Trainer.cpu().data.numpy", "distributed.all_reduce_and_rescale_tensors", "float", "mask.float", "trainer_ext.Trainer.numel", "float", "trainer_ext.Trainer.model.parameters", "trainer_ext.Trainer.model.parameters", "trainer_ext.Trainer.cpu"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_reduce_and_rescale_tensors"], ["", "def", "_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "            ", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "src", "=", "batch", ".", "src", "\n", "labels", "=", "batch", ".", "src_sent_labels", "\n", "segs", "=", "batch", ".", "segs", "\n", "clss", "=", "batch", ".", "clss", "\n", "mask", "=", "batch", ".", "mask_src", "\n", "mask_cls", "=", "batch", ".", "mask_cls", "\n", "\n", "sent_scores", ",", "mask", "=", "self", ".", "model", "(", "src", ",", "segs", ",", "clss", ",", "mask", ",", "mask_cls", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "sent_scores", ",", "labels", ".", "float", "(", ")", ")", "\n", "loss", "=", "(", "loss", "*", "mask", ".", "float", "(", ")", ")", ".", "sum", "(", ")", "\n", "(", "loss", "/", "loss", ".", "numel", "(", ")", ")", ".", "backward", "(", ")", "\n", "# loss.div(float(normalization)).backward()", "\n", "\n", "batch_stats", "=", "Statistics", "(", "float", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", ",", "normalization", ")", "\n", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# 4. Update the parameters and statistics.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "# Multi GPU gradient gather", "\n", "                ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# in case of multi step gradient accumulation,", "\n", "# update only after accum batches", "\n", "", "", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._save": [[346, 366], ["real_model.state_dict", "os.path.join", "others.logging.logger.info", "os.path.exists", "torch.save"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict"], ["", "", "def", "_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "real_model", "=", "self", ".", "model", "\n", "# real_generator = (self.generator.module", "\n", "#                   if isinstance(self.generator, torch.nn.DataParallel)", "\n", "#                   else self.generator)", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "# generator_state_dict = real_generator.state_dict()", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "# 'generator': generator_state_dict,", "\n", "'opt'", ":", "self", ".", "args", ",", "\n", "'optim'", ":", "self", ".", "optim", ",", "\n", "}", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "model_path", ",", "'model_step_%d.pt'", "%", "step", ")", "\n", "logger", ".", "info", "(", "\"Saving checkpoint %s\"", "%", "checkpoint_path", ")", "\n", "# checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)", "\n", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_path", ")", ")", ":", "\n", "            ", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._start_report_manager": [[367, 376], ["trainer_ext.Trainer.report_manager.start"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start"], ["", "", "def", "_start_report_manager", "(", "self", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to start report manager (if any)\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "if", "start_time", "is", "None", ":", "\n", "                ", "self", ".", "report_manager", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "report_manager", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._maybe_gather_stats": [[377, 391], ["models.reporter_ext.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats"], ["", "", "", "def", "_maybe_gather_stats", "(", "self", ",", "stat", ")", ":", "\n", "        ", "\"\"\"\n        Gather statistics in multi-processes cases\n\n        Args:\n            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n                or None (it returns None in this case)\n\n        Returns:\n            stat: the updated (or unchanged) stat object\n        \"\"\"", "\n", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "return", "Statistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._maybe_report_training": [[392, 402], ["trainer_ext.Trainer.report_manager.report_training"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.report_training"], ["", "def", "_maybe_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report training stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_training` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ",", "\n", "multigpu", "=", "self", ".", "n_gpu", ">", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._report_step": [[403, 413], ["trainer_ext.Trainer.report_manager.report_step"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.report_step"], ["", "", "def", "_report_step", "(", "self", ",", "learning_rate", ",", "step", ",", "train_stats", "=", "None", ",", "\n", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_step` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_step", "(", "\n", "learning_rate", ",", "step", ",", "train_stats", "=", "train_stats", ",", "\n", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.Trainer._maybe_save": [[414, 420], ["trainer_ext.Trainer.model_saver.maybe_save"], "methods", ["None"], ["", "", "def", "_maybe_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"\n        Save the model if a model saver is set\n        \"\"\"", "\n", "if", "self", ".", "model_saver", "is", "not", "None", ":", "\n", "            ", "self", ".", "model_saver", ".", "maybe_save", "(", "step", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext._tally_parameters": [[13, 16], ["sum", "p.nelement", "model.parameters"], "function", ["None"], ["def", "_tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "return", "n_params", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext.build_trainer": [[18, 57], ["print", "tensorboardX.SummaryWriter", "models.reporter_ext.ReportMgr", "trainer_ext.Trainer", "int", "trainer_ext._tally_parameters", "others.logging.logger.info"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.trainer_ext._tally_parameters"], ["", "def", "build_trainer", "(", "args", ",", "device_id", ",", "model", ",", "optim", ")", ":", "\n", "    ", "\"\"\"\n    Simplify `Trainer` creation based on user `opt`s*\n    Args:\n        opt (:obj:`Namespace`): user options (usually from argument parsing)\n        model (:obj:`onmt.models.NMTModel`): the model to train\n        fields (dict): dict of fields\n        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n        data_type (str): string describing the type of data\n            e.g. \"text\", \"img\", \"audio\"\n        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n            used to save the model\n    \"\"\"", "\n", "\n", "grad_accum_count", "=", "args", ".", "accum_count", "\n", "n_gpu", "=", "args", ".", "world_size", "\n", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "gpu_rank", "=", "int", "(", "args", ".", "gpu_ranks", "[", "device_id", "]", ")", "\n", "", "else", ":", "\n", "        ", "gpu_rank", "=", "0", "\n", "n_gpu", "=", "0", "\n", "\n", "", "print", "(", "'gpu_rank %d'", "%", "gpu_rank", ")", "\n", "\n", "tensorboard_log_dir", "=", "args", ".", "model_path", "\n", "\n", "writer", "=", "SummaryWriter", "(", "tensorboard_log_dir", ",", "comment", "=", "\"Unmt\"", ")", "\n", "\n", "report_manager", "=", "ReportMgr", "(", "args", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "tensorboard_writer", "=", "writer", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "args", ",", "model", ",", "optim", ",", "grad_accum_count", ",", "n_gpu", ",", "gpu_rank", ",", "report_manager", ")", "\n", "\n", "# print(tr)", "\n", "if", "(", "model", ")", ":", "\n", "        ", "n_params", "=", "_tally_parameters", "(", "model", ")", "\n", "logger", ".", "info", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "\n", "", "return", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderLayer.__init__": [[27, 44], ["torch.Module.__init__", "models.neural.MultiHeadedAttention", "models.neural.MultiHeadedAttention", "models.neural.PositionwiseFeedForward", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "decoder.TransformerDecoderLayer._get_attn_subsequent_mask", "decoder.TransformerDecoderLayer.register_buffer"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderLayer._get_attn_subsequent_mask"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "\n", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "context_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "layer_norm_2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "mask", "=", "self", ".", "_get_attn_subsequent_mask", "(", "MAX_SIZE", ")", "\n", "# Register self.mask as a buffer in TransformerDecoderLayer, so", "\n", "# it gets TransformerDecoderLayer's cuda behavior automatically.", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderLayer.forward": [[45, 86], ["torch.gt", "torch.gt", "torch.gt", "torch.gt", "decoder.TransformerDecoderLayer.layer_norm_1", "decoder.TransformerDecoderLayer.self_attn", "decoder.TransformerDecoderLayer.layer_norm_2", "decoder.TransformerDecoderLayer.context_attn", "decoder.TransformerDecoderLayer.feed_forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.TransformerDecoderLayer.drop", "decoder.TransformerDecoderLayer.drop", "tgt_pad_mask.size", "tgt_pad_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "previous_input", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (`FloatTensor`): `[batch_size x 1 x model_dim]`\n            memory_bank (`FloatTensor`): `[batch_size x src_len x model_dim]`\n            src_pad_mask (`LongTensor`): `[batch_size x 1 x src_len]`\n            tgt_pad_mask (`LongTensor`): `[batch_size x 1 x 1]`\n\n        Returns:\n            (`FloatTensor`, `FloatTensor`, `FloatTensor`):\n\n            * output `[batch_size x 1 x model_dim]`\n            * attn `[batch_size x 1 x src_len]`\n            * all_input `[batch_size x current_step x model_dim]`\n\n        \"\"\"", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "\n", "self", ".", "mask", "[", ":", ",", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", ",", "\n", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", "]", ",", "0", ")", "\n", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "all_input", "=", "input_norm", "\n", "if", "previous_input", "is", "not", "None", ":", "\n", "            ", "all_input", "=", "torch", ".", "cat", "(", "(", "previous_input", ",", "input_norm", ")", ",", "dim", "=", "1", ")", "\n", "dec_mask", "=", "None", "\n", "\n", "", "query", "=", "self", ".", "self_attn", "(", "all_input", ",", "all_input", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "\n", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "mid", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "self", ".", "drop", "(", "mid", ")", "+", "query", ")", "\n", "\n", "return", "output", ",", "all_input", "\n", "# return output", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderLayer._get_attn_subsequent_mask": [[88, 104], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "methods", ["None"], ["", "def", "_get_attn_subsequent_mask", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n        Get an attention mask to avoid using the subsequent info.\n\n        Args:\n            size: int\n\n        Returns:\n            (`LongTensor`):\n\n            * subsequent_mask `[1 x size x size]`\n        \"\"\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoder.__init__": [[137, 153], ["torch.Module.__init__", "models.encoder.PositionalEncoding", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "decoder.TransformerDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "TransformerDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'transformer'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "pos_emb", "=", "PositionalEncoding", "(", "dropout", ",", "self", ".", "embeddings", ".", "embedding_dim", ")", "\n", "\n", "\n", "# Build TransformerDecoder.", "\n", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerDecoderLayer", "(", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoder.forward": [[154, 215], ["src_words.size", "tgt_words.size", "decoder.TransformerDecoder.embeddings", "decoder.TransformerDecoder.pos_emb", "tgt_words.data.eq().unsqueeze().expand", "range", "decoder.TransformerDecoder.layer_norm", "decoder.TransformerDecoder.dim", "memory_masks.size", "memory_masks.expand", "src_words.data.eq().unsqueeze().expand", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "state.update_state.update_state.update_state", "tgt_words.data.eq().unsqueeze", "torch.stack.append", "torch.stack.append", "src_words.data.eq().unsqueeze", "tgt_words.data.eq", "src_words.data.eq"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.update_state"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ",", "cache", "=", "None", ",", "memory_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :obj:`onmt.modules.RNNDecoderBase.forward()`\n        \"\"\"", "\n", "\n", "src_words", "=", "state", ".", "src", "\n", "tgt_words", "=", "tgt", "\n", "src_batch", ",", "src_len", "=", "src_words", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", "=", "tgt_words", ".", "size", "(", ")", "\n", "\n", "# Run the forward pass of the TransformerDecoder.", "\n", "# emb = self.embeddings(tgt, step=step)", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "output", "=", "self", ".", "pos_emb", "(", "emb", ",", "step", ")", "\n", "\n", "src_memory_bank", "=", "memory_bank", "\n", "padding_idx", "=", "self", ".", "embeddings", ".", "padding_idx", "\n", "tgt_pad_mask", "=", "tgt_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_len", ")", "\n", "\n", "if", "(", "not", "memory_masks", "is", "None", ")", ":", "\n", "            ", "src_len", "=", "memory_masks", ".", "size", "(", "-", "1", ")", "\n", "src_pad_mask", "=", "memory_masks", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "else", ":", "\n", "            ", "src_pad_mask", "=", "src_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "saved_inputs", "=", "[", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "prev_layer_input", "=", "None", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "                ", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "                    ", "prev_layer_input", "=", "state", ".", "previous_layer_inputs", "[", "i", "]", "\n", "", "", "output", ",", "all_input", "=", "self", ".", "transformer_layers", "[", "i", "]", "(", "\n", "output", ",", "src_memory_bank", ",", "\n", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "previous_input", "=", "prev_layer_input", ",", "\n", "layer_cache", "=", "state", ".", "cache", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "\n", "if", "state", ".", "cache", "is", "not", "None", "else", "None", ",", "\n", "step", "=", "step", ")", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "                ", "saved_inputs", ".", "append", "(", "all_input", ")", "\n", "\n", "", "", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "saved_inputs", "=", "torch", ".", "stack", "(", "saved_inputs", ")", "\n", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "state", "=", "state", ".", "update_state", "(", "tgt", ",", "saved_inputs", ")", "\n", "\n", "", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoder.init_decoder_state": [[216, 223], ["decoder.TransformerDecoderState", "decoder.TransformerDecoderState._init_cache"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState._init_cache"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "\n", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\" Init decoder state \"\"\"", "\n", "state", "=", "TransformerDecoderState", "(", "src", ")", "\n", "if", "with_cache", ":", "\n", "            ", "state", ".", "_init_cache", "(", "memory_bank", ",", "self", ".", "num_layers", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.__init__": [[229, 239], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (FloatTensor): a sequence of source words tensors\n                    with optional feature tensors, of size (len x batch).\n        \"\"\"", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "previous_input", "=", "None", "\n", "self", ".", "previous_layer_inputs", "=", "None", "\n", "self", ".", "cache", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState._all": [[240, 252], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "if", "(", "self", ".", "previous_input", "is", "not", "None", "\n", "and", "self", ".", "previous_layer_inputs", "is", "not", "None", ")", ":", "\n", "            ", "return", "(", "self", ".", "previous_input", ",", "\n", "self", ".", "previous_layer_inputs", ",", "\n", "self", ".", "src", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "self", ".", "src", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.detach": [[253, 259], ["decoder.TransformerDecoderState.src.detach", "decoder.TransformerDecoderState.previous_input.detach", "decoder.TransformerDecoderState.previous_layer_inputs.detach"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.detach", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.detach", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.detach"], ["", "", "def", "detach", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_input", "=", "self", ".", "previous_input", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "previous_layer_inputs", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_layer_inputs", "=", "self", ".", "previous_layer_inputs", ".", "detach", "(", ")", "\n", "", "self", ".", "src", "=", "self", ".", "src", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.update_state": [[260, 265], ["decoder.TransformerDecoderState"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_input", ",", "previous_layer_inputs", ")", ":", "\n", "        ", "state", "=", "TransformerDecoderState", "(", "self", ".", "src", ")", "\n", "state", ".", "previous_input", "=", "new_input", "\n", "state", ".", "previous_layer_inputs", "=", "previous_layer_inputs", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState._init_cache": [[266, 277], ["range"], "methods", ["None"], ["", "def", "_init_cache", "(", "self", ",", "memory_bank", ",", "num_layers", ")", ":", "\n", "        ", "self", ".", "cache", "=", "{", "}", "\n", "\n", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "layer_cache", "=", "{", "\n", "\"memory_keys\"", ":", "None", ",", "\n", "\"memory_values\"", ":", "None", "\n", "}", "\n", "layer_cache", "[", "\"self_keys\"", "]", "=", "None", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "None", "\n", "self", ".", "cache", "[", "\"layer_{}\"", ".", "format", "(", "l", ")", "]", "=", "layer_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.repeat_beam_size_times": [[278, 281], ["decoder.TransformerDecoderState.src.data.repeat"], "methods", ["None"], ["", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "src", "=", "self", ".", "src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoderState.map_batch_fn": [[282, 294], ["fn", "struct.items", "decoder.TransformerDecoderState.map_batch_fn._recursive_map"], "methods", ["None"], ["", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "def", "_recursive_map", "(", "struct", ",", "batch_dim", "=", "0", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "struct", ".", "items", "(", ")", ":", "\n", "                ", "if", "v", "is", "not", "None", ":", "\n", "                    ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                        ", "_recursive_map", "(", "v", ")", "\n", "", "else", ":", "\n", "                        ", "struct", "[", "k", "]", "=", "fn", "(", "v", ",", "batch_dim", ")", "\n", "\n", "", "", "", "", "self", ".", "src", "=", "fn", "(", "self", ".", "src", ",", "0", ")", "\n", "if", "self", ".", "cache", "is", "not", "None", ":", "\n", "            ", "_recursive_map", "(", "self", ".", "cache", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.__init__": [[37, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            report_every(int): Report status every this many sentences\n            start_time(float): manually set report start time. Negative values\n                means that you will need to set it later or use `start()`\n        \"\"\"", "\n", "self", ".", "report_every", "=", "report_every", "\n", "self", ".", "progress_step", "=", "0", "\n", "self", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.start": [[48, 50], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log": [[51, 53], ["others.logging.logger.info"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.report_training": [[54, 82], ["ValueError", "reporter_ext.ReportMgrBase._report_training", "reporter_ext.Statistics", "reporter_ext.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_training", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats"], ["", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(Statistics): old Statistics instance.\n        Returns:\n            report_stats(Statistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "if", "multigpu", ":", "\n", "                ", "report_stats", "=", "Statistics", ".", "all_gather_stats", "(", "report_stats", ")", "\n", "", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "return", "Statistics", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase._report_training": [[83, 86], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_report_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" To be overridden \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.report_step": [[87, 98], ["reporter_ext.ReportMgrBase._report_step"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step"], ["", "def", "report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report stats of a step\n\n        Args:\n            train_stats(Statistics): training stats\n            valid_stats(Statistics): validation stats\n            lr(float): current learning rate\n        \"\"\"", "\n", "self", ".", "_report_step", "(", "\n", "lr", ",", "step", ",", "train_stats", "=", "train_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase._report_step": [[99, 101], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.__init__": [[104, 116], ["reporter_ext.ReportMgrBase.__init__"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["    ", "def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ",", "tensorboard_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A report manager that writes statistics on standard output as well as\n        (optionally) TensorBoard\n\n        Args:\n            report_every(int): Report status every this many sentences\n            tensorboard_writer(:obj:`tensorboard.SummaryWriter`):\n                The TensorBoard Summary writer to use or None\n        \"\"\"", "\n", "super", "(", "ReportMgr", ",", "self", ")", ".", "__init__", "(", "report_every", ",", "start_time", ")", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard": [[117, 121], ["stats.log_tensorboard"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.log_tensorboard"], ["", "def", "maybe_log_tensorboard", "(", "self", ",", "stats", ",", "prefix", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "            ", "stats", ".", "log_tensorboard", "(", "\n", "prefix", ",", "self", ".", "tensorboard_writer", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_training": [[122, 138], ["reporter_ext.Statistics.output", "reporter_ext.ReportMgr.maybe_log_tensorboard", "reporter_ext.Statistics"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.output", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard"], ["", "", "def", "_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_training`.\n        \"\"\"", "\n", "report_stats", ".", "output", "(", "step", ",", "num_steps", ",", "\n", "learning_rate", ",", "self", ".", "start_time", ")", "\n", "\n", "# Log the progress using the number of batches on the x-axis.", "\n", "self", ".", "maybe_log_tensorboard", "(", "report_stats", ",", "\n", "\"progress\"", ",", "\n", "learning_rate", ",", "\n", "self", ".", "progress_step", ")", "\n", "report_stats", "=", "Statistics", "(", ")", "\n", "\n", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr._report_step": [[139, 158], ["reporter_ext.ReportMgr.log", "reporter_ext.ReportMgr.maybe_log_tensorboard", "reporter_ext.ReportMgr.log", "reporter_ext.ReportMgr.maybe_log_tensorboard", "train_stats.xent", "valid_stats.xent"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgrBase.log", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent"], ["", "def", "_report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_step`.\n        \"\"\"", "\n", "if", "train_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Train xent: %g'", "%", "train_stats", ".", "xent", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "train_stats", ",", "\n", "\"train\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n", "", "if", "valid_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Validation xent: %g at step %d'", "%", "(", "valid_stats", ".", "xent", "(", ")", ",", "step", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "valid_stats", ",", "\n", "\"valid\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.__init__": [[170, 174], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_docs", "=", "0", ",", "n_correct", "=", "0", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_docs", "=", "n_docs", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats": [[175, 190], ["reporter_ext.Statistics.all_gather_stats_list"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats_list"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats", "(", "stat", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` object accross multiple process/nodes\n\n        Args:\n            stat(:obj:Statistics): the statistics object to gather\n                accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            `Statistics`, the update stats object\n        \"\"\"", "\n", "stats", "=", "Statistics", ".", "all_gather_stats_list", "(", "[", "stat", "]", ",", "max_size", "=", "max_size", ")", "\n", "return", "stats", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.all_gather_stats_list": [[191, 218], ["all_gather_list", "get_rank", "enumerate", "enumerate", "our_stats[].update"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.src.distributed.all_gather_list", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats_list", "(", "stat_list", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` list accross all processes/nodes\n\n        Args:\n            stat_list(list([`Statistics`])): list of statistics objects to\n                gather accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            our_stats(list([`Statistics`])): list of updated stats\n        \"\"\"", "\n", "from", "torch", ".", "distributed", "import", "get_rank", "\n", "from", "distributed", "import", "all_gather_list", "\n", "\n", "# Get a list of world_size lists with len(stat_list) Statistics objects", "\n", "all_stats", "=", "all_gather_list", "(", "stat_list", ",", "max_size", "=", "max_size", ")", "\n", "\n", "our_rank", "=", "get_rank", "(", ")", "\n", "our_stats", "=", "all_stats", "[", "our_rank", "]", "\n", "for", "other_rank", ",", "stats", "in", "enumerate", "(", "all_stats", ")", ":", "\n", "            ", "if", "other_rank", "==", "our_rank", ":", "\n", "                ", "continue", "\n", "", "for", "i", ",", "stat", "in", "enumerate", "(", "stats", ")", ":", "\n", "                ", "our_stats", "[", "i", "]", ".", "update", "(", "stat", ",", "update_n_src_words", "=", "True", ")", "\n", "", "", "return", "our_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update": [[219, 232], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "stat", ",", "update_n_src_words", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update statistics by suming values with another `Statistics` object\n\n        Args:\n            stat: another statistic object\n            update_n_src_words(bool): whether to update (sum) `n_src_words`\n                or not\n\n        \"\"\"", "\n", "self", ".", "loss", "+=", "stat", ".", "loss", "\n", "\n", "self", ".", "n_docs", "+=", "stat", ".", "n_docs", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent": [[233, 238], ["None"], "methods", ["None"], ["", "def", "xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n", "if", "(", "self", ".", "n_docs", "==", "0", ")", ":", "\n", "            ", "return", "0", "\n", "", "return", "self", ".", "loss", "/", "self", ".", "n_docs", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.elapsed_time": [[239, 242], ["time.time"], "methods", ["None"], ["", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute elapsed time \"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.output": [[243, 264], ["reporter_ext.Statistics.elapsed_time", "others.logging.logger.info", "sys.stdout.flush", "reporter_ext.Statistics.xent", "time.time"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.elapsed_time", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent"], ["", "def", "output", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           step (int): current step\n           n_batch (int): total batches\n           start (int): start time of step.\n        \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "step_fmt", "=", "\"%2d\"", "%", "step", "\n", "if", "num_steps", ">", "0", ":", "\n", "            ", "step_fmt", "=", "\"%s/%5d\"", "%", "(", "step_fmt", ",", "num_steps", ")", "\n", "", "logger", ".", "info", "(", "\n", "(", "\"Step %s; xent: %4.2f; \"", "+", "\n", "\"lr: %7.7f; %3.0f docs/s; %6.0f sec\"", ")", "\n", "%", "(", "step_fmt", ",", "\n", "self", ".", "xent", "(", ")", ",", "\n", "learning_rate", ",", "\n", "self", ".", "n_docs", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.log_tensorboard": [[265, 270], ["reporter_ext.Statistics.elapsed_time", "writer.add_scalar", "writer.add_scalar", "reporter_ext.Statistics.xent"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.elapsed_time", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.xent"], ["", "def", "log_tensorboard", "(", "self", ",", "prefix", ",", "writer", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "\"\"\" display statistics to tensorboard \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/xent\"", ",", "self", ".", "xent", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/lr\"", ",", "learning_rate", ",", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.build_report_manager": [[11, 27], ["reporter_ext.ReportMgr", "SummaryWriter", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "build_report_manager", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "tensorboard_log_dir", "=", "opt", ".", "tensorboard_log_dir", "\n", "\n", "if", "not", "opt", ".", "train_from", ":", "\n", "            ", "tensorboard_log_dir", "+=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"/%b-%d_%H-%M-%S\"", ")", "\n", "\n", "", "writer", "=", "SummaryWriter", "(", "tensorboard_log_dir", ",", "\n", "comment", "=", "\"Unmt\"", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "report_mgr", "=", "ReportMgr", "(", "opt", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "\n", "tensorboard_writer", "=", "writer", ")", "\n", "return", "report_mgr", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase.__init__": [[44, 48], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "pad_id", ")", ":", "\n", "        ", "super", "(", "LossComputeBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "padding_idx", "=", "pad_id", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._make_shard_state": [[51, 64], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "attns", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Make shard state dictionary for shards() to return iterable\n        shards for efficient loss computation. Subclass must define\n        this method to match its own _compute_loss() interface.\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            range_: the range of examples for computing, the whole\n                    batch or a trunc of it?\n            attns: the attns dictionary returned from the model.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._compute_loss": [[65, 77], ["None"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n\n        Args:\n\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            **kwargs(optional): additional info for computing loss.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase.monolithic_compute_loss": [[78, 96], ["loss.LossComputeBase._make_shard_state", "loss.LossComputeBase._compute_loss"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute._make_shard_state", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute._compute_loss"], ["", "def", "monolithic_compute_loss", "(", "self", ",", "batch", ",", "output", ")", ":", "\n", "        ", "\"\"\"\n        Compute the forward loss for the batch.\n\n        Args:\n          batch (batch): batch of labeled examples\n          output (:obj:`FloatTensor`):\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict of :obj:`FloatTensor`) :\n              dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n        Returns:\n            :obj:`onmt.utils.Statistics`: loss statistics\n        \"\"\"", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ")", "\n", "_", ",", "batch_stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "\n", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase.sharded_compute_loss": [[97, 135], ["models.reporter.Statistics", "loss.LossComputeBase._make_shard_state", "loss.shards", "loss.LossComputeBase._compute_loss", "loss.div().backward", "models.reporter.Statistics.update", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute._make_shard_state", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.shards", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute._compute_loss", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update"], ["", "def", "sharded_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "\n", "shard_size", ",", "\n", "normalization", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss and backpropagate.  Computation is done\n        with shards and optionally truncation for memory efficiency.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(cur_trunc, cur_trunc + trunc_size)`.\n\n        Note sharding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          cur_trunc (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n          shard_size (int) : maximum number of examples in a shard\n          normalization (int) : Loss is divided by this number\n\n        Returns:\n            :obj:`onmt.utils.Statistics`: validation loss statistics\n\n        \"\"\"", "\n", "batch_stats", "=", "Statistics", "(", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "loss", ".", "div", "(", "float", "(", "normalization", ")", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "\n", "", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._stats": [[136, 154], ["target.ne", "pred.eq().masked_select().sum().item", "target.ne.sum().item", "models.reporter.Statistics", "scores.max", "loss.item", "pred.eq().masked_select().sum", "target.ne.sum", "pred.eq().masked_select", "pred.eq"], "methods", ["None"], ["", "def", "_stats", "(", "self", ",", "loss", ",", "scores", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss (:obj:`FloatTensor`): the loss computed by the loss criterion.\n            scores (:obj:`FloatTensor`): a score for each possible output\n            target (:obj:`FloatTensor`): true targets\n\n        Returns:\n            :obj:`onmt.utils.Statistics` : statistics for this batch.\n        \"\"\"", "\n", "pred", "=", "scores", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "non_padding", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "num_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "non_padding", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_non_padding", "=", "non_padding", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "Statistics", "(", "loss", ".", "item", "(", ")", ",", "num_non_padding", ",", "num_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._bottle": [[155, 157], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_bottle", "(", "self", ",", "_v", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "_v", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._unbottle": [[158, 160], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_unbottle", "(", "self", ",", "_v", ",", "batch_size", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "batch_size", ",", "_v", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LabelSmoothingLoss.__init__": [[168, 178], ["torch.Module.__init__", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "loss.LabelSmoothingLoss.register_buffer", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "label_smoothing", ",", "tgt_vocab_size", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "        ", "assert", "0.0", "<", "label_smoothing", "<=", "1.0", "\n", "self", ".", "padding_idx", "=", "ignore_index", "\n", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "smoothing_value", "=", "label_smoothing", "/", "(", "tgt_vocab_size", "-", "2", ")", "\n", "one_hot", "=", "torch", ".", "full", "(", "(", "tgt_vocab_size", ",", ")", ",", "smoothing_value", ")", "\n", "one_hot", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "self", ".", "register_buffer", "(", "'one_hot'", ",", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "self", ".", "confidence", "=", "1.0", "-", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LabelSmoothingLoss.forward": [[179, 189], ["loss.LabelSmoothingLoss.one_hot.repeat", "loss.LabelSmoothingLoss.scatter_", "loss.LabelSmoothingLoss.masked_fill_", "torch.kl_div", "torch.kl_div", "torch.kl_div", "target.size", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        output (FloatTensor): batch_size x n_classes\n        target (LongTensor): batch_size\n        \"\"\"", "\n", "model_prob", "=", "self", ".", "one_hot", ".", "repeat", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "model_prob", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "model_prob", ".", "masked_fill_", "(", "(", "target", "==", "self", ".", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ",", "0", ")", "\n", "\n", "return", "F", ".", "kl_div", "(", "output", ",", "model_prob", ",", "reduction", "=", "'sum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute.__init__": [[196, 207], ["loss.LossComputeBase.__init__", "isinstance", "loss.LabelSmoothingLoss", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "symbols", ",", "vocab_size", ",", "\n", "label_smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "NMTLossCompute", ",", "self", ")", ".", "__init__", "(", "generator", ",", "symbols", "[", "'PAD'", "]", ")", "\n", "self", ".", "sparse", "=", "not", "isinstance", "(", "generator", "[", "1", "]", ",", "nn", ".", "LogSoftmax", ")", "\n", "if", "label_smoothing", ">", "0", ":", "\n", "            ", "self", ".", "criterion", "=", "LabelSmoothingLoss", "(", "\n", "label_smoothing", ",", "vocab_size", ",", "ignore_index", "=", "self", ".", "padding_idx", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "criterion", "=", "nn", ".", "NLLLoss", "(", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "reduction", "=", "'sum'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute._make_shard_state": [[209, 213], ["None"], "methods", ["None"], ["", "", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ")", ":", "\n", "        ", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", ":", ",", "1", ":", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.NMTLossCompute._compute_loss": [[215, 225], ["loss.NMTLossCompute.NMTLossCompute._bottle", "loss.NMTLossCompute.NMTLossCompute.generator", "target.contiguous().view", "loss.NMTLossCompute.NMTLossCompute.criterion", "loss.NMTLossCompute.NMTLossCompute._stats", "loss.NMTLossCompute.NMTLossCompute.clone", "target.contiguous"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.LossComputeBase._stats"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ")", ":", "\n", "        ", "bottled_output", "=", "self", ".", "_bottle", "(", "output", ")", "\n", "scores", "=", "self", ".", "generator", "(", "bottled_output", ")", "\n", "gtruth", "=", "target", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "gtruth", ")", "\n", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "clone", "(", ")", ",", "scores", ",", "gtruth", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.abs_loss": [[15, 21], ["loss.NMTLossCompute", "NMTLossCompute.to"], "function", ["None"], ["def", "abs_loss", "(", "generator", ",", "symbols", ",", "vocab_size", ",", "device", ",", "train", "=", "True", ",", "label_smoothing", "=", "0.0", ")", ":", "\n", "    ", "compute", "=", "NMTLossCompute", "(", "\n", "generator", ",", "symbols", ",", "vocab_size", ",", "\n", "label_smoothing", "=", "label_smoothing", "if", "train", "else", "0.0", ")", "\n", "compute", ".", "to", "(", "device", ")", "\n", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.filter_shard_state": [[227, 241], ["state.items", "isinstance", "torch.split", "torch.split", "torch.split", "v_chunk.data.clone.data.clone", "v_split.append"], "function", ["None"], ["", "", "def", "filter_shard_state", "(", "state", ",", "shard_size", "=", "None", ")", ":", "\n", "    ", "\"\"\" ? \"\"\"", "\n", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "        ", "if", "shard_size", "is", "None", ":", "\n", "            ", "yield", "k", ",", "v", "\n", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v_split", "=", "[", "]", "\n", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "for", "v_chunk", "in", "torch", ".", "split", "(", "v", ",", "shard_size", ")", ":", "\n", "                    ", "v_chunk", "=", "v_chunk", ".", "data", ".", "clone", "(", ")", "\n", "v_chunk", ".", "requires_grad", "=", "v", ".", "requires_grad", "\n", "v_split", ".", "append", "(", "v_chunk", ")", "\n", "", "", "yield", "k", ",", "(", "v", ",", "v_split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.shards": [[243, 291], ["dict", "zip", "zip", "dict.items", "zip", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "loss.filter_shard_state", "loss.filter_shard_state", "dict", "isinstance", "variables.extend", "zip", "zip", "dict.items", "torch.split", "torch.split", "torch.split"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.filter_shard_state", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.loss.filter_shard_state"], ["", "", "", "def", "shards", "(", "state", ",", "shard_size", ",", "eval_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        state: A dictionary which corresponds to the output of\n               *LossCompute._make_shard_state(). The values for\n               those keys are Tensor-like or None.\n        shard_size: The maximum size of the shards yielded by the model.\n        eval_only: If True, only yield the state, nothing else.\n              Otherwise, yield shards.\n\n    Yields:\n        Each yielded shard is a dict.\n\n    Side effect:\n        After the last shard, this function does back-propagation.\n    \"\"\"", "\n", "if", "eval_only", ":", "\n", "        ", "yield", "filter_shard_state", "(", "state", ")", "\n", "", "else", ":", "\n", "# non_none: the subdict of the state dictionary where the values", "\n", "# are not None.", "\n", "        ", "non_none", "=", "dict", "(", "filter_shard_state", "(", "state", ",", "shard_size", ")", ")", "\n", "\n", "# Now, the iteration:", "\n", "# state is a dictionary of sequences of tensor-like but we", "\n", "# want a sequence of dictionaries of tensors.", "\n", "# First, unzip the dictionary into a sequence of keys and a", "\n", "# sequence of tensor-like sequences.", "\n", "keys", ",", "values", "=", "zip", "(", "*", "(", "(", "k", ",", "[", "v_chunk", "for", "v_chunk", "in", "v_split", "]", ")", "\n", "for", "k", ",", "(", "_", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ")", ")", "\n", "\n", "# Now, yield a dictionary for each shard. The keys are always", "\n", "# the same. values is a sequence of length #keys where each", "\n", "# element is a sequence of length #shards. We want to iterate", "\n", "# over the shards, not over the keys: therefore, the values need", "\n", "# to be re-zipped by shard and then each shard can be paired", "\n", "# with the keys.", "\n", "for", "shard_tensors", "in", "zip", "(", "*", "values", ")", ":", "\n", "            ", "yield", "dict", "(", "zip", "(", "keys", ",", "shard_tensors", ")", ")", "\n", "\n", "# Assumed backprop'd", "\n", "", "variables", "=", "[", "]", "\n", "for", "k", ",", "(", "v", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "and", "state", "[", "k", "]", ".", "requires_grad", ":", "\n", "                ", "variables", ".", "extend", "(", "zip", "(", "torch", ".", "split", "(", "state", "[", "k", "]", ",", "shard_size", ")", ",", "\n", "[", "v_chunk", ".", "grad", "for", "v_chunk", "in", "v_split", "]", ")", ")", "\n", "", "", "inputs", ",", "grads", "=", "zip", "(", "*", "variables", ")", "\n", "torch", ".", "autograd", ".", "backward", "(", "inputs", ",", "grads", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.Bert.__init__": [[116, 124], ["torch.Module.__init__", "pytorch_transformers.BertModel.from_pretrained", "pytorch_transformers.BertModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "large", ",", "temp_dir", ",", "finetune", "=", "False", ")", ":", "\n", "        ", "super", "(", "Bert", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "(", "large", ")", ":", "\n", "            ", "self", ".", "model", "=", "BertModel", ".", "from_pretrained", "(", "'bert-large-uncased'", ",", "cache_dir", "=", "temp_dir", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "cache_dir", "=", "temp_dir", ")", "\n", "\n", "", "self", ".", "finetune", "=", "finetune", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.Bert.forward": [[125, 133], ["model_builder.Bert.model", "model_builder.Bert.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_builder.Bert.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "segs", ",", "mask", ")", ":", "\n", "        ", "if", "(", "self", ".", "finetune", ")", ":", "\n", "            ", "top_vec", ",", "_", "=", "self", ".", "model", "(", "x", ",", "segs", ",", "attention_mask", "=", "mask", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "top_vec", ",", "_", "=", "self", ".", "model", "(", "x", ",", "segs", ",", "attention_mask", "=", "mask", ")", "\n", "", "", "return", "top_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.ExtSummarizer.__init__": [[136, 169], ["torch.Module.__init__", "model_builder.Bert", "models.encoder.ExtTransformerEncoder", "model_builder.ExtSummarizer.to", "pytorch_transformers.BertConfig", "pytorch_transformers.BertModel", "models.encoder.Classifier", "torch.Embedding", "torch.Embedding", "[].repeat", "model_builder.ExtSummarizer.load_state_dict", "model_builder.ExtSummarizer.ext_layer.parameters", "model_builder.ExtSummarizer.ext_layer.parameters", "p.data.uniform_", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "device", ",", "checkpoint", ")", ":", "\n", "        ", "super", "(", "ExtSummarizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "bert", "=", "Bert", "(", "args", ".", "large", ",", "args", ".", "temp_dir", ",", "args", ".", "finetune_bert", ")", "\n", "\n", "self", ".", "ext_layer", "=", "ExtTransformerEncoder", "(", "self", ".", "bert", ".", "model", ".", "config", ".", "hidden_size", ",", "args", ".", "ext_ff_size", ",", "args", ".", "ext_heads", ",", "\n", "args", ".", "ext_dropout", ",", "args", ".", "ext_layers", ")", "\n", "if", "(", "args", ".", "encoder", "==", "'baseline'", ")", ":", "\n", "            ", "bert_config", "=", "BertConfig", "(", "self", ".", "bert", ".", "model", ".", "config", ".", "vocab_size", ",", "hidden_size", "=", "args", ".", "ext_hidden_size", ",", "\n", "num_hidden_layers", "=", "args", ".", "ext_layers", ",", "num_attention_heads", "=", "args", ".", "ext_heads", ",", "intermediate_size", "=", "args", ".", "ext_ff_size", ")", "\n", "self", ".", "bert", ".", "model", "=", "BertModel", "(", "bert_config", ")", "\n", "self", ".", "ext_layer", "=", "Classifier", "(", "self", ".", "bert", ".", "model", ".", "config", ".", "hidden_size", ")", "\n", "\n", "", "if", "(", "args", ".", "max_pos", ">", "512", ")", ":", "\n", "            ", "my_pos_embeddings", "=", "nn", ".", "Embedding", "(", "args", ".", "max_pos", ",", "self", ".", "bert", ".", "model", ".", "config", ".", "hidden_size", ")", "\n", "my_pos_embeddings", ".", "weight", ".", "data", "[", ":", "512", "]", "=", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "data", "\n", "my_pos_embeddings", ".", "weight", ".", "data", "[", "512", ":", "]", "=", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "data", "[", "-", "1", "]", "[", "None", ",", ":", "]", ".", "repeat", "(", "args", ".", "max_pos", "-", "512", ",", "1", ")", "\n", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "position_embeddings", "=", "my_pos_embeddings", "\n", "\n", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "param_init", "!=", "0.0", ":", "\n", "                ", "for", "p", "in", "self", ".", "ext_layer", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "data", ".", "uniform_", "(", "-", "args", ".", "param_init", ",", "args", ".", "param_init", ")", "\n", "", "", "if", "args", ".", "param_init_glorot", ":", "\n", "                ", "for", "p", "in", "self", ".", "ext_layer", ".", "parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                        ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "", "self", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.ExtSummarizer.forward": [[170, 176], ["model_builder.ExtSummarizer.bert", "model_builder.ExtSummarizer.ext_layer().squeeze", "mask_cls[].float", "model_builder.ExtSummarizer.ext_layer", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "model_builder.ExtSummarizer.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "segs", ",", "clss", ",", "mask_src", ",", "mask_cls", ")", ":", "\n", "        ", "top_vec", "=", "self", ".", "bert", "(", "src", ",", "segs", ",", "mask_src", ")", "\n", "sents_vec", "=", "top_vec", "[", "torch", ".", "arange", "(", "top_vec", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "1", ")", ",", "clss", "]", "\n", "sents_vec", "=", "sents_vec", "*", "mask_cls", "[", ":", ",", ":", ",", "None", "]", ".", "float", "(", ")", "\n", "sent_scores", "=", "self", ".", "ext_layer", "(", "sents_vec", ",", "mask_cls", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "return", "sent_scores", ",", "mask_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.AbsSummarizer.__init__": [[179, 239], ["torch.Module.__init__", "model_builder.Bert", "torch.Embedding", "torch.Embedding", "models.decoder.TransformerDecoder", "model_builder.get_generator", "model_builder.AbsSummarizer.to", "model_builder.AbsSummarizer.bert.model.load_state_dict", "pytorch_transformers.BertConfig", "pytorch_transformers.BertModel", "torch.Embedding", "torch.Embedding", "[].repeat", "copy.deepcopy", "model_builder.AbsSummarizer.load_state_dict", "model_builder.AbsSummarizer.decoder.modules", "model_builder.AbsSummarizer.generator.parameters", "dict", "isinstance", "torch.Embedding", "torch.Embedding", "copy.deepcopy", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "p.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "bert_from_extractive.items", "n.startswith"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.get_generator", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "device", ",", "checkpoint", "=", "None", ",", "bert_from_extractive", "=", "None", ")", ":", "\n", "        ", "super", "(", "AbsSummarizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "bert", "=", "Bert", "(", "args", ".", "large", ",", "args", ".", "temp_dir", ",", "args", ".", "finetune_bert", ")", "\n", "\n", "if", "bert_from_extractive", "is", "not", "None", ":", "\n", "            ", "self", ".", "bert", ".", "model", ".", "load_state_dict", "(", "\n", "dict", "(", "[", "(", "n", "[", "11", ":", "]", ",", "p", ")", "for", "n", ",", "p", "in", "bert_from_extractive", ".", "items", "(", ")", "if", "n", ".", "startswith", "(", "'bert.model'", ")", "]", ")", ",", "strict", "=", "True", ")", "\n", "\n", "", "if", "(", "args", ".", "encoder", "==", "'baseline'", ")", ":", "\n", "            ", "bert_config", "=", "BertConfig", "(", "self", ".", "bert", ".", "model", ".", "config", ".", "vocab_size", ",", "hidden_size", "=", "args", ".", "enc_hidden_size", ",", "\n", "num_hidden_layers", "=", "args", ".", "enc_layers", ",", "num_attention_heads", "=", "8", ",", "\n", "intermediate_size", "=", "args", ".", "enc_ff_size", ",", "\n", "hidden_dropout_prob", "=", "args", ".", "enc_dropout", ",", "\n", "attention_probs_dropout_prob", "=", "args", ".", "enc_dropout", ")", "\n", "self", ".", "bert", ".", "model", "=", "BertModel", "(", "bert_config", ")", "\n", "\n", "", "if", "(", "args", ".", "max_pos", ">", "512", ")", ":", "\n", "            ", "my_pos_embeddings", "=", "nn", ".", "Embedding", "(", "args", ".", "max_pos", ",", "self", ".", "bert", ".", "model", ".", "config", ".", "hidden_size", ")", "\n", "my_pos_embeddings", ".", "weight", ".", "data", "[", ":", "512", "]", "=", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "data", "\n", "my_pos_embeddings", ".", "weight", ".", "data", "[", "512", ":", "]", "=", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "data", "[", "-", "1", "]", "[", "None", ",", ":", "]", ".", "repeat", "(", "args", ".", "max_pos", "-", "512", ",", "1", ")", "\n", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "position_embeddings", "=", "my_pos_embeddings", "\n", "", "self", ".", "vocab_size", "=", "self", ".", "bert", ".", "model", ".", "config", ".", "vocab_size", "\n", "tgt_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", ",", "self", ".", "bert", ".", "model", ".", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "if", "(", "self", ".", "args", ".", "share_emb", ")", ":", "\n", "            ", "tgt_embeddings", ".", "weight", "=", "copy", ".", "deepcopy", "(", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "\n", "", "self", ".", "decoder", "=", "TransformerDecoder", "(", "\n", "self", ".", "args", ".", "dec_layers", ",", "\n", "self", ".", "args", ".", "dec_hidden_size", ",", "heads", "=", "self", ".", "args", ".", "dec_heads", ",", "\n", "d_ff", "=", "self", ".", "args", ".", "dec_ff_size", ",", "dropout", "=", "self", ".", "args", ".", "dec_dropout", ",", "embeddings", "=", "tgt_embeddings", ")", "\n", "\n", "self", ".", "generator", "=", "get_generator", "(", "self", ".", "vocab_size", ",", "self", ".", "args", ".", "dec_hidden_size", ",", "device", ")", "\n", "self", ".", "generator", "[", "0", "]", ".", "weight", "=", "self", ".", "decoder", ".", "embeddings", ".", "weight", "\n", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "for", "module", "in", "self", ".", "decoder", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                    ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "                    ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "for", "p", "in", "self", ".", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "if", "(", "args", ".", "use_bert_emb", ")", ":", "\n", "                ", "tgt_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", ",", "self", ".", "bert", ".", "model", ".", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "tgt_embeddings", ".", "weight", "=", "copy", ".", "deepcopy", "(", "self", ".", "bert", ".", "model", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "decoder", ".", "embeddings", "=", "tgt_embeddings", "\n", "self", ".", "generator", "[", "0", "]", ".", "weight", "=", "self", ".", "decoder", ".", "embeddings", ".", "weight", "\n", "\n", "", "", "self", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.AbsSummarizer.forward": [[240, 245], ["model_builder.AbsSummarizer.bert", "model_builder.AbsSummarizer.decoder.init_decoder_state", "model_builder.AbsSummarizer.decoder"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.decoder.TransformerDecoder.init_decoder_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "segs", ",", "clss", ",", "mask_src", ",", "mask_tgt", ",", "mask_cls", ")", ":", "\n", "        ", "top_vec", "=", "self", ".", "bert", "(", "src", ",", "segs", ",", "mask_src", ")", "\n", "dec_state", "=", "self", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "top_vec", ")", "\n", "decoder_outputs", ",", "state", "=", "self", ".", "decoder", "(", "tgt", "[", ":", ",", ":", "-", "1", "]", ",", "top_vec", ",", "dec_state", ")", "\n", "return", "decoder_outputs", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.build_optim": [[12, 41], ["models.optimizers.Optimizer.set_parameters", "models.optimizers.Optimizer.optimizer.state_dict", "models.optimizers.Optimizer.optimizer.load_state_dict", "models.optimizers.Optimizer", "list", "models.optimizers.Optimizer.optimizer.state.values", "RuntimeError", "model.named_parameters", "state.items", "len", "torch.is_tensor", "torch.is_tensor", "v.cuda"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.set_parameters", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict"], ["def", "build_optim", "(", "args", ",", "model", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "optim", "=", "checkpoint", "[", "'optim'", "]", "[", "0", "]", "\n", "saved_optimizer_state_dict", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "saved_optimizer_state_dict", ")", "\n", "if", "args", ".", "visible_gpus", "!=", "'-1'", ":", "\n", "            ", "for", "state", "in", "optim", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "", "if", "(", "optim", ".", "method", "==", "'adam'", ")", "and", "(", "len", "(", "optim", ".", "optimizer", ".", "state", ")", "<", "1", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error: loaded Adam optimizer from existing model\"", "+", "\n", "\" but optimizer state is empty\"", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "optim", "=", "Optimizer", "(", "\n", "args", ".", "optim", ",", "args", ".", "lr", ",", "args", ".", "max_grad_norm", ",", "\n", "beta1", "=", "args", ".", "beta1", ",", "beta2", "=", "args", ".", "beta2", ",", "\n", "decay_method", "=", "'noam'", ",", "\n", "warmup_steps", "=", "args", ".", "warmup_steps", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "list", "(", "model", ".", "named_parameters", "(", ")", ")", ")", "\n", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.build_optim_bert": [[42, 72], ["models.optimizers.Optimizer.set_parameters", "models.optimizers.Optimizer.optimizer.state_dict", "models.optimizers.Optimizer.optimizer.load_state_dict", "models.optimizers.Optimizer", "models.optimizers.Optimizer.optimizer.state.values", "RuntimeError", "list", "n.startswith", "state.items", "len", "model.named_parameters", "torch.is_tensor", "torch.is_tensor", "v.cuda"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.set_parameters", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict"], ["", "def", "build_optim_bert", "(", "args", ",", "model", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "optim", "=", "checkpoint", "[", "'optims'", "]", "[", "0", "]", "\n", "saved_optimizer_state_dict", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "saved_optimizer_state_dict", ")", "\n", "if", "args", ".", "visible_gpus", "!=", "'-1'", ":", "\n", "            ", "for", "state", "in", "optim", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "", "if", "(", "optim", ".", "method", "==", "'adam'", ")", "and", "(", "len", "(", "optim", ".", "optimizer", ".", "state", ")", "<", "1", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error: loaded Adam optimizer from existing model\"", "+", "\n", "\" but optimizer state is empty\"", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "optim", "=", "Optimizer", "(", "\n", "args", ".", "optim", ",", "args", ".", "lr_bert", ",", "args", ".", "max_grad_norm", ",", "\n", "beta1", "=", "args", ".", "beta1", ",", "beta2", "=", "args", ".", "beta2", ",", "\n", "decay_method", "=", "'noam'", ",", "\n", "warmup_steps", "=", "args", ".", "warmup_steps_bert", ")", "\n", "\n", "", "params", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "if", "n", ".", "startswith", "(", "'bert.model'", ")", "]", "\n", "optim", ".", "set_parameters", "(", "params", ")", "\n", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.build_optim_dec": [[73, 103], ["models.optimizers.Optimizer.set_parameters", "models.optimizers.Optimizer.optimizer.state_dict", "models.optimizers.Optimizer.optimizer.load_state_dict", "models.optimizers.Optimizer", "models.optimizers.Optimizer.optimizer.state.values", "RuntimeError", "list", "state.items", "len", "model.named_parameters", "n.startswith", "torch.is_tensor", "torch.is_tensor", "v.cuda"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.set_parameters", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict"], ["", "def", "build_optim_dec", "(", "args", ",", "model", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "optim", "=", "checkpoint", "[", "'optims'", "]", "[", "1", "]", "\n", "saved_optimizer_state_dict", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "saved_optimizer_state_dict", ")", "\n", "if", "args", ".", "visible_gpus", "!=", "'-1'", ":", "\n", "            ", "for", "state", "in", "optim", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "", "if", "(", "optim", ".", "method", "==", "'adam'", ")", "and", "(", "len", "(", "optim", ".", "optimizer", ".", "state", ")", "<", "1", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error: loaded Adam optimizer from existing model\"", "+", "\n", "\" but optimizer state is empty\"", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "optim", "=", "Optimizer", "(", "\n", "args", ".", "optim", ",", "args", ".", "lr_dec", ",", "args", ".", "max_grad_norm", ",", "\n", "beta1", "=", "args", ".", "beta1", ",", "beta2", "=", "args", ".", "beta2", ",", "\n", "decay_method", "=", "'noam'", ",", "\n", "warmup_steps", "=", "args", ".", "warmup_steps_dec", ")", "\n", "\n", "", "params", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "if", "not", "n", ".", "startswith", "(", "'bert.model'", ")", "]", "\n", "optim", ".", "set_parameters", "(", "params", ")", "\n", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.model_builder.get_generator": [[105, 114], ["torch.LogSoftmax", "torch.Sequential", "nn.Sequential.to", "torch.Linear"], "function", ["None"], ["", "def", "get_generator", "(", "vocab_size", ",", "dec_hidden_size", ",", "device", ")", ":", "\n", "    ", "gen_func", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dec_hidden_size", ",", "vocab_size", ")", ",", "\n", "gen_func", "\n", ")", "\n", "generator", ".", "to", "(", "device", ")", "\n", "\n", "return", "generator", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.adam.Adam.__init__": [[30, 43], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ")", "\n", "super", "(", "Adam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.adam.Adam.__setstate__": [[44, 48], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.adam.Adam.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "Adam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'amsgrad'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.adam.Adam.step": [[49, 110], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "next_m.mul_", "next_v.mul_", "next_v.sqrt"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'eps'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.__init__": [[63, 66], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "optimizers", "=", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.zero_grad": [[67, 71], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.step": [[72, 76], ["op.step"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state": [[77, 81], ["op.state.items"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "{", "k", ":", "v", "for", "op", "in", "self", ".", "optimizers", "for", "k", ",", "v", "in", "op", ".", "state", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict": [[82, 85], ["op.state_dict"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "[", "op", ".", "state_dict", "(", ")", "for", "op", "in", "self", ".", "optimizers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict": [[86, 91], ["range", "len", "len", "len", "optimizers.MultipleOptimizer.optimizers[].load_state_dict"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dicts", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "assert", "len", "(", "state_dicts", ")", "==", "len", "(", "self", ".", "optimizers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "state_dicts", ")", ")", ":", "\n", "            ", "self", ".", "optimizers", "[", "i", "]", ".", "load_state_dict", "(", "state_dicts", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.__init__": [[124, 145], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "method", ",", "learning_rate", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_steps", "=", "None", ",", "decay_steps", "=", "None", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "adagrad_accum", "=", "0.0", ",", "\n", "decay_method", "=", "None", ",", "\n", "warmup_steps", "=", "4000", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "original_lr", "=", "learning_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_steps", "=", "start_decay_steps", "\n", "self", ".", "decay_steps", "=", "decay_steps", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "betas", "=", "[", "beta1", ",", "beta2", "]", "\n", "self", ".", "adagrad_accum", "=", "adagrad_accum", "\n", "self", ".", "decay_method", "=", "decay_method", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.set_parameters": [[146, 171], ["torch.SGD", "torch.SGD", "torch.Adagrad", "torch.Adagrad", "optimizers.Optimizer.params.append", "optimizers.Optimizer.sparse_params.append", "torch.Adadelta", "torch.Adadelta", "[].fill_", "torch.Adam", "torch.Adam", "RuntimeError"], "methods", ["None"], ["", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "params", "=", "[", "]", "\n", "self", ".", "sparse_params", "=", "[", "]", "\n", "for", "k", ",", "p", "in", "params", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "if", "self", ".", "method", "!=", "'sparseadam'", "or", "\"embed\"", "not", "in", "k", ":", "\n", "                    ", "self", ".", "params", ".", "append", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "sparse_params", ".", "append", "(", "p", ")", "\n", "", "", "", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", "=", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", ".", "fill_", "(", "self", ".", "adagrad_accum", ")", "\n", "", "", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-9", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer._set_rate": [[172, 179], ["None"], "methods", ["None"], ["", "", "def", "_set_rate", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "self", ".", "learning_rate", "=", "learning_rate", "\n", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "", "else", ":", "\n", "            ", "for", "op", "in", "self", ".", "optimizer", ".", "optimizers", ":", "\n", "                ", "op", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step": [[180, 210], ["optimizers.Optimizer.optimizer.step", "optimizers.Optimizer._set_rate", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "min"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer._set_rate"], ["", "", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "self", ".", "_step", "+=", "1", "\n", "\n", "# Decay method used in tensor2tensor.", "\n", "if", "self", ".", "decay_method", "==", "\"noam\"", ":", "\n", "            ", "self", ".", "_set_rate", "(", "\n", "self", ".", "original_lr", "*", "\n", "min", "(", "self", ".", "_step", "**", "(", "-", "0.5", ")", ",", "\n", "self", ".", "_step", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "(", "(", "self", ".", "start_decay_steps", "is", "not", "None", ")", "and", "(", "\n", "self", ".", "_step", ">=", "self", ".", "start_decay_steps", ")", ")", ":", "\n", "                ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "self", ".", "start_decay", ":", "\n", "                ", "if", "(", "(", "self", ".", "_step", "-", "self", ".", "start_decay_steps", ")", "\n", "%", "self", ".", "decay_steps", "==", "0", ")", ":", "\n", "                    ", "self", ".", "learning_rate", "=", "self", ".", "learning_rate", "*", "self", ".", "lr_decay", "\n", "\n", "", "", "", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n", "", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.use_gpu": [[11, 17], ["hasattr", "hasattr", "len"], "function", ["None"], ["def", "use_gpu", "(", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean if gpu used\n    \"\"\"", "\n", "return", "(", "hasattr", "(", "opt", ",", "'gpu_ranks'", ")", "and", "len", "(", "opt", ".", "gpu_ranks", ")", ">", "0", ")", "or", "(", "hasattr", "(", "opt", ",", "'gpu'", ")", "and", "opt", ".", "gpu", ">", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.build_optim": [[18, 58], ["optimizers.Optimizer.set_parameters", "Optimizer.optimizer.state_dict", "optimizers.Optimizer", "model.named_parameters", "Optimizer.optimizer.load_state_dict", "optimizers.use_gpu", "Optimizer.optimizer.state.values", "RuntimeError", "state.items", "len", "torch.is_tensor", "torch.is_tensor", "v.cuda"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.Optimizer.set_parameters", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.nlpyang_PreSumm.models.optimizers.use_gpu"], ["", "def", "build_optim", "(", "model", ",", "opt", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "saved_optimizer_state_dict", "=", "None", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "# We need to save a copy of optim.optimizer.state_dict() for setting", "\n", "# the, optimizer state later on in Stage 2 in this method, since", "\n", "# the method optim.set_parameters(model.parameters()) will overwrite", "\n", "# optim.optimizer, and with ith the values stored in", "\n", "# optim.optimizer.state_dict()", "\n", "saved_optimizer_state_dict", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "Optimizer", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_steps", "=", "opt", ".", "start_decay_steps", ",", "\n", "decay_steps", "=", "opt", ".", "decay_steps", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "optim", ".", "optimizer", ".", "load_state_dict", "(", "saved_optimizer_state_dict", ")", "\n", "if", "use_gpu", "(", "opt", ")", ":", "\n", "            ", "for", "state", "in", "optim", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "", "if", "(", "optim", ".", "method", "==", "'adam'", ")", "and", "(", "len", "(", "optim", ".", "optimizer", ".", "state", ")", "<", "1", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error: loaded Adam optimizer from existing model\"", "+", "\n", "\" but optimizer state is empty\"", ")", "\n", "\n", "", "", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.__init__": [[208, 221], ["others.tokenization.BertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "do_lower_case", "=", "True", ")", "\n", "\n", "self", ".", "sep_token", "=", "'[SEP]'", "\n", "self", ".", "cls_token", "=", "'[CLS]'", "\n", "self", ".", "pad_token", "=", "'[PAD]'", "\n", "self", ".", "tgt_bos", "=", "'[unused0]'", "\n", "self", ".", "tgt_eos", "=", "'[unused1]'", "\n", "self", ".", "tgt_sent_split", "=", "'[unused2]'", "\n", "self", ".", "sep_vid", "=", "self", ".", "tokenizer", ".", "vocab", "[", "self", ".", "sep_token", "]", "\n", "self", ".", "cls_vid", "=", "self", ".", "tokenizer", ".", "vocab", "[", "self", ".", "cls_token", "]", "\n", "self", ".", "pad_vid", "=", "self", ".", "tokenizer", ".", "vocab", "[", "self", ".", "pad_token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.preprocess": [[222, 273], ["data_builder.BertData.tokenizer.tokenize", "data_builder.BertData.tokenizer.convert_tokens_to_ids", "enumerate", "data_builder.BertData.tokenizer.convert_tokens_to_ids", "len", "tgt_subtokens_str.split", "len", "enumerate", "len", "range", "enumerate", "len", "len", "len", "enumerate", "len", "data_builder.BertData.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.tokenize", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.tokenize"], ["", "def", "preprocess", "(", "self", ",", "src", ",", "tgt", ",", "sent_labels", ",", "use_bert_basic_tokenizer", "=", "False", ",", "is_test", "=", "False", ")", ":", "\n", "\n", "        ", "if", "(", "(", "not", "is_test", ")", "and", "len", "(", "src", ")", "==", "0", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "original_src_txt", "=", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "src", "]", "\n", "\n", "idxs", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "src", ")", "if", "(", "len", "(", "s", ")", ">", "self", ".", "args", ".", "min_src_ntokens_per_sent", ")", "]", "\n", "\n", "_sent_labels", "=", "[", "0", "]", "*", "len", "(", "src", ")", "\n", "for", "l", "in", "sent_labels", ":", "\n", "            ", "_sent_labels", "[", "l", "]", "=", "1", "\n", "\n", "", "src", "=", "[", "src", "[", "i", "]", "[", ":", "self", ".", "args", ".", "max_src_ntokens_per_sent", "]", "for", "i", "in", "idxs", "]", "\n", "sent_labels", "=", "[", "_sent_labels", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "src", "=", "src", "[", ":", "self", ".", "args", ".", "max_src_nsents", "]", "\n", "sent_labels", "=", "sent_labels", "[", ":", "self", ".", "args", ".", "max_src_nsents", "]", "\n", "\n", "if", "(", "(", "not", "is_test", ")", "and", "len", "(", "src", ")", "<", "self", ".", "args", ".", "min_src_nsents", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "src_txt", "=", "[", "' '", ".", "join", "(", "sent", ")", "for", "sent", "in", "src", "]", "\n", "text", "=", "' {} {} '", ".", "format", "(", "self", ".", "sep_token", ",", "self", ".", "cls_token", ")", ".", "join", "(", "src_txt", ")", "\n", "\n", "src_subtokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "\n", "src_subtokens", "=", "[", "self", ".", "cls_token", "]", "+", "src_subtokens", "+", "[", "self", ".", "sep_token", "]", "\n", "src_subtoken_idxs", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "src_subtokens", ")", "\n", "_segs", "=", "[", "-", "1", "]", "+", "[", "i", "for", "i", ",", "t", "in", "enumerate", "(", "src_subtoken_idxs", ")", "if", "t", "==", "self", ".", "sep_vid", "]", "\n", "segs", "=", "[", "_segs", "[", "i", "]", "-", "_segs", "[", "i", "-", "1", "]", "for", "i", "in", "range", "(", "1", ",", "len", "(", "_segs", ")", ")", "]", "\n", "segments_ids", "=", "[", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "segs", ")", ":", "\n", "            ", "if", "(", "i", "%", "2", "==", "0", ")", ":", "\n", "                ", "segments_ids", "+=", "s", "*", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "segments_ids", "+=", "s", "*", "[", "1", "]", "\n", "", "", "cls_ids", "=", "[", "i", "for", "i", ",", "t", "in", "enumerate", "(", "src_subtoken_idxs", ")", "if", "t", "==", "self", ".", "cls_vid", "]", "\n", "sent_labels", "=", "sent_labels", "[", ":", "len", "(", "cls_ids", ")", "]", "\n", "\n", "tgt_subtokens_str", "=", "'[unused0] '", "+", "' [unused2] '", ".", "join", "(", "\n", "[", "' '", ".", "join", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "tt", ")", ",", "use_bert_basic_tokenizer", "=", "use_bert_basic_tokenizer", ")", ")", "for", "tt", "in", "tgt", "]", ")", "+", "' [unused1]'", "\n", "tgt_subtoken", "=", "tgt_subtokens_str", ".", "split", "(", ")", "[", ":", "self", ".", "args", ".", "max_tgt_ntokens", "]", "\n", "if", "(", "(", "not", "is_test", ")", "and", "len", "(", "tgt_subtoken", ")", "<", "self", ".", "args", ".", "min_tgt_ntokens", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "tgt_subtoken_idxs", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tgt_subtoken", ")", "\n", "\n", "tgt_txt", "=", "'<q>'", ".", "join", "(", "[", "' '", ".", "join", "(", "tt", ")", "for", "tt", "in", "tgt", "]", ")", "\n", "src_txt", "=", "[", "original_src_txt", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "\n", "return", "src_subtoken_idxs", ",", "sent_labels", ",", "tgt_subtoken_idxs", ",", "segments_ids", ",", "cls_ids", ",", "src_txt", ",", "tgt_txt", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.recover_from_corenlp": [[28, 31], ["re.sub", "re.sub"], "function", ["None"], ["def", "recover_from_corenlp", "(", "s", ")", ":", "\n", "    ", "s", "=", "re", ".", "sub", "(", "r' \\'{\\w}'", ",", "'\\'\\g<1>'", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "r'\\'\\' {\\w}'", ",", "'\\'\\'\\g<1>'", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.load_json": [[34, 54], ["json.load", "others.utils.clean().split", "others.utils.clean().split", "open", "tgt.append", "tgt[].extend", "source.append", "t.lower", "others.utils.clean", "others.utils.clean"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.clean", "home.repos.pwc.inspect_result.nlpyang_PreSumm.others.utils.clean"], ["", "def", "load_json", "(", "p", ",", "lower", ")", ":", "\n", "    ", "source", "=", "[", "]", "\n", "tgt", "=", "[", "]", "\n", "flag", "=", "False", "\n", "for", "sent", "in", "json", ".", "load", "(", "open", "(", "p", ")", ")", "[", "'sentences'", "]", ":", "\n", "        ", "tokens", "=", "[", "t", "[", "'word'", "]", "for", "t", "in", "sent", "[", "'tokens'", "]", "]", "\n", "if", "(", "lower", ")", ":", "\n", "            ", "tokens", "=", "[", "t", ".", "lower", "(", ")", "for", "t", "in", "tokens", "]", "\n", "", "if", "(", "tokens", "[", "0", "]", "==", "'@highlight'", ")", ":", "\n", "            ", "flag", "=", "True", "\n", "tgt", ".", "append", "(", "[", "]", ")", "\n", "continue", "\n", "", "if", "(", "flag", ")", ":", "\n", "            ", "tgt", "[", "-", "1", "]", ".", "extend", "(", "tokens", ")", "\n", "", "else", ":", "\n", "            ", "source", ".", "append", "(", "tokens", ")", "\n", "\n", "", "", "source", "=", "[", "clean", "(", "' '", ".", "join", "(", "sent", ")", ")", ".", "split", "(", ")", "for", "sent", "in", "source", "]", "\n", "tgt", "=", "[", "clean", "(", "' '", ".", "join", "(", "sent", ")", ")", ".", "split", "(", ")", "for", "sent", "in", "tgt", "]", "\n", "return", "source", ",", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.load_xml": [[57, 108], ["xml.parse", "ET.parse.getroot", "list", "list", "list", "abs[].replace", "abs[].replace", "tree.getroot.iter", "tree.getroot.iter", "len", "tree.getroot.iter", "len", "byline_node[].text.lower().split", "tree.getroot.iter", "len", "abs[].replace", "p.split", "doc_node.get", "len", "len", "print", "byline_node[].text.lower", "print", "len", "p.text.lower().split", "p.text.lower().split", "p.text.lower().split", "list", "list", "list", "p.text.lower", "doc_node.iter", "p.text.lower", "title_node[].iter", "p.text.lower", "abs_node[].iter"], "function", ["None"], ["", "def", "load_xml", "(", "p", ")", ":", "\n", "    ", "tree", "=", "ET", ".", "parse", "(", "p", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "title", ",", "byline", ",", "abs", ",", "paras", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "title_node", "=", "list", "(", "root", ".", "iter", "(", "'hedline'", ")", ")", "\n", "if", "(", "len", "(", "title_node", ")", ">", "0", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "title", "=", "[", "p", ".", "text", ".", "lower", "(", ")", ".", "split", "(", ")", "for", "p", "in", "list", "(", "title_node", "[", "0", "]", ".", "iter", "(", "'hl1'", ")", ")", "]", "[", "0", "]", "\n", "", "except", ":", "\n", "            ", "print", "(", "p", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "byline_node", "=", "list", "(", "root", ".", "iter", "(", "'byline'", ")", ")", "\n", "byline_node", "=", "[", "n", "for", "n", "in", "byline_node", "if", "n", ".", "attrib", "[", "'class'", "]", "==", "'normalized_byline'", "]", "\n", "if", "(", "len", "(", "byline_node", ")", ">", "0", ")", ":", "\n", "        ", "byline", "=", "byline_node", "[", "0", "]", ".", "text", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "", "abs_node", "=", "list", "(", "root", ".", "iter", "(", "'abstract'", ")", ")", "\n", "if", "(", "len", "(", "abs_node", ")", ">", "0", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "abs", "=", "[", "p", ".", "text", ".", "lower", "(", ")", ".", "split", "(", ")", "for", "p", "in", "list", "(", "abs_node", "[", "0", "]", ".", "iter", "(", "'p'", ")", ")", "]", "[", "0", "]", "\n", "", "except", ":", "\n", "            ", "print", "(", "p", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "abs", "=", "' '", ".", "join", "(", "abs", ")", ".", "split", "(", "';'", ")", "\n", "abs", "[", "-", "1", "]", "=", "abs", "[", "-", "1", "]", ".", "replace", "(", "'(m)'", ",", "''", ")", "\n", "abs", "[", "-", "1", "]", "=", "abs", "[", "-", "1", "]", ".", "replace", "(", "'(s)'", ",", "''", ")", "\n", "\n", "for", "ww", "in", "nyt_remove_words", ":", "\n", "        ", "abs", "[", "-", "1", "]", "=", "abs", "[", "-", "1", "]", ".", "replace", "(", "'('", "+", "ww", "+", "')'", ",", "''", ")", "\n", "", "abs", "=", "[", "p", ".", "split", "(", ")", "for", "p", "in", "abs", "]", "\n", "abs", "=", "[", "p", "for", "p", "in", "abs", "if", "len", "(", "p", ")", ">", "2", "]", "\n", "\n", "for", "doc_node", "in", "root", ".", "iter", "(", "'block'", ")", ":", "\n", "        ", "att", "=", "doc_node", ".", "get", "(", "'class'", ")", "\n", "# if(att == 'abstract'):", "\n", "#     abs = [p.text for p in list(f.iter('p'))]", "\n", "if", "(", "att", "==", "'full_text'", ")", ":", "\n", "            ", "paras", "=", "[", "p", ".", "text", ".", "lower", "(", ")", ".", "split", "(", ")", "for", "p", "in", "list", "(", "doc_node", ".", "iter", "(", "'p'", ")", ")", "]", "\n", "break", "\n", "", "", "if", "(", "len", "(", "paras", ")", ">", "0", ")", ":", "\n", "        ", "if", "(", "len", "(", "byline", ")", ">", "0", ")", ":", "\n", "            ", "paras", "=", "[", "title", "+", "[", "'[unused3]'", "]", "+", "byline", "+", "[", "'[unused4]'", "]", "]", "+", "paras", "\n", "", "else", ":", "\n", "            ", "paras", "=", "[", "title", "+", "[", "'[unused3]'", "]", "]", "+", "paras", "\n", "\n", "", "return", "paras", ",", "abs", "\n", "", "else", ":", "\n", "        ", "return", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.tokenize": [[110, 139], ["os.path.abspath", "os.path.abspath", "print", "os.listdir", "print", "print", "subprocess.call", "print", "os.remove", "len", "len", "print", "open", "os.listdir", "os.listdir", "Exception", "f.write", "s.endswith", "len", "os.path.join"], "function", ["None"], ["", "", "def", "tokenize", "(", "args", ")", ":", "\n", "    ", "stories_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "raw_path", ")", "\n", "tokenized_stories_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "save_path", ")", "\n", "\n", "print", "(", "\"Preparing to tokenize %s to %s...\"", "%", "(", "stories_dir", ",", "tokenized_stories_dir", ")", ")", "\n", "stories", "=", "os", ".", "listdir", "(", "stories_dir", ")", "\n", "# make IO list file", "\n", "print", "(", "\"Making list of files to tokenize...\"", ")", "\n", "with", "open", "(", "\"mapping_for_corenlp.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "s", "in", "stories", ":", "\n", "            ", "if", "(", "not", "s", ".", "endswith", "(", "'story'", ")", ")", ":", "\n", "                ", "continue", "\n", "", "f", ".", "write", "(", "\"%s\\n\"", "%", "(", "os", ".", "path", ".", "join", "(", "stories_dir", ",", "s", ")", ")", ")", "\n", "", "", "command", "=", "[", "'java'", ",", "'edu.stanford.nlp.pipeline.StanfordCoreNLP'", ",", "'-annotators'", ",", "'tokenize,ssplit'", ",", "\n", "'-ssplit.newlineIsSentenceBreak'", ",", "'always'", ",", "'-filelist'", ",", "'mapping_for_corenlp.txt'", ",", "'-outputFormat'", ",", "\n", "'json'", ",", "'-outputDirectory'", ",", "tokenized_stories_dir", "]", "\n", "print", "(", "\"Tokenizing %i files in %s and saving in %s...\"", "%", "(", "len", "(", "stories", ")", ",", "stories_dir", ",", "tokenized_stories_dir", ")", ")", "\n", "subprocess", ".", "call", "(", "command", ")", "\n", "print", "(", "\"Stanford CoreNLP Tokenizer has finished.\"", ")", "\n", "os", ".", "remove", "(", "\"mapping_for_corenlp.txt\"", ")", "\n", "\n", "# Check that the tokenized stories directory contains the same number of files as the original directory", "\n", "num_orig", "=", "len", "(", "os", ".", "listdir", "(", "stories_dir", ")", ")", "\n", "num_tokenized", "=", "len", "(", "os", ".", "listdir", "(", "tokenized_stories_dir", ")", ")", "\n", "if", "num_orig", "!=", "num_tokenized", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"The tokenized stories directory %s contains %i files, but it should contain the same number as %s (which has %i files). Was there an error during tokenization?\"", "%", "(", "\n", "tokenized_stories_dir", ",", "num_tokenized", ",", "stories_dir", ",", "num_orig", ")", ")", "\n", "", "print", "(", "\"Successfully finished tokenizing %s to %s.\\n\"", "%", "(", "stories_dir", ",", "tokenized_stories_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.cal_rouge": [[140, 159], ["len", "len", "evaluated_ngrams.intersection", "len"], "function", ["None"], ["", "def", "cal_rouge", "(", "evaluated_ngrams", ",", "reference_ngrams", ")", ":", "\n", "    ", "reference_count", "=", "len", "(", "reference_ngrams", ")", "\n", "evaluated_count", "=", "len", "(", "evaluated_ngrams", ")", "\n", "\n", "overlapping_ngrams", "=", "evaluated_ngrams", ".", "intersection", "(", "reference_ngrams", ")", "\n", "overlapping_count", "=", "len", "(", "overlapping_ngrams", ")", "\n", "\n", "if", "evaluated_count", "==", "0", ":", "\n", "        ", "precision", "=", "0.0", "\n", "", "else", ":", "\n", "        ", "precision", "=", "overlapping_count", "/", "evaluated_count", "\n", "\n", "", "if", "reference_count", "==", "0", ":", "\n", "        ", "recall", "=", "0.0", "\n", "", "else", ":", "\n", "        ", "recall", "=", "overlapping_count", "/", "reference_count", "\n", "\n", "", "f1_score", "=", "2.0", "*", "(", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", "+", "1e-8", ")", ")", "\n", "return", "{", "\"f\"", ":", "f1_score", ",", "\"p\"", ":", "precision", ",", "\"r\"", ":", "recall", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.greedy_selection": [[161, 198], ["sum", "_rouge_clean().split", "prepro.utils._get_word_ngrams", "prepro.utils._get_word_ngrams", "range", "sorted", "re.sub", "_rouge_clean().split", "prepro.utils._get_word_ngrams", "prepro.utils._get_word_ngrams", "range", "selected.append", "data_builder.greedy_selection._rouge_clean"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_word_ngrams", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_word_ngrams", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_word_ngrams", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_word_ngrams"], ["", "def", "greedy_selection", "(", "doc_sent_list", ",", "abstract_sent_list", ",", "summary_size", ")", ":", "\n", "    ", "def", "_rouge_clean", "(", "s", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'[^a-zA-Z0-9 ]'", ",", "''", ",", "s", ")", "\n", "\n", "", "max_rouge", "=", "0.0", "\n", "abstract", "=", "sum", "(", "abstract_sent_list", ",", "[", "]", ")", "\n", "abstract", "=", "_rouge_clean", "(", "' '", ".", "join", "(", "abstract", ")", ")", ".", "split", "(", ")", "\n", "sents", "=", "[", "_rouge_clean", "(", "' '", ".", "join", "(", "s", ")", ")", ".", "split", "(", ")", "for", "s", "in", "doc_sent_list", "]", "\n", "evaluated_1grams", "=", "[", "_get_word_ngrams", "(", "1", ",", "[", "sent", "]", ")", "for", "sent", "in", "sents", "]", "\n", "reference_1grams", "=", "_get_word_ngrams", "(", "1", ",", "[", "abstract", "]", ")", "\n", "evaluated_2grams", "=", "[", "_get_word_ngrams", "(", "2", ",", "[", "sent", "]", ")", "for", "sent", "in", "sents", "]", "\n", "reference_2grams", "=", "_get_word_ngrams", "(", "2", ",", "[", "abstract", "]", ")", "\n", "\n", "selected", "=", "[", "]", "\n", "for", "s", "in", "range", "(", "summary_size", ")", ":", "\n", "        ", "cur_max_rouge", "=", "max_rouge", "\n", "cur_id", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "sents", ")", ")", ":", "\n", "            ", "if", "(", "i", "in", "selected", ")", ":", "\n", "                ", "continue", "\n", "", "c", "=", "selected", "+", "[", "i", "]", "\n", "candidates_1", "=", "[", "evaluated_1grams", "[", "idx", "]", "for", "idx", "in", "c", "]", "\n", "candidates_1", "=", "set", ".", "union", "(", "*", "map", "(", "set", ",", "candidates_1", ")", ")", "\n", "candidates_2", "=", "[", "evaluated_2grams", "[", "idx", "]", "for", "idx", "in", "c", "]", "\n", "candidates_2", "=", "set", ".", "union", "(", "*", "map", "(", "set", ",", "candidates_2", ")", ")", "\n", "rouge_1", "=", "cal_rouge", "(", "candidates_1", ",", "reference_1grams", ")", "[", "'f'", "]", "\n", "rouge_2", "=", "cal_rouge", "(", "candidates_2", ",", "reference_2grams", ")", "[", "'f'", "]", "\n", "rouge_score", "=", "rouge_1", "+", "rouge_2", "\n", "if", "rouge_score", ">", "cur_max_rouge", ":", "\n", "                ", "cur_max_rouge", "=", "rouge_score", "\n", "cur_id", "=", "i", "\n", "", "", "if", "(", "cur_id", "==", "-", "1", ")", ":", "\n", "            ", "return", "selected", "\n", "", "selected", ".", "append", "(", "cur_id", ")", "\n", "max_rouge", "=", "cur_max_rouge", "\n", "\n", "", "return", "sorted", "(", "selected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.hashhex": [[200, 205], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.models.reporter_ext.Statistics.update"], ["", "def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.format_to_bert": [[275, 292], ["glob.glob", "print", "multiprocess.Pool", "multiprocess.Pool.imap", "multiprocess.Pool.close", "multiprocess.Pool.join", "os.path.join", "a_lst.append", "json_f.split", "os.path.join", "real_name.replace"], "function", ["None"], ["", "", "def", "format_to_bert", "(", "args", ")", ":", "\n", "    ", "if", "(", "args", ".", "dataset", "!=", "''", ")", ":", "\n", "        ", "datasets", "=", "[", "args", ".", "dataset", "]", "\n", "", "else", ":", "\n", "        ", "datasets", "=", "[", "'train'", ",", "'valid'", ",", "'test'", "]", "\n", "", "for", "corpus_type", "in", "datasets", ":", "\n", "        ", "a_lst", "=", "[", "]", "\n", "for", "json_f", "in", "glob", ".", "glob", "(", "pjoin", "(", "args", ".", "raw_path", ",", "'*'", "+", "corpus_type", "+", "'.*.json'", ")", ")", ":", "\n", "            ", "real_name", "=", "json_f", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "a_lst", ".", "append", "(", "(", "corpus_type", ",", "json_f", ",", "args", ",", "pjoin", "(", "args", ".", "save_path", ",", "real_name", ".", "replace", "(", "'json'", ",", "'bert.pt'", ")", ")", ")", ")", "\n", "", "print", "(", "a_lst", ")", "\n", "pool", "=", "Pool", "(", "args", ".", "n_cpus", ")", "\n", "for", "d", "in", "pool", ".", "imap", "(", "_format_to_bert", ",", "a_lst", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder._format_to_bert": [[294, 329], ["os.path.exists", "data_builder.BertData", "others.logging.logger.info", "json.load", "others.logging.logger.info", "others.logging.logger.info", "torch.save", "gc.collect", "others.logging.logger.info", "open", "data_builder.greedy_selection", "data_builder.BertData.preprocess", "datasets.append", "len"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.greedy_selection", "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.BertData.preprocess"], ["", "", "def", "_format_to_bert", "(", "params", ")", ":", "\n", "    ", "corpus_type", ",", "json_file", ",", "args", ",", "save_file", "=", "params", "\n", "is_test", "=", "corpus_type", "==", "'test'", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "save_file", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Ignore %s'", "%", "save_file", ")", "\n", "return", "\n", "\n", "", "bert", "=", "BertData", "(", "args", ")", "\n", "\n", "logger", ".", "info", "(", "'Processing %s'", "%", "json_file", ")", "\n", "jobs", "=", "json", ".", "load", "(", "open", "(", "json_file", ")", ")", "\n", "datasets", "=", "[", "]", "\n", "for", "d", "in", "jobs", ":", "\n", "        ", "source", ",", "tgt", "=", "d", "[", "'src'", "]", ",", "d", "[", "'tgt'", "]", "\n", "\n", "sent_labels", "=", "greedy_selection", "(", "source", "[", ":", "args", ".", "max_src_nsents", "]", ",", "tgt", ",", "3", ")", "\n", "if", "(", "args", ".", "lower", ")", ":", "\n", "            ", "source", "=", "[", "' '", ".", "join", "(", "s", ")", ".", "lower", "(", ")", ".", "split", "(", ")", "for", "s", "in", "source", "]", "\n", "tgt", "=", "[", "' '", ".", "join", "(", "s", ")", ".", "lower", "(", ")", ".", "split", "(", ")", "for", "s", "in", "tgt", "]", "\n", "", "b_data", "=", "bert", ".", "preprocess", "(", "source", ",", "tgt", ",", "sent_labels", ",", "use_bert_basic_tokenizer", "=", "args", ".", "use_bert_basic_tokenizer", ",", "\n", "is_test", "=", "is_test", ")", "\n", "# b_data = bert.preprocess(source, tgt, sent_labels, use_bert_basic_tokenizer=args.use_bert_basic_tokenizer)", "\n", "\n", "if", "(", "b_data", "is", "None", ")", ":", "\n", "            ", "continue", "\n", "", "src_subtoken_idxs", ",", "sent_labels", ",", "tgt_subtoken_idxs", ",", "segments_ids", ",", "cls_ids", ",", "src_txt", ",", "tgt_txt", "=", "b_data", "\n", "b_data_dict", "=", "{", "\"src\"", ":", "src_subtoken_idxs", ",", "\"tgt\"", ":", "tgt_subtoken_idxs", ",", "\n", "\"src_sent_labels\"", ":", "sent_labels", ",", "\"segs\"", ":", "segments_ids", ",", "'clss'", ":", "cls_ids", ",", "\n", "'src_txt'", ":", "src_txt", ",", "\"tgt_txt\"", ":", "tgt_txt", "}", "\n", "datasets", ".", "append", "(", "b_data_dict", ")", "\n", "", "logger", ".", "info", "(", "'Processed instances %d'", "%", "len", "(", "datasets", ")", ")", "\n", "logger", ".", "info", "(", "'Saving to %s'", "%", "save_file", ")", "\n", "torch", ".", "save", "(", "datasets", ",", "save_file", ")", "\n", "datasets", "=", "[", "]", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.format_to_lines": [[331, 375], ["glob.glob", "open", "os.path.join", "multiprocess.Pool", "multiprocess.Pool.imap_unordered", "multiprocess.Pool.close", "multiprocess.Pool.join", "os.path.join", "temp.append", "key.strip", "[].split", "valid_files.append", "dataset.append", "len", "data_builder.hashhex", "test_files.append", "len", "open", "save.write", "line.strip", "train_files.append", "open", "save.write", "json.dumps", "f.split", "json.dumps"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.hashhex"], ["", "def", "format_to_lines", "(", "args", ")", ":", "\n", "    ", "corpus_mapping", "=", "{", "}", "\n", "for", "corpus_type", "in", "[", "'valid'", ",", "'test'", ",", "'train'", "]", ":", "\n", "        ", "temp", "=", "[", "]", "\n", "for", "line", "in", "open", "(", "pjoin", "(", "args", ".", "map_path", ",", "'mapping_'", "+", "corpus_type", "+", "'.txt'", ")", ")", ":", "\n", "            ", "temp", ".", "append", "(", "hashhex", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "", "corpus_mapping", "[", "corpus_type", "]", "=", "{", "key", ".", "strip", "(", ")", ":", "1", "for", "key", "in", "temp", "}", "\n", "", "train_files", ",", "valid_files", ",", "test_files", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "f", "in", "glob", ".", "glob", "(", "pjoin", "(", "args", ".", "raw_path", ",", "'*.json'", ")", ")", ":", "\n", "        ", "real_name", "=", "f", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "(", "real_name", "in", "corpus_mapping", "[", "'valid'", "]", ")", ":", "\n", "            ", "valid_files", ".", "append", "(", "f", ")", "\n", "", "elif", "(", "real_name", "in", "corpus_mapping", "[", "'test'", "]", ")", ":", "\n", "            ", "test_files", ".", "append", "(", "f", ")", "\n", "", "elif", "(", "real_name", "in", "corpus_mapping", "[", "'train'", "]", ")", ":", "\n", "            ", "train_files", ".", "append", "(", "f", ")", "\n", "# else:", "\n", "#     train_files.append(f)", "\n", "\n", "", "", "corpora", "=", "{", "'train'", ":", "train_files", ",", "'valid'", ":", "valid_files", ",", "'test'", ":", "test_files", "}", "\n", "for", "corpus_type", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "        ", "a_lst", "=", "[", "(", "f", ",", "args", ")", "for", "f", "in", "corpora", "[", "corpus_type", "]", "]", "\n", "pool", "=", "Pool", "(", "args", ".", "n_cpus", ")", "\n", "dataset", "=", "[", "]", "\n", "p_ct", "=", "0", "\n", "for", "d", "in", "pool", ".", "imap_unordered", "(", "_format_to_lines", ",", "a_lst", ")", ":", "\n", "            ", "dataset", ".", "append", "(", "d", ")", "\n", "if", "(", "len", "(", "dataset", ")", ">", "args", ".", "shard_size", ")", ":", "\n", "                ", "pt_file", "=", "\"{:s}.{:s}.{:d}.json\"", ".", "format", "(", "args", ".", "save_path", ",", "corpus_type", ",", "p_ct", ")", "\n", "with", "open", "(", "pt_file", ",", "'w'", ")", "as", "save", ":", "\n", "# save.write('\\n'.join(dataset))", "\n", "                    ", "save", ".", "write", "(", "json", ".", "dumps", "(", "dataset", ")", ")", "\n", "p_ct", "+=", "1", "\n", "dataset", "=", "[", "]", "\n", "\n", "", "", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "if", "(", "len", "(", "dataset", ")", ">", "0", ")", ":", "\n", "            ", "pt_file", "=", "\"{:s}.{:s}.{:d}.json\"", ".", "format", "(", "args", ".", "save_path", ",", "corpus_type", ",", "p_ct", ")", "\n", "with", "open", "(", "pt_file", ",", "'w'", ")", "as", "save", ":", "\n", "# save.write('\\n'.join(dataset))", "\n", "                ", "save", ".", "write", "(", "json", ".", "dumps", "(", "dataset", ")", ")", "\n", "p_ct", "+=", "1", "\n", "dataset", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder._format_to_lines": [[377, 382], ["print", "data_builder.load_json"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.load_json"], ["", "", "", "", "def", "_format_to_lines", "(", "params", ")", ":", "\n", "    ", "f", ",", "args", "=", "params", "\n", "print", "(", "f", ")", "\n", "source", ",", "tgt", "=", "load_json", "(", "f", ",", "args", ".", "lower", ")", "\n", "return", "{", "'src'", ":", "source", ",", "'tgt'", ":", "tgt", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder.format_xsum_to_lines": [[386, 424], ["json.load", "open", "os.path.join", "os.path.join", "multiprocess.Pool", "multiprocess.Pool.imap_unordered", "multiprocess.Pool.close", "multiprocess.Pool.join", "os.path.join", "dataset.append", "len", "len", "open", "save.write", "open", "save.write", "json.dumps", "json.dumps"], "function", ["None"], ["", "def", "format_xsum_to_lines", "(", "args", ")", ":", "\n", "    ", "if", "(", "args", ".", "dataset", "!=", "''", ")", ":", "\n", "        ", "datasets", "=", "[", "args", ".", "dataset", "]", "\n", "", "else", ":", "\n", "        ", "datasets", "=", "[", "'train'", ",", "'test'", ",", "'valid'", "]", "\n", "\n", "", "corpus_mapping", "=", "json", ".", "load", "(", "open", "(", "pjoin", "(", "args", ".", "raw_path", ",", "'XSum-TRAINING-DEV-TEST-SPLIT-90-5-5.json'", ")", ")", ")", "\n", "\n", "for", "corpus_type", "in", "datasets", ":", "\n", "        ", "mapped_fnames", "=", "corpus_mapping", "[", "corpus_type", "]", "\n", "root_src", "=", "pjoin", "(", "args", ".", "raw_path", ",", "'restbody'", ")", "\n", "root_tgt", "=", "pjoin", "(", "args", ".", "raw_path", ",", "'firstsentence'", ")", "\n", "# realnames = [fname.split('.')[0] for fname in os.listdir(root_src)]", "\n", "realnames", "=", "mapped_fnames", "\n", "\n", "a_lst", "=", "[", "(", "root_src", ",", "root_tgt", ",", "n", ")", "for", "n", "in", "realnames", "]", "\n", "pool", "=", "Pool", "(", "args", ".", "n_cpus", ")", "\n", "dataset", "=", "[", "]", "\n", "p_ct", "=", "0", "\n", "for", "d", "in", "pool", ".", "imap_unordered", "(", "_format_xsum_to_lines", ",", "a_lst", ")", ":", "\n", "            ", "if", "(", "d", "is", "None", ")", ":", "\n", "                ", "continue", "\n", "", "dataset", ".", "append", "(", "d", ")", "\n", "if", "(", "len", "(", "dataset", ")", ">", "args", ".", "shard_size", ")", ":", "\n", "                ", "pt_file", "=", "\"{:s}.{:s}.{:d}.json\"", ".", "format", "(", "args", ".", "save_path", ",", "corpus_type", ",", "p_ct", ")", "\n", "with", "open", "(", "pt_file", ",", "'w'", ")", "as", "save", ":", "\n", "                    ", "save", ".", "write", "(", "json", ".", "dumps", "(", "dataset", ")", ")", "\n", "p_ct", "+=", "1", "\n", "dataset", "=", "[", "]", "\n", "\n", "", "", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "if", "(", "len", "(", "dataset", ")", ">", "0", ")", ":", "\n", "            ", "pt_file", "=", "\"{:s}.{:s}.{:d}.json\"", ".", "format", "(", "args", ".", "save_path", ",", "corpus_type", ",", "p_ct", ")", "\n", "with", "open", "(", "pt_file", ",", "'w'", ")", "as", "save", ":", "\n", "                ", "save", ".", "write", "(", "json", ".", "dumps", "(", "dataset", ")", ")", "\n", "p_ct", "+=", "1", "\n", "dataset", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.data_builder._format_xsum_to_lines": [[426, 440], ["os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "print", "open", "open", "source.append", "tgt.append", "sent.split", "sent.split"], "function", ["None"], ["", "", "", "", "def", "_format_xsum_to_lines", "(", "params", ")", ":", "\n", "    ", "src_path", ",", "root_tgt", ",", "name", "=", "params", "\n", "f_src", "=", "pjoin", "(", "src_path", ",", "name", "+", "'.restbody'", ")", "\n", "f_tgt", "=", "pjoin", "(", "root_tgt", ",", "name", "+", "'.fs'", ")", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "f_src", ")", "and", "os", ".", "path", ".", "exists", "(", "f_tgt", ")", ")", ":", "\n", "        ", "print", "(", "name", ")", "\n", "source", "=", "[", "]", "\n", "for", "sent", "in", "open", "(", "f_src", ")", ":", "\n", "            ", "source", ".", "append", "(", "sent", ".", "split", "(", ")", ")", "\n", "", "tgt", "=", "[", "]", "\n", "for", "sent", "in", "open", "(", "f_tgt", ")", ":", "\n", "            ", "tgt", ".", "append", "(", "sent", ".", "split", "(", ")", ")", "\n", "", "return", "{", "'src'", ":", "source", ",", "'tgt'", ":", "tgt", "}", "\n", "", "return", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_ngrams": [[6, 22], ["set", "len", "range", "set.add", "tuple"], "function", ["None"], ["from", "others", "import", "pyrouge", "\n", "\n", "REMAP", "=", "{", "\"-lrb-\"", ":", "\"(\"", ",", "\"-rrb-\"", ":", "\")\"", ",", "\"-lcb-\"", ":", "\"{\"", ",", "\"-rcb-\"", ":", "\"}\"", ",", "\n", "\"-lsb-\"", ":", "\"[\"", ",", "\"-rsb-\"", ":", "\"]\"", ",", "\"``\"", ":", "'\"'", ",", "\"''\"", ":", "'\"'", "}", "\n", "\n", "\n", "def", "clean", "(", "x", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "\n", "r\"-lrb-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|``|''\"", ",", "\n", "lambda", "m", ":", "REMAP", ".", "get", "(", "m", ".", "group", "(", ")", ")", ",", "x", ")", "\n", "\n", "\n", "", "def", "process", "(", "params", ")", ":", "\n", "    ", "temp_dir", ",", "data", "=", "params", "\n", "candidates", ",", "references", ",", "pool_id", "=", "data", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_word_ngrams": [[24, 35], ["sum", "utils._get_ngrams", "len"], "function", ["home.repos.pwc.inspect_result.nlpyang_PreSumm.prepro.utils._get_ngrams"], ["if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "try", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n"]]}