{"home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.GradCAM.__init__": [[14, 54], ["dict", "dict", "utils.find_resnet18_layer.register_forward_hook", "utils.find_resnet18_layer.register_backward_hook", "model_type.lower", "utils.find_vgg_layer", "model_type.lower", "utils.find_resnet_layer", "methods.GradCAM.model_arch", "print", "model_type.lower", "utils.find_densenet_layer", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model_type.lower", "utils.find_alexnet_layer", "next", "model_type.lower", "utils.find_squeezenet_layer", "methods.GradCAM.model_arch.parameters", "model_type.lower", "utils.find_resnet18_layer"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_vgg_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_densenet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_alexnet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_squeezenet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet18_layer"], ["    ", "def", "__init__", "(", "self", ",", "model_dict", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "model_type", "=", "model_dict", "[", "'type'", "]", "\n", "layer_name", "=", "model_dict", "[", "'layer_name'", "]", "\n", "self", ".", "model_arch", "=", "model_dict", "[", "'arch'", "]", "\n", "\n", "self", ".", "gradients", "=", "dict", "(", ")", "\n", "self", ".", "activations", "=", "dict", "(", ")", "\n", "def", "backward_hook", "(", "module", ",", "grad_input", ",", "grad_output", ")", ":", "\n", "            ", "self", ".", "gradients", "[", "'value'", "]", "=", "grad_output", "[", "0", "]", "\n", "return", "None", "\n", "", "def", "forward_hook", "(", "module", ",", "input", ",", "output", ")", ":", "\n", "            ", "self", ".", "activations", "[", "'value'", "]", "=", "output", "\n", "return", "None", "\n", "\n", "", "if", "'vgg'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_vgg_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'resnet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_resnet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'densenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_densenet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'alexnet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_alexnet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'squeezenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_squeezenet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'small'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_resnet18_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "\n", "", "target_layer", ".", "register_forward_hook", "(", "forward_hook", ")", "\n", "target_layer", ".", "register_backward_hook", "(", "backward_hook", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "try", ":", "\n", "                ", "input_size", "=", "model_dict", "[", "'input_size'", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "print", "(", "\"please specify size of input image in model_dict. e.g. {'input_size':(224, 224)}\"", ")", "\n", "pass", "\n", "", "else", ":", "\n", "                ", "device", "=", "'cuda'", "if", "next", "(", "self", ".", "model_arch", ".", "parameters", "(", ")", ")", ".", "is_cuda", "else", "'cpu'", "\n", "self", ".", "model_arch", "(", "torch", ".", "zeros", "(", "1", ",", "3", ",", "*", "(", "input_size", ")", ",", "device", "=", "device", ")", ")", "\n", "print", "(", "'saliency_map size :'", ",", "self", ".", "activations", "[", "'value'", "]", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.GradCAM.forward": [[56, 95], ["input.size", "methods.GradCAM.model_arch.eval", "methods.GradCAM.model_arch.cuda", "methods.GradCAM.model_arch", "methods.GradCAM.model_arch.zero_grad", "logit[].squeeze.backward", "gradients.size", "gradients.view().mean", "gradients.view().mean.view", "torch.relu", "torch.relu", "torch.upsample", "torch.upsample", "logit[].squeeze", "logit[].squeeze", "torch.upsample.min", "torch.upsample.max", "gradients.view", "methods.GradCAM.max"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input", ",", "class_idx", "=", "None", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: input image with shape of (1, 3, H, W)\n            class_idx (int): class index for calculating GradCAM.\n                    If not specified, the class index that makes the highest model prediction score will be used.\n        Return:\n            mask: saliency map of the same spatial dimension with input\n            logit: model output\n        \"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "input", ".", "size", "(", ")", "\n", "self", ".", "model_arch", ".", "eval", "(", ")", "\n", "self", ".", "model_arch", ".", "cuda", "(", ")", "\n", "\n", "logit", "=", "self", ".", "model_arch", "(", "input", ")", "\n", "#Grad-CAM gradient initialization", "\n", "if", "class_idx", "is", "None", ":", "\n", "            ", "score", "=", "logit", "[", ":", ",", "logit", ".", "max", "(", "1", ")", "[", "-", "1", "]", "]", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "logit", "[", ":", ",", "class_idx", "]", ".", "squeeze", "(", ")", "\n", "\n", "", "self", ".", "model_arch", ".", "zero_grad", "(", ")", "\n", "score", ".", "backward", "(", "retain_graph", "=", "retain_graph", ")", "\n", "\n", "gradients", "=", "self", ".", "gradients", "[", "'value'", "]", "\n", "activations", "=", "self", ".", "activations", "[", "'value'", "]", "\n", "b", ",", "k", ",", "u", ",", "v", "=", "gradients", ".", "size", "(", ")", "\n", "\n", "alpha", "=", "gradients", ".", "view", "(", "b", ",", "k", ",", "-", "1", ")", ".", "mean", "(", "2", ")", "\n", "#alpha = F.relu(gradients.view(b, k, -1)).mean(2)", "\n", "weights", "=", "alpha", ".", "view", "(", "b", ",", "k", ",", "1", ",", "1", ")", "\n", "\n", "saliency_map", "=", "(", "weights", "*", "activations", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "saliency_map", "=", "F", ".", "relu", "(", "saliency_map", ")", "\n", "saliency_map", "=", "F", ".", "upsample", "(", "saliency_map", ",", "size", "=", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "saliency_map_min", ",", "saliency_map_max", "=", "saliency_map", ".", "min", "(", ")", ",", "saliency_map", ".", "max", "(", ")", "\n", "saliency_map", "=", "(", "saliency_map", "-", "saliency_map_min", ")", ".", "div", "(", "saliency_map_max", "-", "saliency_map_min", ")", ".", "data", "\n", "\n", "return", "saliency_map", ",", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.GradCAM.__call__": [[96, 98], ["methods.GradCAM.forward"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.ContrastCAM.forward"], ["", "def", "__call__", "(", "self", ",", "input", ",", "class_idx", "=", "None", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "input", ",", "class_idx", ",", "retain_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.CounterfactualCAM.__init__": [[101, 141], ["dict", "dict", "utils.find_resnet18_layer.register_forward_hook", "utils.find_resnet18_layer.register_backward_hook", "model_type.lower", "utils.find_vgg_layer", "model_type.lower", "utils.find_resnet_layer", "methods.CounterfactualCAM.model_arch", "print", "model_type.lower", "utils.find_densenet_layer", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model_type.lower", "utils.find_alexnet_layer", "next", "model_type.lower", "utils.find_squeezenet_layer", "methods.CounterfactualCAM.model_arch.parameters", "model_type.lower", "utils.find_resnet18_layer"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_vgg_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_densenet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_alexnet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_squeezenet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet18_layer"], ["    ", "def", "__init__", "(", "self", ",", "model_dict", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "model_type", "=", "model_dict", "[", "'type'", "]", "\n", "layer_name", "=", "model_dict", "[", "'layer_name'", "]", "\n", "self", ".", "model_arch", "=", "model_dict", "[", "'arch'", "]", "\n", "\n", "self", ".", "gradients", "=", "dict", "(", ")", "\n", "self", ".", "activations", "=", "dict", "(", ")", "\n", "def", "backward_hook", "(", "module", ",", "grad_input", ",", "grad_output", ")", ":", "\n", "            ", "self", ".", "gradients", "[", "'value'", "]", "=", "grad_output", "[", "0", "]", "\n", "return", "None", "\n", "", "def", "forward_hook", "(", "module", ",", "input", ",", "output", ")", ":", "\n", "            ", "self", ".", "activations", "[", "'value'", "]", "=", "output", "\n", "return", "None", "\n", "\n", "", "if", "'vgg'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_vgg_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'resnet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_resnet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'densenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_densenet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'alexnet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_alexnet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'squeezenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_squeezenet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'small'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_resnet18_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "\n", "", "target_layer", ".", "register_forward_hook", "(", "forward_hook", ")", "\n", "target_layer", ".", "register_backward_hook", "(", "backward_hook", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "try", ":", "\n", "                ", "input_size", "=", "model_dict", "[", "'input_size'", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "print", "(", "\"please specify size of input image in model_dict. e.g. {'input_size':(224, 224)}\"", ")", "\n", "pass", "\n", "", "else", ":", "\n", "                ", "device", "=", "'cuda'", "if", "next", "(", "self", ".", "model_arch", ".", "parameters", "(", ")", ")", ".", "is_cuda", "else", "'cpu'", "\n", "self", ".", "model_arch", "(", "torch", ".", "zeros", "(", "1", ",", "3", ",", "*", "(", "input_size", ")", ",", "device", "=", "device", ")", ")", "\n", "print", "(", "'saliency_map size :'", ",", "self", ".", "activations", "[", "'value'", "]", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.CounterfactualCAM.forward": [[143, 182], ["input.size", "methods.CounterfactualCAM.model_arch.eval", "methods.CounterfactualCAM.model_arch.cuda", "methods.CounterfactualCAM.model_arch", "methods.CounterfactualCAM.model_arch.zero_grad", "logit[].squeeze.backward", "gradients.size", "gradients.view().mean", "torch.relu", "torch.relu", "torch.upsample", "torch.upsample", "logit[].squeeze", "logit[].squeeze", "gradients.view().mean.view", "torch.upsample.min", "torch.upsample.max", "gradients.view", "methods.CounterfactualCAM.max"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input", ",", "class_idx", "=", "None", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: input image with shape of (1, 3, H, W)\n            class_idx (int): class index for calculating GradCAM.\n                    If not specified, the class index that makes the highest model prediction score will be used.\n        Return:\n            mask: saliency map of the same spatial dimension with input\n            logit: model output\n        \"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "input", ".", "size", "(", ")", "\n", "self", ".", "model_arch", ".", "eval", "(", ")", "\n", "self", ".", "model_arch", ".", "cuda", "(", ")", "\n", "\n", "logit", "=", "self", ".", "model_arch", "(", "input", ")", "\n", "#Grad-CAM gradient initialization", "\n", "if", "class_idx", "is", "None", ":", "\n", "            ", "score", "=", "logit", "[", ":", ",", "logit", ".", "max", "(", "1", ")", "[", "-", "1", "]", "]", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "logit", "[", ":", ",", "class_idx", "]", ".", "squeeze", "(", ")", "\n", "\n", "", "self", ".", "model_arch", ".", "zero_grad", "(", ")", "\n", "score", ".", "backward", "(", "retain_graph", "=", "retain_graph", ")", "\n", "\n", "gradients", "=", "self", ".", "gradients", "[", "'value'", "]", "\n", "activations", "=", "self", ".", "activations", "[", "'value'", "]", "\n", "b", ",", "k", ",", "u", ",", "v", "=", "gradients", ".", "size", "(", ")", "\n", "\n", "alpha", "=", "gradients", ".", "view", "(", "b", ",", "k", ",", "-", "1", ")", ".", "mean", "(", "2", ")", "\n", "#alpha = F.relu(gradients.view(b, k, -1)).mean(2)", "\n", "weights", "=", "-", "alpha", ".", "view", "(", "b", ",", "k", ",", "1", ",", "1", ")", "\n", "\n", "saliency_map", "=", "(", "weights", "*", "activations", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "saliency_map", "=", "F", ".", "relu", "(", "saliency_map", ")", "\n", "saliency_map", "=", "F", ".", "upsample", "(", "saliency_map", ",", "size", "=", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "saliency_map_min", ",", "saliency_map_max", "=", "saliency_map", ".", "min", "(", ")", ",", "saliency_map", ".", "max", "(", ")", "\n", "saliency_map", "=", "(", "saliency_map", "-", "saliency_map_min", ")", ".", "div", "(", "saliency_map_max", "-", "saliency_map_min", ")", ".", "data", "\n", "\n", "return", "saliency_map", ",", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.CounterfactualCAM.__call__": [[183, 185], ["methods.CounterfactualCAM.forward"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.ContrastCAM.forward"], ["", "def", "__call__", "(", "self", ",", "input", ",", "class_idx", "=", "None", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "input", ",", "class_idx", ",", "retain_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.ContrastCAM.__init__": [[188, 230], ["dict", "dict", "utils.find_squeezenet_layer.register_forward_hook", "utils.find_squeezenet_layer.register_backward_hook", "model_type.lower", "utils.find_vgg_layer", "model_type.lower", "utils.find_resnet_layer", "methods.ContrastCAM.model_arch", "print", "model_type.lower", "utils.find_densenet_layer", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model_type.lower", "utils.find_alexnet_layer", "next", "model_type.lower", "utils.find_squeezenet_layer", "methods.ContrastCAM.model_arch.parameters", "model_type.lower"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_vgg_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_densenet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_alexnet_layer", "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_squeezenet_layer"], ["    ", "def", "__init__", "(", "self", ",", "model_dict", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "model_type", "=", "model_dict", "[", "'type'", "]", "\n", "layer_name", "=", "model_dict", "[", "'layer_name'", "]", "\n", "self", ".", "model_arch", "=", "model_dict", "[", "'arch'", "]", "\n", "\n", "self", ".", "gradients", "=", "dict", "(", ")", "\n", "self", ".", "activations", "=", "dict", "(", ")", "\n", "\n", "def", "backward_hook", "(", "module", ",", "grad_input", ",", "grad_output", ")", ":", "\n", "            ", "self", ".", "gradients", "[", "'value'", "]", "=", "grad_output", "[", "0", "]", "\n", "return", "None", "\n", "\n", "", "def", "forward_hook", "(", "module", ",", "input", ",", "output", ")", ":", "\n", "            ", "self", ".", "activations", "[", "'value'", "]", "=", "output", "\n", "return", "None", "\n", "\n", "", "if", "'vgg'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_vgg_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'resnet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_resnet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'densenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_densenet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'alexnet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_alexnet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'squeezenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "find_squeezenet_layer", "(", "self", ".", "model_arch", ",", "layer_name", ")", "\n", "", "elif", "'curenet'", "in", "model_type", ".", "lower", "(", ")", ":", "\n", "            ", "target_layer", "=", "self", ".", "model_arch", ".", "conv2", "\n", "\n", "", "target_layer", ".", "register_forward_hook", "(", "forward_hook", ")", "\n", "target_layer", ".", "register_backward_hook", "(", "backward_hook", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "try", ":", "\n", "                ", "input_size", "=", "model_dict", "[", "'input_size'", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "print", "(", "\"please specify size of input image in model_dict. e.g. {'input_size':(224, 224)}\"", ")", "\n", "pass", "\n", "", "else", ":", "\n", "                ", "device", "=", "'cuda'", "if", "next", "(", "self", ".", "model_arch", ".", "parameters", "(", ")", ")", ".", "is_cuda", "else", "'cpu'", "\n", "self", ".", "model_arch", "(", "torch", ".", "zeros", "(", "1", ",", "3", ",", "*", "(", "input_size", ")", ",", "device", "=", "device", ")", ")", "\n", "print", "(", "'saliency_map size :'", ",", "self", ".", "activations", "[", "'value'", "]", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.ContrastCAM.forward": [[231, 273], ["input.size", "methods.ContrastCAM.model_arch.eval", "methods.ContrastCAM.model_arch.cuda", "input.cuda", "methods.ContrastCAM.model_arch", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.CrossEntropyLoss.", "methods.ContrastCAM.model_arch.zero_grad", "nn.CrossEntropyLoss.backward", "gradients.size", "gradients.view().mean", "gradients.view().mean.view", "torch.relu", "torch.relu", "[].cpu().numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "methods.ContrastCAM.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.upsample", "torch.upsample", "torch.relu.min", "torch.relu.max", "numpy.asarray", "gradients.view", "[].cpu", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input", ",", "Q", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: input image with shape of (1, 3, H, W)\n            Q (int): class index for calculating GradCAM.\n                    If not specified, the class index that makes the highest model prediction score will be used.\n        Return:\n            mask: saliency map of the same spatial dimension with input\n            logit: model output\n        \"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "input", ".", "size", "(", ")", "\n", "self", ".", "model_arch", ".", "eval", "(", ")", "\n", "self", ".", "model_arch", ".", "cuda", "(", ")", "\n", "input", ".", "cuda", "(", ")", "\n", "\n", "logit", "=", "self", ".", "model_arch", "(", "input", ")", "\n", "# The only change to Grad-CAM code", "\n", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "if", "Q", "is", "None", ":", "\n", "            ", "Q", "=", "torch", ".", "argsort", "(", "-", "logit", ")", "[", "0", "]", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "im_label_as_var", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "[", "Q", "]", ")", ")", ")", "\n", "pred_loss", "=", "ce_loss", "(", "logit", ".", "cuda", "(", ")", ",", "im_label_as_var", ".", "cuda", "(", ")", ")", "\n", "\n", "self", ".", "model_arch", ".", "zero_grad", "(", ")", "\n", "pred_loss", ".", "backward", "(", ")", "\n", "\n", "gradients", "=", "self", ".", "gradients", "[", "'value'", "]", "\n", "activations", "=", "self", ".", "activations", "[", "'value'", "]", "\n", "b", ",", "k", ",", "u", ",", "v", "=", "gradients", ".", "size", "(", ")", "\n", "\n", "alpha", "=", "(", "gradients", ".", "view", "(", "b", ",", "k", ",", "-", "1", ")", ".", "mean", "(", "2", ")", ")", "\n", "weights", "=", "alpha", ".", "view", "(", "b", ",", "k", ",", "1", ",", "1", ")", "\n", "\n", "saliency_map", "=", "(", "weights", "*", "activations", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "saliency_map", "=", "F", ".", "relu", "(", "saliency_map", ")", "\n", "saliency_map", "=", "F", ".", "upsample", "(", "saliency_map", ",", "size", "=", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", ".", "data", "\n", "saliency_map_min", ",", "saliency_map_max", "=", "saliency_map", ".", "min", "(", ")", ",", "saliency_map", ".", "max", "(", ")", "\n", "saliency_map", "=", "(", "saliency_map", "-", "saliency_map_min", ")", ".", "div", "(", "saliency_map_max", "-", "saliency_map_min", ")", ".", "data", "\n", "\n", "return", "saliency_map", ",", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.ContrastCAM.__call__": [[274, 277], ["methods.ContrastCAM.forward"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.methods.ContrastCAM.forward"], ["", "def", "__call__", "(", "self", ",", "input", ",", "class_idx", "=", "None", ",", "retain_graph", "=", "False", ")", ":", "\n", "\n", "        ", "return", "self", ".", "forward", "(", "input", ",", "class_idx", ",", "retain_graph", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.Normalize.__init__": [[260, 263], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.Normalize.__call__": [[264, 266], ["utils.Normalize.do"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.Normalize.do"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "self", ".", "do", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.Normalize.do": [[267, 269], ["utils.normalize"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.normalize"], ["", "def", "do", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "normalize", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.Normalize.undo": [[270, 272], ["utils.denormalize"], "methods", ["home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.denormalize"], ["", "def", "undo", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "denormalize", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.Normalize.__repr__": [[273, 275], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(mean={0}, std={1})'", ".", "format", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.visualize_cam": [[7, 26], ["cv2.applyColorMap", "torch.from_numpy().permute().float().div", "torch.cat.split", "torch.cat", "result.div().squeeze.div().squeeze", "numpy.uint8", "img.cpu", "torch.from_numpy().permute().float", "result.div().squeeze.div", "mask.squeeze", "result.div().squeeze.max", "torch.from_numpy().permute", "torch.from_numpy"], "function", ["None"], ["def", "visualize_cam", "(", "mask", ",", "img", ")", ":", "\n", "    ", "\"\"\"Make heatmap from mask and synthesize GradCAM result image using heatmap and img.\n    Args:\n        mask (torch.tensor): mask shape of (1, 1, H, W) and each element has value in range [0, 1]\n        img (torch.tensor): img shape of (1, 3, H, W) and each pixel value is in range [0, 1]\n        \n    Return:\n        heatmap (torch.tensor): heatmap img shape of (3, H, W)\n        result (torch.tensor): synthesized GradCAM result of same shape with heatmap.\n    \"\"\"", "\n", "heatmap", "=", "cv2", ".", "applyColorMap", "(", "np", ".", "uint8", "(", "255", "*", "mask", ".", "squeeze", "(", ")", ")", ",", "cv2", ".", "COLORMAP_JET", ")", "\n", "heatmap", "=", "torch", ".", "from_numpy", "(", "heatmap", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "float", "(", ")", ".", "div", "(", "255", ")", "\n", "b", ",", "g", ",", "r", "=", "heatmap", ".", "split", "(", "1", ")", "\n", "heatmap", "=", "torch", ".", "cat", "(", "[", "r", ",", "g", ",", "b", "]", ")", "\n", "\n", "result", "=", "heatmap", "+", "img", ".", "cpu", "(", ")", "\n", "result", "=", "result", ".", "div", "(", "result", ".", "max", "(", ")", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "heatmap", ",", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet_layer": [[28, 76], ["target_layer_name.split", "int", "hierarchy[].lstrip", "len", "int", "len", "len", "hierarchy[].lower().lstrip().lstrip", "ValueError", "hierarchy[].lower().lstrip", "hierarchy[].lower"], "function", ["None"], ["", "def", "find_resnet_layer", "(", "arch", ",", "target_layer_name", ")", ":", "\n", "    ", "\"\"\"Find resnet layer to calculate GradCAM and GradCAM++\n    \n    Args:\n        arch: default torchvision densenet models\n        target_layer_name (str): the name of layer with its hierarchical information. please refer to usages below.\n            target_layer_name = 'conv1'\n            target_layer_name = 'layer1'\n            target_layer_name = 'layer1_basicblock0'\n            target_layer_name = 'layer1_basicblock0_relu'\n            target_layer_name = 'layer1_bottleneck0'\n            target_layer_name = 'layer1_bottleneck0_conv1'\n            target_layer_name = 'layer1_bottleneck0_downsample'\n            target_layer_name = 'layer1_bottleneck0_downsample_0'\n            target_layer_name = 'avgpool'\n            target_layer_name = 'fc'\n            \n    Return:\n        target_layer: found layer. this layer will be hooked to get forward/backward pass information.\n    \"\"\"", "\n", "if", "'layer'", "in", "target_layer_name", ":", "\n", "        ", "hierarchy", "=", "target_layer_name", ".", "split", "(", "'_'", ")", "\n", "layer_num", "=", "int", "(", "hierarchy", "[", "0", "]", ".", "lstrip", "(", "'layer'", ")", ")", "\n", "if", "layer_num", "==", "1", ":", "\n", "            ", "target_layer", "=", "arch", ".", "layer1", "\n", "", "elif", "layer_num", "==", "2", ":", "\n", "            ", "target_layer", "=", "arch", ".", "layer2", "\n", "", "elif", "layer_num", "==", "3", ":", "\n", "            ", "target_layer", "=", "arch", ".", "layer3", "\n", "", "elif", "layer_num", "==", "4", ":", "\n", "            ", "target_layer", "=", "arch", ".", "layer4", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown layer : {}'", ".", "format", "(", "target_layer_name", ")", ")", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", ">=", "2", ":", "\n", "            ", "bottleneck_num", "=", "int", "(", "hierarchy", "[", "1", "]", ".", "lower", "(", ")", ".", "lstrip", "(", "'bottleneck'", ")", ".", "lstrip", "(", "'basicblock'", ")", ")", "\n", "target_layer", "=", "target_layer", "[", "bottleneck_num", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", ">=", "3", ":", "\n", "            ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "2", "]", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", "==", "4", ":", "\n", "            ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "3", "]", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "target_layer", "=", "arch", ".", "_modules", "[", "target_layer_name", "]", "\n", "\n", "", "return", "target_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_resnet18_layer": [[78, 126], ["target_layer_name.split", "int", "hierarchy[].lstrip", "len", "int", "len", "len", "hierarchy[].lower().lstrip().lstrip", "ValueError", "hierarchy[].lower().lstrip", "hierarchy[].lower"], "function", ["None"], ["", "def", "find_resnet18_layer", "(", "arch", ",", "target_layer_name", ")", ":", "\n", "    ", "\"\"\"Find resnet layer to calculate GradCAM and GradCAM++\n\n    Args:\n        arch: default torchvision densenet models\n        target_layer_name (str): the name of layer with its hierarchical information. please refer to usages below.\n            target_layer_name = 'conv1'\n            target_layer_name = 'layer1'\n            target_layer_name = 'layer1_basicblock0'\n            target_layer_name = 'layer1_basicblock0_relu'\n            target_layer_name = 'layer1_bottleneck0'\n            target_layer_name = 'layer1_bottleneck0_conv1'\n            target_layer_name = 'layer1_bottleneck0_downsample'\n            target_layer_name = 'layer1_bottleneck0_downsample_0'\n            target_layer_name = 'avgpool'\n            target_layer_name = 'fc'\n\n    Return:\n        target_layer: found layer. this layer will be hooked to get forward/backward pass information.\n    \"\"\"", "\n", "if", "'layer'", "in", "target_layer_name", ":", "\n", "        ", "hierarchy", "=", "target_layer_name", ".", "split", "(", "'_'", ")", "\n", "layer_num", "=", "int", "(", "hierarchy", "[", "0", "]", ".", "lstrip", "(", "'layer'", ")", ")", "\n", "if", "layer_num", "==", "1", ":", "\n", "            ", "target_layer", "=", "arch", ".", "_modules", "[", "'0'", "]", ".", "layer1", "\n", "", "elif", "layer_num", "==", "2", ":", "\n", "            ", "target_layer", "=", "arch", ".", "_modules", "[", "'0'", "]", ".", "layer2", "\n", "", "elif", "layer_num", "==", "3", ":", "\n", "            ", "target_layer", "=", "arch", ".", "_modules", "[", "'0'", "]", ".", "layer3", "\n", "", "elif", "layer_num", "==", "4", ":", "\n", "            ", "target_layer", "=", "arch", ".", "_modules", "[", "'0'", "]", ".", "layer4", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown layer : {}'", ".", "format", "(", "target_layer_name", ")", ")", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", ">=", "2", ":", "\n", "            ", "bottleneck_num", "=", "int", "(", "hierarchy", "[", "1", "]", ".", "lower", "(", ")", ".", "lstrip", "(", "'bottleneck'", ")", ".", "lstrip", "(", "'basicblock'", ")", ")", "\n", "target_layer", "=", "target_layer", "[", "bottleneck_num", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", ">=", "3", ":", "\n", "            ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "2", "]", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", "==", "4", ":", "\n", "            ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "3", "]", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "target_layer", "=", "arch", ".", "_modules", "[", "target_layer_name", "]", "\n", "\n", "", "return", "target_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_densenet_layer": [[128, 159], ["target_layer_name.split", "len", "len", "len"], "function", ["None"], ["", "def", "find_densenet_layer", "(", "arch", ",", "target_layer_name", ")", ":", "\n", "    ", "\"\"\"Find densenet layer to calculate GradCAM and GradCAM++\n    \n    Args:\n        arch: default torchvision densenet models\n        target_layer_name (str): the name of layer with its hierarchical information. please refer to usages below.\n            target_layer_name = 'features'\n            target_layer_name = 'features_transition1'\n            target_layer_name = 'features_transition1_norm'\n            target_layer_name = 'features_denseblock2_denselayer12'\n            target_layer_name = 'features_denseblock2_denselayer12_norm1'\n            target_layer_name = 'features_denseblock2_denselayer12_norm1'\n            target_layer_name = 'classifier'\n            \n    Return:\n        target_layer: found layer. this layer will be hooked to get forward/backward pass information.\n    \"\"\"", "\n", "\n", "hierarchy", "=", "target_layer_name", ".", "split", "(", "'_'", ")", "\n", "target_layer", "=", "arch", ".", "_modules", "[", "hierarchy", "[", "0", "]", "]", "\n", "\n", "if", "len", "(", "hierarchy", ")", ">=", "2", ":", "\n", "        ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "1", "]", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", ">=", "3", ":", "\n", "        ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "2", "]", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", "==", "4", ":", "\n", "        ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "3", "]", "]", "\n", "\n", "", "return", "target_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_vgg_layer": [[161, 184], ["target_layer_name.split", "len", "len", "int"], "function", ["None"], ["", "def", "find_vgg_layer", "(", "arch", ",", "target_layer_name", ")", ":", "\n", "    ", "\"\"\"Find vgg layer to calculate GradCAM and GradCAM++\n    \n    Args:\n        arch: default torchvision densenet models\n        target_layer_name (str): the name of layer with its hierarchical information. please refer to usages below.\n            target_layer_name = 'features'\n            target_layer_name = 'features_42'\n            target_layer_name = 'classifier'\n            target_layer_name = 'classifier_0'\n            \n    Return:\n        target_layer: found layer. this layer will be hooked to get forward/backward pass information.\n    \"\"\"", "\n", "hierarchy", "=", "target_layer_name", ".", "split", "(", "'_'", ")", "\n", "\n", "if", "len", "(", "hierarchy", ")", ">=", "1", ":", "\n", "        ", "target_layer", "=", "arch", ".", "features", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", "==", "2", ":", "\n", "        ", "target_layer", "=", "target_layer", "[", "int", "(", "hierarchy", "[", "1", "]", ")", "]", "\n", "\n", "", "return", "target_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_alexnet_layer": [[186, 209], ["target_layer_name.split", "len", "len", "int"], "function", ["None"], ["", "def", "find_alexnet_layer", "(", "arch", ",", "target_layer_name", ")", ":", "\n", "    ", "\"\"\"Find alexnet layer to calculate GradCAM and GradCAM++\n    \n    Args:\n        arch: default torchvision densenet models\n        target_layer_name (str): the name of layer with its hierarchical information. please refer to usages below.\n            target_layer_name = 'features'\n            target_layer_name = 'features_0'\n            target_layer_name = 'classifier'\n            target_layer_name = 'classifier_0'\n            \n    Return:\n        target_layer: found layer. this layer will be hooked to get forward/backward pass information.\n    \"\"\"", "\n", "hierarchy", "=", "target_layer_name", ".", "split", "(", "'_'", ")", "\n", "\n", "if", "len", "(", "hierarchy", ")", ">=", "1", ":", "\n", "        ", "target_layer", "=", "arch", ".", "features", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", "==", "2", ":", "\n", "        ", "target_layer", "=", "target_layer", "[", "int", "(", "hierarchy", "[", "1", "]", ")", "]", "\n", "\n", "", "return", "target_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.find_squeezenet_layer": [[211, 237], ["target_layer_name.split", "len", "len", "len"], "function", ["None"], ["", "def", "find_squeezenet_layer", "(", "arch", ",", "target_layer_name", ")", ":", "\n", "    ", "\"\"\"Find squeezenet layer to calculate GradCAM and GradCAM++\n    \n    Args:\n        arch: default torchvision densenet models\n        target_layer_name (str): the name of layer with its hierarchical information. please refer to usages below.\n            target_layer_name = 'features_12'\n            target_layer_name = 'features_12_expand3x3'\n            target_layer_name = 'features_12_expand3x3_activation'\n            \n    Return:\n        target_layer: found layer. this layer will be hooked to get forward/backward pass information.\n    \"\"\"", "\n", "hierarchy", "=", "target_layer_name", ".", "split", "(", "'_'", ")", "\n", "target_layer", "=", "arch", ".", "_modules", "[", "hierarchy", "[", "0", "]", "]", "\n", "\n", "if", "len", "(", "hierarchy", ")", ">=", "2", ":", "\n", "        ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "1", "]", "]", "\n", "\n", "", "if", "len", "(", "hierarchy", ")", "==", "3", ":", "\n", "        ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "2", "]", "]", "\n", "\n", "", "elif", "len", "(", "hierarchy", ")", "==", "4", ":", "\n", "        ", "target_layer", "=", "target_layer", ".", "_modules", "[", "hierarchy", "[", "2", "]", "+", "'_'", "+", "hierarchy", "[", "3", "]", "]", "\n", "\n", "", "return", "target_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.denormalize": [[239, 247], ["torch.FloatTensor().view().expand_as().to", "torch.FloatTensor().view().expand_as().to", "tensor.mul().add", "TypeError", "tensor.ndimension", "torch.FloatTensor().view().expand_as", "torch.FloatTensor().view().expand_as", "tensor.mul", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "denormalize", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "    ", "if", "not", "tensor", ".", "ndimension", "(", ")", "==", "4", ":", "\n", "        ", "raise", "TypeError", "(", "'tensor should be 4D'", ")", "\n", "\n", "", "mean", "=", "torch", ".", "FloatTensor", "(", "mean", ")", ".", "view", "(", "1", ",", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "tensor", ")", ".", "to", "(", "tensor", ".", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "std", ")", ".", "view", "(", "1", ",", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "tensor", ")", ".", "to", "(", "tensor", ".", "device", ")", "\n", "\n", "return", "tensor", ".", "mul", "(", "std", ")", ".", "add", "(", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.olivesgatech_explanatory-paradigms.None.utils.normalize": [[249, 257], ["torch.FloatTensor().view().expand_as().to", "torch.FloatTensor().view().expand_as().to", "tensor.sub().div", "TypeError", "tensor.ndimension", "torch.FloatTensor().view().expand_as", "torch.FloatTensor().view().expand_as", "tensor.sub", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["", "def", "normalize", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "    ", "if", "not", "tensor", ".", "ndimension", "(", ")", "==", "4", ":", "\n", "        ", "raise", "TypeError", "(", "'tensor should be 4D'", ")", "\n", "\n", "", "mean", "=", "torch", ".", "FloatTensor", "(", "mean", ")", ".", "view", "(", "1", ",", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "tensor", ")", ".", "to", "(", "tensor", ".", "device", ")", "\n", "std", "=", "torch", ".", "FloatTensor", "(", "std", ")", ".", "view", "(", "1", ",", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "tensor", ")", ".", "to", "(", "tensor", ".", "device", ")", "\n", "\n", "return", "tensor", ".", "sub", "(", "mean", ")", ".", "div", "(", "std", ")", "\n", "\n"]]}